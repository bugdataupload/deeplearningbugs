WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:55:19.218234 4469583296 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:55:19.218452 4469583296 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:55:19.218556 4469583296 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:55:19.732421 4469583296 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:55:19.732773 4469583296 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:55:19.733082: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:55:19.748018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb24787ad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:55:19.748041: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:55:19.748400 4469583296 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:55:19.751636 4469583296 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:55:19.761901 4469583296 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:55:19.770983 4469583296 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:55:19.794447 4469583296 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:55:19.802520 4469583296 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:55:19.802739 4469583296 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:55:19.813287 4469583296 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:55:19.815662 4469583296 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:55:19.841844 4469583296 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:55:20.078117 4469583296 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:55:20.078490 4469583296 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:55:20.087098 4469583296 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:55:20.105706 4469583296 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:55:20.106789 4469583296 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:55:20.122063 4469583296 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:55:20.123300 4469583296 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:55:20.145153 4469583296 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:55:20.146224 4469583296 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:55:20.160295 4469583296 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:55:20.161348 4469583296 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:55:20.177443 4469583296 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:55:20.178744 4469583296 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:55:20.197257 4469583296 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:55:20.198347 4469583296 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:55:20.212528 4469583296 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:55:20.213583 4469583296 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:55:20.231884 4469583296 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:55:20.233731 4469583296 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:55:20.250988 4469583296 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:55:20.252074 4469583296 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:55:20.255608 4469583296 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:55:20.594690 4469583296 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:55:20.594875 4469583296 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:55:20.639477 4469583296 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:55:21.183777 4469583296 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:56:43.531927 4469583296 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720

2020-02-08T02:55:21.183312: step 1, loss 3.06655, acc 0.53125
2020-02-08T02:55:21.339066: step 2, loss 2.58106, acc 0.40625
2020-02-08T02:55:21.455379: step 3, loss 2.48816, acc 0.453125
2020-02-08T02:55:21.570069: step 4, loss 2.38754, acc 0.453125
2020-02-08T02:55:21.686505: step 5, loss 2.19772, acc 0.484375
2020-02-08T02:55:21.804678: step 6, loss 2.59005, acc 0.484375
2020-02-08T02:55:21.922033: step 7, loss 1.67136, acc 0.609375
2020-02-08T02:55:22.041974: step 8, loss 2.51223, acc 0.40625
2020-02-08T02:55:22.161658: step 9, loss 1.52557, acc 0.65625
2020-02-08T02:55:22.277511: step 10, loss 1.78795, acc 0.546875
2020-02-08T02:55:22.399222: step 11, loss 1.79403, acc 0.546875
2020-02-08T02:55:22.515538: step 12, loss 1.87288, acc 0.5
2020-02-08T02:55:22.634755: step 13, loss 2.04006, acc 0.46875
2020-02-08T02:55:22.751890: step 14, loss 2.03054, acc 0.484375
2020-02-08T02:55:22.868713: step 15, loss 2.46245, acc 0.484375
2020-02-08T02:55:22.988655: step 16, loss 1.62834, acc 0.5
2020-02-08T02:55:23.106789: step 17, loss 1.59837, acc 0.5
2020-02-08T02:55:23.223200: step 18, loss 1.98476, acc 0.5
2020-02-08T02:55:23.339478: step 19, loss 1.81366, acc 0.46875
2020-02-08T02:55:23.456051: step 20, loss 2.16856, acc 0.375
2020-02-08T02:55:23.573067: step 21, loss 1.92155, acc 0.46875
2020-02-08T02:55:23.691121: step 22, loss 1.69789, acc 0.484375
2020-02-08T02:55:23.807697: step 23, loss 2.37929, acc 0.46875
2020-02-08T02:55:23.923715: step 24, loss 1.86689, acc 0.5
2020-02-08T02:55:24.041128: step 25, loss 1.37925, acc 0.5625
2020-02-08T02:55:24.156729: step 26, loss 1.617, acc 0.5
2020-02-08T02:55:24.271076: step 27, loss 1.54183, acc 0.5
2020-02-08T02:55:24.391769: step 28, loss 1.65181, acc 0.5
2020-02-08T02:55:24.510141: step 29, loss 2.07392, acc 0.359375
2020-02-08T02:55:24.627489: step 30, loss 1.67459, acc 0.5625
2020-02-08T02:55:24.744702: step 31, loss 1.63475, acc 0.5625
2020-02-08T02:55:24.861696: step 32, loss 1.7267, acc 0.5
2020-02-08T02:55:24.978613: step 33, loss 1.60714, acc 0.484375
2020-02-08T02:55:25.097540: step 34, loss 1.33289, acc 0.59375
2020-02-08T02:55:25.212501: step 35, loss 2.11843, acc 0.5
2020-02-08T02:55:25.328765: step 36, loss 1.48382, acc 0.5625
2020-02-08T02:55:25.445939: step 37, loss 1.90924, acc 0.546875
2020-02-08T02:55:25.562608: step 38, loss 1.65501, acc 0.578125
2020-02-08T02:55:25.678867: step 39, loss 2.19432, acc 0.5
2020-02-08T02:55:25.795749: step 40, loss 1.62845, acc 0.5625
2020-02-08T02:55:25.911846: step 41, loss 1.63504, acc 0.5
2020-02-08T02:55:26.027141: step 42, loss 1.69101, acc 0.5
2020-02-08T02:55:26.142763: step 43, loss 2.09881, acc 0.375
2020-02-08T02:55:26.260219: step 44, loss 1.46128, acc 0.578125
2020-02-08T02:55:26.372269: step 45, loss 1.68187, acc 0.546875
2020-02-08T02:55:26.489396: step 46, loss 1.66175, acc 0.46875
2020-02-08T02:55:26.605640: step 47, loss 1.63086, acc 0.5
2020-02-08T02:55:26.720454: step 48, loss 1.78515, acc 0.484375
2020-02-08T02:55:26.846095: step 49, loss 1.55221, acc 0.578125
2020-02-08T02:55:26.963703: step 50, loss 1.21978, acc 0.625
2020-02-08T02:55:27.079257: step 51, loss 1.97422, acc 0.46875
2020-02-08T02:55:27.194807: step 52, loss 1.53774, acc 0.5625
2020-02-08T02:55:27.311775: step 53, loss 1.42771, acc 0.5625
2020-02-08T02:55:27.429286: step 54, loss 1.35667, acc 0.59375
2020-02-08T02:55:27.545776: step 55, loss 1.24343, acc 0.546875
2020-02-08T02:55:27.663087: step 56, loss 1.73808, acc 0.53125
2020-02-08T02:55:27.782299: step 57, loss 1.6505, acc 0.5625
2020-02-08T02:55:27.899467: step 58, loss 1.41663, acc 0.5
2020-02-08T02:55:28.015001: step 59, loss 1.80035, acc 0.546875
2020-02-08T02:55:28.136888: step 60, loss 2.04813, acc 0.359375
2020-02-08T02:55:28.252957: step 61, loss 1.46142, acc 0.5
2020-02-08T02:55:28.368883: step 62, loss 1.5559, acc 0.5625
2020-02-08T02:55:28.488874: step 63, loss 1.33382, acc 0.453125
2020-02-08T02:55:28.607202: step 64, loss 1.47297, acc 0.453125
2020-02-08T02:55:28.722883: step 65, loss 1.82002, acc 0.5
2020-02-08T02:55:28.839554: step 66, loss 1.45695, acc 0.515625
2020-02-08T02:55:28.957460: step 67, loss 1.73594, acc 0.40625
2020-02-08T02:55:29.075458: step 68, loss 1.47054, acc 0.546875
2020-02-08T02:55:29.190805: step 69, loss 1.70419, acc 0.5
2020-02-08T02:55:29.305184: step 70, loss 1.52784, acc 0.5
2020-02-08T02:55:29.420828: step 71, loss 1.15838, acc 0.625
2020-02-08T02:55:29.536573: step 72, loss 1.89106, acc 0.453125
2020-02-08T02:55:29.654738: step 73, loss 1.23584, acc 0.65625
2020-02-08T02:55:29.773171: step 74, loss 1.45613, acc 0.46875
2020-02-08T02:55:29.893053: step 75, loss 1.46336, acc 0.515625
2020-02-08T02:55:30.011780: step 76, loss 1.27879, acc 0.609375
2020-02-08T02:55:30.128617: step 77, loss 1.65634, acc 0.5625
2020-02-08T02:55:30.246871: step 78, loss 1.20724, acc 0.59375
2020-02-08T02:55:30.362487: step 79, loss 1.30771, acc 0.53125
2020-02-08T02:55:30.480286: step 80, loss 1.2821, acc 0.59375
2020-02-08T02:55:30.598044: step 81, loss 1.77655, acc 0.515625
2020-02-08T02:55:30.717191: step 82, loss 1.58381, acc 0.515625
2020-02-08T02:55:30.835842: step 83, loss 1.98781, acc 0.484375
2020-02-08T02:55:30.953317: step 84, loss 1.3716, acc 0.53125
2020-02-08T02:55:31.068457: step 85, loss 1.19014, acc 0.546875
2020-02-08T02:55:31.185953: step 86, loss 1.61934, acc 0.4375
2020-02-08T02:55:31.304436: step 87, loss 1.57938, acc 0.484375
2020-02-08T02:55:31.420379: step 88, loss 1.36678, acc 0.484375
2020-02-08T02:55:31.536835: step 89, loss 1.87064, acc 0.59375
2020-02-08T02:55:31.653769: step 90, loss 1.58884, acc 0.5
2020-02-08T02:55:31.769218: step 91, loss 1.20831, acc 0.609375
2020-02-08T02:55:31.884960: step 92, loss 1.89968, acc 0.40625
2020-02-08T02:55:32.002260: step 93, loss 1.09928, acc 0.640625
2020-02-08T02:55:32.118005: step 94, loss 1.36968, acc 0.59375
2020-02-08T02:55:32.234662: step 95, loss 1.63993, acc 0.46875
2020-02-08T02:55:32.352259: step 96, loss 1.11189, acc 0.578125
2020-02-08T02:55:32.468397: step 97, loss 1.68998, acc 0.515625
2020-02-08T02:55:32.584214: step 98, loss 2.01338, acc 0.46875
2020-02-08T02:55:32.700797: step 99, loss 1.41855, acc 0.515625
2020-02-08T02:55:32.818544: step 100, loss 1.25053, acc 0.5625

Evaluation:
2020-02-08T02:55:33.055727: step 100, loss 0.827814, acc 0.553471

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-100

2020-02-08T02:55:34.893261: step 101, loss 1.23915, acc 0.546875
2020-02-08T02:55:35.008276: step 102, loss 1.68459, acc 0.546875
2020-02-08T02:55:35.122904: step 103, loss 1.30131, acc 0.546875
2020-02-08T02:55:35.239673: step 104, loss 1.7637, acc 0.515625
2020-02-08T02:55:35.353249: step 105, loss 1.36416, acc 0.484375
2020-02-08T02:55:35.470879: step 106, loss 1.57943, acc 0.515625
2020-02-08T02:55:35.586189: step 107, loss 1.67711, acc 0.484375
2020-02-08T02:55:35.704036: step 108, loss 1.68661, acc 0.484375
2020-02-08T02:55:35.819841: step 109, loss 1.28708, acc 0.515625
2020-02-08T02:55:35.935492: step 110, loss 1.12166, acc 0.546875
2020-02-08T02:55:36.047939: step 111, loss 1.30406, acc 0.484375
2020-02-08T02:55:36.167516: step 112, loss 1.23803, acc 0.65625
2020-02-08T02:55:36.284535: step 113, loss 1.456, acc 0.515625
2020-02-08T02:55:36.407053: step 114, loss 1.3407, acc 0.53125
2020-02-08T02:55:36.524003: step 115, loss 1.38591, acc 0.546875
2020-02-08T02:55:36.640576: step 116, loss 1.5706, acc 0.484375
2020-02-08T02:55:36.761000: step 117, loss 1.81401, acc 0.359375
2020-02-08T02:55:36.880628: step 118, loss 1.23451, acc 0.546875
2020-02-08T02:55:36.998189: step 119, loss 1.51063, acc 0.484375
2020-02-08T02:55:37.116190: step 120, loss 1.19527, acc 0.5625
2020-02-08T02:55:37.231839: step 121, loss 1.40745, acc 0.5625
2020-02-08T02:55:37.351650: step 122, loss 1.38575, acc 0.53125
2020-02-08T02:55:37.471419: step 123, loss 1.45611, acc 0.453125
2020-02-08T02:55:37.587782: step 124, loss 1.43259, acc 0.546875
2020-02-08T02:55:37.704914: step 125, loss 1.46248, acc 0.5
2020-02-08T02:55:37.821573: step 126, loss 1.17668, acc 0.53125
2020-02-08T02:55:37.937410: step 127, loss 1.80586, acc 0.5
2020-02-08T02:55:38.055341: step 128, loss 1.46758, acc 0.484375
2020-02-08T02:55:38.172173: step 129, loss 1.13231, acc 0.484375
2020-02-08T02:55:38.287492: step 130, loss 1.38239, acc 0.53125
2020-02-08T02:55:38.402776: step 131, loss 1.40179, acc 0.5625
2020-02-08T02:55:38.519058: step 132, loss 1.25304, acc 0.65625
2020-02-08T02:55:38.637007: step 133, loss 1.22013, acc 0.578125
2020-02-08T02:55:38.754564: step 134, loss 1.9504, acc 0.453125
2020-02-08T02:55:38.872041: step 135, loss 1.18361, acc 0.5625
2020-02-08T02:55:38.988338: step 136, loss 1.81219, acc 0.46875
2020-02-08T02:55:39.105928: step 137, loss 1.39649, acc 0.53125
2020-02-08T02:55:39.220316: step 138, loss 1.22947, acc 0.484375
2020-02-08T02:55:39.339509: step 139, loss 0.99412, acc 0.59375
2020-02-08T02:55:39.457165: step 140, loss 1.35302, acc 0.5625
2020-02-08T02:55:39.573463: step 141, loss 1.57442, acc 0.546875
2020-02-08T02:55:39.691087: step 142, loss 1.53301, acc 0.53125
2020-02-08T02:55:39.808694: step 143, loss 0.858613, acc 0.671875
2020-02-08T02:55:39.925931: step 144, loss 1.00617, acc 0.53125
2020-02-08T02:55:40.043530: step 145, loss 1.64684, acc 0.5
2020-02-08T02:55:40.159162: step 146, loss 1.17107, acc 0.453125
2020-02-08T02:55:40.274687: step 147, loss 1.14549, acc 0.609375
2020-02-08T02:55:40.391889: step 148, loss 1.35765, acc 0.515625
2020-02-08T02:55:40.508850: step 149, loss 1.26167, acc 0.421875
2020-02-08T02:55:40.620927: step 150, loss 1.3039, acc 0.566667
2020-02-08T02:55:40.738821: step 151, loss 1.24478, acc 0.484375
2020-02-08T02:55:40.858383: step 152, loss 1.11201, acc 0.515625
2020-02-08T02:55:40.976400: step 153, loss 1.07643, acc 0.59375
2020-02-08T02:55:41.093515: step 154, loss 0.991021, acc 0.578125
2020-02-08T02:55:41.208872: step 155, loss 1.04452, acc 0.625
2020-02-08T02:55:41.323033: step 156, loss 0.990093, acc 0.65625
2020-02-08T02:55:41.442013: step 157, loss 0.708289, acc 0.734375
2020-02-08T02:55:41.558936: step 158, loss 1.14012, acc 0.546875
2020-02-08T02:55:41.674962: step 159, loss 0.898903, acc 0.59375
2020-02-08T02:55:41.794558: step 160, loss 0.99859, acc 0.640625
2020-02-08T02:55:41.910737: step 161, loss 1.02833, acc 0.53125
2020-02-08T02:55:42.028225: step 162, loss 1.00251, acc 0.578125
2020-02-08T02:55:42.146332: step 163, loss 0.911432, acc 0.65625
2020-02-08T02:55:42.269562: step 164, loss 1.12637, acc 0.609375
2020-02-08T02:55:42.388197: step 165, loss 0.947622, acc 0.65625
2020-02-08T02:55:42.616240: step 166, loss 1.0263, acc 0.546875
2020-02-08T02:55:42.749675: step 167, loss 0.692266, acc 0.671875
2020-02-08T02:55:42.875036: step 168, loss 0.780178, acc 0.609375
2020-02-08T02:55:43.007864: step 169, loss 0.829227, acc 0.6875
2020-02-08T02:55:43.141328: step 170, loss 1.08482, acc 0.5625
2020-02-08T02:55:43.277927: step 171, loss 0.919524, acc 0.640625
2020-02-08T02:55:43.411778: step 172, loss 0.964824, acc 0.59375
2020-02-08T02:55:43.546048: step 173, loss 0.996316, acc 0.625
2020-02-08T02:55:43.679362: step 174, loss 1.30768, acc 0.546875
2020-02-08T02:55:43.810262: step 175, loss 1.15563, acc 0.5625
2020-02-08T02:55:43.939455: step 176, loss 0.723248, acc 0.640625
2020-02-08T02:55:44.070756: step 177, loss 0.768943, acc 0.625
2020-02-08T02:55:44.198200: step 178, loss 0.939357, acc 0.609375
2020-02-08T02:55:44.327616: step 179, loss 1.03169, acc 0.609375
2020-02-08T02:55:44.459883: step 180, loss 0.952108, acc 0.625
2020-02-08T02:55:44.592246: step 181, loss 1.06361, acc 0.5625
2020-02-08T02:55:44.724469: step 182, loss 0.79814, acc 0.671875
2020-02-08T02:55:44.857330: step 183, loss 1.12569, acc 0.578125
2020-02-08T02:55:44.987053: step 184, loss 1.18107, acc 0.515625
2020-02-08T02:55:45.119916: step 185, loss 0.92189, acc 0.515625
2020-02-08T02:55:45.251771: step 186, loss 1.01979, acc 0.53125
2020-02-08T02:55:45.375706: step 187, loss 0.776342, acc 0.6875
2020-02-08T02:55:45.512966: step 188, loss 0.908212, acc 0.625
2020-02-08T02:55:45.654099: step 189, loss 1.00641, acc 0.640625
2020-02-08T02:55:45.797099: step 190, loss 1.22038, acc 0.53125
2020-02-08T02:55:45.940856: step 191, loss 0.839565, acc 0.640625
2020-02-08T02:55:46.080290: step 192, loss 1.2676, acc 0.546875
2020-02-08T02:55:46.220475: step 193, loss 0.856482, acc 0.625
2020-02-08T02:55:46.360295: step 194, loss 0.886679, acc 0.640625
2020-02-08T02:55:46.491517: step 195, loss 1.1498, acc 0.578125
2020-02-08T02:55:46.619356: step 196, loss 0.819333, acc 0.625
2020-02-08T02:55:46.749215: step 197, loss 0.730319, acc 0.671875
2020-02-08T02:55:46.871935: step 198, loss 0.879174, acc 0.609375
2020-02-08T02:55:46.996738: step 199, loss 1.08144, acc 0.546875
2020-02-08T02:55:47.121656: step 200, loss 0.992397, acc 0.546875

Evaluation:
2020-02-08T02:55:47.321405: step 200, loss 0.692064, acc 0.586304

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-200

2020-02-08T02:55:48.843760: step 201, loss 1.034, acc 0.640625
2020-02-08T02:55:48.973091: step 202, loss 0.926268, acc 0.671875
2020-02-08T02:55:49.098589: step 203, loss 0.928887, acc 0.578125
2020-02-08T02:55:49.222632: step 204, loss 1.03402, acc 0.515625
2020-02-08T02:55:49.356865: step 205, loss 0.99821, acc 0.59375
2020-02-08T02:55:49.496554: step 206, loss 1.01058, acc 0.578125
2020-02-08T02:55:49.637163: step 207, loss 0.787949, acc 0.65625
2020-02-08T02:55:49.771750: step 208, loss 0.765154, acc 0.59375
2020-02-08T02:55:49.907615: step 209, loss 1.02728, acc 0.5625
2020-02-08T02:55:50.046341: step 210, loss 0.97104, acc 0.484375
2020-02-08T02:55:50.187439: step 211, loss 0.634522, acc 0.6875
2020-02-08T02:55:50.326583: step 212, loss 0.81344, acc 0.65625
2020-02-08T02:55:50.465083: step 213, loss 0.727425, acc 0.65625
2020-02-08T02:55:50.617723: step 214, loss 0.704559, acc 0.671875
2020-02-08T02:55:50.757988: step 215, loss 0.77156, acc 0.671875
2020-02-08T02:55:50.895343: step 216, loss 0.871515, acc 0.609375
2020-02-08T02:55:51.030492: step 217, loss 0.765629, acc 0.59375
2020-02-08T02:55:51.163441: step 218, loss 1.01809, acc 0.546875
2020-02-08T02:55:51.286277: step 219, loss 0.918272, acc 0.578125
2020-02-08T02:55:51.418625: step 220, loss 0.54306, acc 0.734375
2020-02-08T02:55:51.559960: step 221, loss 0.76784, acc 0.59375
2020-02-08T02:55:51.727754: step 222, loss 0.932154, acc 0.53125
2020-02-08T02:55:51.864272: step 223, loss 0.867199, acc 0.609375
2020-02-08T02:55:52.004599: step 224, loss 0.884623, acc 0.625
2020-02-08T02:55:52.146085: step 225, loss 1.13713, acc 0.453125
2020-02-08T02:55:52.285298: step 226, loss 0.87363, acc 0.578125
2020-02-08T02:55:52.425291: step 227, loss 0.996388, acc 0.578125
2020-02-08T02:55:52.564221: step 228, loss 1.02682, acc 0.5
2020-02-08T02:55:52.700485: step 229, loss 0.85089, acc 0.59375
2020-02-08T02:55:52.827962: step 230, loss 0.921384, acc 0.578125
2020-02-08T02:55:52.956984: step 231, loss 0.983419, acc 0.578125
2020-02-08T02:55:53.080052: step 232, loss 0.81571, acc 0.65625
2020-02-08T02:55:53.205112: step 233, loss 0.688398, acc 0.6875
2020-02-08T02:55:53.332806: step 234, loss 0.914988, acc 0.578125
2020-02-08T02:55:53.456908: step 235, loss 0.735234, acc 0.5625
2020-02-08T02:55:53.580385: step 236, loss 0.887606, acc 0.625
2020-02-08T02:55:53.712894: step 237, loss 0.894356, acc 0.59375
2020-02-08T02:55:53.835468: step 238, loss 0.497749, acc 0.71875
2020-02-08T02:55:53.962696: step 239, loss 0.900093, acc 0.5625
2020-02-08T02:55:54.092558: step 240, loss 1.17494, acc 0.53125
2020-02-08T02:55:54.214970: step 241, loss 0.904822, acc 0.578125
2020-02-08T02:55:54.340784: step 242, loss 0.89161, acc 0.578125
2020-02-08T02:55:54.462024: step 243, loss 0.874427, acc 0.625
2020-02-08T02:55:54.589388: step 244, loss 0.972291, acc 0.59375
2020-02-08T02:55:54.711752: step 245, loss 0.844249, acc 0.5625
2020-02-08T02:55:54.833971: step 246, loss 0.741943, acc 0.640625
2020-02-08T02:55:54.960954: step 247, loss 0.725991, acc 0.625
2020-02-08T02:55:55.080527: step 248, loss 0.701723, acc 0.625
2020-02-08T02:55:55.202102: step 249, loss 0.871635, acc 0.625
2020-02-08T02:55:55.319846: step 250, loss 0.696409, acc 0.671875
2020-02-08T02:55:55.442389: step 251, loss 0.849267, acc 0.625
2020-02-08T02:55:55.558753: step 252, loss 0.878755, acc 0.65625
2020-02-08T02:55:55.674736: step 253, loss 0.956646, acc 0.65625
2020-02-08T02:55:55.794697: step 254, loss 0.925625, acc 0.546875
2020-02-08T02:55:55.912811: step 255, loss 0.77752, acc 0.65625
2020-02-08T02:55:56.032187: step 256, loss 0.957737, acc 0.5625
2020-02-08T02:55:56.149239: step 257, loss 0.949627, acc 0.515625
2020-02-08T02:55:56.265132: step 258, loss 0.931811, acc 0.5625
2020-02-08T02:55:56.386747: step 259, loss 0.80999, acc 0.625
2020-02-08T02:55:56.504302: step 260, loss 0.684274, acc 0.703125
2020-02-08T02:55:56.620367: step 261, loss 0.890003, acc 0.59375
2020-02-08T02:55:56.739111: step 262, loss 0.74499, acc 0.59375
2020-02-08T02:55:56.857818: step 263, loss 0.837754, acc 0.609375
2020-02-08T02:55:56.972150: step 264, loss 0.939362, acc 0.578125
2020-02-08T02:55:57.088899: step 265, loss 0.692631, acc 0.703125
2020-02-08T02:55:57.205532: step 266, loss 0.888749, acc 0.578125
2020-02-08T02:55:57.320467: step 267, loss 0.888725, acc 0.671875
2020-02-08T02:55:57.435693: step 268, loss 0.675472, acc 0.703125
2020-02-08T02:55:57.555785: step 269, loss 0.748161, acc 0.625
2020-02-08T02:55:57.671774: step 270, loss 0.735648, acc 0.65625
2020-02-08T02:55:57.788196: step 271, loss 0.770171, acc 0.5625
2020-02-08T02:55:57.906700: step 272, loss 0.981161, acc 0.5625
2020-02-08T02:55:58.021312: step 273, loss 0.749653, acc 0.6875
2020-02-08T02:55:58.142337: step 274, loss 0.673412, acc 0.671875
2020-02-08T02:55:58.260407: step 275, loss 0.649995, acc 0.703125
2020-02-08T02:55:58.378620: step 276, loss 0.805537, acc 0.515625
2020-02-08T02:55:58.496642: step 277, loss 0.528926, acc 0.703125
2020-02-08T02:55:58.611994: step 278, loss 0.5953, acc 0.75
2020-02-08T02:55:58.725192: step 279, loss 0.940701, acc 0.484375
2020-02-08T02:55:58.844009: step 280, loss 0.743842, acc 0.71875
2020-02-08T02:55:58.961045: step 281, loss 0.716408, acc 0.65625
2020-02-08T02:55:59.079922: step 282, loss 0.901026, acc 0.5625
2020-02-08T02:55:59.197331: step 283, loss 0.950585, acc 0.5625
2020-02-08T02:55:59.314680: step 284, loss 0.700802, acc 0.5625
2020-02-08T02:55:59.432634: step 285, loss 0.795773, acc 0.59375
2020-02-08T02:55:59.548007: step 286, loss 0.874647, acc 0.625
2020-02-08T02:55:59.664550: step 287, loss 0.897127, acc 0.53125
2020-02-08T02:55:59.781277: step 288, loss 0.755919, acc 0.5625
2020-02-08T02:55:59.898325: step 289, loss 0.673636, acc 0.625
2020-02-08T02:56:00.014624: step 290, loss 0.752206, acc 0.609375
2020-02-08T02:56:00.129757: step 291, loss 0.793654, acc 0.53125
2020-02-08T02:56:00.248918: step 292, loss 0.821078, acc 0.59375
2020-02-08T02:56:00.364753: step 293, loss 0.897175, acc 0.640625
2020-02-08T02:56:00.482689: step 294, loss 0.925003, acc 0.59375
2020-02-08T02:56:00.602403: step 295, loss 0.575816, acc 0.71875
2020-02-08T02:56:00.718632: step 296, loss 0.679083, acc 0.640625
2020-02-08T02:56:00.837281: step 297, loss 0.568213, acc 0.765625
2020-02-08T02:56:00.954038: step 298, loss 0.690791, acc 0.703125
2020-02-08T02:56:01.069315: step 299, loss 0.902728, acc 0.515625
2020-02-08T02:56:01.182042: step 300, loss 0.799385, acc 0.616667

Evaluation:
2020-02-08T02:56:01.367656: step 300, loss 0.659861, acc 0.61257

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-300

2020-02-08T02:56:03.160668: step 301, loss 0.737748, acc 0.6875
2020-02-08T02:56:03.276186: step 302, loss 0.972678, acc 0.546875
2020-02-08T02:56:03.392296: step 303, loss 0.747861, acc 0.609375
2020-02-08T02:56:03.508242: step 304, loss 0.713421, acc 0.609375
2020-02-08T02:56:03.625397: step 305, loss 0.639798, acc 0.71875
2020-02-08T02:56:03.742010: step 306, loss 0.797808, acc 0.578125
2020-02-08T02:56:03.860995: step 307, loss 0.488938, acc 0.75
2020-02-08T02:56:03.978994: step 308, loss 0.841804, acc 0.609375
2020-02-08T02:56:04.095919: step 309, loss 0.632814, acc 0.703125
2020-02-08T02:56:04.212373: step 310, loss 0.992295, acc 0.515625
2020-02-08T02:56:04.328134: step 311, loss 0.628849, acc 0.703125
2020-02-08T02:56:04.444839: step 312, loss 0.47764, acc 0.765625
2020-02-08T02:56:04.563046: step 313, loss 0.793426, acc 0.640625
2020-02-08T02:56:04.679046: step 314, loss 0.72739, acc 0.640625
2020-02-08T02:56:04.798148: step 315, loss 0.66722, acc 0.625
2020-02-08T02:56:04.917195: step 316, loss 0.77939, acc 0.609375
2020-02-08T02:56:05.032429: step 317, loss 0.620711, acc 0.6875
2020-02-08T02:56:05.149604: step 318, loss 0.711265, acc 0.609375
2020-02-08T02:56:05.269053: step 319, loss 0.71752, acc 0.625
2020-02-08T02:56:05.388654: step 320, loss 0.757821, acc 0.59375
2020-02-08T02:56:05.507790: step 321, loss 0.676889, acc 0.6875
2020-02-08T02:56:05.623027: step 322, loss 0.682542, acc 0.640625
2020-02-08T02:56:05.740428: step 323, loss 0.587905, acc 0.671875
2020-02-08T02:56:05.858075: step 324, loss 0.586518, acc 0.734375
2020-02-08T02:56:05.970923: step 325, loss 0.677522, acc 0.65625
2020-02-08T02:56:06.087627: step 326, loss 0.66556, acc 0.640625
2020-02-08T02:56:06.206812: step 327, loss 0.595868, acc 0.671875
2020-02-08T02:56:06.320272: step 328, loss 0.591134, acc 0.6875
2020-02-08T02:56:06.436232: step 329, loss 0.757132, acc 0.625
2020-02-08T02:56:06.551513: step 330, loss 0.591078, acc 0.734375
2020-02-08T02:56:06.666073: step 331, loss 0.645873, acc 0.71875
2020-02-08T02:56:06.781860: step 332, loss 0.97968, acc 0.5
2020-02-08T02:56:06.899271: step 333, loss 0.723974, acc 0.6875
2020-02-08T02:56:07.018136: step 334, loss 0.760535, acc 0.578125
2020-02-08T02:56:07.133441: step 335, loss 0.742741, acc 0.59375
2020-02-08T02:56:07.250508: step 336, loss 0.659546, acc 0.65625
2020-02-08T02:56:07.365088: step 337, loss 0.748449, acc 0.640625
2020-02-08T02:56:07.480186: step 338, loss 0.547188, acc 0.6875
2020-02-08T02:56:07.595269: step 339, loss 0.723586, acc 0.75
2020-02-08T02:56:07.712492: step 340, loss 0.705686, acc 0.640625
2020-02-08T02:56:07.827958: step 341, loss 0.577285, acc 0.734375
2020-02-08T02:56:07.944574: step 342, loss 0.753101, acc 0.578125
2020-02-08T02:56:08.061911: step 343, loss 0.554413, acc 0.75
2020-02-08T02:56:08.177135: step 344, loss 0.677035, acc 0.671875
2020-02-08T02:56:08.295390: step 345, loss 0.649839, acc 0.6875
2020-02-08T02:56:08.413646: step 346, loss 0.751154, acc 0.625
2020-02-08T02:56:08.530058: step 347, loss 0.646321, acc 0.671875
2020-02-08T02:56:08.645810: step 348, loss 0.681949, acc 0.65625
2020-02-08T02:56:08.761709: step 349, loss 0.58333, acc 0.6875
2020-02-08T02:56:08.878172: step 350, loss 0.662136, acc 0.625
2020-02-08T02:56:08.994496: step 351, loss 0.534253, acc 0.75
2020-02-08T02:56:09.108929: step 352, loss 0.584351, acc 0.71875
2020-02-08T02:56:09.224511: step 353, loss 0.578737, acc 0.78125
2020-02-08T02:56:09.341030: step 354, loss 0.603213, acc 0.734375
2020-02-08T02:56:09.456722: step 355, loss 0.751935, acc 0.703125
2020-02-08T02:56:09.573449: step 356, loss 0.53415, acc 0.734375
2020-02-08T02:56:09.689919: step 357, loss 0.644771, acc 0.59375
2020-02-08T02:56:09.804957: step 358, loss 0.639017, acc 0.703125
2020-02-08T02:56:09.920946: step 359, loss 0.626982, acc 0.703125
2020-02-08T02:56:10.040038: step 360, loss 0.631383, acc 0.734375
2020-02-08T02:56:10.156119: step 361, loss 0.61285, acc 0.625
2020-02-08T02:56:10.268640: step 362, loss 0.757748, acc 0.546875
2020-02-08T02:56:10.387423: step 363, loss 0.777252, acc 0.609375
2020-02-08T02:56:10.501605: step 364, loss 0.525554, acc 0.703125
2020-02-08T02:56:10.614150: step 365, loss 0.589697, acc 0.6875
2020-02-08T02:56:10.729322: step 366, loss 0.549538, acc 0.703125
2020-02-08T02:56:10.847437: step 367, loss 0.714918, acc 0.65625
2020-02-08T02:56:10.963103: step 368, loss 0.697276, acc 0.640625
2020-02-08T02:56:11.077526: step 369, loss 0.703909, acc 0.640625
2020-02-08T02:56:11.199021: step 370, loss 0.585907, acc 0.671875
2020-02-08T02:56:11.314606: step 371, loss 0.63776, acc 0.6875
2020-02-08T02:56:11.428765: step 372, loss 0.631022, acc 0.609375
2020-02-08T02:56:11.546263: step 373, loss 0.644856, acc 0.71875
2020-02-08T02:56:11.662218: step 374, loss 0.799617, acc 0.5625
2020-02-08T02:56:11.778142: step 375, loss 0.640823, acc 0.671875
2020-02-08T02:56:11.894808: step 376, loss 0.596409, acc 0.6875
2020-02-08T02:56:12.010996: step 377, loss 0.577978, acc 0.734375
2020-02-08T02:56:12.128363: step 378, loss 0.554254, acc 0.78125
2020-02-08T02:56:12.245019: step 379, loss 0.617252, acc 0.6875
2020-02-08T02:56:12.360034: step 380, loss 0.512981, acc 0.703125
2020-02-08T02:56:12.473998: step 381, loss 0.67137, acc 0.671875
2020-02-08T02:56:12.591629: step 382, loss 0.660651, acc 0.59375
2020-02-08T02:56:12.709469: step 383, loss 0.509994, acc 0.796875
2020-02-08T02:56:12.824158: step 384, loss 0.792223, acc 0.578125
2020-02-08T02:56:12.941396: step 385, loss 0.619128, acc 0.75
2020-02-08T02:56:13.056696: step 386, loss 0.689054, acc 0.65625
2020-02-08T02:56:13.173609: step 387, loss 0.737354, acc 0.609375
2020-02-08T02:56:13.292375: step 388, loss 0.668617, acc 0.609375
2020-02-08T02:56:13.408595: step 389, loss 0.65073, acc 0.65625
2020-02-08T02:56:13.522327: step 390, loss 0.554295, acc 0.703125
2020-02-08T02:56:13.639104: step 391, loss 0.62437, acc 0.65625
2020-02-08T02:56:13.756400: step 392, loss 0.833127, acc 0.5625
2020-02-08T02:56:13.872798: step 393, loss 0.637819, acc 0.65625
2020-02-08T02:56:13.988508: step 394, loss 0.872029, acc 0.5
2020-02-08T02:56:14.105147: step 395, loss 0.532929, acc 0.765625
2020-02-08T02:56:14.218268: step 396, loss 0.713826, acc 0.59375
2020-02-08T02:56:14.332631: step 397, loss 0.568785, acc 0.6875
2020-02-08T02:56:14.451000: step 398, loss 0.626906, acc 0.671875
2020-02-08T02:56:14.566915: step 399, loss 0.589487, acc 0.734375
2020-02-08T02:56:14.683429: step 400, loss 0.596584, acc 0.703125

Evaluation:
2020-02-08T02:56:14.870519: step 400, loss 0.647166, acc 0.621013

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-400

2020-02-08T02:56:17.257500: step 401, loss 0.611521, acc 0.6875
2020-02-08T02:56:17.371071: step 402, loss 0.617205, acc 0.703125
2020-02-08T02:56:17.485868: step 403, loss 0.738901, acc 0.609375
2020-02-08T02:56:17.606532: step 404, loss 0.671655, acc 0.71875
2020-02-08T02:56:17.724335: step 405, loss 0.657662, acc 0.671875
2020-02-08T02:56:17.844148: step 406, loss 0.545897, acc 0.796875
2020-02-08T02:56:17.959796: step 407, loss 0.572983, acc 0.6875
2020-02-08T02:56:18.073453: step 408, loss 0.64036, acc 0.671875
2020-02-08T02:56:18.189666: step 409, loss 0.589094, acc 0.6875
2020-02-08T02:56:18.303514: step 410, loss 0.680891, acc 0.640625
2020-02-08T02:56:18.417137: step 411, loss 0.760791, acc 0.609375
2020-02-08T02:56:18.534142: step 412, loss 0.6712, acc 0.640625
2020-02-08T02:56:18.649778: step 413, loss 0.63302, acc 0.703125
2020-02-08T02:56:18.766863: step 414, loss 0.66028, acc 0.671875
2020-02-08T02:56:18.885282: step 415, loss 0.478879, acc 0.78125
2020-02-08T02:56:19.001952: step 416, loss 0.778113, acc 0.546875
2020-02-08T02:56:19.116844: step 417, loss 0.64899, acc 0.703125
2020-02-08T02:56:19.232542: step 418, loss 0.565859, acc 0.71875
2020-02-08T02:56:19.347426: step 419, loss 0.806389, acc 0.625
2020-02-08T02:56:19.461603: step 420, loss 0.632887, acc 0.640625
2020-02-08T02:56:19.576284: step 421, loss 0.716417, acc 0.609375
2020-02-08T02:56:19.693112: step 422, loss 0.550284, acc 0.734375
2020-02-08T02:56:19.809269: step 423, loss 0.694136, acc 0.609375
2020-02-08T02:56:19.922503: step 424, loss 0.750389, acc 0.546875
2020-02-08T02:56:20.038457: step 425, loss 0.503065, acc 0.765625
2020-02-08T02:56:20.156430: step 426, loss 0.64142, acc 0.671875
2020-02-08T02:56:20.273519: step 427, loss 0.675179, acc 0.640625
2020-02-08T02:56:20.391883: step 428, loss 0.632825, acc 0.671875
2020-02-08T02:56:20.505844: step 429, loss 0.640416, acc 0.625
2020-02-08T02:56:20.620477: step 430, loss 0.598652, acc 0.71875
2020-02-08T02:56:20.736508: step 431, loss 0.555315, acc 0.75
2020-02-08T02:56:20.854308: step 432, loss 0.646091, acc 0.65625
2020-02-08T02:56:20.967998: step 433, loss 0.702078, acc 0.640625
2020-02-08T02:56:21.083761: step 434, loss 0.567496, acc 0.75
2020-02-08T02:56:21.198219: step 435, loss 0.673717, acc 0.640625
2020-02-08T02:56:21.311463: step 436, loss 0.736265, acc 0.625
2020-02-08T02:56:21.500234: step 437, loss 0.548069, acc 0.703125
2020-02-08T02:56:21.631508: step 438, loss 0.577984, acc 0.625
2020-02-08T02:56:21.747980: step 439, loss 0.686285, acc 0.65625
2020-02-08T02:56:21.862882: step 440, loss 0.6189, acc 0.609375
2020-02-08T02:56:21.978524: step 441, loss 0.642314, acc 0.640625
2020-02-08T02:56:22.091228: step 442, loss 0.516825, acc 0.71875
2020-02-08T02:56:22.205563: step 443, loss 0.740147, acc 0.609375
2020-02-08T02:56:22.320608: step 444, loss 0.723804, acc 0.53125
2020-02-08T02:56:22.434883: step 445, loss 0.79257, acc 0.609375
2020-02-08T02:56:22.552654: step 446, loss 0.787984, acc 0.578125
2020-02-08T02:56:22.667043: step 447, loss 0.764565, acc 0.578125
2020-02-08T02:56:22.780949: step 448, loss 0.627082, acc 0.6875
2020-02-08T02:56:22.898545: step 449, loss 0.752282, acc 0.5625
2020-02-08T02:56:23.011517: step 450, loss 0.787768, acc 0.533333
2020-02-08T02:56:23.126252: step 451, loss 0.495496, acc 0.765625
2020-02-08T02:56:23.241853: step 452, loss 0.569847, acc 0.6875
2020-02-08T02:56:23.360594: step 453, loss 0.650328, acc 0.609375
2020-02-08T02:56:23.478653: step 454, loss 0.580656, acc 0.671875
2020-02-08T02:56:23.590581: step 455, loss 0.56447, acc 0.671875
2020-02-08T02:56:23.706849: step 456, loss 0.607369, acc 0.625
2020-02-08T02:56:23.823101: step 457, loss 0.54061, acc 0.734375
2020-02-08T02:56:23.940736: step 458, loss 0.631364, acc 0.640625
2020-02-08T02:56:24.055746: step 459, loss 0.460029, acc 0.734375
2020-02-08T02:56:24.174130: step 460, loss 0.625249, acc 0.671875
2020-02-08T02:56:24.290736: step 461, loss 0.607228, acc 0.703125
2020-02-08T02:56:24.407259: step 462, loss 0.602714, acc 0.703125
2020-02-08T02:56:24.522193: step 463, loss 0.44385, acc 0.78125
2020-02-08T02:56:24.638436: step 464, loss 0.75262, acc 0.59375
2020-02-08T02:56:24.754594: step 465, loss 0.645271, acc 0.59375
2020-02-08T02:56:24.870986: step 466, loss 0.654195, acc 0.640625
2020-02-08T02:56:24.985912: step 467, loss 0.524289, acc 0.75
2020-02-08T02:56:25.101087: step 468, loss 0.527179, acc 0.765625
2020-02-08T02:56:25.220087: step 469, loss 0.550708, acc 0.703125
2020-02-08T02:56:25.337709: step 470, loss 0.506913, acc 0.765625
2020-02-08T02:56:25.454749: step 471, loss 0.611032, acc 0.71875
2020-02-08T02:56:25.570261: step 472, loss 0.583135, acc 0.625
2020-02-08T02:56:25.688867: step 473, loss 0.634729, acc 0.671875
2020-02-08T02:56:25.802827: step 474, loss 0.471855, acc 0.765625
2020-02-08T02:56:25.918067: step 475, loss 0.579539, acc 0.703125
2020-02-08T02:56:26.035108: step 476, loss 0.570807, acc 0.75
2020-02-08T02:56:26.152271: step 477, loss 0.636265, acc 0.6875
2020-02-08T02:56:26.268902: step 478, loss 0.498574, acc 0.828125
2020-02-08T02:56:26.384724: step 479, loss 0.63257, acc 0.703125
2020-02-08T02:56:26.500347: step 480, loss 0.502105, acc 0.734375
2020-02-08T02:56:26.616615: step 481, loss 0.559865, acc 0.75
2020-02-08T02:56:26.734333: step 482, loss 0.589645, acc 0.703125
2020-02-08T02:56:26.849882: step 483, loss 0.526271, acc 0.734375
2020-02-08T02:56:26.966264: step 484, loss 0.694381, acc 0.6875
2020-02-08T02:56:27.083417: step 485, loss 0.77201, acc 0.609375
2020-02-08T02:56:27.198957: step 486, loss 0.764437, acc 0.609375
2020-02-08T02:56:27.315024: step 487, loss 0.537006, acc 0.71875
2020-02-08T02:56:27.431100: step 488, loss 0.553092, acc 0.71875
2020-02-08T02:56:27.545730: step 489, loss 0.505233, acc 0.75
2020-02-08T02:56:27.661491: step 490, loss 0.421041, acc 0.828125
2020-02-08T02:56:27.776614: step 491, loss 0.563408, acc 0.734375
2020-02-08T02:56:27.892778: step 492, loss 0.526743, acc 0.703125
2020-02-08T02:56:28.006539: step 493, loss 0.614715, acc 0.6875
2020-02-08T02:56:28.122864: step 494, loss 0.534434, acc 0.78125
2020-02-08T02:56:28.239543: step 495, loss 0.535109, acc 0.75
2020-02-08T02:56:28.355302: step 496, loss 0.623483, acc 0.640625
2020-02-08T02:56:28.470096: step 497, loss 0.579176, acc 0.703125
2020-02-08T02:56:28.587290: step 498, loss 0.587679, acc 0.6875
2020-02-08T02:56:28.703042: step 499, loss 0.593616, acc 0.6875
2020-02-08T02:56:28.818267: step 500, loss 0.619614, acc 0.734375

Evaluation:
2020-02-08T02:56:29.010892: step 500, loss 0.627735, acc 0.637899

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-500

2020-02-08T02:56:30.527632: step 501, loss 0.556611, acc 0.703125
2020-02-08T02:56:30.643131: step 502, loss 0.607927, acc 0.671875
2020-02-08T02:56:30.760200: step 503, loss 0.58766, acc 0.625
2020-02-08T02:56:30.875806: step 504, loss 0.550022, acc 0.734375
2020-02-08T02:56:30.994877: step 505, loss 0.463222, acc 0.859375
2020-02-08T02:56:31.110477: step 506, loss 0.612085, acc 0.6875
2020-02-08T02:56:31.228268: step 507, loss 0.574705, acc 0.6875
2020-02-08T02:56:31.342337: step 508, loss 0.442723, acc 0.78125
2020-02-08T02:56:31.459913: step 509, loss 0.48201, acc 0.75
2020-02-08T02:56:31.574166: step 510, loss 0.426461, acc 0.796875
2020-02-08T02:56:31.690596: step 511, loss 0.621239, acc 0.640625
2020-02-08T02:56:31.806776: step 512, loss 0.545715, acc 0.703125
2020-02-08T02:56:31.922487: step 513, loss 0.573012, acc 0.75
2020-02-08T02:56:32.039027: step 514, loss 0.558982, acc 0.703125
2020-02-08T02:56:32.157165: step 515, loss 0.62048, acc 0.65625
2020-02-08T02:56:32.272018: step 516, loss 0.496623, acc 0.8125
2020-02-08T02:56:32.388316: step 517, loss 0.544901, acc 0.6875
2020-02-08T02:56:32.509777: step 518, loss 0.492392, acc 0.796875
2020-02-08T02:56:32.624616: step 519, loss 0.529148, acc 0.671875
2020-02-08T02:56:32.741637: step 520, loss 0.598132, acc 0.671875
2020-02-08T02:56:32.858173: step 521, loss 0.665971, acc 0.625
2020-02-08T02:56:32.973070: step 522, loss 0.5779, acc 0.6875
2020-02-08T02:56:33.088031: step 523, loss 0.446846, acc 0.8125
2020-02-08T02:56:33.203947: step 524, loss 0.546623, acc 0.78125
2020-02-08T02:56:33.317508: step 525, loss 0.598211, acc 0.71875
2020-02-08T02:56:33.433352: step 526, loss 0.559295, acc 0.734375
2020-02-08T02:56:33.550108: step 527, loss 0.552774, acc 0.703125
2020-02-08T02:56:33.665475: step 528, loss 0.550166, acc 0.78125
2020-02-08T02:56:33.780810: step 529, loss 0.653818, acc 0.625
2020-02-08T02:56:33.902191: step 530, loss 0.471593, acc 0.78125
2020-02-08T02:56:34.017760: step 531, loss 0.610016, acc 0.640625
2020-02-08T02:56:34.133913: step 532, loss 0.525671, acc 0.78125
2020-02-08T02:56:34.251209: step 533, loss 0.605709, acc 0.65625
2020-02-08T02:56:34.365933: step 534, loss 0.458722, acc 0.796875
2020-02-08T02:56:34.481124: step 535, loss 0.500215, acc 0.734375
2020-02-08T02:56:34.597009: step 536, loss 0.536885, acc 0.71875
2020-02-08T02:56:34.713604: step 537, loss 0.4378, acc 0.78125
2020-02-08T02:56:34.828613: step 538, loss 0.533508, acc 0.71875
2020-02-08T02:56:34.945161: step 539, loss 0.630808, acc 0.6875
2020-02-08T02:56:35.060133: step 540, loss 0.594538, acc 0.6875
2020-02-08T02:56:35.174311: step 541, loss 0.445076, acc 0.8125
2020-02-08T02:56:35.292617: step 542, loss 0.642345, acc 0.671875
2020-02-08T02:56:35.407425: step 543, loss 0.585719, acc 0.734375
2020-02-08T02:56:35.522766: step 544, loss 0.502388, acc 0.65625
2020-02-08T02:56:35.638423: step 545, loss 0.518005, acc 0.765625
2020-02-08T02:56:35.756198: step 546, loss 0.587827, acc 0.671875
2020-02-08T02:56:35.871134: step 547, loss 0.55472, acc 0.703125
2020-02-08T02:56:35.985421: step 548, loss 0.498167, acc 0.734375
2020-02-08T02:56:36.101771: step 549, loss 0.558177, acc 0.671875
2020-02-08T02:56:36.217065: step 550, loss 0.489478, acc 0.6875
2020-02-08T02:56:36.330453: step 551, loss 0.598928, acc 0.6875
2020-02-08T02:56:36.450147: step 552, loss 0.650188, acc 0.65625
2020-02-08T02:56:36.565212: step 553, loss 0.494511, acc 0.765625
2020-02-08T02:56:36.678124: step 554, loss 0.469603, acc 0.75
2020-02-08T02:56:36.797320: step 555, loss 0.529989, acc 0.6875
2020-02-08T02:56:36.923650: step 556, loss 0.715069, acc 0.640625
2020-02-08T02:56:37.040635: step 557, loss 0.500449, acc 0.75
2020-02-08T02:56:37.156708: step 558, loss 0.542871, acc 0.703125
2020-02-08T02:56:37.269233: step 559, loss 0.508556, acc 0.75
2020-02-08T02:56:37.385239: step 560, loss 0.577681, acc 0.671875
2020-02-08T02:56:37.503538: step 561, loss 0.626989, acc 0.6875
2020-02-08T02:56:37.617128: step 562, loss 0.530757, acc 0.765625
2020-02-08T02:56:37.733166: step 563, loss 0.577766, acc 0.671875
2020-02-08T02:56:37.851969: step 564, loss 0.620071, acc 0.671875
2020-02-08T02:56:37.968811: step 565, loss 0.608245, acc 0.6875
2020-02-08T02:56:38.084320: step 566, loss 0.624161, acc 0.640625
2020-02-08T02:56:38.201399: step 567, loss 0.52819, acc 0.734375
2020-02-08T02:56:38.315594: step 568, loss 0.587649, acc 0.671875
2020-02-08T02:56:38.429929: step 569, loss 0.572484, acc 0.734375
2020-02-08T02:56:38.546674: step 570, loss 0.561876, acc 0.671875
2020-02-08T02:56:38.663326: step 571, loss 0.590075, acc 0.703125
2020-02-08T02:56:38.782848: step 572, loss 0.527225, acc 0.78125
2020-02-08T02:56:38.898414: step 573, loss 0.632783, acc 0.671875
2020-02-08T02:56:39.011748: step 574, loss 0.601583, acc 0.703125
2020-02-08T02:56:39.130780: step 575, loss 0.613803, acc 0.71875
2020-02-08T02:56:39.247113: step 576, loss 0.508609, acc 0.75
2020-02-08T02:56:39.362389: step 577, loss 0.601239, acc 0.703125
2020-02-08T02:56:39.478487: step 578, loss 0.598807, acc 0.640625
2020-02-08T02:56:39.595854: step 579, loss 0.476355, acc 0.734375
2020-02-08T02:56:39.712601: step 580, loss 0.637833, acc 0.65625
2020-02-08T02:56:39.825135: step 581, loss 0.670544, acc 0.671875
2020-02-08T02:56:39.941919: step 582, loss 0.583425, acc 0.765625
2020-02-08T02:56:40.058885: step 583, loss 0.60334, acc 0.6875
2020-02-08T02:56:40.172690: step 584, loss 0.571311, acc 0.734375
2020-02-08T02:56:40.288503: step 585, loss 0.459008, acc 0.78125
2020-02-08T02:56:40.404658: step 586, loss 0.484408, acc 0.765625
2020-02-08T02:56:40.518791: step 587, loss 0.59683, acc 0.65625
2020-02-08T02:56:40.635193: step 588, loss 0.467533, acc 0.828125
2020-02-08T02:56:40.752862: step 589, loss 0.5916, acc 0.765625
2020-02-08T02:56:40.867110: step 590, loss 0.681082, acc 0.640625
2020-02-08T02:56:40.983302: step 591, loss 0.530341, acc 0.75
2020-02-08T02:56:41.099972: step 592, loss 0.563617, acc 0.703125
2020-02-08T02:56:41.213067: step 593, loss 0.566883, acc 0.71875
2020-02-08T02:56:41.325374: step 594, loss 0.477576, acc 0.828125
2020-02-08T02:56:41.443700: step 595, loss 0.552271, acc 0.703125
2020-02-08T02:56:41.560430: step 596, loss 0.64366, acc 0.71875
2020-02-08T02:56:41.674930: step 597, loss 0.533271, acc 0.765625
2020-02-08T02:56:41.791283: step 598, loss 0.480001, acc 0.765625
2020-02-08T02:56:41.908532: step 599, loss 0.487509, acc 0.71875
2020-02-08T02:56:42.021212: step 600, loss 0.512203, acc 0.75

Evaluation:
2020-02-08T02:56:42.209327: step 600, loss 0.688674, acc 0.566604

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-600

2020-02-08T02:56:43.718747: step 601, loss 0.455944, acc 0.75
2020-02-08T02:56:43.840067: step 602, loss 0.447493, acc 0.84375
2020-02-08T02:56:43.956124: step 603, loss 0.53703, acc 0.71875
2020-02-08T02:56:44.071423: step 604, loss 0.617991, acc 0.625
2020-02-08T02:56:44.186154: step 605, loss 0.580469, acc 0.65625
2020-02-08T02:56:44.303390: step 606, loss 0.579161, acc 0.6875
2020-02-08T02:56:44.419634: step 607, loss 0.46949, acc 0.765625
2020-02-08T02:56:44.538213: step 608, loss 0.586336, acc 0.640625
2020-02-08T02:56:44.654068: step 609, loss 0.57241, acc 0.65625
2020-02-08T02:56:44.767763: step 610, loss 0.478372, acc 0.796875
2020-02-08T02:56:44.886945: step 611, loss 0.528787, acc 0.78125
2020-02-08T02:56:45.004924: step 612, loss 0.444658, acc 0.796875
2020-02-08T02:56:45.120330: step 613, loss 0.499286, acc 0.75
2020-02-08T02:56:45.239490: step 614, loss 0.50217, acc 0.78125
2020-02-08T02:56:45.366144: step 615, loss 0.505385, acc 0.734375
2020-02-08T02:56:45.482636: step 616, loss 0.495398, acc 0.71875
2020-02-08T02:56:45.599722: step 617, loss 0.745678, acc 0.6875
2020-02-08T02:56:45.718541: step 618, loss 0.524868, acc 0.71875
2020-02-08T02:56:45.836969: step 619, loss 0.488587, acc 0.765625
2020-02-08T02:56:45.955202: step 620, loss 0.482906, acc 0.75
2020-02-08T02:56:46.069202: step 621, loss 0.693457, acc 0.65625
2020-02-08T02:56:46.183953: step 622, loss 0.463385, acc 0.75
2020-02-08T02:56:46.301839: step 623, loss 0.537747, acc 0.703125
2020-02-08T02:56:46.418955: step 624, loss 0.559952, acc 0.765625
2020-02-08T02:56:46.534812: step 625, loss 0.468763, acc 0.75
2020-02-08T02:56:46.652279: step 626, loss 0.585191, acc 0.65625
2020-02-08T02:56:46.768725: step 627, loss 0.529459, acc 0.765625
2020-02-08T02:56:46.884545: step 628, loss 0.503122, acc 0.6875
2020-02-08T02:56:47.004350: step 629, loss 0.424991, acc 0.75
2020-02-08T02:56:47.119615: step 630, loss 0.591421, acc 0.71875
2020-02-08T02:56:47.238713: step 631, loss 0.54493, acc 0.765625
2020-02-08T02:56:47.353752: step 632, loss 0.545201, acc 0.71875
2020-02-08T02:56:47.467821: step 633, loss 0.50361, acc 0.78125
2020-02-08T02:56:47.582282: step 634, loss 0.553076, acc 0.6875
2020-02-08T02:56:47.698425: step 635, loss 0.484428, acc 0.765625
2020-02-08T02:56:47.814954: step 636, loss 0.514353, acc 0.78125
2020-02-08T02:56:47.931359: step 637, loss 0.471396, acc 0.796875
2020-02-08T02:56:48.051052: step 638, loss 0.518528, acc 0.671875
2020-02-08T02:56:48.167984: step 639, loss 0.455402, acc 0.8125
2020-02-08T02:56:48.285155: step 640, loss 0.500405, acc 0.765625
2020-02-08T02:56:48.400492: step 641, loss 0.61416, acc 0.703125
2020-02-08T02:56:48.517105: step 642, loss 0.471678, acc 0.75
2020-02-08T02:56:48.633162: step 643, loss 0.625134, acc 0.65625
2020-02-08T02:56:48.752441: step 644, loss 0.639888, acc 0.65625
2020-02-08T02:56:48.865969: step 645, loss 0.556655, acc 0.71875
2020-02-08T02:56:48.984152: step 646, loss 0.591704, acc 0.71875
2020-02-08T02:56:49.099082: step 647, loss 0.620622, acc 0.671875
2020-02-08T02:56:49.216372: step 648, loss 0.350335, acc 0.859375
2020-02-08T02:56:49.332205: step 649, loss 0.379831, acc 0.84375
2020-02-08T02:56:49.450555: step 650, loss 0.466473, acc 0.8125
2020-02-08T02:56:49.566286: step 651, loss 0.471664, acc 0.765625
2020-02-08T02:56:49.684692: step 652, loss 0.478584, acc 0.75
2020-02-08T02:56:49.805177: step 653, loss 0.401499, acc 0.796875
2020-02-08T02:56:49.920432: step 654, loss 0.446811, acc 0.78125
2020-02-08T02:56:50.036953: step 655, loss 0.382729, acc 0.828125
2020-02-08T02:56:50.156827: step 656, loss 0.545274, acc 0.75
2020-02-08T02:56:50.272449: step 657, loss 0.411933, acc 0.859375
2020-02-08T02:56:50.387379: step 658, loss 0.507469, acc 0.765625
2020-02-08T02:56:50.501719: step 659, loss 0.382104, acc 0.8125
2020-02-08T02:56:50.616147: step 660, loss 0.508801, acc 0.78125
2020-02-08T02:56:50.733102: step 661, loss 0.532643, acc 0.75
2020-02-08T02:56:50.850452: step 662, loss 0.409418, acc 0.828125
2020-02-08T02:56:50.965565: step 663, loss 0.551035, acc 0.71875
2020-02-08T02:56:51.082564: step 664, loss 0.437265, acc 0.875
2020-02-08T02:56:51.199690: step 665, loss 0.540173, acc 0.78125
2020-02-08T02:56:51.315184: step 666, loss 0.660544, acc 0.671875
2020-02-08T02:56:51.549440: step 667, loss 0.439429, acc 0.828125
2020-02-08T02:56:51.676660: step 668, loss 0.525177, acc 0.734375
2020-02-08T02:56:51.793003: step 669, loss 0.599421, acc 0.703125
2020-02-08T02:56:51.910912: step 670, loss 0.489961, acc 0.78125
2020-02-08T02:56:52.026644: step 671, loss 0.607059, acc 0.6875
2020-02-08T02:56:52.141667: step 672, loss 0.544323, acc 0.78125
2020-02-08T02:56:52.258100: step 673, loss 0.512783, acc 0.6875
2020-02-08T02:56:52.373456: step 674, loss 0.440269, acc 0.828125
2020-02-08T02:56:52.493316: step 675, loss 0.542589, acc 0.734375
2020-02-08T02:56:52.611239: step 676, loss 0.59963, acc 0.703125
2020-02-08T02:56:52.725942: step 677, loss 0.460484, acc 0.765625
2020-02-08T02:56:52.843110: step 678, loss 0.48573, acc 0.734375
2020-02-08T02:56:52.962933: step 679, loss 0.499194, acc 0.734375
2020-02-08T02:56:53.081185: step 680, loss 0.531442, acc 0.734375
2020-02-08T02:56:53.198135: step 681, loss 0.571558, acc 0.671875
2020-02-08T02:56:53.312845: step 682, loss 0.555816, acc 0.765625
2020-02-08T02:56:53.427604: step 683, loss 0.49034, acc 0.734375
2020-02-08T02:56:53.542763: step 684, loss 0.501264, acc 0.75
2020-02-08T02:56:53.659157: step 685, loss 0.503722, acc 0.71875
2020-02-08T02:56:53.773422: step 686, loss 0.609125, acc 0.6875
2020-02-08T02:56:53.888458: step 687, loss 0.553301, acc 0.71875
2020-02-08T02:56:54.005527: step 688, loss 0.617458, acc 0.703125
2020-02-08T02:56:54.120581: step 689, loss 0.492769, acc 0.71875
2020-02-08T02:56:54.236607: step 690, loss 0.47797, acc 0.765625
2020-02-08T02:56:54.352483: step 691, loss 0.484849, acc 0.78125
2020-02-08T02:56:54.467538: step 692, loss 0.571654, acc 0.703125
2020-02-08T02:56:54.580724: step 693, loss 0.577703, acc 0.703125
2020-02-08T02:56:54.697069: step 694, loss 0.508161, acc 0.765625
2020-02-08T02:56:54.813107: step 695, loss 0.48204, acc 0.734375
2020-02-08T02:56:54.925811: step 696, loss 0.432566, acc 0.796875
2020-02-08T02:56:55.043067: step 697, loss 0.45637, acc 0.78125
2020-02-08T02:56:55.159294: step 698, loss 0.362452, acc 0.84375
2020-02-08T02:56:55.276789: step 699, loss 0.426451, acc 0.765625
2020-02-08T02:56:55.393661: step 700, loss 0.595819, acc 0.65625

Evaluation:
2020-02-08T02:56:55.583298: step 700, loss 0.608683, acc 0.662289

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-700

2020-02-08T02:56:57.158170: step 701, loss 0.459788, acc 0.78125
2020-02-08T02:56:57.270681: step 702, loss 0.513444, acc 0.796875
2020-02-08T02:56:57.387104: step 703, loss 0.490747, acc 0.78125
2020-02-08T02:56:57.505015: step 704, loss 0.53648, acc 0.75
2020-02-08T02:56:57.618174: step 705, loss 0.443428, acc 0.765625
2020-02-08T02:56:57.736671: step 706, loss 0.582099, acc 0.75
2020-02-08T02:56:57.855306: step 707, loss 0.538217, acc 0.75
2020-02-08T02:56:57.972482: step 708, loss 0.494329, acc 0.71875
2020-02-08T02:56:58.088938: step 709, loss 0.467179, acc 0.75
2020-02-08T02:56:58.204868: step 710, loss 0.502748, acc 0.765625
2020-02-08T02:56:58.321718: step 711, loss 0.425791, acc 0.765625
2020-02-08T02:56:58.438633: step 712, loss 0.470653, acc 0.765625
2020-02-08T02:56:58.557615: step 713, loss 0.474217, acc 0.78125
2020-02-08T02:56:58.670266: step 714, loss 0.61016, acc 0.703125
2020-02-08T02:56:58.788896: step 715, loss 0.579665, acc 0.75
2020-02-08T02:56:58.906724: step 716, loss 0.530569, acc 0.71875
2020-02-08T02:56:59.024959: step 717, loss 0.670728, acc 0.671875
2020-02-08T02:56:59.140362: step 718, loss 0.515009, acc 0.75
2020-02-08T02:56:59.258659: step 719, loss 0.534109, acc 0.734375
2020-02-08T02:56:59.372965: step 720, loss 0.436131, acc 0.78125
2020-02-08T02:56:59.487034: step 721, loss 0.562163, acc 0.671875
2020-02-08T02:56:59.604088: step 722, loss 0.543625, acc 0.71875
2020-02-08T02:56:59.719715: step 723, loss 0.538812, acc 0.75
2020-02-08T02:56:59.831967: step 724, loss 0.511734, acc 0.75
2020-02-08T02:56:59.947220: step 725, loss 0.740349, acc 0.640625
2020-02-08T02:57:00.064367: step 726, loss 0.558323, acc 0.71875
2020-02-08T02:57:00.182002: step 727, loss 0.429546, acc 0.84375
2020-02-08T02:57:00.302020: step 728, loss 0.465195, acc 0.828125
2020-02-08T02:57:00.418743: step 729, loss 0.461326, acc 0.75
2020-02-08T02:57:00.535187: step 730, loss 0.502209, acc 0.78125
2020-02-08T02:57:00.652849: step 731, loss 0.543812, acc 0.703125
2020-02-08T02:57:00.767645: step 732, loss 0.534328, acc 0.734375
2020-02-08T02:57:00.885621: step 733, loss 0.479931, acc 0.765625
2020-02-08T02:57:01.002096: step 734, loss 0.452543, acc 0.75
2020-02-08T02:57:01.116444: step 735, loss 0.399143, acc 0.796875
2020-02-08T02:57:01.234691: step 736, loss 0.560947, acc 0.71875
2020-02-08T02:57:01.350536: step 737, loss 0.623782, acc 0.65625
2020-02-08T02:57:01.465401: step 738, loss 0.540113, acc 0.765625
2020-02-08T02:57:01.580772: step 739, loss 0.59589, acc 0.671875
2020-02-08T02:57:01.700145: step 740, loss 0.55469, acc 0.625
2020-02-08T02:57:01.815204: step 741, loss 0.554418, acc 0.703125
2020-02-08T02:57:01.930256: step 742, loss 0.637519, acc 0.703125
2020-02-08T02:57:02.048189: step 743, loss 0.663284, acc 0.6875
2020-02-08T02:57:02.164273: step 744, loss 0.565104, acc 0.71875
2020-02-08T02:57:02.278518: step 745, loss 0.646075, acc 0.6875
2020-02-08T02:57:02.396407: step 746, loss 0.479866, acc 0.78125
2020-02-08T02:57:02.511825: step 747, loss 0.363718, acc 0.84375
2020-02-08T02:57:02.626552: step 748, loss 0.61025, acc 0.71875
2020-02-08T02:57:02.744329: step 749, loss 0.476079, acc 0.75
2020-02-08T02:57:02.857733: step 750, loss 0.454351, acc 0.75
2020-02-08T02:57:02.976286: step 751, loss 0.457712, acc 0.796875
2020-02-08T02:57:03.093017: step 752, loss 0.540181, acc 0.6875
2020-02-08T02:57:03.208970: step 753, loss 0.421179, acc 0.796875
2020-02-08T02:57:03.325572: step 754, loss 0.413407, acc 0.796875
2020-02-08T02:57:03.444384: step 755, loss 0.412749, acc 0.859375
2020-02-08T02:57:03.560744: step 756, loss 0.540445, acc 0.71875
2020-02-08T02:57:03.675201: step 757, loss 0.577921, acc 0.71875
2020-02-08T02:57:03.790037: step 758, loss 0.446044, acc 0.765625
2020-02-08T02:57:03.905737: step 759, loss 0.538574, acc 0.765625
2020-02-08T02:57:04.021173: step 760, loss 0.51778, acc 0.765625
2020-02-08T02:57:04.135107: step 761, loss 0.500055, acc 0.75
2020-02-08T02:57:04.250447: step 762, loss 0.428395, acc 0.765625
2020-02-08T02:57:04.367838: step 763, loss 0.357849, acc 0.84375
2020-02-08T02:57:04.484473: step 764, loss 0.382864, acc 0.78125
2020-02-08T02:57:04.601289: step 765, loss 0.430402, acc 0.796875
2020-02-08T02:57:04.719857: step 766, loss 0.381436, acc 0.84375
2020-02-08T02:57:04.837595: step 767, loss 0.439046, acc 0.796875
2020-02-08T02:57:04.955396: step 768, loss 0.47098, acc 0.734375
2020-02-08T02:57:05.071051: step 769, loss 0.38762, acc 0.859375
2020-02-08T02:57:05.187660: step 770, loss 0.467696, acc 0.765625
2020-02-08T02:57:05.301630: step 771, loss 0.345197, acc 0.84375
2020-02-08T02:57:05.417752: step 772, loss 0.456053, acc 0.8125
2020-02-08T02:57:05.532093: step 773, loss 0.650848, acc 0.640625
2020-02-08T02:57:05.649674: step 774, loss 0.295697, acc 0.828125
2020-02-08T02:57:05.764253: step 775, loss 0.366927, acc 0.828125
2020-02-08T02:57:05.879818: step 776, loss 0.406987, acc 0.78125
2020-02-08T02:57:05.995797: step 777, loss 0.490427, acc 0.765625
2020-02-08T02:57:06.112075: step 778, loss 0.521635, acc 0.75
2020-02-08T02:57:06.229388: step 779, loss 0.386982, acc 0.84375
2020-02-08T02:57:06.346329: step 780, loss 0.476463, acc 0.75
2020-02-08T02:57:06.460995: step 781, loss 0.39323, acc 0.84375
2020-02-08T02:57:06.574980: step 782, loss 0.443941, acc 0.78125
2020-02-08T02:57:06.689852: step 783, loss 0.405869, acc 0.84375
2020-02-08T02:57:06.805968: step 784, loss 0.492988, acc 0.828125
2020-02-08T02:57:06.920595: step 785, loss 0.31799, acc 0.890625
2020-02-08T02:57:07.037340: step 786, loss 0.383034, acc 0.84375
2020-02-08T02:57:07.154756: step 787, loss 0.34767, acc 0.828125
2020-02-08T02:57:07.269904: step 788, loss 0.477904, acc 0.78125
2020-02-08T02:57:07.386717: step 789, loss 0.48182, acc 0.75
2020-02-08T02:57:07.507035: step 790, loss 0.406663, acc 0.859375
2020-02-08T02:57:07.620796: step 791, loss 0.386115, acc 0.8125
2020-02-08T02:57:07.733895: step 792, loss 0.452899, acc 0.75
2020-02-08T02:57:07.849632: step 793, loss 0.381209, acc 0.84375
2020-02-08T02:57:07.966134: step 794, loss 0.371604, acc 0.828125
2020-02-08T02:57:08.078787: step 795, loss 0.408182, acc 0.8125
2020-02-08T02:57:08.194681: step 796, loss 0.495209, acc 0.71875
2020-02-08T02:57:08.312792: step 797, loss 0.470868, acc 0.796875
2020-02-08T02:57:08.428176: step 798, loss 0.449365, acc 0.796875
2020-02-08T02:57:08.549257: step 799, loss 0.411714, acc 0.78125
2020-02-08T02:57:08.664945: step 800, loss 0.470758, acc 0.734375

Evaluation:
2020-02-08T02:57:08.862213: step 800, loss 0.603649, acc 0.673546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-800

2020-02-08T02:57:10.348820: step 801, loss 0.385138, acc 0.828125
2020-02-08T02:57:10.464680: step 802, loss 0.512681, acc 0.78125
2020-02-08T02:57:10.581992: step 803, loss 0.526337, acc 0.734375
2020-02-08T02:57:10.700779: step 804, loss 0.410594, acc 0.828125
2020-02-08T02:57:10.817597: step 805, loss 0.461384, acc 0.78125
2020-02-08T02:57:10.930716: step 806, loss 0.494663, acc 0.78125
2020-02-08T02:57:11.047745: step 807, loss 0.495515, acc 0.8125
2020-02-08T02:57:11.162899: step 808, loss 0.486648, acc 0.71875
2020-02-08T02:57:11.279179: step 809, loss 0.469622, acc 0.828125
2020-02-08T02:57:11.398705: step 810, loss 0.497378, acc 0.796875
2020-02-08T02:57:11.515200: step 811, loss 0.452376, acc 0.78125
2020-02-08T02:57:11.632991: step 812, loss 0.559669, acc 0.6875
2020-02-08T02:57:11.752025: step 813, loss 0.373061, acc 0.828125
2020-02-08T02:57:11.867558: step 814, loss 0.382458, acc 0.859375
2020-02-08T02:57:11.985164: step 815, loss 0.526493, acc 0.6875
2020-02-08T02:57:12.101687: step 816, loss 0.448423, acc 0.796875
2020-02-08T02:57:12.218045: step 817, loss 0.349452, acc 0.796875
2020-02-08T02:57:12.334991: step 818, loss 0.418854, acc 0.796875
2020-02-08T02:57:12.452691: step 819, loss 0.417562, acc 0.765625
2020-02-08T02:57:12.568995: step 820, loss 0.381932, acc 0.8125
2020-02-08T02:57:12.683376: step 821, loss 0.358144, acc 0.8125
2020-02-08T02:57:12.803137: step 822, loss 0.493673, acc 0.796875
2020-02-08T02:57:12.919878: step 823, loss 0.453347, acc 0.8125
2020-02-08T02:57:13.037184: step 824, loss 0.376778, acc 0.859375
2020-02-08T02:57:13.151792: step 825, loss 0.321181, acc 0.890625
2020-02-08T02:57:13.267934: step 826, loss 0.363458, acc 0.859375
2020-02-08T02:57:13.385650: step 827, loss 0.576057, acc 0.71875
2020-02-08T02:57:13.503322: step 828, loss 0.399724, acc 0.8125
2020-02-08T02:57:13.615950: step 829, loss 0.414118, acc 0.796875
2020-02-08T02:57:13.731015: step 830, loss 0.463415, acc 0.765625
2020-02-08T02:57:13.848779: step 831, loss 0.45153, acc 0.75
2020-02-08T02:57:13.963160: step 832, loss 0.431295, acc 0.78125
2020-02-08T02:57:14.078575: step 833, loss 0.344978, acc 0.859375
2020-02-08T02:57:14.194169: step 834, loss 0.43832, acc 0.765625
2020-02-08T02:57:14.310842: step 835, loss 0.535263, acc 0.765625
2020-02-08T02:57:14.428556: step 836, loss 0.529368, acc 0.796875
2020-02-08T02:57:14.544498: step 837, loss 0.408283, acc 0.78125
2020-02-08T02:57:14.659955: step 838, loss 0.434926, acc 0.796875
2020-02-08T02:57:14.779013: step 839, loss 0.388352, acc 0.828125
2020-02-08T02:57:14.895964: step 840, loss 0.345118, acc 0.84375
2020-02-08T02:57:15.014005: step 841, loss 0.626043, acc 0.65625
2020-02-08T02:57:15.130075: step 842, loss 0.501112, acc 0.734375
2020-02-08T02:57:15.246605: step 843, loss 0.511796, acc 0.796875
2020-02-08T02:57:15.360892: step 844, loss 0.473741, acc 0.765625
2020-02-08T02:57:15.474158: step 845, loss 0.550157, acc 0.71875
2020-02-08T02:57:15.588124: step 846, loss 0.314258, acc 0.875
2020-02-08T02:57:15.701785: step 847, loss 0.54273, acc 0.78125
2020-02-08T02:57:15.817374: step 848, loss 0.488758, acc 0.75
2020-02-08T02:57:15.934576: step 849, loss 0.321776, acc 0.90625
2020-02-08T02:57:16.051817: step 850, loss 0.472607, acc 0.734375
2020-02-08T02:57:16.166041: step 851, loss 0.390522, acc 0.859375
2020-02-08T02:57:16.281675: step 852, loss 0.423702, acc 0.8125
2020-02-08T02:57:16.400841: step 853, loss 0.431542, acc 0.796875
2020-02-08T02:57:16.515406: step 854, loss 0.427273, acc 0.78125
2020-02-08T02:57:16.629861: step 855, loss 0.469954, acc 0.78125
2020-02-08T02:57:16.747527: step 856, loss 0.482495, acc 0.8125
2020-02-08T02:57:16.863661: step 857, loss 0.420218, acc 0.859375
2020-02-08T02:57:16.982237: step 858, loss 0.394519, acc 0.828125
2020-02-08T02:57:17.100570: step 859, loss 0.506348, acc 0.796875
2020-02-08T02:57:17.217856: step 860, loss 0.360901, acc 0.859375
2020-02-08T02:57:17.334440: step 861, loss 0.508098, acc 0.8125
2020-02-08T02:57:17.453684: step 862, loss 0.387399, acc 0.8125
2020-02-08T02:57:17.569119: step 863, loss 0.551214, acc 0.703125
2020-02-08T02:57:17.687050: step 864, loss 0.533751, acc 0.6875
2020-02-08T02:57:17.805992: step 865, loss 0.459014, acc 0.75
2020-02-08T02:57:17.920086: step 866, loss 0.385465, acc 0.828125
2020-02-08T02:57:18.038625: step 867, loss 0.531667, acc 0.734375
2020-02-08T02:57:18.154153: step 868, loss 0.362889, acc 0.859375
2020-02-08T02:57:18.270004: step 869, loss 0.503721, acc 0.75
2020-02-08T02:57:18.387230: step 870, loss 0.499297, acc 0.765625
2020-02-08T02:57:18.503162: step 871, loss 0.424561, acc 0.78125
2020-02-08T02:57:18.621001: step 872, loss 0.270838, acc 0.875
2020-02-08T02:57:18.737139: step 873, loss 0.521351, acc 0.734375
2020-02-08T02:57:18.853786: step 874, loss 0.553295, acc 0.703125
2020-02-08T02:57:18.965870: step 875, loss 0.617246, acc 0.671875
2020-02-08T02:57:19.078687: step 876, loss 0.384002, acc 0.8125
2020-02-08T02:57:19.197764: step 877, loss 0.393322, acc 0.84375
2020-02-08T02:57:19.315478: step 878, loss 0.491744, acc 0.765625
2020-02-08T02:57:19.431014: step 879, loss 0.511389, acc 0.734375
2020-02-08T02:57:19.548992: step 880, loss 0.399897, acc 0.75
2020-02-08T02:57:19.665891: step 881, loss 0.396142, acc 0.84375
2020-02-08T02:57:19.784666: step 882, loss 0.477887, acc 0.8125
2020-02-08T02:57:19.903685: step 883, loss 0.425309, acc 0.796875
2020-02-08T02:57:20.018213: step 884, loss 0.480877, acc 0.78125
2020-02-08T02:57:20.133841: step 885, loss 0.492026, acc 0.734375
2020-02-08T02:57:20.255099: step 886, loss 0.486659, acc 0.765625
2020-02-08T02:57:20.370430: step 887, loss 0.587793, acc 0.703125
2020-02-08T02:57:20.484588: step 888, loss 0.413404, acc 0.8125
2020-02-08T02:57:20.601339: step 889, loss 0.326737, acc 0.828125
2020-02-08T02:57:20.715137: step 890, loss 0.358921, acc 0.890625
2020-02-08T02:57:20.830724: step 891, loss 0.439075, acc 0.796875
2020-02-08T02:57:20.947916: step 892, loss 0.436397, acc 0.78125
2020-02-08T02:57:21.063106: step 893, loss 0.537417, acc 0.765625
2020-02-08T02:57:21.178658: step 894, loss 0.517596, acc 0.796875
2020-02-08T02:57:21.469711: step 895, loss 0.455437, acc 0.765625
2020-02-08T02:57:21.600328: step 896, loss 0.454741, acc 0.796875
2020-02-08T02:57:21.715631: step 897, loss 0.367611, acc 0.828125
2020-02-08T02:57:21.834505: step 898, loss 0.395662, acc 0.796875
2020-02-08T02:57:21.950750: step 899, loss 0.361511, acc 0.796875
2020-02-08T02:57:22.061483: step 900, loss 0.440479, acc 0.766667

Evaluation:
2020-02-08T02:57:22.250393: step 900, loss 0.58894, acc 0.683865

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-900

2020-02-08T02:57:23.756562: step 901, loss 0.450185, acc 0.8125
2020-02-08T02:57:23.872280: step 902, loss 0.359305, acc 0.875
2020-02-08T02:57:23.990771: step 903, loss 0.357612, acc 0.875
2020-02-08T02:57:24.109219: step 904, loss 0.377934, acc 0.8125
2020-02-08T02:57:24.222777: step 905, loss 0.355739, acc 0.859375
2020-02-08T02:57:24.337762: step 906, loss 0.435464, acc 0.796875
2020-02-08T02:57:24.455698: step 907, loss 0.510996, acc 0.765625
2020-02-08T02:57:24.569344: step 908, loss 0.404586, acc 0.828125
2020-02-08T02:57:24.682690: step 909, loss 0.347156, acc 0.875
2020-02-08T02:57:24.800736: step 910, loss 0.36635, acc 0.859375
2020-02-08T02:57:24.915587: step 911, loss 0.386988, acc 0.828125
2020-02-08T02:57:25.031763: step 912, loss 0.33161, acc 0.859375
2020-02-08T02:57:25.147167: step 913, loss 0.400235, acc 0.8125
2020-02-08T02:57:25.263312: step 914, loss 0.427835, acc 0.796875
2020-02-08T02:57:25.380257: step 915, loss 0.32998, acc 0.875
2020-02-08T02:57:25.497245: step 916, loss 0.416205, acc 0.765625
2020-02-08T02:57:25.611828: step 917, loss 0.347565, acc 0.828125
2020-02-08T02:57:25.725287: step 918, loss 0.344564, acc 0.84375
2020-02-08T02:57:25.842555: step 919, loss 0.358255, acc 0.84375
2020-02-08T02:57:25.958161: step 920, loss 0.26439, acc 0.890625
2020-02-08T02:57:26.071768: step 921, loss 0.378445, acc 0.796875
2020-02-08T02:57:26.189213: step 922, loss 0.378744, acc 0.859375
2020-02-08T02:57:26.306463: step 923, loss 0.299131, acc 0.875
2020-02-08T02:57:26.422223: step 924, loss 0.435931, acc 0.765625
2020-02-08T02:57:26.541035: step 925, loss 0.326307, acc 0.84375
2020-02-08T02:57:26.655348: step 926, loss 0.337725, acc 0.828125
2020-02-08T02:57:26.770302: step 927, loss 0.457182, acc 0.78125
2020-02-08T02:57:26.885455: step 928, loss 0.213654, acc 0.921875
2020-02-08T02:57:27.001515: step 929, loss 0.260723, acc 0.90625
2020-02-08T02:57:27.117526: step 930, loss 0.37548, acc 0.84375
2020-02-08T02:57:27.231273: step 931, loss 0.472791, acc 0.75
2020-02-08T02:57:27.350913: step 932, loss 0.356723, acc 0.859375
2020-02-08T02:57:27.465658: step 933, loss 0.309345, acc 0.890625
2020-02-08T02:57:27.582341: step 934, loss 0.341755, acc 0.84375
2020-02-08T02:57:27.701046: step 935, loss 0.318911, acc 0.828125
2020-02-08T02:57:27.818373: step 936, loss 0.453406, acc 0.828125
2020-02-08T02:57:27.935760: step 937, loss 0.454321, acc 0.78125
2020-02-08T02:57:28.052375: step 938, loss 0.37684, acc 0.84375
2020-02-08T02:57:28.167854: step 939, loss 0.228739, acc 0.875
2020-02-08T02:57:28.282901: step 940, loss 0.482138, acc 0.8125
2020-02-08T02:57:28.398412: step 941, loss 0.269997, acc 0.890625
2020-02-08T02:57:28.515535: step 942, loss 0.31541, acc 0.859375
2020-02-08T02:57:28.631378: step 943, loss 0.446551, acc 0.84375
2020-02-08T02:57:28.751784: step 944, loss 0.332064, acc 0.90625
2020-02-08T02:57:28.867233: step 945, loss 0.333464, acc 0.859375
2020-02-08T02:57:28.980675: step 946, loss 0.379123, acc 0.84375
2020-02-08T02:57:29.100724: step 947, loss 0.401798, acc 0.859375
2020-02-08T02:57:29.215375: step 948, loss 0.333605, acc 0.84375
2020-02-08T02:57:29.328810: step 949, loss 0.29152, acc 0.890625
2020-02-08T02:57:29.443429: step 950, loss 0.385582, acc 0.828125
2020-02-08T02:57:29.559477: step 951, loss 0.419966, acc 0.796875
2020-02-08T02:57:29.674830: step 952, loss 0.355479, acc 0.84375
2020-02-08T02:57:29.792062: step 953, loss 0.397492, acc 0.859375
2020-02-08T02:57:29.908836: step 954, loss 0.313952, acc 0.859375
2020-02-08T02:57:30.023951: step 955, loss 0.419154, acc 0.8125
2020-02-08T02:57:30.144283: step 956, loss 0.430951, acc 0.796875
2020-02-08T02:57:30.261459: step 957, loss 0.431444, acc 0.828125
2020-02-08T02:57:30.376403: step 958, loss 0.388001, acc 0.78125
2020-02-08T02:57:30.492859: step 959, loss 0.399802, acc 0.78125
2020-02-08T02:57:30.607604: step 960, loss 0.395857, acc 0.859375
2020-02-08T02:57:30.721944: step 961, loss 0.318547, acc 0.875
2020-02-08T02:57:30.836304: step 962, loss 0.364199, acc 0.796875
2020-02-08T02:57:30.952256: step 963, loss 0.337996, acc 0.84375
2020-02-08T02:57:31.067555: step 964, loss 0.429351, acc 0.796875
2020-02-08T02:57:31.183405: step 965, loss 0.581196, acc 0.703125
2020-02-08T02:57:31.300470: step 966, loss 0.35146, acc 0.796875
2020-02-08T02:57:31.420472: step 967, loss 0.414282, acc 0.8125
2020-02-08T02:57:31.535011: step 968, loss 0.31643, acc 0.84375
2020-02-08T02:57:31.650913: step 969, loss 0.397086, acc 0.78125
2020-02-08T02:57:31.769838: step 970, loss 0.462643, acc 0.78125
2020-02-08T02:57:31.886424: step 971, loss 0.445639, acc 0.8125
2020-02-08T02:57:32.003152: step 972, loss 0.277747, acc 0.859375
2020-02-08T02:57:32.118165: step 973, loss 0.328463, acc 0.84375
2020-02-08T02:57:32.232821: step 974, loss 0.492378, acc 0.765625
2020-02-08T02:57:32.348678: step 975, loss 0.462484, acc 0.765625
2020-02-08T02:57:32.465648: step 976, loss 0.380801, acc 0.828125
2020-02-08T02:57:32.581166: step 977, loss 0.352942, acc 0.875
2020-02-08T02:57:32.698473: step 978, loss 0.518371, acc 0.78125
2020-02-08T02:57:32.817121: step 979, loss 0.473345, acc 0.796875
2020-02-08T02:57:32.935781: step 980, loss 0.421751, acc 0.8125
2020-02-08T02:57:33.051446: step 981, loss 0.34481, acc 0.859375
2020-02-08T02:57:33.168794: step 982, loss 0.326445, acc 0.890625
2020-02-08T02:57:33.285622: step 983, loss 0.447274, acc 0.8125
2020-02-08T02:57:33.403302: step 984, loss 0.343533, acc 0.84375
2020-02-08T02:57:33.517670: step 985, loss 0.390138, acc 0.875
2020-02-08T02:57:33.632870: step 986, loss 0.335639, acc 0.859375
2020-02-08T02:57:33.748909: step 987, loss 0.425627, acc 0.796875
2020-02-08T02:57:33.863955: step 988, loss 0.345314, acc 0.796875
2020-02-08T02:57:33.979096: step 989, loss 0.337177, acc 0.875
2020-02-08T02:57:34.096778: step 990, loss 0.346639, acc 0.828125
2020-02-08T02:57:34.214635: step 991, loss 0.439271, acc 0.75
2020-02-08T02:57:34.328869: step 992, loss 0.478928, acc 0.828125
2020-02-08T02:57:34.448083: step 993, loss 0.50229, acc 0.703125
2020-02-08T02:57:34.564313: step 994, loss 0.415525, acc 0.796875
2020-02-08T02:57:34.679433: step 995, loss 0.399288, acc 0.828125
2020-02-08T02:57:34.798005: step 996, loss 0.342864, acc 0.921875
2020-02-08T02:57:34.913035: step 997, loss 0.428765, acc 0.828125
2020-02-08T02:57:35.029672: step 998, loss 0.425258, acc 0.8125
2020-02-08T02:57:35.146013: step 999, loss 0.337353, acc 0.84375
2020-02-08T02:57:35.261496: step 1000, loss 0.374337, acc 0.8125

Evaluation:
2020-02-08T02:57:35.449979: step 1000, loss 0.588544, acc 0.692308

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1000

2020-02-08T02:57:38.036029: step 1001, loss 0.274414, acc 0.921875
2020-02-08T02:57:38.151130: step 1002, loss 0.411869, acc 0.796875
2020-02-08T02:57:38.267196: step 1003, loss 0.43499, acc 0.796875
2020-02-08T02:57:38.383845: step 1004, loss 0.395346, acc 0.859375
2020-02-08T02:57:38.501653: step 1005, loss 0.644737, acc 0.703125
2020-02-08T02:57:38.617487: step 1006, loss 0.420251, acc 0.796875
2020-02-08T02:57:38.733726: step 1007, loss 0.364864, acc 0.78125
2020-02-08T02:57:38.850652: step 1008, loss 0.402495, acc 0.875
2020-02-08T02:57:38.967590: step 1009, loss 0.423027, acc 0.765625
2020-02-08T02:57:39.084423: step 1010, loss 0.434744, acc 0.765625
2020-02-08T02:57:39.200270: step 1011, loss 0.396413, acc 0.859375
2020-02-08T02:57:39.315613: step 1012, loss 0.40263, acc 0.78125
2020-02-08T02:57:39.435328: step 1013, loss 0.425776, acc 0.796875
2020-02-08T02:57:39.557161: step 1014, loss 0.409736, acc 0.828125
2020-02-08T02:57:39.675182: step 1015, loss 0.334263, acc 0.828125
2020-02-08T02:57:39.793448: step 1016, loss 0.389845, acc 0.78125
2020-02-08T02:57:39.908305: step 1017, loss 0.359039, acc 0.828125
2020-02-08T02:57:40.022278: step 1018, loss 0.446441, acc 0.8125
2020-02-08T02:57:40.139483: step 1019, loss 0.556756, acc 0.75
2020-02-08T02:57:40.255232: step 1020, loss 0.293795, acc 0.859375
2020-02-08T02:57:40.372048: step 1021, loss 0.284643, acc 0.890625
2020-02-08T02:57:40.490621: step 1022, loss 0.431529, acc 0.8125
2020-02-08T02:57:40.605551: step 1023, loss 0.465715, acc 0.828125
2020-02-08T02:57:40.721338: step 1024, loss 0.342455, acc 0.90625
2020-02-08T02:57:40.839862: step 1025, loss 0.483625, acc 0.765625
2020-02-08T02:57:40.953737: step 1026, loss 0.388481, acc 0.8125
2020-02-08T02:57:41.070312: step 1027, loss 0.358802, acc 0.796875
2020-02-08T02:57:41.185396: step 1028, loss 0.370782, acc 0.8125
2020-02-08T02:57:41.301638: step 1029, loss 0.488424, acc 0.765625
2020-02-08T02:57:41.417434: step 1030, loss 0.532191, acc 0.796875
2020-02-08T02:57:41.535147: step 1031, loss 0.251484, acc 0.875
2020-02-08T02:57:41.652538: step 1032, loss 0.471828, acc 0.75
2020-02-08T02:57:41.769489: step 1033, loss 0.378951, acc 0.796875
2020-02-08T02:57:41.887221: step 1034, loss 0.394379, acc 0.796875
2020-02-08T02:57:42.002052: step 1035, loss 0.460829, acc 0.828125
2020-02-08T02:57:42.118740: step 1036, loss 0.25278, acc 0.890625
2020-02-08T02:57:42.232999: step 1037, loss 0.375439, acc 0.84375
2020-02-08T02:57:42.350905: step 1038, loss 0.437464, acc 0.78125
2020-02-08T02:57:42.465656: step 1039, loss 0.487874, acc 0.75
2020-02-08T02:57:42.582638: step 1040, loss 0.366751, acc 0.828125
2020-02-08T02:57:42.697549: step 1041, loss 0.302014, acc 0.890625
2020-02-08T02:57:42.814529: step 1042, loss 0.356443, acc 0.828125
2020-02-08T02:57:42.936178: step 1043, loss 0.340865, acc 0.859375
2020-02-08T02:57:43.053063: step 1044, loss 0.49715, acc 0.796875
2020-02-08T02:57:43.168696: step 1045, loss 0.298057, acc 0.859375
2020-02-08T02:57:43.285374: step 1046, loss 0.374215, acc 0.84375
2020-02-08T02:57:43.401347: step 1047, loss 0.572304, acc 0.75
2020-02-08T02:57:43.516930: step 1048, loss 0.333949, acc 0.859375
2020-02-08T02:57:43.631498: step 1049, loss 0.325178, acc 0.859375
2020-02-08T02:57:43.745479: step 1050, loss 0.316167, acc 0.85
2020-02-08T02:57:43.863768: step 1051, loss 0.283586, acc 0.90625
2020-02-08T02:57:43.978364: step 1052, loss 0.296762, acc 0.890625
2020-02-08T02:57:44.095736: step 1053, loss 0.276924, acc 0.875
2020-02-08T02:57:44.210395: step 1054, loss 0.370035, acc 0.84375
2020-02-08T02:57:44.326685: step 1055, loss 0.374941, acc 0.84375
2020-02-08T02:57:44.442855: step 1056, loss 0.313434, acc 0.875
2020-02-08T02:57:44.558733: step 1057, loss 0.242172, acc 0.9375
2020-02-08T02:57:44.672556: step 1058, loss 0.305412, acc 0.828125
2020-02-08T02:57:44.787973: step 1059, loss 0.344593, acc 0.84375
2020-02-08T02:57:44.901741: step 1060, loss 0.283284, acc 0.90625
2020-02-08T02:57:45.015732: step 1061, loss 0.305519, acc 0.875
2020-02-08T02:57:45.129658: step 1062, loss 0.30879, acc 0.875
2020-02-08T02:57:45.248155: step 1063, loss 0.296761, acc 0.875
2020-02-08T02:57:45.364285: step 1064, loss 0.264486, acc 0.90625
2020-02-08T02:57:45.479699: step 1065, loss 0.229894, acc 0.921875
2020-02-08T02:57:45.598240: step 1066, loss 0.236436, acc 0.890625
2020-02-08T02:57:45.716913: step 1067, loss 0.294611, acc 0.859375
2020-02-08T02:57:45.832761: step 1068, loss 0.277603, acc 0.859375
2020-02-08T02:57:45.955650: step 1069, loss 0.274558, acc 0.875
2020-02-08T02:57:46.073299: step 1070, loss 0.320815, acc 0.859375
2020-02-08T02:57:46.188856: step 1071, loss 0.251336, acc 0.921875
2020-02-08T02:57:46.306526: step 1072, loss 0.330641, acc 0.921875
2020-02-08T02:57:46.423077: step 1073, loss 0.347535, acc 0.890625
2020-02-08T02:57:46.541953: step 1074, loss 0.297668, acc 0.90625
2020-02-08T02:57:46.657257: step 1075, loss 0.325577, acc 0.859375
2020-02-08T02:57:46.771231: step 1076, loss 0.314975, acc 0.828125
2020-02-08T02:57:46.889232: step 1077, loss 0.173542, acc 0.9375
2020-02-08T02:57:47.008068: step 1078, loss 0.307327, acc 0.875
2020-02-08T02:57:47.121306: step 1079, loss 0.432848, acc 0.828125
2020-02-08T02:57:47.239820: step 1080, loss 0.346255, acc 0.8125
2020-02-08T02:57:47.356254: step 1081, loss 0.331371, acc 0.828125
2020-02-08T02:57:47.474201: step 1082, loss 0.336787, acc 0.875
2020-02-08T02:57:47.590032: step 1083, loss 0.317311, acc 0.890625
2020-02-08T02:57:47.706771: step 1084, loss 0.291177, acc 0.859375
2020-02-08T02:57:47.820939: step 1085, loss 0.237325, acc 0.90625
2020-02-08T02:57:47.938759: step 1086, loss 0.335561, acc 0.84375
2020-02-08T02:57:48.056105: step 1087, loss 0.480555, acc 0.796875
2020-02-08T02:57:48.170629: step 1088, loss 0.283231, acc 0.921875
2020-02-08T02:57:48.285396: step 1089, loss 0.257108, acc 0.890625
2020-02-08T02:57:48.404425: step 1090, loss 0.305898, acc 0.890625
2020-02-08T02:57:48.519385: step 1091, loss 0.221054, acc 0.953125
2020-02-08T02:57:48.633666: step 1092, loss 0.327912, acc 0.828125
2020-02-08T02:57:48.748994: step 1093, loss 0.316473, acc 0.875
2020-02-08T02:57:48.865780: step 1094, loss 0.261277, acc 0.84375
2020-02-08T02:57:48.979070: step 1095, loss 0.329153, acc 0.828125
2020-02-08T02:57:49.096282: step 1096, loss 0.262981, acc 0.90625
2020-02-08T02:57:49.213354: step 1097, loss 0.216473, acc 0.921875
2020-02-08T02:57:49.327092: step 1098, loss 0.363409, acc 0.8125
2020-02-08T02:57:49.444068: step 1099, loss 0.18295, acc 0.953125
2020-02-08T02:57:49.559904: step 1100, loss 0.333918, acc 0.875

Evaluation:
2020-02-08T02:57:49.746801: step 1100, loss 0.595196, acc 0.69137

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1100

2020-02-08T02:57:51.278512: step 1101, loss 0.362506, acc 0.78125
2020-02-08T02:57:51.391459: step 1102, loss 0.305423, acc 0.84375
2020-02-08T02:57:51.513682: step 1103, loss 0.222236, acc 0.90625
2020-02-08T02:57:51.634218: step 1104, loss 0.297228, acc 0.90625
2020-02-08T02:57:51.747340: step 1105, loss 0.277945, acc 0.90625
2020-02-08T02:57:51.863495: step 1106, loss 0.45179, acc 0.828125
2020-02-08T02:57:51.978433: step 1107, loss 0.467677, acc 0.796875
2020-02-08T02:57:52.096901: step 1108, loss 0.427344, acc 0.828125
2020-02-08T02:57:52.214179: step 1109, loss 0.250077, acc 0.890625
2020-02-08T02:57:52.326278: step 1110, loss 0.381152, acc 0.84375
2020-02-08T02:57:52.441854: step 1111, loss 0.259148, acc 0.890625
2020-02-08T02:57:52.558172: step 1112, loss 0.335195, acc 0.84375
2020-02-08T02:57:52.674046: step 1113, loss 0.375827, acc 0.796875
2020-02-08T02:57:52.791791: step 1114, loss 0.226095, acc 0.9375
2020-02-08T02:57:52.908122: step 1115, loss 0.317161, acc 0.859375
2020-02-08T02:57:53.024393: step 1116, loss 0.255504, acc 0.9375
2020-02-08T02:57:53.141662: step 1117, loss 0.241794, acc 0.890625
2020-02-08T02:57:53.257963: step 1118, loss 0.349459, acc 0.84375
2020-02-08T02:57:53.374213: step 1119, loss 0.28834, acc 0.890625
2020-02-08T02:57:53.489036: step 1120, loss 0.304218, acc 0.875
2020-02-08T02:57:53.603704: step 1121, loss 0.342868, acc 0.90625
2020-02-08T02:57:53.720106: step 1122, loss 0.287383, acc 0.875
2020-02-08T02:57:53.839462: step 1123, loss 0.221091, acc 0.921875
2020-02-08T02:57:53.956426: step 1124, loss 0.272261, acc 0.921875
2020-02-08T02:57:54.070226: step 1125, loss 0.34231, acc 0.84375
2020-02-08T02:57:54.184757: step 1126, loss 0.271255, acc 0.890625
2020-02-08T02:57:54.301376: step 1127, loss 0.266977, acc 0.859375
2020-02-08T02:57:54.415880: step 1128, loss 0.314203, acc 0.875
2020-02-08T02:57:54.531764: step 1129, loss 0.327501, acc 0.859375
2020-02-08T02:57:54.649003: step 1130, loss 0.243654, acc 0.953125
2020-02-08T02:57:54.765731: step 1131, loss 0.286657, acc 0.859375
2020-02-08T02:57:54.878376: step 1132, loss 0.27316, acc 0.875
2020-02-08T02:57:54.994577: step 1133, loss 0.290704, acc 0.890625
2020-02-08T02:57:55.110998: step 1134, loss 0.267911, acc 0.890625
2020-02-08T02:57:55.225309: step 1135, loss 0.341619, acc 0.8125
2020-02-08T02:57:55.339605: step 1136, loss 0.201208, acc 0.9375
2020-02-08T02:57:55.455286: step 1137, loss 0.239749, acc 0.921875
2020-02-08T02:57:55.569265: step 1138, loss 0.174023, acc 0.953125
2020-02-08T02:57:55.683650: step 1139, loss 0.384944, acc 0.8125
2020-02-08T02:57:55.797640: step 1140, loss 0.229043, acc 0.875
2020-02-08T02:57:55.913282: step 1141, loss 0.360576, acc 0.8125
2020-02-08T02:57:56.029405: step 1142, loss 0.456541, acc 0.796875
2020-02-08T02:57:56.143596: step 1143, loss 0.228859, acc 0.90625
2020-02-08T02:57:56.258325: step 1144, loss 0.381648, acc 0.84375
2020-02-08T02:57:56.373058: step 1145, loss 0.299675, acc 0.859375
2020-02-08T02:57:56.489437: step 1146, loss 0.213939, acc 0.9375
2020-02-08T02:57:56.606837: step 1147, loss 0.325908, acc 0.875
2020-02-08T02:57:56.722808: step 1148, loss 0.298618, acc 0.890625
2020-02-08T02:57:56.839712: step 1149, loss 0.332786, acc 0.890625
2020-02-08T02:57:56.958225: step 1150, loss 0.263258, acc 0.921875
2020-02-08T02:57:57.074762: step 1151, loss 0.396284, acc 0.828125
2020-02-08T02:57:57.190757: step 1152, loss 0.37688, acc 0.765625
2020-02-08T02:57:57.307649: step 1153, loss 0.428298, acc 0.828125
2020-02-08T02:57:57.425086: step 1154, loss 0.284388, acc 0.890625
2020-02-08T02:57:57.540567: step 1155, loss 0.416534, acc 0.828125
2020-02-08T02:57:57.657543: step 1156, loss 0.295042, acc 0.890625
2020-02-08T02:57:57.771950: step 1157, loss 0.276714, acc 0.890625
2020-02-08T02:57:57.888579: step 1158, loss 0.291402, acc 0.875
2020-02-08T02:57:58.002772: step 1159, loss 0.214707, acc 0.9375
2020-02-08T02:57:58.118373: step 1160, loss 0.377132, acc 0.859375
2020-02-08T02:57:58.232872: step 1161, loss 0.337941, acc 0.828125
2020-02-08T02:57:58.345470: step 1162, loss 0.284042, acc 0.875
2020-02-08T02:57:58.460796: step 1163, loss 0.231226, acc 0.921875
2020-02-08T02:57:58.577720: step 1164, loss 0.363304, acc 0.828125
2020-02-08T02:57:58.693937: step 1165, loss 0.297111, acc 0.875
2020-02-08T02:57:58.811800: step 1166, loss 0.34531, acc 0.78125
2020-02-08T02:57:58.924902: step 1167, loss 0.336094, acc 0.828125
2020-02-08T02:57:59.041161: step 1168, loss 0.391487, acc 0.84375
2020-02-08T02:57:59.157853: step 1169, loss 0.307994, acc 0.875
2020-02-08T02:57:59.270450: step 1170, loss 0.248562, acc 0.890625
2020-02-08T02:57:59.386711: step 1171, loss 0.331325, acc 0.875
2020-02-08T02:57:59.501897: step 1172, loss 0.315363, acc 0.875
2020-02-08T02:57:59.615096: step 1173, loss 0.416019, acc 0.8125
2020-02-08T02:57:59.731279: step 1174, loss 0.284522, acc 0.84375
2020-02-08T02:57:59.846857: step 1175, loss 0.495157, acc 0.828125
2020-02-08T02:57:59.960673: step 1176, loss 0.351266, acc 0.859375
2020-02-08T02:58:00.075733: step 1177, loss 0.273501, acc 0.859375
2020-02-08T02:58:00.190238: step 1178, loss 0.470646, acc 0.796875
2020-02-08T02:58:00.305644: step 1179, loss 0.329466, acc 0.859375
2020-02-08T02:58:00.425245: step 1180, loss 0.291146, acc 0.90625
2020-02-08T02:58:00.541419: step 1181, loss 0.370262, acc 0.828125
2020-02-08T02:58:00.655830: step 1182, loss 0.29281, acc 0.8125
2020-02-08T02:58:00.771370: step 1183, loss 0.239825, acc 0.921875
2020-02-08T02:58:00.889090: step 1184, loss 0.304464, acc 0.875
2020-02-08T02:58:01.004716: step 1185, loss 0.354876, acc 0.859375
2020-02-08T02:58:01.122323: step 1186, loss 0.329034, acc 0.859375
2020-02-08T02:58:01.241426: step 1187, loss 0.420393, acc 0.796875
2020-02-08T02:58:01.357444: step 1188, loss 0.351606, acc 0.84375
2020-02-08T02:58:01.476257: step 1189, loss 0.366671, acc 0.828125
2020-02-08T02:58:01.592130: step 1190, loss 0.31109, acc 0.859375
2020-02-08T02:58:01.709723: step 1191, loss 0.272557, acc 0.828125
2020-02-08T02:58:01.830484: step 1192, loss 0.415516, acc 0.796875
2020-02-08T02:58:01.946999: step 1193, loss 0.315356, acc 0.859375
2020-02-08T02:58:02.062187: step 1194, loss 0.293872, acc 0.890625
2020-02-08T02:58:02.177060: step 1195, loss 0.188787, acc 0.953125
2020-02-08T02:58:02.292221: step 1196, loss 0.347897, acc 0.875
2020-02-08T02:58:02.409200: step 1197, loss 0.285136, acc 0.890625
2020-02-08T02:58:02.523204: step 1198, loss 0.361175, acc 0.828125
2020-02-08T02:58:02.638279: step 1199, loss 0.301998, acc 0.875
2020-02-08T02:58:02.749770: step 1200, loss 0.350437, acc 0.833333

Evaluation:
2020-02-08T02:58:02.941501: step 1200, loss 0.601314, acc 0.69606

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1200

2020-02-08T02:58:04.474217: step 1201, loss 0.204329, acc 0.921875
2020-02-08T02:58:04.592488: step 1202, loss 0.295282, acc 0.84375
2020-02-08T02:58:04.707078: step 1203, loss 0.37666, acc 0.859375
2020-02-08T02:58:04.823144: step 1204, loss 0.179579, acc 0.921875
2020-02-08T02:58:04.939747: step 1205, loss 0.259758, acc 0.890625
2020-02-08T02:58:05.054882: step 1206, loss 0.306842, acc 0.828125
2020-02-08T02:58:05.171163: step 1207, loss 0.245697, acc 0.921875
2020-02-08T02:58:05.287425: step 1208, loss 0.290128, acc 0.90625
2020-02-08T02:58:05.404438: step 1209, loss 0.327261, acc 0.8125
2020-02-08T02:58:05.517872: step 1210, loss 0.172649, acc 0.9375
2020-02-08T02:58:05.633738: step 1211, loss 0.220619, acc 0.90625
2020-02-08T02:58:05.755113: step 1212, loss 0.257297, acc 0.890625
2020-02-08T02:58:05.872710: step 1213, loss 0.233296, acc 0.90625
2020-02-08T02:58:05.991680: step 1214, loss 0.242794, acc 0.90625
2020-02-08T02:58:06.110078: step 1215, loss 0.310866, acc 0.875
2020-02-08T02:58:06.226042: step 1216, loss 0.399267, acc 0.796875
2020-02-08T02:58:06.344645: step 1217, loss 0.208817, acc 0.90625
2020-02-08T02:58:06.462096: step 1218, loss 0.186558, acc 0.9375
2020-02-08T02:58:06.578781: step 1219, loss 0.247342, acc 0.859375
2020-02-08T02:58:06.697689: step 1220, loss 0.242776, acc 0.9375
2020-02-08T02:58:06.814013: step 1221, loss 0.250197, acc 0.875
2020-02-08T02:58:06.929808: step 1222, loss 0.252025, acc 0.90625
2020-02-08T02:58:07.048943: step 1223, loss 0.278509, acc 0.828125
2020-02-08T02:58:07.164312: step 1224, loss 0.230141, acc 0.90625
2020-02-08T02:58:07.281859: step 1225, loss 0.345781, acc 0.890625
2020-02-08T02:58:07.404028: step 1226, loss 0.216449, acc 0.921875
2020-02-08T02:58:07.520428: step 1227, loss 0.160926, acc 0.953125
2020-02-08T02:58:07.634232: step 1228, loss 0.326622, acc 0.90625
2020-02-08T02:58:07.750315: step 1229, loss 0.199175, acc 0.921875
2020-02-08T02:58:07.866425: step 1230, loss 0.272623, acc 0.90625
2020-02-08T02:58:07.981917: step 1231, loss 0.299095, acc 0.859375
2020-02-08T02:58:08.098264: step 1232, loss 0.312615, acc 0.84375
2020-02-08T02:58:08.213220: step 1233, loss 0.240397, acc 0.890625
2020-02-08T02:58:08.329964: step 1234, loss 0.235997, acc 0.859375
2020-02-08T02:58:08.447515: step 1235, loss 0.163163, acc 0.9375
2020-02-08T02:58:08.563607: step 1236, loss 0.216088, acc 0.921875
2020-02-08T02:58:08.682699: step 1237, loss 0.249786, acc 0.890625
2020-02-08T02:58:08.801661: step 1238, loss 0.321139, acc 0.859375
2020-02-08T02:58:08.917940: step 1239, loss 0.312998, acc 0.84375
2020-02-08T02:58:09.035624: step 1240, loss 0.201612, acc 0.921875
2020-02-08T02:58:09.149908: step 1241, loss 0.164398, acc 0.953125
2020-02-08T02:58:09.267525: step 1242, loss 0.253203, acc 0.9375
2020-02-08T02:58:09.384288: step 1243, loss 0.291288, acc 0.921875
2020-02-08T02:58:09.501138: step 1244, loss 0.255043, acc 0.859375
2020-02-08T02:58:09.618435: step 1245, loss 0.289757, acc 0.859375
2020-02-08T02:58:09.733163: step 1246, loss 0.312844, acc 0.890625
2020-02-08T02:58:09.852583: step 1247, loss 0.233798, acc 0.890625
2020-02-08T02:58:09.967285: step 1248, loss 0.229757, acc 0.90625
2020-02-08T02:58:10.084943: step 1249, loss 0.244603, acc 0.875
2020-02-08T02:58:10.202083: step 1250, loss 0.119027, acc 0.984375
2020-02-08T02:58:10.319341: step 1251, loss 0.179345, acc 0.953125
2020-02-08T02:58:10.435177: step 1252, loss 0.173788, acc 0.9375
2020-02-08T02:58:10.552052: step 1253, loss 0.242104, acc 0.90625
2020-02-08T02:58:10.670542: step 1254, loss 0.382659, acc 0.859375
2020-02-08T02:58:10.788671: step 1255, loss 0.233917, acc 0.875
2020-02-08T02:58:10.903171: step 1256, loss 0.251333, acc 0.921875
2020-02-08T02:58:11.018887: step 1257, loss 0.205092, acc 0.9375
2020-02-08T02:58:11.134797: step 1258, loss 0.222802, acc 0.921875
2020-02-08T02:58:11.250176: step 1259, loss 0.163654, acc 0.953125
2020-02-08T02:58:11.366897: step 1260, loss 0.167111, acc 0.9375
2020-02-08T02:58:11.482813: step 1261, loss 0.19045, acc 0.9375
2020-02-08T02:58:11.602047: step 1262, loss 0.256587, acc 0.890625
2020-02-08T02:58:11.720059: step 1263, loss 0.261438, acc 0.875
2020-02-08T02:58:11.839381: step 1264, loss 0.214898, acc 0.90625
2020-02-08T02:58:11.956248: step 1265, loss 0.249641, acc 0.90625
2020-02-08T02:58:12.070277: step 1266, loss 0.266712, acc 0.875
2020-02-08T02:58:12.184384: step 1267, loss 0.340756, acc 0.828125
2020-02-08T02:58:12.301104: step 1268, loss 0.296982, acc 0.875
2020-02-08T02:58:12.415782: step 1269, loss 0.202903, acc 0.90625
2020-02-08T02:58:12.530902: step 1270, loss 0.269761, acc 0.84375
2020-02-08T02:58:12.648079: step 1271, loss 0.414151, acc 0.78125
2020-02-08T02:58:12.764581: step 1272, loss 0.234117, acc 0.875
2020-02-08T02:58:12.880385: step 1273, loss 0.285932, acc 0.875
2020-02-08T02:58:12.998078: step 1274, loss 0.214826, acc 0.890625
2020-02-08T02:58:13.114065: step 1275, loss 0.297406, acc 0.84375
2020-02-08T02:58:13.228796: step 1276, loss 0.321241, acc 0.859375
2020-02-08T02:58:13.346013: step 1277, loss 0.315642, acc 0.859375
2020-02-08T02:58:13.463774: step 1278, loss 0.276937, acc 0.90625
2020-02-08T02:58:13.580217: step 1279, loss 0.240322, acc 0.890625
2020-02-08T02:58:13.700727: step 1280, loss 0.215882, acc 0.875
2020-02-08T02:58:13.817962: step 1281, loss 0.359131, acc 0.8125
2020-02-08T02:58:13.938290: step 1282, loss 0.308031, acc 0.875
2020-02-08T02:58:14.058996: step 1283, loss 0.223365, acc 0.890625
2020-02-08T02:58:14.172624: step 1284, loss 0.258834, acc 0.875
2020-02-08T02:58:14.290105: step 1285, loss 0.247756, acc 0.890625
2020-02-08T02:58:14.407273: step 1286, loss 0.179143, acc 0.953125
2020-02-08T02:58:14.525147: step 1287, loss 0.233257, acc 0.9375
2020-02-08T02:58:14.644967: step 1288, loss 0.185813, acc 0.9375
2020-02-08T02:58:14.760135: step 1289, loss 0.263643, acc 0.875
2020-02-08T02:58:14.872836: step 1290, loss 0.216833, acc 0.921875
2020-02-08T02:58:14.986857: step 1291, loss 0.244517, acc 0.84375
2020-02-08T02:58:15.102708: step 1292, loss 0.15959, acc 0.953125
2020-02-08T02:58:15.218580: step 1293, loss 0.262999, acc 0.90625
2020-02-08T02:58:15.334485: step 1294, loss 0.2063, acc 0.921875
2020-02-08T02:58:15.451676: step 1295, loss 0.287085, acc 0.828125
2020-02-08T02:58:15.567425: step 1296, loss 0.179457, acc 0.9375
2020-02-08T02:58:15.681044: step 1297, loss 0.291766, acc 0.890625
2020-02-08T02:58:15.798182: step 1298, loss 0.218156, acc 0.9375
2020-02-08T02:58:15.914769: step 1299, loss 0.214003, acc 0.921875
2020-02-08T02:58:16.031527: step 1300, loss 0.291563, acc 0.890625

Evaluation:
2020-02-08T02:58:16.217695: step 1300, loss 0.591182, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1300

2020-02-08T02:58:18.965254: step 1301, loss 0.345204, acc 0.796875
2020-02-08T02:58:19.079120: step 1302, loss 0.277621, acc 0.875
2020-02-08T02:58:19.196354: step 1303, loss 0.140855, acc 0.96875
2020-02-08T02:58:19.313829: step 1304, loss 0.186456, acc 0.9375
2020-02-08T02:58:19.430315: step 1305, loss 0.27287, acc 0.890625
2020-02-08T02:58:19.550370: step 1306, loss 0.183027, acc 0.921875
2020-02-08T02:58:19.664540: step 1307, loss 0.367948, acc 0.84375
2020-02-08T02:58:19.781613: step 1308, loss 0.331728, acc 0.875
2020-02-08T02:58:19.899904: step 1309, loss 0.387159, acc 0.828125
2020-02-08T02:58:20.022375: step 1310, loss 0.118008, acc 0.984375
2020-02-08T02:58:20.135307: step 1311, loss 0.240165, acc 0.90625
2020-02-08T02:58:20.253393: step 1312, loss 0.276938, acc 0.890625
2020-02-08T02:58:20.368010: step 1313, loss 0.240072, acc 0.875
2020-02-08T02:58:20.482149: step 1314, loss 0.178689, acc 0.9375
2020-02-08T02:58:20.599716: step 1315, loss 0.202183, acc 0.90625
2020-02-08T02:58:20.716841: step 1316, loss 0.315818, acc 0.828125
2020-02-08T02:58:20.835338: step 1317, loss 0.2774, acc 0.90625
2020-02-08T02:58:20.949829: step 1318, loss 0.278033, acc 0.84375
2020-02-08T02:58:21.065701: step 1319, loss 0.216577, acc 0.9375
2020-02-08T02:58:21.179913: step 1320, loss 0.312296, acc 0.84375
2020-02-08T02:58:21.514594: step 1321, loss 0.317566, acc 0.84375
2020-02-08T02:58:21.634265: step 1322, loss 0.228868, acc 0.890625
2020-02-08T02:58:21.752158: step 1323, loss 0.237413, acc 0.890625
2020-02-08T02:58:21.867587: step 1324, loss 0.229014, acc 0.890625
2020-02-08T02:58:21.983219: step 1325, loss 0.252651, acc 0.90625
2020-02-08T02:58:22.101116: step 1326, loss 0.298597, acc 0.84375
2020-02-08T02:58:22.215871: step 1327, loss 0.225232, acc 0.921875
2020-02-08T02:58:22.335371: step 1328, loss 0.147776, acc 0.953125
2020-02-08T02:58:22.454772: step 1329, loss 0.231543, acc 0.921875
2020-02-08T02:58:22.571428: step 1330, loss 0.250514, acc 0.890625
2020-02-08T02:58:22.689125: step 1331, loss 0.285597, acc 0.859375
2020-02-08T02:58:22.804100: step 1332, loss 0.263094, acc 0.859375
2020-02-08T02:58:22.921022: step 1333, loss 0.254895, acc 0.921875
2020-02-08T02:58:23.034839: step 1334, loss 0.279496, acc 0.890625
2020-02-08T02:58:23.150985: step 1335, loss 0.235081, acc 0.90625
2020-02-08T02:58:23.266790: step 1336, loss 0.26661, acc 0.875
2020-02-08T02:58:23.382046: step 1337, loss 0.128031, acc 0.96875
2020-02-08T02:58:23.500596: step 1338, loss 0.323476, acc 0.859375
2020-02-08T02:58:23.616678: step 1339, loss 0.300818, acc 0.875
2020-02-08T02:58:23.731104: step 1340, loss 0.267067, acc 0.890625
2020-02-08T02:58:23.848690: step 1341, loss 0.216745, acc 0.890625
2020-02-08T02:58:23.965282: step 1342, loss 0.282462, acc 0.875
2020-02-08T02:58:24.080959: step 1343, loss 0.244792, acc 0.90625
2020-02-08T02:58:24.198317: step 1344, loss 0.191084, acc 0.921875
2020-02-08T02:58:24.314204: step 1345, loss 0.310565, acc 0.859375
2020-02-08T02:58:24.429560: step 1346, loss 0.199489, acc 0.890625
2020-02-08T02:58:24.546848: step 1347, loss 0.242038, acc 0.9375
2020-02-08T02:58:24.662110: step 1348, loss 0.362474, acc 0.859375
2020-02-08T02:58:24.779588: step 1349, loss 0.230842, acc 0.90625
2020-02-08T02:58:24.892912: step 1350, loss 0.245735, acc 0.9
2020-02-08T02:58:25.012655: step 1351, loss 0.218462, acc 0.9375
2020-02-08T02:58:25.128642: step 1352, loss 0.17601, acc 0.9375
2020-02-08T02:58:25.245501: step 1353, loss 0.238343, acc 0.875
2020-02-08T02:58:25.362155: step 1354, loss 0.258523, acc 0.875
2020-02-08T02:58:25.477221: step 1355, loss 0.304586, acc 0.890625
2020-02-08T02:58:25.594581: step 1356, loss 0.198528, acc 0.9375
2020-02-08T02:58:25.713794: step 1357, loss 0.190948, acc 0.90625
2020-02-08T02:58:25.827194: step 1358, loss 0.212709, acc 0.90625
2020-02-08T02:58:25.945085: step 1359, loss 0.149305, acc 0.953125
2020-02-08T02:58:26.061336: step 1360, loss 0.15007, acc 0.953125
2020-02-08T02:58:26.175835: step 1361, loss 0.169972, acc 0.96875
2020-02-08T02:58:26.296596: step 1362, loss 0.269622, acc 0.890625
2020-02-08T02:58:26.418758: step 1363, loss 0.0964973, acc 0.984375
2020-02-08T02:58:26.537965: step 1364, loss 0.221574, acc 0.921875
2020-02-08T02:58:26.658106: step 1365, loss 0.208816, acc 0.921875
2020-02-08T02:58:26.774966: step 1366, loss 0.286233, acc 0.890625
2020-02-08T02:58:26.893082: step 1367, loss 0.16946, acc 0.953125
2020-02-08T02:58:27.010772: step 1368, loss 0.210893, acc 0.90625
2020-02-08T02:58:27.126196: step 1369, loss 0.333354, acc 0.90625
2020-02-08T02:58:27.241906: step 1370, loss 0.121591, acc 0.96875
2020-02-08T02:58:27.360057: step 1371, loss 0.220531, acc 0.890625
2020-02-08T02:58:27.475097: step 1372, loss 0.187041, acc 0.90625
2020-02-08T02:58:27.591966: step 1373, loss 0.183474, acc 0.953125
2020-02-08T02:58:27.708739: step 1374, loss 0.221444, acc 0.90625
2020-02-08T02:58:27.823971: step 1375, loss 0.197203, acc 0.953125
2020-02-08T02:58:27.944462: step 1376, loss 0.248478, acc 0.90625
2020-02-08T02:58:28.065358: step 1377, loss 0.156175, acc 0.9375
2020-02-08T02:58:28.180379: step 1378, loss 0.164857, acc 0.921875
2020-02-08T02:58:28.297967: step 1379, loss 0.220373, acc 0.9375
2020-02-08T02:58:28.412386: step 1380, loss 0.114465, acc 0.984375
2020-02-08T02:58:28.525620: step 1381, loss 0.215184, acc 0.890625
2020-02-08T02:58:28.639634: step 1382, loss 0.28182, acc 0.90625
2020-02-08T02:58:28.757501: step 1383, loss 0.170426, acc 0.921875
2020-02-08T02:58:28.871259: step 1384, loss 0.216054, acc 0.921875
2020-02-08T02:58:28.986859: step 1385, loss 0.267639, acc 0.90625
2020-02-08T02:58:29.102980: step 1386, loss 0.13203, acc 0.953125
2020-02-08T02:58:29.217263: step 1387, loss 0.307617, acc 0.84375
2020-02-08T02:58:29.331858: step 1388, loss 0.228462, acc 0.90625
2020-02-08T02:58:29.449816: step 1389, loss 0.1771, acc 0.9375
2020-02-08T02:58:29.564988: step 1390, loss 0.235384, acc 0.9375
2020-02-08T02:58:29.679735: step 1391, loss 0.196098, acc 0.921875
2020-02-08T02:58:29.796868: step 1392, loss 0.278886, acc 0.859375
2020-02-08T02:58:29.914281: step 1393, loss 0.18648, acc 0.9375
2020-02-08T02:58:30.030464: step 1394, loss 0.205027, acc 0.921875
2020-02-08T02:58:30.146135: step 1395, loss 0.194612, acc 0.9375
2020-02-08T02:58:30.261195: step 1396, loss 0.200466, acc 0.9375
2020-02-08T02:58:30.375126: step 1397, loss 0.176854, acc 0.9375
2020-02-08T02:58:30.491903: step 1398, loss 0.194354, acc 0.921875
2020-02-08T02:58:30.607603: step 1399, loss 0.220646, acc 0.875
2020-02-08T02:58:30.724297: step 1400, loss 0.207645, acc 0.921875

Evaluation:
2020-02-08T02:58:30.910713: step 1400, loss 0.631127, acc 0.712946

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1400

2020-02-08T02:58:32.466920: step 1401, loss 0.139247, acc 0.953125
2020-02-08T02:58:32.580643: step 1402, loss 0.224686, acc 0.875
2020-02-08T02:58:32.698361: step 1403, loss 0.23458, acc 0.921875
2020-02-08T02:58:32.815321: step 1404, loss 0.226262, acc 0.921875
2020-02-08T02:58:32.932326: step 1405, loss 0.120258, acc 0.953125
2020-02-08T02:58:33.051553: step 1406, loss 0.200269, acc 0.90625
2020-02-08T02:58:33.169301: step 1407, loss 0.2681, acc 0.890625
2020-02-08T02:58:33.286234: step 1408, loss 0.106377, acc 0.953125
2020-02-08T02:58:33.403405: step 1409, loss 0.200486, acc 0.921875
2020-02-08T02:58:33.521302: step 1410, loss 0.133525, acc 0.9375
2020-02-08T02:58:33.634224: step 1411, loss 0.184692, acc 0.921875
2020-02-08T02:58:33.749931: step 1412, loss 0.185345, acc 0.9375
2020-02-08T02:58:33.865007: step 1413, loss 0.140191, acc 0.921875
2020-02-08T02:58:33.979417: step 1414, loss 0.103651, acc 0.984375
2020-02-08T02:58:34.095733: step 1415, loss 0.251869, acc 0.90625
2020-02-08T02:58:34.210990: step 1416, loss 0.264106, acc 0.890625
2020-02-08T02:58:34.324608: step 1417, loss 0.187639, acc 0.90625
2020-02-08T02:58:34.438935: step 1418, loss 0.252934, acc 0.859375
2020-02-08T02:58:34.560900: step 1419, loss 0.224667, acc 0.875
2020-02-08T02:58:34.675150: step 1420, loss 0.235124, acc 0.890625
2020-02-08T02:58:34.796500: step 1421, loss 0.197554, acc 0.90625
2020-02-08T02:58:34.913787: step 1422, loss 0.163593, acc 0.921875
2020-02-08T02:58:35.030806: step 1423, loss 0.0835748, acc 0.984375
2020-02-08T02:58:35.147819: step 1424, loss 0.180656, acc 0.953125
2020-02-08T02:58:35.261761: step 1425, loss 0.310341, acc 0.828125
2020-02-08T02:58:35.373596: step 1426, loss 0.168828, acc 0.953125
2020-02-08T02:58:35.489817: step 1427, loss 0.192557, acc 0.90625
2020-02-08T02:58:35.605196: step 1428, loss 0.154196, acc 0.953125
2020-02-08T02:58:35.720260: step 1429, loss 0.116695, acc 0.96875
2020-02-08T02:58:35.836310: step 1430, loss 0.213477, acc 0.90625
2020-02-08T02:58:35.952255: step 1431, loss 0.202933, acc 0.9375
2020-02-08T02:58:36.069251: step 1432, loss 0.193234, acc 0.96875
2020-02-08T02:58:36.183645: step 1433, loss 0.137371, acc 0.953125
2020-02-08T02:58:36.301013: step 1434, loss 0.170448, acc 0.890625
2020-02-08T02:58:36.418567: step 1435, loss 0.138983, acc 0.921875
2020-02-08T02:58:36.534657: step 1436, loss 0.209837, acc 0.90625
2020-02-08T02:58:36.651175: step 1437, loss 0.266784, acc 0.890625
2020-02-08T02:58:36.767980: step 1438, loss 0.228551, acc 0.890625
2020-02-08T02:58:36.883157: step 1439, loss 0.188731, acc 0.921875
2020-02-08T02:58:37.001239: step 1440, loss 0.294319, acc 0.890625
2020-02-08T02:58:37.117685: step 1441, loss 0.234051, acc 0.90625
2020-02-08T02:58:37.234927: step 1442, loss 0.217483, acc 0.890625
2020-02-08T02:58:37.351593: step 1443, loss 0.248657, acc 0.890625
2020-02-08T02:58:37.468544: step 1444, loss 0.15573, acc 0.9375
2020-02-08T02:58:37.584605: step 1445, loss 0.209605, acc 0.921875
2020-02-08T02:58:37.703199: step 1446, loss 0.151158, acc 0.921875
2020-02-08T02:58:37.820269: step 1447, loss 0.233291, acc 0.921875
2020-02-08T02:58:37.937114: step 1448, loss 0.201816, acc 0.921875
2020-02-08T02:58:38.054497: step 1449, loss 0.176809, acc 0.9375
2020-02-08T02:58:38.168969: step 1450, loss 0.163729, acc 0.953125
2020-02-08T02:58:38.283572: step 1451, loss 0.32752, acc 0.859375
2020-02-08T02:58:38.399506: step 1452, loss 0.169474, acc 0.921875
2020-02-08T02:58:38.514031: step 1453, loss 0.197292, acc 0.9375
2020-02-08T02:58:38.629445: step 1454, loss 0.0938578, acc 0.96875
2020-02-08T02:58:38.747284: step 1455, loss 0.169158, acc 0.953125
2020-02-08T02:58:38.864282: step 1456, loss 0.249654, acc 0.90625
2020-02-08T02:58:38.984028: step 1457, loss 0.155928, acc 0.953125
2020-02-08T02:58:39.104015: step 1458, loss 0.433712, acc 0.828125
2020-02-08T02:58:39.219402: step 1459, loss 0.214228, acc 0.84375
2020-02-08T02:58:39.335177: step 1460, loss 0.135987, acc 0.953125
2020-02-08T02:58:39.451179: step 1461, loss 0.14912, acc 0.9375
2020-02-08T02:58:39.565722: step 1462, loss 0.170048, acc 0.9375
2020-02-08T02:58:39.681994: step 1463, loss 0.218182, acc 0.890625
2020-02-08T02:58:39.797928: step 1464, loss 0.239539, acc 0.875
2020-02-08T02:58:39.912096: step 1465, loss 0.24207, acc 0.875
2020-02-08T02:58:40.029688: step 1466, loss 0.190287, acc 0.921875
2020-02-08T02:58:40.148906: step 1467, loss 0.271541, acc 0.890625
2020-02-08T02:58:40.265153: step 1468, loss 0.132029, acc 0.953125
2020-02-08T02:58:40.379415: step 1469, loss 0.191344, acc 0.921875
2020-02-08T02:58:40.497720: step 1470, loss 0.251109, acc 0.90625
2020-02-08T02:58:40.614251: step 1471, loss 0.212623, acc 0.9375
2020-02-08T02:58:40.730057: step 1472, loss 0.226798, acc 0.890625
2020-02-08T02:58:40.848304: step 1473, loss 0.233179, acc 0.90625
2020-02-08T02:58:40.965416: step 1474, loss 0.24474, acc 0.90625
2020-02-08T02:58:41.080679: step 1475, loss 0.199356, acc 0.921875
2020-02-08T02:58:41.196922: step 1476, loss 0.219264, acc 0.9375
2020-02-08T02:58:41.313358: step 1477, loss 0.141296, acc 0.9375
2020-02-08T02:58:41.428943: step 1478, loss 0.194212, acc 0.875
2020-02-08T02:58:41.543918: step 1479, loss 0.392729, acc 0.765625
2020-02-08T02:58:41.660933: step 1480, loss 0.160949, acc 0.96875
2020-02-08T02:58:41.774709: step 1481, loss 0.10479, acc 0.96875
2020-02-08T02:58:41.891296: step 1482, loss 0.19784, acc 0.90625
2020-02-08T02:58:42.008883: step 1483, loss 0.219459, acc 0.875
2020-02-08T02:58:42.122523: step 1484, loss 0.275864, acc 0.875
2020-02-08T02:58:42.238891: step 1485, loss 0.148369, acc 0.96875
2020-02-08T02:58:42.355918: step 1486, loss 0.146902, acc 0.953125
2020-02-08T02:58:42.470454: step 1487, loss 0.213763, acc 0.9375
2020-02-08T02:58:42.585500: step 1488, loss 0.176914, acc 0.9375
2020-02-08T02:58:42.704329: step 1489, loss 0.176613, acc 0.921875
2020-02-08T02:58:42.819397: step 1490, loss 0.1502, acc 0.953125
2020-02-08T02:58:42.934874: step 1491, loss 0.177982, acc 0.953125
2020-02-08T02:58:43.055511: step 1492, loss 0.276858, acc 0.921875
2020-02-08T02:58:43.169755: step 1493, loss 0.306543, acc 0.890625
2020-02-08T02:58:43.285207: step 1494, loss 0.1226, acc 0.9375
2020-02-08T02:58:43.403053: step 1495, loss 0.152746, acc 0.9375
2020-02-08T02:58:43.518978: step 1496, loss 0.162901, acc 0.9375
2020-02-08T02:58:43.635569: step 1497, loss 0.276525, acc 0.859375
2020-02-08T02:58:43.751718: step 1498, loss 0.252232, acc 0.890625
2020-02-08T02:58:43.868642: step 1499, loss 0.148976, acc 0.921875
2020-02-08T02:58:43.978023: step 1500, loss 0.126895, acc 0.966667

Evaluation:
2020-02-08T02:58:44.164399: step 1500, loss 0.61592, acc 0.712008

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1500

2020-02-08T02:58:45.683057: step 1501, loss 0.0468034, acc 1
2020-02-08T02:58:45.800307: step 1502, loss 0.172137, acc 0.9375
2020-02-08T02:58:45.917352: step 1503, loss 0.162722, acc 0.921875
2020-02-08T02:58:46.030628: step 1504, loss 0.121895, acc 0.96875
2020-02-08T02:58:46.148829: step 1505, loss 0.139266, acc 0.953125
2020-02-08T02:58:46.264130: step 1506, loss 0.0833655, acc 0.984375
2020-02-08T02:58:46.381036: step 1507, loss 0.100247, acc 1
2020-02-08T02:58:46.498854: step 1508, loss 0.227267, acc 0.9375
2020-02-08T02:58:46.617487: step 1509, loss 0.158292, acc 0.90625
2020-02-08T02:58:46.735155: step 1510, loss 0.11299, acc 0.984375
2020-02-08T02:58:46.850903: step 1511, loss 0.131962, acc 0.953125
2020-02-08T02:58:46.967163: step 1512, loss 0.179817, acc 0.9375
2020-02-08T02:58:47.083059: step 1513, loss 0.0827904, acc 1
2020-02-08T02:58:47.199836: step 1514, loss 0.171316, acc 0.953125
2020-02-08T02:58:47.318570: step 1515, loss 0.0695924, acc 0.96875
2020-02-08T02:58:47.437799: step 1516, loss 0.0807791, acc 0.984375
2020-02-08T02:58:47.553791: step 1517, loss 0.126264, acc 0.9375
2020-02-08T02:58:47.672700: step 1518, loss 0.169208, acc 0.90625
2020-02-08T02:58:47.788319: step 1519, loss 0.15169, acc 0.9375
2020-02-08T02:58:47.903310: step 1520, loss 0.165391, acc 0.9375
2020-02-08T02:58:48.019446: step 1521, loss 0.168488, acc 0.921875
2020-02-08T02:58:48.133415: step 1522, loss 0.175137, acc 0.9375
2020-02-08T02:58:48.250606: step 1523, loss 0.173058, acc 0.953125
2020-02-08T02:58:48.367350: step 1524, loss 0.154262, acc 0.90625
2020-02-08T02:58:48.483164: step 1525, loss 0.181389, acc 0.90625
2020-02-08T02:58:48.597583: step 1526, loss 0.222847, acc 0.921875
2020-02-08T02:58:48.709358: step 1527, loss 0.202696, acc 0.90625
2020-02-08T02:58:48.824160: step 1528, loss 0.160374, acc 0.953125
2020-02-08T02:58:48.941953: step 1529, loss 0.169951, acc 0.90625
2020-02-08T02:58:49.060408: step 1530, loss 0.183987, acc 0.953125
2020-02-08T02:58:49.175971: step 1531, loss 0.151251, acc 0.953125
2020-02-08T02:58:49.292221: step 1532, loss 0.15313, acc 0.921875
2020-02-08T02:58:49.410540: step 1533, loss 0.134103, acc 0.96875
2020-02-08T02:58:49.527300: step 1534, loss 0.103504, acc 0.96875
2020-02-08T02:58:49.643484: step 1535, loss 0.226728, acc 0.875
2020-02-08T02:58:49.759914: step 1536, loss 0.134154, acc 0.921875
2020-02-08T02:58:49.877319: step 1537, loss 0.139667, acc 0.90625
2020-02-08T02:58:49.994127: step 1538, loss 0.147729, acc 0.953125
2020-02-08T02:58:50.111659: step 1539, loss 0.144246, acc 0.9375
2020-02-08T02:58:50.227563: step 1540, loss 0.0909421, acc 0.96875
2020-02-08T02:58:50.345703: step 1541, loss 0.115748, acc 0.953125
2020-02-08T02:58:50.463461: step 1542, loss 0.110928, acc 0.984375
2020-02-08T02:58:50.584685: step 1543, loss 0.137372, acc 0.9375
2020-02-08T02:58:50.701587: step 1544, loss 0.174387, acc 0.9375
2020-02-08T02:58:50.821191: step 1545, loss 0.162794, acc 0.9375
2020-02-08T02:58:50.937184: step 1546, loss 0.156664, acc 0.953125
2020-02-08T02:58:51.054816: step 1547, loss 0.215577, acc 0.84375
2020-02-08T02:58:51.170662: step 1548, loss 0.146448, acc 0.9375
2020-02-08T02:58:51.286573: step 1549, loss 0.197048, acc 0.953125
2020-02-08T02:58:51.402520: step 1550, loss 0.123873, acc 0.984375
2020-02-08T02:58:51.515464: step 1551, loss 0.226215, acc 0.921875
2020-02-08T02:58:51.630513: step 1552, loss 0.153023, acc 0.9375
2020-02-08T02:58:51.795714: step 1553, loss 0.175482, acc 0.9375
2020-02-08T02:58:51.919959: step 1554, loss 0.169437, acc 0.953125
2020-02-08T02:58:52.036908: step 1555, loss 0.189986, acc 0.90625
2020-02-08T02:58:52.151667: step 1556, loss 0.12159, acc 0.96875
2020-02-08T02:58:52.269831: step 1557, loss 0.0868944, acc 0.984375
2020-02-08T02:58:52.384184: step 1558, loss 0.132528, acc 0.9375
2020-02-08T02:58:52.498239: step 1559, loss 0.160751, acc 0.890625
2020-02-08T02:58:52.611727: step 1560, loss 0.139963, acc 0.953125
2020-02-08T02:58:52.725262: step 1561, loss 0.133896, acc 0.9375
2020-02-08T02:58:52.842074: step 1562, loss 0.132823, acc 0.9375
2020-02-08T02:58:52.961784: step 1563, loss 0.14504, acc 0.953125
2020-02-08T02:58:53.084884: step 1564, loss 0.168973, acc 0.9375
2020-02-08T02:58:53.199386: step 1565, loss 0.149651, acc 0.921875
2020-02-08T02:58:53.313418: step 1566, loss 0.113662, acc 0.953125
2020-02-08T02:58:53.428134: step 1567, loss 0.120376, acc 0.9375
2020-02-08T02:58:53.543650: step 1568, loss 0.197344, acc 0.890625
2020-02-08T02:58:53.659901: step 1569, loss 0.120997, acc 0.9375
2020-02-08T02:58:53.778716: step 1570, loss 0.0815843, acc 0.984375
2020-02-08T02:58:53.895677: step 1571, loss 0.17515, acc 0.9375
2020-02-08T02:58:54.011568: step 1572, loss 0.126716, acc 0.953125
2020-02-08T02:58:54.126765: step 1573, loss 0.125318, acc 0.953125
2020-02-08T02:58:54.245428: step 1574, loss 0.148891, acc 0.9375
2020-02-08T02:58:54.362245: step 1575, loss 0.146961, acc 0.9375
2020-02-08T02:58:54.478024: step 1576, loss 0.166566, acc 0.953125
2020-02-08T02:58:54.594786: step 1577, loss 0.115431, acc 0.984375
2020-02-08T02:58:54.710722: step 1578, loss 0.149596, acc 0.9375
2020-02-08T02:58:54.827325: step 1579, loss 0.163758, acc 0.9375
2020-02-08T02:58:54.944928: step 1580, loss 0.235881, acc 0.90625
2020-02-08T02:58:55.059357: step 1581, loss 0.16398, acc 0.921875
2020-02-08T02:58:55.174464: step 1582, loss 0.151485, acc 0.9375
2020-02-08T02:58:55.288882: step 1583, loss 0.1431, acc 0.96875
2020-02-08T02:58:55.407690: step 1584, loss 0.170041, acc 0.9375
2020-02-08T02:58:55.527673: step 1585, loss 0.158443, acc 0.90625
2020-02-08T02:58:55.643240: step 1586, loss 0.142877, acc 0.90625
2020-02-08T02:58:55.758140: step 1587, loss 0.0817772, acc 1
2020-02-08T02:58:55.875345: step 1588, loss 0.133016, acc 0.921875
2020-02-08T02:58:55.989277: step 1589, loss 0.125521, acc 0.96875
2020-02-08T02:58:56.105653: step 1590, loss 0.170256, acc 0.9375
2020-02-08T02:58:56.220943: step 1591, loss 0.174782, acc 0.953125
2020-02-08T02:58:56.336531: step 1592, loss 0.199, acc 0.9375
2020-02-08T02:58:56.453545: step 1593, loss 0.208519, acc 0.90625
2020-02-08T02:58:56.568398: step 1594, loss 0.254605, acc 0.921875
2020-02-08T02:58:56.682278: step 1595, loss 0.240751, acc 0.875
2020-02-08T02:58:56.801395: step 1596, loss 0.064133, acc 1
2020-02-08T02:58:56.916837: step 1597, loss 0.151668, acc 0.9375
2020-02-08T02:58:57.034443: step 1598, loss 0.201763, acc 0.9375
2020-02-08T02:58:57.152895: step 1599, loss 0.157133, acc 0.953125
2020-02-08T02:58:57.273640: step 1600, loss 0.16266, acc 0.9375

Evaluation:
2020-02-08T02:58:57.461660: step 1600, loss 0.671726, acc 0.712008

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1600

2020-02-08T02:59:00.003669: step 1601, loss 0.222827, acc 0.921875
2020-02-08T02:59:00.120855: step 1602, loss 0.146102, acc 0.953125
2020-02-08T02:59:00.235777: step 1603, loss 0.136164, acc 0.921875
2020-02-08T02:59:00.354187: step 1604, loss 0.218716, acc 0.921875
2020-02-08T02:59:00.470188: step 1605, loss 0.151919, acc 0.90625
2020-02-08T02:59:00.585405: step 1606, loss 0.199283, acc 0.921875
2020-02-08T02:59:00.701054: step 1607, loss 0.269295, acc 0.875
2020-02-08T02:59:00.818336: step 1608, loss 0.2332, acc 0.921875
2020-02-08T02:59:00.937475: step 1609, loss 0.188058, acc 0.921875
2020-02-08T02:59:01.053369: step 1610, loss 0.137515, acc 0.96875
2020-02-08T02:59:01.170929: step 1611, loss 0.173116, acc 0.953125
2020-02-08T02:59:01.287450: step 1612, loss 0.231471, acc 0.90625
2020-02-08T02:59:01.405452: step 1613, loss 0.223497, acc 0.921875
2020-02-08T02:59:01.521719: step 1614, loss 0.142305, acc 0.953125
2020-02-08T02:59:01.638145: step 1615, loss 0.202611, acc 0.921875
2020-02-08T02:59:01.753048: step 1616, loss 0.235782, acc 0.921875
2020-02-08T02:59:01.871505: step 1617, loss 0.16847, acc 0.921875
2020-02-08T02:59:01.985599: step 1618, loss 0.179221, acc 0.9375
2020-02-08T02:59:02.104802: step 1619, loss 0.13478, acc 0.953125
2020-02-08T02:59:02.225291: step 1620, loss 0.216682, acc 0.90625
2020-02-08T02:59:02.431133: step 1621, loss 0.177904, acc 0.921875
2020-02-08T02:59:02.569972: step 1622, loss 0.101282, acc 0.96875
2020-02-08T02:59:02.693588: step 1623, loss 0.181158, acc 0.921875
2020-02-08T02:59:02.820023: step 1624, loss 0.239858, acc 0.921875
2020-02-08T02:59:02.960204: step 1625, loss 0.145743, acc 0.953125
2020-02-08T02:59:03.089631: step 1626, loss 0.143338, acc 0.9375
2020-02-08T02:59:03.223706: step 1627, loss 0.233569, acc 0.921875
2020-02-08T02:59:03.357187: step 1628, loss 0.104219, acc 0.953125
2020-02-08T02:59:03.486895: step 1629, loss 0.182503, acc 0.921875
2020-02-08T02:59:03.615802: step 1630, loss 0.0983588, acc 0.96875
2020-02-08T02:59:03.747170: step 1631, loss 0.303107, acc 0.859375
2020-02-08T02:59:03.887904: step 1632, loss 0.184314, acc 0.921875
2020-02-08T02:59:04.015875: step 1633, loss 0.215206, acc 0.921875
2020-02-08T02:59:04.149024: step 1634, loss 0.190631, acc 0.90625
2020-02-08T02:59:04.279302: step 1635, loss 0.260442, acc 0.890625
2020-02-08T02:59:04.411960: step 1636, loss 0.201307, acc 0.921875
2020-02-08T02:59:04.547872: step 1637, loss 0.23039, acc 0.875
2020-02-08T02:59:04.678705: step 1638, loss 0.106173, acc 0.96875
2020-02-08T02:59:04.813602: step 1639, loss 0.112011, acc 0.984375
2020-02-08T02:59:04.949562: step 1640, loss 0.117385, acc 0.953125
2020-02-08T02:59:05.079858: step 1641, loss 0.0979356, acc 0.953125
2020-02-08T02:59:05.214241: step 1642, loss 0.254112, acc 0.9375
2020-02-08T02:59:05.353433: step 1643, loss 0.197591, acc 0.9375
2020-02-08T02:59:05.483247: step 1644, loss 0.0838349, acc 0.96875
2020-02-08T02:59:05.621531: step 1645, loss 0.125648, acc 0.953125
2020-02-08T02:59:05.765028: step 1646, loss 0.164887, acc 0.9375
2020-02-08T02:59:05.897855: step 1647, loss 0.122987, acc 0.9375
2020-02-08T02:59:06.033404: step 1648, loss 0.06296, acc 1
2020-02-08T02:59:06.178996: step 1649, loss 0.179948, acc 0.96875
2020-02-08T02:59:06.301507: step 1650, loss 0.166214, acc 0.916667
2020-02-08T02:59:06.433027: step 1651, loss 0.0792697, acc 0.96875
2020-02-08T02:59:06.571551: step 1652, loss 0.164595, acc 0.9375
2020-02-08T02:59:06.709056: step 1653, loss 0.08063, acc 0.984375
2020-02-08T02:59:06.846192: step 1654, loss 0.105174, acc 0.953125
2020-02-08T02:59:06.990984: step 1655, loss 0.130907, acc 0.96875
2020-02-08T02:59:07.117183: step 1656, loss 0.243317, acc 0.859375
2020-02-08T02:59:07.240227: step 1657, loss 0.141517, acc 0.890625
2020-02-08T02:59:07.371777: step 1658, loss 0.209137, acc 0.90625
2020-02-08T02:59:07.506691: step 1659, loss 0.0835885, acc 0.96875
2020-02-08T02:59:07.644155: step 1660, loss 0.061001, acc 1
2020-02-08T02:59:07.782831: step 1661, loss 0.0720841, acc 0.984375
2020-02-08T02:59:07.919155: step 1662, loss 0.145302, acc 0.9375
2020-02-08T02:59:08.054777: step 1663, loss 0.106133, acc 0.96875
2020-02-08T02:59:08.192831: step 1664, loss 0.117734, acc 0.96875
2020-02-08T02:59:08.326757: step 1665, loss 0.143579, acc 0.953125
2020-02-08T02:59:08.461772: step 1666, loss 0.136516, acc 0.953125
2020-02-08T02:59:08.595408: step 1667, loss 0.0901662, acc 0.953125
2020-02-08T02:59:08.729485: step 1668, loss 0.121138, acc 0.96875
2020-02-08T02:59:08.868607: step 1669, loss 0.076552, acc 0.984375
2020-02-08T02:59:09.002854: step 1670, loss 0.151559, acc 0.921875
2020-02-08T02:59:09.144362: step 1671, loss 0.102226, acc 0.96875
2020-02-08T02:59:09.280348: step 1672, loss 0.149666, acc 0.96875
2020-02-08T02:59:09.412261: step 1673, loss 0.0632662, acc 1
2020-02-08T02:59:09.554499: step 1674, loss 0.11177, acc 0.96875
2020-02-08T02:59:09.692114: step 1675, loss 0.0908828, acc 0.96875
2020-02-08T02:59:09.829299: step 1676, loss 0.137924, acc 0.953125
2020-02-08T02:59:09.964071: step 1677, loss 0.0458851, acc 1
2020-02-08T02:59:10.099363: step 1678, loss 0.158241, acc 0.953125
2020-02-08T02:59:10.234280: step 1679, loss 0.0800412, acc 0.96875
2020-02-08T02:59:10.370969: step 1680, loss 0.16022, acc 0.96875
2020-02-08T02:59:10.510849: step 1681, loss 0.170685, acc 0.96875
2020-02-08T02:59:10.647247: step 1682, loss 0.158954, acc 0.953125
2020-02-08T02:59:10.782277: step 1683, loss 0.106717, acc 0.96875
2020-02-08T02:59:10.914666: step 1684, loss 0.0809829, acc 0.96875
2020-02-08T02:59:11.052008: step 1685, loss 0.152262, acc 0.9375
2020-02-08T02:59:11.164213: step 1686, loss 0.101423, acc 0.96875
2020-02-08T02:59:11.281179: step 1687, loss 0.0617505, acc 0.96875
2020-02-08T02:59:11.401259: step 1688, loss 0.106308, acc 0.96875
2020-02-08T02:59:11.526665: step 1689, loss 0.0923953, acc 0.984375
2020-02-08T02:59:11.657054: step 1690, loss 0.110774, acc 0.96875
2020-02-08T02:59:11.789732: step 1691, loss 0.052715, acc 0.984375
2020-02-08T02:59:11.912085: step 1692, loss 0.141751, acc 0.9375
2020-02-08T02:59:12.039601: step 1693, loss 0.0740852, acc 0.984375
2020-02-08T02:59:12.158844: step 1694, loss 0.154581, acc 0.9375
2020-02-08T02:59:12.275568: step 1695, loss 0.224518, acc 0.921875
2020-02-08T02:59:12.396109: step 1696, loss 0.104705, acc 0.9375
2020-02-08T02:59:12.516825: step 1697, loss 0.142017, acc 0.9375
2020-02-08T02:59:12.633588: step 1698, loss 0.0892443, acc 0.984375
2020-02-08T02:59:12.752244: step 1699, loss 0.0711557, acc 0.984375
2020-02-08T02:59:12.872038: step 1700, loss 0.106208, acc 0.96875

Evaluation:
2020-02-08T02:59:13.061924: step 1700, loss 0.662185, acc 0.710131

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1700

2020-02-08T02:59:14.618529: step 1701, loss 0.10908, acc 0.96875
2020-02-08T02:59:14.737541: step 1702, loss 0.105231, acc 0.953125
2020-02-08T02:59:14.859719: step 1703, loss 0.136623, acc 0.921875
2020-02-08T02:59:14.979172: step 1704, loss 0.162445, acc 0.921875
2020-02-08T02:59:15.108346: step 1705, loss 0.139659, acc 0.921875
2020-02-08T02:59:15.224094: step 1706, loss 0.151265, acc 0.9375
2020-02-08T02:59:15.342249: step 1707, loss 0.0600002, acc 1
2020-02-08T02:59:15.458772: step 1708, loss 0.119229, acc 0.96875
2020-02-08T02:59:15.574230: step 1709, loss 0.0962299, acc 0.953125
2020-02-08T02:59:15.690126: step 1710, loss 0.0972209, acc 0.96875
2020-02-08T02:59:15.810972: step 1711, loss 0.094314, acc 0.96875
2020-02-08T02:59:15.924513: step 1712, loss 0.104759, acc 0.984375
2020-02-08T02:59:16.042090: step 1713, loss 0.170954, acc 0.953125
2020-02-08T02:59:16.160003: step 1714, loss 0.160713, acc 0.953125
2020-02-08T02:59:16.277908: step 1715, loss 0.0512591, acc 1
2020-02-08T02:59:16.394117: step 1716, loss 0.0999402, acc 0.984375
2020-02-08T02:59:16.511507: step 1717, loss 0.240993, acc 0.90625
2020-02-08T02:59:16.626291: step 1718, loss 0.0928762, acc 0.96875
2020-02-08T02:59:16.744241: step 1719, loss 0.083865, acc 0.953125
2020-02-08T02:59:16.860566: step 1720, loss 0.114976, acc 0.953125
2020-02-08T02:59:16.974769: step 1721, loss 0.152923, acc 0.9375
2020-02-08T02:59:17.091155: step 1722, loss 0.191951, acc 0.9375
2020-02-08T02:59:17.208724: step 1723, loss 0.103011, acc 0.96875
2020-02-08T02:59:17.325384: step 1724, loss 0.151674, acc 0.96875
2020-02-08T02:59:17.440510: step 1725, loss 0.0600258, acc 0.984375
2020-02-08T02:59:17.559890: step 1726, loss 0.199744, acc 0.921875
2020-02-08T02:59:17.672791: step 1727, loss 0.115506, acc 0.9375
2020-02-08T02:59:17.800419: step 1728, loss 0.131259, acc 0.9375
2020-02-08T02:59:17.918017: step 1729, loss 0.113015, acc 0.96875
2020-02-08T02:59:18.033316: step 1730, loss 0.134283, acc 0.9375
2020-02-08T02:59:18.148155: step 1731, loss 0.0788829, acc 0.96875
2020-02-08T02:59:18.264815: step 1732, loss 0.16492, acc 0.9375
2020-02-08T02:59:18.379323: step 1733, loss 0.127527, acc 0.953125
2020-02-08T02:59:18.495310: step 1734, loss 0.123617, acc 0.96875
2020-02-08T02:59:18.611182: step 1735, loss 0.0878742, acc 0.984375
2020-02-08T02:59:18.726569: step 1736, loss 0.139453, acc 0.9375
2020-02-08T02:59:18.848855: step 1737, loss 0.0858832, acc 0.953125
2020-02-08T02:59:18.964621: step 1738, loss 0.0879424, acc 0.984375
2020-02-08T02:59:19.079045: step 1739, loss 0.114568, acc 0.953125
2020-02-08T02:59:19.196266: step 1740, loss 0.0854875, acc 0.96875
2020-02-08T02:59:19.313770: step 1741, loss 0.0715269, acc 0.984375
2020-02-08T02:59:19.427958: step 1742, loss 0.0742642, acc 1
2020-02-08T02:59:19.544488: step 1743, loss 0.125285, acc 0.953125
2020-02-08T02:59:19.662854: step 1744, loss 0.170906, acc 0.921875
2020-02-08T02:59:19.778940: step 1745, loss 0.136819, acc 0.921875
2020-02-08T02:59:19.897674: step 1746, loss 0.137284, acc 0.9375
2020-02-08T02:59:20.014623: step 1747, loss 0.0891451, acc 0.984375
2020-02-08T02:59:20.128228: step 1748, loss 0.111969, acc 0.96875
2020-02-08T02:59:20.245027: step 1749, loss 0.233295, acc 0.890625
2020-02-08T02:59:20.367756: step 1750, loss 0.0871814, acc 0.96875
2020-02-08T02:59:20.483988: step 1751, loss 0.190291, acc 0.90625
2020-02-08T02:59:20.600529: step 1752, loss 0.179757, acc 0.921875
2020-02-08T02:59:20.716474: step 1753, loss 0.0753664, acc 0.96875
2020-02-08T02:59:20.837164: step 1754, loss 0.0539098, acc 0.984375
2020-02-08T02:59:20.955955: step 1755, loss 0.0744897, acc 0.984375
2020-02-08T02:59:21.072556: step 1756, loss 0.0855984, acc 0.984375
2020-02-08T02:59:21.189522: step 1757, loss 0.107717, acc 0.9375
2020-02-08T02:59:21.301564: step 1758, loss 0.0815278, acc 0.984375
2020-02-08T02:59:21.510510: step 1759, loss 0.110831, acc 0.96875
2020-02-08T02:59:21.636843: step 1760, loss 0.106709, acc 0.984375
2020-02-08T02:59:21.753182: step 1761, loss 0.150494, acc 0.90625
2020-02-08T02:59:21.871842: step 1762, loss 0.0321521, acc 1
2020-02-08T02:59:21.989965: step 1763, loss 0.103587, acc 0.984375
2020-02-08T02:59:22.105776: step 1764, loss 0.082261, acc 0.96875
2020-02-08T02:59:22.221381: step 1765, loss 0.122683, acc 0.96875
2020-02-08T02:59:22.340984: step 1766, loss 0.113894, acc 0.953125
2020-02-08T02:59:22.458367: step 1767, loss 0.0635742, acc 0.96875
2020-02-08T02:59:22.574800: step 1768, loss 0.0672324, acc 0.984375
2020-02-08T02:59:22.695981: step 1769, loss 0.0789952, acc 0.96875
2020-02-08T02:59:22.822809: step 1770, loss 0.110647, acc 0.953125
2020-02-08T02:59:22.946795: step 1771, loss 0.0973172, acc 0.96875
2020-02-08T02:59:23.065306: step 1772, loss 0.0739272, acc 0.984375
2020-02-08T02:59:23.188709: step 1773, loss 0.187474, acc 0.890625
2020-02-08T02:59:23.310729: step 1774, loss 0.0999229, acc 0.96875
2020-02-08T02:59:23.437233: step 1775, loss 0.12886, acc 0.953125
2020-02-08T02:59:23.561708: step 1776, loss 0.118076, acc 0.953125
2020-02-08T02:59:23.679426: step 1777, loss 0.202431, acc 0.921875
2020-02-08T02:59:23.802248: step 1778, loss 0.174812, acc 0.9375
2020-02-08T02:59:23.923197: step 1779, loss 0.177326, acc 0.921875
2020-02-08T02:59:24.041061: step 1780, loss 0.087895, acc 0.96875
2020-02-08T02:59:24.164095: step 1781, loss 0.147514, acc 0.953125
2020-02-08T02:59:24.278155: step 1782, loss 0.0457567, acc 1
2020-02-08T02:59:24.398771: step 1783, loss 0.124106, acc 0.96875
2020-02-08T02:59:24.515754: step 1784, loss 0.152545, acc 0.9375
2020-02-08T02:59:24.633481: step 1785, loss 0.103358, acc 0.96875
2020-02-08T02:59:24.756405: step 1786, loss 0.0673643, acc 0.96875
2020-02-08T02:59:24.873185: step 1787, loss 0.10826, acc 0.984375
2020-02-08T02:59:24.995787: step 1788, loss 0.221885, acc 0.875
2020-02-08T02:59:25.112380: step 1789, loss 0.187727, acc 0.921875
2020-02-08T02:59:25.225866: step 1790, loss 0.235004, acc 0.90625
2020-02-08T02:59:25.346166: step 1791, loss 0.0942008, acc 0.96875
2020-02-08T02:59:25.462846: step 1792, loss 0.183408, acc 0.9375
2020-02-08T02:59:25.577301: step 1793, loss 0.109687, acc 0.96875
2020-02-08T02:59:25.694797: step 1794, loss 0.232298, acc 0.9375
2020-02-08T02:59:25.815560: step 1795, loss 0.0696995, acc 0.984375
2020-02-08T02:59:25.930178: step 1796, loss 0.196531, acc 0.90625
2020-02-08T02:59:26.047179: step 1797, loss 0.166142, acc 0.9375
2020-02-08T02:59:26.162810: step 1798, loss 0.144257, acc 0.9375
2020-02-08T02:59:26.275113: step 1799, loss 0.09741, acc 0.9375
2020-02-08T02:59:26.387089: step 1800, loss 0.0815692, acc 0.95

Evaluation:
2020-02-08T02:59:26.574332: step 1800, loss 0.690293, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1800

2020-02-08T02:59:28.137259: step 1801, loss 0.070709, acc 0.984375
2020-02-08T02:59:28.254841: step 1802, loss 0.059338, acc 0.984375
2020-02-08T02:59:28.370412: step 1803, loss 0.189339, acc 0.9375
2020-02-08T02:59:28.489387: step 1804, loss 0.0534226, acc 0.984375
2020-02-08T02:59:28.610563: step 1805, loss 0.0407705, acc 0.984375
2020-02-08T02:59:28.723750: step 1806, loss 0.0385589, acc 0.984375
2020-02-08T02:59:28.843378: step 1807, loss 0.104321, acc 0.96875
2020-02-08T02:59:28.960869: step 1808, loss 0.098316, acc 0.953125
2020-02-08T02:59:29.077359: step 1809, loss 0.0893781, acc 0.96875
2020-02-08T02:59:29.195408: step 1810, loss 0.139613, acc 0.921875
2020-02-08T02:59:29.311391: step 1811, loss 0.0865988, acc 0.984375
2020-02-08T02:59:29.425487: step 1812, loss 0.0540035, acc 0.984375
2020-02-08T02:59:29.543544: step 1813, loss 0.0516972, acc 0.984375
2020-02-08T02:59:29.661654: step 1814, loss 0.0794509, acc 0.96875
2020-02-08T02:59:29.779689: step 1815, loss 0.0816022, acc 0.96875
2020-02-08T02:59:29.897730: step 1816, loss 0.0857586, acc 0.984375
2020-02-08T02:59:30.016278: step 1817, loss 0.070705, acc 0.96875
2020-02-08T02:59:30.130724: step 1818, loss 0.0507106, acc 1
2020-02-08T02:59:30.246460: step 1819, loss 0.0982038, acc 0.984375
2020-02-08T02:59:30.360488: step 1820, loss 0.0995404, acc 0.953125
2020-02-08T02:59:30.476732: step 1821, loss 0.0985927, acc 0.9375
2020-02-08T02:59:30.593751: step 1822, loss 0.138021, acc 0.9375
2020-02-08T02:59:30.711074: step 1823, loss 0.199151, acc 0.921875
2020-02-08T02:59:30.829455: step 1824, loss 0.0636573, acc 0.953125
2020-02-08T02:59:30.948620: step 1825, loss 0.112969, acc 0.953125
2020-02-08T02:59:31.065482: step 1826, loss 0.129359, acc 0.984375
2020-02-08T02:59:31.181131: step 1827, loss 0.0307856, acc 1
2020-02-08T02:59:31.299623: step 1828, loss 0.0808681, acc 0.953125
2020-02-08T02:59:31.417526: step 1829, loss 0.0840927, acc 0.984375
2020-02-08T02:59:31.534781: step 1830, loss 0.0363641, acc 1
2020-02-08T02:59:31.652800: step 1831, loss 0.0895795, acc 0.96875
2020-02-08T02:59:31.770903: step 1832, loss 0.0795846, acc 0.984375
2020-02-08T02:59:31.887746: step 1833, loss 0.067483, acc 0.984375
2020-02-08T02:59:32.005605: step 1834, loss 0.177012, acc 0.890625
2020-02-08T02:59:32.120452: step 1835, loss 0.0676791, acc 0.96875
2020-02-08T02:59:32.232465: step 1836, loss 0.0760143, acc 0.984375
2020-02-08T02:59:32.349543: step 1837, loss 0.0802254, acc 0.96875
2020-02-08T02:59:32.466652: step 1838, loss 0.0890637, acc 0.953125
2020-02-08T02:59:32.581617: step 1839, loss 0.0939645, acc 0.96875
2020-02-08T02:59:32.698173: step 1840, loss 0.0653384, acc 0.984375
2020-02-08T02:59:32.818206: step 1841, loss 0.0502615, acc 1
2020-02-08T02:59:32.960206: step 1842, loss 0.139682, acc 0.953125
2020-02-08T02:59:33.096097: step 1843, loss 0.119683, acc 0.953125
2020-02-08T02:59:33.210843: step 1844, loss 0.147755, acc 0.9375
2020-02-08T02:59:33.326802: step 1845, loss 0.100366, acc 0.984375
2020-02-08T02:59:33.444100: step 1846, loss 0.0963369, acc 0.984375
2020-02-08T02:59:33.563645: step 1847, loss 0.0670195, acc 0.984375
2020-02-08T02:59:33.677937: step 1848, loss 0.112234, acc 0.96875
2020-02-08T02:59:33.799539: step 1849, loss 0.106978, acc 0.953125
2020-02-08T02:59:33.916121: step 1850, loss 0.0735361, acc 0.984375
2020-02-08T02:59:34.033441: step 1851, loss 0.0626818, acc 0.984375
2020-02-08T02:59:34.149490: step 1852, loss 0.147209, acc 0.9375
2020-02-08T02:59:34.267047: step 1853, loss 0.0811801, acc 0.984375
2020-02-08T02:59:34.385643: step 1854, loss 0.0958054, acc 0.96875
2020-02-08T02:59:34.503355: step 1855, loss 0.085899, acc 0.953125
2020-02-08T02:59:34.618530: step 1856, loss 0.0944218, acc 0.96875
2020-02-08T02:59:34.734640: step 1857, loss 0.163215, acc 0.9375
2020-02-08T02:59:34.852626: step 1858, loss 0.0600927, acc 0.984375
2020-02-08T02:59:34.968828: step 1859, loss 0.110356, acc 0.953125
2020-02-08T02:59:35.086271: step 1860, loss 0.0849013, acc 0.984375
2020-02-08T02:59:35.206193: step 1861, loss 0.106313, acc 0.96875
2020-02-08T02:59:35.324060: step 1862, loss 0.08004, acc 0.984375
2020-02-08T02:59:35.442433: step 1863, loss 0.127646, acc 0.9375
2020-02-08T02:59:35.560767: step 1864, loss 0.0712662, acc 0.96875
2020-02-08T02:59:35.677412: step 1865, loss 0.132742, acc 0.953125
2020-02-08T02:59:35.796564: step 1866, loss 0.144024, acc 0.953125
2020-02-08T02:59:35.913322: step 1867, loss 0.0542866, acc 0.984375
2020-02-08T02:59:36.030746: step 1868, loss 0.0883735, acc 0.953125
2020-02-08T02:59:36.148710: step 1869, loss 0.0397796, acc 1
2020-02-08T02:59:36.265027: step 1870, loss 0.0401221, acc 1
2020-02-08T02:59:36.381444: step 1871, loss 0.110269, acc 0.96875
2020-02-08T02:59:36.498985: step 1872, loss 0.133779, acc 0.96875
2020-02-08T02:59:36.613747: step 1873, loss 0.135809, acc 0.953125
2020-02-08T02:59:36.730566: step 1874, loss 0.133298, acc 0.9375
2020-02-08T02:59:36.857557: step 1875, loss 0.0455886, acc 0.984375
2020-02-08T02:59:36.972208: step 1876, loss 0.132183, acc 0.953125
2020-02-08T02:59:37.090939: step 1877, loss 0.0520993, acc 0.984375
2020-02-08T02:59:37.207765: step 1878, loss 0.268251, acc 0.953125
2020-02-08T02:59:37.324623: step 1879, loss 0.0730961, acc 0.96875
2020-02-08T02:59:37.443583: step 1880, loss 0.0522552, acc 0.984375
2020-02-08T02:59:37.560813: step 1881, loss 0.0960333, acc 0.953125
2020-02-08T02:59:37.672113: step 1882, loss 0.123011, acc 0.953125
2020-02-08T02:59:37.798361: step 1883, loss 0.225332, acc 0.9375
2020-02-08T02:59:37.914536: step 1884, loss 0.108612, acc 0.953125
2020-02-08T02:59:38.035419: step 1885, loss 0.0787314, acc 0.96875
2020-02-08T02:59:38.154584: step 1886, loss 0.0978759, acc 0.96875
2020-02-08T02:59:38.270006: step 1887, loss 0.0947604, acc 0.953125
2020-02-08T02:59:38.387943: step 1888, loss 0.155278, acc 0.9375
2020-02-08T02:59:38.504623: step 1889, loss 0.0394643, acc 1
2020-02-08T02:59:38.622495: step 1890, loss 0.102989, acc 0.953125
2020-02-08T02:59:38.743252: step 1891, loss 0.0831083, acc 0.953125
2020-02-08T02:59:38.859925: step 1892, loss 0.0499226, acc 0.984375
2020-02-08T02:59:38.978105: step 1893, loss 0.0888247, acc 0.984375
2020-02-08T02:59:39.093089: step 1894, loss 0.0900573, acc 0.96875
2020-02-08T02:59:39.210047: step 1895, loss 0.0908516, acc 0.96875
2020-02-08T02:59:39.324954: step 1896, loss 0.0411374, acc 0.984375
2020-02-08T02:59:39.440071: step 1897, loss 0.149595, acc 0.9375
2020-02-08T02:59:39.554572: step 1898, loss 0.0565983, acc 0.984375
2020-02-08T02:59:39.670062: step 1899, loss 0.0840222, acc 1
2020-02-08T02:59:39.790285: step 1900, loss 0.0787187, acc 1

Evaluation:
2020-02-08T02:59:39.978520: step 1900, loss 0.703249, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-1900

2020-02-08T02:59:41.566599: step 1901, loss 0.034852, acc 0.984375
2020-02-08T02:59:41.689103: step 1902, loss 0.0567584, acc 0.984375
2020-02-08T02:59:41.810480: step 1903, loss 0.0582859, acc 1
2020-02-08T02:59:41.931219: step 1904, loss 0.113726, acc 0.96875
2020-02-08T02:59:42.047289: step 1905, loss 0.098884, acc 0.9375
2020-02-08T02:59:42.161271: step 1906, loss 0.121744, acc 0.953125
2020-02-08T02:59:42.277046: step 1907, loss 0.100067, acc 0.96875
2020-02-08T02:59:42.394878: step 1908, loss 0.108103, acc 0.96875
2020-02-08T02:59:42.512409: step 1909, loss 0.0966545, acc 0.96875
2020-02-08T02:59:42.628103: step 1910, loss 0.102047, acc 0.96875
2020-02-08T02:59:42.747395: step 1911, loss 0.0769679, acc 0.96875
2020-02-08T02:59:42.864321: step 1912, loss 0.135695, acc 0.953125
2020-02-08T02:59:42.983807: step 1913, loss 0.0840367, acc 0.96875
2020-02-08T02:59:43.099587: step 1914, loss 0.0947431, acc 0.96875
2020-02-08T02:59:43.215866: step 1915, loss 0.10577, acc 0.96875
2020-02-08T02:59:43.330868: step 1916, loss 0.117429, acc 0.9375
2020-02-08T02:59:43.449855: step 1917, loss 0.167652, acc 0.921875
2020-02-08T02:59:43.565281: step 1918, loss 0.175302, acc 0.90625
2020-02-08T02:59:43.679729: step 1919, loss 0.139133, acc 0.953125
2020-02-08T02:59:43.799063: step 1920, loss 0.0836924, acc 0.984375
2020-02-08T02:59:43.914739: step 1921, loss 0.0691252, acc 0.984375
2020-02-08T02:59:44.031739: step 1922, loss 0.104057, acc 0.953125
2020-02-08T02:59:44.148550: step 1923, loss 0.0793499, acc 0.96875
2020-02-08T02:59:44.266694: step 1924, loss 0.0611504, acc 0.96875
2020-02-08T02:59:44.383126: step 1925, loss 0.0444671, acc 0.984375
2020-02-08T02:59:44.498733: step 1926, loss 0.0888235, acc 0.96875
2020-02-08T02:59:44.615314: step 1927, loss 0.0972292, acc 0.96875
2020-02-08T02:59:44.733302: step 1928, loss 0.082028, acc 0.96875
2020-02-08T02:59:44.854323: step 1929, loss 0.0679478, acc 0.984375
2020-02-08T02:59:44.973641: step 1930, loss 0.0994843, acc 0.96875
2020-02-08T02:59:45.087072: step 1931, loss 0.0603924, acc 0.96875
2020-02-08T02:59:45.202517: step 1932, loss 0.0698468, acc 0.984375
2020-02-08T02:59:45.317592: step 1933, loss 0.130064, acc 0.953125
2020-02-08T02:59:45.435447: step 1934, loss 0.0558152, acc 1
2020-02-08T02:59:45.551709: step 1935, loss 0.0725155, acc 0.96875
2020-02-08T02:59:45.668635: step 1936, loss 0.130775, acc 0.953125
2020-02-08T02:59:45.789706: step 1937, loss 0.108157, acc 0.953125
2020-02-08T02:59:45.902919: step 1938, loss 0.0438629, acc 1
2020-02-08T02:59:46.018851: step 1939, loss 0.093026, acc 0.96875
2020-02-08T02:59:46.134731: step 1940, loss 0.0655712, acc 0.984375
2020-02-08T02:59:46.249597: step 1941, loss 0.0418372, acc 1
2020-02-08T02:59:46.365058: step 1942, loss 0.162069, acc 0.9375
2020-02-08T02:59:46.481679: step 1943, loss 0.112712, acc 0.9375
2020-02-08T02:59:46.599234: step 1944, loss 0.191072, acc 0.921875
2020-02-08T02:59:46.715036: step 1945, loss 0.0614869, acc 0.984375
2020-02-08T02:59:46.836531: step 1946, loss 0.0752694, acc 0.96875
2020-02-08T02:59:46.953582: step 1947, loss 0.0908713, acc 0.96875
2020-02-08T02:59:47.071062: step 1948, loss 0.155039, acc 0.9375
2020-02-08T02:59:47.187873: step 1949, loss 0.0380844, acc 1
2020-02-08T02:59:47.300277: step 1950, loss 0.185397, acc 0.95
2020-02-08T02:59:47.419408: step 1951, loss 0.0685842, acc 0.984375
2020-02-08T02:59:47.536132: step 1952, loss 0.0439724, acc 1
2020-02-08T02:59:47.656201: step 1953, loss 0.152502, acc 0.953125
2020-02-08T02:59:47.774746: step 1954, loss 0.0179611, acc 1
2020-02-08T02:59:47.891279: step 1955, loss 0.0992079, acc 0.96875
2020-02-08T02:59:48.009071: step 1956, loss 0.0707171, acc 0.984375
2020-02-08T02:59:48.124902: step 1957, loss 0.0797196, acc 0.96875
2020-02-08T02:59:48.241731: step 1958, loss 0.113139, acc 0.921875
2020-02-08T02:59:48.357965: step 1959, loss 0.047755, acc 0.984375
2020-02-08T02:59:48.473426: step 1960, loss 0.127705, acc 0.9375
2020-02-08T02:59:48.590464: step 1961, loss 0.0684109, acc 0.96875
2020-02-08T02:59:48.708023: step 1962, loss 0.0498158, acc 0.984375
2020-02-08T02:59:48.828325: step 1963, loss 0.0656901, acc 0.984375
2020-02-08T02:59:48.947222: step 1964, loss 0.0953176, acc 0.96875
2020-02-08T02:59:49.062924: step 1965, loss 0.124026, acc 0.9375
2020-02-08T02:59:49.177218: step 1966, loss 0.0826077, acc 0.96875
2020-02-08T02:59:49.293443: step 1967, loss 0.0643163, acc 0.984375
2020-02-08T02:59:49.410648: step 1968, loss 0.0452357, acc 0.984375
2020-02-08T02:59:49.525900: step 1969, loss 0.0796427, acc 0.96875
2020-02-08T02:59:49.642481: step 1970, loss 0.074258, acc 0.953125
2020-02-08T02:59:49.761307: step 1971, loss 0.0852815, acc 0.953125
2020-02-08T02:59:49.875952: step 1972, loss 0.0689409, acc 0.984375
2020-02-08T02:59:49.990883: step 1973, loss 0.047194, acc 0.984375
2020-02-08T02:59:50.107074: step 1974, loss 0.0715406, acc 0.96875
2020-02-08T02:59:50.223452: step 1975, loss 0.0453199, acc 0.984375
2020-02-08T02:59:50.338689: step 1976, loss 0.0355474, acc 0.984375
2020-02-08T02:59:50.457569: step 1977, loss 0.156308, acc 0.9375
2020-02-08T02:59:50.574124: step 1978, loss 0.0600708, acc 0.96875
2020-02-08T02:59:50.691418: step 1979, loss 0.118533, acc 0.96875
2020-02-08T02:59:50.812957: step 1980, loss 0.0859389, acc 0.96875
2020-02-08T02:59:50.927687: step 1981, loss 0.0473041, acc 0.984375
2020-02-08T02:59:51.043156: step 1982, loss 0.059129, acc 0.984375
2020-02-08T02:59:51.157892: step 1983, loss 0.0680528, acc 0.984375
2020-02-08T02:59:51.528826: step 1984, loss 0.0624857, acc 0.984375
2020-02-08T02:59:51.656615: step 1985, loss 0.044066, acc 1
2020-02-08T02:59:51.774388: step 1986, loss 0.161108, acc 0.90625
2020-02-08T02:59:51.891657: step 1987, loss 0.0511201, acc 1
2020-02-08T02:59:52.008137: step 1988, loss 0.027216, acc 1
2020-02-08T02:59:52.122806: step 1989, loss 0.0395408, acc 1
2020-02-08T02:59:52.239734: step 1990, loss 0.0559512, acc 0.96875
2020-02-08T02:59:52.354571: step 1991, loss 0.103123, acc 0.9375
2020-02-08T02:59:52.471231: step 1992, loss 0.0288834, acc 1
2020-02-08T02:59:52.591795: step 1993, loss 0.0957493, acc 0.96875
2020-02-08T02:59:52.710451: step 1994, loss 0.0398675, acc 1
2020-02-08T02:59:52.829134: step 1995, loss 0.0944938, acc 0.984375
2020-02-08T02:59:52.948372: step 1996, loss 0.0508563, acc 0.984375
2020-02-08T02:59:53.067272: step 1997, loss 0.134664, acc 0.953125
2020-02-08T02:59:53.184356: step 1998, loss 0.0626518, acc 0.984375
2020-02-08T02:59:53.301979: step 1999, loss 0.0624436, acc 0.96875
2020-02-08T02:59:53.417971: step 2000, loss 0.118678, acc 0.921875

Evaluation:
2020-02-08T02:59:53.604911: step 2000, loss 0.770974, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2000

2020-02-08T02:59:55.172608: step 2001, loss 0.0146432, acc 1
2020-02-08T02:59:55.285707: step 2002, loss 0.0340407, acc 1
2020-02-08T02:59:55.403586: step 2003, loss 0.0737594, acc 0.984375
2020-02-08T02:59:55.520207: step 2004, loss 0.083978, acc 0.9375
2020-02-08T02:59:55.638310: step 2005, loss 0.117901, acc 0.96875
2020-02-08T02:59:55.755843: step 2006, loss 0.0355425, acc 0.984375
2020-02-08T02:59:55.874072: step 2007, loss 0.0290529, acc 1
2020-02-08T02:59:55.990779: step 2008, loss 0.0227229, acc 1
2020-02-08T02:59:56.109255: step 2009, loss 0.186018, acc 0.9375
2020-02-08T02:59:56.224053: step 2010, loss 0.0557906, acc 0.984375
2020-02-08T02:59:56.341639: step 2011, loss 0.0757373, acc 0.96875
2020-02-08T02:59:56.463371: step 2012, loss 0.0679596, acc 0.96875
2020-02-08T02:59:56.580479: step 2013, loss 0.0671764, acc 0.96875
2020-02-08T02:59:56.696722: step 2014, loss 0.0769656, acc 0.96875
2020-02-08T02:59:56.817972: step 2015, loss 0.103251, acc 0.9375
2020-02-08T02:59:56.932801: step 2016, loss 0.0840541, acc 0.96875
2020-02-08T02:59:57.052427: step 2017, loss 0.071966, acc 0.984375
2020-02-08T02:59:57.171616: step 2018, loss 0.0823572, acc 0.96875
2020-02-08T02:59:57.288936: step 2019, loss 0.0702777, acc 0.984375
2020-02-08T02:59:57.406533: step 2020, loss 0.0447016, acc 0.984375
2020-02-08T02:59:57.523856: step 2021, loss 0.0380729, acc 1
2020-02-08T02:59:57.639283: step 2022, loss 0.0481186, acc 0.984375
2020-02-08T02:59:57.758903: step 2023, loss 0.0644381, acc 0.984375
2020-02-08T02:59:57.875253: step 2024, loss 0.0198647, acc 1
2020-02-08T02:59:57.993878: step 2025, loss 0.0724126, acc 0.984375
2020-02-08T02:59:58.110378: step 2026, loss 0.0500732, acc 0.96875
2020-02-08T02:59:58.226702: step 2027, loss 0.117009, acc 0.9375
2020-02-08T02:59:58.342562: step 2028, loss 0.136483, acc 0.953125
2020-02-08T02:59:58.458903: step 2029, loss 0.0570161, acc 0.984375
2020-02-08T02:59:58.573559: step 2030, loss 0.0970075, acc 0.96875
2020-02-08T02:59:58.690235: step 2031, loss 0.0488287, acc 0.96875
2020-02-08T02:59:58.812496: step 2032, loss 0.0849427, acc 0.96875
2020-02-08T02:59:58.926608: step 2033, loss 0.12062, acc 0.953125
2020-02-08T02:59:59.040818: step 2034, loss 0.094215, acc 0.953125
2020-02-08T02:59:59.158946: step 2035, loss 0.0779877, acc 0.984375
2020-02-08T02:59:59.275272: step 2036, loss 0.130532, acc 0.953125
2020-02-08T02:59:59.394522: step 2037, loss 0.0958229, acc 0.96875
2020-02-08T02:59:59.511774: step 2038, loss 0.115063, acc 0.953125
2020-02-08T02:59:59.626355: step 2039, loss 0.0921156, acc 0.96875
2020-02-08T02:59:59.745414: step 2040, loss 0.0818585, acc 0.953125
2020-02-08T02:59:59.863542: step 2041, loss 0.112256, acc 0.96875
2020-02-08T02:59:59.977228: step 2042, loss 0.0954864, acc 0.953125
2020-02-08T03:00:00.096038: step 2043, loss 0.10643, acc 0.9375
2020-02-08T03:00:00.214008: step 2044, loss 0.0789532, acc 0.984375
2020-02-08T03:00:00.331127: step 2045, loss 0.0391394, acc 0.984375
2020-02-08T03:00:00.445921: step 2046, loss 0.0313099, acc 0.984375
2020-02-08T03:00:00.563146: step 2047, loss 0.0605706, acc 0.984375
2020-02-08T03:00:00.679571: step 2048, loss 0.025696, acc 1
2020-02-08T03:00:00.800217: step 2049, loss 0.0585169, acc 0.984375
2020-02-08T03:00:00.916186: step 2050, loss 0.0403084, acc 1
2020-02-08T03:00:01.031928: step 2051, loss 0.0774235, acc 0.984375
2020-02-08T03:00:01.149181: step 2052, loss 0.0355266, acc 1
2020-02-08T03:00:01.265020: step 2053, loss 0.0525096, acc 0.984375
2020-02-08T03:00:01.379095: step 2054, loss 0.0563513, acc 0.984375
2020-02-08T03:00:01.495895: step 2055, loss 0.0776034, acc 0.96875
2020-02-08T03:00:01.614438: step 2056, loss 0.0624754, acc 0.984375
2020-02-08T03:00:01.731481: step 2057, loss 0.0275697, acc 1
2020-02-08T03:00:01.854237: step 2058, loss 0.114061, acc 0.9375
2020-02-08T03:00:01.972951: step 2059, loss 0.0478078, acc 0.984375
2020-02-08T03:00:02.087863: step 2060, loss 0.0578195, acc 0.96875
2020-02-08T03:00:02.206086: step 2061, loss 0.135736, acc 0.9375
2020-02-08T03:00:02.324325: step 2062, loss 0.0422716, acc 0.984375
2020-02-08T03:00:02.439250: step 2063, loss 0.0393758, acc 0.984375
2020-02-08T03:00:02.556089: step 2064, loss 0.065082, acc 0.984375
2020-02-08T03:00:02.671491: step 2065, loss 0.064968, acc 0.96875
2020-02-08T03:00:02.795778: step 2066, loss 0.155181, acc 0.96875
2020-02-08T03:00:02.912278: step 2067, loss 0.067344, acc 0.953125
2020-02-08T03:00:03.029682: step 2068, loss 0.0907438, acc 0.96875
2020-02-08T03:00:03.150057: step 2069, loss 0.0297955, acc 1
2020-02-08T03:00:03.269267: step 2070, loss 0.0783131, acc 0.953125
2020-02-08T03:00:03.385523: step 2071, loss 0.119151, acc 0.96875
2020-02-08T03:00:03.506546: step 2072, loss 0.0536128, acc 0.984375
2020-02-08T03:00:03.625329: step 2073, loss 0.0639659, acc 0.96875
2020-02-08T03:00:03.742504: step 2074, loss 0.0209673, acc 1
2020-02-08T03:00:03.860263: step 2075, loss 0.0935445, acc 0.984375
2020-02-08T03:00:03.976285: step 2076, loss 0.138078, acc 0.953125
2020-02-08T03:00:04.095624: step 2077, loss 0.0297909, acc 0.984375
2020-02-08T03:00:04.214573: step 2078, loss 0.0806443, acc 0.96875
2020-02-08T03:00:04.328457: step 2079, loss 0.090222, acc 0.953125
2020-02-08T03:00:04.445498: step 2080, loss 0.0890635, acc 0.96875
2020-02-08T03:00:04.562793: step 2081, loss 0.0819246, acc 0.984375
2020-02-08T03:00:04.681750: step 2082, loss 0.0803089, acc 0.984375
2020-02-08T03:00:04.805169: step 2083, loss 0.0917088, acc 0.953125
2020-02-08T03:00:04.924961: step 2084, loss 0.0298981, acc 1
2020-02-08T03:00:05.041923: step 2085, loss 0.0298906, acc 1
2020-02-08T03:00:05.163877: step 2086, loss 0.120213, acc 0.9375
2020-02-08T03:00:05.281286: step 2087, loss 0.0373178, acc 1
2020-02-08T03:00:05.396669: step 2088, loss 0.0584752, acc 0.984375
2020-02-08T03:00:05.514966: step 2089, loss 0.0487998, acc 0.984375
2020-02-08T03:00:05.631476: step 2090, loss 0.128544, acc 0.953125
2020-02-08T03:00:05.756850: step 2091, loss 0.0736872, acc 0.96875
2020-02-08T03:00:05.872089: step 2092, loss 0.0959472, acc 0.96875
2020-02-08T03:00:05.988560: step 2093, loss 0.0646932, acc 0.984375
2020-02-08T03:00:06.104566: step 2094, loss 0.101983, acc 0.9375
2020-02-08T03:00:06.225469: step 2095, loss 0.0427976, acc 1
2020-02-08T03:00:06.343009: step 2096, loss 0.116502, acc 0.9375
2020-02-08T03:00:06.461747: step 2097, loss 0.106714, acc 0.921875
2020-02-08T03:00:06.577828: step 2098, loss 0.0403207, acc 1
2020-02-08T03:00:06.693164: step 2099, loss 0.0723764, acc 0.984375
2020-02-08T03:00:06.813962: step 2100, loss 0.0508646, acc 0.983333

Evaluation:
2020-02-08T03:00:07.002666: step 2100, loss 0.778764, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2100

2020-02-08T03:00:09.007759: step 2101, loss 0.0371823, acc 0.984375
2020-02-08T03:00:09.127963: step 2102, loss 0.0212294, acc 1
2020-02-08T03:00:09.245669: step 2103, loss 0.0463981, acc 1
2020-02-08T03:00:09.363636: step 2104, loss 0.07059, acc 0.96875
2020-02-08T03:00:09.478550: step 2105, loss 0.0362561, acc 1
2020-02-08T03:00:09.599981: step 2106, loss 0.0317622, acc 0.984375
2020-02-08T03:00:09.718222: step 2107, loss 0.0826336, acc 0.96875
2020-02-08T03:00:09.837905: step 2108, loss 0.0967818, acc 0.984375
2020-02-08T03:00:09.954713: step 2109, loss 0.0547948, acc 0.984375
2020-02-08T03:00:10.072075: step 2110, loss 0.0852374, acc 0.96875
2020-02-08T03:00:10.191694: step 2111, loss 0.0270523, acc 1
2020-02-08T03:00:10.310030: step 2112, loss 0.0285257, acc 1
2020-02-08T03:00:10.425035: step 2113, loss 0.0584772, acc 0.96875
2020-02-08T03:00:10.541940: step 2114, loss 0.0218541, acc 1
2020-02-08T03:00:10.660623: step 2115, loss 0.0447614, acc 0.984375
2020-02-08T03:00:10.780069: step 2116, loss 0.0917536, acc 0.953125
2020-02-08T03:00:10.894638: step 2117, loss 0.069193, acc 0.96875
2020-02-08T03:00:11.012606: step 2118, loss 0.0281377, acc 1
2020-02-08T03:00:11.128899: step 2119, loss 0.110803, acc 0.9375
2020-02-08T03:00:11.246308: step 2120, loss 0.0290832, acc 1
2020-02-08T03:00:11.363773: step 2121, loss 0.0477625, acc 0.984375
2020-02-08T03:00:11.481348: step 2122, loss 0.0508379, acc 0.96875
2020-02-08T03:00:11.600470: step 2123, loss 0.0191603, acc 1
2020-02-08T03:00:11.722199: step 2124, loss 0.0204595, acc 1
2020-02-08T03:00:11.845390: step 2125, loss 0.0788068, acc 0.96875
2020-02-08T03:00:11.963049: step 2126, loss 0.0377963, acc 0.984375
2020-02-08T03:00:12.082624: step 2127, loss 0.0573667, acc 0.984375
2020-02-08T03:00:12.202274: step 2128, loss 0.0298384, acc 1
2020-02-08T03:00:12.318741: step 2129, loss 0.0791916, acc 0.984375
2020-02-08T03:00:12.434625: step 2130, loss 0.073938, acc 0.953125
2020-02-08T03:00:12.555048: step 2131, loss 0.0173467, acc 1
2020-02-08T03:00:12.674291: step 2132, loss 0.0660261, acc 0.96875
2020-02-08T03:00:12.796747: step 2133, loss 0.0517004, acc 0.984375
2020-02-08T03:00:12.915223: step 2134, loss 0.0677278, acc 0.984375
2020-02-08T03:00:13.032100: step 2135, loss 0.0230385, acc 1
2020-02-08T03:00:13.147196: step 2136, loss 0.080673, acc 0.96875
2020-02-08T03:00:13.262295: step 2137, loss 0.0213419, acc 1
2020-02-08T03:00:13.377980: step 2138, loss 0.0269634, acc 1
2020-02-08T03:00:13.496347: step 2139, loss 0.0762867, acc 0.953125
2020-02-08T03:00:13.611664: step 2140, loss 0.0410356, acc 1
2020-02-08T03:00:13.733301: step 2141, loss 0.0724707, acc 0.984375
2020-02-08T03:00:13.855033: step 2142, loss 0.0458477, acc 0.984375
2020-02-08T03:00:13.971202: step 2143, loss 0.0437683, acc 0.984375
2020-02-08T03:00:14.085835: step 2144, loss 0.0330851, acc 1
2020-02-08T03:00:14.201862: step 2145, loss 0.025408, acc 1
2020-02-08T03:00:14.319952: step 2146, loss 0.033458, acc 0.984375
2020-02-08T03:00:14.435935: step 2147, loss 0.0383235, acc 1
2020-02-08T03:00:14.552124: step 2148, loss 0.0192285, acc 1
2020-02-08T03:00:14.667928: step 2149, loss 0.0885598, acc 0.953125
2020-02-08T03:00:14.784575: step 2150, loss 0.0436681, acc 1
2020-02-08T03:00:14.902546: step 2151, loss 0.0592823, acc 1
2020-02-08T03:00:15.020244: step 2152, loss 0.0235822, acc 1
2020-02-08T03:00:15.136036: step 2153, loss 0.0180368, acc 1
2020-02-08T03:00:15.253860: step 2154, loss 0.0241136, acc 0.984375
2020-02-08T03:00:15.374073: step 2155, loss 0.0519884, acc 0.984375
2020-02-08T03:00:15.491038: step 2156, loss 0.169038, acc 0.96875
2020-02-08T03:00:15.611457: step 2157, loss 0.0341021, acc 1
2020-02-08T03:00:15.727854: step 2158, loss 0.0450769, acc 1
2020-02-08T03:00:15.853591: step 2159, loss 0.0788816, acc 0.96875
2020-02-08T03:00:15.970056: step 2160, loss 0.0883443, acc 0.984375
2020-02-08T03:00:16.085880: step 2161, loss 0.0639852, acc 0.96875
2020-02-08T03:00:16.203152: step 2162, loss 0.0414431, acc 1
2020-02-08T03:00:16.319562: step 2163, loss 0.156138, acc 0.9375
2020-02-08T03:00:16.432768: step 2164, loss 0.0769652, acc 0.96875
2020-02-08T03:00:16.547830: step 2165, loss 0.0480255, acc 0.984375
2020-02-08T03:00:16.668417: step 2166, loss 0.0346138, acc 1
2020-02-08T03:00:16.792879: step 2167, loss 0.0949795, acc 0.953125
2020-02-08T03:00:16.910646: step 2168, loss 0.0190882, acc 1
2020-02-08T03:00:17.026621: step 2169, loss 0.0143701, acc 1
2020-02-08T03:00:17.142724: step 2170, loss 0.0125801, acc 1
2020-02-08T03:00:17.261230: step 2171, loss 0.101066, acc 0.96875
2020-02-08T03:00:17.376272: step 2172, loss 0.051421, acc 0.96875
2020-02-08T03:00:17.492416: step 2173, loss 0.0753171, acc 0.96875
2020-02-08T03:00:17.609318: step 2174, loss 0.0282034, acc 1
2020-02-08T03:00:17.724318: step 2175, loss 0.0428342, acc 0.984375
2020-02-08T03:00:17.842845: step 2176, loss 0.0425813, acc 0.984375
2020-02-08T03:00:17.960818: step 2177, loss 0.0241661, acc 1
2020-02-08T03:00:18.075965: step 2178, loss 0.0184959, acc 1
2020-02-08T03:00:18.191399: step 2179, loss 0.0650178, acc 0.96875
2020-02-08T03:00:18.308620: step 2180, loss 0.0471321, acc 0.984375
2020-02-08T03:00:18.425895: step 2181, loss 0.0803793, acc 0.984375
2020-02-08T03:00:18.540330: step 2182, loss 0.0484675, acc 0.96875
2020-02-08T03:00:18.657384: step 2183, loss 0.10415, acc 0.953125
2020-02-08T03:00:18.775537: step 2184, loss 0.0327063, acc 1
2020-02-08T03:00:18.891876: step 2185, loss 0.0189871, acc 1
2020-02-08T03:00:19.013428: step 2186, loss 0.0873152, acc 0.96875
2020-02-08T03:00:19.138531: step 2187, loss 0.0946627, acc 0.984375
2020-02-08T03:00:19.256506: step 2188, loss 0.0210882, acc 1
2020-02-08T03:00:19.371300: step 2189, loss 0.0495847, acc 0.96875
2020-02-08T03:00:19.487672: step 2190, loss 0.0346941, acc 0.984375
2020-02-08T03:00:19.605742: step 2191, loss 0.112581, acc 0.953125
2020-02-08T03:00:19.720800: step 2192, loss 0.0595492, acc 0.96875
2020-02-08T03:00:19.840866: step 2193, loss 0.0578418, acc 0.984375
2020-02-08T03:00:19.959291: step 2194, loss 0.0453232, acc 1
2020-02-08T03:00:20.075077: step 2195, loss 0.018071, acc 1
2020-02-08T03:00:20.193641: step 2196, loss 0.0501195, acc 0.984375
2020-02-08T03:00:20.309371: step 2197, loss 0.0598008, acc 0.984375
2020-02-08T03:00:20.427314: step 2198, loss 0.0295558, acc 1
2020-02-08T03:00:20.547120: step 2199, loss 0.0483979, acc 0.984375
2020-02-08T03:00:20.665793: step 2200, loss 0.0535072, acc 0.984375

Evaluation:
2020-02-08T03:00:20.858057: step 2200, loss 0.793294, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2200

2020-02-08T03:00:23.630460: step 2201, loss 0.0296704, acc 0.984375
2020-02-08T03:00:23.749080: step 2202, loss 0.0399337, acc 0.96875
2020-02-08T03:00:23.868344: step 2203, loss 0.0957485, acc 0.96875
2020-02-08T03:00:24.155096: step 2204, loss 0.0864221, acc 0.96875
2020-02-08T03:00:24.280236: step 2205, loss 0.0490112, acc 0.984375
2020-02-08T03:00:24.398531: step 2206, loss 0.0532796, acc 0.96875
2020-02-08T03:00:24.516714: step 2207, loss 0.0703151, acc 0.984375
2020-02-08T03:00:24.630700: step 2208, loss 0.0455945, acc 0.984375
2020-02-08T03:00:24.750462: step 2209, loss 0.153795, acc 0.921875
2020-02-08T03:00:24.866222: step 2210, loss 0.0897523, acc 0.96875
2020-02-08T03:00:24.981616: step 2211, loss 0.0366795, acc 0.984375
2020-02-08T03:00:25.098562: step 2212, loss 0.0715661, acc 0.96875
2020-02-08T03:00:25.213896: step 2213, loss 0.0676311, acc 0.984375
2020-02-08T03:00:25.329806: step 2214, loss 0.0327067, acc 1
2020-02-08T03:00:25.446806: step 2215, loss 0.0347341, acc 1
2020-02-08T03:00:25.562805: step 2216, loss 0.0236037, acc 1
2020-02-08T03:00:25.678367: step 2217, loss 0.0307955, acc 1
2020-02-08T03:00:25.800084: step 2218, loss 0.0370431, acc 0.984375
2020-02-08T03:00:25.919729: step 2219, loss 0.0340353, acc 1
2020-02-08T03:00:26.032480: step 2220, loss 0.0574742, acc 0.984375
2020-02-08T03:00:26.150040: step 2221, loss 0.0734278, acc 0.96875
2020-02-08T03:00:26.265731: step 2222, loss 0.162775, acc 0.90625
2020-02-08T03:00:26.379489: step 2223, loss 0.0112495, acc 1
2020-02-08T03:00:26.496958: step 2224, loss 0.0796199, acc 0.96875
2020-02-08T03:00:26.613806: step 2225, loss 0.041616, acc 0.984375
2020-02-08T03:00:26.731730: step 2226, loss 0.0991742, acc 0.953125
2020-02-08T03:00:26.851406: step 2227, loss 0.172751, acc 0.9375
2020-02-08T03:00:26.968735: step 2228, loss 0.0569418, acc 0.984375
2020-02-08T03:00:27.092655: step 2229, loss 0.0254328, acc 1
2020-02-08T03:00:27.213169: step 2230, loss 0.0622801, acc 0.96875
2020-02-08T03:00:27.329250: step 2231, loss 0.0530667, acc 0.984375
2020-02-08T03:00:27.442391: step 2232, loss 0.0812912, acc 0.96875
2020-02-08T03:00:27.558648: step 2233, loss 0.0263425, acc 1
2020-02-08T03:00:27.674273: step 2234, loss 0.0391502, acc 0.984375
2020-02-08T03:00:27.791276: step 2235, loss 0.0383056, acc 1
2020-02-08T03:00:27.906254: step 2236, loss 0.0505886, acc 0.984375
2020-02-08T03:00:28.022859: step 2237, loss 0.0450167, acc 0.984375
2020-02-08T03:00:28.138799: step 2238, loss 0.0515611, acc 0.96875
2020-02-08T03:00:28.254671: step 2239, loss 0.0328036, acc 0.984375
2020-02-08T03:00:28.370979: step 2240, loss 0.0948323, acc 0.953125
2020-02-08T03:00:28.486938: step 2241, loss 0.0693798, acc 0.96875
2020-02-08T03:00:28.603246: step 2242, loss 0.0802254, acc 0.96875
2020-02-08T03:00:28.719838: step 2243, loss 0.0701313, acc 0.96875
2020-02-08T03:00:28.838435: step 2244, loss 0.0575947, acc 0.953125
2020-02-08T03:00:28.956763: step 2245, loss 0.0272946, acc 1
2020-02-08T03:00:29.074268: step 2246, loss 0.102885, acc 0.984375
2020-02-08T03:00:29.188305: step 2247, loss 0.0674393, acc 0.984375
2020-02-08T03:00:29.307535: step 2248, loss 0.0454002, acc 0.96875
2020-02-08T03:00:29.425795: step 2249, loss 0.0776349, acc 0.953125
2020-02-08T03:00:29.538789: step 2250, loss 0.096378, acc 0.966667
2020-02-08T03:00:29.659575: step 2251, loss 0.136047, acc 0.96875
2020-02-08T03:00:29.777737: step 2252, loss 0.020258, acc 1
2020-02-08T03:00:29.896069: step 2253, loss 0.0466717, acc 0.96875
2020-02-08T03:00:30.014330: step 2254, loss 0.0126829, acc 1
2020-02-08T03:00:30.130251: step 2255, loss 0.0151633, acc 1
2020-02-08T03:00:30.248156: step 2256, loss 0.0532832, acc 0.984375
2020-02-08T03:00:30.365990: step 2257, loss 0.018943, acc 1
2020-02-08T03:00:30.480310: step 2258, loss 0.047237, acc 0.96875
2020-02-08T03:00:30.597166: step 2259, loss 0.052883, acc 0.984375
2020-02-08T03:00:30.716587: step 2260, loss 0.0172265, acc 1
2020-02-08T03:00:30.836172: step 2261, loss 0.0509869, acc 0.96875
2020-02-08T03:00:30.954701: step 2262, loss 0.0490154, acc 0.984375
2020-02-08T03:00:31.078951: step 2263, loss 0.102498, acc 0.953125
2020-02-08T03:00:31.196181: step 2264, loss 0.0233478, acc 1
2020-02-08T03:00:31.310969: step 2265, loss 0.0254274, acc 0.984375
2020-02-08T03:00:31.425355: step 2266, loss 0.0382768, acc 0.984375
2020-02-08T03:00:31.540452: step 2267, loss 0.0261047, acc 0.984375
2020-02-08T03:00:31.656841: step 2268, loss 0.0645098, acc 0.96875
2020-02-08T03:00:31.773352: step 2269, loss 0.030818, acc 0.984375
2020-02-08T03:00:31.887861: step 2270, loss 0.0888628, acc 0.953125
2020-02-08T03:00:32.006960: step 2271, loss 0.0308727, acc 0.984375
2020-02-08T03:00:32.122504: step 2272, loss 0.0163948, acc 1
2020-02-08T03:00:32.239197: step 2273, loss 0.0712376, acc 0.953125
2020-02-08T03:00:32.358845: step 2274, loss 0.0476611, acc 0.984375
2020-02-08T03:00:32.474282: step 2275, loss 0.0315614, acc 0.984375
2020-02-08T03:00:32.592372: step 2276, loss 0.0414657, acc 0.984375
2020-02-08T03:00:32.708862: step 2277, loss 0.0177899, acc 1
2020-02-08T03:00:32.827413: step 2278, loss 0.0587987, acc 0.984375
2020-02-08T03:00:32.946576: step 2279, loss 0.0193235, acc 1
2020-02-08T03:00:33.063837: step 2280, loss 0.0310362, acc 1
2020-02-08T03:00:33.180504: step 2281, loss 0.0368851, acc 0.984375
2020-02-08T03:00:33.298601: step 2282, loss 0.0309949, acc 0.984375
2020-02-08T03:00:33.416697: step 2283, loss 0.0392092, acc 1
2020-02-08T03:00:33.531596: step 2284, loss 0.0150103, acc 1
2020-02-08T03:00:33.649855: step 2285, loss 0.0205355, acc 1
2020-02-08T03:00:33.768762: step 2286, loss 0.0822219, acc 0.953125
2020-02-08T03:00:33.885243: step 2287, loss 0.0282589, acc 1
2020-02-08T03:00:34.002878: step 2288, loss 0.0100694, acc 1
2020-02-08T03:00:34.119927: step 2289, loss 0.026602, acc 1
2020-02-08T03:00:34.233679: step 2290, loss 0.0389968, acc 0.984375
2020-02-08T03:00:34.351532: step 2291, loss 0.0291953, acc 0.984375
2020-02-08T03:00:34.469526: step 2292, loss 0.0412219, acc 0.984375
2020-02-08T03:00:34.585339: step 2293, loss 0.00727092, acc 1
2020-02-08T03:00:34.704277: step 2294, loss 0.0231531, acc 1
2020-02-08T03:00:34.823449: step 2295, loss 0.0603603, acc 0.96875
2020-02-08T03:00:34.939590: step 2296, loss 0.0336243, acc 1
2020-02-08T03:00:35.055897: step 2297, loss 0.0161098, acc 1
2020-02-08T03:00:35.177844: step 2298, loss 0.0610461, acc 0.96875
2020-02-08T03:00:35.292609: step 2299, loss 0.0390331, acc 0.984375
2020-02-08T03:00:35.409941: step 2300, loss 0.0296239, acc 1

Evaluation:
2020-02-08T03:00:35.602727: step 2300, loss 0.849393, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2300

2020-02-08T03:00:37.430083: step 2301, loss 0.0601714, acc 0.984375
2020-02-08T03:00:37.548345: step 2302, loss 0.0659265, acc 0.984375
2020-02-08T03:00:37.665577: step 2303, loss 0.0349736, acc 0.984375
2020-02-08T03:00:37.781944: step 2304, loss 0.0193129, acc 1
2020-02-08T03:00:37.899782: step 2305, loss 0.0150757, acc 1
2020-02-08T03:00:38.020867: step 2306, loss 0.0687182, acc 0.96875
2020-02-08T03:00:38.136961: step 2307, loss 0.0350993, acc 0.984375
2020-02-08T03:00:38.254540: step 2308, loss 0.0415486, acc 0.96875
2020-02-08T03:00:38.370707: step 2309, loss 0.0265002, acc 1
2020-02-08T03:00:38.486145: step 2310, loss 0.0297775, acc 0.984375
2020-02-08T03:00:38.602837: step 2311, loss 0.0142099, acc 1
2020-02-08T03:00:38.720307: step 2312, loss 0.0220869, acc 1
2020-02-08T03:00:38.841363: step 2313, loss 0.051036, acc 0.984375
2020-02-08T03:00:38.959182: step 2314, loss 0.0799129, acc 0.96875
2020-02-08T03:00:39.078374: step 2315, loss 0.0233221, acc 1
2020-02-08T03:00:39.194780: step 2316, loss 0.0816096, acc 0.96875
2020-02-08T03:00:39.311939: step 2317, loss 0.0431525, acc 0.984375
2020-02-08T03:00:39.428495: step 2318, loss 0.0252475, acc 1
2020-02-08T03:00:39.543235: step 2319, loss 0.0805438, acc 0.96875
2020-02-08T03:00:39.660107: step 2320, loss 0.0675089, acc 0.984375
2020-02-08T03:00:39.778338: step 2321, loss 0.0208392, acc 1
2020-02-08T03:00:39.895161: step 2322, loss 0.088704, acc 0.96875
2020-02-08T03:00:40.010976: step 2323, loss 0.0891909, acc 0.96875
2020-02-08T03:00:40.127119: step 2324, loss 0.0360815, acc 0.984375
2020-02-08T03:00:40.254317: step 2325, loss 0.0226905, acc 1
2020-02-08T03:00:40.372817: step 2326, loss 0.0455177, acc 0.984375
2020-02-08T03:00:40.489508: step 2327, loss 0.0216556, acc 1
2020-02-08T03:00:40.606383: step 2328, loss 0.0327944, acc 1
2020-02-08T03:00:40.723803: step 2329, loss 0.102386, acc 0.984375
2020-02-08T03:00:40.845869: step 2330, loss 0.0784705, acc 0.96875
2020-02-08T03:00:40.964265: step 2331, loss 0.0104152, acc 1
2020-02-08T03:00:41.078322: step 2332, loss 0.0234055, acc 1
2020-02-08T03:00:41.190581: step 2333, loss 0.043021, acc 0.984375
2020-02-08T03:00:41.306476: step 2334, loss 0.0297682, acc 1
2020-02-08T03:00:41.421878: step 2335, loss 0.117567, acc 0.953125
2020-02-08T03:00:41.539357: step 2336, loss 0.034072, acc 0.984375
2020-02-08T03:00:41.656166: step 2337, loss 0.0386595, acc 0.96875
2020-02-08T03:00:41.773897: step 2338, loss 0.0627297, acc 0.984375
2020-02-08T03:00:41.891032: step 2339, loss 0.0541469, acc 0.984375
2020-02-08T03:00:42.007166: step 2340, loss 0.0926701, acc 0.96875
2020-02-08T03:00:42.122883: step 2341, loss 0.0952712, acc 0.9375
2020-02-08T03:00:42.235004: step 2342, loss 0.0302221, acc 1
2020-02-08T03:00:42.350284: step 2343, loss 0.055154, acc 0.984375
2020-02-08T03:00:42.467101: step 2344, loss 0.00996814, acc 1
2020-02-08T03:00:42.583210: step 2345, loss 0.0168408, acc 1
2020-02-08T03:00:42.700920: step 2346, loss 0.0694687, acc 0.96875
2020-02-08T03:00:42.822788: step 2347, loss 0.0280803, acc 0.984375
2020-02-08T03:00:42.940739: step 2348, loss 0.0619396, acc 0.96875
2020-02-08T03:00:43.058801: step 2349, loss 0.0698201, acc 0.984375
2020-02-08T03:00:43.176716: step 2350, loss 0.0353434, acc 0.984375
2020-02-08T03:00:43.295038: step 2351, loss 0.0517871, acc 0.984375
2020-02-08T03:00:43.411578: step 2352, loss 0.08325, acc 0.96875
2020-02-08T03:00:43.528655: step 2353, loss 0.072702, acc 0.96875
2020-02-08T03:00:43.644901: step 2354, loss 0.0234328, acc 1
2020-02-08T03:00:43.765881: step 2355, loss 0.0209314, acc 1
2020-02-08T03:00:43.880940: step 2356, loss 0.0357839, acc 0.984375
2020-02-08T03:00:43.997516: step 2357, loss 0.0198649, acc 1
2020-02-08T03:00:44.115982: step 2358, loss 0.0473513, acc 0.984375
2020-02-08T03:00:44.232797: step 2359, loss 0.0158799, acc 1
2020-02-08T03:00:44.351342: step 2360, loss 0.0592829, acc 0.96875
2020-02-08T03:00:44.467168: step 2361, loss 0.0374263, acc 0.984375
2020-02-08T03:00:44.580673: step 2362, loss 0.0281249, acc 1
2020-02-08T03:00:44.700715: step 2363, loss 0.0842652, acc 0.984375
2020-02-08T03:00:44.830624: step 2364, loss 0.0313054, acc 1
2020-02-08T03:00:44.949121: step 2365, loss 0.0282588, acc 1
2020-02-08T03:00:45.068621: step 2366, loss 0.0185325, acc 1
2020-02-08T03:00:45.185131: step 2367, loss 0.0462564, acc 0.96875
2020-02-08T03:00:45.300760: step 2368, loss 0.0295682, acc 0.984375
2020-02-08T03:00:45.419770: step 2369, loss 0.0460662, acc 0.96875
2020-02-08T03:00:45.536523: step 2370, loss 0.0820561, acc 0.96875
2020-02-08T03:00:45.652691: step 2371, loss 0.0501569, acc 0.984375
2020-02-08T03:00:45.769830: step 2372, loss 0.0254256, acc 1
2020-02-08T03:00:45.886606: step 2373, loss 0.0660779, acc 0.984375
2020-02-08T03:00:46.004866: step 2374, loss 0.0174537, acc 1
2020-02-08T03:00:46.120494: step 2375, loss 0.0510899, acc 0.984375
2020-02-08T03:00:46.234159: step 2376, loss 0.0347086, acc 1
2020-02-08T03:00:46.350795: step 2377, loss 0.0723502, acc 0.96875
2020-02-08T03:00:46.464972: step 2378, loss 0.0278955, acc 1
2020-02-08T03:00:46.580190: step 2379, loss 0.00516881, acc 1
2020-02-08T03:00:46.695979: step 2380, loss 0.0350286, acc 0.984375
2020-02-08T03:00:46.819322: step 2381, loss 0.0355453, acc 1
2020-02-08T03:00:46.936307: step 2382, loss 0.0109637, acc 1
2020-02-08T03:00:47.051588: step 2383, loss 0.0313701, acc 1
2020-02-08T03:00:47.168339: step 2384, loss 0.163941, acc 0.9375
2020-02-08T03:00:47.282172: step 2385, loss 0.0333389, acc 0.984375
2020-02-08T03:00:47.399147: step 2386, loss 0.0500802, acc 0.984375
2020-02-08T03:00:47.515815: step 2387, loss 0.0444639, acc 0.984375
2020-02-08T03:00:47.631406: step 2388, loss 0.0419305, acc 1
2020-02-08T03:00:47.750768: step 2389, loss 0.0530296, acc 0.984375
2020-02-08T03:00:47.869002: step 2390, loss 0.0536099, acc 0.984375
2020-02-08T03:00:47.987211: step 2391, loss 0.0788534, acc 0.9375
2020-02-08T03:00:48.115613: step 2392, loss 0.0481555, acc 0.984375
2020-02-08T03:00:48.233392: step 2393, loss 0.0602534, acc 0.984375
2020-02-08T03:00:48.351088: step 2394, loss 0.0591453, acc 0.96875
2020-02-08T03:00:48.466963: step 2395, loss 0.0191423, acc 1
2020-02-08T03:00:48.585797: step 2396, loss 0.0397271, acc 1
2020-02-08T03:00:48.702478: step 2397, loss 0.117209, acc 0.96875
2020-02-08T03:00:48.823167: step 2398, loss 0.137722, acc 0.9375
2020-02-08T03:00:48.938525: step 2399, loss 0.0142514, acc 1
2020-02-08T03:00:49.051944: step 2400, loss 0.0451525, acc 0.983333

Evaluation:
2020-02-08T03:00:49.240109: step 2400, loss 0.872156, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2400

2020-02-08T03:00:50.864407: step 2401, loss 0.0258771, acc 1
2020-02-08T03:00:50.979736: step 2402, loss 0.0115477, acc 1
2020-02-08T03:00:51.096556: step 2403, loss 0.0499755, acc 0.984375
2020-02-08T03:00:51.215833: step 2404, loss 0.0290477, acc 0.984375
2020-02-08T03:00:52.158672: step 2405, loss 0.0289272, acc 1
2020-02-08T03:00:52.285573: step 2406, loss 0.0466138, acc 0.984375
2020-02-08T03:00:52.402093: step 2407, loss 0.0554738, acc 0.96875
2020-02-08T03:00:52.519416: step 2408, loss 0.00691632, acc 1
2020-02-08T03:00:52.634449: step 2409, loss 0.121877, acc 0.984375
2020-02-08T03:00:52.754193: step 2410, loss 0.0362069, acc 0.984375
2020-02-08T03:00:52.870542: step 2411, loss 0.120719, acc 0.984375
2020-02-08T03:00:52.984293: step 2412, loss 0.0296088, acc 0.984375
2020-02-08T03:00:53.109558: step 2413, loss 0.0303642, acc 1
2020-02-08T03:00:53.226820: step 2414, loss 0.0237096, acc 1
2020-02-08T03:00:53.345493: step 2415, loss 0.0185161, acc 1
2020-02-08T03:00:53.464323: step 2416, loss 0.0963347, acc 0.96875
2020-02-08T03:00:53.580969: step 2417, loss 0.0177118, acc 1
2020-02-08T03:00:53.698567: step 2418, loss 0.00939685, acc 1
2020-02-08T03:00:53.820097: step 2419, loss 0.0795331, acc 0.984375
2020-02-08T03:00:53.933816: step 2420, loss 0.0468904, acc 0.984375
2020-02-08T03:00:54.051172: step 2421, loss 0.0378082, acc 0.984375
2020-02-08T03:00:54.168765: step 2422, loss 0.0337626, acc 0.984375
2020-02-08T03:00:54.281954: step 2423, loss 0.0181353, acc 0.984375
2020-02-08T03:00:54.398009: step 2424, loss 0.0803478, acc 0.96875
2020-02-08T03:00:54.514091: step 2425, loss 0.0570608, acc 0.984375
2020-02-08T03:00:54.630185: step 2426, loss 0.0143607, acc 1
2020-02-08T03:00:54.748273: step 2427, loss 0.0759508, acc 0.984375
2020-02-08T03:00:54.867754: step 2428, loss 0.0240835, acc 1
2020-02-08T03:00:54.983565: step 2429, loss 0.0977937, acc 0.96875
2020-02-08T03:00:55.102457: step 2430, loss 0.0211067, acc 0.984375
2020-02-08T03:00:55.217655: step 2431, loss 0.0139013, acc 1
2020-02-08T03:00:55.333227: step 2432, loss 0.0126329, acc 1
2020-02-08T03:00:55.450116: step 2433, loss 0.0429957, acc 0.984375
2020-02-08T03:00:55.568014: step 2434, loss 0.0594357, acc 0.96875
2020-02-08T03:00:55.682800: step 2435, loss 0.0387073, acc 0.984375
2020-02-08T03:00:55.804644: step 2436, loss 0.019214, acc 1
2020-02-08T03:00:55.921141: step 2437, loss 0.0135403, acc 1
2020-02-08T03:00:56.041070: step 2438, loss 0.0406016, acc 0.96875
2020-02-08T03:00:56.156590: step 2439, loss 0.0310464, acc 0.984375
2020-02-08T03:00:56.273382: step 2440, loss 0.0121333, acc 1
2020-02-08T03:00:56.390902: step 2441, loss 0.0449164, acc 0.96875
2020-02-08T03:00:56.508727: step 2442, loss 0.0213242, acc 1
2020-02-08T03:00:56.625855: step 2443, loss 0.0199444, acc 1
2020-02-08T03:00:56.742974: step 2444, loss 0.0296177, acc 0.984375
2020-02-08T03:00:56.860059: step 2445, loss 0.0709619, acc 0.984375
2020-02-08T03:00:56.975514: step 2446, loss 0.0202507, acc 1
2020-02-08T03:00:57.090176: step 2447, loss 0.0425866, acc 0.984375
2020-02-08T03:00:57.206931: step 2448, loss 0.0495049, acc 0.984375
2020-02-08T03:00:57.322242: step 2449, loss 0.0148244, acc 1
2020-02-08T03:00:57.435810: step 2450, loss 0.0187989, acc 1
2020-02-08T03:00:57.553350: step 2451, loss 0.0211915, acc 1
2020-02-08T03:00:57.672151: step 2452, loss 0.0314984, acc 1
2020-02-08T03:00:57.792399: step 2453, loss 0.00623265, acc 1
2020-02-08T03:00:57.909696: step 2454, loss 0.0127192, acc 1
2020-02-08T03:00:58.025582: step 2455, loss 0.0583981, acc 0.984375
2020-02-08T03:00:58.144462: step 2456, loss 0.0348962, acc 0.984375
2020-02-08T03:00:58.261573: step 2457, loss 0.0448177, acc 0.984375
2020-02-08T03:00:58.377852: step 2458, loss 0.0310616, acc 1
2020-02-08T03:00:58.494870: step 2459, loss 0.0258235, acc 1
2020-02-08T03:00:58.611528: step 2460, loss 0.0200757, acc 1
2020-02-08T03:00:58.726649: step 2461, loss 0.0703432, acc 0.96875
2020-02-08T03:00:58.849254: step 2462, loss 0.0138609, acc 1
2020-02-08T03:00:58.967570: step 2463, loss 0.0851765, acc 0.953125
2020-02-08T03:00:59.087078: step 2464, loss 0.0298386, acc 0.984375
2020-02-08T03:00:59.209116: step 2465, loss 0.0288156, acc 1
2020-02-08T03:00:59.325471: step 2466, loss 0.0749237, acc 0.984375
2020-02-08T03:00:59.442064: step 2467, loss 0.0176099, acc 1
2020-02-08T03:00:59.557426: step 2468, loss 0.0201221, acc 1
2020-02-08T03:00:59.674072: step 2469, loss 0.0149617, acc 1
2020-02-08T03:00:59.792452: step 2470, loss 0.026586, acc 1
2020-02-08T03:00:59.909259: step 2471, loss 0.0438252, acc 0.984375
2020-02-08T03:01:00.024913: step 2472, loss 0.0192209, acc 1
2020-02-08T03:01:00.141210: step 2473, loss 0.0100825, acc 1
2020-02-08T03:01:00.258622: step 2474, loss 0.021652, acc 1
2020-02-08T03:01:00.378080: step 2475, loss 0.0197685, acc 1
2020-02-08T03:01:00.495621: step 2476, loss 0.0178659, acc 1
2020-02-08T03:01:00.610803: step 2477, loss 0.0153878, acc 1
2020-02-08T03:01:00.725699: step 2478, loss 0.0452746, acc 0.984375
2020-02-08T03:01:00.848288: step 2479, loss 0.00612279, acc 1
2020-02-08T03:01:00.964214: step 2480, loss 0.0138652, acc 1
2020-02-08T03:01:01.083832: step 2481, loss 0.0301979, acc 0.984375
2020-02-08T03:01:01.203927: step 2482, loss 0.00935763, acc 1
2020-02-08T03:01:01.322896: step 2483, loss 0.0205335, acc 1
2020-02-08T03:01:01.438347: step 2484, loss 0.030533, acc 1
2020-02-08T03:01:01.554840: step 2485, loss 0.071286, acc 0.96875
2020-02-08T03:01:01.672898: step 2486, loss 0.0516672, acc 0.984375
2020-02-08T03:01:01.794288: step 2487, loss 0.0109557, acc 1
2020-02-08T03:01:01.910077: step 2488, loss 0.122327, acc 0.953125
2020-02-08T03:01:02.022656: step 2489, loss 0.0165254, acc 1
2020-02-08T03:01:02.137695: step 2490, loss 0.0247823, acc 0.984375
2020-02-08T03:01:02.253499: step 2491, loss 0.0310693, acc 1
2020-02-08T03:01:02.372958: step 2492, loss 0.0171243, acc 1
2020-02-08T03:01:02.489418: step 2493, loss 0.00798051, acc 1
2020-02-08T03:01:02.606781: step 2494, loss 0.0224812, acc 1
2020-02-08T03:01:02.723632: step 2495, loss 0.0213472, acc 1
2020-02-08T03:01:02.845506: step 2496, loss 0.0327892, acc 0.984375
2020-02-08T03:01:02.962333: step 2497, loss 0.0233527, acc 0.984375
2020-02-08T03:01:03.079978: step 2498, loss 0.0721666, acc 0.96875
2020-02-08T03:01:03.196991: step 2499, loss 0.0120967, acc 1
2020-02-08T03:01:03.315360: step 2500, loss 0.052106, acc 0.953125

Evaluation:
2020-02-08T03:01:03.506125: step 2500, loss 0.898624, acc 0.732645

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2500

2020-02-08T03:01:06.042912: step 2501, loss 0.0241049, acc 1
2020-02-08T03:01:06.159979: step 2502, loss 0.0570786, acc 0.984375
2020-02-08T03:01:06.274116: step 2503, loss 0.0158286, acc 1
2020-02-08T03:01:06.391170: step 2504, loss 0.0313888, acc 0.984375
2020-02-08T03:01:06.508922: step 2505, loss 0.041773, acc 0.984375
2020-02-08T03:01:06.624051: step 2506, loss 0.0149481, acc 1
2020-02-08T03:01:06.744707: step 2507, loss 0.0115483, acc 1
2020-02-08T03:01:06.862943: step 2508, loss 0.0288501, acc 1
2020-02-08T03:01:06.979330: step 2509, loss 0.0395041, acc 0.984375
2020-02-08T03:01:07.100432: step 2510, loss 0.00868758, acc 1
2020-02-08T03:01:07.219043: step 2511, loss 0.0153969, acc 1
2020-02-08T03:01:07.333899: step 2512, loss 0.0253387, acc 1
2020-02-08T03:01:07.447756: step 2513, loss 0.037584, acc 1
2020-02-08T03:01:07.564047: step 2514, loss 0.040116, acc 0.984375
2020-02-08T03:01:07.680893: step 2515, loss 0.0218197, acc 1
2020-02-08T03:01:07.800788: step 2516, loss 0.0322179, acc 0.984375
2020-02-08T03:01:07.917703: step 2517, loss 0.00906181, acc 1
2020-02-08T03:01:08.034309: step 2518, loss 0.0122306, acc 1
2020-02-08T03:01:08.149892: step 2519, loss 0.023624, acc 1
2020-02-08T03:01:08.264180: step 2520, loss 0.0475008, acc 0.96875
2020-02-08T03:01:08.378344: step 2521, loss 0.0166028, acc 1
2020-02-08T03:01:08.496960: step 2522, loss 0.0371795, acc 0.984375
2020-02-08T03:01:08.614265: step 2523, loss 0.00972574, acc 1
2020-02-08T03:01:08.729224: step 2524, loss 0.0544328, acc 0.96875
2020-02-08T03:01:08.850413: step 2525, loss 0.0352469, acc 1
2020-02-08T03:01:08.966859: step 2526, loss 0.013876, acc 1
2020-02-08T03:01:09.083345: step 2527, loss 0.022865, acc 1
2020-02-08T03:01:09.200370: step 2528, loss 0.0320905, acc 0.984375
2020-02-08T03:01:09.319389: step 2529, loss 0.0395288, acc 0.984375
2020-02-08T03:01:09.435998: step 2530, loss 0.0216494, acc 1
2020-02-08T03:01:09.554632: step 2531, loss 0.0124958, acc 1
2020-02-08T03:01:09.669523: step 2532, loss 0.018039, acc 1
2020-02-08T03:01:09.788758: step 2533, loss 0.0286425, acc 0.984375
2020-02-08T03:01:09.906255: step 2534, loss 0.0742146, acc 0.984375
2020-02-08T03:01:10.025423: step 2535, loss 0.0215382, acc 0.984375
2020-02-08T03:01:10.141230: step 2536, loss 0.018019, acc 1
2020-02-08T03:01:10.259448: step 2537, loss 0.0231034, acc 1
2020-02-08T03:01:10.377450: step 2538, loss 0.00943347, acc 1
2020-02-08T03:01:10.494503: step 2539, loss 0.0232636, acc 1
2020-02-08T03:01:10.609537: step 2540, loss 0.0383218, acc 0.96875
2020-02-08T03:01:10.725063: step 2541, loss 0.055717, acc 0.96875
2020-02-08T03:01:10.843596: step 2542, loss 0.0405575, acc 0.984375
2020-02-08T03:01:10.959462: step 2543, loss 0.0159728, acc 1
2020-02-08T03:01:11.075104: step 2544, loss 0.0323181, acc 0.984375
2020-02-08T03:01:11.190035: step 2545, loss 0.0213779, acc 1
2020-02-08T03:01:11.307718: step 2546, loss 0.0263139, acc 1
2020-02-08T03:01:11.426832: step 2547, loss 0.0324175, acc 0.984375
2020-02-08T03:01:11.546451: step 2548, loss 0.0163026, acc 1
2020-02-08T03:01:11.663662: step 2549, loss 0.0161173, acc 1
2020-02-08T03:01:11.777555: step 2550, loss 0.0162938, acc 1
2020-02-08T03:01:11.895953: step 2551, loss 0.0228235, acc 1
2020-02-08T03:01:12.011855: step 2552, loss 0.0545322, acc 0.96875
2020-02-08T03:01:12.126633: step 2553, loss 0.0131467, acc 1
2020-02-08T03:01:12.239572: step 2554, loss 0.0197701, acc 1
2020-02-08T03:01:12.356818: step 2555, loss 0.0533247, acc 0.96875
2020-02-08T03:01:12.474212: step 2556, loss 0.0507515, acc 0.984375
2020-02-08T03:01:12.589776: step 2557, loss 0.0182416, acc 1
2020-02-08T03:01:12.708130: step 2558, loss 0.0524242, acc 0.984375
2020-02-08T03:01:12.827063: step 2559, loss 0.0523386, acc 0.984375
2020-02-08T03:01:12.945052: step 2560, loss 0.0173491, acc 0.984375
2020-02-08T03:01:13.065818: step 2561, loss 0.0658546, acc 0.96875
2020-02-08T03:01:13.181969: step 2562, loss 0.0345478, acc 0.984375
2020-02-08T03:01:13.295943: step 2563, loss 0.0748893, acc 0.96875
2020-02-08T03:01:13.415461: step 2564, loss 0.0334285, acc 0.984375
2020-02-08T03:01:13.529715: step 2565, loss 0.0428683, acc 0.984375
2020-02-08T03:01:13.646986: step 2566, loss 0.0108334, acc 1
2020-02-08T03:01:13.764273: step 2567, loss 0.0238177, acc 1
2020-02-08T03:01:13.879933: step 2568, loss 0.0320262, acc 1
2020-02-08T03:01:13.997523: step 2569, loss 0.020113, acc 1
2020-02-08T03:01:14.115063: step 2570, loss 0.00749612, acc 1
2020-02-08T03:01:14.229452: step 2571, loss 0.0150311, acc 1
2020-02-08T03:01:14.350740: step 2572, loss 0.0213521, acc 1
2020-02-08T03:01:14.468455: step 2573, loss 0.0896436, acc 0.953125
2020-02-08T03:01:14.583105: step 2574, loss 0.032474, acc 0.984375
2020-02-08T03:01:14.700558: step 2575, loss 0.0212488, acc 1
2020-02-08T03:01:14.822903: step 2576, loss 0.0280718, acc 0.984375
2020-02-08T03:01:14.936386: step 2577, loss 0.0123941, acc 1
2020-02-08T03:01:15.053751: step 2578, loss 0.0328398, acc 0.984375
2020-02-08T03:01:15.169982: step 2579, loss 0.0138009, acc 1
2020-02-08T03:01:15.283854: step 2580, loss 0.00818116, acc 1
2020-02-08T03:01:15.402350: step 2581, loss 0.0078012, acc 1
2020-02-08T03:01:15.519217: step 2582, loss 0.0262994, acc 0.984375
2020-02-08T03:01:15.634776: step 2583, loss 0.0401262, acc 0.984375
2020-02-08T03:01:15.753735: step 2584, loss 0.0197826, acc 1
2020-02-08T03:01:15.868435: step 2585, loss 0.0425292, acc 0.96875
2020-02-08T03:01:15.983097: step 2586, loss 0.0330684, acc 0.984375
2020-02-08T03:01:16.100422: step 2587, loss 0.0152185, acc 1
2020-02-08T03:01:16.215460: step 2588, loss 0.0191075, acc 1
2020-02-08T03:01:16.329017: step 2589, loss 0.0100191, acc 1
2020-02-08T03:01:16.445267: step 2590, loss 0.0376357, acc 0.984375
2020-02-08T03:01:16.561318: step 2591, loss 0.0289479, acc 0.984375
2020-02-08T03:01:16.677411: step 2592, loss 0.042426, acc 0.984375
2020-02-08T03:01:16.798117: step 2593, loss 0.0186778, acc 1
2020-02-08T03:01:16.917199: step 2594, loss 0.0482667, acc 0.96875
2020-02-08T03:01:17.032279: step 2595, loss 0.0134271, acc 1
2020-02-08T03:01:17.148386: step 2596, loss 0.00932003, acc 1
2020-02-08T03:01:17.262880: step 2597, loss 0.0658588, acc 0.953125
2020-02-08T03:01:17.377751: step 2598, loss 0.044986, acc 0.984375
2020-02-08T03:01:17.491037: step 2599, loss 0.0319296, acc 1
2020-02-08T03:01:17.608067: step 2600, loss 0.00482892, acc 1

Evaluation:
2020-02-08T03:01:17.796923: step 2600, loss 0.964972, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2600

2020-02-08T03:01:19.624297: step 2601, loss 0.0124178, acc 1
2020-02-08T03:01:19.741998: step 2602, loss 0.0229971, acc 0.984375
2020-02-08T03:01:19.858488: step 2603, loss 0.067149, acc 0.96875
2020-02-08T03:01:19.976113: step 2604, loss 0.0225541, acc 1
2020-02-08T03:01:20.093585: step 2605, loss 0.0328398, acc 0.984375
2020-02-08T03:01:20.212094: step 2606, loss 0.0418325, acc 0.984375
2020-02-08T03:01:20.328618: step 2607, loss 0.00992817, acc 1
2020-02-08T03:01:20.445256: step 2608, loss 0.0133429, acc 1
2020-02-08T03:01:20.559933: step 2609, loss 0.00860023, acc 1
2020-02-08T03:01:20.675598: step 2610, loss 0.0148176, acc 1
2020-02-08T03:01:20.796742: step 2611, loss 0.010484, acc 1
2020-02-08T03:01:20.912375: step 2612, loss 0.053269, acc 0.96875
2020-02-08T03:01:21.027857: step 2613, loss 0.0113617, acc 1
2020-02-08T03:01:21.145069: step 2614, loss 0.0906209, acc 0.96875
2020-02-08T03:01:21.262646: step 2615, loss 0.0306321, acc 0.984375
2020-02-08T03:01:21.383372: step 2616, loss 0.0411211, acc 0.984375
2020-02-08T03:01:21.498550: step 2617, loss 0.0227041, acc 1
2020-02-08T03:01:21.614288: step 2618, loss 0.0411387, acc 0.984375
2020-02-08T03:01:21.746954: step 2619, loss 0.0132749, acc 1
2020-02-08T03:01:21.884645: step 2620, loss 0.0189222, acc 1
2020-02-08T03:01:22.000530: step 2621, loss 0.038461, acc 0.96875
2020-02-08T03:01:22.115445: step 2622, loss 0.00494235, acc 1
2020-02-08T03:01:22.231293: step 2623, loss 0.026358, acc 0.984375
2020-02-08T03:01:22.347962: step 2624, loss 0.0762301, acc 0.96875
2020-02-08T03:01:22.464561: step 2625, loss 0.0124391, acc 1
2020-02-08T03:01:22.581074: step 2626, loss 0.0232601, acc 1
2020-02-08T03:01:22.695919: step 2627, loss 0.00336359, acc 1
2020-02-08T03:01:22.817479: step 2628, loss 0.00778168, acc 1
2020-02-08T03:01:22.935065: step 2629, loss 0.022166, acc 0.984375
2020-02-08T03:01:23.053733: step 2630, loss 0.0496465, acc 0.984375
2020-02-08T03:01:23.169828: step 2631, loss 0.0179089, acc 0.984375
2020-02-08T03:01:23.285951: step 2632, loss 0.0597747, acc 0.96875
2020-02-08T03:01:23.403235: step 2633, loss 0.0230602, acc 1
2020-02-08T03:01:23.518660: step 2634, loss 0.0355126, acc 0.96875
2020-02-08T03:01:23.633679: step 2635, loss 0.0239661, acc 1
2020-02-08T03:01:23.749541: step 2636, loss 0.0628176, acc 0.984375
2020-02-08T03:01:23.862683: step 2637, loss 0.015399, acc 1
2020-02-08T03:01:23.978243: step 2638, loss 0.010315, acc 1
2020-02-08T03:01:24.093968: step 2639, loss 0.00625333, acc 1
2020-02-08T03:01:24.210192: step 2640, loss 0.0182271, acc 1
2020-02-08T03:01:24.325819: step 2641, loss 0.056471, acc 0.984375
2020-02-08T03:01:24.443726: step 2642, loss 0.0096042, acc 1
2020-02-08T03:01:24.562552: step 2643, loss 0.033305, acc 0.984375
2020-02-08T03:01:24.682786: step 2644, loss 0.128397, acc 0.953125
2020-02-08T03:01:24.803576: step 2645, loss 0.044309, acc 0.984375
2020-02-08T03:01:24.919495: step 2646, loss 0.055137, acc 0.96875
2020-02-08T03:01:25.035278: step 2647, loss 0.0165677, acc 1
2020-02-08T03:01:25.153155: step 2648, loss 0.00873292, acc 1
2020-02-08T03:01:25.267120: step 2649, loss 0.021167, acc 0.984375
2020-02-08T03:01:25.382211: step 2650, loss 0.0403315, acc 0.96875
2020-02-08T03:01:25.497399: step 2651, loss 0.0248749, acc 1
2020-02-08T03:01:25.615659: step 2652, loss 0.0279654, acc 1
2020-02-08T03:01:25.734087: step 2653, loss 0.0536086, acc 0.96875
2020-02-08T03:01:25.852001: step 2654, loss 0.0131549, acc 1
2020-02-08T03:01:25.968232: step 2655, loss 0.00772379, acc 1
2020-02-08T03:01:26.083402: step 2656, loss 0.0139448, acc 1
2020-02-08T03:01:26.203348: step 2657, loss 0.0123748, acc 1
2020-02-08T03:01:26.319229: step 2658, loss 0.0188435, acc 1
2020-02-08T03:01:26.435561: step 2659, loss 0.0236534, acc 1
2020-02-08T03:01:26.552322: step 2660, loss 0.0060266, acc 1
2020-02-08T03:01:26.669204: step 2661, loss 0.0221462, acc 1
2020-02-08T03:01:26.789956: step 2662, loss 0.0165418, acc 1
2020-02-08T03:01:26.903091: step 2663, loss 0.0818243, acc 0.984375
2020-02-08T03:01:27.017631: step 2664, loss 0.00959307, acc 1
2020-02-08T03:01:27.133931: step 2665, loss 0.120056, acc 0.96875
2020-02-08T03:01:27.252105: step 2666, loss 0.0346456, acc 1
2020-02-08T03:01:27.367561: step 2667, loss 0.0100337, acc 1
2020-02-08T03:01:27.482704: step 2668, loss 0.0487233, acc 0.984375
2020-02-08T03:01:27.601065: step 2669, loss 0.0406176, acc 0.96875
2020-02-08T03:01:27.719172: step 2670, loss 0.0174534, acc 1
2020-02-08T03:01:27.843530: step 2671, loss 0.00711133, acc 1
2020-02-08T03:01:27.966352: step 2672, loss 0.0706736, acc 0.984375
2020-02-08T03:01:28.083377: step 2673, loss 0.0111966, acc 1
2020-02-08T03:01:28.202401: step 2674, loss 0.087636, acc 0.984375
2020-02-08T03:01:28.321649: step 2675, loss 0.0218022, acc 1
2020-02-08T03:01:28.436407: step 2676, loss 0.0102904, acc 1
2020-02-08T03:01:28.554580: step 2677, loss 0.0255192, acc 0.984375
2020-02-08T03:01:28.672089: step 2678, loss 0.0266801, acc 1
2020-02-08T03:01:28.790035: step 2679, loss 0.0600398, acc 0.984375
2020-02-08T03:01:28.909126: step 2680, loss 0.0187022, acc 1
2020-02-08T03:01:29.025917: step 2681, loss 0.0347692, acc 0.96875
2020-02-08T03:01:29.139681: step 2682, loss 0.0217837, acc 1
2020-02-08T03:01:29.255637: step 2683, loss 0.0179253, acc 1
2020-02-08T03:01:29.369647: step 2684, loss 0.00872727, acc 1
2020-02-08T03:01:29.484397: step 2685, loss 0.0319893, acc 0.984375
2020-02-08T03:01:29.600641: step 2686, loss 0.0272579, acc 0.984375
2020-02-08T03:01:29.717690: step 2687, loss 0.068097, acc 0.984375
2020-02-08T03:01:29.838683: step 2688, loss 0.0115946, acc 1
2020-02-08T03:01:29.954024: step 2689, loss 0.0109456, acc 1
2020-02-08T03:01:30.069637: step 2690, loss 0.00815063, acc 1
2020-02-08T03:01:30.186128: step 2691, loss 0.0181354, acc 1
2020-02-08T03:01:30.301650: step 2692, loss 0.0517742, acc 1
2020-02-08T03:01:30.417758: step 2693, loss 0.0555091, acc 0.984375
2020-02-08T03:01:30.532886: step 2694, loss 0.012953, acc 1
2020-02-08T03:01:30.649210: step 2695, loss 0.0444685, acc 0.984375
2020-02-08T03:01:30.766826: step 2696, loss 0.0131521, acc 1
2020-02-08T03:01:30.883354: step 2697, loss 0.0304116, acc 0.984375
2020-02-08T03:01:30.998862: step 2698, loss 0.0390816, acc 1
2020-02-08T03:01:31.114266: step 2699, loss 0.0707054, acc 0.984375
2020-02-08T03:01:31.228364: step 2700, loss 0.0144599, acc 1

Evaluation:
2020-02-08T03:01:31.418519: step 2700, loss 0.964064, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2700

2020-02-08T03:01:33.459203: step 2701, loss 0.0500906, acc 0.984375
2020-02-08T03:01:33.577095: step 2702, loss 0.0131803, acc 1
2020-02-08T03:01:33.690104: step 2703, loss 0.00582504, acc 1
2020-02-08T03:01:33.811107: step 2704, loss 0.0169938, acc 1
2020-02-08T03:01:33.926900: step 2705, loss 0.0131243, acc 1
2020-02-08T03:01:34.040954: step 2706, loss 0.014306, acc 1
2020-02-08T03:01:34.159402: step 2707, loss 0.0135287, acc 1
2020-02-08T03:01:34.277403: step 2708, loss 0.0200699, acc 1
2020-02-08T03:01:34.391368: step 2709, loss 0.00777739, acc 1
2020-02-08T03:01:34.511502: step 2710, loss 0.0276376, acc 1
2020-02-08T03:01:34.627194: step 2711, loss 0.0203623, acc 1
2020-02-08T03:01:34.743403: step 2712, loss 0.00640578, acc 1
2020-02-08T03:01:34.863999: step 2713, loss 0.0108005, acc 1
2020-02-08T03:01:34.980333: step 2714, loss 0.0274833, acc 1
2020-02-08T03:01:35.097549: step 2715, loss 0.0847849, acc 0.96875
2020-02-08T03:01:35.215038: step 2716, loss 0.0189309, acc 1
2020-02-08T03:01:35.331082: step 2717, loss 0.0190631, acc 1
2020-02-08T03:01:35.449672: step 2718, loss 0.0315463, acc 1
2020-02-08T03:01:35.567131: step 2719, loss 0.0122227, acc 1
2020-02-08T03:01:35.683902: step 2720, loss 0.0270921, acc 0.984375
2020-02-08T03:01:35.804634: step 2721, loss 0.0114433, acc 1
2020-02-08T03:01:35.921066: step 2722, loss 0.0301589, acc 0.984375
2020-02-08T03:01:36.036171: step 2723, loss 0.0220546, acc 0.984375
2020-02-08T03:01:36.153246: step 2724, loss 0.0120828, acc 1
2020-02-08T03:01:36.270984: step 2725, loss 0.0335242, acc 0.984375
2020-02-08T03:01:36.385527: step 2726, loss 0.00668069, acc 1
2020-02-08T03:01:36.502599: step 2727, loss 0.00474676, acc 1
2020-02-08T03:01:36.620010: step 2728, loss 0.012158, acc 1
2020-02-08T03:01:36.734183: step 2729, loss 0.0308803, acc 0.984375
2020-02-08T03:01:36.855997: step 2730, loss 0.0457392, acc 0.984375
2020-02-08T03:01:36.973143: step 2731, loss 0.0061482, acc 1
2020-02-08T03:01:37.087366: step 2732, loss 0.0323065, acc 0.984375
2020-02-08T03:01:37.203461: step 2733, loss 0.0069255, acc 1
2020-02-08T03:01:37.319837: step 2734, loss 0.0459729, acc 0.96875
2020-02-08T03:01:37.435395: step 2735, loss 0.012797, acc 1
2020-02-08T03:01:37.552108: step 2736, loss 0.00469716, acc 1
2020-02-08T03:01:37.668916: step 2737, loss 0.00287599, acc 1
2020-02-08T03:01:37.784947: step 2738, loss 0.0124915, acc 1
2020-02-08T03:01:37.902492: step 2739, loss 0.0248484, acc 0.984375
2020-02-08T03:01:38.020291: step 2740, loss 0.0339041, acc 0.984375
2020-02-08T03:01:38.135442: step 2741, loss 0.0174744, acc 1
2020-02-08T03:01:38.250369: step 2742, loss 0.0140361, acc 1
2020-02-08T03:01:38.368275: step 2743, loss 0.071102, acc 0.953125
2020-02-08T03:01:38.482941: step 2744, loss 0.00795853, acc 1
2020-02-08T03:01:38.600729: step 2745, loss 0.0352025, acc 0.984375
2020-02-08T03:01:38.717358: step 2746, loss 0.0204697, acc 1
2020-02-08T03:01:38.842129: step 2747, loss 0.0112739, acc 1
2020-02-08T03:01:38.958734: step 2748, loss 0.00940581, acc 1
2020-02-08T03:01:39.075967: step 2749, loss 0.00397762, acc 1
2020-02-08T03:01:39.190999: step 2750, loss 0.0304948, acc 0.984375
2020-02-08T03:01:39.305925: step 2751, loss 0.0130378, acc 1
2020-02-08T03:01:39.422080: step 2752, loss 0.0127512, acc 1
2020-02-08T03:01:39.536832: step 2753, loss 0.0112857, acc 1
2020-02-08T03:01:39.653190: step 2754, loss 0.0120194, acc 1
2020-02-08T03:01:39.768603: step 2755, loss 0.0370084, acc 0.984375
2020-02-08T03:01:39.883039: step 2756, loss 0.0311591, acc 1
2020-02-08T03:01:39.999992: step 2757, loss 0.0229945, acc 1
2020-02-08T03:01:40.116795: step 2758, loss 0.0060978, acc 1
2020-02-08T03:01:40.233121: step 2759, loss 0.0080827, acc 1
2020-02-08T03:01:40.347856: step 2760, loss 0.0176007, acc 1
2020-02-08T03:01:40.469296: step 2761, loss 0.0221779, acc 0.984375
2020-02-08T03:01:40.588118: step 2762, loss 0.00830672, acc 1
2020-02-08T03:01:40.705245: step 2763, loss 0.0374931, acc 0.984375
2020-02-08T03:01:40.826705: step 2764, loss 0.0275438, acc 1
2020-02-08T03:01:40.942748: step 2765, loss 0.00951703, acc 1
2020-02-08T03:01:41.062255: step 2766, loss 0.0319612, acc 0.984375
2020-02-08T03:01:41.176307: step 2767, loss 0.0129251, acc 1
2020-02-08T03:01:41.291971: step 2768, loss 0.057092, acc 0.984375
2020-02-08T03:01:41.407768: step 2769, loss 0.0192611, acc 1
2020-02-08T03:01:41.524596: step 2770, loss 0.019602, acc 1
2020-02-08T03:01:41.641970: step 2771, loss 0.0277972, acc 0.984375
2020-02-08T03:01:41.760695: step 2772, loss 0.00661761, acc 1
2020-02-08T03:01:41.876777: step 2773, loss 0.00499793, acc 1
2020-02-08T03:01:41.990651: step 2774, loss 0.0291756, acc 0.984375
2020-02-08T03:01:42.106611: step 2775, loss 0.0622212, acc 0.96875
2020-02-08T03:01:42.232513: step 2776, loss 0.0636717, acc 0.96875
2020-02-08T03:01:42.348514: step 2777, loss 0.0163388, acc 1
2020-02-08T03:01:42.465473: step 2778, loss 0.00774777, acc 1
2020-02-08T03:01:42.580159: step 2779, loss 0.00617015, acc 1
2020-02-08T03:01:42.694029: step 2780, loss 0.0204084, acc 1
2020-02-08T03:01:42.815572: step 2781, loss 0.0492305, acc 0.984375
2020-02-08T03:01:42.931245: step 2782, loss 0.0324154, acc 0.984375
2020-02-08T03:01:43.046944: step 2783, loss 0.0259409, acc 1
2020-02-08T03:01:43.164964: step 2784, loss 0.0177175, acc 1
2020-02-08T03:01:43.284258: step 2785, loss 0.0501055, acc 0.96875
2020-02-08T03:01:43.401705: step 2786, loss 0.0268474, acc 0.984375
2020-02-08T03:01:43.516878: step 2787, loss 0.0158129, acc 1
2020-02-08T03:01:43.633659: step 2788, loss 0.00417775, acc 1
2020-02-08T03:01:43.755503: step 2789, loss 0.0264879, acc 0.984375
2020-02-08T03:01:43.873886: step 2790, loss 0.0263748, acc 1
2020-02-08T03:01:43.991722: step 2791, loss 0.00672216, acc 1
2020-02-08T03:01:44.108447: step 2792, loss 0.0388211, acc 0.984375
2020-02-08T03:01:44.224277: step 2793, loss 0.0111967, acc 1
2020-02-08T03:01:44.338288: step 2794, loss 0.00263966, acc 1
2020-02-08T03:01:44.453528: step 2795, loss 0.00850555, acc 1
2020-02-08T03:01:44.569823: step 2796, loss 0.0286183, acc 0.984375
2020-02-08T03:01:44.684816: step 2797, loss 0.0142593, acc 1
2020-02-08T03:01:44.805521: step 2798, loss 0.0125126, acc 1
2020-02-08T03:01:44.923463: step 2799, loss 0.0604044, acc 0.984375
2020-02-08T03:01:45.036839: step 2800, loss 0.0132731, acc 1

Evaluation:
2020-02-08T03:01:45.221469: step 2800, loss 1.01268, acc 0.716698

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2800

2020-02-08T03:01:48.036572: step 2801, loss 0.0174846, acc 1
2020-02-08T03:01:48.154203: step 2802, loss 0.00416321, acc 1
2020-02-08T03:01:48.270800: step 2803, loss 0.0320643, acc 0.984375
2020-02-08T03:01:48.386984: step 2804, loss 0.0467435, acc 0.984375
2020-02-08T03:01:48.503290: step 2805, loss 0.0258297, acc 1
2020-02-08T03:01:48.619649: step 2806, loss 0.0264591, acc 0.984375
2020-02-08T03:01:48.734283: step 2807, loss 0.0191001, acc 1
2020-02-08T03:01:48.853374: step 2808, loss 0.0172065, acc 1
2020-02-08T03:01:48.970948: step 2809, loss 0.00752248, acc 1
2020-02-08T03:01:49.086517: step 2810, loss 0.0233389, acc 1
2020-02-08T03:01:49.202034: step 2811, loss 0.013585, acc 1
2020-02-08T03:01:49.317891: step 2812, loss 0.0156965, acc 1
2020-02-08T03:01:49.432238: step 2813, loss 0.00830531, acc 1
2020-02-08T03:01:49.547289: step 2814, loss 0.0151974, acc 1
2020-02-08T03:01:49.665335: step 2815, loss 0.0172833, acc 1
2020-02-08T03:01:49.782117: step 2816, loss 0.00900717, acc 1
2020-02-08T03:01:49.900705: step 2817, loss 0.0325582, acc 0.984375
2020-02-08T03:01:50.017521: step 2818, loss 0.0187255, acc 1
2020-02-08T03:01:50.132506: step 2819, loss 0.00933569, acc 1
2020-02-08T03:01:50.248643: step 2820, loss 0.0302905, acc 0.984375
2020-02-08T03:01:50.365316: step 2821, loss 0.0297953, acc 1
2020-02-08T03:01:50.481122: step 2822, loss 0.012501, acc 1
2020-02-08T03:01:50.598135: step 2823, loss 0.0211125, acc 1
2020-02-08T03:01:50.715196: step 2824, loss 0.0541284, acc 0.984375
2020-02-08T03:01:50.833768: step 2825, loss 0.0496627, acc 0.984375
2020-02-08T03:01:50.949790: step 2826, loss 0.00644469, acc 1
2020-02-08T03:01:51.064700: step 2827, loss 0.0121761, acc 1
2020-02-08T03:01:51.179666: step 2828, loss 0.0106197, acc 1
2020-02-08T03:01:51.302018: step 2829, loss 0.0301614, acc 0.984375
2020-02-08T03:01:51.420136: step 2830, loss 0.0970028, acc 0.96875
2020-02-08T03:01:51.535428: step 2831, loss 0.0137213, acc 1
2020-02-08T03:01:51.886997: step 2832, loss 0.0241403, acc 1
2020-02-08T03:01:52.012523: step 2833, loss 0.0233856, acc 0.984375
2020-02-08T03:01:52.127067: step 2834, loss 0.027905, acc 1
2020-02-08T03:01:52.243748: step 2835, loss 0.0220151, acc 0.984375
2020-02-08T03:01:52.359999: step 2836, loss 0.00658872, acc 1
2020-02-08T03:01:52.476573: step 2837, loss 0.0289119, acc 0.984375
2020-02-08T03:01:52.592230: step 2838, loss 0.0247055, acc 1
2020-02-08T03:01:52.707611: step 2839, loss 0.0161768, acc 1
2020-02-08T03:01:52.826297: step 2840, loss 0.0565398, acc 0.984375
2020-02-08T03:01:52.943931: step 2841, loss 0.00908851, acc 1
2020-02-08T03:01:53.061025: step 2842, loss 0.0233933, acc 0.984375
2020-02-08T03:01:53.177868: step 2843, loss 0.0406535, acc 0.984375
2020-02-08T03:01:53.295173: step 2844, loss 0.0253249, acc 1
2020-02-08T03:01:53.412792: step 2845, loss 0.0272061, acc 0.984375
2020-02-08T03:01:53.529361: step 2846, loss 0.0473035, acc 0.984375
2020-02-08T03:01:53.644964: step 2847, loss 0.0296471, acc 0.984375
2020-02-08T03:01:53.764217: step 2848, loss 0.0479435, acc 0.984375
2020-02-08T03:01:53.878978: step 2849, loss 0.0287253, acc 1
2020-02-08T03:01:53.990475: step 2850, loss 0.00241187, acc 1
2020-02-08T03:01:54.110638: step 2851, loss 0.00724852, acc 1
2020-02-08T03:01:54.225089: step 2852, loss 0.0132469, acc 1
2020-02-08T03:01:54.340320: step 2853, loss 0.0133902, acc 1
2020-02-08T03:01:54.456212: step 2854, loss 0.00537677, acc 1
2020-02-08T03:01:54.573370: step 2855, loss 0.0687042, acc 0.984375
2020-02-08T03:01:54.689864: step 2856, loss 0.0114613, acc 1
2020-02-08T03:01:54.814876: step 2857, loss 0.01723, acc 1
2020-02-08T03:01:54.929886: step 2858, loss 0.0102613, acc 1
2020-02-08T03:01:55.046311: step 2859, loss 0.0115912, acc 1
2020-02-08T03:01:55.163562: step 2860, loss 0.00818397, acc 1
2020-02-08T03:01:55.278118: step 2861, loss 0.0346142, acc 1
2020-02-08T03:01:55.394817: step 2862, loss 0.00506721, acc 1
2020-02-08T03:01:55.511727: step 2863, loss 0.0228301, acc 0.984375
2020-02-08T03:01:55.627696: step 2864, loss 0.0133903, acc 1
2020-02-08T03:01:55.749753: step 2865, loss 0.012367, acc 1
2020-02-08T03:01:55.868516: step 2866, loss 0.0076293, acc 1
2020-02-08T03:01:55.984497: step 2867, loss 0.015317, acc 1
2020-02-08T03:01:56.102490: step 2868, loss 0.0336096, acc 0.984375
2020-02-08T03:01:56.218302: step 2869, loss 0.021838, acc 1
2020-02-08T03:01:56.332371: step 2870, loss 0.0526742, acc 0.984375
2020-02-08T03:01:56.449501: step 2871, loss 0.00625105, acc 1
2020-02-08T03:01:56.568831: step 2872, loss 0.0515301, acc 0.984375
2020-02-08T03:01:56.685358: step 2873, loss 0.028376, acc 0.984375
2020-02-08T03:01:56.804841: step 2874, loss 0.0320577, acc 0.984375
2020-02-08T03:01:56.920726: step 2875, loss 0.0384017, acc 0.984375
2020-02-08T03:01:57.034210: step 2876, loss 0.0161802, acc 1
2020-02-08T03:01:57.152909: step 2877, loss 0.00572376, acc 1
2020-02-08T03:01:57.274026: step 2878, loss 0.00850377, acc 1
2020-02-08T03:01:57.388795: step 2879, loss 0.0510465, acc 0.984375
2020-02-08T03:01:57.504990: step 2880, loss 0.0140791, acc 1
2020-02-08T03:01:57.621301: step 2881, loss 0.0520362, acc 0.984375
2020-02-08T03:01:57.738495: step 2882, loss 0.0316474, acc 0.984375
2020-02-08T03:01:57.860787: step 2883, loss 0.024305, acc 0.984375
2020-02-08T03:01:57.979510: step 2884, loss 0.00926514, acc 1
2020-02-08T03:01:58.095062: step 2885, loss 0.0647586, acc 0.96875
2020-02-08T03:01:58.210672: step 2886, loss 0.0238895, acc 0.984375
2020-02-08T03:01:58.328452: step 2887, loss 0.0255557, acc 0.984375
2020-02-08T03:01:58.448281: step 2888, loss 0.0432364, acc 0.984375
2020-02-08T03:01:58.564008: step 2889, loss 0.00105663, acc 1
2020-02-08T03:01:58.678620: step 2890, loss 0.0194164, acc 1
2020-02-08T03:01:58.797474: step 2891, loss 0.00542429, acc 1
2020-02-08T03:01:58.920649: step 2892, loss 0.0124668, acc 1
2020-02-08T03:01:59.037313: step 2893, loss 0.0570267, acc 0.984375
2020-02-08T03:01:59.153533: step 2894, loss 0.0272125, acc 1
2020-02-08T03:01:59.270106: step 2895, loss 0.050628, acc 0.984375
2020-02-08T03:01:59.385520: step 2896, loss 0.00767772, acc 1
2020-02-08T03:01:59.500215: step 2897, loss 0.00611258, acc 1
2020-02-08T03:01:59.624169: step 2898, loss 0.0175183, acc 1
2020-02-08T03:01:59.739737: step 2899, loss 0.0271004, acc 0.984375
2020-02-08T03:01:59.857945: step 2900, loss 0.00510812, acc 1

Evaluation:
2020-02-08T03:02:00.058793: step 2900, loss 1.032, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-2900

2020-02-08T03:02:01.792458: step 2901, loss 0.00817249, acc 1
2020-02-08T03:02:01.910471: step 2902, loss 0.053024, acc 0.984375
2020-02-08T03:02:02.026994: step 2903, loss 0.00566798, acc 1
2020-02-08T03:02:02.145769: step 2904, loss 0.0138639, acc 1
2020-02-08T03:02:02.262584: step 2905, loss 0.00155028, acc 1
2020-02-08T03:02:02.377393: step 2906, loss 0.00634213, acc 1
2020-02-08T03:02:02.492597: step 2907, loss 0.0180453, acc 1
2020-02-08T03:02:02.607983: step 2908, loss 0.0161823, acc 1
2020-02-08T03:02:02.725019: step 2909, loss 0.0130274, acc 1
2020-02-08T03:02:02.845849: step 2910, loss 0.00434084, acc 1
2020-02-08T03:02:02.962815: step 2911, loss 0.0273146, acc 1
2020-02-08T03:02:03.077931: step 2912, loss 0.0149449, acc 1
2020-02-08T03:02:03.193504: step 2913, loss 0.00851803, acc 1
2020-02-08T03:02:03.310483: step 2914, loss 0.00760943, acc 1
2020-02-08T03:02:03.426916: step 2915, loss 0.0195589, acc 1
2020-02-08T03:02:03.544066: step 2916, loss 0.00682109, acc 1
2020-02-08T03:02:03.660392: step 2917, loss 0.0155762, acc 1
2020-02-08T03:02:03.776770: step 2918, loss 0.0115915, acc 1
2020-02-08T03:02:03.895358: step 2919, loss 0.00486571, acc 1
2020-02-08T03:02:04.010691: step 2920, loss 0.0243612, acc 1
2020-02-08T03:02:04.126816: step 2921, loss 0.00394823, acc 1
2020-02-08T03:02:04.244790: step 2922, loss 0.0206289, acc 0.984375
2020-02-08T03:02:04.362303: step 2923, loss 0.0134784, acc 1
2020-02-08T03:02:04.478296: step 2924, loss 0.00455347, acc 1
2020-02-08T03:02:04.595970: step 2925, loss 0.00740798, acc 1
2020-02-08T03:02:04.715985: step 2926, loss 0.00736129, acc 1
2020-02-08T03:02:04.834453: step 2927, loss 0.012772, acc 1
2020-02-08T03:02:04.948769: step 2928, loss 0.0137313, acc 1
2020-02-08T03:02:05.071023: step 2929, loss 0.00883385, acc 1
2020-02-08T03:02:05.184520: step 2930, loss 0.0197485, acc 1
2020-02-08T03:02:05.302329: step 2931, loss 0.0199824, acc 1
2020-02-08T03:02:05.418884: step 2932, loss 0.00767058, acc 1
2020-02-08T03:02:05.533243: step 2933, loss 0.03035, acc 0.984375
2020-02-08T03:02:05.650233: step 2934, loss 0.00553739, acc 1
2020-02-08T03:02:05.769243: step 2935, loss 0.0166531, acc 1
2020-02-08T03:02:05.884861: step 2936, loss 0.00622003, acc 1
2020-02-08T03:02:06.000419: step 2937, loss 0.0131968, acc 1
2020-02-08T03:02:06.120891: step 2938, loss 0.0189633, acc 1
2020-02-08T03:02:06.236583: step 2939, loss 0.00809568, acc 1
2020-02-08T03:02:06.355146: step 2940, loss 0.0150047, acc 1
2020-02-08T03:02:06.472715: step 2941, loss 0.00309888, acc 1
2020-02-08T03:02:06.591426: step 2942, loss 0.00586249, acc 1
2020-02-08T03:02:06.709206: step 2943, loss 0.0555619, acc 0.96875
2020-02-08T03:02:06.828943: step 2944, loss 0.0022936, acc 1
2020-02-08T03:02:06.946244: step 2945, loss 0.021135, acc 1
2020-02-08T03:02:07.063081: step 2946, loss 0.020867, acc 0.984375
2020-02-08T03:02:07.178451: step 2947, loss 0.0232921, acc 1
2020-02-08T03:02:07.293811: step 2948, loss 0.0176293, acc 1
2020-02-08T03:02:07.410926: step 2949, loss 0.00841131, acc 1
2020-02-08T03:02:07.529088: step 2950, loss 0.0112721, acc 1
2020-02-08T03:02:07.644665: step 2951, loss 0.0134552, acc 1
2020-02-08T03:02:07.762191: step 2952, loss 0.0159352, acc 1
2020-02-08T03:02:07.876734: step 2953, loss 0.021252, acc 1
2020-02-08T03:02:07.991549: step 2954, loss 0.0394353, acc 0.984375
2020-02-08T03:02:08.110899: step 2955, loss 0.0196169, acc 1
2020-02-08T03:02:08.229529: step 2956, loss 0.0670544, acc 0.984375
2020-02-08T03:02:08.345642: step 2957, loss 0.0603807, acc 0.984375
2020-02-08T03:02:08.462537: step 2958, loss 0.0231014, acc 1
2020-02-08T03:02:08.578184: step 2959, loss 0.0106311, acc 1
2020-02-08T03:02:08.693404: step 2960, loss 0.0206788, acc 1
2020-02-08T03:02:08.815200: step 2961, loss 0.0517167, acc 0.984375
2020-02-08T03:02:08.930420: step 2962, loss 0.00762215, acc 1
2020-02-08T03:02:09.048031: step 2963, loss 0.0138499, acc 1
2020-02-08T03:02:09.167971: step 2964, loss 0.00358439, acc 1
2020-02-08T03:02:09.282186: step 2965, loss 0.0130683, acc 1
2020-02-08T03:02:09.402131: step 2966, loss 0.0283283, acc 0.984375
2020-02-08T03:02:09.519917: step 2967, loss 0.0328233, acc 0.984375
2020-02-08T03:02:09.634059: step 2968, loss 0.00597545, acc 1
2020-02-08T03:02:09.752051: step 2969, loss 0.00527861, acc 1
2020-02-08T03:02:09.869831: step 2970, loss 0.0183289, acc 1
2020-02-08T03:02:09.983100: step 2971, loss 0.0132425, acc 1
2020-02-08T03:02:10.100403: step 2972, loss 0.0107097, acc 1
2020-02-08T03:02:10.222506: step 2973, loss 0.011916, acc 1
2020-02-08T03:02:10.338556: step 2974, loss 0.0287464, acc 0.984375
2020-02-08T03:02:10.458002: step 2975, loss 0.00820842, acc 1
2020-02-08T03:02:10.575400: step 2976, loss 0.0190828, acc 0.984375
2020-02-08T03:02:10.695448: step 2977, loss 0.0866916, acc 0.953125
2020-02-08T03:02:10.817202: step 2978, loss 0.0156964, acc 1
2020-02-08T03:02:10.934125: step 2979, loss 0.0127179, acc 1
2020-02-08T03:02:11.051437: step 2980, loss 0.00496858, acc 1
2020-02-08T03:02:11.170733: step 2981, loss 0.00716726, acc 1
2020-02-08T03:02:11.283644: step 2982, loss 0.0418567, acc 0.984375
2020-02-08T03:02:11.400756: step 2983, loss 0.0133636, acc 1
2020-02-08T03:02:11.517496: step 2984, loss 0.035495, acc 0.984375
2020-02-08T03:02:11.633111: step 2985, loss 0.0128616, acc 1
2020-02-08T03:02:11.753467: step 2986, loss 0.0202384, acc 1
2020-02-08T03:02:11.870835: step 2987, loss 0.0170815, acc 1
2020-02-08T03:02:11.987981: step 2988, loss 0.0242845, acc 0.984375
2020-02-08T03:02:12.105267: step 2989, loss 0.00359726, acc 1
2020-02-08T03:02:12.222787: step 2990, loss 0.00488821, acc 1
2020-02-08T03:02:12.343900: step 2991, loss 0.00696864, acc 1
2020-02-08T03:02:12.460063: step 2992, loss 0.00523797, acc 1
2020-02-08T03:02:12.578264: step 2993, loss 0.0170399, acc 1
2020-02-08T03:02:12.695466: step 2994, loss 0.00869814, acc 1
2020-02-08T03:02:12.818465: step 2995, loss 0.0123309, acc 1
2020-02-08T03:02:12.931890: step 2996, loss 0.00883206, acc 1
2020-02-08T03:02:13.046653: step 2997, loss 0.00619449, acc 1
2020-02-08T03:02:13.169178: step 2998, loss 0.0211604, acc 1
2020-02-08T03:02:13.285794: step 2999, loss 0.00906442, acc 1
2020-02-08T03:02:13.399139: step 3000, loss 0.00497309, acc 1

Evaluation:
2020-02-08T03:02:13.585417: step 3000, loss 1.03923, acc 0.732645

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101720/checkpoints/model-3000

