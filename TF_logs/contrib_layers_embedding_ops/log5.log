WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 23:01:27.429770 4699491776 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 23:01:27.431738 4699491776 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 23:01:27.433516 4699491776 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 23:01:28.186033 4699491776 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 23:01:28.186360 4699491776 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 23:01:28.186637: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 23:01:28.207161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8abba006c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 23:01:28.207186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 23:01:28.207600 4699491776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 23:01:28.211519 4699491776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 23:01:28.228404 4699491776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 23:01:28.248665 4699491776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 23:01:28.286056 4699491776 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 23:01:28.304682 4699491776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 23:01:28.304973 4699491776 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 23:01:28.324443 4699491776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 23:01:28.327817 4699491776 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 23:01:28.374310 4699491776 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 23:01:28.780936 4699491776 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 23:01:28.781759 4699491776 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 23:01:28.794537 4699491776 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 23:01:28.829628 4699491776 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 23:01:28.833261 4699491776 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 23:01:28.869451 4699491776 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 23:01:28.871728 4699491776 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 23:01:28.904448 4699491776 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 23:01:28.907788 4699491776 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 23:01:28.930053 4699491776 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 23:01:28.934437 4699491776 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 23:01:28.989933 4699491776 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 23:01:28.992708 4699491776 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 23:01:29.021573 4699491776 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 23:01:29.025305 4699491776 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 23:01:29.057024 4699491776 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 23:01:29.060685 4699491776 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 23:01:29.102540 4699491776 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 23:01:29.104019 4699491776 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 23:01:29.154915 4699491776 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 23:01:29.157855 4699491776 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 23:01:29.162254 4699491776 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 23:01:29.554725 4699491776 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 23:01:29.554934 4699491776 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 23:01:29.672489 4699491776 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 23:01:30.517148 4699491776 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 23:03:41.395366 4699491776 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089

2020-02-08T23:01:30.515287: step 1, loss 5.78732, acc 0.515625
2020-02-08T23:01:30.730755: step 2, loss 4.91951, acc 0.46875
2020-02-08T23:01:30.936785: step 3, loss 3.18994, acc 0.53125
2020-02-08T23:01:31.131279: step 4, loss 2.5718, acc 0.5
2020-02-08T23:01:31.333448: step 5, loss 1.89994, acc 0.46875
2020-02-08T23:01:31.547074: step 6, loss 1.9758, acc 0.546875
2020-02-08T23:01:31.729118: step 7, loss 2.45868, acc 0.5625
2020-02-08T23:01:31.924113: step 8, loss 3.22064, acc 0.421875
2020-02-08T23:01:32.104448: step 9, loss 2.56591, acc 0.546875
2020-02-08T23:01:32.292308: step 10, loss 3.2302, acc 0.390625
2020-02-08T23:01:32.477436: step 11, loss 3.22763, acc 0.46875
2020-02-08T23:01:32.671468: step 12, loss 1.99097, acc 0.546875
2020-02-08T23:01:32.865036: step 13, loss 2.65245, acc 0.46875
2020-02-08T23:01:33.056019: step 14, loss 1.84689, acc 0.484375
2020-02-08T23:01:33.255367: step 15, loss 1.66362, acc 0.53125
2020-02-08T23:01:33.461208: step 16, loss 2.12531, acc 0.5625
2020-02-08T23:01:33.662699: step 17, loss 2.08543, acc 0.453125
2020-02-08T23:01:33.853645: step 18, loss 1.93222, acc 0.484375
2020-02-08T23:01:34.043415: step 19, loss 2.19036, acc 0.625
2020-02-08T23:01:34.236925: step 20, loss 2.37818, acc 0.46875
2020-02-08T23:01:34.431272: step 21, loss 1.70173, acc 0.5
2020-02-08T23:01:34.627038: step 22, loss 2.33862, acc 0.515625
2020-02-08T23:01:34.815703: step 23, loss 1.69874, acc 0.53125
2020-02-08T23:01:35.010333: step 24, loss 2.24486, acc 0.421875
2020-02-08T23:01:35.207281: step 25, loss 1.81725, acc 0.546875
2020-02-08T23:01:35.391320: step 26, loss 2.03319, acc 0.46875
2020-02-08T23:01:35.582230: step 27, loss 1.24358, acc 0.65625
2020-02-08T23:01:35.781304: step 28, loss 2.60916, acc 0.46875
2020-02-08T23:01:35.981697: step 29, loss 1.96151, acc 0.4375
2020-02-08T23:01:36.166770: step 30, loss 1.74749, acc 0.515625
2020-02-08T23:01:36.365380: step 31, loss 2.17199, acc 0.4375
2020-02-08T23:01:36.561887: step 32, loss 1.62448, acc 0.640625
2020-02-08T23:01:36.769117: step 33, loss 2.06027, acc 0.484375
2020-02-08T23:01:37.065975: step 34, loss 1.6645, acc 0.453125
2020-02-08T23:01:37.284646: step 35, loss 2.37874, acc 0.5
2020-02-08T23:01:37.595898: step 36, loss 1.80063, acc 0.5
2020-02-08T23:01:37.849609: step 37, loss 1.96607, acc 0.53125
2020-02-08T23:01:38.061353: step 38, loss 1.95313, acc 0.484375
2020-02-08T23:01:38.267886: step 39, loss 2.36829, acc 0.421875
2020-02-08T23:01:38.465330: step 40, loss 1.45751, acc 0.5625
2020-02-08T23:01:38.658713: step 41, loss 1.71539, acc 0.53125
2020-02-08T23:01:38.850017: step 42, loss 1.5802, acc 0.5
2020-02-08T23:01:39.046008: step 43, loss 1.81973, acc 0.46875
2020-02-08T23:01:39.247755: step 44, loss 2.10899, acc 0.46875
2020-02-08T23:01:39.426481: step 45, loss 1.7073, acc 0.46875
2020-02-08T23:01:39.613927: step 46, loss 1.43758, acc 0.546875
2020-02-08T23:01:39.801187: step 47, loss 1.56112, acc 0.515625
2020-02-08T23:01:39.997908: step 48, loss 1.51742, acc 0.46875
2020-02-08T23:01:40.195011: step 49, loss 1.54465, acc 0.5625
2020-02-08T23:01:40.380195: step 50, loss 1.69569, acc 0.5625
2020-02-08T23:01:40.581360: step 51, loss 1.56411, acc 0.421875
2020-02-08T23:01:40.757431: step 52, loss 1.5713, acc 0.578125
2020-02-08T23:01:40.965223: step 53, loss 1.36996, acc 0.5
2020-02-08T23:01:41.156628: step 54, loss 1.7218, acc 0.515625
2020-02-08T23:01:41.343246: step 55, loss 1.86985, acc 0.46875
2020-02-08T23:01:41.526367: step 56, loss 2.08195, acc 0.515625
2020-02-08T23:01:41.709246: step 57, loss 1.90644, acc 0.390625
2020-02-08T23:01:41.872696: step 58, loss 2.48246, acc 0.484375
2020-02-08T23:01:42.049081: step 59, loss 1.59881, acc 0.484375
2020-02-08T23:01:42.223239: step 60, loss 1.60052, acc 0.453125
2020-02-08T23:01:42.408020: step 61, loss 1.86467, acc 0.421875
2020-02-08T23:01:42.602625: step 62, loss 1.50417, acc 0.609375
2020-02-08T23:01:42.793385: step 63, loss 1.52604, acc 0.546875
2020-02-08T23:01:42.979832: step 64, loss 1.73421, acc 0.53125
2020-02-08T23:01:43.157005: step 65, loss 0.964763, acc 0.71875
2020-02-08T23:01:43.336214: step 66, loss 1.85196, acc 0.53125
2020-02-08T23:01:43.515809: step 67, loss 1.53646, acc 0.546875
2020-02-08T23:01:43.687228: step 68, loss 1.61544, acc 0.53125
2020-02-08T23:01:43.943697: step 69, loss 1.83789, acc 0.453125
2020-02-08T23:01:44.123134: step 70, loss 1.48314, acc 0.46875
2020-02-08T23:01:44.321222: step 71, loss 2.25277, acc 0.453125
2020-02-08T23:01:44.520774: step 72, loss 1.76743, acc 0.40625
2020-02-08T23:01:44.694220: step 73, loss 1.66694, acc 0.484375
2020-02-08T23:01:44.861564: step 74, loss 1.8587, acc 0.53125
2020-02-08T23:01:45.039264: step 75, loss 1.57196, acc 0.578125
2020-02-08T23:01:45.220307: step 76, loss 1.94519, acc 0.40625
2020-02-08T23:01:45.402862: step 77, loss 1.41922, acc 0.578125
2020-02-08T23:01:45.596823: step 78, loss 1.7147, acc 0.515625
2020-02-08T23:01:45.771804: step 79, loss 2.24896, acc 0.453125
2020-02-08T23:01:45.979769: step 80, loss 1.88914, acc 0.546875
2020-02-08T23:01:46.202329: step 81, loss 1.90609, acc 0.5
2020-02-08T23:01:46.377444: step 82, loss 1.60946, acc 0.546875
2020-02-08T23:01:46.562767: step 83, loss 1.89786, acc 0.4375
2020-02-08T23:01:46.763375: step 84, loss 1.59294, acc 0.53125
2020-02-08T23:01:46.922376: step 85, loss 1.65575, acc 0.53125
2020-02-08T23:01:47.114634: step 86, loss 1.04156, acc 0.578125
2020-02-08T23:01:47.294543: step 87, loss 1.4068, acc 0.515625
2020-02-08T23:01:47.463404: step 88, loss 1.96991, acc 0.40625
2020-02-08T23:01:47.647624: step 89, loss 1.41861, acc 0.546875
2020-02-08T23:01:47.828742: step 90, loss 1.79513, acc 0.40625
2020-02-08T23:01:48.019150: step 91, loss 1.56183, acc 0.5625
2020-02-08T23:01:48.206537: step 92, loss 1.30697, acc 0.59375
2020-02-08T23:01:48.392274: step 93, loss 1.34709, acc 0.515625
2020-02-08T23:01:48.585194: step 94, loss 1.80138, acc 0.484375
2020-02-08T23:01:48.779776: step 95, loss 1.65917, acc 0.5
2020-02-08T23:01:48.977934: step 96, loss 1.38343, acc 0.59375
2020-02-08T23:01:49.156756: step 97, loss 1.54865, acc 0.53125
2020-02-08T23:01:49.342620: step 98, loss 1.99641, acc 0.5
2020-02-08T23:01:49.536616: step 99, loss 1.82694, acc 0.484375
2020-02-08T23:01:49.722032: step 100, loss 1.25246, acc 0.5

Evaluation:
2020-02-08T23:01:50.132215: step 100, loss 0.730468, acc 0.591932

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-100

2020-02-08T23:01:52.114507: step 101, loss 1.46195, acc 0.578125
2020-02-08T23:01:52.300745: step 102, loss 1.18493, acc 0.640625
2020-02-08T23:01:52.514925: step 103, loss 1.70293, acc 0.5
2020-02-08T23:01:52.720734: step 104, loss 0.841006, acc 0.671875
2020-02-08T23:01:52.916423: step 105, loss 1.80066, acc 0.421875
2020-02-08T23:01:53.138082: step 106, loss 2.02611, acc 0.515625
2020-02-08T23:01:53.350415: step 107, loss 1.94778, acc 0.453125
2020-02-08T23:01:53.583911: step 108, loss 1.7809, acc 0.484375
2020-02-08T23:01:53.805309: step 109, loss 1.08256, acc 0.609375
2020-02-08T23:01:54.024876: step 110, loss 2.30822, acc 0.5
2020-02-08T23:01:54.176397: step 111, loss 1.11532, acc 0.640625
2020-02-08T23:01:54.383239: step 112, loss 1.42178, acc 0.546875
2020-02-08T23:01:54.601789: step 113, loss 1.40028, acc 0.578125
2020-02-08T23:01:54.821801: step 114, loss 1.08184, acc 0.578125
2020-02-08T23:01:55.041842: step 115, loss 1.3936, acc 0.640625
2020-02-08T23:01:55.256514: step 116, loss 1.34477, acc 0.5625
2020-02-08T23:01:55.465903: step 117, loss 1.85045, acc 0.484375
2020-02-08T23:01:55.682892: step 118, loss 1.40549, acc 0.53125
2020-02-08T23:01:55.898599: step 119, loss 1.80682, acc 0.515625
2020-02-08T23:01:56.093422: step 120, loss 1.74603, acc 0.46875
2020-02-08T23:01:56.302503: step 121, loss 1.07012, acc 0.59375
2020-02-08T23:01:56.503375: step 122, loss 1.58932, acc 0.484375
2020-02-08T23:01:56.708298: step 123, loss 1.45666, acc 0.515625
2020-02-08T23:01:56.907989: step 124, loss 1.86956, acc 0.40625
2020-02-08T23:01:57.116912: step 125, loss 1.42323, acc 0.609375
2020-02-08T23:01:57.314369: step 126, loss 1.58267, acc 0.46875
2020-02-08T23:01:57.513007: step 127, loss 0.96428, acc 0.703125
2020-02-08T23:01:57.707237: step 128, loss 1.99256, acc 0.296875
2020-02-08T23:01:57.885724: step 129, loss 1.037, acc 0.609375
2020-02-08T23:01:58.065652: step 130, loss 1.05545, acc 0.640625
2020-02-08T23:01:58.253737: step 131, loss 1.35165, acc 0.484375
2020-02-08T23:01:58.434494: step 132, loss 1.05514, acc 0.53125
2020-02-08T23:01:58.618320: step 133, loss 1.62174, acc 0.546875
2020-02-08T23:01:58.801058: step 134, loss 1.54755, acc 0.546875
2020-02-08T23:01:58.989362: step 135, loss 1.41328, acc 0.5
2020-02-08T23:01:59.183304: step 136, loss 1.62092, acc 0.484375
2020-02-08T23:01:59.389339: step 137, loss 1.61587, acc 0.484375
2020-02-08T23:01:59.579676: step 138, loss 1.58792, acc 0.53125
2020-02-08T23:01:59.766332: step 139, loss 1.47636, acc 0.578125
2020-02-08T23:01:59.948246: step 140, loss 1.35769, acc 0.53125
2020-02-08T23:02:00.143763: step 141, loss 1.01908, acc 0.609375
2020-02-08T23:02:00.327163: step 142, loss 1.28603, acc 0.546875
2020-02-08T23:02:00.511970: step 143, loss 1.75131, acc 0.484375
2020-02-08T23:02:00.697907: step 144, loss 1.17844, acc 0.5625
2020-02-08T23:02:00.890536: step 145, loss 1.78667, acc 0.4375
2020-02-08T23:02:01.092960: step 146, loss 1.2634, acc 0.5625
2020-02-08T23:02:01.277646: step 147, loss 1.39017, acc 0.515625
2020-02-08T23:02:01.469059: step 148, loss 1.42587, acc 0.578125
2020-02-08T23:02:01.666667: step 149, loss 1.33831, acc 0.546875
2020-02-08T23:02:01.846541: step 150, loss 1.48575, acc 0.516667
2020-02-08T23:02:02.035789: step 151, loss 1.11629, acc 0.578125
2020-02-08T23:02:02.227746: step 152, loss 0.876911, acc 0.671875
2020-02-08T23:02:02.420245: step 153, loss 1.10457, acc 0.609375
2020-02-08T23:02:02.609667: step 154, loss 1.07999, acc 0.546875
2020-02-08T23:02:02.795124: step 155, loss 0.992326, acc 0.578125
2020-02-08T23:02:02.993359: step 156, loss 0.839412, acc 0.640625
2020-02-08T23:02:03.203889: step 157, loss 0.970411, acc 0.65625
2020-02-08T23:02:03.407982: step 158, loss 0.987998, acc 0.703125
2020-02-08T23:02:03.576623: step 159, loss 0.76626, acc 0.6875
2020-02-08T23:02:03.776814: step 160, loss 1.25149, acc 0.59375
2020-02-08T23:02:03.975931: step 161, loss 1.03009, acc 0.59375
2020-02-08T23:02:04.169395: step 162, loss 0.955219, acc 0.640625
2020-02-08T23:02:04.359906: step 163, loss 1.29569, acc 0.515625
2020-02-08T23:02:04.530000: step 164, loss 1.09552, acc 0.5
2020-02-08T23:02:04.712722: step 165, loss 0.955469, acc 0.671875
2020-02-08T23:02:04.875498: step 166, loss 0.975195, acc 0.671875
2020-02-08T23:02:05.059461: step 167, loss 1.042, acc 0.5625
2020-02-08T23:02:05.248381: step 168, loss 1.13908, acc 0.59375
2020-02-08T23:02:05.443090: step 169, loss 0.96281, acc 0.671875
2020-02-08T23:02:05.635277: step 170, loss 0.998525, acc 0.640625
2020-02-08T23:02:05.819641: step 171, loss 0.700672, acc 0.625
2020-02-08T23:02:06.005471: step 172, loss 1.30457, acc 0.46875
2020-02-08T23:02:06.196521: step 173, loss 0.83623, acc 0.640625
2020-02-08T23:02:06.392036: step 174, loss 1.22053, acc 0.5625
2020-02-08T23:02:06.572595: step 175, loss 0.915171, acc 0.65625
2020-02-08T23:02:06.757577: step 176, loss 0.936321, acc 0.53125
2020-02-08T23:02:06.940387: step 177, loss 1.17735, acc 0.59375
2020-02-08T23:02:07.120716: step 178, loss 0.77439, acc 0.6875
2020-02-08T23:02:07.298693: step 179, loss 0.992136, acc 0.671875
2020-02-08T23:02:07.482208: step 180, loss 0.88924, acc 0.65625
2020-02-08T23:02:07.669891: step 181, loss 1.2486, acc 0.578125
2020-02-08T23:02:07.851987: step 182, loss 0.950095, acc 0.609375
2020-02-08T23:02:08.039337: step 183, loss 1.00677, acc 0.578125
2020-02-08T23:02:08.230900: step 184, loss 0.700024, acc 0.734375
2020-02-08T23:02:08.414493: step 185, loss 1.18263, acc 0.625
2020-02-08T23:02:08.594328: step 186, loss 1.0268, acc 0.546875
2020-02-08T23:02:08.771910: step 187, loss 0.861599, acc 0.640625
2020-02-08T23:02:08.953698: step 188, loss 0.947255, acc 0.65625
2020-02-08T23:02:09.148834: step 189, loss 0.823146, acc 0.640625
2020-02-08T23:02:09.345753: step 190, loss 1.16294, acc 0.625
2020-02-08T23:02:09.525122: step 191, loss 1.28194, acc 0.59375
2020-02-08T23:02:09.712477: step 192, loss 1.15787, acc 0.640625
2020-02-08T23:02:09.904833: step 193, loss 0.918882, acc 0.59375
2020-02-08T23:02:10.080115: step 194, loss 1.05453, acc 0.578125
2020-02-08T23:02:10.256173: step 195, loss 1.12677, acc 0.546875
2020-02-08T23:02:10.445614: step 196, loss 1.39007, acc 0.609375
2020-02-08T23:02:10.645861: step 197, loss 1.11562, acc 0.59375
2020-02-08T23:02:10.832627: step 198, loss 1.08267, acc 0.546875
2020-02-08T23:02:11.031459: step 199, loss 1.23208, acc 0.515625
2020-02-08T23:02:11.218998: step 200, loss 0.943502, acc 0.53125

Evaluation:
2020-02-08T23:02:11.562730: step 200, loss 0.671025, acc 0.61257

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-200

2020-02-08T23:02:13.206205: step 201, loss 0.867033, acc 0.6875
2020-02-08T23:02:13.397644: step 202, loss 1.23953, acc 0.5
2020-02-08T23:02:13.592108: step 203, loss 1.27557, acc 0.5625
2020-02-08T23:02:13.779767: step 204, loss 0.875703, acc 0.640625
2020-02-08T23:02:13.971265: step 205, loss 0.738847, acc 0.71875
2020-02-08T23:02:14.167037: step 206, loss 0.969277, acc 0.59375
2020-02-08T23:02:14.381521: step 207, loss 0.902621, acc 0.609375
2020-02-08T23:02:14.560851: step 208, loss 0.803299, acc 0.65625
2020-02-08T23:02:14.745882: step 209, loss 0.908339, acc 0.5
2020-02-08T23:02:14.952293: step 210, loss 0.860062, acc 0.671875
2020-02-08T23:02:15.158239: step 211, loss 1.02185, acc 0.5
2020-02-08T23:02:15.326767: step 212, loss 0.844479, acc 0.65625
2020-02-08T23:02:15.511673: step 213, loss 1.14656, acc 0.515625
2020-02-08T23:02:15.712973: step 214, loss 0.946135, acc 0.546875
2020-02-08T23:02:15.897573: step 215, loss 0.937924, acc 0.640625
2020-02-08T23:02:16.078203: step 216, loss 1.00956, acc 0.59375
2020-02-08T23:02:16.265777: step 217, loss 0.786435, acc 0.65625
2020-02-08T23:02:16.442389: step 218, loss 1.18091, acc 0.5625
2020-02-08T23:02:16.634917: step 219, loss 0.981609, acc 0.640625
2020-02-08T23:02:16.844659: step 220, loss 0.624373, acc 0.71875
2020-02-08T23:02:17.043208: step 221, loss 0.995248, acc 0.65625
2020-02-08T23:02:17.219865: step 222, loss 0.954368, acc 0.625
2020-02-08T23:02:17.417475: step 223, loss 0.849411, acc 0.640625
2020-02-08T23:02:17.606239: step 224, loss 0.991426, acc 0.609375
2020-02-08T23:02:17.795166: step 225, loss 1.31167, acc 0.453125
2020-02-08T23:02:17.992057: step 226, loss 0.75703, acc 0.671875
2020-02-08T23:02:18.186419: step 227, loss 0.88764, acc 0.5625
2020-02-08T23:02:18.377640: step 228, loss 0.848558, acc 0.625
2020-02-08T23:02:18.569570: step 229, loss 0.931796, acc 0.65625
2020-02-08T23:02:18.766148: step 230, loss 0.799136, acc 0.59375
2020-02-08T23:02:18.961888: step 231, loss 0.806433, acc 0.6875
2020-02-08T23:02:19.166789: step 232, loss 0.945199, acc 0.640625
2020-02-08T23:02:19.351591: step 233, loss 0.812481, acc 0.671875
2020-02-08T23:02:19.532240: step 234, loss 0.846583, acc 0.671875
2020-02-08T23:02:19.725491: step 235, loss 1.24643, acc 0.5
2020-02-08T23:02:19.934545: step 236, loss 0.758026, acc 0.625
2020-02-08T23:02:20.152950: step 237, loss 1.34103, acc 0.53125
2020-02-08T23:02:20.364541: step 238, loss 1.25329, acc 0.453125
2020-02-08T23:02:20.588501: step 239, loss 0.926093, acc 0.609375
2020-02-08T23:02:20.780686: step 240, loss 1.00209, acc 0.46875
2020-02-08T23:02:20.996359: step 241, loss 0.961253, acc 0.609375
2020-02-08T23:02:21.189072: step 242, loss 1.25997, acc 0.53125
2020-02-08T23:02:21.384880: step 243, loss 0.718263, acc 0.671875
2020-02-08T23:02:21.576086: step 244, loss 1.05316, acc 0.5625
2020-02-08T23:02:21.773098: step 245, loss 0.840687, acc 0.640625
2020-02-08T23:02:21.967567: step 246, loss 1.06827, acc 0.609375
2020-02-08T23:02:22.156567: step 247, loss 0.785756, acc 0.609375
2020-02-08T23:02:22.353050: step 248, loss 1.1995, acc 0.515625
2020-02-08T23:02:22.545720: step 249, loss 0.883612, acc 0.625
2020-02-08T23:02:22.752135: step 250, loss 0.917778, acc 0.578125
2020-02-08T23:02:22.937488: step 251, loss 0.627466, acc 0.703125
2020-02-08T23:02:23.116179: step 252, loss 0.785172, acc 0.640625
2020-02-08T23:02:23.305460: step 253, loss 1.03603, acc 0.578125
2020-02-08T23:02:23.494482: step 254, loss 0.978469, acc 0.578125
2020-02-08T23:02:23.682993: step 255, loss 0.90246, acc 0.5625
2020-02-08T23:02:23.868799: step 256, loss 0.98822, acc 0.578125
2020-02-08T23:02:24.061996: step 257, loss 1.14494, acc 0.484375
2020-02-08T23:02:24.230651: step 258, loss 0.982196, acc 0.59375
2020-02-08T23:02:24.438771: step 259, loss 0.764782, acc 0.640625
2020-02-08T23:02:24.605761: step 260, loss 1.07748, acc 0.578125
2020-02-08T23:02:24.806816: step 261, loss 1.10954, acc 0.578125
2020-02-08T23:02:25.019124: step 262, loss 0.895692, acc 0.5625
2020-02-08T23:02:25.245725: step 263, loss 0.959022, acc 0.59375
2020-02-08T23:02:25.475877: step 264, loss 0.821074, acc 0.625
2020-02-08T23:02:25.703982: step 265, loss 1.19714, acc 0.5625
2020-02-08T23:02:25.922858: step 266, loss 0.608069, acc 0.734375
2020-02-08T23:02:26.154032: step 267, loss 0.998265, acc 0.65625
2020-02-08T23:02:26.410699: step 268, loss 0.984448, acc 0.59375
2020-02-08T23:02:26.622104: step 269, loss 0.805758, acc 0.671875
2020-02-08T23:02:26.830351: step 270, loss 1.06712, acc 0.484375
2020-02-08T23:02:27.025139: step 271, loss 0.636427, acc 0.65625
2020-02-08T23:02:27.246379: step 272, loss 0.94942, acc 0.65625
2020-02-08T23:02:27.459276: step 273, loss 0.84177, acc 0.65625
2020-02-08T23:02:27.662477: step 274, loss 0.905602, acc 0.53125
2020-02-08T23:02:27.867567: step 275, loss 0.835853, acc 0.625
2020-02-08T23:02:28.065397: step 276, loss 0.913322, acc 0.578125
2020-02-08T23:02:28.274257: step 277, loss 0.797796, acc 0.65625
2020-02-08T23:02:28.467509: step 278, loss 0.889686, acc 0.625
2020-02-08T23:02:28.695924: step 279, loss 0.87156, acc 0.625
2020-02-08T23:02:28.868122: step 280, loss 0.849257, acc 0.609375
2020-02-08T23:02:29.072118: step 281, loss 0.844279, acc 0.640625
2020-02-08T23:02:29.223705: step 282, loss 0.842695, acc 0.546875
2020-02-08T23:02:29.432131: step 283, loss 0.914864, acc 0.59375
2020-02-08T23:02:29.645123: step 284, loss 0.969689, acc 0.53125
2020-02-08T23:02:29.855622: step 285, loss 0.912772, acc 0.640625
2020-02-08T23:02:30.083252: step 286, loss 0.917623, acc 0.609375
2020-02-08T23:02:30.337419: step 287, loss 0.81541, acc 0.6875
2020-02-08T23:02:30.590565: step 288, loss 0.877876, acc 0.6875
2020-02-08T23:02:30.827973: step 289, loss 0.73616, acc 0.734375
2020-02-08T23:02:31.049999: step 290, loss 0.873528, acc 0.546875
2020-02-08T23:02:31.256430: step 291, loss 1.11667, acc 0.515625
2020-02-08T23:02:31.476089: step 292, loss 0.830633, acc 0.640625
2020-02-08T23:02:31.674370: step 293, loss 0.951398, acc 0.53125
2020-02-08T23:02:31.905601: step 294, loss 0.800014, acc 0.53125
2020-02-08T23:02:32.110530: step 295, loss 0.822825, acc 0.625
2020-02-08T23:02:32.312354: step 296, loss 0.84185, acc 0.609375
2020-02-08T23:02:32.510923: step 297, loss 0.876678, acc 0.5625
2020-02-08T23:02:32.721285: step 298, loss 0.760485, acc 0.65625
2020-02-08T23:02:32.926728: step 299, loss 0.871767, acc 0.578125
2020-02-08T23:02:33.123832: step 300, loss 0.908935, acc 0.65

Evaluation:
2020-02-08T23:02:33.526778: step 300, loss 0.648692, acc 0.62758

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-300

2020-02-08T23:02:35.103959: step 301, loss 0.860215, acc 0.59375
2020-02-08T23:02:35.292017: step 302, loss 0.767094, acc 0.625
2020-02-08T23:02:35.524979: step 303, loss 0.907262, acc 0.546875
2020-02-08T23:02:35.725000: step 304, loss 0.679191, acc 0.65625
2020-02-08T23:02:35.932739: step 305, loss 0.578772, acc 0.75
2020-02-08T23:02:36.144121: step 306, loss 0.670687, acc 0.625
2020-02-08T23:02:36.363216: step 307, loss 0.863196, acc 0.640625
2020-02-08T23:02:36.584338: step 308, loss 0.725517, acc 0.578125
2020-02-08T23:02:36.758015: step 309, loss 0.78446, acc 0.640625
2020-02-08T23:02:36.968107: step 310, loss 0.712245, acc 0.71875
2020-02-08T23:02:37.174238: step 311, loss 0.666389, acc 0.671875
2020-02-08T23:02:37.386546: step 312, loss 0.595871, acc 0.703125
2020-02-08T23:02:37.614114: step 313, loss 0.621498, acc 0.65625
2020-02-08T23:02:37.826564: step 314, loss 0.613287, acc 0.6875
2020-02-08T23:02:38.036460: step 315, loss 0.662803, acc 0.734375
2020-02-08T23:02:38.254022: step 316, loss 0.956025, acc 0.578125
2020-02-08T23:02:38.454080: step 317, loss 0.758841, acc 0.609375
2020-02-08T23:02:38.639844: step 318, loss 0.719454, acc 0.65625
2020-02-08T23:02:38.840904: step 319, loss 0.681669, acc 0.75
2020-02-08T23:02:39.044407: step 320, loss 0.815001, acc 0.625
2020-02-08T23:02:39.254884: step 321, loss 0.751335, acc 0.671875
2020-02-08T23:02:39.460811: step 322, loss 0.694562, acc 0.625
2020-02-08T23:02:39.649565: step 323, loss 0.684452, acc 0.625
2020-02-08T23:02:39.854135: step 324, loss 0.708458, acc 0.625
2020-02-08T23:02:40.062365: step 325, loss 0.962445, acc 0.578125
2020-02-08T23:02:40.263897: step 326, loss 0.567839, acc 0.703125
2020-02-08T23:02:40.476294: step 327, loss 0.590497, acc 0.75
2020-02-08T23:02:40.690875: step 328, loss 0.777394, acc 0.71875
2020-02-08T23:02:40.872319: step 329, loss 0.85732, acc 0.5625
2020-02-08T23:02:41.083627: step 330, loss 0.464068, acc 0.765625
2020-02-08T23:02:41.275034: step 331, loss 0.688167, acc 0.6875
2020-02-08T23:02:41.456442: step 332, loss 0.712301, acc 0.640625
2020-02-08T23:02:41.678255: step 333, loss 0.776195, acc 0.59375
2020-02-08T23:02:41.874426: step 334, loss 0.656521, acc 0.640625
2020-02-08T23:02:42.061590: step 335, loss 0.769208, acc 0.578125
2020-02-08T23:02:42.284378: step 336, loss 0.779331, acc 0.671875
2020-02-08T23:02:42.522140: step 337, loss 0.701486, acc 0.703125
2020-02-08T23:02:42.722270: step 338, loss 0.732518, acc 0.65625
2020-02-08T23:02:42.931771: step 339, loss 0.722519, acc 0.65625
2020-02-08T23:02:43.134245: step 340, loss 0.770825, acc 0.640625
2020-02-08T23:02:43.344842: step 341, loss 0.624443, acc 0.71875
2020-02-08T23:02:43.543519: step 342, loss 0.6389, acc 0.75
2020-02-08T23:02:43.906305: step 343, loss 0.752675, acc 0.6875
2020-02-08T23:02:44.101045: step 344, loss 0.842796, acc 0.625
2020-02-08T23:02:44.307711: step 345, loss 0.673564, acc 0.6875
2020-02-08T23:02:44.515688: step 346, loss 0.576666, acc 0.71875
2020-02-08T23:02:44.737739: step 347, loss 0.744279, acc 0.609375
2020-02-08T23:02:44.948223: step 348, loss 0.670602, acc 0.671875
2020-02-08T23:02:45.165488: step 349, loss 0.585786, acc 0.71875
2020-02-08T23:02:45.388816: step 350, loss 0.589034, acc 0.71875
2020-02-08T23:02:45.603128: step 351, loss 0.617609, acc 0.71875
2020-02-08T23:02:45.822510: step 352, loss 0.679908, acc 0.671875
2020-02-08T23:02:46.040276: step 353, loss 0.660196, acc 0.734375
2020-02-08T23:02:46.258767: step 354, loss 0.91935, acc 0.578125
2020-02-08T23:02:46.477635: step 355, loss 0.693295, acc 0.71875
2020-02-08T23:02:46.713548: step 356, loss 0.647028, acc 0.59375
2020-02-08T23:02:46.952529: step 357, loss 0.662202, acc 0.671875
2020-02-08T23:02:47.181853: step 358, loss 0.711628, acc 0.625
2020-02-08T23:02:47.434648: step 359, loss 0.542907, acc 0.734375
2020-02-08T23:02:47.694878: step 360, loss 0.748023, acc 0.640625
2020-02-08T23:02:47.992617: step 361, loss 0.581577, acc 0.6875
2020-02-08T23:02:48.252334: step 362, loss 0.717232, acc 0.59375
2020-02-08T23:02:48.537897: step 363, loss 0.754767, acc 0.671875
2020-02-08T23:02:48.776973: step 364, loss 0.643075, acc 0.71875
2020-02-08T23:02:48.995837: step 365, loss 0.783445, acc 0.671875
2020-02-08T23:02:49.202888: step 366, loss 0.721716, acc 0.65625
2020-02-08T23:02:49.415365: step 367, loss 0.588618, acc 0.65625
2020-02-08T23:02:49.627099: step 368, loss 0.667973, acc 0.65625
2020-02-08T23:02:49.832559: step 369, loss 0.830686, acc 0.59375
2020-02-08T23:02:50.036127: step 370, loss 0.591199, acc 0.6875
2020-02-08T23:02:50.257258: step 371, loss 0.561581, acc 0.734375
2020-02-08T23:02:50.462519: step 372, loss 0.602065, acc 0.671875
2020-02-08T23:02:50.651521: step 373, loss 0.691474, acc 0.625
2020-02-08T23:02:50.858934: step 374, loss 0.640326, acc 0.671875
2020-02-08T23:02:51.069105: step 375, loss 0.772504, acc 0.6875
2020-02-08T23:02:51.275544: step 376, loss 0.63646, acc 0.703125
2020-02-08T23:02:51.490078: step 377, loss 0.594282, acc 0.75
2020-02-08T23:02:51.697581: step 378, loss 0.423678, acc 0.8125
2020-02-08T23:02:51.872267: step 379, loss 0.737748, acc 0.71875
2020-02-08T23:02:52.078741: step 380, loss 0.770499, acc 0.71875
2020-02-08T23:02:52.278029: step 381, loss 0.868719, acc 0.578125
2020-02-08T23:02:52.485366: step 382, loss 0.667459, acc 0.6875
2020-02-08T23:02:52.706104: step 383, loss 0.479288, acc 0.796875
2020-02-08T23:02:52.878169: step 384, loss 0.714455, acc 0.65625
2020-02-08T23:02:53.087953: step 385, loss 0.692009, acc 0.640625
2020-02-08T23:02:53.306262: step 386, loss 0.718495, acc 0.625
2020-02-08T23:02:53.522042: step 387, loss 0.548158, acc 0.765625
2020-02-08T23:02:53.746640: step 388, loss 0.698679, acc 0.625
2020-02-08T23:02:53.954745: step 389, loss 0.623256, acc 0.71875
2020-02-08T23:02:54.111628: step 390, loss 0.709875, acc 0.65625
2020-02-08T23:02:54.317272: step 391, loss 0.499608, acc 0.796875
2020-02-08T23:02:54.528245: step 392, loss 0.647267, acc 0.65625
2020-02-08T23:02:54.763126: step 393, loss 0.633002, acc 0.578125
2020-02-08T23:02:54.967338: step 394, loss 0.781316, acc 0.5625
2020-02-08T23:02:55.153751: step 395, loss 0.759208, acc 0.671875
2020-02-08T23:02:55.369290: step 396, loss 0.575315, acc 0.71875
2020-02-08T23:02:55.564148: step 397, loss 0.787035, acc 0.609375
2020-02-08T23:02:55.770109: step 398, loss 0.53788, acc 0.734375
2020-02-08T23:02:55.964313: step 399, loss 0.40388, acc 0.859375
2020-02-08T23:02:56.145159: step 400, loss 0.720158, acc 0.6875

Evaluation:
2020-02-08T23:02:56.497873: step 400, loss 0.669227, acc 0.594747

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-400

2020-02-08T23:02:58.105907: step 401, loss 0.671191, acc 0.6875
2020-02-08T23:02:58.298027: step 402, loss 0.64129, acc 0.671875
2020-02-08T23:02:58.491090: step 403, loss 0.806334, acc 0.59375
2020-02-08T23:02:58.678705: step 404, loss 0.528782, acc 0.703125
2020-02-08T23:02:58.870199: step 405, loss 0.540399, acc 0.671875
2020-02-08T23:02:59.058380: step 406, loss 0.749963, acc 0.640625
2020-02-08T23:02:59.249705: step 407, loss 0.712333, acc 0.671875
2020-02-08T23:02:59.445501: step 408, loss 0.829663, acc 0.609375
2020-02-08T23:02:59.640471: step 409, loss 0.725826, acc 0.625
2020-02-08T23:02:59.826774: step 410, loss 0.703061, acc 0.625
2020-02-08T23:03:00.021859: step 411, loss 0.767183, acc 0.625
2020-02-08T23:03:00.216821: step 412, loss 0.677612, acc 0.703125
2020-02-08T23:03:00.383633: step 413, loss 0.709069, acc 0.65625
2020-02-08T23:03:00.572601: step 414, loss 0.746935, acc 0.609375
2020-02-08T23:03:00.757072: step 415, loss 0.619078, acc 0.609375
2020-02-08T23:03:00.965081: step 416, loss 0.636348, acc 0.578125
2020-02-08T23:03:01.143134: step 417, loss 0.598095, acc 0.734375
2020-02-08T23:03:01.327175: step 418, loss 0.842674, acc 0.65625
2020-02-08T23:03:01.519122: step 419, loss 0.667005, acc 0.6875
2020-02-08T23:03:01.713152: step 420, loss 0.639411, acc 0.703125
2020-02-08T23:03:01.882206: step 421, loss 0.569957, acc 0.6875
2020-02-08T23:03:02.066469: step 422, loss 0.586386, acc 0.71875
2020-02-08T23:03:02.259414: step 423, loss 0.627484, acc 0.6875
2020-02-08T23:03:02.460728: step 424, loss 0.660711, acc 0.703125
2020-02-08T23:03:02.645141: step 425, loss 0.772791, acc 0.546875
2020-02-08T23:03:02.839824: step 426, loss 0.494253, acc 0.703125
2020-02-08T23:03:03.023174: step 427, loss 0.53258, acc 0.78125
2020-02-08T23:03:03.215280: step 428, loss 0.704876, acc 0.625
2020-02-08T23:03:03.414538: step 429, loss 0.579756, acc 0.71875
2020-02-08T23:03:03.607441: step 430, loss 0.548995, acc 0.75
2020-02-08T23:03:03.792836: step 431, loss 0.683233, acc 0.640625
2020-02-08T23:03:03.984310: step 432, loss 0.554429, acc 0.703125
2020-02-08T23:03:04.169366: step 433, loss 0.637692, acc 0.71875
2020-02-08T23:03:04.365369: step 434, loss 0.676686, acc 0.625
2020-02-08T23:03:04.546840: step 435, loss 0.666169, acc 0.671875
2020-02-08T23:03:04.738989: step 436, loss 0.713555, acc 0.609375
2020-02-08T23:03:04.921019: step 437, loss 0.546394, acc 0.734375
2020-02-08T23:03:05.119977: step 438, loss 0.737363, acc 0.734375
2020-02-08T23:03:05.317706: step 439, loss 0.688882, acc 0.671875
2020-02-08T23:03:05.510676: step 440, loss 0.64043, acc 0.6875
2020-02-08T23:03:05.697580: step 441, loss 0.558385, acc 0.703125
2020-02-08T23:03:05.871898: step 442, loss 0.62687, acc 0.65625
2020-02-08T23:03:06.066576: step 443, loss 0.840276, acc 0.640625
2020-02-08T23:03:06.254146: step 444, loss 0.580732, acc 0.671875
2020-02-08T23:03:06.450220: step 445, loss 0.616585, acc 0.6875
2020-02-08T23:03:06.641036: step 446, loss 0.62992, acc 0.6875
2020-02-08T23:03:06.833283: step 447, loss 0.772828, acc 0.671875
2020-02-08T23:03:07.020445: step 448, loss 0.566792, acc 0.734375
2020-02-08T23:03:07.207084: step 449, loss 0.57919, acc 0.734375
2020-02-08T23:03:07.387014: step 450, loss 0.641565, acc 0.65
2020-02-08T23:03:07.570420: step 451, loss 0.626692, acc 0.671875
2020-02-08T23:03:07.762910: step 452, loss 0.559693, acc 0.703125
2020-02-08T23:03:07.959573: step 453, loss 0.654997, acc 0.6875
2020-02-08T23:03:08.155548: step 454, loss 0.545702, acc 0.734375
2020-02-08T23:03:08.336484: step 455, loss 0.433919, acc 0.765625
2020-02-08T23:03:08.520063: step 456, loss 0.457304, acc 0.796875
2020-02-08T23:03:08.714038: step 457, loss 0.508477, acc 0.765625
2020-02-08T23:03:08.901132: step 458, loss 0.550386, acc 0.734375
2020-02-08T23:03:09.087793: step 459, loss 0.531185, acc 0.765625
2020-02-08T23:03:09.277982: step 460, loss 0.794708, acc 0.578125
2020-02-08T23:03:09.467108: step 461, loss 0.668764, acc 0.671875
2020-02-08T23:03:09.653622: step 462, loss 0.540999, acc 0.75
2020-02-08T23:03:09.851687: step 463, loss 0.422064, acc 0.75
2020-02-08T23:03:10.044367: step 464, loss 0.535199, acc 0.671875
2020-02-08T23:03:10.244891: step 465, loss 0.619532, acc 0.65625
2020-02-08T23:03:10.456152: step 466, loss 0.553282, acc 0.6875
2020-02-08T23:03:10.645024: step 467, loss 0.634307, acc 0.640625
2020-02-08T23:03:10.847451: step 468, loss 0.515156, acc 0.75
2020-02-08T23:03:11.029843: step 469, loss 0.58913, acc 0.75
2020-02-08T23:03:11.227210: step 470, loss 0.481041, acc 0.75
2020-02-08T23:03:11.429331: step 471, loss 0.63079, acc 0.71875
2020-02-08T23:03:11.643552: step 472, loss 0.641338, acc 0.65625
2020-02-08T23:03:11.861563: step 473, loss 0.745201, acc 0.578125
2020-02-08T23:03:12.053480: step 474, loss 0.612569, acc 0.703125
2020-02-08T23:03:12.265917: step 475, loss 0.704022, acc 0.625
2020-02-08T23:03:12.477918: step 476, loss 0.650552, acc 0.6875
2020-02-08T23:03:12.651237: step 477, loss 0.614963, acc 0.6875
2020-02-08T23:03:12.862026: step 478, loss 0.695862, acc 0.75
2020-02-08T23:03:13.021220: step 479, loss 0.51633, acc 0.71875
2020-02-08T23:03:13.240653: step 480, loss 0.601652, acc 0.625
2020-02-08T23:03:13.392401: step 481, loss 0.613585, acc 0.671875
2020-02-08T23:03:13.613576: step 482, loss 0.546891, acc 0.75
2020-02-08T23:03:13.817715: step 483, loss 0.583723, acc 0.625
2020-02-08T23:03:14.157810: step 484, loss 0.675513, acc 0.640625
2020-02-08T23:03:14.384675: step 485, loss 0.783255, acc 0.578125
2020-02-08T23:03:14.612220: step 486, loss 0.620985, acc 0.6875
2020-02-08T23:03:14.776434: step 487, loss 0.636617, acc 0.671875
2020-02-08T23:03:14.976893: step 488, loss 0.457378, acc 0.734375
2020-02-08T23:03:15.172773: step 489, loss 0.549402, acc 0.65625
2020-02-08T23:03:15.379612: step 490, loss 0.762488, acc 0.609375
2020-02-08T23:03:15.582276: step 491, loss 0.532003, acc 0.75
2020-02-08T23:03:15.796764: step 492, loss 0.661689, acc 0.671875
2020-02-08T23:03:16.014053: step 493, loss 0.706861, acc 0.640625
2020-02-08T23:03:16.229192: step 494, loss 0.650959, acc 0.6875
2020-02-08T23:03:16.398060: step 495, loss 0.468623, acc 0.8125
2020-02-08T23:03:16.609125: step 496, loss 0.666462, acc 0.625
2020-02-08T23:03:16.787481: step 497, loss 0.516844, acc 0.703125
2020-02-08T23:03:16.997357: step 498, loss 0.478042, acc 0.71875
2020-02-08T23:03:17.165889: step 499, loss 0.537216, acc 0.75
2020-02-08T23:03:17.368709: step 500, loss 0.606408, acc 0.65625

Evaluation:
2020-02-08T23:03:17.760592: step 500, loss 0.619652, acc 0.654784

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-500

2020-02-08T23:03:19.348787: step 501, loss 0.586493, acc 0.671875
2020-02-08T23:03:19.546753: step 502, loss 0.624896, acc 0.71875
2020-02-08T23:03:19.744418: step 503, loss 0.61177, acc 0.671875
2020-02-08T23:03:19.934259: step 504, loss 0.54304, acc 0.6875
2020-02-08T23:03:20.117282: step 505, loss 0.474941, acc 0.796875
2020-02-08T23:03:20.295938: step 506, loss 0.741028, acc 0.640625
2020-02-08T23:03:20.470246: step 507, loss 0.659, acc 0.703125
2020-02-08T23:03:20.658192: step 508, loss 0.546271, acc 0.75
2020-02-08T23:03:20.847408: step 509, loss 0.637659, acc 0.703125
2020-02-08T23:03:21.038786: step 510, loss 0.513497, acc 0.75
2020-02-08T23:03:21.227425: step 511, loss 0.614838, acc 0.65625
2020-02-08T23:03:21.452871: step 512, loss 0.568129, acc 0.6875
2020-02-08T23:03:21.655333: step 513, loss 0.548498, acc 0.71875
2020-02-08T23:03:21.883031: step 514, loss 0.658143, acc 0.671875
2020-02-08T23:03:22.101985: step 515, loss 0.639374, acc 0.71875
2020-02-08T23:03:22.302606: step 516, loss 0.449863, acc 0.828125
2020-02-08T23:03:22.523607: step 517, loss 0.515652, acc 0.734375
2020-02-08T23:03:22.727365: step 518, loss 0.464739, acc 0.75
2020-02-08T23:03:22.938148: step 519, loss 0.581294, acc 0.78125
2020-02-08T23:03:23.165623: step 520, loss 0.674829, acc 0.6875
2020-02-08T23:03:23.549861: step 521, loss 0.59881, acc 0.65625
2020-02-08T23:03:23.782655: step 522, loss 0.432724, acc 0.75
2020-02-08T23:03:23.971377: step 523, loss 0.57132, acc 0.71875
2020-02-08T23:03:24.183443: step 524, loss 0.500325, acc 0.734375
2020-02-08T23:03:24.403386: step 525, loss 0.651874, acc 0.671875
2020-02-08T23:03:24.603279: step 526, loss 0.532621, acc 0.734375
2020-02-08T23:03:24.821158: step 527, loss 0.515945, acc 0.75
2020-02-08T23:03:25.047311: step 528, loss 0.516516, acc 0.71875
2020-02-08T23:03:25.273866: step 529, loss 0.687014, acc 0.6875
2020-02-08T23:03:25.487010: step 530, loss 0.602631, acc 0.6875
2020-02-08T23:03:25.715367: step 531, loss 0.658316, acc 0.671875
2020-02-08T23:03:25.938688: step 532, loss 0.55684, acc 0.703125
2020-02-08T23:03:26.175987: step 533, loss 0.529026, acc 0.6875
2020-02-08T23:03:26.383982: step 534, loss 0.562688, acc 0.6875
2020-02-08T23:03:26.577261: step 535, loss 0.371743, acc 0.859375
2020-02-08T23:03:26.827273: step 536, loss 0.647713, acc 0.734375
2020-02-08T23:03:27.098590: step 537, loss 0.721027, acc 0.671875
2020-02-08T23:03:27.324363: step 538, loss 0.66807, acc 0.671875
2020-02-08T23:03:27.504186: step 539, loss 0.58009, acc 0.640625
2020-02-08T23:03:27.684697: step 540, loss 0.495226, acc 0.75
2020-02-08T23:03:27.886497: step 541, loss 0.569905, acc 0.6875
2020-02-08T23:03:28.070928: step 542, loss 0.588474, acc 0.6875
2020-02-08T23:03:28.288933: step 543, loss 0.702279, acc 0.59375
2020-02-08T23:03:28.505625: step 544, loss 0.658833, acc 0.6875
2020-02-08T23:03:28.670186: step 545, loss 0.631572, acc 0.703125
2020-02-08T23:03:28.866005: step 546, loss 0.645639, acc 0.671875
2020-02-08T23:03:29.088220: step 547, loss 0.449292, acc 0.796875
2020-02-08T23:03:29.313834: step 548, loss 0.53047, acc 0.75
2020-02-08T23:03:29.503960: step 549, loss 0.529888, acc 0.75
2020-02-08T23:03:29.667185: step 550, loss 0.640467, acc 0.703125
2020-02-08T23:03:29.880166: step 551, loss 0.50023, acc 0.734375
2020-02-08T23:03:30.091581: step 552, loss 0.789784, acc 0.578125
2020-02-08T23:03:30.304346: step 553, loss 0.430123, acc 0.8125
2020-02-08T23:03:30.515005: step 554, loss 0.537943, acc 0.765625
2020-02-08T23:03:30.719574: step 555, loss 0.583596, acc 0.703125
2020-02-08T23:03:30.940007: step 556, loss 0.590811, acc 0.703125
2020-02-08T23:03:31.156769: step 557, loss 0.590589, acc 0.75
2020-02-08T23:03:31.370907: step 558, loss 0.565448, acc 0.703125
2020-02-08T23:03:31.651723: step 559, loss 0.510117, acc 0.75
2020-02-08T23:03:31.836479: step 560, loss 0.650773, acc 0.703125
2020-02-08T23:03:32.041295: step 561, loss 0.616668, acc 0.703125
2020-02-08T23:03:32.254748: step 562, loss 0.498091, acc 0.734375
2020-02-08T23:03:32.474030: step 563, loss 0.536833, acc 0.671875
2020-02-08T23:03:32.687784: step 564, loss 0.52386, acc 0.703125
2020-02-08T23:03:32.891214: step 565, loss 0.607709, acc 0.6875
2020-02-08T23:03:33.112497: step 566, loss 0.496339, acc 0.78125
2020-02-08T23:03:33.331700: step 567, loss 0.609996, acc 0.578125
2020-02-08T23:03:33.505532: step 568, loss 0.584172, acc 0.71875
2020-02-08T23:03:33.759554: step 569, loss 0.584229, acc 0.703125
2020-02-08T23:03:33.916842: step 570, loss 0.596123, acc 0.703125
2020-02-08T23:03:34.113969: step 571, loss 0.520954, acc 0.796875
2020-02-08T23:03:34.300651: step 572, loss 0.729158, acc 0.578125
2020-02-08T23:03:34.506351: step 573, loss 0.421416, acc 0.765625
2020-02-08T23:03:34.699263: step 574, loss 0.543855, acc 0.671875
2020-02-08T23:03:34.909156: step 575, loss 0.556977, acc 0.6875
2020-02-08T23:03:35.128571: step 576, loss 0.716307, acc 0.5625
2020-02-08T23:03:35.299258: step 577, loss 0.603259, acc 0.6875
2020-02-08T23:03:35.516291: step 578, loss 0.653322, acc 0.65625
2020-02-08T23:03:35.714729: step 579, loss 0.583676, acc 0.734375
2020-02-08T23:03:35.908945: step 580, loss 0.586536, acc 0.71875
2020-02-08T23:03:36.100632: step 581, loss 0.586328, acc 0.671875
2020-02-08T23:03:36.307026: step 582, loss 0.673625, acc 0.640625
2020-02-08T23:03:36.508031: step 583, loss 0.575457, acc 0.6875
2020-02-08T23:03:36.701349: step 584, loss 0.532819, acc 0.796875
2020-02-08T23:03:36.882810: step 585, loss 0.511432, acc 0.734375
2020-02-08T23:03:37.084586: step 586, loss 0.636728, acc 0.703125
2020-02-08T23:03:37.278080: step 587, loss 0.595326, acc 0.71875
2020-02-08T23:03:37.480781: step 588, loss 0.531307, acc 0.765625
2020-02-08T23:03:37.671763: step 589, loss 0.51181, acc 0.75
2020-02-08T23:03:37.859552: step 590, loss 0.812963, acc 0.53125
2020-02-08T23:03:38.062052: step 591, loss 0.643893, acc 0.71875
2020-02-08T23:03:38.252966: step 592, loss 0.532835, acc 0.765625
2020-02-08T23:03:38.440332: step 593, loss 0.511786, acc 0.796875
2020-02-08T23:03:38.624603: step 594, loss 0.478167, acc 0.75
2020-02-08T23:03:38.818725: step 595, loss 0.665871, acc 0.6875
2020-02-08T23:03:39.007302: step 596, loss 0.580133, acc 0.71875
2020-02-08T23:03:39.200653: step 597, loss 0.611402, acc 0.734375
2020-02-08T23:03:39.387536: step 598, loss 0.424469, acc 0.8125
2020-02-08T23:03:39.575449: step 599, loss 0.739857, acc 0.71875
2020-02-08T23:03:39.767575: step 600, loss 0.535321, acc 0.716667

Evaluation:
2020-02-08T23:03:40.104774: step 600, loss 0.634135, acc 0.624765

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-600

2020-02-08T23:03:41.679674: step 601, loss 0.538573, acc 0.78125
2020-02-08T23:03:41.861407: step 602, loss 0.522149, acc 0.734375
2020-02-08T23:03:42.052207: step 603, loss 0.688785, acc 0.59375
2020-02-08T23:03:42.249726: step 604, loss 0.461099, acc 0.828125
2020-02-08T23:03:42.443669: step 605, loss 0.470925, acc 0.734375
2020-02-08T23:03:42.644398: step 606, loss 0.52959, acc 0.734375
2020-02-08T23:03:42.837372: step 607, loss 0.526641, acc 0.71875
2020-02-08T23:03:43.026202: step 608, loss 0.54717, acc 0.734375
2020-02-08T23:03:43.226112: step 609, loss 0.685784, acc 0.609375
2020-02-08T23:03:43.418688: step 610, loss 0.407903, acc 0.828125
2020-02-08T23:03:43.609777: step 611, loss 0.465473, acc 0.8125
2020-02-08T23:03:43.814002: step 612, loss 0.505818, acc 0.734375
2020-02-08T23:03:44.024784: step 613, loss 0.588757, acc 0.734375
2020-02-08T23:03:44.222083: step 614, loss 0.562993, acc 0.703125
2020-02-08T23:03:44.415377: step 615, loss 0.423892, acc 0.8125
2020-02-08T23:03:44.612589: step 616, loss 0.427709, acc 0.796875
2020-02-08T23:03:44.802222: step 617, loss 0.608676, acc 0.6875
2020-02-08T23:03:44.994231: step 618, loss 0.577826, acc 0.765625
2020-02-08T23:03:45.203678: step 619, loss 0.480326, acc 0.734375
2020-02-08T23:03:45.374094: step 620, loss 0.520026, acc 0.703125
2020-02-08T23:03:45.610441: step 621, loss 0.593565, acc 0.75
2020-02-08T23:03:45.800917: step 622, loss 0.478626, acc 0.78125
2020-02-08T23:03:45.992854: step 623, loss 0.440876, acc 0.84375
2020-02-08T23:03:46.181110: step 624, loss 0.558711, acc 0.671875
2020-02-08T23:03:46.376558: step 625, loss 0.482245, acc 0.765625
2020-02-08T23:03:46.556118: step 626, loss 0.596375, acc 0.71875
2020-02-08T23:03:46.754393: step 627, loss 0.405698, acc 0.734375
2020-02-08T23:03:46.955895: step 628, loss 0.533063, acc 0.75
2020-02-08T23:03:47.150191: step 629, loss 0.594971, acc 0.734375
2020-02-08T23:03:47.338096: step 630, loss 0.722163, acc 0.65625
2020-02-08T23:03:47.519909: step 631, loss 0.463045, acc 0.828125
2020-02-08T23:03:47.707938: step 632, loss 0.541475, acc 0.71875
2020-02-08T23:03:47.892013: step 633, loss 0.406396, acc 0.84375
2020-02-08T23:03:48.096720: step 634, loss 0.468762, acc 0.765625
2020-02-08T23:03:48.283609: step 635, loss 0.60107, acc 0.71875
2020-02-08T23:03:48.490332: step 636, loss 0.505165, acc 0.78125
2020-02-08T23:03:48.676149: step 637, loss 0.600885, acc 0.6875
2020-02-08T23:03:48.858198: step 638, loss 0.399983, acc 0.796875
2020-02-08T23:03:49.042987: step 639, loss 0.652745, acc 0.6875
2020-02-08T23:03:49.236613: step 640, loss 0.412936, acc 0.8125
2020-02-08T23:03:49.427458: step 641, loss 0.576299, acc 0.703125
2020-02-08T23:03:49.621440: step 642, loss 0.50416, acc 0.734375
2020-02-08T23:03:49.811166: step 643, loss 0.461999, acc 0.765625
2020-02-08T23:03:50.010626: step 644, loss 0.679606, acc 0.671875
2020-02-08T23:03:50.198836: step 645, loss 0.524099, acc 0.734375
2020-02-08T23:03:50.383787: step 646, loss 0.508894, acc 0.703125
2020-02-08T23:03:50.574056: step 647, loss 0.485181, acc 0.734375
2020-02-08T23:03:50.773588: step 648, loss 0.544419, acc 0.75
2020-02-08T23:03:50.955708: step 649, loss 0.538362, acc 0.6875
2020-02-08T23:03:51.141240: step 650, loss 0.468869, acc 0.78125
2020-02-08T23:03:51.323339: step 651, loss 0.628153, acc 0.671875
2020-02-08T23:03:51.511153: step 652, loss 0.45993, acc 0.71875
2020-02-08T23:03:51.698060: step 653, loss 0.471636, acc 0.8125
2020-02-08T23:03:51.885841: step 654, loss 0.445102, acc 0.765625
2020-02-08T23:03:52.067959: step 655, loss 0.593281, acc 0.671875
2020-02-08T23:03:52.260712: step 656, loss 0.493349, acc 0.78125
2020-02-08T23:03:52.449460: step 657, loss 0.470741, acc 0.8125
2020-02-08T23:03:52.635909: step 658, loss 0.481352, acc 0.796875
2020-02-08T23:03:52.818745: step 659, loss 0.555981, acc 0.75
2020-02-08T23:03:53.013652: step 660, loss 0.439404, acc 0.796875
2020-02-08T23:03:53.206057: step 661, loss 0.524888, acc 0.734375
2020-02-08T23:03:53.403203: step 662, loss 0.418368, acc 0.796875
2020-02-08T23:03:53.594452: step 663, loss 0.567559, acc 0.734375
2020-02-08T23:03:53.783116: step 664, loss 0.468857, acc 0.75
2020-02-08T23:03:54.036884: step 665, loss 0.582894, acc 0.703125
2020-02-08T23:03:54.209166: step 666, loss 0.47567, acc 0.734375
2020-02-08T23:03:54.396245: step 667, loss 0.596361, acc 0.6875
2020-02-08T23:03:54.576551: step 668, loss 0.438113, acc 0.78125
2020-02-08T23:03:54.767391: step 669, loss 0.548432, acc 0.6875
2020-02-08T23:03:54.967863: step 670, loss 0.522963, acc 0.671875
2020-02-08T23:03:55.168678: step 671, loss 0.424067, acc 0.75
2020-02-08T23:03:55.353575: step 672, loss 0.38076, acc 0.859375
2020-02-08T23:03:55.537509: step 673, loss 0.499876, acc 0.78125
2020-02-08T23:03:55.729757: step 674, loss 0.479486, acc 0.734375
2020-02-08T23:03:55.920221: step 675, loss 0.627531, acc 0.703125
2020-02-08T23:03:56.119272: step 676, loss 0.585695, acc 0.734375
2020-02-08T23:03:56.313328: step 677, loss 0.531039, acc 0.765625
2020-02-08T23:03:56.504091: step 678, loss 0.508125, acc 0.75
2020-02-08T23:03:56.711267: step 679, loss 0.444039, acc 0.796875
2020-02-08T23:03:56.903421: step 680, loss 0.696591, acc 0.546875
2020-02-08T23:03:57.104656: step 681, loss 0.526803, acc 0.734375
2020-02-08T23:03:57.315369: step 682, loss 0.629361, acc 0.6875
2020-02-08T23:03:57.521592: step 683, loss 0.569501, acc 0.75
2020-02-08T23:03:57.770329: step 684, loss 0.477008, acc 0.734375
2020-02-08T23:03:57.938831: step 685, loss 0.639302, acc 0.75
2020-02-08T23:03:58.170253: step 686, loss 0.470937, acc 0.734375
2020-02-08T23:03:58.381723: step 687, loss 0.504671, acc 0.765625
2020-02-08T23:03:58.585554: step 688, loss 0.639759, acc 0.703125
2020-02-08T23:03:58.802408: step 689, loss 0.503793, acc 0.765625
2020-02-08T23:03:59.010209: step 690, loss 0.457956, acc 0.796875
2020-02-08T23:03:59.216561: step 691, loss 0.355403, acc 0.90625
2020-02-08T23:03:59.428623: step 692, loss 0.598712, acc 0.71875
2020-02-08T23:03:59.636867: step 693, loss 0.40782, acc 0.8125
2020-02-08T23:03:59.845105: step 694, loss 0.393859, acc 0.828125
2020-02-08T23:04:00.053953: step 695, loss 0.445942, acc 0.796875
2020-02-08T23:04:00.267465: step 696, loss 0.512018, acc 0.765625
2020-02-08T23:04:00.441646: step 697, loss 0.427703, acc 0.765625
2020-02-08T23:04:00.651387: step 698, loss 0.45592, acc 0.765625
2020-02-08T23:04:00.858240: step 699, loss 0.584467, acc 0.71875
2020-02-08T23:04:01.059520: step 700, loss 0.426017, acc 0.8125

Evaluation:
2020-02-08T23:04:01.457067: step 700, loss 0.605145, acc 0.666041

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-700

2020-02-08T23:04:03.147305: step 701, loss 0.470719, acc 0.765625
2020-02-08T23:04:03.322153: step 702, loss 0.58643, acc 0.6875
2020-02-08T23:04:03.505931: step 703, loss 0.561475, acc 0.703125
2020-02-08T23:04:03.688067: step 704, loss 0.521734, acc 0.6875
2020-02-08T23:04:03.877435: step 705, loss 0.440968, acc 0.796875
2020-02-08T23:04:04.067393: step 706, loss 0.604578, acc 0.71875
2020-02-08T23:04:04.253574: step 707, loss 0.440774, acc 0.8125
2020-02-08T23:04:04.434219: step 708, loss 0.486075, acc 0.78125
2020-02-08T23:04:04.624474: step 709, loss 0.693686, acc 0.625
2020-02-08T23:04:04.873449: step 710, loss 0.509408, acc 0.75
2020-02-08T23:04:05.098940: step 711, loss 0.412381, acc 0.78125
2020-02-08T23:04:05.286321: step 712, loss 0.499166, acc 0.78125
2020-02-08T23:04:05.478061: step 713, loss 0.49103, acc 0.796875
2020-02-08T23:04:05.663204: step 714, loss 0.484906, acc 0.734375
2020-02-08T23:04:05.849511: step 715, loss 0.525826, acc 0.734375
2020-02-08T23:04:06.035119: step 716, loss 0.475058, acc 0.828125
2020-02-08T23:04:06.214418: step 717, loss 0.581525, acc 0.765625
2020-02-08T23:04:06.396281: step 718, loss 0.611482, acc 0.65625
2020-02-08T23:04:06.575945: step 719, loss 0.352879, acc 0.859375
2020-02-08T23:04:06.778777: step 720, loss 0.524293, acc 0.734375
2020-02-08T23:04:07.043459: step 721, loss 0.490854, acc 0.75
2020-02-08T23:04:07.232526: step 722, loss 0.359346, acc 0.859375
2020-02-08T23:04:07.426363: step 723, loss 0.512629, acc 0.765625
2020-02-08T23:04:07.609597: step 724, loss 0.471959, acc 0.78125
2020-02-08T23:04:07.798158: step 725, loss 0.621428, acc 0.671875
2020-02-08T23:04:07.992520: step 726, loss 0.450702, acc 0.796875
2020-02-08T23:04:08.191641: step 727, loss 0.544536, acc 0.703125
2020-02-08T23:04:08.415604: step 728, loss 0.490743, acc 0.828125
2020-02-08T23:04:08.587051: step 729, loss 0.42231, acc 0.78125
2020-02-08T23:04:08.767025: step 730, loss 0.49736, acc 0.828125
2020-02-08T23:04:08.973203: step 731, loss 0.500067, acc 0.703125
2020-02-08T23:04:09.188313: step 732, loss 0.547402, acc 0.78125
2020-02-08T23:04:09.425157: step 733, loss 0.460955, acc 0.78125
2020-02-08T23:04:09.640477: step 734, loss 0.488476, acc 0.78125
2020-02-08T23:04:09.843550: step 735, loss 0.486202, acc 0.734375
2020-02-08T23:04:09.991441: step 736, loss 0.505528, acc 0.765625
2020-02-08T23:04:10.132849: step 737, loss 0.561111, acc 0.75
2020-02-08T23:04:10.393868: step 738, loss 0.504999, acc 0.734375
2020-02-08T23:04:10.608572: step 739, loss 0.398085, acc 0.84375
2020-02-08T23:04:10.755508: step 740, loss 0.450245, acc 0.765625
2020-02-08T23:04:10.894653: step 741, loss 0.495322, acc 0.734375
2020-02-08T23:04:11.100460: step 742, loss 0.615199, acc 0.703125
2020-02-08T23:04:11.294153: step 743, loss 0.41521, acc 0.8125
2020-02-08T23:04:11.458467: step 744, loss 0.681166, acc 0.65625
2020-02-08T23:04:11.661212: step 745, loss 0.534616, acc 0.671875
2020-02-08T23:04:11.807100: step 746, loss 0.49747, acc 0.734375
2020-02-08T23:04:12.032436: step 747, loss 0.507422, acc 0.78125
2020-02-08T23:04:12.192080: step 748, loss 0.51988, acc 0.734375
2020-02-08T23:04:12.402367: step 749, loss 0.519888, acc 0.71875
2020-02-08T23:04:12.555342: step 750, loss 0.511612, acc 0.783333
2020-02-08T23:04:12.704641: step 751, loss 0.492739, acc 0.78125
2020-02-08T23:04:12.861854: step 752, loss 0.525343, acc 0.75
2020-02-08T23:04:13.000418: step 753, loss 0.506581, acc 0.75
2020-02-08T23:04:13.197228: step 754, loss 0.579231, acc 0.71875
2020-02-08T23:04:13.359071: step 755, loss 0.40755, acc 0.796875
2020-02-08T23:04:13.500753: step 756, loss 0.414922, acc 0.8125
2020-02-08T23:04:13.644374: step 757, loss 0.540744, acc 0.6875
2020-02-08T23:04:13.879252: step 758, loss 0.438686, acc 0.828125
2020-02-08T23:04:14.033172: step 759, loss 0.49628, acc 0.765625
2020-02-08T23:04:14.185046: step 760, loss 0.502159, acc 0.78125
2020-02-08T23:04:14.393469: step 761, loss 0.411562, acc 0.828125
2020-02-08T23:04:14.558403: step 762, loss 0.366706, acc 0.84375
2020-02-08T23:04:14.706000: step 763, loss 0.41871, acc 0.8125
2020-02-08T23:04:14.897582: step 764, loss 0.36686, acc 0.8125
2020-02-08T23:04:15.053543: step 765, loss 0.363245, acc 0.875
2020-02-08T23:04:15.201921: step 766, loss 0.469495, acc 0.765625
2020-02-08T23:04:15.405227: step 767, loss 0.358571, acc 0.875
2020-02-08T23:04:15.567735: step 768, loss 0.456234, acc 0.78125
2020-02-08T23:04:15.725946: step 769, loss 0.261492, acc 0.921875
2020-02-08T23:04:15.864745: step 770, loss 0.499894, acc 0.703125
2020-02-08T23:04:16.016885: step 771, loss 0.363164, acc 0.828125
2020-02-08T23:04:16.165414: step 772, loss 0.473426, acc 0.78125
2020-02-08T23:04:16.307543: step 773, loss 0.414779, acc 0.890625
2020-02-08T23:04:16.446318: step 774, loss 0.381365, acc 0.796875
2020-02-08T23:04:16.591697: step 775, loss 0.455375, acc 0.75
2020-02-08T23:04:16.730418: step 776, loss 0.368813, acc 0.875
2020-02-08T23:04:16.873159: step 777, loss 0.448818, acc 0.765625
2020-02-08T23:04:17.017846: step 778, loss 0.450734, acc 0.765625
2020-02-08T23:04:17.158566: step 779, loss 0.412678, acc 0.75
2020-02-08T23:04:17.303895: step 780, loss 0.531932, acc 0.671875
2020-02-08T23:04:17.441161: step 781, loss 0.526776, acc 0.8125
2020-02-08T23:04:17.597040: step 782, loss 0.400307, acc 0.796875
2020-02-08T23:04:17.732888: step 783, loss 0.369865, acc 0.84375
2020-02-08T23:04:17.872655: step 784, loss 0.463967, acc 0.796875
2020-02-08T23:04:18.014485: step 785, loss 0.360945, acc 0.8125
2020-02-08T23:04:18.155135: step 786, loss 0.381589, acc 0.84375
2020-02-08T23:04:18.289912: step 787, loss 0.45496, acc 0.796875
2020-02-08T23:04:18.427321: step 788, loss 0.435352, acc 0.828125
2020-02-08T23:04:18.566665: step 789, loss 0.494992, acc 0.734375
2020-02-08T23:04:18.704864: step 790, loss 0.420616, acc 0.8125
2020-02-08T23:04:18.841405: step 791, loss 0.411249, acc 0.828125
2020-02-08T23:04:18.978093: step 792, loss 0.500063, acc 0.734375
2020-02-08T23:04:19.115087: step 793, loss 0.430702, acc 0.828125
2020-02-08T23:04:19.246837: step 794, loss 0.443323, acc 0.78125
2020-02-08T23:04:19.384275: step 795, loss 0.388309, acc 0.8125
2020-02-08T23:04:19.519655: step 796, loss 0.518471, acc 0.734375
2020-02-08T23:04:19.661390: step 797, loss 0.380122, acc 0.8125
2020-02-08T23:04:19.831377: step 798, loss 0.503752, acc 0.734375
2020-02-08T23:04:20.028282: step 799, loss 0.442861, acc 0.78125
2020-02-08T23:04:20.171673: step 800, loss 0.515852, acc 0.78125

Evaluation:
2020-02-08T23:04:20.402026: step 800, loss 0.598961, acc 0.678236

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-800

2020-02-08T23:04:22.016374: step 801, loss 0.364424, acc 0.890625
2020-02-08T23:04:22.215515: step 802, loss 0.470413, acc 0.734375
2020-02-08T23:04:22.393061: step 803, loss 0.398514, acc 0.8125
2020-02-08T23:04:22.582231: step 804, loss 0.34904, acc 0.828125
2020-02-08T23:04:22.753337: step 805, loss 0.364445, acc 0.796875
2020-02-08T23:04:22.915680: step 806, loss 0.523803, acc 0.765625
2020-02-08T23:04:23.097832: step 807, loss 0.517993, acc 0.796875
2020-02-08T23:04:23.244203: step 808, loss 0.599345, acc 0.734375
2020-02-08T23:04:23.393199: step 809, loss 0.465332, acc 0.75
2020-02-08T23:04:23.545670: step 810, loss 0.37163, acc 0.8125
2020-02-08T23:04:23.682012: step 811, loss 0.415841, acc 0.859375
2020-02-08T23:04:23.829686: step 812, loss 0.478588, acc 0.78125
2020-02-08T23:04:24.012349: step 813, loss 0.391932, acc 0.828125
2020-02-08T23:04:24.164819: step 814, loss 0.396661, acc 0.828125
2020-02-08T23:04:24.301374: step 815, loss 0.52301, acc 0.75
2020-02-08T23:04:24.442479: step 816, loss 0.479526, acc 0.796875
2020-02-08T23:04:24.582092: step 817, loss 0.389514, acc 0.78125
2020-02-08T23:04:24.716397: step 818, loss 0.426276, acc 0.84375
2020-02-08T23:04:24.848731: step 819, loss 0.355837, acc 0.859375
2020-02-08T23:04:24.986155: step 820, loss 0.490456, acc 0.6875
2020-02-08T23:04:25.143982: step 821, loss 0.546968, acc 0.765625
2020-02-08T23:04:25.366143: step 822, loss 0.377002, acc 0.84375
2020-02-08T23:04:25.497874: step 823, loss 0.431159, acc 0.796875
2020-02-08T23:04:25.641092: step 824, loss 0.518345, acc 0.71875
2020-02-08T23:04:25.784431: step 825, loss 0.337403, acc 0.859375
2020-02-08T23:04:26.000227: step 826, loss 0.416273, acc 0.796875
2020-02-08T23:04:26.159564: step 827, loss 0.578096, acc 0.734375
2020-02-08T23:04:26.300125: step 828, loss 0.419293, acc 0.859375
2020-02-08T23:04:26.436015: step 829, loss 0.359638, acc 0.859375
2020-02-08T23:04:26.577025: step 830, loss 0.513672, acc 0.671875
2020-02-08T23:04:26.729359: step 831, loss 0.41194, acc 0.8125
2020-02-08T23:04:26.871125: step 832, loss 0.393171, acc 0.859375
2020-02-08T23:04:27.013306: step 833, loss 0.418245, acc 0.796875
2020-02-08T23:04:27.154929: step 834, loss 0.40342, acc 0.78125
2020-02-08T23:04:27.293627: step 835, loss 0.5429, acc 0.734375
2020-02-08T23:04:27.429174: step 836, loss 0.434698, acc 0.796875
2020-02-08T23:04:27.573205: step 837, loss 0.429228, acc 0.796875
2020-02-08T23:04:27.704648: step 838, loss 0.412498, acc 0.8125
2020-02-08T23:04:27.847681: step 839, loss 0.294009, acc 0.859375
2020-02-08T23:04:27.991358: step 840, loss 0.486776, acc 0.75
2020-02-08T23:04:28.138080: step 841, loss 0.508979, acc 0.765625
2020-02-08T23:04:28.270502: step 842, loss 0.616284, acc 0.765625
2020-02-08T23:04:28.414016: step 843, loss 0.407507, acc 0.8125
2020-02-08T23:04:28.556850: step 844, loss 0.517804, acc 0.78125
2020-02-08T23:04:28.691832: step 845, loss 0.4702, acc 0.765625
2020-02-08T23:04:28.826886: step 846, loss 0.347938, acc 0.84375
2020-02-08T23:04:28.965123: step 847, loss 0.538358, acc 0.6875
2020-02-08T23:04:29.104448: step 848, loss 0.419972, acc 0.8125
2020-02-08T23:04:29.242922: step 849, loss 0.399743, acc 0.84375
2020-02-08T23:04:29.384345: step 850, loss 0.422331, acc 0.796875
2020-02-08T23:04:29.522157: step 851, loss 0.337699, acc 0.875
2020-02-08T23:04:29.681848: step 852, loss 0.445861, acc 0.765625
2020-02-08T23:04:29.870691: step 853, loss 0.456156, acc 0.765625
2020-02-08T23:04:30.006845: step 854, loss 0.451542, acc 0.828125
2020-02-08T23:04:30.149808: step 855, loss 0.340983, acc 0.859375
2020-02-08T23:04:30.287205: step 856, loss 0.460427, acc 0.796875
2020-02-08T23:04:30.432135: step 857, loss 0.444238, acc 0.78125
2020-02-08T23:04:30.571823: step 858, loss 0.429388, acc 0.8125
2020-02-08T23:04:30.716980: step 859, loss 0.395712, acc 0.84375
2020-02-08T23:04:30.857435: step 860, loss 0.398916, acc 0.8125
2020-02-08T23:04:31.005626: step 861, loss 0.572163, acc 0.6875
2020-02-08T23:04:31.147204: step 862, loss 0.484639, acc 0.734375
2020-02-08T23:04:31.277553: step 863, loss 0.39967, acc 0.8125
2020-02-08T23:04:31.423096: step 864, loss 0.535599, acc 0.75
2020-02-08T23:04:31.564285: step 865, loss 0.409982, acc 0.8125
2020-02-08T23:04:31.706451: step 866, loss 0.452318, acc 0.859375
2020-02-08T23:04:31.852459: step 867, loss 0.419729, acc 0.828125
2020-02-08T23:04:31.989495: step 868, loss 0.541649, acc 0.78125
2020-02-08T23:04:32.132593: step 869, loss 0.31541, acc 0.875
2020-02-08T23:04:32.300403: step 870, loss 0.416279, acc 0.78125
2020-02-08T23:04:32.527178: step 871, loss 0.576499, acc 0.71875
2020-02-08T23:04:32.757532: step 872, loss 0.514678, acc 0.78125
2020-02-08T23:04:32.921217: step 873, loss 0.426108, acc 0.8125
2020-02-08T23:04:33.092214: step 874, loss 0.562856, acc 0.71875
2020-02-08T23:04:33.257048: step 875, loss 0.560397, acc 0.71875
2020-02-08T23:04:33.415664: step 876, loss 0.4363, acc 0.8125
2020-02-08T23:04:33.587469: step 877, loss 0.402174, acc 0.859375
2020-02-08T23:04:33.768432: step 878, loss 0.434602, acc 0.84375
2020-02-08T23:04:33.911145: step 879, loss 0.675584, acc 0.734375
2020-02-08T23:04:34.153699: step 880, loss 0.511883, acc 0.6875
2020-02-08T23:04:34.313078: step 881, loss 0.380304, acc 0.828125
2020-02-08T23:04:34.472192: step 882, loss 0.514085, acc 0.796875
2020-02-08T23:04:34.653040: step 883, loss 0.494258, acc 0.78125
2020-02-08T23:04:34.793705: step 884, loss 0.404493, acc 0.828125
2020-02-08T23:04:34.954281: step 885, loss 0.407098, acc 0.796875
2020-02-08T23:04:35.092593: step 886, loss 0.392264, acc 0.859375
2020-02-08T23:04:35.244008: step 887, loss 0.42222, acc 0.84375
2020-02-08T23:04:35.422190: step 888, loss 0.646973, acc 0.734375
2020-02-08T23:04:35.573673: step 889, loss 0.355557, acc 0.828125
2020-02-08T23:04:35.729828: step 890, loss 0.312834, acc 0.890625
2020-02-08T23:04:35.917700: step 891, loss 0.385081, acc 0.828125
2020-02-08T23:04:36.080402: step 892, loss 0.518162, acc 0.734375
2020-02-08T23:04:36.236997: step 893, loss 0.466388, acc 0.765625
2020-02-08T23:04:36.395846: step 894, loss 0.671407, acc 0.609375
2020-02-08T23:04:36.588640: step 895, loss 0.34584, acc 0.859375
2020-02-08T23:04:36.745135: step 896, loss 0.346826, acc 0.84375
2020-02-08T23:04:36.905946: step 897, loss 0.36669, acc 0.84375
2020-02-08T23:04:37.064564: step 898, loss 0.361226, acc 0.828125
2020-02-08T23:04:37.246560: step 899, loss 0.360568, acc 0.84375
2020-02-08T23:04:37.392871: step 900, loss 0.487211, acc 0.8

Evaluation:
2020-02-08T23:04:37.652881: step 900, loss 0.606257, acc 0.668856

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-900

2020-02-08T23:04:39.201212: step 901, loss 0.320177, acc 0.828125
2020-02-08T23:04:39.342105: step 902, loss 0.389201, acc 0.78125
2020-02-08T23:04:39.493791: step 903, loss 0.337274, acc 0.875
2020-02-08T23:04:39.661970: step 904, loss 0.314446, acc 0.859375
2020-02-08T23:04:39.813040: step 905, loss 0.439432, acc 0.78125
2020-02-08T23:04:39.983817: step 906, loss 0.376141, acc 0.796875
2020-02-08T23:04:40.164451: step 907, loss 0.426979, acc 0.765625
2020-02-08T23:04:40.310639: step 908, loss 0.315655, acc 0.84375
2020-02-08T23:04:40.466204: step 909, loss 0.337427, acc 0.84375
2020-02-08T23:04:40.626281: step 910, loss 0.519594, acc 0.75
2020-02-08T23:04:40.791834: step 911, loss 0.376564, acc 0.875
2020-02-08T23:04:40.942780: step 912, loss 0.333236, acc 0.84375
2020-02-08T23:04:41.096777: step 913, loss 0.509126, acc 0.75
2020-02-08T23:04:41.250508: step 914, loss 0.338392, acc 0.84375
2020-02-08T23:04:41.408689: step 915, loss 0.442894, acc 0.796875
2020-02-08T23:04:41.610287: step 916, loss 0.284546, acc 0.875
2020-02-08T23:04:41.781003: step 917, loss 0.341432, acc 0.859375
2020-02-08T23:04:42.001282: step 918, loss 0.398462, acc 0.765625
2020-02-08T23:04:42.174736: step 919, loss 0.190515, acc 0.9375
2020-02-08T23:04:42.345455: step 920, loss 0.33256, acc 0.828125
2020-02-08T23:04:42.514168: step 921, loss 0.432187, acc 0.828125
2020-02-08T23:04:42.701207: step 922, loss 0.307741, acc 0.890625
2020-02-08T23:04:42.867734: step 923, loss 0.334573, acc 0.875
2020-02-08T23:04:43.001794: step 924, loss 0.323261, acc 0.859375
2020-02-08T23:04:43.149218: step 925, loss 0.407444, acc 0.875
2020-02-08T23:04:43.307663: step 926, loss 0.525108, acc 0.8125
2020-02-08T23:04:43.463082: step 927, loss 0.435114, acc 0.84375
2020-02-08T23:04:43.625713: step 928, loss 0.302453, acc 0.890625
2020-02-08T23:04:43.767527: step 929, loss 0.328443, acc 0.859375
2020-02-08T23:04:43.923473: step 930, loss 0.511375, acc 0.78125
2020-02-08T23:04:44.071684: step 931, loss 0.479348, acc 0.75
2020-02-08T23:04:44.370591: step 932, loss 0.40678, acc 0.8125
2020-02-08T23:04:44.523063: step 933, loss 0.354066, acc 0.859375
2020-02-08T23:04:44.675190: step 934, loss 0.464601, acc 0.75
2020-02-08T23:04:44.833132: step 935, loss 0.293568, acc 0.875
2020-02-08T23:04:44.976735: step 936, loss 0.387919, acc 0.796875
2020-02-08T23:04:45.110496: step 937, loss 0.466651, acc 0.734375
2020-02-08T23:04:45.244752: step 938, loss 0.325254, acc 0.828125
2020-02-08T23:04:45.392803: step 939, loss 0.347114, acc 0.859375
2020-02-08T23:04:45.603717: step 940, loss 0.308072, acc 0.890625
2020-02-08T23:04:45.756105: step 941, loss 0.368673, acc 0.859375
2020-02-08T23:04:45.911177: step 942, loss 0.323045, acc 0.890625
2020-02-08T23:04:46.090253: step 943, loss 0.33171, acc 0.890625
2020-02-08T23:04:46.225566: step 944, loss 0.340693, acc 0.90625
2020-02-08T23:04:46.362402: step 945, loss 0.250531, acc 0.953125
2020-02-08T23:04:46.492039: step 946, loss 0.423882, acc 0.8125
2020-02-08T23:04:46.641634: step 947, loss 0.353315, acc 0.859375
2020-02-08T23:04:46.793333: step 948, loss 0.44251, acc 0.828125
2020-02-08T23:04:47.032726: step 949, loss 0.252002, acc 0.890625
2020-02-08T23:04:47.217684: step 950, loss 0.297912, acc 0.875
2020-02-08T23:04:47.530080: step 951, loss 0.24336, acc 0.921875
2020-02-08T23:04:47.739874: step 952, loss 0.252007, acc 0.921875
2020-02-08T23:04:47.955120: step 953, loss 0.42871, acc 0.828125
2020-02-08T23:04:48.220738: step 954, loss 0.415306, acc 0.8125
2020-02-08T23:04:48.408198: step 955, loss 0.336552, acc 0.859375
2020-02-08T23:04:48.634885: step 956, loss 0.393087, acc 0.796875
2020-02-08T23:04:48.875692: step 957, loss 0.474929, acc 0.78125
2020-02-08T23:04:49.068325: step 958, loss 0.31163, acc 0.875
2020-02-08T23:04:49.245547: step 959, loss 0.51009, acc 0.734375
2020-02-08T23:04:49.423071: step 960, loss 0.419618, acc 0.875
2020-02-08T23:04:49.598692: step 961, loss 0.356229, acc 0.859375
2020-02-08T23:04:49.778300: step 962, loss 0.279695, acc 0.890625
2020-02-08T23:04:49.974459: step 963, loss 0.352045, acc 0.84375
2020-02-08T23:04:50.167106: step 964, loss 0.411547, acc 0.828125
2020-02-08T23:04:50.343130: step 965, loss 0.362649, acc 0.875
2020-02-08T23:04:50.519057: step 966, loss 0.444219, acc 0.8125
2020-02-08T23:04:50.710048: step 967, loss 0.345751, acc 0.859375
2020-02-08T23:04:50.900430: step 968, loss 0.442238, acc 0.75
2020-02-08T23:04:51.085721: step 969, loss 0.477545, acc 0.796875
2020-02-08T23:04:51.276057: step 970, loss 0.397201, acc 0.796875
2020-02-08T23:04:51.475059: step 971, loss 0.45066, acc 0.796875
2020-02-08T23:04:51.655753: step 972, loss 0.272641, acc 0.90625
2020-02-08T23:04:51.852515: step 973, loss 0.389564, acc 0.8125
2020-02-08T23:04:52.066929: step 974, loss 0.414622, acc 0.796875
2020-02-08T23:04:52.271655: step 975, loss 0.339132, acc 0.84375
2020-02-08T23:04:52.466029: step 976, loss 0.366764, acc 0.859375
2020-02-08T23:04:52.665852: step 977, loss 0.616897, acc 0.734375
2020-02-08T23:04:52.867195: step 978, loss 0.218552, acc 0.9375
2020-02-08T23:04:53.059593: step 979, loss 0.294623, acc 0.90625
2020-02-08T23:04:53.261376: step 980, loss 0.38184, acc 0.8125
2020-02-08T23:04:53.460527: step 981, loss 0.289188, acc 0.859375
2020-02-08T23:04:53.657910: step 982, loss 0.507177, acc 0.75
2020-02-08T23:04:53.863361: step 983, loss 0.397221, acc 0.84375
2020-02-08T23:04:54.057766: step 984, loss 0.311081, acc 0.875
2020-02-08T23:04:54.256075: step 985, loss 0.326769, acc 0.890625
2020-02-08T23:04:54.442968: step 986, loss 0.27481, acc 0.90625
2020-02-08T23:04:54.652404: step 987, loss 0.384264, acc 0.8125
2020-02-08T23:04:54.850910: step 988, loss 0.385711, acc 0.796875
2020-02-08T23:04:55.046634: step 989, loss 0.43282, acc 0.75
2020-02-08T23:04:55.242475: step 990, loss 0.493111, acc 0.78125
2020-02-08T23:04:55.433022: step 991, loss 0.381962, acc 0.796875
2020-02-08T23:04:55.627195: step 992, loss 0.349942, acc 0.84375
2020-02-08T23:04:55.823420: step 993, loss 0.381984, acc 0.828125
2020-02-08T23:04:56.018851: step 994, loss 0.423064, acc 0.765625
2020-02-08T23:04:56.236070: step 995, loss 0.352777, acc 0.859375
2020-02-08T23:04:56.423057: step 996, loss 0.416094, acc 0.8125
2020-02-08T23:04:56.628949: step 997, loss 0.460383, acc 0.828125
2020-02-08T23:04:56.814458: step 998, loss 0.370433, acc 0.8125
2020-02-08T23:04:57.018816: step 999, loss 0.454836, acc 0.796875
2020-02-08T23:04:57.206413: step 1000, loss 0.36163, acc 0.828125

Evaluation:
2020-02-08T23:04:57.539633: step 1000, loss 0.609956, acc 0.690432

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1000

2020-02-08T23:04:59.129797: step 1001, loss 0.307017, acc 0.875
2020-02-08T23:04:59.308454: step 1002, loss 0.42009, acc 0.8125
2020-02-08T23:04:59.474262: step 1003, loss 0.431712, acc 0.796875
2020-02-08T23:04:59.645236: step 1004, loss 0.250469, acc 0.90625
2020-02-08T23:04:59.826409: step 1005, loss 0.326236, acc 0.875
2020-02-08T23:05:00.010722: step 1006, loss 0.421128, acc 0.78125
2020-02-08T23:05:00.189633: step 1007, loss 0.250087, acc 0.890625
2020-02-08T23:05:00.366779: step 1008, loss 0.592662, acc 0.6875
2020-02-08T23:05:00.543014: step 1009, loss 0.457697, acc 0.828125
2020-02-08T23:05:00.720176: step 1010, loss 0.427145, acc 0.796875
2020-02-08T23:05:00.916915: step 1011, loss 0.289521, acc 0.890625
2020-02-08T23:05:01.107655: step 1012, loss 0.42354, acc 0.796875
2020-02-08T23:05:01.273435: step 1013, loss 0.309995, acc 0.875
2020-02-08T23:05:01.450680: step 1014, loss 0.332782, acc 0.84375
2020-02-08T23:05:01.621861: step 1015, loss 0.491207, acc 0.75
2020-02-08T23:05:01.799699: step 1016, loss 0.480848, acc 0.78125
2020-02-08T23:05:01.985653: step 1017, loss 0.391207, acc 0.875
2020-02-08T23:05:02.164865: step 1018, loss 0.409406, acc 0.84375
2020-02-08T23:05:02.333150: step 1019, loss 0.375223, acc 0.765625
2020-02-08T23:05:02.504111: step 1020, loss 0.448562, acc 0.796875
2020-02-08T23:05:02.678597: step 1021, loss 0.365927, acc 0.859375
2020-02-08T23:05:02.857791: step 1022, loss 0.46286, acc 0.75
2020-02-08T23:05:03.029549: step 1023, loss 0.413517, acc 0.796875
2020-02-08T23:05:03.205450: step 1024, loss 0.318343, acc 0.84375
2020-02-08T23:05:03.387154: step 1025, loss 0.452248, acc 0.765625
2020-02-08T23:05:03.561544: step 1026, loss 0.400874, acc 0.796875
2020-02-08T23:05:03.734053: step 1027, loss 0.367083, acc 0.828125
2020-02-08T23:05:03.906994: step 1028, loss 0.321857, acc 0.890625
2020-02-08T23:05:04.083159: step 1029, loss 0.325876, acc 0.796875
2020-02-08T23:05:04.257071: step 1030, loss 0.455891, acc 0.75
2020-02-08T23:05:04.440856: step 1031, loss 0.35945, acc 0.84375
2020-02-08T23:05:04.616281: step 1032, loss 0.444204, acc 0.78125
2020-02-08T23:05:04.791206: step 1033, loss 0.362568, acc 0.84375
2020-02-08T23:05:04.972258: step 1034, loss 0.332206, acc 0.84375
2020-02-08T23:05:05.148227: step 1035, loss 0.414594, acc 0.84375
2020-02-08T23:05:05.315672: step 1036, loss 0.278519, acc 0.90625
2020-02-08T23:05:05.488983: step 1037, loss 0.34771, acc 0.84375
2020-02-08T23:05:05.664145: step 1038, loss 0.317347, acc 0.84375
2020-02-08T23:05:05.844803: step 1039, loss 0.322679, acc 0.875
2020-02-08T23:05:06.018244: step 1040, loss 0.462686, acc 0.78125
2020-02-08T23:05:06.195333: step 1041, loss 0.374077, acc 0.828125
2020-02-08T23:05:06.371077: step 1042, loss 0.372496, acc 0.78125
2020-02-08T23:05:06.543432: step 1043, loss 0.270085, acc 0.90625
2020-02-08T23:05:06.717931: step 1044, loss 0.501096, acc 0.71875
2020-02-08T23:05:06.898994: step 1045, loss 0.433178, acc 0.78125
2020-02-08T23:05:07.069408: step 1046, loss 0.423791, acc 0.828125
2020-02-08T23:05:07.304084: step 1047, loss 0.566642, acc 0.78125
2020-02-08T23:05:07.603608: step 1048, loss 0.317686, acc 0.828125
2020-02-08T23:05:07.776266: step 1049, loss 0.322913, acc 0.84375
2020-02-08T23:05:07.949168: step 1050, loss 0.470535, acc 0.783333
2020-02-08T23:05:08.125103: step 1051, loss 0.268549, acc 0.890625
2020-02-08T23:05:08.297118: step 1052, loss 0.253118, acc 0.890625
2020-02-08T23:05:08.467022: step 1053, loss 0.360689, acc 0.8125
2020-02-08T23:05:08.641859: step 1054, loss 0.34392, acc 0.859375
2020-02-08T23:05:08.814906: step 1055, loss 0.347461, acc 0.78125
2020-02-08T23:05:08.985017: step 1056, loss 0.297553, acc 0.875
2020-02-08T23:05:09.165571: step 1057, loss 0.273059, acc 0.90625
2020-02-08T23:05:09.332436: step 1058, loss 0.33882, acc 0.828125
2020-02-08T23:05:09.505519: step 1059, loss 0.316705, acc 0.859375
2020-02-08T23:05:09.673432: step 1060, loss 0.409177, acc 0.78125
2020-02-08T23:05:09.848092: step 1061, loss 0.394777, acc 0.8125
2020-02-08T23:05:10.024710: step 1062, loss 0.315465, acc 0.890625
2020-02-08T23:05:10.202562: step 1063, loss 0.373504, acc 0.875
2020-02-08T23:05:10.371818: step 1064, loss 0.302837, acc 0.84375
2020-02-08T23:05:10.546824: step 1065, loss 0.282895, acc 0.859375
2020-02-08T23:05:10.726848: step 1066, loss 0.242442, acc 0.953125
2020-02-08T23:05:10.917090: step 1067, loss 0.331535, acc 0.875
2020-02-08T23:05:11.088519: step 1068, loss 0.394854, acc 0.765625
2020-02-08T23:05:11.260991: step 1069, loss 0.294159, acc 0.90625
2020-02-08T23:05:11.441249: step 1070, loss 0.319948, acc 0.875
2020-02-08T23:05:11.622071: step 1071, loss 0.234227, acc 0.921875
2020-02-08T23:05:11.797974: step 1072, loss 0.327115, acc 0.84375
2020-02-08T23:05:11.975129: step 1073, loss 0.380466, acc 0.828125
2020-02-08T23:05:12.167086: step 1074, loss 0.348325, acc 0.8125
2020-02-08T23:05:12.355358: step 1075, loss 0.301875, acc 0.859375
2020-02-08T23:05:12.539294: step 1076, loss 0.446775, acc 0.78125
2020-02-08T23:05:12.723566: step 1077, loss 0.270406, acc 0.875
2020-02-08T23:05:12.905341: step 1078, loss 0.396821, acc 0.8125
2020-02-08T23:05:13.084505: step 1079, loss 0.426936, acc 0.8125
2020-02-08T23:05:13.268563: step 1080, loss 0.279636, acc 0.8125
2020-02-08T23:05:13.452179: step 1081, loss 0.388065, acc 0.78125
2020-02-08T23:05:13.639378: step 1082, loss 0.293518, acc 0.921875
2020-02-08T23:05:13.825927: step 1083, loss 0.437215, acc 0.8125
2020-02-08T23:05:14.008787: step 1084, loss 0.225092, acc 0.90625
2020-02-08T23:05:14.260856: step 1085, loss 0.402313, acc 0.796875
2020-02-08T23:05:14.463125: step 1086, loss 0.354601, acc 0.8125
2020-02-08T23:05:14.656417: step 1087, loss 0.410348, acc 0.8125
2020-02-08T23:05:14.843798: step 1088, loss 0.235937, acc 0.90625
2020-02-08T23:05:15.031186: step 1089, loss 0.287516, acc 0.890625
2020-02-08T23:05:15.222462: step 1090, loss 0.287828, acc 0.890625
2020-02-08T23:05:15.404213: step 1091, loss 0.427785, acc 0.796875
2020-02-08T23:05:15.594621: step 1092, loss 0.28038, acc 0.859375
2020-02-08T23:05:15.787236: step 1093, loss 0.229879, acc 0.953125
2020-02-08T23:05:15.979512: step 1094, loss 0.408061, acc 0.8125
2020-02-08T23:05:16.174066: step 1095, loss 0.369577, acc 0.84375
2020-02-08T23:05:16.358442: step 1096, loss 0.270173, acc 0.90625
2020-02-08T23:05:16.621168: step 1097, loss 0.287582, acc 0.921875
2020-02-08T23:05:16.804913: step 1098, loss 0.251412, acc 0.890625
2020-02-08T23:05:17.061099: step 1099, loss 0.328612, acc 0.796875
2020-02-08T23:05:17.271101: step 1100, loss 0.343784, acc 0.84375

Evaluation:
2020-02-08T23:05:17.627929: step 1100, loss 0.597905, acc 0.695122

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1100

2020-02-08T23:05:19.271205: step 1101, loss 0.334108, acc 0.890625
2020-02-08T23:05:19.474916: step 1102, loss 0.317539, acc 0.890625
2020-02-08T23:05:19.660209: step 1103, loss 0.364453, acc 0.890625
2020-02-08T23:05:19.851716: step 1104, loss 0.429798, acc 0.796875
2020-02-08T23:05:20.039229: step 1105, loss 0.262559, acc 0.859375
2020-02-08T23:05:20.212571: step 1106, loss 0.310402, acc 0.875
2020-02-08T23:05:20.403811: step 1107, loss 0.335078, acc 0.890625
2020-02-08T23:05:20.583972: step 1108, loss 0.414513, acc 0.78125
2020-02-08T23:05:20.754754: step 1109, loss 0.237037, acc 0.921875
2020-02-08T23:05:20.946517: step 1110, loss 0.500692, acc 0.796875
2020-02-08T23:05:21.112896: step 1111, loss 0.297057, acc 0.828125
2020-02-08T23:05:21.295278: step 1112, loss 0.361836, acc 0.859375
2020-02-08T23:05:21.476051: step 1113, loss 0.30287, acc 0.828125
2020-02-08T23:05:21.649870: step 1114, loss 0.383095, acc 0.78125
2020-02-08T23:05:21.826368: step 1115, loss 0.330897, acc 0.84375
2020-02-08T23:05:21.999090: step 1116, loss 0.494005, acc 0.8125
2020-02-08T23:05:22.177336: step 1117, loss 0.4312, acc 0.796875
2020-02-08T23:05:22.349129: step 1118, loss 0.322448, acc 0.859375
2020-02-08T23:05:22.526563: step 1119, loss 0.320722, acc 0.828125
2020-02-08T23:05:22.698185: step 1120, loss 0.466919, acc 0.796875
2020-02-08T23:05:22.878686: step 1121, loss 0.239024, acc 0.890625
2020-02-08T23:05:23.081307: step 1122, loss 0.33202, acc 0.84375
2020-02-08T23:05:23.278022: step 1123, loss 0.28747, acc 0.875
2020-02-08T23:05:23.479330: step 1124, loss 0.294474, acc 0.890625
2020-02-08T23:05:23.686669: step 1125, loss 0.252021, acc 0.90625
2020-02-08T23:05:23.867247: step 1126, loss 0.300029, acc 0.84375
2020-02-08T23:05:24.065536: step 1127, loss 0.361329, acc 0.859375
2020-02-08T23:05:24.268369: step 1128, loss 0.464856, acc 0.8125
2020-02-08T23:05:24.471464: step 1129, loss 0.344365, acc 0.828125
2020-02-08T23:05:24.650420: step 1130, loss 0.353085, acc 0.828125
2020-02-08T23:05:24.841403: step 1131, loss 0.219874, acc 0.921875
2020-02-08T23:05:25.040660: step 1132, loss 0.302066, acc 0.84375
2020-02-08T23:05:25.235405: step 1133, loss 0.21275, acc 0.9375
2020-02-08T23:05:25.421025: step 1134, loss 0.262493, acc 0.859375
2020-02-08T23:05:25.596706: step 1135, loss 0.323865, acc 0.84375
2020-02-08T23:05:25.793152: step 1136, loss 0.246583, acc 0.90625
2020-02-08T23:05:25.981073: step 1137, loss 0.351073, acc 0.890625
2020-02-08T23:05:26.169962: step 1138, loss 0.300284, acc 0.859375
2020-02-08T23:05:26.352620: step 1139, loss 0.321914, acc 0.875
2020-02-08T23:05:26.532983: step 1140, loss 0.28678, acc 0.859375
2020-02-08T23:05:26.713614: step 1141, loss 0.185636, acc 0.9375
2020-02-08T23:05:26.898223: step 1142, loss 0.368464, acc 0.859375
2020-02-08T23:05:27.080205: step 1143, loss 0.235474, acc 0.859375
2020-02-08T23:05:27.274044: step 1144, loss 0.280659, acc 0.875
2020-02-08T23:05:27.464422: step 1145, loss 0.293974, acc 0.890625
2020-02-08T23:05:27.650171: step 1146, loss 0.252384, acc 0.890625
2020-02-08T23:05:27.835400: step 1147, loss 0.30009, acc 0.890625
2020-02-08T23:05:28.022448: step 1148, loss 0.248149, acc 0.921875
2020-02-08T23:05:28.223322: step 1149, loss 0.273916, acc 0.875
2020-02-08T23:05:28.431292: step 1150, loss 0.287338, acc 0.875
2020-02-08T23:05:28.643704: step 1151, loss 0.365218, acc 0.84375
2020-02-08T23:05:28.828610: step 1152, loss 0.392282, acc 0.8125
2020-02-08T23:05:29.023016: step 1153, loss 0.326612, acc 0.859375
2020-02-08T23:05:29.230169: step 1154, loss 0.371449, acc 0.84375
2020-02-08T23:05:29.432043: step 1155, loss 0.430213, acc 0.8125
2020-02-08T23:05:29.628905: step 1156, loss 0.383874, acc 0.78125
2020-02-08T23:05:29.829070: step 1157, loss 0.323363, acc 0.828125
2020-02-08T23:05:30.031966: step 1158, loss 0.36786, acc 0.875
2020-02-08T23:05:30.227223: step 1159, loss 0.290093, acc 0.859375
2020-02-08T23:05:30.412404: step 1160, loss 0.451838, acc 0.78125
2020-02-08T23:05:30.614732: step 1161, loss 0.24364, acc 0.921875
2020-02-08T23:05:30.813405: step 1162, loss 0.255081, acc 0.890625
2020-02-08T23:05:31.015749: step 1163, loss 0.291353, acc 0.859375
2020-02-08T23:05:31.218945: step 1164, loss 0.426972, acc 0.796875
2020-02-08T23:05:31.386544: step 1165, loss 0.241569, acc 0.90625
2020-02-08T23:05:31.586761: step 1166, loss 0.307691, acc 0.859375
2020-02-08T23:05:31.786286: step 1167, loss 0.257249, acc 0.875
2020-02-08T23:05:32.004030: step 1168, loss 0.316486, acc 0.890625
2020-02-08T23:05:32.209556: step 1169, loss 0.276096, acc 0.90625
2020-02-08T23:05:32.421227: step 1170, loss 0.329644, acc 0.875
2020-02-08T23:05:32.628355: step 1171, loss 0.476242, acc 0.796875
2020-02-08T23:05:32.824918: step 1172, loss 0.267834, acc 0.890625
2020-02-08T23:05:33.028538: step 1173, loss 0.390247, acc 0.828125
2020-02-08T23:05:33.318264: step 1174, loss 0.265487, acc 0.890625
2020-02-08T23:05:33.543025: step 1175, loss 0.282211, acc 0.90625
2020-02-08T23:05:33.747681: step 1176, loss 0.294454, acc 0.875
2020-02-08T23:05:33.932405: step 1177, loss 0.294822, acc 0.890625
2020-02-08T23:05:34.134098: step 1178, loss 0.461919, acc 0.8125
2020-02-08T23:05:34.328987: step 1179, loss 0.286002, acc 0.90625
2020-02-08T23:05:34.526955: step 1180, loss 0.370283, acc 0.859375
2020-02-08T23:05:34.726465: step 1181, loss 0.279196, acc 0.90625
2020-02-08T23:05:34.931632: step 1182, loss 0.351501, acc 0.8125
2020-02-08T23:05:35.135415: step 1183, loss 0.31154, acc 0.859375
2020-02-08T23:05:35.334808: step 1184, loss 0.297578, acc 0.828125
2020-02-08T23:05:35.533302: step 1185, loss 0.35988, acc 0.796875
2020-02-08T23:05:35.739813: step 1186, loss 0.329337, acc 0.84375
2020-02-08T23:05:35.897174: step 1187, loss 0.245697, acc 0.890625
2020-02-08T23:05:36.100123: step 1188, loss 0.386188, acc 0.8125
2020-02-08T23:05:36.269979: step 1189, loss 0.28791, acc 0.875
2020-02-08T23:05:36.463525: step 1190, loss 0.332382, acc 0.859375
2020-02-08T23:05:36.661760: step 1191, loss 0.329837, acc 0.890625
2020-02-08T23:05:36.886647: step 1192, loss 0.248327, acc 0.890625
2020-02-08T23:05:37.101867: step 1193, loss 0.246402, acc 0.90625
2020-02-08T23:05:37.305301: step 1194, loss 0.282237, acc 0.90625
2020-02-08T23:05:37.503898: step 1195, loss 0.355527, acc 0.8125
2020-02-08T23:05:37.706118: step 1196, loss 0.346932, acc 0.828125
2020-02-08T23:05:37.905575: step 1197, loss 0.288918, acc 0.875
2020-02-08T23:05:38.099581: step 1198, loss 0.455411, acc 0.71875
2020-02-08T23:05:38.307726: step 1199, loss 0.2501, acc 0.921875
2020-02-08T23:05:38.514293: step 1200, loss 0.330812, acc 0.866667

Evaluation:
2020-02-08T23:05:38.988934: step 1200, loss 0.591654, acc 0.710131

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1200

2020-02-08T23:05:40.566536: step 1201, loss 0.306232, acc 0.875
2020-02-08T23:05:40.753071: step 1202, loss 0.204889, acc 0.90625
2020-02-08T23:05:40.987291: step 1203, loss 0.148419, acc 0.96875
2020-02-08T23:05:41.159461: step 1204, loss 0.290962, acc 0.84375
2020-02-08T23:05:41.380512: step 1205, loss 0.18482, acc 0.953125
2020-02-08T23:05:41.557692: step 1206, loss 0.326426, acc 0.84375
2020-02-08T23:05:41.807259: step 1207, loss 0.165296, acc 0.9375
2020-02-08T23:05:42.026344: step 1208, loss 0.31598, acc 0.875
2020-02-08T23:05:42.324964: step 1209, loss 0.16975, acc 0.9375
2020-02-08T23:05:42.572746: step 1210, loss 0.259328, acc 0.875
2020-02-08T23:05:42.863784: step 1211, loss 0.313983, acc 0.828125
2020-02-08T23:05:43.135136: step 1212, loss 0.349084, acc 0.828125
2020-02-08T23:05:43.381799: step 1213, loss 0.195128, acc 0.9375
2020-02-08T23:05:43.584851: step 1214, loss 0.265887, acc 0.859375
2020-02-08T23:05:43.796204: step 1215, loss 0.185113, acc 0.921875
2020-02-08T23:05:44.010192: step 1216, loss 0.252129, acc 0.90625
2020-02-08T23:05:44.210357: step 1217, loss 0.172267, acc 0.921875
2020-02-08T23:05:44.423469: step 1218, loss 0.354023, acc 0.875
2020-02-08T23:05:44.633443: step 1219, loss 0.213465, acc 0.890625
2020-02-08T23:05:44.832234: step 1220, loss 0.215491, acc 0.90625
2020-02-08T23:05:45.033493: step 1221, loss 0.185648, acc 0.9375
2020-02-08T23:05:45.237019: step 1222, loss 0.272359, acc 0.921875
2020-02-08T23:05:45.439270: step 1223, loss 0.336498, acc 0.828125
2020-02-08T23:05:45.641113: step 1224, loss 0.345722, acc 0.859375
2020-02-08T23:05:45.843230: step 1225, loss 0.29847, acc 0.859375
2020-02-08T23:05:46.048380: step 1226, loss 0.261843, acc 0.921875
2020-02-08T23:05:46.262952: step 1227, loss 0.332626, acc 0.84375
2020-02-08T23:05:46.467391: step 1228, loss 0.294251, acc 0.859375
2020-02-08T23:05:46.658932: step 1229, loss 0.206197, acc 0.890625
2020-02-08T23:05:46.876756: step 1230, loss 0.147317, acc 0.96875
2020-02-08T23:05:47.060821: step 1231, loss 0.245713, acc 0.859375
2020-02-08T23:05:47.270920: step 1232, loss 0.255064, acc 0.890625
2020-02-08T23:05:47.466746: step 1233, loss 0.216989, acc 0.921875
2020-02-08T23:05:47.668926: step 1234, loss 0.177938, acc 0.921875
2020-02-08T23:05:47.876816: step 1235, loss 0.396909, acc 0.796875
2020-02-08T23:05:48.079096: step 1236, loss 0.378673, acc 0.890625
2020-02-08T23:05:48.281965: step 1237, loss 0.235854, acc 0.859375
2020-02-08T23:05:48.506778: step 1238, loss 0.221624, acc 0.921875
2020-02-08T23:05:48.707961: step 1239, loss 0.21884, acc 0.90625
2020-02-08T23:05:48.915343: step 1240, loss 0.207753, acc 0.9375
2020-02-08T23:05:49.124223: step 1241, loss 0.229279, acc 0.90625
2020-02-08T23:05:49.316499: step 1242, loss 0.184043, acc 0.921875
2020-02-08T23:05:49.526123: step 1243, loss 0.31385, acc 0.84375
2020-02-08T23:05:49.719922: step 1244, loss 0.22896, acc 0.90625
2020-02-08T23:05:49.923225: step 1245, loss 0.26206, acc 0.90625
2020-02-08T23:05:50.126898: step 1246, loss 0.289951, acc 0.859375
2020-02-08T23:05:50.330710: step 1247, loss 0.168948, acc 0.96875
2020-02-08T23:05:50.525781: step 1248, loss 0.265503, acc 0.875
2020-02-08T23:05:50.721540: step 1249, loss 0.199641, acc 0.90625
2020-02-08T23:05:50.955613: step 1250, loss 0.179266, acc 0.9375
2020-02-08T23:05:51.142849: step 1251, loss 0.237731, acc 0.90625
2020-02-08T23:05:51.358022: step 1252, loss 0.191806, acc 0.9375
2020-02-08T23:05:51.521502: step 1253, loss 0.307608, acc 0.875
2020-02-08T23:05:51.720487: step 1254, loss 0.357691, acc 0.84375
2020-02-08T23:05:51.981131: step 1255, loss 0.308412, acc 0.859375
2020-02-08T23:05:52.124546: step 1256, loss 0.254039, acc 0.890625
2020-02-08T23:05:52.346666: step 1257, loss 0.216646, acc 0.9375
2020-02-08T23:05:52.568599: step 1258, loss 0.208329, acc 0.921875
2020-02-08T23:05:52.777001: step 1259, loss 0.262156, acc 0.90625
2020-02-08T23:05:52.978867: step 1260, loss 0.257108, acc 0.875
2020-02-08T23:05:53.173590: step 1261, loss 0.210332, acc 0.9375
2020-02-08T23:05:53.370943: step 1262, loss 0.154561, acc 0.953125
2020-02-08T23:05:53.556803: step 1263, loss 0.206245, acc 0.953125
2020-02-08T23:05:53.759430: step 1264, loss 0.245006, acc 0.9375
2020-02-08T23:05:53.962595: step 1265, loss 0.148822, acc 0.9375
2020-02-08T23:05:54.161871: step 1266, loss 0.154954, acc 0.9375
2020-02-08T23:05:54.370195: step 1267, loss 0.351355, acc 0.859375
2020-02-08T23:05:54.531815: step 1268, loss 0.253285, acc 0.828125
2020-02-08T23:05:54.727804: step 1269, loss 0.256859, acc 0.859375
2020-02-08T23:05:54.915646: step 1270, loss 0.338541, acc 0.875
2020-02-08T23:05:55.110412: step 1271, loss 0.243159, acc 0.890625
2020-02-08T23:05:55.307158: step 1272, loss 0.200675, acc 0.90625
2020-02-08T23:05:55.495666: step 1273, loss 0.448681, acc 0.84375
2020-02-08T23:05:55.692591: step 1274, loss 0.21353, acc 0.90625
2020-02-08T23:05:55.890406: step 1275, loss 0.322644, acc 0.828125
2020-02-08T23:05:56.089615: step 1276, loss 0.378848, acc 0.828125
2020-02-08T23:05:56.276258: step 1277, loss 0.228612, acc 0.90625
2020-02-08T23:05:56.468259: step 1278, loss 0.276893, acc 0.875
2020-02-08T23:05:56.660616: step 1279, loss 0.255648, acc 0.890625
2020-02-08T23:05:56.854700: step 1280, loss 0.215074, acc 0.9375
2020-02-08T23:05:57.033414: step 1281, loss 0.303587, acc 0.828125
2020-02-08T23:05:57.226387: step 1282, loss 0.229754, acc 0.90625
2020-02-08T23:05:57.421978: step 1283, loss 0.189152, acc 0.921875
2020-02-08T23:05:57.623176: step 1284, loss 0.200311, acc 0.90625
2020-02-08T23:05:57.814904: step 1285, loss 0.27815, acc 0.890625
2020-02-08T23:05:58.040202: step 1286, loss 0.141654, acc 0.96875
2020-02-08T23:05:58.257472: step 1287, loss 0.233018, acc 0.875
2020-02-08T23:05:58.459012: step 1288, loss 0.201858, acc 0.90625
2020-02-08T23:05:58.663360: step 1289, loss 0.160252, acc 0.9375
2020-02-08T23:05:58.855410: step 1290, loss 0.20346, acc 0.921875
2020-02-08T23:05:59.063577: step 1291, loss 0.296387, acc 0.84375
2020-02-08T23:05:59.273309: step 1292, loss 0.319167, acc 0.84375
2020-02-08T23:05:59.478563: step 1293, loss 0.187672, acc 0.953125
2020-02-08T23:05:59.687804: step 1294, loss 0.322449, acc 0.828125
2020-02-08T23:05:59.908770: step 1295, loss 0.259734, acc 0.90625
2020-02-08T23:06:00.114912: step 1296, loss 0.241425, acc 0.90625
2020-02-08T23:06:00.278979: step 1297, loss 0.350288, acc 0.828125
2020-02-08T23:06:00.485855: step 1298, loss 0.30741, acc 0.890625
2020-02-08T23:06:00.685010: step 1299, loss 0.178467, acc 0.953125
2020-02-08T23:06:00.916687: step 1300, loss 0.372614, acc 0.84375

Evaluation:
2020-02-08T23:06:01.314370: step 1300, loss 0.608337, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1300

2020-02-08T23:06:03.274777: step 1301, loss 0.312525, acc 0.859375
2020-02-08T23:06:03.461457: step 1302, loss 0.214693, acc 0.90625
2020-02-08T23:06:03.649325: step 1303, loss 0.158196, acc 0.9375
2020-02-08T23:06:03.851588: step 1304, loss 0.20103, acc 0.921875
2020-02-08T23:06:04.052405: step 1305, loss 0.241235, acc 0.921875
2020-02-08T23:06:04.263102: step 1306, loss 0.397693, acc 0.8125
2020-02-08T23:06:04.472298: step 1307, loss 0.216461, acc 0.890625
2020-02-08T23:06:04.717093: step 1308, loss 0.295026, acc 0.875
2020-02-08T23:06:04.936576: step 1309, loss 0.274513, acc 0.921875
2020-02-08T23:06:05.146025: step 1310, loss 0.203479, acc 0.921875
2020-02-08T23:06:05.342316: step 1311, loss 0.293528, acc 0.90625
2020-02-08T23:06:05.544985: step 1312, loss 0.166183, acc 0.9375
2020-02-08T23:06:05.820300: step 1313, loss 0.243716, acc 0.859375
2020-02-08T23:06:06.013196: step 1314, loss 0.160359, acc 0.96875
2020-02-08T23:06:06.152967: step 1315, loss 0.255401, acc 0.875
2020-02-08T23:06:06.307366: step 1316, loss 0.270222, acc 0.875
2020-02-08T23:06:06.511536: step 1317, loss 0.355222, acc 0.859375
2020-02-08T23:06:06.666406: step 1318, loss 0.267097, acc 0.890625
2020-02-08T23:06:06.820949: step 1319, loss 0.234384, acc 0.9375
2020-02-08T23:06:06.969622: step 1320, loss 0.313237, acc 0.828125
2020-02-08T23:06:07.122392: step 1321, loss 0.312563, acc 0.875
2020-02-08T23:06:07.312813: step 1322, loss 0.195286, acc 0.921875
2020-02-08T23:06:07.475739: step 1323, loss 0.184486, acc 0.90625
2020-02-08T23:06:07.620603: step 1324, loss 0.253472, acc 0.90625
2020-02-08T23:06:07.771487: step 1325, loss 0.338131, acc 0.890625
2020-02-08T23:06:07.919089: step 1326, loss 0.246797, acc 0.890625
2020-02-08T23:06:08.118329: step 1327, loss 0.278125, acc 0.875
2020-02-08T23:06:08.265394: step 1328, loss 0.252702, acc 0.90625
2020-02-08T23:06:08.420674: step 1329, loss 0.211089, acc 0.890625
2020-02-08T23:06:08.620978: step 1330, loss 0.213488, acc 0.9375
2020-02-08T23:06:08.760974: step 1331, loss 0.289287, acc 0.828125
2020-02-08T23:06:08.939038: step 1332, loss 0.181877, acc 0.90625
2020-02-08T23:06:09.110566: step 1333, loss 0.229982, acc 0.90625
2020-02-08T23:06:09.262206: step 1334, loss 0.224487, acc 0.921875
2020-02-08T23:06:09.419336: step 1335, loss 0.210048, acc 0.859375
2020-02-08T23:06:09.642193: step 1336, loss 0.288612, acc 0.890625
2020-02-08T23:06:09.789706: step 1337, loss 0.209351, acc 0.921875
2020-02-08T23:06:09.933976: step 1338, loss 0.301845, acc 0.84375
2020-02-08T23:06:10.074986: step 1339, loss 0.283838, acc 0.90625
2020-02-08T23:06:10.274857: step 1340, loss 0.272058, acc 0.890625
2020-02-08T23:06:10.453115: step 1341, loss 0.252216, acc 0.875
2020-02-08T23:06:10.600791: step 1342, loss 0.411967, acc 0.8125
2020-02-08T23:06:10.755641: step 1343, loss 0.274592, acc 0.890625
2020-02-08T23:06:10.910064: step 1344, loss 0.191384, acc 0.921875
2020-02-08T23:06:11.071633: step 1345, loss 0.308287, acc 0.875
2020-02-08T23:06:11.221966: step 1346, loss 0.251616, acc 0.921875
2020-02-08T23:06:11.369866: step 1347, loss 0.255997, acc 0.90625
2020-02-08T23:06:11.517422: step 1348, loss 0.28334, acc 0.875
2020-02-08T23:06:11.657259: step 1349, loss 0.277558, acc 0.890625
2020-02-08T23:06:11.794618: step 1350, loss 0.165665, acc 0.95
2020-02-08T23:06:11.932996: step 1351, loss 0.159846, acc 0.9375
2020-02-08T23:06:12.074896: step 1352, loss 0.254539, acc 0.890625
2020-02-08T23:06:12.225539: step 1353, loss 0.129031, acc 0.953125
2020-02-08T23:06:12.362508: step 1354, loss 0.136346, acc 0.953125
2020-02-08T23:06:12.507376: step 1355, loss 0.217056, acc 0.921875
2020-02-08T23:06:12.656062: step 1356, loss 0.20114, acc 0.953125
2020-02-08T23:06:12.880028: step 1357, loss 0.261927, acc 0.921875
2020-02-08T23:06:13.038280: step 1358, loss 0.347849, acc 0.90625
2020-02-08T23:06:13.240057: step 1359, loss 0.218847, acc 0.90625
2020-02-08T23:06:13.411249: step 1360, loss 0.166219, acc 0.9375
2020-02-08T23:06:13.573531: step 1361, loss 0.273826, acc 0.875
2020-02-08T23:06:13.713700: step 1362, loss 0.268456, acc 0.84375
2020-02-08T23:06:13.858089: step 1363, loss 0.138078, acc 0.9375
2020-02-08T23:06:14.015779: step 1364, loss 0.233241, acc 0.921875
2020-02-08T23:06:14.155793: step 1365, loss 0.138869, acc 0.953125
2020-02-08T23:06:14.291673: step 1366, loss 0.155496, acc 0.9375
2020-02-08T23:06:14.430376: step 1367, loss 0.176615, acc 0.953125
2020-02-08T23:06:14.567240: step 1368, loss 0.228202, acc 0.90625
2020-02-08T23:06:14.700825: step 1369, loss 0.258919, acc 0.890625
2020-02-08T23:06:14.839520: step 1370, loss 0.188815, acc 0.9375
2020-02-08T23:06:14.979748: step 1371, loss 0.15786, acc 0.96875
2020-02-08T23:06:15.113867: step 1372, loss 0.135212, acc 0.953125
2020-02-08T23:06:15.252595: step 1373, loss 0.137513, acc 0.96875
2020-02-08T23:06:15.386184: step 1374, loss 0.270115, acc 0.875
2020-02-08T23:06:15.524242: step 1375, loss 0.18425, acc 0.890625
2020-02-08T23:06:15.659102: step 1376, loss 0.224565, acc 0.859375
2020-02-08T23:06:15.798635: step 1377, loss 0.151311, acc 0.96875
2020-02-08T23:06:15.926883: step 1378, loss 0.169936, acc 0.953125
2020-02-08T23:06:16.060304: step 1379, loss 0.243337, acc 0.890625
2020-02-08T23:06:16.209917: step 1380, loss 0.122864, acc 0.96875
2020-02-08T23:06:16.379652: step 1381, loss 0.274522, acc 0.875
2020-02-08T23:06:16.523176: step 1382, loss 0.318623, acc 0.859375
2020-02-08T23:06:16.657975: step 1383, loss 0.248237, acc 0.875
2020-02-08T23:06:16.811106: step 1384, loss 0.247467, acc 0.90625
2020-02-08T23:06:16.983836: step 1385, loss 0.153582, acc 0.96875
2020-02-08T23:06:17.126385: step 1386, loss 0.152901, acc 0.921875
2020-02-08T23:06:17.324645: step 1387, loss 0.254903, acc 0.90625
2020-02-08T23:06:17.504298: step 1388, loss 0.284971, acc 0.875
2020-02-08T23:06:17.651600: step 1389, loss 0.251867, acc 0.90625
2020-02-08T23:06:17.872889: step 1390, loss 0.443337, acc 0.828125
2020-02-08T23:06:18.079002: step 1391, loss 0.234121, acc 0.921875
2020-02-08T23:06:18.240837: step 1392, loss 0.311646, acc 0.84375
2020-02-08T23:06:18.434658: step 1393, loss 0.212615, acc 0.859375
2020-02-08T23:06:18.625737: step 1394, loss 0.158172, acc 0.96875
2020-02-08T23:06:18.775942: step 1395, loss 0.203225, acc 0.90625
2020-02-08T23:06:18.930573: step 1396, loss 0.265763, acc 0.875
2020-02-08T23:06:19.077655: step 1397, loss 0.205494, acc 0.90625
2020-02-08T23:06:19.215792: step 1398, loss 0.159324, acc 0.96875
2020-02-08T23:06:19.369622: step 1399, loss 0.187175, acc 0.921875
2020-02-08T23:06:19.521978: step 1400, loss 0.154657, acc 0.921875

Evaluation:
2020-02-08T23:06:19.764909: step 1400, loss 0.615688, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1400

2020-02-08T23:06:21.322644: step 1401, loss 0.292536, acc 0.828125
2020-02-08T23:06:21.456756: step 1402, loss 0.166468, acc 0.953125
2020-02-08T23:06:21.593224: step 1403, loss 0.249849, acc 0.890625
2020-02-08T23:06:21.729825: step 1404, loss 0.147053, acc 0.9375
2020-02-08T23:06:21.941723: step 1405, loss 0.153052, acc 0.90625
2020-02-08T23:06:22.081902: step 1406, loss 0.249088, acc 0.90625
2020-02-08T23:06:22.221408: step 1407, loss 0.222786, acc 0.890625
2020-02-08T23:06:22.384273: step 1408, loss 0.195579, acc 0.90625
2020-02-08T23:06:22.585201: step 1409, loss 0.236472, acc 0.921875
2020-02-08T23:06:22.725274: step 1410, loss 0.328819, acc 0.875
2020-02-08T23:06:22.870338: step 1411, loss 0.172816, acc 0.921875
2020-02-08T23:06:23.016864: step 1412, loss 0.210277, acc 0.9375
2020-02-08T23:06:23.185257: step 1413, loss 0.231911, acc 0.890625
2020-02-08T23:06:23.355436: step 1414, loss 0.108214, acc 0.96875
2020-02-08T23:06:23.490270: step 1415, loss 0.139814, acc 0.9375
2020-02-08T23:06:23.628488: step 1416, loss 0.15379, acc 0.9375
2020-02-08T23:06:23.780257: step 1417, loss 0.242086, acc 0.890625
2020-02-08T23:06:23.930530: step 1418, loss 0.258972, acc 0.875
2020-02-08T23:06:24.088967: step 1419, loss 0.130723, acc 0.96875
2020-02-08T23:06:24.285616: step 1420, loss 0.259082, acc 0.890625
2020-02-08T23:06:24.453068: step 1421, loss 0.248652, acc 0.875
2020-02-08T23:06:24.607148: step 1422, loss 0.16077, acc 0.921875
2020-02-08T23:06:24.749844: step 1423, loss 0.142645, acc 0.96875
2020-02-08T23:06:24.891204: step 1424, loss 0.261611, acc 0.921875
2020-02-08T23:06:25.052105: step 1425, loss 0.221809, acc 0.921875
2020-02-08T23:06:25.204296: step 1426, loss 0.279567, acc 0.859375
2020-02-08T23:06:25.353887: step 1427, loss 0.285334, acc 0.890625
2020-02-08T23:06:25.485978: step 1428, loss 0.152266, acc 0.953125
2020-02-08T23:06:25.628703: step 1429, loss 0.158093, acc 0.9375
2020-02-08T23:06:25.769203: step 1430, loss 0.161522, acc 0.9375
2020-02-08T23:06:25.913021: step 1431, loss 0.190364, acc 0.9375
2020-02-08T23:06:26.053820: step 1432, loss 0.27753, acc 0.875
2020-02-08T23:06:26.190758: step 1433, loss 0.0720357, acc 1
2020-02-08T23:06:26.331851: step 1434, loss 0.124307, acc 0.953125
2020-02-08T23:06:26.468401: step 1435, loss 0.202527, acc 0.875
2020-02-08T23:06:26.612363: step 1436, loss 0.310766, acc 0.90625
2020-02-08T23:06:26.753833: step 1437, loss 0.251002, acc 0.90625
2020-02-08T23:06:26.950224: step 1438, loss 0.228463, acc 0.84375
2020-02-08T23:06:27.094854: step 1439, loss 0.195887, acc 0.90625
2020-02-08T23:06:27.263089: step 1440, loss 0.26874, acc 0.90625
2020-02-08T23:06:27.428079: step 1441, loss 0.159145, acc 0.953125
2020-02-08T23:06:27.598892: step 1442, loss 0.185255, acc 0.96875
2020-02-08T23:06:27.748520: step 1443, loss 0.400446, acc 0.84375
2020-02-08T23:06:27.948185: step 1444, loss 0.279931, acc 0.890625
2020-02-08T23:06:28.101016: step 1445, loss 0.196736, acc 0.90625
2020-02-08T23:06:28.239311: step 1446, loss 0.172702, acc 0.921875
2020-02-08T23:06:28.403981: step 1447, loss 0.133648, acc 0.984375
2020-02-08T23:06:28.560363: step 1448, loss 0.186851, acc 0.90625
2020-02-08T23:06:28.711441: step 1449, loss 0.176186, acc 0.9375
2020-02-08T23:06:28.850807: step 1450, loss 0.205432, acc 0.9375
2020-02-08T23:06:28.988410: step 1451, loss 0.294293, acc 0.84375
2020-02-08T23:06:29.131169: step 1452, loss 0.217583, acc 0.875
2020-02-08T23:06:29.267646: step 1453, loss 0.232207, acc 0.890625
2020-02-08T23:06:29.410463: step 1454, loss 0.256036, acc 0.890625
2020-02-08T23:06:29.550109: step 1455, loss 0.236106, acc 0.921875
2020-02-08T23:06:29.692119: step 1456, loss 0.249544, acc 0.9375
2020-02-08T23:06:29.848601: step 1457, loss 0.129367, acc 0.96875
2020-02-08T23:06:30.106464: step 1458, loss 0.247701, acc 0.90625
2020-02-08T23:06:30.336842: step 1459, loss 0.198627, acc 0.90625
2020-02-08T23:06:30.482625: step 1460, loss 0.206871, acc 0.921875
2020-02-08T23:06:30.642268: step 1461, loss 0.141142, acc 0.953125
2020-02-08T23:06:30.855458: step 1462, loss 0.132768, acc 0.96875
2020-02-08T23:06:31.144749: step 1463, loss 0.166078, acc 0.9375
2020-02-08T23:06:31.337642: step 1464, loss 0.201855, acc 0.921875
2020-02-08T23:06:31.508972: step 1465, loss 0.331406, acc 0.90625
2020-02-08T23:06:31.723032: step 1466, loss 0.132501, acc 0.96875
2020-02-08T23:06:31.964476: step 1467, loss 0.26608, acc 0.875
2020-02-08T23:06:32.185537: step 1468, loss 0.159127, acc 0.90625
2020-02-08T23:06:32.408227: step 1469, loss 0.170225, acc 0.9375
2020-02-08T23:06:32.610113: step 1470, loss 0.161753, acc 0.9375
2020-02-08T23:06:32.827078: step 1471, loss 0.242641, acc 0.921875
2020-02-08T23:06:33.130733: step 1472, loss 0.192931, acc 0.921875
2020-02-08T23:06:33.304764: step 1473, loss 0.238474, acc 0.921875
2020-02-08T23:06:33.481974: step 1474, loss 0.172581, acc 0.9375
2020-02-08T23:06:33.621493: step 1475, loss 0.243586, acc 0.90625
2020-02-08T23:06:33.782802: step 1476, loss 0.16663, acc 0.9375
2020-02-08T23:06:33.961677: step 1477, loss 0.167166, acc 0.9375
2020-02-08T23:06:34.210599: step 1478, loss 0.229773, acc 0.90625
2020-02-08T23:06:34.425657: step 1479, loss 0.214358, acc 0.921875
2020-02-08T23:06:34.548390: step 1480, loss 0.208518, acc 0.90625
2020-02-08T23:06:34.673417: step 1481, loss 0.115447, acc 0.953125
2020-02-08T23:06:34.797182: step 1482, loss 0.157144, acc 0.953125
2020-02-08T23:06:34.926722: step 1483, loss 0.156762, acc 0.921875
2020-02-08T23:06:35.183174: step 1484, loss 0.189417, acc 0.921875
2020-02-08T23:06:35.441624: step 1485, loss 0.163281, acc 0.921875
2020-02-08T23:06:35.658882: step 1486, loss 0.0998332, acc 0.96875
2020-02-08T23:06:35.836220: step 1487, loss 0.167706, acc 0.9375
2020-02-08T23:06:35.978305: step 1488, loss 0.190354, acc 0.921875
2020-02-08T23:06:36.119108: step 1489, loss 0.215023, acc 0.90625
2020-02-08T23:06:36.259585: step 1490, loss 0.139846, acc 0.96875
2020-02-08T23:06:36.406911: step 1491, loss 0.127836, acc 0.96875
2020-02-08T23:06:36.530325: step 1492, loss 0.294565, acc 0.875
2020-02-08T23:06:36.659564: step 1493, loss 0.282299, acc 0.859375
2020-02-08T23:06:36.800924: step 1494, loss 0.106552, acc 0.953125
2020-02-08T23:06:36.960321: step 1495, loss 0.320899, acc 0.796875
2020-02-08T23:06:37.099748: step 1496, loss 0.132851, acc 0.96875
2020-02-08T23:06:37.224490: step 1497, loss 0.231746, acc 0.90625
2020-02-08T23:06:37.354451: step 1498, loss 0.156221, acc 0.953125
2020-02-08T23:06:37.479505: step 1499, loss 0.221104, acc 0.890625
2020-02-08T23:06:37.601531: step 1500, loss 0.164888, acc 0.933333

Evaluation:
2020-02-08T23:06:37.809465: step 1500, loss 0.636791, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1500

2020-02-08T23:06:39.253224: step 1501, loss 0.108799, acc 0.96875
2020-02-08T23:06:39.378369: step 1502, loss 0.0719321, acc 1
2020-02-08T23:06:39.498956: step 1503, loss 0.0743085, acc 0.96875
2020-02-08T23:06:39.624952: step 1504, loss 0.127476, acc 0.953125
2020-02-08T23:06:39.746870: step 1505, loss 0.207625, acc 0.90625
2020-02-08T23:06:39.868374: step 1506, loss 0.188757, acc 0.9375
2020-02-08T23:06:39.985525: step 1507, loss 0.17018, acc 0.921875
2020-02-08T23:06:40.113538: step 1508, loss 0.150649, acc 0.953125
2020-02-08T23:06:40.233463: step 1509, loss 0.160663, acc 0.921875
2020-02-08T23:06:40.357966: step 1510, loss 0.156249, acc 0.90625
2020-02-08T23:06:40.476352: step 1511, loss 0.0845241, acc 0.96875
2020-02-08T23:06:40.603281: step 1512, loss 0.104242, acc 0.953125
2020-02-08T23:06:40.726120: step 1513, loss 0.148745, acc 0.953125
2020-02-08T23:06:40.854778: step 1514, loss 0.168222, acc 0.921875
2020-02-08T23:06:40.977139: step 1515, loss 0.127055, acc 0.9375
2020-02-08T23:06:41.101130: step 1516, loss 0.122199, acc 0.96875
2020-02-08T23:06:41.222858: step 1517, loss 0.149199, acc 0.921875
2020-02-08T23:06:41.347336: step 1518, loss 0.135103, acc 0.921875
2020-02-08T23:06:41.470943: step 1519, loss 0.131909, acc 0.921875
2020-02-08T23:06:41.596546: step 1520, loss 0.14396, acc 0.921875
2020-02-08T23:06:41.786666: step 1521, loss 0.119566, acc 0.984375
2020-02-08T23:06:41.990110: step 1522, loss 0.135502, acc 0.953125
2020-02-08T23:06:42.195397: step 1523, loss 0.16879, acc 0.921875
2020-02-08T23:06:42.414051: step 1524, loss 0.0888754, acc 0.984375
2020-02-08T23:06:42.625017: step 1525, loss 0.097663, acc 0.984375
2020-02-08T23:06:42.820502: step 1526, loss 0.198337, acc 0.9375
2020-02-08T23:06:42.989502: step 1527, loss 0.18927, acc 0.921875
2020-02-08T23:06:43.211661: step 1528, loss 0.23005, acc 0.90625
2020-02-08T23:06:43.414692: step 1529, loss 0.146253, acc 0.9375
2020-02-08T23:06:43.572562: step 1530, loss 0.197787, acc 0.921875
2020-02-08T23:06:43.881873: step 1531, loss 0.156127, acc 0.921875
2020-02-08T23:06:44.156583: step 1532, loss 0.108519, acc 0.984375
2020-02-08T23:06:44.364076: step 1533, loss 0.216237, acc 0.921875
2020-02-08T23:06:44.565070: step 1534, loss 0.172766, acc 0.96875
2020-02-08T23:06:44.740214: step 1535, loss 0.138168, acc 0.953125
2020-02-08T23:06:44.993095: step 1536, loss 0.174182, acc 0.921875
2020-02-08T23:06:45.173190: step 1537, loss 0.200192, acc 0.890625
2020-02-08T23:06:45.337508: step 1538, loss 0.0920476, acc 0.96875
2020-02-08T23:06:45.506031: step 1539, loss 0.0524286, acc 1
2020-02-08T23:06:45.664080: step 1540, loss 0.111755, acc 0.953125
2020-02-08T23:06:45.821636: step 1541, loss 0.0719125, acc 1
2020-02-08T23:06:45.980907: step 1542, loss 0.116049, acc 0.96875
2020-02-08T23:06:46.165677: step 1543, loss 0.140492, acc 0.953125
2020-02-08T23:06:46.345314: step 1544, loss 0.0927634, acc 0.984375
2020-02-08T23:06:46.532164: step 1545, loss 0.204487, acc 0.90625
2020-02-08T23:06:46.786111: step 1546, loss 0.190001, acc 0.921875
2020-02-08T23:06:46.974700: step 1547, loss 0.124331, acc 0.984375
2020-02-08T23:06:47.167875: step 1548, loss 0.113078, acc 0.96875
2020-02-08T23:06:47.326357: step 1549, loss 0.180582, acc 0.9375
2020-02-08T23:06:47.479338: step 1550, loss 0.0901452, acc 0.984375
2020-02-08T23:06:47.635968: step 1551, loss 0.174272, acc 0.921875
2020-02-08T23:06:47.811672: step 1552, loss 0.114471, acc 0.953125
2020-02-08T23:06:47.986592: step 1553, loss 0.190925, acc 0.9375
2020-02-08T23:06:48.191621: step 1554, loss 0.145942, acc 0.96875
2020-02-08T23:06:48.367426: step 1555, loss 0.0693673, acc 1
2020-02-08T23:06:48.541891: step 1556, loss 0.12279, acc 0.9375
2020-02-08T23:06:48.729485: step 1557, loss 0.139695, acc 0.921875
2020-02-08T23:06:48.913515: step 1558, loss 0.245288, acc 0.9375
2020-02-08T23:06:49.074261: step 1559, loss 0.120773, acc 0.96875
2020-02-08T23:06:49.229986: step 1560, loss 0.132665, acc 0.9375
2020-02-08T23:06:49.392507: step 1561, loss 0.080651, acc 0.953125
2020-02-08T23:06:49.546014: step 1562, loss 0.109412, acc 0.90625
2020-02-08T23:06:49.698658: step 1563, loss 0.238011, acc 0.875
2020-02-08T23:06:49.853234: step 1564, loss 0.101897, acc 0.953125
2020-02-08T23:06:50.013363: step 1565, loss 0.14546, acc 0.9375
2020-02-08T23:06:50.169228: step 1566, loss 0.100206, acc 0.96875
2020-02-08T23:06:50.326714: step 1567, loss 0.110957, acc 0.953125
2020-02-08T23:06:50.478621: step 1568, loss 0.108402, acc 0.96875
2020-02-08T23:06:50.634453: step 1569, loss 0.0911059, acc 0.96875
2020-02-08T23:06:50.791400: step 1570, loss 0.109026, acc 0.96875
2020-02-08T23:06:50.953384: step 1571, loss 0.138153, acc 0.96875
2020-02-08T23:06:51.110316: step 1572, loss 0.130777, acc 0.96875
2020-02-08T23:06:51.271411: step 1573, loss 0.12916, acc 0.953125
2020-02-08T23:06:51.430467: step 1574, loss 0.0652302, acc 0.984375
2020-02-08T23:06:51.591697: step 1575, loss 0.127895, acc 0.953125
2020-02-08T23:06:51.750198: step 1576, loss 0.190038, acc 0.890625
2020-02-08T23:06:51.909686: step 1577, loss 0.112908, acc 0.953125
2020-02-08T23:06:52.064586: step 1578, loss 0.269447, acc 0.921875
2020-02-08T23:06:52.236138: step 1579, loss 0.115049, acc 0.953125
2020-02-08T23:06:52.414120: step 1580, loss 0.109179, acc 0.9375
2020-02-08T23:06:52.607255: step 1581, loss 0.0951214, acc 0.96875
2020-02-08T23:06:52.865472: step 1582, loss 0.178103, acc 0.875
2020-02-08T23:06:53.113207: step 1583, loss 0.158831, acc 0.953125
2020-02-08T23:06:53.375934: step 1584, loss 0.284154, acc 0.859375
2020-02-08T23:06:53.638238: step 1585, loss 0.174034, acc 0.953125
2020-02-08T23:06:53.804396: step 1586, loss 0.146589, acc 0.953125
2020-02-08T23:06:53.996958: step 1587, loss 0.118424, acc 0.9375
2020-02-08T23:06:54.173441: step 1588, loss 0.0900897, acc 0.96875
2020-02-08T23:06:54.343351: step 1589, loss 0.103117, acc 0.96875
2020-02-08T23:06:54.506836: step 1590, loss 0.18636, acc 0.921875
2020-02-08T23:06:54.670960: step 1591, loss 0.131692, acc 0.953125
2020-02-08T23:06:54.830593: step 1592, loss 0.0950916, acc 0.953125
2020-02-08T23:06:54.999708: step 1593, loss 0.128585, acc 0.953125
2020-02-08T23:06:55.180024: step 1594, loss 0.140448, acc 0.96875
2020-02-08T23:06:55.359484: step 1595, loss 0.164186, acc 0.953125
2020-02-08T23:06:55.517852: step 1596, loss 0.124683, acc 0.9375
2020-02-08T23:06:55.684237: step 1597, loss 0.165741, acc 0.953125
2020-02-08T23:06:55.854823: step 1598, loss 0.102614, acc 1
2020-02-08T23:06:56.039000: step 1599, loss 0.130768, acc 0.9375
2020-02-08T23:06:56.232799: step 1600, loss 0.173765, acc 0.90625

Evaluation:
2020-02-08T23:06:56.540406: step 1600, loss 0.666254, acc 0.724203

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1600

2020-02-08T23:06:58.177523: step 1601, loss 0.225444, acc 0.859375
2020-02-08T23:06:58.399933: step 1602, loss 0.129044, acc 0.953125
2020-02-08T23:06:58.600282: step 1603, loss 0.0677144, acc 1
2020-02-08T23:06:58.825339: step 1604, loss 0.1846, acc 0.890625
2020-02-08T23:06:59.001407: step 1605, loss 0.162371, acc 0.9375
2020-02-08T23:06:59.216402: step 1606, loss 0.224536, acc 0.90625
2020-02-08T23:06:59.414943: step 1607, loss 0.12707, acc 0.953125
2020-02-08T23:06:59.588371: step 1608, loss 0.123295, acc 0.953125
2020-02-08T23:06:59.767051: step 1609, loss 0.0631815, acc 0.984375
2020-02-08T23:06:59.923031: step 1610, loss 0.172498, acc 0.921875
2020-02-08T23:07:00.086691: step 1611, loss 0.16347, acc 0.9375
2020-02-08T23:07:00.275525: step 1612, loss 0.143012, acc 0.953125
2020-02-08T23:07:00.450119: step 1613, loss 0.192601, acc 0.9375
2020-02-08T23:07:00.632104: step 1614, loss 0.12341, acc 0.953125
2020-02-08T23:07:00.793292: step 1615, loss 0.154581, acc 0.921875
2020-02-08T23:07:00.994338: step 1616, loss 0.0747731, acc 1
2020-02-08T23:07:01.211505: step 1617, loss 0.11666, acc 0.96875
2020-02-08T23:07:01.394300: step 1618, loss 0.132106, acc 0.953125
2020-02-08T23:07:01.557533: step 1619, loss 0.23776, acc 0.921875
2020-02-08T23:07:01.731837: step 1620, loss 0.116706, acc 0.953125
2020-02-08T23:07:02.006373: step 1621, loss 0.213778, acc 0.921875
2020-02-08T23:07:02.167943: step 1622, loss 0.10303, acc 0.96875
2020-02-08T23:07:02.334766: step 1623, loss 0.125126, acc 0.96875
2020-02-08T23:07:02.514728: step 1624, loss 0.145307, acc 0.9375
2020-02-08T23:07:02.681953: step 1625, loss 0.0942028, acc 0.953125
2020-02-08T23:07:02.897717: step 1626, loss 0.0811744, acc 0.96875
2020-02-08T23:07:03.054562: step 1627, loss 0.261391, acc 0.890625
2020-02-08T23:07:03.225983: step 1628, loss 0.171312, acc 0.921875
2020-02-08T23:07:03.396394: step 1629, loss 0.250391, acc 0.890625
2020-02-08T23:07:03.578606: step 1630, loss 0.148298, acc 0.9375
2020-02-08T23:07:03.744679: step 1631, loss 0.23238, acc 0.9375
2020-02-08T23:07:03.929714: step 1632, loss 0.183101, acc 0.921875
2020-02-08T23:07:04.119832: step 1633, loss 0.117966, acc 0.96875
2020-02-08T23:07:04.318083: step 1634, loss 0.199706, acc 0.9375
2020-02-08T23:07:04.508829: step 1635, loss 0.101522, acc 0.9375
2020-02-08T23:07:04.665342: step 1636, loss 0.123607, acc 0.96875
2020-02-08T23:07:04.837293: step 1637, loss 0.278737, acc 0.890625
2020-02-08T23:07:05.020732: step 1638, loss 0.124487, acc 0.953125
2020-02-08T23:07:05.215329: step 1639, loss 0.113098, acc 0.96875
2020-02-08T23:07:05.388443: step 1640, loss 0.116223, acc 0.96875
2020-02-08T23:07:05.575232: step 1641, loss 0.115273, acc 0.921875
2020-02-08T23:07:05.734874: step 1642, loss 0.0674663, acc 0.984375
2020-02-08T23:07:05.922725: step 1643, loss 0.223716, acc 0.90625
2020-02-08T23:07:06.133344: step 1644, loss 0.100974, acc 0.953125
2020-02-08T23:07:06.294662: step 1645, loss 0.278578, acc 0.90625
2020-02-08T23:07:06.517160: step 1646, loss 0.150236, acc 0.9375
2020-02-08T23:07:06.680485: step 1647, loss 0.2057, acc 0.921875
2020-02-08T23:07:06.895354: step 1648, loss 0.140252, acc 0.953125
2020-02-08T23:07:07.038617: step 1649, loss 0.178276, acc 0.90625
2020-02-08T23:07:07.238465: step 1650, loss 0.13831, acc 0.916667
2020-02-08T23:07:07.480654: step 1651, loss 0.123083, acc 0.953125
2020-02-08T23:07:07.712732: step 1652, loss 0.0696845, acc 1
2020-02-08T23:07:07.900918: step 1653, loss 0.0462488, acc 1
2020-02-08T23:07:08.085209: step 1654, loss 0.143395, acc 0.921875
2020-02-08T23:07:08.267261: step 1655, loss 0.130106, acc 0.9375
2020-02-08T23:07:08.449344: step 1656, loss 0.115801, acc 0.96875
2020-02-08T23:07:08.633456: step 1657, loss 0.148727, acc 0.953125
2020-02-08T23:07:08.824242: step 1658, loss 0.0563668, acc 1
2020-02-08T23:07:09.005060: step 1659, loss 0.0485818, acc 0.984375
2020-02-08T23:07:09.189280: step 1660, loss 0.107008, acc 0.953125
2020-02-08T23:07:09.363683: step 1661, loss 0.0708721, acc 0.984375
2020-02-08T23:07:09.527762: step 1662, loss 0.105809, acc 0.953125
2020-02-08T23:07:09.689154: step 1663, loss 0.0931177, acc 0.96875
2020-02-08T23:07:09.863390: step 1664, loss 0.129566, acc 0.9375
2020-02-08T23:07:10.053430: step 1665, loss 0.07903, acc 0.96875
2020-02-08T23:07:10.256277: step 1666, loss 0.143114, acc 0.921875
2020-02-08T23:07:10.449515: step 1667, loss 0.0767026, acc 0.984375
2020-02-08T23:07:10.647758: step 1668, loss 0.0964021, acc 0.96875
2020-02-08T23:07:10.863508: step 1669, loss 0.126198, acc 0.921875
2020-02-08T23:07:11.041292: step 1670, loss 0.0588532, acc 1
2020-02-08T23:07:11.221157: step 1671, loss 0.122873, acc 0.96875
2020-02-08T23:07:11.402320: step 1672, loss 0.133631, acc 0.9375
2020-02-08T23:07:11.582023: step 1673, loss 0.169737, acc 0.96875
2020-02-08T23:07:11.786245: step 1674, loss 0.22224, acc 0.90625
2020-02-08T23:07:12.027850: step 1675, loss 0.138195, acc 0.953125
2020-02-08T23:07:12.188403: step 1676, loss 0.142203, acc 0.953125
2020-02-08T23:07:12.381950: step 1677, loss 0.117198, acc 0.953125
2020-02-08T23:07:12.549718: step 1678, loss 0.114157, acc 0.96875
2020-02-08T23:07:12.725442: step 1679, loss 0.0950869, acc 0.953125
2020-02-08T23:07:12.875557: step 1680, loss 0.121598, acc 0.96875
2020-02-08T23:07:13.036090: step 1681, loss 0.195521, acc 0.9375
2020-02-08T23:07:13.188426: step 1682, loss 0.203975, acc 0.953125
2020-02-08T23:07:13.341811: step 1683, loss 0.16381, acc 0.9375
2020-02-08T23:07:13.489911: step 1684, loss 0.127203, acc 0.96875
2020-02-08T23:07:13.648298: step 1685, loss 0.0679254, acc 0.984375
2020-02-08T23:07:13.806025: step 1686, loss 0.059699, acc 0.984375
2020-02-08T23:07:13.976296: step 1687, loss 0.124304, acc 0.96875
2020-02-08T23:07:14.143252: step 1688, loss 0.0937424, acc 0.953125
2020-02-08T23:07:14.297863: step 1689, loss 0.127081, acc 0.953125
2020-02-08T23:07:14.454924: step 1690, loss 0.133591, acc 0.921875
2020-02-08T23:07:14.612829: step 1691, loss 0.0519556, acc 1
2020-02-08T23:07:14.767187: step 1692, loss 0.120241, acc 0.953125
2020-02-08T23:07:14.917199: step 1693, loss 0.113848, acc 0.9375
2020-02-08T23:07:15.069724: step 1694, loss 0.191097, acc 0.96875
2020-02-08T23:07:15.226553: step 1695, loss 0.170602, acc 0.953125
2020-02-08T23:07:15.386360: step 1696, loss 0.156591, acc 0.90625
2020-02-08T23:07:15.538992: step 1697, loss 0.133484, acc 0.9375
2020-02-08T23:07:15.690902: step 1698, loss 0.10882, acc 0.9375
2020-02-08T23:07:15.842163: step 1699, loss 0.128668, acc 0.921875
2020-02-08T23:07:15.999602: step 1700, loss 0.123962, acc 0.96875

Evaluation:
2020-02-08T23:07:16.264724: step 1700, loss 0.732462, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1700

2020-02-08T23:07:17.827828: step 1701, loss 0.149588, acc 0.9375
2020-02-08T23:07:17.985170: step 1702, loss 0.278704, acc 0.890625
2020-02-08T23:07:18.138085: step 1703, loss 0.177684, acc 0.921875
2020-02-08T23:07:18.288892: step 1704, loss 0.096674, acc 0.96875
2020-02-08T23:07:18.442692: step 1705, loss 0.240896, acc 0.921875
2020-02-08T23:07:18.601482: step 1706, loss 0.119775, acc 0.9375
2020-02-08T23:07:18.756510: step 1707, loss 0.133646, acc 0.9375
2020-02-08T23:07:18.914910: step 1708, loss 0.0674141, acc 0.96875
2020-02-08T23:07:19.065194: step 1709, loss 0.112495, acc 0.96875
2020-02-08T23:07:19.227212: step 1710, loss 0.13902, acc 0.953125
2020-02-08T23:07:19.387490: step 1711, loss 0.131576, acc 0.9375
2020-02-08T23:07:19.540323: step 1712, loss 0.220283, acc 0.921875
2020-02-08T23:07:19.690697: step 1713, loss 0.126631, acc 0.953125
2020-02-08T23:07:19.841796: step 1714, loss 0.239163, acc 0.890625
2020-02-08T23:07:20.001370: step 1715, loss 0.0472847, acc 1
2020-02-08T23:07:20.157073: step 1716, loss 0.0795166, acc 0.984375
2020-02-08T23:07:20.311701: step 1717, loss 0.0994207, acc 0.984375
2020-02-08T23:07:20.466432: step 1718, loss 0.112131, acc 0.953125
2020-02-08T23:07:20.617469: step 1719, loss 0.0959308, acc 0.984375
2020-02-08T23:07:20.783907: step 1720, loss 0.155586, acc 0.921875
2020-02-08T23:07:20.944459: step 1721, loss 0.122141, acc 0.9375
2020-02-08T23:07:21.093563: step 1722, loss 0.102999, acc 0.984375
2020-02-08T23:07:21.245831: step 1723, loss 0.101315, acc 0.96875
2020-02-08T23:07:21.404379: step 1724, loss 0.160575, acc 0.921875
2020-02-08T23:07:21.563094: step 1725, loss 0.173349, acc 0.953125
2020-02-08T23:07:21.717492: step 1726, loss 0.120554, acc 0.9375
2020-02-08T23:07:21.869562: step 1727, loss 0.0510643, acc 1
2020-02-08T23:07:22.024357: step 1728, loss 0.0862805, acc 0.96875
2020-02-08T23:07:22.181221: step 1729, loss 0.0614082, acc 0.984375
2020-02-08T23:07:22.341013: step 1730, loss 0.138102, acc 0.953125
2020-02-08T23:07:22.494420: step 1731, loss 0.0965868, acc 0.96875
2020-02-08T23:07:22.655114: step 1732, loss 0.134786, acc 0.953125
2020-02-08T23:07:22.822332: step 1733, loss 0.121618, acc 0.953125
2020-02-08T23:07:22.978443: step 1734, loss 0.104619, acc 0.984375
2020-02-08T23:07:23.136600: step 1735, loss 0.0782729, acc 0.984375
2020-02-08T23:07:23.282084: step 1736, loss 0.110856, acc 0.953125
2020-02-08T23:07:23.430984: step 1737, loss 0.149202, acc 0.9375
2020-02-08T23:07:23.588665: step 1738, loss 0.140797, acc 0.953125
2020-02-08T23:07:23.738397: step 1739, loss 0.0599942, acc 0.984375
2020-02-08T23:07:23.885451: step 1740, loss 0.116707, acc 0.953125
2020-02-08T23:07:24.037868: step 1741, loss 0.104756, acc 0.953125
2020-02-08T23:07:24.195351: step 1742, loss 0.0973383, acc 0.96875
2020-02-08T23:07:24.354478: step 1743, loss 0.0624332, acc 1
2020-02-08T23:07:24.502902: step 1744, loss 0.0885721, acc 0.984375
2020-02-08T23:07:24.657173: step 1745, loss 0.149847, acc 0.921875
2020-02-08T23:07:24.828115: step 1746, loss 0.17803, acc 0.921875
2020-02-08T23:07:25.004647: step 1747, loss 0.105404, acc 0.953125
2020-02-08T23:07:25.172909: step 1748, loss 0.168944, acc 0.9375
2020-02-08T23:07:25.336285: step 1749, loss 0.225677, acc 0.90625
2020-02-08T23:07:25.501412: step 1750, loss 0.0833076, acc 0.984375
2020-02-08T23:07:25.661087: step 1751, loss 0.157768, acc 0.9375
2020-02-08T23:07:25.825623: step 1752, loss 0.0882019, acc 0.984375
2020-02-08T23:07:25.991840: step 1753, loss 0.0699625, acc 0.984375
2020-02-08T23:07:26.150918: step 1754, loss 0.179251, acc 0.9375
2020-02-08T23:07:26.309261: step 1755, loss 0.114366, acc 0.953125
2020-02-08T23:07:26.459032: step 1756, loss 0.069709, acc 0.984375
2020-02-08T23:07:26.615735: step 1757, loss 0.121634, acc 0.9375
2020-02-08T23:07:26.778333: step 1758, loss 0.103808, acc 0.9375
2020-02-08T23:07:26.940727: step 1759, loss 0.0982776, acc 0.96875
2020-02-08T23:07:27.091323: step 1760, loss 0.0532813, acc 0.984375
2020-02-08T23:07:27.244010: step 1761, loss 0.0794981, acc 0.96875
2020-02-08T23:07:27.408825: step 1762, loss 0.111664, acc 0.953125
2020-02-08T23:07:27.588919: step 1763, loss 0.11567, acc 0.9375
2020-02-08T23:07:27.822606: step 1764, loss 0.104223, acc 0.984375
2020-02-08T23:07:28.061082: step 1765, loss 0.0681287, acc 0.984375
2020-02-08T23:07:28.216008: step 1766, loss 0.18654, acc 0.890625
2020-02-08T23:07:28.373847: step 1767, loss 0.135304, acc 0.921875
2020-02-08T23:07:28.525038: step 1768, loss 0.136853, acc 0.96875
2020-02-08T23:07:28.675797: step 1769, loss 0.0544496, acc 0.984375
2020-02-08T23:07:28.830499: step 1770, loss 0.0890422, acc 0.96875
2020-02-08T23:07:28.991133: step 1771, loss 0.118382, acc 0.953125
2020-02-08T23:07:29.144282: step 1772, loss 0.163109, acc 0.9375
2020-02-08T23:07:29.302660: step 1773, loss 0.123653, acc 0.953125
2020-02-08T23:07:29.454882: step 1774, loss 0.119788, acc 0.953125
2020-02-08T23:07:29.611384: step 1775, loss 0.151276, acc 0.90625
2020-02-08T23:07:29.774296: step 1776, loss 0.0784855, acc 0.984375
2020-02-08T23:07:29.931042: step 1777, loss 0.133717, acc 0.953125
2020-02-08T23:07:30.083548: step 1778, loss 0.195189, acc 0.921875
2020-02-08T23:07:30.240647: step 1779, loss 0.124836, acc 0.96875
2020-02-08T23:07:30.394984: step 1780, loss 0.0848798, acc 0.984375
2020-02-08T23:07:30.552581: step 1781, loss 0.0643089, acc 0.984375
2020-02-08T23:07:30.707079: step 1782, loss 0.154566, acc 0.9375
2020-02-08T23:07:30.868456: step 1783, loss 0.140992, acc 0.9375
2020-02-08T23:07:31.031078: step 1784, loss 0.133437, acc 0.921875
2020-02-08T23:07:31.189206: step 1785, loss 0.143473, acc 0.9375
2020-02-08T23:07:31.345203: step 1786, loss 0.0976697, acc 0.953125
2020-02-08T23:07:31.499693: step 1787, loss 0.375476, acc 0.875
2020-02-08T23:07:31.661253: step 1788, loss 0.131315, acc 0.96875
2020-02-08T23:07:31.825491: step 1789, loss 0.0901078, acc 0.984375
2020-02-08T23:07:31.988963: step 1790, loss 0.0780308, acc 0.984375
2020-02-08T23:07:32.144525: step 1791, loss 0.237323, acc 0.9375
2020-02-08T23:07:32.296747: step 1792, loss 0.0715857, acc 0.984375
2020-02-08T23:07:32.448410: step 1793, loss 0.292822, acc 0.859375
2020-02-08T23:07:32.607704: step 1794, loss 0.195524, acc 0.9375
2020-02-08T23:07:32.760969: step 1795, loss 0.241702, acc 0.890625
2020-02-08T23:07:32.915636: step 1796, loss 0.125124, acc 0.953125
2020-02-08T23:07:33.068032: step 1797, loss 0.119514, acc 0.9375
2020-02-08T23:07:33.226722: step 1798, loss 0.191152, acc 0.90625
2020-02-08T23:07:33.384253: step 1799, loss 0.115256, acc 0.96875
2020-02-08T23:07:33.534838: step 1800, loss 0.128668, acc 0.966667

Evaluation:
2020-02-08T23:07:33.799741: step 1800, loss 0.703096, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1800

2020-02-08T23:07:35.337382: step 1801, loss 0.0809942, acc 0.984375
2020-02-08T23:07:35.468544: step 1802, loss 0.0787358, acc 0.984375
2020-02-08T23:07:35.611164: step 1803, loss 0.0441533, acc 1
2020-02-08T23:07:35.755910: step 1804, loss 0.0786197, acc 0.96875
2020-02-08T23:07:35.898023: step 1805, loss 0.195604, acc 0.9375
2020-02-08T23:07:36.038408: step 1806, loss 0.105053, acc 0.96875
2020-02-08T23:07:36.181084: step 1807, loss 0.100957, acc 0.96875
2020-02-08T23:07:36.331037: step 1808, loss 0.0604082, acc 0.984375
2020-02-08T23:07:36.532788: step 1809, loss 0.0625116, acc 1
2020-02-08T23:07:36.669065: step 1810, loss 0.106524, acc 0.96875
2020-02-08T23:07:36.798377: step 1811, loss 0.128549, acc 0.96875
2020-02-08T23:07:36.924661: step 1812, loss 0.119789, acc 0.953125
2020-02-08T23:07:37.048407: step 1813, loss 0.114523, acc 0.953125
2020-02-08T23:07:37.174307: step 1814, loss 0.123093, acc 0.96875
2020-02-08T23:07:37.298840: step 1815, loss 0.0394532, acc 1
2020-02-08T23:07:37.427437: step 1816, loss 0.122287, acc 0.953125
2020-02-08T23:07:37.553882: step 1817, loss 0.0810136, acc 0.96875
2020-02-08T23:07:37.683121: step 1818, loss 0.0815512, acc 0.984375
2020-02-08T23:07:37.812360: step 1819, loss 0.0796888, acc 0.96875
2020-02-08T23:07:37.935962: step 1820, loss 0.102801, acc 0.953125
2020-02-08T23:07:38.064882: step 1821, loss 0.0912717, acc 0.953125
2020-02-08T23:07:38.187098: step 1822, loss 0.102019, acc 0.953125
2020-02-08T23:07:38.311082: step 1823, loss 0.0867121, acc 0.953125
2020-02-08T23:07:38.433242: step 1824, loss 0.0513652, acc 1
2020-02-08T23:07:38.558743: step 1825, loss 0.120483, acc 0.96875
2020-02-08T23:07:38.680859: step 1826, loss 0.0862115, acc 0.9375
2020-02-08T23:07:38.809062: step 1827, loss 0.100643, acc 0.953125
2020-02-08T23:07:38.957123: step 1828, loss 0.086872, acc 0.96875
2020-02-08T23:07:39.085886: step 1829, loss 0.0919297, acc 0.96875
2020-02-08T23:07:39.224942: step 1830, loss 0.0613488, acc 1
2020-02-08T23:07:39.366460: step 1831, loss 0.0488844, acc 0.984375
2020-02-08T23:07:39.503643: step 1832, loss 0.0352614, acc 0.984375
2020-02-08T23:07:39.642434: step 1833, loss 0.0762738, acc 1
2020-02-08T23:07:39.782534: step 1834, loss 0.147326, acc 0.890625
2020-02-08T23:07:39.910234: step 1835, loss 0.0603439, acc 0.984375
2020-02-08T23:07:40.035498: step 1836, loss 0.100983, acc 0.9375
2020-02-08T23:07:40.163394: step 1837, loss 0.0598936, acc 0.984375
2020-02-08T23:07:40.285745: step 1838, loss 0.0975255, acc 0.953125
2020-02-08T23:07:40.412464: step 1839, loss 0.0357949, acc 1
2020-02-08T23:07:40.536360: step 1840, loss 0.0462198, acc 1
2020-02-08T23:07:40.663093: step 1841, loss 0.134453, acc 0.921875
2020-02-08T23:07:40.787614: step 1842, loss 0.159904, acc 0.953125
2020-02-08T23:07:40.924115: step 1843, loss 0.0713687, acc 0.984375
2020-02-08T23:07:41.050419: step 1844, loss 0.081273, acc 0.984375
2020-02-08T23:07:41.180971: step 1845, loss 0.110832, acc 0.953125
2020-02-08T23:07:41.314589: step 1846, loss 0.106439, acc 0.921875
2020-02-08T23:07:41.492560: step 1847, loss 0.070892, acc 0.953125
2020-02-08T23:07:41.683233: step 1848, loss 0.10963, acc 0.984375
2020-02-08T23:07:41.868361: step 1849, loss 0.183001, acc 0.9375
2020-02-08T23:07:42.020723: step 1850, loss 0.0822974, acc 0.96875
2020-02-08T23:07:42.184114: step 1851, loss 0.061428, acc 1
2020-02-08T23:07:42.327330: step 1852, loss 0.072102, acc 0.96875
2020-02-08T23:07:42.468565: step 1853, loss 0.183505, acc 0.921875
2020-02-08T23:07:42.610102: step 1854, loss 0.124588, acc 0.96875
2020-02-08T23:07:42.753041: step 1855, loss 0.138302, acc 0.953125
2020-02-08T23:07:42.892261: step 1856, loss 0.09127, acc 0.9375
2020-02-08T23:07:43.037166: step 1857, loss 0.111204, acc 0.9375
2020-02-08T23:07:43.186583: step 1858, loss 0.133654, acc 0.953125
2020-02-08T23:07:43.331388: step 1859, loss 0.0784248, acc 0.984375
2020-02-08T23:07:43.473245: step 1860, loss 0.0520078, acc 0.984375
2020-02-08T23:07:43.620189: step 1861, loss 0.143772, acc 0.953125
2020-02-08T23:07:43.753977: step 1862, loss 0.0581503, acc 1
2020-02-08T23:07:43.894042: step 1863, loss 0.12444, acc 0.921875
2020-02-08T23:07:44.056323: step 1864, loss 0.123761, acc 0.96875
2020-02-08T23:07:44.203238: step 1865, loss 0.0437214, acc 0.984375
2020-02-08T23:07:44.354151: step 1866, loss 0.0314611, acc 1
2020-02-08T23:07:44.503166: step 1867, loss 0.0812162, acc 0.984375
2020-02-08T23:07:44.651404: step 1868, loss 0.0797227, acc 0.953125
2020-02-08T23:07:44.793463: step 1869, loss 0.12264, acc 0.984375
2020-02-08T23:07:44.930391: step 1870, loss 0.103234, acc 0.953125
2020-02-08T23:07:45.062401: step 1871, loss 0.192042, acc 0.96875
2020-02-08T23:07:45.200486: step 1872, loss 0.142826, acc 0.953125
2020-02-08T23:07:45.338957: step 1873, loss 0.0620829, acc 0.96875
2020-02-08T23:07:45.481909: step 1874, loss 0.179541, acc 0.921875
2020-02-08T23:07:45.627104: step 1875, loss 0.0573685, acc 0.96875
2020-02-08T23:07:45.765692: step 1876, loss 0.14873, acc 0.953125
2020-02-08T23:07:45.908042: step 1877, loss 0.0472608, acc 0.984375
2020-02-08T23:07:46.047870: step 1878, loss 0.161704, acc 0.9375
2020-02-08T23:07:46.188437: step 1879, loss 0.118608, acc 0.953125
2020-02-08T23:07:46.337305: step 1880, loss 0.0996359, acc 0.953125
2020-02-08T23:07:46.486040: step 1881, loss 0.102294, acc 0.953125
2020-02-08T23:07:46.634322: step 1882, loss 0.174993, acc 0.921875
2020-02-08T23:07:46.774689: step 1883, loss 0.0574275, acc 0.984375
2020-02-08T23:07:46.916133: step 1884, loss 0.296111, acc 0.84375
2020-02-08T23:07:47.059992: step 1885, loss 0.0875385, acc 0.96875
2020-02-08T23:07:47.244664: step 1886, loss 0.0369593, acc 0.984375
2020-02-08T23:07:47.402335: step 1887, loss 0.125073, acc 0.953125
2020-02-08T23:07:47.562516: step 1888, loss 0.101167, acc 0.96875
2020-02-08T23:07:47.747441: step 1889, loss 0.0989844, acc 0.953125
2020-02-08T23:07:47.897509: step 1890, loss 0.135811, acc 0.9375
2020-02-08T23:07:48.046910: step 1891, loss 0.057624, acc 0.96875
2020-02-08T23:07:48.198708: step 1892, loss 0.121435, acc 0.96875
2020-02-08T23:07:48.374045: step 1893, loss 0.0656642, acc 0.96875
2020-02-08T23:07:48.541308: step 1894, loss 0.0872081, acc 0.984375
2020-02-08T23:07:48.732425: step 1895, loss 0.0410766, acc 0.984375
2020-02-08T23:07:48.923689: step 1896, loss 0.11509, acc 0.9375
2020-02-08T23:07:49.143092: step 1897, loss 0.0535948, acc 1
2020-02-08T23:07:49.384114: step 1898, loss 0.0539401, acc 0.96875
2020-02-08T23:07:49.599794: step 1899, loss 0.123594, acc 0.953125
2020-02-08T23:07:49.784564: step 1900, loss 0.0989837, acc 0.953125

Evaluation:
2020-02-08T23:07:50.192220: step 1900, loss 0.729467, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-1900

2020-02-08T23:07:51.912709: step 1901, loss 0.04527, acc 1
2020-02-08T23:07:52.090201: step 1902, loss 0.111989, acc 0.953125
2020-02-08T23:07:52.297671: step 1903, loss 0.0564754, acc 0.984375
2020-02-08T23:07:52.487290: step 1904, loss 0.142522, acc 0.9375
2020-02-08T23:07:52.679724: step 1905, loss 0.0799791, acc 0.953125
2020-02-08T23:07:52.879492: step 1906, loss 0.0957327, acc 0.96875
2020-02-08T23:07:53.072953: step 1907, loss 0.198488, acc 0.953125
2020-02-08T23:07:53.273661: step 1908, loss 0.0602364, acc 0.984375
2020-02-08T23:07:53.467654: step 1909, loss 0.0969748, acc 0.953125
2020-02-08T23:07:53.660275: step 1910, loss 0.20098, acc 0.921875
2020-02-08T23:07:53.855617: step 1911, loss 0.0394965, acc 0.984375
2020-02-08T23:07:54.048628: step 1912, loss 0.0949037, acc 0.953125
2020-02-08T23:07:54.213201: step 1913, loss 0.0709648, acc 0.984375
2020-02-08T23:07:54.367456: step 1914, loss 0.0742106, acc 0.96875
2020-02-08T23:07:54.521755: step 1915, loss 0.174427, acc 0.953125
2020-02-08T23:07:54.678681: step 1916, loss 0.0457569, acc 1
2020-02-08T23:07:54.830606: step 1917, loss 0.13663, acc 0.921875
2020-02-08T23:07:54.980248: step 1918, loss 0.0682409, acc 0.96875
2020-02-08T23:07:55.131035: step 1919, loss 0.0679306, acc 0.96875
2020-02-08T23:07:55.281382: step 1920, loss 0.206083, acc 0.9375
2020-02-08T23:07:55.436529: step 1921, loss 0.110227, acc 0.953125
2020-02-08T23:07:55.589615: step 1922, loss 0.0899858, acc 0.96875
2020-02-08T23:07:55.733221: step 1923, loss 0.0449203, acc 1
2020-02-08T23:07:55.883317: step 1924, loss 0.0730915, acc 0.984375
2020-02-08T23:07:56.033351: step 1925, loss 0.113591, acc 0.9375
2020-02-08T23:07:56.186734: step 1926, loss 0.0421746, acc 1
2020-02-08T23:07:56.333391: step 1927, loss 0.0889801, acc 0.953125
2020-02-08T23:07:56.484026: step 1928, loss 0.0928426, acc 0.96875
2020-02-08T23:07:56.635903: step 1929, loss 0.0447954, acc 0.984375
2020-02-08T23:07:56.797952: step 1930, loss 0.106141, acc 0.96875
2020-02-08T23:07:56.950992: step 1931, loss 0.164648, acc 0.921875
2020-02-08T23:07:57.108350: step 1932, loss 0.0713599, acc 0.96875
2020-02-08T23:07:57.268397: step 1933, loss 0.0815407, acc 0.96875
2020-02-08T23:07:57.429605: step 1934, loss 0.109096, acc 0.953125
2020-02-08T23:07:57.582458: step 1935, loss 0.0497392, acc 0.984375
2020-02-08T23:07:57.736673: step 1936, loss 0.147021, acc 0.90625
2020-02-08T23:07:57.891335: step 1937, loss 0.16388, acc 0.921875
2020-02-08T23:07:58.046494: step 1938, loss 0.0558612, acc 1
2020-02-08T23:07:58.211352: step 1939, loss 0.102446, acc 0.96875
2020-02-08T23:07:58.359914: step 1940, loss 0.0692917, acc 0.984375
2020-02-08T23:07:58.519968: step 1941, loss 0.141416, acc 0.953125
2020-02-08T23:07:58.801382: step 1942, loss 0.110982, acc 0.953125
2020-02-08T23:07:58.953574: step 1943, loss 0.0720868, acc 0.96875
2020-02-08T23:07:59.118182: step 1944, loss 0.147518, acc 0.953125
2020-02-08T23:07:59.275790: step 1945, loss 0.0373077, acc 1
2020-02-08T23:07:59.434167: step 1946, loss 0.0375238, acc 1
2020-02-08T23:07:59.585375: step 1947, loss 0.150254, acc 0.9375
2020-02-08T23:07:59.736119: step 1948, loss 0.0804581, acc 0.984375
2020-02-08T23:07:59.885184: step 1949, loss 0.0963004, acc 0.96875
2020-02-08T23:08:00.034962: step 1950, loss 0.115853, acc 0.95
2020-02-08T23:08:00.186570: step 1951, loss 0.0282537, acc 1
2020-02-08T23:08:00.339424: step 1952, loss 0.0455697, acc 0.984375
2020-02-08T23:08:00.488226: step 1953, loss 0.069431, acc 0.96875
2020-02-08T23:08:00.647630: step 1954, loss 0.0441086, acc 1
2020-02-08T23:08:00.801126: step 1955, loss 0.044894, acc 0.984375
2020-02-08T23:08:00.967488: step 1956, loss 0.0481569, acc 0.984375
2020-02-08T23:08:01.132705: step 1957, loss 0.116473, acc 0.9375
2020-02-08T23:08:01.286212: step 1958, loss 0.0740536, acc 0.984375
2020-02-08T23:08:01.440712: step 1959, loss 0.0446345, acc 1
2020-02-08T23:08:01.595941: step 1960, loss 0.0757699, acc 0.96875
2020-02-08T23:08:01.749015: step 1961, loss 0.0366602, acc 0.984375
2020-02-08T23:08:01.910929: step 1962, loss 0.119446, acc 0.953125
2020-02-08T23:08:02.067463: step 1963, loss 0.0504188, acc 0.984375
2020-02-08T23:08:02.230072: step 1964, loss 0.0642763, acc 0.96875
2020-02-08T23:08:02.390783: step 1965, loss 0.0444873, acc 0.984375
2020-02-08T23:08:02.550613: step 1966, loss 0.0888049, acc 0.96875
2020-02-08T23:08:02.716570: step 1967, loss 0.073403, acc 0.984375
2020-02-08T23:08:02.877726: step 1968, loss 0.0547307, acc 0.96875
2020-02-08T23:08:03.037539: step 1969, loss 0.060914, acc 0.984375
2020-02-08T23:08:03.193700: step 1970, loss 0.0636865, acc 0.984375
2020-02-08T23:08:03.349143: step 1971, loss 0.0699802, acc 0.984375
2020-02-08T23:08:03.503736: step 1972, loss 0.0290598, acc 1
2020-02-08T23:08:03.657132: step 1973, loss 0.076318, acc 0.96875
2020-02-08T23:08:03.819784: step 1974, loss 0.0321581, acc 1
2020-02-08T23:08:03.983089: step 1975, loss 0.0690804, acc 0.96875
2020-02-08T23:08:04.135968: step 1976, loss 0.0993131, acc 0.953125
2020-02-08T23:08:04.286476: step 1977, loss 0.0913668, acc 0.96875
2020-02-08T23:08:04.445870: step 1978, loss 0.0783261, acc 0.96875
2020-02-08T23:08:04.604798: step 1979, loss 0.085608, acc 0.984375
2020-02-08T23:08:04.765210: step 1980, loss 0.0652297, acc 0.984375
2020-02-08T23:08:04.922492: step 1981, loss 0.0322405, acc 1
2020-02-08T23:08:05.080148: step 1982, loss 0.0762095, acc 0.96875
2020-02-08T23:08:05.235467: step 1983, loss 0.0450179, acc 0.984375
2020-02-08T23:08:05.395835: step 1984, loss 0.0557686, acc 0.984375
2020-02-08T23:08:05.554428: step 1985, loss 0.101723, acc 0.96875
2020-02-08T23:08:05.708513: step 1986, loss 0.047691, acc 0.984375
2020-02-08T23:08:05.869952: step 1987, loss 0.0511028, acc 0.984375
2020-02-08T23:08:06.030882: step 1988, loss 0.0526824, acc 0.984375
2020-02-08T23:08:06.186170: step 1989, loss 0.0277439, acc 1
2020-02-08T23:08:06.342812: step 1990, loss 0.0505142, acc 1
2020-02-08T23:08:06.502414: step 1991, loss 0.0425948, acc 0.984375
2020-02-08T23:08:06.662476: step 1992, loss 0.0383434, acc 0.984375
2020-02-08T23:08:06.820118: step 1993, loss 0.05308, acc 0.984375
2020-02-08T23:08:06.980363: step 1994, loss 0.0222255, acc 1
2020-02-08T23:08:07.132100: step 1995, loss 0.0512805, acc 0.96875
2020-02-08T23:08:07.282500: step 1996, loss 0.0335086, acc 1
2020-02-08T23:08:07.436803: step 1997, loss 0.0944918, acc 0.984375
2020-02-08T23:08:07.590483: step 1998, loss 0.0952359, acc 0.953125
2020-02-08T23:08:07.744883: step 1999, loss 0.0385322, acc 0.984375
2020-02-08T23:08:07.892475: step 2000, loss 0.117802, acc 0.953125

Evaluation:
2020-02-08T23:08:08.168638: step 2000, loss 0.765697, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2000

2020-02-08T23:08:09.791108: step 2001, loss 0.0465266, acc 0.984375
2020-02-08T23:08:09.940747: step 2002, loss 0.0965569, acc 0.96875
2020-02-08T23:08:10.096350: step 2003, loss 0.0864475, acc 0.96875
2020-02-08T23:08:10.257095: step 2004, loss 0.0382933, acc 1
2020-02-08T23:08:10.417222: step 2005, loss 0.0353795, acc 1
2020-02-08T23:08:10.576843: step 2006, loss 0.0835433, acc 0.96875
2020-02-08T23:08:10.735325: step 2007, loss 0.0238635, acc 1
2020-02-08T23:08:10.897605: step 2008, loss 0.0620467, acc 0.96875
2020-02-08T23:08:11.058957: step 2009, loss 0.0528575, acc 0.984375
2020-02-08T23:08:11.219334: step 2010, loss 0.0366961, acc 1
2020-02-08T23:08:11.376300: step 2011, loss 0.0414317, acc 0.984375
2020-02-08T23:08:11.534236: step 2012, loss 0.0311645, acc 1
2020-02-08T23:08:11.683031: step 2013, loss 0.0386004, acc 1
2020-02-08T23:08:11.843855: step 2014, loss 0.0381737, acc 0.984375
2020-02-08T23:08:11.999038: step 2015, loss 0.124914, acc 0.953125
2020-02-08T23:08:12.154626: step 2016, loss 0.0839356, acc 0.953125
2020-02-08T23:08:12.311207: step 2017, loss 0.0319177, acc 1
2020-02-08T23:08:12.469701: step 2018, loss 0.0374121, acc 1
2020-02-08T23:08:12.628057: step 2019, loss 0.101588, acc 0.96875
2020-02-08T23:08:12.801151: step 2020, loss 0.120126, acc 0.953125
2020-02-08T23:08:12.966714: step 2021, loss 0.0548155, acc 0.96875
2020-02-08T23:08:13.123386: step 2022, loss 0.062271, acc 0.984375
2020-02-08T23:08:13.281485: step 2023, loss 0.149808, acc 0.953125
2020-02-08T23:08:13.440726: step 2024, loss 0.0551112, acc 0.984375
2020-02-08T23:08:13.603889: step 2025, loss 0.0721573, acc 0.96875
2020-02-08T23:08:13.987849: step 2026, loss 0.0836697, acc 0.9375
2020-02-08T23:08:14.161671: step 2027, loss 0.0239751, acc 1
2020-02-08T23:08:14.318642: step 2028, loss 0.0490761, acc 0.984375
2020-02-08T23:08:14.473704: step 2029, loss 0.0686972, acc 0.9375
2020-02-08T23:08:14.632781: step 2030, loss 0.119242, acc 0.984375
2020-02-08T23:08:14.785538: step 2031, loss 0.055482, acc 0.984375
2020-02-08T23:08:14.936993: step 2032, loss 0.137474, acc 0.9375
2020-02-08T23:08:15.091533: step 2033, loss 0.129089, acc 0.9375
2020-02-08T23:08:15.251227: step 2034, loss 0.08936, acc 0.953125
2020-02-08T23:08:15.403443: step 2035, loss 0.176579, acc 0.953125
2020-02-08T23:08:15.563386: step 2036, loss 0.0497322, acc 0.984375
2020-02-08T23:08:15.720837: step 2037, loss 0.118722, acc 0.984375
2020-02-08T23:08:15.875572: step 2038, loss 0.157697, acc 0.9375
2020-02-08T23:08:16.035505: step 2039, loss 0.0848927, acc 0.984375
2020-02-08T23:08:16.192332: step 2040, loss 0.0450532, acc 0.984375
2020-02-08T23:08:16.348498: step 2041, loss 0.0848114, acc 0.96875
2020-02-08T23:08:16.508028: step 2042, loss 0.0699875, acc 0.984375
2020-02-08T23:08:16.669087: step 2043, loss 0.098696, acc 0.96875
2020-02-08T23:08:16.837064: step 2044, loss 0.0847419, acc 0.96875
2020-02-08T23:08:17.009900: step 2045, loss 0.0831816, acc 0.96875
2020-02-08T23:08:17.174260: step 2046, loss 0.15535, acc 0.953125
2020-02-08T23:08:17.331297: step 2047, loss 0.0462719, acc 1
2020-02-08T23:08:17.488453: step 2048, loss 0.0226385, acc 1
2020-02-08T23:08:17.643470: step 2049, loss 0.0919825, acc 0.953125
2020-02-08T23:08:17.811216: step 2050, loss 0.104206, acc 0.9375
2020-02-08T23:08:17.983922: step 2051, loss 0.0144138, acc 1
2020-02-08T23:08:18.141357: step 2052, loss 0.0794572, acc 0.953125
2020-02-08T23:08:18.311644: step 2053, loss 0.0736619, acc 0.96875
2020-02-08T23:08:18.471454: step 2054, loss 0.0873351, acc 0.96875
2020-02-08T23:08:18.630971: step 2055, loss 0.0744538, acc 0.96875
2020-02-08T23:08:18.791187: step 2056, loss 0.0813645, acc 0.96875
2020-02-08T23:08:18.946316: step 2057, loss 0.0258259, acc 1
2020-02-08T23:08:19.120123: step 2058, loss 0.154286, acc 0.921875
2020-02-08T23:08:19.278253: step 2059, loss 0.0758836, acc 0.96875
2020-02-08T23:08:19.442205: step 2060, loss 0.0441455, acc 0.984375
2020-02-08T23:08:19.606605: step 2061, loss 0.0580973, acc 0.96875
2020-02-08T23:08:19.793812: step 2062, loss 0.104099, acc 0.96875
2020-02-08T23:08:19.960905: step 2063, loss 0.0447626, acc 0.984375
2020-02-08T23:08:20.113770: step 2064, loss 0.0427883, acc 0.984375
2020-02-08T23:08:20.279915: step 2065, loss 0.101338, acc 0.953125
2020-02-08T23:08:20.441349: step 2066, loss 0.0411593, acc 1
2020-02-08T23:08:20.614260: step 2067, loss 0.044086, acc 1
2020-02-08T23:08:20.772798: step 2068, loss 0.0535931, acc 1
2020-02-08T23:08:20.937969: step 2069, loss 0.067043, acc 0.96875
2020-02-08T23:08:21.088255: step 2070, loss 0.155268, acc 0.96875
2020-02-08T23:08:21.246932: step 2071, loss 0.0805822, acc 0.96875
2020-02-08T23:08:21.409406: step 2072, loss 0.0815146, acc 0.96875
2020-02-08T23:08:21.571911: step 2073, loss 0.141999, acc 0.921875
2020-02-08T23:08:21.725615: step 2074, loss 0.0464949, acc 0.96875
2020-02-08T23:08:21.879970: step 2075, loss 0.0754474, acc 0.953125
2020-02-08T23:08:22.042599: step 2076, loss 0.0487555, acc 0.96875
2020-02-08T23:08:22.203089: step 2077, loss 0.0229346, acc 1
2020-02-08T23:08:22.358275: step 2078, loss 0.114271, acc 0.953125
2020-02-08T23:08:22.512586: step 2079, loss 0.076297, acc 0.953125
2020-02-08T23:08:22.671167: step 2080, loss 0.0374851, acc 0.984375
2020-02-08T23:08:22.828929: step 2081, loss 0.0745115, acc 0.96875
2020-02-08T23:08:22.987292: step 2082, loss 0.0818932, acc 0.96875
2020-02-08T23:08:23.135158: step 2083, loss 0.118446, acc 0.953125
2020-02-08T23:08:23.288236: step 2084, loss 0.0725688, acc 0.96875
2020-02-08T23:08:23.439849: step 2085, loss 0.174772, acc 0.921875
2020-02-08T23:08:23.589432: step 2086, loss 0.123356, acc 0.953125
2020-02-08T23:08:23.749275: step 2087, loss 0.0712568, acc 0.984375
2020-02-08T23:08:23.913849: step 2088, loss 0.0504213, acc 0.984375
2020-02-08T23:08:24.074195: step 2089, loss 0.0672371, acc 0.96875
2020-02-08T23:08:24.231659: step 2090, loss 0.0365552, acc 1
2020-02-08T23:08:24.390838: step 2091, loss 0.0503849, acc 0.984375
2020-02-08T23:08:24.546022: step 2092, loss 0.0963364, acc 0.9375
2020-02-08T23:08:24.704395: step 2093, loss 0.0317977, acc 1
2020-02-08T23:08:24.862581: step 2094, loss 0.0552254, acc 0.96875
2020-02-08T23:08:25.024960: step 2095, loss 0.133494, acc 0.953125
2020-02-08T23:08:25.183422: step 2096, loss 0.15361, acc 0.921875
2020-02-08T23:08:25.336233: step 2097, loss 0.0858404, acc 0.953125
2020-02-08T23:08:25.491113: step 2098, loss 0.0650379, acc 0.984375
2020-02-08T23:08:25.657439: step 2099, loss 0.070817, acc 0.96875
2020-02-08T23:08:25.826528: step 2100, loss 0.1012, acc 0.966667

Evaluation:
2020-02-08T23:08:26.143304: step 2100, loss 0.79404, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2100

2020-02-08T23:08:27.700195: step 2101, loss 0.0821786, acc 0.984375
2020-02-08T23:08:27.864557: step 2102, loss 0.0404649, acc 0.984375
2020-02-08T23:08:28.027090: step 2103, loss 0.0480201, acc 0.96875
2020-02-08T23:08:28.189032: step 2104, loss 0.0358387, acc 0.984375
2020-02-08T23:08:28.348051: step 2105, loss 0.056615, acc 0.984375
2020-02-08T23:08:28.502137: step 2106, loss 0.0589744, acc 1
2020-02-08T23:08:28.663506: step 2107, loss 0.0828331, acc 0.96875
2020-02-08T23:08:28.824939: step 2108, loss 0.038877, acc 1
2020-02-08T23:08:28.982536: step 2109, loss 0.0259144, acc 1
2020-02-08T23:08:29.144378: step 2110, loss 0.0308112, acc 1
2020-02-08T23:08:29.306595: step 2111, loss 0.022804, acc 1
2020-02-08T23:08:29.467766: step 2112, loss 0.05, acc 0.984375
2020-02-08T23:08:29.626653: step 2113, loss 0.0307353, acc 1
2020-02-08T23:08:29.784162: step 2114, loss 0.0335337, acc 1
2020-02-08T23:08:29.944764: step 2115, loss 0.0959032, acc 0.96875
2020-02-08T23:08:30.104692: step 2116, loss 0.043654, acc 0.984375
2020-02-08T23:08:30.264055: step 2117, loss 0.0517226, acc 0.984375
2020-02-08T23:08:30.424557: step 2118, loss 0.0426216, acc 0.984375
2020-02-08T23:08:30.582582: step 2119, loss 0.0449993, acc 0.984375
2020-02-08T23:08:30.737624: step 2120, loss 0.12608, acc 0.96875
2020-02-08T23:08:30.912636: step 2121, loss 0.0582644, acc 0.96875
2020-02-08T23:08:31.075093: step 2122, loss 0.0349983, acc 0.984375
2020-02-08T23:08:31.237221: step 2123, loss 0.133832, acc 0.9375
2020-02-08T23:08:31.410983: step 2124, loss 0.04955, acc 1
2020-02-08T23:08:31.568030: step 2125, loss 0.0269185, acc 1
2020-02-08T23:08:31.729920: step 2126, loss 0.028018, acc 0.984375
2020-02-08T23:08:31.897733: step 2127, loss 0.0247521, acc 1
2020-02-08T23:08:32.065188: step 2128, loss 0.0169481, acc 1
2020-02-08T23:08:32.221027: step 2129, loss 0.109392, acc 0.984375
2020-02-08T23:08:32.382025: step 2130, loss 0.0346006, acc 0.984375
2020-02-08T23:08:32.535593: step 2131, loss 0.0267484, acc 0.984375
2020-02-08T23:08:32.695768: step 2132, loss 0.0493002, acc 0.984375
2020-02-08T23:08:32.852854: step 2133, loss 0.0309981, acc 1
2020-02-08T23:08:33.013050: step 2134, loss 0.0596375, acc 0.96875
2020-02-08T23:08:33.174005: step 2135, loss 0.142079, acc 0.953125
2020-02-08T23:08:33.332022: step 2136, loss 0.121212, acc 0.96875
2020-02-08T23:08:33.493709: step 2137, loss 0.0167404, acc 1
2020-02-08T23:08:33.765001: step 2138, loss 0.0766153, acc 0.984375
2020-02-08T23:08:33.930466: step 2139, loss 0.0497725, acc 0.984375
2020-02-08T23:08:34.093595: step 2140, loss 0.112848, acc 0.953125
2020-02-08T23:08:34.262780: step 2141, loss 0.0437807, acc 0.96875
2020-02-08T23:08:34.429071: step 2142, loss 0.0224359, acc 1
2020-02-08T23:08:34.639222: step 2143, loss 0.0548349, acc 0.984375
2020-02-08T23:08:34.912080: step 2144, loss 0.10059, acc 0.96875
2020-02-08T23:08:35.088119: step 2145, loss 0.125817, acc 0.953125
2020-02-08T23:08:35.269129: step 2146, loss 0.0207139, acc 1
2020-02-08T23:08:35.479246: step 2147, loss 0.0301541, acc 1
2020-02-08T23:08:35.636533: step 2148, loss 0.0251169, acc 1
2020-02-08T23:08:35.793928: step 2149, loss 0.0945579, acc 0.96875
2020-02-08T23:08:35.993559: step 2150, loss 0.0397237, acc 1
2020-02-08T23:08:36.199813: step 2151, loss 0.0939045, acc 0.953125
2020-02-08T23:08:36.363704: step 2152, loss 0.0211722, acc 1
2020-02-08T23:08:36.511688: step 2153, loss 0.0783974, acc 0.984375
2020-02-08T23:08:36.670707: step 2154, loss 0.0703065, acc 0.953125
2020-02-08T23:08:36.832163: step 2155, loss 0.0477101, acc 1
2020-02-08T23:08:36.989346: step 2156, loss 0.0703191, acc 0.984375
2020-02-08T23:08:37.139260: step 2157, loss 0.0394689, acc 1
2020-02-08T23:08:37.294354: step 2158, loss 0.0424451, acc 1
2020-02-08T23:08:37.463475: step 2159, loss 0.04907, acc 0.984375
2020-02-08T23:08:37.619342: step 2160, loss 0.0588777, acc 0.96875
2020-02-08T23:08:37.781398: step 2161, loss 0.0369376, acc 1
2020-02-08T23:08:37.937027: step 2162, loss 0.0656411, acc 0.96875
2020-02-08T23:08:38.091333: step 2163, loss 0.114458, acc 0.96875
2020-02-08T23:08:38.250733: step 2164, loss 0.0330794, acc 1
2020-02-08T23:08:38.410708: step 2165, loss 0.0867325, acc 0.984375
2020-02-08T23:08:38.586612: step 2166, loss 0.0401564, acc 0.984375
2020-02-08T23:08:38.740828: step 2167, loss 0.0285913, acc 1
2020-02-08T23:08:38.900561: step 2168, loss 0.033018, acc 0.984375
2020-02-08T23:08:39.061257: step 2169, loss 0.105112, acc 0.96875
2020-02-08T23:08:39.224626: step 2170, loss 0.109376, acc 0.921875
2020-02-08T23:08:39.387323: step 2171, loss 0.057173, acc 0.984375
2020-02-08T23:08:39.548596: step 2172, loss 0.127986, acc 0.96875
2020-02-08T23:08:39.705142: step 2173, loss 0.0610313, acc 0.984375
2020-02-08T23:08:39.862975: step 2174, loss 0.0183538, acc 1
2020-02-08T23:08:40.020805: step 2175, loss 0.0479429, acc 0.984375
2020-02-08T23:08:40.182893: step 2176, loss 0.0881341, acc 0.96875
2020-02-08T23:08:40.337351: step 2177, loss 0.0645768, acc 0.96875
2020-02-08T23:08:40.490942: step 2178, loss 0.0910702, acc 0.96875
2020-02-08T23:08:40.650570: step 2179, loss 0.0655871, acc 0.96875
2020-02-08T23:08:40.805866: step 2180, loss 0.100532, acc 0.953125
2020-02-08T23:08:40.985934: step 2181, loss 0.0426621, acc 0.984375
2020-02-08T23:08:41.138239: step 2182, loss 0.080562, acc 0.96875
2020-02-08T23:08:41.295090: step 2183, loss 0.0250701, acc 1
2020-02-08T23:08:41.456764: step 2184, loss 0.131437, acc 0.921875
2020-02-08T23:08:41.617224: step 2185, loss 0.0562664, acc 0.96875
2020-02-08T23:08:41.778945: step 2186, loss 0.0412335, acc 0.984375
2020-02-08T23:08:41.932232: step 2187, loss 0.0560052, acc 0.984375
2020-02-08T23:08:42.087573: step 2188, loss 0.0280894, acc 1
2020-02-08T23:08:42.247931: step 2189, loss 0.0519806, acc 0.96875
2020-02-08T23:08:42.414331: step 2190, loss 0.0373798, acc 1
2020-02-08T23:08:42.572060: step 2191, loss 0.0770696, acc 0.96875
2020-02-08T23:08:42.729863: step 2192, loss 0.118816, acc 0.984375
2020-02-08T23:08:42.887063: step 2193, loss 0.0717946, acc 0.96875
2020-02-08T23:08:43.041226: step 2194, loss 0.0504265, acc 0.96875
2020-02-08T23:08:43.209969: step 2195, loss 0.0313409, acc 1
2020-02-08T23:08:43.371621: step 2196, loss 0.0437746, acc 0.984375
2020-02-08T23:08:43.527733: step 2197, loss 0.0527213, acc 0.984375
2020-02-08T23:08:43.687889: step 2198, loss 0.0324966, acc 1
2020-02-08T23:08:43.851459: step 2199, loss 0.0452501, acc 0.984375
2020-02-08T23:08:44.024350: step 2200, loss 0.0313751, acc 0.984375

Evaluation:
2020-02-08T23:08:44.309806: step 2200, loss 0.814533, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2200

2020-02-08T23:08:45.847728: step 2201, loss 0.0596926, acc 0.953125
2020-02-08T23:08:46.004937: step 2202, loss 0.0319722, acc 1
2020-02-08T23:08:46.165065: step 2203, loss 0.0289273, acc 0.984375
2020-02-08T23:08:46.319747: step 2204, loss 0.0357743, acc 0.984375
2020-02-08T23:08:46.473050: step 2205, loss 0.0528061, acc 0.984375
2020-02-08T23:08:46.639917: step 2206, loss 0.0262187, acc 1
2020-02-08T23:08:46.794967: step 2207, loss 0.0212717, acc 1
2020-02-08T23:08:46.983135: step 2208, loss 0.0448183, acc 0.96875
2020-02-08T23:08:47.141007: step 2209, loss 0.0205991, acc 1
2020-02-08T23:08:47.291734: step 2210, loss 0.0618416, acc 0.96875
2020-02-08T23:08:47.448279: step 2211, loss 0.0444968, acc 0.984375
2020-02-08T23:08:47.610454: step 2212, loss 0.0599004, acc 0.984375
2020-02-08T23:08:47.772229: step 2213, loss 0.0390242, acc 0.984375
2020-02-08T23:08:47.930885: step 2214, loss 0.019558, acc 1
2020-02-08T23:08:48.091795: step 2215, loss 0.0600539, acc 0.96875
2020-02-08T23:08:48.263089: step 2216, loss 0.0310672, acc 1
2020-02-08T23:08:48.438265: step 2217, loss 0.0327359, acc 0.984375
2020-02-08T23:08:48.602428: step 2218, loss 0.0380577, acc 0.984375
2020-02-08T23:08:48.758946: step 2219, loss 0.0663895, acc 0.984375
2020-02-08T23:08:48.913759: step 2220, loss 0.0820844, acc 0.984375
2020-02-08T23:08:49.071125: step 2221, loss 0.114834, acc 0.96875
2020-02-08T23:08:49.229594: step 2222, loss 0.0582223, acc 0.984375
2020-02-08T23:08:49.395924: step 2223, loss 0.0488136, acc 0.984375
2020-02-08T23:08:49.553134: step 2224, loss 0.0496891, acc 1
2020-02-08T23:08:49.706119: step 2225, loss 0.091102, acc 0.96875
2020-02-08T23:08:49.860794: step 2226, loss 0.0774702, acc 0.96875
2020-02-08T23:08:50.023695: step 2227, loss 0.0879848, acc 0.96875
2020-02-08T23:08:50.183516: step 2228, loss 0.0461434, acc 0.984375
2020-02-08T23:08:50.340315: step 2229, loss 0.0310148, acc 1
2020-02-08T23:08:50.492271: step 2230, loss 0.0618781, acc 0.96875
2020-02-08T23:08:50.647065: step 2231, loss 0.0537007, acc 0.96875
2020-02-08T23:08:50.807901: step 2232, loss 0.036566, acc 1
2020-02-08T23:08:50.977160: step 2233, loss 0.0503699, acc 0.96875
2020-02-08T23:08:51.131117: step 2234, loss 0.122396, acc 0.96875
2020-02-08T23:08:51.290494: step 2235, loss 0.0141789, acc 1
2020-02-08T23:08:51.448844: step 2236, loss 0.0564923, acc 0.96875
2020-02-08T23:08:51.609468: step 2237, loss 0.0251792, acc 1
2020-02-08T23:08:51.766231: step 2238, loss 0.0329691, acc 1
2020-02-08T23:08:51.924936: step 2239, loss 0.0526296, acc 0.96875
2020-02-08T23:08:52.080963: step 2240, loss 0.0432006, acc 0.96875
2020-02-08T23:08:52.254897: step 2241, loss 0.0923708, acc 0.96875
2020-02-08T23:08:52.419462: step 2242, loss 0.0515602, acc 0.96875
2020-02-08T23:08:52.577854: step 2243, loss 0.0278393, acc 1
2020-02-08T23:08:52.733086: step 2244, loss 0.0421846, acc 0.984375
2020-02-08T23:08:52.891213: step 2245, loss 0.062091, acc 0.96875
2020-02-08T23:08:53.047473: step 2246, loss 0.0425451, acc 0.984375
2020-02-08T23:08:53.208895: step 2247, loss 0.024124, acc 1
2020-02-08T23:08:53.368650: step 2248, loss 0.0524659, acc 0.984375
2020-02-08T23:08:53.524818: step 2249, loss 0.0755166, acc 0.96875
2020-02-08T23:08:53.671014: step 2250, loss 0.0305372, acc 1
2020-02-08T23:08:53.837814: step 2251, loss 0.015068, acc 1
2020-02-08T23:08:54.007720: step 2252, loss 0.0698435, acc 0.96875
2020-02-08T23:08:54.161846: step 2253, loss 0.0459592, acc 0.96875
2020-02-08T23:08:54.317608: step 2254, loss 0.0355674, acc 0.984375
2020-02-08T23:08:54.476283: step 2255, loss 0.0485164, acc 0.984375
2020-02-08T23:08:54.641852: step 2256, loss 0.0141727, acc 1
2020-02-08T23:08:54.802761: step 2257, loss 0.0659504, acc 0.984375
2020-02-08T23:08:54.966106: step 2258, loss 0.0251338, acc 1
2020-02-08T23:08:55.122836: step 2259, loss 0.0270959, acc 0.984375
2020-02-08T23:08:55.279887: step 2260, loss 0.0204104, acc 1
2020-02-08T23:08:55.443535: step 2261, loss 0.0354905, acc 0.984375
2020-02-08T23:08:55.602690: step 2262, loss 0.0308174, acc 1
2020-02-08T23:08:55.764497: step 2263, loss 0.0419251, acc 0.984375
2020-02-08T23:08:55.918172: step 2264, loss 0.0447624, acc 1
2020-02-08T23:08:56.072671: step 2265, loss 0.038075, acc 0.984375
2020-02-08T23:08:56.230090: step 2266, loss 0.0181555, acc 1
2020-02-08T23:08:56.392655: step 2267, loss 0.0380111, acc 0.984375
2020-02-08T23:08:56.544337: step 2268, loss 0.0589779, acc 0.984375
2020-02-08T23:08:56.697860: step 2269, loss 0.0216094, acc 1
2020-02-08T23:08:56.859542: step 2270, loss 0.0471651, acc 0.984375
2020-02-08T23:08:57.019992: step 2271, loss 0.0703038, acc 0.96875
2020-02-08T23:08:57.178898: step 2272, loss 0.0839433, acc 0.953125
2020-02-08T23:08:57.330477: step 2273, loss 0.0503231, acc 0.984375
2020-02-08T23:08:57.483306: step 2274, loss 0.0602083, acc 0.984375
2020-02-08T23:08:57.645136: step 2275, loss 0.0289111, acc 1
2020-02-08T23:08:57.799764: step 2276, loss 0.0219031, acc 1
2020-02-08T23:08:57.956779: step 2277, loss 0.0230174, acc 1
2020-02-08T23:08:58.112961: step 2278, loss 0.0302636, acc 1
2020-02-08T23:08:58.267985: step 2279, loss 0.037289, acc 0.984375
2020-02-08T23:08:58.427380: step 2280, loss 0.0878724, acc 0.953125
2020-02-08T23:08:58.584439: step 2281, loss 0.0772713, acc 0.96875
2020-02-08T23:08:58.739683: step 2282, loss 0.0834431, acc 0.953125
2020-02-08T23:08:58.902676: step 2283, loss 0.0432733, acc 0.984375
2020-02-08T23:08:59.067166: step 2284, loss 0.0270644, acc 0.984375
2020-02-08T23:08:59.222640: step 2285, loss 0.0425723, acc 0.96875
2020-02-08T23:08:59.383549: step 2286, loss 0.0426717, acc 0.96875
2020-02-08T23:08:59.538713: step 2287, loss 0.0843654, acc 0.953125
2020-02-08T23:08:59.695977: step 2288, loss 0.0250859, acc 1
2020-02-08T23:08:59.849224: step 2289, loss 0.0866667, acc 0.953125
2020-02-08T23:09:00.006126: step 2290, loss 0.0172033, acc 1
2020-02-08T23:09:00.166407: step 2291, loss 0.0937475, acc 0.96875
2020-02-08T23:09:00.326852: step 2292, loss 0.0241084, acc 1
2020-02-08T23:09:00.481913: step 2293, loss 0.0102313, acc 1
2020-02-08T23:09:00.652084: step 2294, loss 0.0522552, acc 1
2020-02-08T23:09:00.813334: step 2295, loss 0.0649288, acc 0.96875
2020-02-08T23:09:00.989970: step 2296, loss 0.0118683, acc 1
2020-02-08T23:09:01.144059: step 2297, loss 0.053945, acc 0.96875
2020-02-08T23:09:01.295265: step 2298, loss 0.0878611, acc 0.96875
2020-02-08T23:09:01.453412: step 2299, loss 0.0217365, acc 1
2020-02-08T23:09:01.611226: step 2300, loss 0.0123657, acc 1

Evaluation:
2020-02-08T23:09:01.890677: step 2300, loss 0.85121, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2300

2020-02-08T23:09:03.473506: step 2301, loss 0.0229848, acc 1
2020-02-08T23:09:03.628766: step 2302, loss 0.0143773, acc 1
2020-02-08T23:09:03.785587: step 2303, loss 0.00802052, acc 1
2020-02-08T23:09:03.942211: step 2304, loss 0.0406171, acc 0.984375
2020-02-08T23:09:04.096574: step 2305, loss 0.0134154, acc 1
2020-02-08T23:09:04.261049: step 2306, loss 0.0384274, acc 1
2020-02-08T23:09:04.418783: step 2307, loss 0.0374607, acc 0.984375
2020-02-08T23:09:04.573567: step 2308, loss 0.0224563, acc 1
2020-02-08T23:09:04.725171: step 2309, loss 0.0269551, acc 0.984375
2020-02-08T23:09:04.880058: step 2310, loss 0.0470158, acc 1
2020-02-08T23:09:05.035366: step 2311, loss 0.104088, acc 0.953125
2020-02-08T23:09:05.194263: step 2312, loss 0.029513, acc 0.984375
2020-02-08T23:09:05.346099: step 2313, loss 0.0445877, acc 0.984375
2020-02-08T23:09:05.497894: step 2314, loss 0.0435178, acc 0.984375
2020-02-08T23:09:05.654185: step 2315, loss 0.0381062, acc 0.96875
2020-02-08T23:09:05.817251: step 2316, loss 0.043449, acc 0.96875
2020-02-08T23:09:05.978009: step 2317, loss 0.0811107, acc 0.96875
2020-02-08T23:09:06.132620: step 2318, loss 0.034575, acc 1
2020-02-08T23:09:06.288180: step 2319, loss 0.0189778, acc 1
2020-02-08T23:09:06.445137: step 2320, loss 0.0329522, acc 0.984375
2020-02-08T23:09:06.599231: step 2321, loss 0.0590286, acc 0.984375
2020-02-08T23:09:06.762607: step 2322, loss 0.0300087, acc 1
2020-02-08T23:09:06.918794: step 2323, loss 0.0235773, acc 1
2020-02-08T23:09:07.070386: step 2324, loss 0.0248109, acc 1
2020-02-08T23:09:07.229294: step 2325, loss 0.0242729, acc 1
2020-02-08T23:09:07.379067: step 2326, loss 0.0312446, acc 1
2020-02-08T23:09:07.534878: step 2327, loss 0.0313393, acc 1
2020-02-08T23:09:07.686931: step 2328, loss 0.0182489, acc 1
2020-02-08T23:09:07.841658: step 2329, loss 0.0206303, acc 1
2020-02-08T23:09:08.000585: step 2330, loss 0.0449754, acc 0.984375
2020-02-08T23:09:08.163227: step 2331, loss 0.0243751, acc 0.984375
2020-02-08T23:09:08.318779: step 2332, loss 0.0270101, acc 1
2020-02-08T23:09:08.479651: step 2333, loss 0.046601, acc 0.984375
2020-02-08T23:09:08.702749: step 2334, loss 0.0191823, acc 1
2020-02-08T23:09:08.892718: step 2335, loss 0.00911187, acc 1
2020-02-08T23:09:09.052785: step 2336, loss 0.0608919, acc 0.984375
2020-02-08T23:09:09.215470: step 2337, loss 0.0365643, acc 0.984375
2020-02-08T23:09:09.411191: step 2338, loss 0.0751716, acc 0.984375
2020-02-08T23:09:09.598031: step 2339, loss 0.0458329, acc 0.984375
2020-02-08T23:09:09.811251: step 2340, loss 0.10964, acc 0.9375
2020-02-08T23:09:10.033286: step 2341, loss 0.0875273, acc 0.96875
2020-02-08T23:09:10.201755: step 2342, loss 0.0330382, acc 1
2020-02-08T23:09:10.373709: step 2343, loss 0.0155752, acc 1
2020-02-08T23:09:10.538176: step 2344, loss 0.0161272, acc 1
2020-02-08T23:09:10.700191: step 2345, loss 0.0264006, acc 0.984375
2020-02-08T23:09:10.866760: step 2346, loss 0.141206, acc 0.9375
2020-02-08T23:09:11.030056: step 2347, loss 0.0390695, acc 1
2020-02-08T23:09:11.185285: step 2348, loss 0.0236924, acc 1
2020-02-08T23:09:11.335956: step 2349, loss 0.0435511, acc 0.984375
2020-02-08T23:09:11.485605: step 2350, loss 0.065656, acc 0.96875
2020-02-08T23:09:11.640405: step 2351, loss 0.0652573, acc 0.96875
2020-02-08T23:09:11.796698: step 2352, loss 0.0311007, acc 1
2020-02-08T23:09:11.949428: step 2353, loss 0.0516637, acc 0.984375
2020-02-08T23:09:12.104326: step 2354, loss 0.0558181, acc 0.984375
2020-02-08T23:09:12.266948: step 2355, loss 0.0463878, acc 0.96875
2020-02-08T23:09:12.422363: step 2356, loss 0.0406729, acc 1
2020-02-08T23:09:12.581404: step 2357, loss 0.0248946, acc 1
2020-02-08T23:09:12.737442: step 2358, loss 0.0273139, acc 1
2020-02-08T23:09:12.890510: step 2359, loss 0.179561, acc 0.953125
2020-02-08T23:09:13.051359: step 2360, loss 0.0670854, acc 0.984375
2020-02-08T23:09:13.212160: step 2361, loss 0.0404936, acc 1
2020-02-08T23:09:13.371558: step 2362, loss 0.0158882, acc 1
2020-02-08T23:09:13.522048: step 2363, loss 0.0455873, acc 1
2020-02-08T23:09:13.765509: step 2364, loss 0.0840392, acc 0.96875
2020-02-08T23:09:13.917814: step 2365, loss 0.0989806, acc 0.96875
2020-02-08T23:09:14.176226: step 2366, loss 0.0215483, acc 1
2020-02-08T23:09:14.349783: step 2367, loss 0.120024, acc 0.953125
2020-02-08T23:09:14.503583: step 2368, loss 0.0376842, acc 0.984375
2020-02-08T23:09:14.657509: step 2369, loss 0.0529311, acc 0.984375
2020-02-08T23:09:14.821442: step 2370, loss 0.0304161, acc 1
2020-02-08T23:09:14.983913: step 2371, loss 0.0330866, acc 1
2020-02-08T23:09:15.136377: step 2372, loss 0.0116582, acc 1
2020-02-08T23:09:15.297463: step 2373, loss 0.0338494, acc 0.984375
2020-02-08T23:09:15.456748: step 2374, loss 0.0267761, acc 1
2020-02-08T23:09:15.617416: step 2375, loss 0.074336, acc 0.96875
2020-02-08T23:09:15.773691: step 2376, loss 0.0324969, acc 1
2020-02-08T23:09:15.932459: step 2377, loss 0.0112638, acc 1
2020-02-08T23:09:16.080192: step 2378, loss 0.0124107, acc 1
2020-02-08T23:09:16.235095: step 2379, loss 0.0466453, acc 0.96875
2020-02-08T23:09:16.392393: step 2380, loss 0.0286786, acc 1
2020-02-08T23:09:16.547926: step 2381, loss 0.0332361, acc 0.984375
2020-02-08T23:09:16.703406: step 2382, loss 0.0288542, acc 0.984375
2020-02-08T23:09:16.866683: step 2383, loss 0.149595, acc 0.953125
2020-02-08T23:09:17.024295: step 2384, loss 0.0262475, acc 1
2020-02-08T23:09:17.180713: step 2385, loss 0.0364829, acc 0.96875
2020-02-08T23:09:17.333017: step 2386, loss 0.0301036, acc 0.984375
2020-02-08T23:09:17.486645: step 2387, loss 0.0908145, acc 0.96875
2020-02-08T23:09:17.640941: step 2388, loss 0.0239094, acc 1
2020-02-08T23:09:17.806961: step 2389, loss 0.183707, acc 0.9375
2020-02-08T23:09:17.965669: step 2390, loss 0.0227699, acc 0.984375
2020-02-08T23:09:18.122258: step 2391, loss 0.0224707, acc 1
2020-02-08T23:09:18.281233: step 2392, loss 0.0426397, acc 0.984375
2020-02-08T23:09:18.433875: step 2393, loss 0.0234181, acc 1
2020-02-08T23:09:18.589701: step 2394, loss 0.0603542, acc 0.984375
2020-02-08T23:09:18.742426: step 2395, loss 0.0237893, acc 1
2020-02-08T23:09:18.893456: step 2396, loss 0.0463851, acc 0.984375
2020-02-08T23:09:19.053788: step 2397, loss 0.0619015, acc 0.96875
2020-02-08T23:09:19.211062: step 2398, loss 0.0320256, acc 0.984375
2020-02-08T23:09:19.363480: step 2399, loss 0.0739111, acc 0.96875
2020-02-08T23:09:19.512196: step 2400, loss 0.129317, acc 0.966667

Evaluation:
2020-02-08T23:09:19.782733: step 2400, loss 0.886408, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2400

2020-02-08T23:09:21.342062: step 2401, loss 0.0103424, acc 1
2020-02-08T23:09:21.489319: step 2402, loss 0.0599369, acc 0.96875
2020-02-08T23:09:21.649584: step 2403, loss 0.141162, acc 0.921875
2020-02-08T23:09:21.807001: step 2404, loss 0.036204, acc 0.984375
2020-02-08T23:09:21.968557: step 2405, loss 0.0195361, acc 1
2020-02-08T23:09:22.123889: step 2406, loss 0.0267014, acc 1
2020-02-08T23:09:22.281079: step 2407, loss 0.0646105, acc 0.953125
2020-02-08T23:09:22.443512: step 2408, loss 0.128915, acc 0.953125
2020-02-08T23:09:22.600446: step 2409, loss 0.0568232, acc 0.984375
2020-02-08T23:09:22.754284: step 2410, loss 0.0390715, acc 0.984375
2020-02-08T23:09:22.902287: step 2411, loss 0.0302862, acc 0.984375
2020-02-08T23:09:23.054707: step 2412, loss 0.0229098, acc 1
2020-02-08T23:09:23.209110: step 2413, loss 0.00931552, acc 1
2020-02-08T23:09:23.367297: step 2414, loss 0.0392164, acc 0.984375
2020-02-08T23:09:23.514427: step 2415, loss 0.0277767, acc 1
2020-02-08T23:09:23.663204: step 2416, loss 0.0184491, acc 1
2020-02-08T23:09:23.818183: step 2417, loss 0.0181463, acc 1
2020-02-08T23:09:23.971027: step 2418, loss 0.0517995, acc 0.984375
2020-02-08T23:09:24.122466: step 2419, loss 0.0153672, acc 1
2020-02-08T23:09:24.275542: step 2420, loss 0.0568956, acc 1
2020-02-08T23:09:24.431509: step 2421, loss 0.0251638, acc 1
2020-02-08T23:09:24.592213: step 2422, loss 0.0197661, acc 1
2020-02-08T23:09:24.748468: step 2423, loss 0.00600455, acc 1
2020-02-08T23:09:24.895658: step 2424, loss 0.0300643, acc 1
2020-02-08T23:09:25.047542: step 2425, loss 0.0392834, acc 0.984375
2020-02-08T23:09:25.206259: step 2426, loss 0.0554831, acc 0.96875
2020-02-08T23:09:25.361828: step 2427, loss 0.0294837, acc 1
2020-02-08T23:09:25.515269: step 2428, loss 0.0196923, acc 1
2020-02-08T23:09:25.669476: step 2429, loss 0.012422, acc 1
2020-02-08T23:09:25.826346: step 2430, loss 0.0579466, acc 0.96875
2020-02-08T23:09:25.976660: step 2431, loss 0.0286038, acc 0.984375
2020-02-08T23:09:26.118560: step 2432, loss 0.0269545, acc 1
2020-02-08T23:09:26.263038: step 2433, loss 0.0357069, acc 1
2020-02-08T23:09:26.431706: step 2434, loss 0.0331582, acc 0.984375
2020-02-08T23:09:26.622651: step 2435, loss 0.0364629, acc 0.984375
2020-02-08T23:09:26.791541: step 2436, loss 0.0452065, acc 0.984375
2020-02-08T23:09:26.959864: step 2437, loss 0.0199285, acc 1
2020-02-08T23:09:27.137107: step 2438, loss 0.0360732, acc 0.984375
2020-02-08T23:09:27.293153: step 2439, loss 0.0600227, acc 0.96875
2020-02-08T23:09:27.452511: step 2440, loss 0.0416545, acc 0.984375
2020-02-08T23:09:27.623991: step 2441, loss 0.0237721, acc 1
2020-02-08T23:09:27.786722: step 2442, loss 0.0122869, acc 1
2020-02-08T23:09:27.936835: step 2443, loss 0.00837145, acc 1
2020-02-08T23:09:28.087525: step 2444, loss 0.070193, acc 0.984375
2020-02-08T23:09:28.236798: step 2445, loss 0.0402813, acc 0.984375
2020-02-08T23:09:28.391878: step 2446, loss 0.0108283, acc 1
2020-02-08T23:09:28.558734: step 2447, loss 0.0168419, acc 1
2020-02-08T23:09:28.713273: step 2448, loss 0.0189287, acc 0.984375
2020-02-08T23:09:28.866696: step 2449, loss 0.0512808, acc 0.984375
2020-02-08T23:09:29.027075: step 2450, loss 0.0139061, acc 1
2020-02-08T23:09:29.186776: step 2451, loss 0.0212176, acc 1
2020-02-08T23:09:29.342567: step 2452, loss 0.0305229, acc 1
2020-02-08T23:09:29.493665: step 2453, loss 0.0101772, acc 1
2020-02-08T23:09:29.649016: step 2454, loss 0.0169999, acc 1
2020-02-08T23:09:29.803538: step 2455, loss 0.0364808, acc 0.984375
2020-02-08T23:09:29.956772: step 2456, loss 0.00803733, acc 1
2020-02-08T23:09:30.106434: step 2457, loss 0.0497976, acc 0.96875
2020-02-08T23:09:30.271466: step 2458, loss 0.014204, acc 1
2020-02-08T23:09:30.430347: step 2459, loss 0.0785829, acc 0.96875
2020-02-08T23:09:30.587288: step 2460, loss 0.0192735, acc 1
2020-02-08T23:09:30.742252: step 2461, loss 0.0813524, acc 0.96875
2020-02-08T23:09:30.901594: step 2462, loss 0.140171, acc 0.921875
2020-02-08T23:09:31.065214: step 2463, loss 0.0137725, acc 1
2020-02-08T23:09:31.227660: step 2464, loss 0.0550381, acc 0.96875
2020-02-08T23:09:31.387619: step 2465, loss 0.0385155, acc 0.984375
2020-02-08T23:09:31.546291: step 2466, loss 0.0404222, acc 0.984375
2020-02-08T23:09:31.698906: step 2467, loss 0.0948762, acc 0.953125
2020-02-08T23:09:31.859481: step 2468, loss 0.0567316, acc 0.96875
2020-02-08T23:09:32.017909: step 2469, loss 0.0116883, acc 1
2020-02-08T23:09:32.184634: step 2470, loss 0.0212633, acc 1
2020-02-08T23:09:32.334311: step 2471, loss 0.0208326, acc 0.984375
2020-02-08T23:09:32.488001: step 2472, loss 0.0705389, acc 0.984375
2020-02-08T23:09:32.642672: step 2473, loss 0.0162506, acc 1
2020-02-08T23:09:32.803757: step 2474, loss 0.0694958, acc 0.96875
2020-02-08T23:09:32.966003: step 2475, loss 0.0255495, acc 0.984375
2020-02-08T23:09:33.124933: step 2476, loss 0.0312831, acc 1
2020-02-08T23:09:33.276442: step 2477, loss 0.0452434, acc 0.984375
2020-02-08T23:09:33.428133: step 2478, loss 0.0466466, acc 0.984375
2020-02-08T23:09:33.583086: step 2479, loss 0.0712783, acc 0.984375
2020-02-08T23:09:33.736290: step 2480, loss 0.0286994, acc 1
2020-02-08T23:09:33.888936: step 2481, loss 0.0310775, acc 0.984375
2020-02-08T23:09:34.047556: step 2482, loss 0.0283413, acc 0.984375
2020-02-08T23:09:34.207130: step 2483, loss 0.0528985, acc 0.984375
2020-02-08T23:09:34.364427: step 2484, loss 0.0487991, acc 0.984375
2020-02-08T23:09:34.524547: step 2485, loss 0.0180823, acc 1
2020-02-08T23:09:34.677561: step 2486, loss 0.0330806, acc 0.984375
2020-02-08T23:09:34.833988: step 2487, loss 0.0285579, acc 0.984375
2020-02-08T23:09:34.998189: step 2488, loss 0.0277477, acc 0.984375
2020-02-08T23:09:35.147052: step 2489, loss 0.0368457, acc 0.984375
2020-02-08T23:09:35.307060: step 2490, loss 0.0730686, acc 0.984375
2020-02-08T23:09:35.463705: step 2491, loss 0.0236389, acc 1
2020-02-08T23:09:35.619504: step 2492, loss 0.0554631, acc 0.96875
2020-02-08T23:09:35.780857: step 2493, loss 0.0175666, acc 1
2020-02-08T23:09:35.936009: step 2494, loss 0.0830526, acc 0.984375
2020-02-08T23:09:36.084838: step 2495, loss 0.0349961, acc 0.984375
2020-02-08T23:09:36.243607: step 2496, loss 0.0820186, acc 0.96875
2020-02-08T23:09:36.403709: step 2497, loss 0.0291277, acc 0.984375
2020-02-08T23:09:36.582578: step 2498, loss 0.086058, acc 0.953125
2020-02-08T23:09:36.801816: step 2499, loss 0.0711816, acc 0.96875
2020-02-08T23:09:36.958361: step 2500, loss 0.0639404, acc 0.96875

Evaluation:
2020-02-08T23:09:37.232061: step 2500, loss 0.933941, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2500

2020-02-08T23:09:38.828876: step 2501, loss 0.0346659, acc 1
2020-02-08T23:09:38.984987: step 2502, loss 0.0583196, acc 0.96875
2020-02-08T23:09:39.137811: step 2503, loss 0.00610677, acc 1
2020-02-08T23:09:39.289493: step 2504, loss 0.038814, acc 0.984375
2020-02-08T23:09:39.450255: step 2505, loss 0.063827, acc 0.984375
2020-02-08T23:09:39.609356: step 2506, loss 0.0213049, acc 1
2020-02-08T23:09:39.765499: step 2507, loss 0.0179267, acc 1
2020-02-08T23:09:39.922484: step 2508, loss 0.0449424, acc 0.96875
2020-02-08T23:09:40.081607: step 2509, loss 0.0142747, acc 1
2020-02-08T23:09:40.238892: step 2510, loss 0.0409596, acc 0.984375
2020-02-08T23:09:40.402473: step 2511, loss 0.0258288, acc 1
2020-02-08T23:09:40.565420: step 2512, loss 0.030225, acc 0.984375
2020-02-08T23:09:40.722914: step 2513, loss 0.0286128, acc 0.984375
2020-02-08T23:09:40.889018: step 2514, loss 0.0231065, acc 1
2020-02-08T23:09:41.055063: step 2515, loss 0.0265585, acc 0.984375
2020-02-08T23:09:41.214225: step 2516, loss 0.0424023, acc 0.984375
2020-02-08T23:09:41.367722: step 2517, loss 0.0519603, acc 0.96875
2020-02-08T23:09:41.529325: step 2518, loss 0.0991066, acc 0.984375
2020-02-08T23:09:41.685069: step 2519, loss 0.0207224, acc 1
2020-02-08T23:09:41.841777: step 2520, loss 0.0361066, acc 0.984375
2020-02-08T23:09:42.005294: step 2521, loss 0.0563626, acc 0.984375
2020-02-08T23:09:42.170048: step 2522, loss 0.01115, acc 1
2020-02-08T23:09:42.325623: step 2523, loss 0.075004, acc 0.96875
2020-02-08T23:09:42.481046: step 2524, loss 0.0146052, acc 1
2020-02-08T23:09:42.638367: step 2525, loss 0.0632251, acc 0.96875
2020-02-08T23:09:42.794818: step 2526, loss 0.0833383, acc 0.953125
2020-02-08T23:09:42.945073: step 2527, loss 0.0513031, acc 0.984375
2020-02-08T23:09:43.093874: step 2528, loss 0.0197485, acc 0.984375
2020-02-08T23:09:43.244699: step 2529, loss 0.0328799, acc 0.984375
2020-02-08T23:09:43.407833: step 2530, loss 0.0583968, acc 0.984375
2020-02-08T23:09:43.601773: step 2531, loss 0.125865, acc 0.96875
2020-02-08T23:09:43.823562: step 2532, loss 0.056401, acc 0.96875
2020-02-08T23:09:43.978438: step 2533, loss 0.011526, acc 1
2020-02-08T23:09:44.139423: step 2534, loss 0.026448, acc 1
2020-02-08T23:09:44.347950: step 2535, loss 0.0327107, acc 0.984375
2020-02-08T23:09:44.539857: step 2536, loss 0.0125666, acc 1
2020-02-08T23:09:44.753018: step 2537, loss 0.145153, acc 0.9375
2020-02-08T23:09:44.922434: step 2538, loss 0.0207129, acc 0.984375
2020-02-08T23:09:45.082327: step 2539, loss 0.0448318, acc 1
2020-02-08T23:09:45.240014: step 2540, loss 0.0143769, acc 1
2020-02-08T23:09:45.395955: step 2541, loss 0.0284506, acc 1
2020-02-08T23:09:45.545810: step 2542, loss 0.0125998, acc 1
2020-02-08T23:09:45.703415: step 2543, loss 0.0669243, acc 0.96875
2020-02-08T23:09:45.859067: step 2544, loss 0.0316622, acc 0.984375
2020-02-08T23:09:46.022199: step 2545, loss 0.0177995, acc 1
2020-02-08T23:09:46.182630: step 2546, loss 0.0817221, acc 0.953125
2020-02-08T23:09:46.337277: step 2547, loss 0.0302459, acc 0.984375
2020-02-08T23:09:46.489817: step 2548, loss 0.0565755, acc 0.984375
2020-02-08T23:09:46.656788: step 2549, loss 0.0168287, acc 1
2020-02-08T23:09:46.811462: step 2550, loss 0.0571732, acc 0.966667
2020-02-08T23:09:46.986745: step 2551, loss 0.0186996, acc 0.984375
2020-02-08T23:09:47.152895: step 2552, loss 0.0133307, acc 1
2020-02-08T23:09:47.309632: step 2553, loss 0.0163869, acc 1
2020-02-08T23:09:47.463305: step 2554, loss 0.00650918, acc 1
2020-02-08T23:09:47.618823: step 2555, loss 0.0344209, acc 0.984375
2020-02-08T23:09:47.774343: step 2556, loss 0.0165594, acc 1
2020-02-08T23:09:47.927698: step 2557, loss 0.01558, acc 1
2020-02-08T23:09:48.084223: step 2558, loss 0.0245017, acc 1
2020-02-08T23:09:48.241490: step 2559, loss 0.00828481, acc 1
2020-02-08T23:09:48.392437: step 2560, loss 0.0170952, acc 1
2020-02-08T23:09:48.551718: step 2561, loss 0.040482, acc 0.984375
2020-02-08T23:09:48.704624: step 2562, loss 0.070966, acc 0.984375
2020-02-08T23:09:48.855573: step 2563, loss 0.0199206, acc 1
2020-02-08T23:09:49.017695: step 2564, loss 0.00810388, acc 1
2020-02-08T23:09:49.173590: step 2565, loss 0.0888926, acc 0.96875
2020-02-08T23:09:49.326647: step 2566, loss 0.0578134, acc 0.96875
2020-02-08T23:09:49.482493: step 2567, loss 0.0148455, acc 1
2020-02-08T23:09:49.635894: step 2568, loss 0.0186354, acc 1
2020-02-08T23:09:49.792349: step 2569, loss 0.0193336, acc 0.984375
2020-02-08T23:09:49.943716: step 2570, loss 0.0529111, acc 0.984375
2020-02-08T23:09:50.095132: step 2571, loss 0.0112157, acc 1
2020-02-08T23:09:50.248343: step 2572, loss 0.0328947, acc 1
2020-02-08T23:09:50.406046: step 2573, loss 0.0207361, acc 0.984375
2020-02-08T23:09:50.564087: step 2574, loss 0.0635252, acc 0.96875
2020-02-08T23:09:50.715992: step 2575, loss 0.0333088, acc 0.984375
2020-02-08T23:09:50.870520: step 2576, loss 0.0458477, acc 0.984375
2020-02-08T23:09:51.027241: step 2577, loss 0.00995117, acc 1
2020-02-08T23:09:51.188231: step 2578, loss 0.053559, acc 0.96875
2020-02-08T23:09:51.339154: step 2579, loss 0.0309624, acc 0.984375
2020-02-08T23:09:51.490781: step 2580, loss 0.02965, acc 0.96875
2020-02-08T23:09:51.640701: step 2581, loss 0.0445473, acc 1
2020-02-08T23:09:51.799696: step 2582, loss 0.0183284, acc 1
2020-02-08T23:09:51.950665: step 2583, loss 0.0181391, acc 1
2020-02-08T23:09:52.098737: step 2584, loss 0.0280713, acc 1
2020-02-08T23:09:52.259187: step 2585, loss 0.0149865, acc 1
2020-02-08T23:09:52.417331: step 2586, loss 0.0456545, acc 0.984375
2020-02-08T23:09:52.573191: step 2587, loss 0.0366639, acc 0.984375
2020-02-08T23:09:52.731417: step 2588, loss 0.0446931, acc 0.96875
2020-02-08T23:09:52.883119: step 2589, loss 0.0104724, acc 1
2020-02-08T23:09:53.039495: step 2590, loss 0.0207032, acc 1
2020-02-08T23:09:53.193643: step 2591, loss 0.0644653, acc 0.96875
2020-02-08T23:09:53.355198: step 2592, loss 0.0153039, acc 1
2020-02-08T23:09:53.506302: step 2593, loss 0.0728163, acc 0.984375
2020-02-08T23:09:53.661084: step 2594, loss 0.00730115, acc 1
2020-02-08T23:09:53.818933: step 2595, loss 0.028351, acc 0.984375
2020-02-08T23:09:53.977888: step 2596, loss 0.0121741, acc 1
2020-02-08T23:09:54.129373: step 2597, loss 0.038693, acc 0.984375
2020-02-08T23:09:54.283629: step 2598, loss 0.01106, acc 1
2020-02-08T23:09:54.435972: step 2599, loss 0.0228113, acc 1
2020-02-08T23:09:54.586828: step 2600, loss 0.0069989, acc 1

Evaluation:
2020-02-08T23:09:54.849993: step 2600, loss 0.954079, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2600

2020-02-08T23:09:56.441338: step 2601, loss 0.0174401, acc 1
2020-02-08T23:09:56.594800: step 2602, loss 0.01442, acc 1
2020-02-08T23:09:56.751825: step 2603, loss 0.00715319, acc 1
2020-02-08T23:09:56.899760: step 2604, loss 0.0228751, acc 1
2020-02-08T23:09:57.058196: step 2605, loss 0.0918715, acc 0.953125
2020-02-08T23:09:57.217983: step 2606, loss 0.0106515, acc 1
2020-02-08T23:09:57.371362: step 2607, loss 0.00851826, acc 1
2020-02-08T23:09:57.526797: step 2608, loss 0.0136494, acc 1
2020-02-08T23:09:57.679992: step 2609, loss 0.0554226, acc 0.96875
2020-02-08T23:09:57.833947: step 2610, loss 0.0312693, acc 1
2020-02-08T23:09:57.984488: step 2611, loss 0.0133928, acc 1
2020-02-08T23:09:58.139856: step 2612, loss 0.00828083, acc 1
2020-02-08T23:09:58.288987: step 2613, loss 0.0129988, acc 1
2020-02-08T23:09:58.441863: step 2614, loss 0.0402353, acc 0.984375
2020-02-08T23:09:58.593935: step 2615, loss 0.0499326, acc 0.984375
2020-02-08T23:09:58.746109: step 2616, loss 0.03035, acc 1
2020-02-08T23:09:58.896883: step 2617, loss 0.013371, acc 1
2020-02-08T23:09:59.054425: step 2618, loss 0.0119739, acc 1
2020-02-08T23:09:59.212981: step 2619, loss 0.0133839, acc 1
2020-02-08T23:09:59.365774: step 2620, loss 0.0225072, acc 1
2020-02-08T23:09:59.518375: step 2621, loss 0.021681, acc 1
2020-02-08T23:09:59.671157: step 2622, loss 0.0143481, acc 1
2020-02-08T23:09:59.827313: step 2623, loss 0.00400374, acc 1
2020-02-08T23:09:59.982344: step 2624, loss 0.0229942, acc 1
2020-02-08T23:10:00.136847: step 2625, loss 0.0147256, acc 1
2020-02-08T23:10:00.284803: step 2626, loss 0.0257678, acc 1
2020-02-08T23:10:00.440730: step 2627, loss 0.0157124, acc 1
2020-02-08T23:10:00.592771: step 2628, loss 0.0385839, acc 0.984375
2020-02-08T23:10:00.744456: step 2629, loss 0.0831172, acc 0.96875
2020-02-08T23:10:00.904069: step 2630, loss 0.0340516, acc 0.984375
2020-02-08T23:10:01.055428: step 2631, loss 0.012254, acc 1
2020-02-08T23:10:01.210923: step 2632, loss 0.0172712, acc 1
2020-02-08T23:10:01.367786: step 2633, loss 0.0333959, acc 0.984375
2020-02-08T23:10:01.520343: step 2634, loss 0.0230256, acc 1
2020-02-08T23:10:01.674090: step 2635, loss 0.0788925, acc 0.984375
2020-02-08T23:10:01.833962: step 2636, loss 0.0554728, acc 0.96875
2020-02-08T23:10:01.995056: step 2637, loss 0.0144353, acc 1
2020-02-08T23:10:02.145065: step 2638, loss 0.00844944, acc 1
2020-02-08T23:10:02.296928: step 2639, loss 0.0200626, acc 1
2020-02-08T23:10:02.457750: step 2640, loss 0.0213114, acc 1
2020-02-08T23:10:02.613097: step 2641, loss 0.0521864, acc 0.984375
2020-02-08T23:10:02.766846: step 2642, loss 0.0752492, acc 0.96875
2020-02-08T23:10:02.923954: step 2643, loss 0.0210878, acc 1
2020-02-08T23:10:03.073377: step 2644, loss 0.0140104, acc 1
2020-02-08T23:10:03.227810: step 2645, loss 0.0556884, acc 0.96875
2020-02-08T23:10:03.380040: step 2646, loss 0.0123924, acc 1
2020-02-08T23:10:03.533521: step 2647, loss 0.0265852, acc 1
2020-02-08T23:10:03.683756: step 2648, loss 0.00858808, acc 1
2020-02-08T23:10:03.836932: step 2649, loss 0.0567768, acc 0.96875
2020-02-08T23:10:03.990978: step 2650, loss 0.00849651, acc 1
2020-02-08T23:10:04.143544: step 2651, loss 0.0614585, acc 0.96875
2020-02-08T23:10:04.292938: step 2652, loss 0.0420032, acc 0.96875
2020-02-08T23:10:04.450448: step 2653, loss 0.101462, acc 0.96875
2020-02-08T23:10:04.611751: step 2654, loss 0.0128653, acc 1
2020-02-08T23:10:04.764176: step 2655, loss 0.0227124, acc 0.984375
2020-02-08T23:10:04.917275: step 2656, loss 0.0219568, acc 0.984375
2020-02-08T23:10:05.072728: step 2657, loss 0.0112789, acc 1
2020-02-08T23:10:05.231066: step 2658, loss 0.032168, acc 0.984375
2020-02-08T23:10:05.388611: step 2659, loss 0.0122004, acc 1
2020-02-08T23:10:05.540805: step 2660, loss 0.0345561, acc 0.984375
2020-02-08T23:10:05.688728: step 2661, loss 0.0059877, acc 1
2020-02-08T23:10:05.844249: step 2662, loss 0.0253818, acc 0.984375
2020-02-08T23:10:06.005034: step 2663, loss 0.00693672, acc 1
2020-02-08T23:10:06.156683: step 2664, loss 0.0112859, acc 1
2020-02-08T23:10:06.316687: step 2665, loss 0.0396249, acc 0.984375
2020-02-08T23:10:06.474080: step 2666, loss 0.0171915, acc 1
2020-02-08T23:10:06.632612: step 2667, loss 0.0778202, acc 0.96875
2020-02-08T23:10:06.798015: step 2668, loss 0.00831103, acc 1
2020-02-08T23:10:06.955536: step 2669, loss 0.0165726, acc 1
2020-02-08T23:10:07.109352: step 2670, loss 0.00645859, acc 1
2020-02-08T23:10:07.268862: step 2671, loss 0.0368161, acc 0.984375
2020-02-08T23:10:07.426098: step 2672, loss 0.0228145, acc 0.984375
2020-02-08T23:10:07.581939: step 2673, loss 0.00491915, acc 1
2020-02-08T23:10:07.743025: step 2674, loss 0.0320821, acc 0.984375
2020-02-08T23:10:07.897621: step 2675, loss 0.0467256, acc 0.96875
2020-02-08T23:10:08.055440: step 2676, loss 0.00740692, acc 1
2020-02-08T23:10:08.215004: step 2677, loss 0.0124941, acc 1
2020-02-08T23:10:08.374075: step 2678, loss 0.0415125, acc 0.984375
2020-02-08T23:10:08.532349: step 2679, loss 0.0259699, acc 0.984375
2020-02-08T23:10:08.684610: step 2680, loss 0.012319, acc 1
2020-02-08T23:10:08.842855: step 2681, loss 0.0165649, acc 1
2020-02-08T23:10:09.001721: step 2682, loss 0.00998202, acc 1
2020-02-08T23:10:09.161420: step 2683, loss 0.0345113, acc 0.984375
2020-02-08T23:10:09.313668: step 2684, loss 0.0129595, acc 1
2020-02-08T23:10:09.468636: step 2685, loss 0.0226178, acc 0.984375
2020-02-08T23:10:09.624498: step 2686, loss 0.0464274, acc 0.96875
2020-02-08T23:10:09.780419: step 2687, loss 0.0252954, acc 0.984375
2020-02-08T23:10:09.935674: step 2688, loss 0.0176127, acc 0.984375
2020-02-08T23:10:10.087553: step 2689, loss 0.0095034, acc 1
2020-02-08T23:10:10.250131: step 2690, loss 0.0221088, acc 1
2020-02-08T23:10:10.414417: step 2691, loss 0.0347634, acc 0.984375
2020-02-08T23:10:10.570379: step 2692, loss 0.0209817, acc 1
2020-02-08T23:10:10.725794: step 2693, loss 0.00718779, acc 1
2020-02-08T23:10:10.883679: step 2694, loss 0.0689812, acc 0.96875
2020-02-08T23:10:11.051682: step 2695, loss 0.0258608, acc 1
2020-02-08T23:10:11.215280: step 2696, loss 0.0525772, acc 0.984375
2020-02-08T23:10:11.374729: step 2697, loss 0.0218852, acc 0.984375
2020-02-08T23:10:11.531899: step 2698, loss 0.0271191, acc 0.984375
2020-02-08T23:10:11.688248: step 2699, loss 0.00913671, acc 1
2020-02-08T23:10:11.837890: step 2700, loss 0.0620648, acc 0.983333

Evaluation:
2020-02-08T23:10:12.116550: step 2700, loss 0.990274, acc 0.726079

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2700

2020-02-08T23:10:13.685220: step 2701, loss 0.0179549, acc 1
2020-02-08T23:10:13.836791: step 2702, loss 0.0248951, acc 1
2020-02-08T23:10:14.142067: step 2703, loss 0.01888, acc 1
2020-02-08T23:10:14.305617: step 2704, loss 0.0337123, acc 1
2020-02-08T23:10:14.470568: step 2705, loss 0.0176582, acc 1
2020-02-08T23:10:14.629793: step 2706, loss 0.0191188, acc 1
2020-02-08T23:10:14.784532: step 2707, loss 0.00806378, acc 1
2020-02-08T23:10:14.937802: step 2708, loss 0.0232397, acc 1
2020-02-08T23:10:15.094477: step 2709, loss 0.0158269, acc 1
2020-02-08T23:10:15.252690: step 2710, loss 0.00936438, acc 1
2020-02-08T23:10:15.413723: step 2711, loss 0.040221, acc 1
2020-02-08T23:10:15.568141: step 2712, loss 0.0430629, acc 0.984375
2020-02-08T23:10:15.728664: step 2713, loss 0.0248616, acc 0.984375
2020-02-08T23:10:15.880111: step 2714, loss 0.010487, acc 1
2020-02-08T23:10:16.033455: step 2715, loss 0.0392167, acc 1
2020-02-08T23:10:16.187721: step 2716, loss 0.0321479, acc 0.984375
2020-02-08T23:10:16.349205: step 2717, loss 0.0124091, acc 1
2020-02-08T23:10:16.502343: step 2718, loss 0.0339812, acc 1
2020-02-08T23:10:16.668824: step 2719, loss 0.0183007, acc 1
2020-02-08T23:10:16.834877: step 2720, loss 0.00947132, acc 1
2020-02-08T23:10:17.004104: step 2721, loss 0.0267594, acc 0.984375
2020-02-08T23:10:17.161979: step 2722, loss 0.00533304, acc 1
2020-02-08T23:10:17.319686: step 2723, loss 0.0131286, acc 1
2020-02-08T23:10:17.472853: step 2724, loss 0.0562814, acc 0.984375
2020-02-08T23:10:17.633511: step 2725, loss 0.0384147, acc 0.984375
2020-02-08T23:10:17.799067: step 2726, loss 0.0378055, acc 0.96875
2020-02-08T23:10:17.964601: step 2727, loss 0.0153074, acc 1
2020-02-08T23:10:18.123644: step 2728, loss 0.0120501, acc 1
2020-02-08T23:10:18.305371: step 2729, loss 0.017363, acc 1
2020-02-08T23:10:18.479444: step 2730, loss 0.0171516, acc 1
2020-02-08T23:10:18.691262: step 2731, loss 0.0101414, acc 1
2020-02-08T23:10:18.878079: step 2732, loss 0.0296646, acc 0.984375
2020-02-08T23:10:19.046026: step 2733, loss 0.0846655, acc 0.96875
2020-02-08T23:10:19.219444: step 2734, loss 0.00887184, acc 1
2020-02-08T23:10:19.390399: step 2735, loss 0.0590134, acc 0.984375
2020-02-08T23:10:19.600430: step 2736, loss 0.00661303, acc 1
2020-02-08T23:10:19.796079: step 2737, loss 0.00923234, acc 1
2020-02-08T23:10:20.023546: step 2738, loss 0.00614565, acc 1
2020-02-08T23:10:20.233191: step 2739, loss 0.054108, acc 0.953125
2020-02-08T23:10:20.391912: step 2740, loss 0.00463533, acc 1
2020-02-08T23:10:20.581337: step 2741, loss 0.0552893, acc 0.984375
2020-02-08T23:10:20.744139: step 2742, loss 0.0065681, acc 1
2020-02-08T23:10:20.929415: step 2743, loss 0.0252383, acc 1
2020-02-08T23:10:21.091124: step 2744, loss 0.079961, acc 0.96875
2020-02-08T23:10:21.255433: step 2745, loss 0.106083, acc 0.96875
2020-02-08T23:10:21.462065: step 2746, loss 0.0221033, acc 1
2020-02-08T23:10:21.657616: step 2747, loss 0.040971, acc 0.984375
2020-02-08T23:10:21.829780: step 2748, loss 0.00461916, acc 1
2020-02-08T23:10:21.999587: step 2749, loss 0.00903278, acc 1
2020-02-08T23:10:22.170551: step 2750, loss 0.0328336, acc 0.984375
2020-02-08T23:10:22.332185: step 2751, loss 0.0269952, acc 0.984375
2020-02-08T23:10:22.492786: step 2752, loss 0.0273492, acc 0.984375
2020-02-08T23:10:22.661933: step 2753, loss 0.093163, acc 0.9375
2020-02-08T23:10:22.834448: step 2754, loss 0.0562686, acc 0.96875
2020-02-08T23:10:22.997804: step 2755, loss 0.0169545, acc 0.984375
2020-02-08T23:10:23.172332: step 2756, loss 0.0776336, acc 0.953125
2020-02-08T23:10:23.335716: step 2757, loss 0.00515325, acc 1
2020-02-08T23:10:23.495769: step 2758, loss 0.089409, acc 0.984375
2020-02-08T23:10:23.676916: step 2759, loss 0.0539951, acc 0.984375
2020-02-08T23:10:23.847141: step 2760, loss 0.0100511, acc 1
2020-02-08T23:10:24.018482: step 2761, loss 0.0162635, acc 1
2020-02-08T23:10:24.192493: step 2762, loss 0.0224471, acc 1
2020-02-08T23:10:24.353744: step 2763, loss 0.0243223, acc 1
2020-02-08T23:10:24.516712: step 2764, loss 0.00296895, acc 1
2020-02-08T23:10:24.687353: step 2765, loss 0.00773479, acc 1
2020-02-08T23:10:24.855031: step 2766, loss 0.0086695, acc 1
2020-02-08T23:10:25.022733: step 2767, loss 0.0440779, acc 0.984375
2020-02-08T23:10:25.183384: step 2768, loss 0.0130099, acc 1
2020-02-08T23:10:25.348579: step 2769, loss 0.00612027, acc 1
2020-02-08T23:10:25.512358: step 2770, loss 0.0239691, acc 0.984375
2020-02-08T23:10:25.682926: step 2771, loss 0.0203455, acc 1
2020-02-08T23:10:25.856593: step 2772, loss 0.0273374, acc 1
2020-02-08T23:10:26.024342: step 2773, loss 0.00970713, acc 1
2020-02-08T23:10:26.185901: step 2774, loss 0.0303753, acc 0.96875
2020-02-08T23:10:26.342426: step 2775, loss 0.0528017, acc 0.96875
2020-02-08T23:10:26.505767: step 2776, loss 0.0140128, acc 1
2020-02-08T23:10:26.674357: step 2777, loss 0.00994575, acc 1
2020-02-08T23:10:26.862733: step 2778, loss 0.0197336, acc 0.984375
2020-02-08T23:10:27.059742: step 2779, loss 0.0212852, acc 1
2020-02-08T23:10:27.275929: step 2780, loss 0.0100096, acc 1
2020-02-08T23:10:27.452767: step 2781, loss 0.0117202, acc 1
2020-02-08T23:10:27.627031: step 2782, loss 0.0234925, acc 1
2020-02-08T23:10:27.794508: step 2783, loss 0.0250189, acc 0.984375
2020-02-08T23:10:27.976676: step 2784, loss 0.0310732, acc 0.984375
2020-02-08T23:10:28.143565: step 2785, loss 0.0296282, acc 0.984375
2020-02-08T23:10:28.307874: step 2786, loss 0.0180793, acc 1
2020-02-08T23:10:28.467593: step 2787, loss 0.0544051, acc 0.96875
2020-02-08T23:10:28.631861: step 2788, loss 0.00528829, acc 1
2020-02-08T23:10:28.794837: step 2789, loss 0.0105067, acc 1
2020-02-08T23:10:28.972134: step 2790, loss 0.0553368, acc 0.96875
2020-02-08T23:10:29.134530: step 2791, loss 0.0250239, acc 1
2020-02-08T23:10:29.300839: step 2792, loss 0.0257461, acc 1
2020-02-08T23:10:29.470224: step 2793, loss 0.0468845, acc 0.984375
2020-02-08T23:10:29.628055: step 2794, loss 0.00887177, acc 1
2020-02-08T23:10:29.788038: step 2795, loss 0.0203259, acc 1
2020-02-08T23:10:29.946654: step 2796, loss 0.0300693, acc 1
2020-02-08T23:10:30.102683: step 2797, loss 0.0225195, acc 1
2020-02-08T23:10:30.265338: step 2798, loss 0.0560513, acc 0.96875
2020-02-08T23:10:30.427603: step 2799, loss 0.0314702, acc 0.984375
2020-02-08T23:10:30.583811: step 2800, loss 0.0194945, acc 1

Evaluation:
2020-02-08T23:10:30.861043: step 2800, loss 1.03633, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2800

2020-02-08T23:10:32.421394: step 2801, loss 0.0211297, acc 1
2020-02-08T23:10:32.578866: step 2802, loss 0.0251074, acc 1
2020-02-08T23:10:32.738048: step 2803, loss 0.00235476, acc 1
2020-02-08T23:10:32.889821: step 2804, loss 0.0158963, acc 1
2020-02-08T23:10:33.046529: step 2805, loss 0.0273995, acc 1
2020-02-08T23:10:33.210860: step 2806, loss 0.0420646, acc 0.984375
2020-02-08T23:10:33.373234: step 2807, loss 0.0322958, acc 0.984375
2020-02-08T23:10:33.526257: step 2808, loss 0.0535391, acc 0.984375
2020-02-08T23:10:33.679358: step 2809, loss 0.0215906, acc 0.984375
2020-02-08T23:10:33.841090: step 2810, loss 0.0136272, acc 1
2020-02-08T23:10:33.994496: step 2811, loss 0.015386, acc 1
2020-02-08T23:10:34.149835: step 2812, loss 0.0508623, acc 0.96875
2020-02-08T23:10:34.304011: step 2813, loss 0.030913, acc 0.984375
2020-02-08T23:10:34.457572: step 2814, loss 0.0112763, acc 1
2020-02-08T23:10:34.613674: step 2815, loss 0.0126062, acc 1
2020-02-08T23:10:34.766025: step 2816, loss 0.00632083, acc 1
2020-02-08T23:10:34.924203: step 2817, loss 0.00400465, acc 1
2020-02-08T23:10:35.081357: step 2818, loss 0.0223, acc 0.984375
2020-02-08T23:10:35.243767: step 2819, loss 0.0279066, acc 0.984375
2020-02-08T23:10:35.405507: step 2820, loss 0.0317681, acc 0.984375
2020-02-08T23:10:35.559883: step 2821, loss 0.0183845, acc 0.984375
2020-02-08T23:10:35.716725: step 2822, loss 0.0264576, acc 1
2020-02-08T23:10:35.879715: step 2823, loss 0.0290432, acc 1
2020-02-08T23:10:36.038272: step 2824, loss 0.00915657, acc 1
2020-02-08T23:10:36.198275: step 2825, loss 0.0712202, acc 0.984375
2020-02-08T23:10:36.355638: step 2826, loss 0.0136571, acc 1
2020-02-08T23:10:36.510447: step 2827, loss 0.0232112, acc 1
2020-02-08T23:10:36.668101: step 2828, loss 0.0795349, acc 0.96875
2020-02-08T23:10:36.831668: step 2829, loss 0.0474886, acc 0.984375
2020-02-08T23:10:37.044712: step 2830, loss 0.0494406, acc 0.96875
2020-02-08T23:10:37.240985: step 2831, loss 0.0132238, acc 1
2020-02-08T23:10:37.396607: step 2832, loss 0.0901172, acc 0.984375
2020-02-08T23:10:37.555606: step 2833, loss 0.0610022, acc 0.96875
2020-02-08T23:10:37.710538: step 2834, loss 0.0236748, acc 1
2020-02-08T23:10:37.865075: step 2835, loss 0.0157176, acc 1
2020-02-08T23:10:38.025954: step 2836, loss 0.0175284, acc 0.984375
2020-02-08T23:10:38.180228: step 2837, loss 0.00710201, acc 1
2020-02-08T23:10:38.334817: step 2838, loss 0.0897856, acc 0.953125
2020-02-08T23:10:38.493698: step 2839, loss 0.0119185, acc 1
2020-02-08T23:10:38.651074: step 2840, loss 0.0134625, acc 1
2020-02-08T23:10:38.814059: step 2841, loss 0.0322297, acc 1
2020-02-08T23:10:38.975351: step 2842, loss 0.0695169, acc 0.984375
2020-02-08T23:10:39.132586: step 2843, loss 0.0198244, acc 0.984375
2020-02-08T23:10:39.285299: step 2844, loss 0.0124648, acc 1
2020-02-08T23:10:39.446660: step 2845, loss 0.0283336, acc 0.984375
2020-02-08T23:10:39.606395: step 2846, loss 0.0432213, acc 1
2020-02-08T23:10:39.769327: step 2847, loss 0.0265363, acc 0.984375
2020-02-08T23:10:39.925844: step 2848, loss 0.0168499, acc 1
2020-02-08T23:10:40.082538: step 2849, loss 0.0561945, acc 0.96875
2020-02-08T23:10:40.235264: step 2850, loss 0.114355, acc 0.983333
2020-02-08T23:10:40.397309: step 2851, loss 0.0156823, acc 1
2020-02-08T23:10:40.550958: step 2852, loss 0.00949134, acc 1
2020-02-08T23:10:40.705938: step 2853, loss 0.0213459, acc 0.984375
2020-02-08T23:10:40.867573: step 2854, loss 0.0160839, acc 0.984375
2020-02-08T23:10:41.035213: step 2855, loss 0.036051, acc 0.96875
2020-02-08T23:10:41.201260: step 2856, loss 0.0333434, acc 0.984375
2020-02-08T23:10:41.371444: step 2857, loss 0.00442311, acc 1
2020-02-08T23:10:41.524528: step 2858, loss 0.0087051, acc 1
2020-02-08T23:10:41.675590: step 2859, loss 0.0135542, acc 1
2020-02-08T23:10:41.832885: step 2860, loss 0.0673318, acc 0.96875
2020-02-08T23:10:41.989478: step 2861, loss 0.0533108, acc 0.984375
2020-02-08T23:10:42.142712: step 2862, loss 0.00547994, acc 1
2020-02-08T23:10:42.294192: step 2863, loss 0.0470058, acc 0.96875
2020-02-08T23:10:42.449160: step 2864, loss 0.0119352, acc 1
2020-02-08T23:10:42.607725: step 2865, loss 0.0378239, acc 0.984375
2020-02-08T23:10:42.771062: step 2866, loss 0.0103778, acc 1
2020-02-08T23:10:42.924509: step 2867, loss 0.00480302, acc 1
2020-02-08T23:10:43.083863: step 2868, loss 0.0219539, acc 0.984375
2020-02-08T23:10:43.247935: step 2869, loss 0.0239021, acc 0.984375
2020-02-08T23:10:43.411765: step 2870, loss 0.0184433, acc 1
2020-02-08T23:10:43.566821: step 2871, loss 0.0266215, acc 1
2020-02-08T23:10:43.722555: step 2872, loss 0.00912858, acc 1
2020-02-08T23:10:44.052202: step 2873, loss 0.0222047, acc 0.984375
2020-02-08T23:10:44.220052: step 2874, loss 0.0305085, acc 0.984375
2020-02-08T23:10:44.381807: step 2875, loss 0.020451, acc 0.984375
2020-02-08T23:10:44.533960: step 2876, loss 0.00632236, acc 1
2020-02-08T23:10:44.685635: step 2877, loss 0.00494503, acc 1
2020-02-08T23:10:44.841380: step 2878, loss 0.00507752, acc 1
2020-02-08T23:10:45.003632: step 2879, loss 0.0120814, acc 1
2020-02-08T23:10:45.169450: step 2880, loss 0.00763623, acc 1
2020-02-08T23:10:45.328185: step 2881, loss 0.0189889, acc 1
2020-02-08T23:10:45.483695: step 2882, loss 0.0146826, acc 1
2020-02-08T23:10:45.641938: step 2883, loss 0.0363248, acc 0.984375
2020-02-08T23:10:45.801484: step 2884, loss 0.0140028, acc 1
2020-02-08T23:10:45.961146: step 2885, loss 0.0147266, acc 1
2020-02-08T23:10:46.120026: step 2886, loss 0.0121174, acc 1
2020-02-08T23:10:46.275751: step 2887, loss 0.0064246, acc 1
2020-02-08T23:10:46.436807: step 2888, loss 0.0274124, acc 1
2020-02-08T23:10:46.600740: step 2889, loss 0.00396407, acc 1
2020-02-08T23:10:46.765062: step 2890, loss 0.0546753, acc 0.984375
2020-02-08T23:10:46.930206: step 2891, loss 0.0315862, acc 0.96875
2020-02-08T23:10:47.088026: step 2892, loss 0.0271295, acc 0.984375
2020-02-08T23:10:47.239807: step 2893, loss 0.0544227, acc 0.984375
2020-02-08T23:10:47.398931: step 2894, loss 0.0111711, acc 1
2020-02-08T23:10:47.550731: step 2895, loss 0.0393925, acc 0.984375
2020-02-08T23:10:47.702911: step 2896, loss 0.0136735, acc 1
2020-02-08T23:10:47.869417: step 2897, loss 0.00578653, acc 1
2020-02-08T23:10:48.034848: step 2898, loss 0.0169926, acc 1
2020-02-08T23:10:48.193403: step 2899, loss 0.0245073, acc 0.984375
2020-02-08T23:10:48.352255: step 2900, loss 0.0194304, acc 1

Evaluation:
2020-02-08T23:10:48.623873: step 2900, loss 1.04411, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-2900

2020-02-08T23:10:50.245635: step 2901, loss 0.00538304, acc 1
2020-02-08T23:10:50.405504: step 2902, loss 0.0142812, acc 1
2020-02-08T23:10:50.566204: step 2903, loss 0.0482605, acc 0.953125
2020-02-08T23:10:50.724936: step 2904, loss 0.00481036, acc 1
2020-02-08T23:10:50.891914: step 2905, loss 0.0352912, acc 0.984375
2020-02-08T23:10:51.052710: step 2906, loss 0.0128957, acc 1
2020-02-08T23:10:51.215597: step 2907, loss 0.00443664, acc 1
2020-02-08T23:10:51.371139: step 2908, loss 0.0579319, acc 0.96875
2020-02-08T23:10:51.526936: step 2909, loss 0.0188406, acc 1
2020-02-08T23:10:51.688800: step 2910, loss 0.0267121, acc 0.984375
2020-02-08T23:10:51.845076: step 2911, loss 0.020633, acc 1
2020-02-08T23:10:52.005810: step 2912, loss 0.00942507, acc 1
2020-02-08T23:10:52.173789: step 2913, loss 0.042508, acc 0.984375
2020-02-08T23:10:52.330979: step 2914, loss 0.00911593, acc 1
2020-02-08T23:10:52.490189: step 2915, loss 0.00998505, acc 1
2020-02-08T23:10:52.659006: step 2916, loss 0.00782927, acc 1
2020-02-08T23:10:52.830860: step 2917, loss 0.0115016, acc 1
2020-02-08T23:10:52.986746: step 2918, loss 0.0506662, acc 0.984375
2020-02-08T23:10:53.141309: step 2919, loss 0.00793472, acc 1
2020-02-08T23:10:53.296232: step 2920, loss 0.0145808, acc 1
2020-02-08T23:10:53.463997: step 2921, loss 0.00963745, acc 1
2020-02-08T23:10:53.650998: step 2922, loss 0.060729, acc 0.96875
2020-02-08T23:10:53.814844: step 2923, loss 0.0156627, acc 1
2020-02-08T23:10:53.981614: step 2924, loss 0.00624559, acc 1
2020-02-08T23:10:54.139937: step 2925, loss 0.079617, acc 0.984375
2020-02-08T23:10:54.375362: step 2926, loss 0.0463719, acc 0.984375
2020-02-08T23:10:54.574762: step 2927, loss 0.024791, acc 1
2020-02-08T23:10:54.798392: step 2928, loss 0.0270806, acc 0.984375
2020-02-08T23:10:54.964066: step 2929, loss 0.0531143, acc 0.96875
2020-02-08T23:10:55.132216: step 2930, loss 0.012413, acc 1
2020-02-08T23:10:55.300188: step 2931, loss 0.0215247, acc 1
2020-02-08T23:10:55.459983: step 2932, loss 0.0067179, acc 1
2020-02-08T23:10:55.620166: step 2933, loss 0.0538179, acc 0.984375
2020-02-08T23:10:55.776491: step 2934, loss 0.00707558, acc 1
2020-02-08T23:10:55.934458: step 2935, loss 0.00967129, acc 1
2020-02-08T23:10:56.091338: step 2936, loss 0.0303345, acc 0.984375
2020-02-08T23:10:56.252634: step 2937, loss 0.021496, acc 1
2020-02-08T23:10:56.414126: step 2938, loss 0.0371617, acc 0.984375
2020-02-08T23:10:56.575172: step 2939, loss 0.00459666, acc 1
2020-02-08T23:10:56.735880: step 2940, loss 0.0150125, acc 1
2020-02-08T23:10:56.888782: step 2941, loss 0.0226526, acc 1
2020-02-08T23:10:57.043483: step 2942, loss 0.0846926, acc 0.953125
2020-02-08T23:10:57.210958: step 2943, loss 0.0151797, acc 1
2020-02-08T23:10:57.372387: step 2944, loss 0.00213987, acc 1
2020-02-08T23:10:57.525098: step 2945, loss 0.0174385, acc 1
2020-02-08T23:10:57.682103: step 2946, loss 0.0137686, acc 1
2020-02-08T23:10:57.838901: step 2947, loss 0.0128898, acc 1
2020-02-08T23:10:57.994902: step 2948, loss 0.0409441, acc 0.984375
2020-02-08T23:10:58.148594: step 2949, loss 0.0358459, acc 0.984375
2020-02-08T23:10:58.297609: step 2950, loss 0.0293917, acc 0.984375
2020-02-08T23:10:58.455373: step 2951, loss 0.0185489, acc 1
2020-02-08T23:10:58.609886: step 2952, loss 0.0182164, acc 1
2020-02-08T23:10:58.772555: step 2953, loss 0.0180995, acc 1
2020-02-08T23:10:58.928781: step 2954, loss 0.032335, acc 0.984375
2020-02-08T23:10:59.087853: step 2955, loss 0.0192003, acc 1
2020-02-08T23:10:59.245533: step 2956, loss 0.103879, acc 0.96875
2020-02-08T23:10:59.401462: step 2957, loss 0.0101835, acc 1
2020-02-08T23:10:59.559934: step 2958, loss 0.0224481, acc 0.984375
2020-02-08T23:10:59.723131: step 2959, loss 0.0182033, acc 1
2020-02-08T23:10:59.876559: step 2960, loss 0.0058197, acc 1
2020-02-08T23:11:00.036725: step 2961, loss 0.0498656, acc 0.984375
2020-02-08T23:11:00.193152: step 2962, loss 0.0569072, acc 0.984375
2020-02-08T23:11:00.349952: step 2963, loss 0.0149205, acc 1
2020-02-08T23:11:00.508949: step 2964, loss 0.0110717, acc 1
2020-02-08T23:11:00.671698: step 2965, loss 0.0111392, acc 1
2020-02-08T23:11:00.831231: step 2966, loss 0.0351691, acc 0.984375
2020-02-08T23:11:01.000813: step 2967, loss 0.0407316, acc 0.984375
2020-02-08T23:11:01.165234: step 2968, loss 0.00892291, acc 1
2020-02-08T23:11:01.318940: step 2969, loss 0.0909517, acc 0.96875
2020-02-08T23:11:01.475758: step 2970, loss 0.0166969, acc 1
2020-02-08T23:11:01.634751: step 2971, loss 0.010995, acc 1
2020-02-08T23:11:01.794888: step 2972, loss 0.0143684, acc 1
2020-02-08T23:11:01.964542: step 2973, loss 0.0140006, acc 1
2020-02-08T23:11:02.124816: step 2974, loss 0.0412124, acc 0.984375
2020-02-08T23:11:02.277900: step 2975, loss 0.0254622, acc 0.984375
2020-02-08T23:11:02.437332: step 2976, loss 0.0222925, acc 0.984375
2020-02-08T23:11:02.588548: step 2977, loss 0.00809408, acc 1
2020-02-08T23:11:02.742058: step 2978, loss 0.0380178, acc 0.984375
2020-02-08T23:11:02.894994: step 2979, loss 0.0054875, acc 1
2020-02-08T23:11:03.049546: step 2980, loss 0.0346043, acc 0.984375
2020-02-08T23:11:03.213757: step 2981, loss 0.0102182, acc 1
2020-02-08T23:11:03.376737: step 2982, loss 0.0416356, acc 0.984375
2020-02-08T23:11:03.528416: step 2983, loss 0.0125682, acc 1
2020-02-08T23:11:03.682359: step 2984, loss 0.0281228, acc 0.984375
2020-02-08T23:11:03.835042: step 2985, loss 0.0135325, acc 1
2020-02-08T23:11:03.994146: step 2986, loss 0.0130685, acc 1
2020-02-08T23:11:04.152460: step 2987, loss 0.0943922, acc 0.96875
2020-02-08T23:11:04.307277: step 2988, loss 0.0228875, acc 0.984375
2020-02-08T23:11:04.463248: step 2989, loss 0.00581501, acc 1
2020-02-08T23:11:04.625081: step 2990, loss 0.0101606, acc 1
2020-02-08T23:11:04.784903: step 2991, loss 0.0100002, acc 1
2020-02-08T23:11:04.937462: step 2992, loss 0.0199821, acc 1
2020-02-08T23:11:05.090651: step 2993, loss 0.0253176, acc 0.984375
2020-02-08T23:11:05.244705: step 2994, loss 0.0263865, acc 1
2020-02-08T23:11:05.398875: step 2995, loss 0.0463502, acc 0.984375
2020-02-08T23:11:05.554633: step 2996, loss 0.0100552, acc 1
2020-02-08T23:11:05.704159: step 2997, loss 0.00727281, acc 1
2020-02-08T23:11:05.861247: step 2998, loss 0.0213966, acc 1
2020-02-08T23:11:06.014354: step 2999, loss 0.00608791, acc 1
2020-02-08T23:11:06.173689: step 3000, loss 0.0176097, acc 1

Evaluation:
2020-02-08T23:11:06.453944: step 3000, loss 1.10056, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581174089/checkpoints/model-3000

