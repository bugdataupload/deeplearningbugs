WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:09:28.184890 4509564352 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:09:28.185106 4509564352 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:09:28.185210 4509564352 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 03:09:28.692627 4509564352 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 03:09:28.692858 4509564352 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 03:09:28.693057: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 03:09:28.706429: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8c92fbde0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 03:09:28.706452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 03:09:28.706892 4509564352 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 03:09:28.711807 4509564352 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 03:09:28.724647 4509564352 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 03:09:28.733849 4509564352 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 03:09:28.761399 4509564352 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 03:09:28.772435 4509564352 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 03:09:28.772656 4509564352 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 03:09:28.783307 4509564352 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 03:09:28.785671 4509564352 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 03:09:28.817253 4509564352 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 03:09:29.052272 4509564352 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 03:09:29.052510 4509564352 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 03:09:29.058647 4509564352 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 03:09:29.079087 4509564352 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 03:09:29.080251 4509564352 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 03:09:29.098501 4509564352 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 03:09:29.099608 4509564352 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 03:09:29.116381 4509564352 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 03:09:29.117806 4509564352 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 03:09:29.132314 4509564352 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 03:09:29.133363 4509564352 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 03:09:29.147528 4509564352 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 03:09:29.148566 4509564352 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 03:09:29.165180 4509564352 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 03:09:29.166309 4509564352 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 03:09:29.182917 4509564352 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 03:09:29.184361 4509564352 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 03:09:29.200777 4509564352 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 03:09:29.201951 4509564352 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 03:09:29.218551 4509564352 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 03:09:29.219987 4509564352 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 03:09:29.224056 4509564352 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 03:09:29.564980 4509564352 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 03:09:29.565178 4509564352 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 03:09:29.608756 4509564352 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 03:09:30.155836 4509564352 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 03:10:50.196500 4509564352 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569

2020-02-08T03:09:30.155384: step 1, loss 2.44377, acc 0.578125
2020-02-08T03:09:30.293072: step 2, loss 2.17329, acc 0.484375
2020-02-08T03:09:30.412031: step 3, loss 2.11621, acc 0.515625
2020-02-08T03:09:30.526983: step 4, loss 2.06045, acc 0.453125
2020-02-08T03:09:30.644001: step 5, loss 1.85839, acc 0.578125
2020-02-08T03:09:30.760760: step 6, loss 2.62786, acc 0.390625
2020-02-08T03:09:30.877832: step 7, loss 1.8859, acc 0.5625
2020-02-08T03:09:30.996826: step 8, loss 2.27848, acc 0.484375
2020-02-08T03:09:31.113920: step 9, loss 2.23732, acc 0.46875
2020-02-08T03:09:31.232222: step 10, loss 1.81065, acc 0.5625
2020-02-08T03:09:31.349307: step 11, loss 2.26453, acc 0.46875
2020-02-08T03:09:31.465464: step 12, loss 2.36147, acc 0.546875
2020-02-08T03:09:31.582614: step 13, loss 2.09402, acc 0.546875
2020-02-08T03:09:31.699208: step 14, loss 2.41385, acc 0.484375
2020-02-08T03:09:31.816810: step 15, loss 2.08088, acc 0.5
2020-02-08T03:09:31.934733: step 16, loss 1.3945, acc 0.625
2020-02-08T03:09:32.051573: step 17, loss 1.82807, acc 0.546875
2020-02-08T03:09:32.166189: step 18, loss 1.62804, acc 0.515625
2020-02-08T03:09:32.281248: step 19, loss 1.63007, acc 0.546875
2020-02-08T03:09:32.398103: step 20, loss 1.98954, acc 0.5625
2020-02-08T03:09:32.513983: step 21, loss 2.09552, acc 0.453125
2020-02-08T03:09:32.631741: step 22, loss 2.27773, acc 0.453125
2020-02-08T03:09:32.752181: step 23, loss 2.04066, acc 0.609375
2020-02-08T03:09:32.870817: step 24, loss 1.49399, acc 0.546875
2020-02-08T03:09:33.016396: step 25, loss 1.78005, acc 0.546875
2020-02-08T03:09:33.138554: step 26, loss 1.88173, acc 0.484375
2020-02-08T03:09:33.257629: step 27, loss 1.66302, acc 0.515625
2020-02-08T03:09:33.371781: step 28, loss 1.62413, acc 0.53125
2020-02-08T03:09:33.486215: step 29, loss 2.10239, acc 0.5
2020-02-08T03:09:33.602382: step 30, loss 1.77027, acc 0.546875
2020-02-08T03:09:33.718289: step 31, loss 1.75021, acc 0.59375
2020-02-08T03:09:33.837223: step 32, loss 1.96572, acc 0.46875
2020-02-08T03:09:33.954957: step 33, loss 1.71631, acc 0.4375
2020-02-08T03:09:34.070789: step 34, loss 1.85008, acc 0.53125
2020-02-08T03:09:34.187258: step 35, loss 3.06914, acc 0.359375
2020-02-08T03:09:34.303205: step 36, loss 1.73093, acc 0.515625
2020-02-08T03:09:34.418098: step 37, loss 1.68969, acc 0.625
2020-02-08T03:09:34.533616: step 38, loss 1.92411, acc 0.484375
2020-02-08T03:09:34.649400: step 39, loss 1.92921, acc 0.546875
2020-02-08T03:09:34.767271: step 40, loss 1.57094, acc 0.515625
2020-02-08T03:09:34.884109: step 41, loss 1.58175, acc 0.5
2020-02-08T03:09:35.003717: step 42, loss 1.45417, acc 0.59375
2020-02-08T03:09:35.119166: step 43, loss 1.90863, acc 0.4375
2020-02-08T03:09:35.235540: step 44, loss 1.78188, acc 0.5625
2020-02-08T03:09:35.352249: step 45, loss 1.81799, acc 0.546875
2020-02-08T03:09:35.468197: step 46, loss 1.23742, acc 0.640625
2020-02-08T03:09:35.581960: step 47, loss 1.66251, acc 0.484375
2020-02-08T03:09:35.696055: step 48, loss 2.03669, acc 0.375
2020-02-08T03:09:35.813986: step 49, loss 1.55317, acc 0.515625
2020-02-08T03:09:35.932094: step 50, loss 1.75637, acc 0.546875
2020-02-08T03:09:36.047937: step 51, loss 1.49008, acc 0.59375
2020-02-08T03:09:36.163869: step 52, loss 1.50273, acc 0.671875
2020-02-08T03:09:36.280134: step 53, loss 1.77799, acc 0.515625
2020-02-08T03:09:36.395450: step 54, loss 1.62079, acc 0.546875
2020-02-08T03:09:36.513053: step 55, loss 1.73599, acc 0.59375
2020-02-08T03:09:36.629958: step 56, loss 1.61295, acc 0.59375
2020-02-08T03:09:36.747793: step 57, loss 1.65362, acc 0.578125
2020-02-08T03:09:36.867148: step 58, loss 1.71939, acc 0.421875
2020-02-08T03:09:36.982056: step 59, loss 1.99677, acc 0.5
2020-02-08T03:09:37.098076: step 60, loss 1.35661, acc 0.546875
2020-02-08T03:09:37.216464: step 61, loss 1.6039, acc 0.484375
2020-02-08T03:09:37.332975: step 62, loss 1.29226, acc 0.53125
2020-02-08T03:09:37.447289: step 63, loss 1.67435, acc 0.515625
2020-02-08T03:09:37.561828: step 64, loss 1.25729, acc 0.5625
2020-02-08T03:09:37.680518: step 65, loss 1.74835, acc 0.46875
2020-02-08T03:09:37.796550: step 66, loss 1.6303, acc 0.578125
2020-02-08T03:09:37.913100: step 67, loss 1.36298, acc 0.59375
2020-02-08T03:09:38.031174: step 68, loss 1.83519, acc 0.46875
2020-02-08T03:09:38.144763: step 69, loss 2.0619, acc 0.484375
2020-02-08T03:09:38.262144: step 70, loss 1.48175, acc 0.5
2020-02-08T03:09:38.378062: step 71, loss 1.26932, acc 0.578125
2020-02-08T03:09:38.493134: step 72, loss 1.79464, acc 0.453125
2020-02-08T03:09:38.611609: step 73, loss 1.56192, acc 0.5625
2020-02-08T03:09:38.727758: step 74, loss 1.7174, acc 0.578125
2020-02-08T03:09:38.841970: step 75, loss 1.13439, acc 0.6875
2020-02-08T03:09:38.958167: step 76, loss 1.50045, acc 0.515625
2020-02-08T03:09:39.076327: step 77, loss 1.30661, acc 0.546875
2020-02-08T03:09:39.192491: step 78, loss 1.15741, acc 0.65625
2020-02-08T03:09:39.310752: step 79, loss 1.29782, acc 0.578125
2020-02-08T03:09:39.432748: step 80, loss 1.88546, acc 0.4375
2020-02-08T03:09:39.548664: step 81, loss 1.68533, acc 0.484375
2020-02-08T03:09:39.665236: step 82, loss 1.30492, acc 0.578125
2020-02-08T03:09:39.782627: step 83, loss 1.77869, acc 0.421875
2020-02-08T03:09:39.898007: step 84, loss 1.17412, acc 0.546875
2020-02-08T03:09:40.015011: step 85, loss 1.35083, acc 0.625
2020-02-08T03:09:40.131872: step 86, loss 1.54313, acc 0.53125
2020-02-08T03:09:40.247199: step 87, loss 1.33151, acc 0.59375
2020-02-08T03:09:40.363281: step 88, loss 1.09013, acc 0.6875
2020-02-08T03:09:40.480270: step 89, loss 1.26953, acc 0.53125
2020-02-08T03:09:40.596109: step 90, loss 1.48718, acc 0.453125
2020-02-08T03:09:40.710003: step 91, loss 1.60308, acc 0.5
2020-02-08T03:09:40.825827: step 92, loss 1.25372, acc 0.546875
2020-02-08T03:09:40.943115: step 93, loss 1.35922, acc 0.640625
2020-02-08T03:09:41.056565: step 94, loss 1.2867, acc 0.5625
2020-02-08T03:09:41.175368: step 95, loss 1.7839, acc 0.421875
2020-02-08T03:09:41.291533: step 96, loss 1.06459, acc 0.671875
2020-02-08T03:09:41.406876: step 97, loss 1.36056, acc 0.53125
2020-02-08T03:09:41.524813: step 98, loss 1.21191, acc 0.5625
2020-02-08T03:09:41.640084: step 99, loss 1.37696, acc 0.53125
2020-02-08T03:09:41.755451: step 100, loss 1.48325, acc 0.578125

Evaluation:
2020-02-08T03:09:41.990254: step 100, loss 0.849541, acc 0.572233

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-100

2020-02-08T03:09:44.133457: step 101, loss 1.15292, acc 0.609375
2020-02-08T03:09:44.251696: step 102, loss 2.05382, acc 0.4375
2020-02-08T03:09:44.369692: step 103, loss 1.82364, acc 0.53125
2020-02-08T03:09:44.488129: step 104, loss 1.4052, acc 0.625
2020-02-08T03:09:44.603552: step 105, loss 1.29782, acc 0.5625
2020-02-08T03:09:44.722741: step 106, loss 0.997579, acc 0.625
2020-02-08T03:09:44.838674: step 107, loss 1.52809, acc 0.546875
2020-02-08T03:09:44.951955: step 108, loss 1.19533, acc 0.53125
2020-02-08T03:09:45.070248: step 109, loss 1.4399, acc 0.578125
2020-02-08T03:09:45.188041: step 110, loss 1.02643, acc 0.578125
2020-02-08T03:09:45.302001: step 111, loss 1.17273, acc 0.5
2020-02-08T03:09:45.419534: step 112, loss 1.49218, acc 0.609375
2020-02-08T03:09:45.539053: step 113, loss 1.21276, acc 0.609375
2020-02-08T03:09:45.655288: step 114, loss 1.3912, acc 0.515625
2020-02-08T03:09:45.774098: step 115, loss 1.1583, acc 0.59375
2020-02-08T03:09:45.891978: step 116, loss 1.97249, acc 0.40625
2020-02-08T03:09:46.005665: step 117, loss 1.49351, acc 0.515625
2020-02-08T03:09:46.122480: step 118, loss 1.22729, acc 0.59375
2020-02-08T03:09:46.238498: step 119, loss 1.39584, acc 0.578125
2020-02-08T03:09:46.351091: step 120, loss 1.06151, acc 0.625
2020-02-08T03:09:46.467423: step 121, loss 1.44233, acc 0.5625
2020-02-08T03:09:46.582365: step 122, loss 1.39336, acc 0.515625
2020-02-08T03:09:46.696062: step 123, loss 1.24066, acc 0.5
2020-02-08T03:09:46.814166: step 124, loss 1.55513, acc 0.453125
2020-02-08T03:09:46.931895: step 125, loss 1.50067, acc 0.453125
2020-02-08T03:09:47.052403: step 126, loss 1.19114, acc 0.546875
2020-02-08T03:09:47.170381: step 127, loss 1.25748, acc 0.5625
2020-02-08T03:09:47.285872: step 128, loss 1.0661, acc 0.578125
2020-02-08T03:09:47.400262: step 129, loss 1.43055, acc 0.546875
2020-02-08T03:09:47.513343: step 130, loss 1.52266, acc 0.53125
2020-02-08T03:09:47.629814: step 131, loss 1.75223, acc 0.53125
2020-02-08T03:09:47.745761: step 132, loss 1.23598, acc 0.578125
2020-02-08T03:09:47.867405: step 133, loss 1.33982, acc 0.546875
2020-02-08T03:09:47.988153: step 134, loss 1.88649, acc 0.4375
2020-02-08T03:09:48.108837: step 135, loss 1.01561, acc 0.625
2020-02-08T03:09:48.229959: step 136, loss 1.1241, acc 0.5
2020-02-08T03:09:48.350395: step 137, loss 1.59485, acc 0.53125
2020-02-08T03:09:48.472857: step 138, loss 1.17033, acc 0.625
2020-02-08T03:09:48.592194: step 139, loss 1.12027, acc 0.65625
2020-02-08T03:09:48.714116: step 140, loss 1.52475, acc 0.46875
2020-02-08T03:09:48.832265: step 141, loss 1.6647, acc 0.5
2020-02-08T03:09:48.949984: step 142, loss 1.24686, acc 0.59375
2020-02-08T03:09:49.068588: step 143, loss 1.25904, acc 0.53125
2020-02-08T03:09:49.187276: step 144, loss 1.12879, acc 0.609375
2020-02-08T03:09:49.309217: step 145, loss 1.21853, acc 0.484375
2020-02-08T03:09:49.429727: step 146, loss 1.17939, acc 0.515625
2020-02-08T03:09:49.544774: step 147, loss 1.35836, acc 0.515625
2020-02-08T03:09:49.664118: step 148, loss 1.26899, acc 0.578125
2020-02-08T03:09:49.783032: step 149, loss 1.23292, acc 0.546875
2020-02-08T03:09:49.893877: step 150, loss 1.32623, acc 0.583333
2020-02-08T03:09:50.012235: step 151, loss 0.819395, acc 0.671875
2020-02-08T03:09:50.127227: step 152, loss 1.14962, acc 0.5
2020-02-08T03:09:50.244988: step 153, loss 0.835765, acc 0.6875
2020-02-08T03:09:50.366115: step 154, loss 0.93565, acc 0.671875
2020-02-08T03:09:50.483944: step 155, loss 1.21716, acc 0.546875
2020-02-08T03:09:50.597936: step 156, loss 1.13758, acc 0.546875
2020-02-08T03:09:50.719066: step 157, loss 0.650484, acc 0.734375
2020-02-08T03:09:50.837146: step 158, loss 0.672949, acc 0.71875
2020-02-08T03:09:50.955446: step 159, loss 0.994853, acc 0.609375
2020-02-08T03:09:51.072912: step 160, loss 1.10324, acc 0.6875
2020-02-08T03:09:51.191755: step 161, loss 1.10941, acc 0.5625
2020-02-08T03:09:51.335144: step 162, loss 1.00529, acc 0.5625
2020-02-08T03:09:51.450500: step 163, loss 0.913202, acc 0.625
2020-02-08T03:09:51.586296: step 164, loss 0.934671, acc 0.65625
2020-02-08T03:09:51.703927: step 165, loss 0.927327, acc 0.65625
2020-02-08T03:09:51.828018: step 166, loss 1.33567, acc 0.59375
2020-02-08T03:09:51.944195: step 167, loss 1.02217, acc 0.578125
2020-02-08T03:09:52.061246: step 168, loss 1.24987, acc 0.59375
2020-02-08T03:09:52.179741: step 169, loss 0.960081, acc 0.6875
2020-02-08T03:09:52.294892: step 170, loss 1.26318, acc 0.5625
2020-02-08T03:09:52.414606: step 171, loss 1.01286, acc 0.609375
2020-02-08T03:09:52.533510: step 172, loss 1.16208, acc 0.53125
2020-02-08T03:09:52.649286: step 173, loss 1.30386, acc 0.546875
2020-02-08T03:09:52.768060: step 174, loss 1.16822, acc 0.546875
2020-02-08T03:09:52.886668: step 175, loss 0.729865, acc 0.6875
2020-02-08T03:09:53.001375: step 176, loss 1.01634, acc 0.671875
2020-02-08T03:09:53.120730: step 177, loss 1.12674, acc 0.546875
2020-02-08T03:09:53.236942: step 178, loss 0.976119, acc 0.59375
2020-02-08T03:09:53.353802: step 179, loss 1.1427, acc 0.578125
2020-02-08T03:09:53.476806: step 180, loss 0.999608, acc 0.640625
2020-02-08T03:09:53.590488: step 181, loss 1.18053, acc 0.546875
2020-02-08T03:09:53.707411: step 182, loss 1.20309, acc 0.578125
2020-02-08T03:09:53.823750: step 183, loss 0.967123, acc 0.578125
2020-02-08T03:09:53.939625: step 184, loss 1.14224, acc 0.515625
2020-02-08T03:09:54.056141: step 185, loss 1.30802, acc 0.484375
2020-02-08T03:09:54.174779: step 186, loss 1.10243, acc 0.625
2020-02-08T03:09:54.290144: step 187, loss 1.04453, acc 0.546875
2020-02-08T03:09:54.408914: step 188, loss 1.24125, acc 0.484375
2020-02-08T03:09:54.523883: step 189, loss 1.09506, acc 0.59375
2020-02-08T03:09:54.638211: step 190, loss 0.915498, acc 0.59375
2020-02-08T03:09:54.756306: step 191, loss 1.02046, acc 0.546875
2020-02-08T03:09:54.875752: step 192, loss 0.995205, acc 0.546875
2020-02-08T03:09:54.991469: step 193, loss 0.788213, acc 0.65625
2020-02-08T03:09:55.105792: step 194, loss 0.43861, acc 0.78125
2020-02-08T03:09:55.221718: step 195, loss 1.2488, acc 0.546875
2020-02-08T03:09:55.337272: step 196, loss 1.29896, acc 0.5625
2020-02-08T03:09:55.453071: step 197, loss 1.05425, acc 0.546875
2020-02-08T03:09:55.569238: step 198, loss 0.860338, acc 0.59375
2020-02-08T03:09:55.686937: step 199, loss 1.0774, acc 0.671875
2020-02-08T03:09:55.803466: step 200, loss 1.03664, acc 0.546875

Evaluation:
2020-02-08T03:09:55.992584: step 200, loss 0.675998, acc 0.622889

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-200

2020-02-08T03:09:57.536059: step 201, loss 1.10199, acc 0.53125
2020-02-08T03:09:57.649272: step 202, loss 0.928162, acc 0.625
2020-02-08T03:09:57.767271: step 203, loss 0.840635, acc 0.609375
2020-02-08T03:09:57.886399: step 204, loss 0.900049, acc 0.546875
2020-02-08T03:09:58.003683: step 205, loss 1.05573, acc 0.53125
2020-02-08T03:09:58.127104: step 206, loss 1.3309, acc 0.625
2020-02-08T03:09:58.243474: step 207, loss 0.944369, acc 0.59375
2020-02-08T03:09:58.360838: step 208, loss 0.885628, acc 0.609375
2020-02-08T03:09:58.479506: step 209, loss 1.07012, acc 0.578125
2020-02-08T03:09:58.594482: step 210, loss 0.772068, acc 0.640625
2020-02-08T03:09:58.709027: step 211, loss 0.993913, acc 0.640625
2020-02-08T03:09:58.826803: step 212, loss 0.804482, acc 0.6875
2020-02-08T03:09:58.943077: step 213, loss 0.907668, acc 0.625
2020-02-08T03:09:59.058462: step 214, loss 0.820549, acc 0.65625
2020-02-08T03:09:59.176596: step 215, loss 1.05972, acc 0.578125
2020-02-08T03:09:59.294180: step 216, loss 0.936317, acc 0.6875
2020-02-08T03:09:59.412777: step 217, loss 0.970335, acc 0.609375
2020-02-08T03:09:59.529523: step 218, loss 0.978802, acc 0.59375
2020-02-08T03:09:59.644494: step 219, loss 1.0368, acc 0.578125
2020-02-08T03:09:59.761018: step 220, loss 0.842674, acc 0.578125
2020-02-08T03:09:59.880151: step 221, loss 1.00375, acc 0.671875
2020-02-08T03:09:59.995686: step 222, loss 0.95681, acc 0.59375
2020-02-08T03:10:00.114949: step 223, loss 0.713785, acc 0.671875
2020-02-08T03:10:00.233373: step 224, loss 0.942888, acc 0.484375
2020-02-08T03:10:00.349377: step 225, loss 0.916709, acc 0.578125
2020-02-08T03:10:00.466008: step 226, loss 0.903334, acc 0.640625
2020-02-08T03:10:00.583986: step 227, loss 0.639807, acc 0.734375
2020-02-08T03:10:00.698797: step 228, loss 1.03738, acc 0.59375
2020-02-08T03:10:00.817339: step 229, loss 0.935583, acc 0.640625
2020-02-08T03:10:00.933176: step 230, loss 0.901592, acc 0.609375
2020-02-08T03:10:01.047492: step 231, loss 0.808714, acc 0.65625
2020-02-08T03:10:01.166290: step 232, loss 0.882225, acc 0.546875
2020-02-08T03:10:01.284958: step 233, loss 0.930342, acc 0.671875
2020-02-08T03:10:01.401363: step 234, loss 0.799385, acc 0.640625
2020-02-08T03:10:01.517999: step 235, loss 0.831849, acc 0.65625
2020-02-08T03:10:01.635735: step 236, loss 0.791905, acc 0.640625
2020-02-08T03:10:01.751292: step 237, loss 0.862208, acc 0.671875
2020-02-08T03:10:01.867461: step 238, loss 0.84084, acc 0.59375
2020-02-08T03:10:01.985458: step 239, loss 0.823843, acc 0.703125
2020-02-08T03:10:02.101770: step 240, loss 1.03834, acc 0.515625
2020-02-08T03:10:02.218279: step 241, loss 0.84978, acc 0.609375
2020-02-08T03:10:02.336470: step 242, loss 0.780659, acc 0.578125
2020-02-08T03:10:02.452559: step 243, loss 0.866824, acc 0.671875
2020-02-08T03:10:02.570383: step 244, loss 0.795215, acc 0.578125
2020-02-08T03:10:02.689286: step 245, loss 1.17331, acc 0.5625
2020-02-08T03:10:02.804633: step 246, loss 0.615903, acc 0.765625
2020-02-08T03:10:02.922081: step 247, loss 0.78102, acc 0.59375
2020-02-08T03:10:03.036550: step 248, loss 1.18605, acc 0.53125
2020-02-08T03:10:03.151831: step 249, loss 0.713821, acc 0.65625
2020-02-08T03:10:03.266150: step 250, loss 0.810225, acc 0.65625
2020-02-08T03:10:03.381164: step 251, loss 0.949594, acc 0.59375
2020-02-08T03:10:03.496491: step 252, loss 1.06372, acc 0.625
2020-02-08T03:10:03.612648: step 253, loss 0.602641, acc 0.6875
2020-02-08T03:10:03.729349: step 254, loss 0.818525, acc 0.578125
2020-02-08T03:10:03.844110: step 255, loss 1.0698, acc 0.5
2020-02-08T03:10:03.963476: step 256, loss 0.755845, acc 0.609375
2020-02-08T03:10:04.083521: step 257, loss 0.83137, acc 0.6875
2020-02-08T03:10:04.198960: step 258, loss 0.88551, acc 0.65625
2020-02-08T03:10:04.312492: step 259, loss 1.04069, acc 0.53125
2020-02-08T03:10:04.430718: step 260, loss 0.835391, acc 0.546875
2020-02-08T03:10:04.545954: step 261, loss 0.809406, acc 0.65625
2020-02-08T03:10:04.662752: step 262, loss 0.662824, acc 0.6875
2020-02-08T03:10:04.779481: step 263, loss 0.711166, acc 0.625
2020-02-08T03:10:04.894572: step 264, loss 0.784246, acc 0.625
2020-02-08T03:10:05.009183: step 265, loss 0.898869, acc 0.578125
2020-02-08T03:10:05.124861: step 266, loss 0.865619, acc 0.46875
2020-02-08T03:10:05.241626: step 267, loss 1.07864, acc 0.578125
2020-02-08T03:10:05.358955: step 268, loss 0.983256, acc 0.5
2020-02-08T03:10:05.481729: step 269, loss 0.915021, acc 0.578125
2020-02-08T03:10:05.598871: step 270, loss 1.07824, acc 0.5625
2020-02-08T03:10:05.719737: step 271, loss 0.785071, acc 0.59375
2020-02-08T03:10:05.837414: step 272, loss 1.05631, acc 0.484375
2020-02-08T03:10:05.952698: step 273, loss 0.806561, acc 0.65625
2020-02-08T03:10:06.072115: step 274, loss 0.831988, acc 0.515625
2020-02-08T03:10:06.194087: step 275, loss 0.83852, acc 0.65625
2020-02-08T03:10:06.311384: step 276, loss 0.830238, acc 0.578125
2020-02-08T03:10:06.428599: step 277, loss 0.988563, acc 0.5
2020-02-08T03:10:06.544235: step 278, loss 0.863462, acc 0.578125
2020-02-08T03:10:06.660351: step 279, loss 0.976817, acc 0.515625
2020-02-08T03:10:06.779679: step 280, loss 0.819068, acc 0.578125
2020-02-08T03:10:06.894594: step 281, loss 0.68519, acc 0.625
2020-02-08T03:10:07.011947: step 282, loss 0.937501, acc 0.53125
2020-02-08T03:10:07.131860: step 283, loss 0.885374, acc 0.5625
2020-02-08T03:10:07.247718: step 284, loss 0.862582, acc 0.625
2020-02-08T03:10:07.365191: step 285, loss 0.694948, acc 0.640625
2020-02-08T03:10:07.481943: step 286, loss 0.887735, acc 0.515625
2020-02-08T03:10:07.595775: step 287, loss 0.721935, acc 0.625
2020-02-08T03:10:07.717086: step 288, loss 0.995669, acc 0.515625
2020-02-08T03:10:07.834199: step 289, loss 0.796454, acc 0.640625
2020-02-08T03:10:07.948923: step 290, loss 0.67194, acc 0.71875
2020-02-08T03:10:08.065262: step 291, loss 0.683796, acc 0.734375
2020-02-08T03:10:08.182788: step 292, loss 0.586248, acc 0.71875
2020-02-08T03:10:08.297961: step 293, loss 0.81165, acc 0.59375
2020-02-08T03:10:08.411446: step 294, loss 0.756903, acc 0.59375
2020-02-08T03:10:08.527880: step 295, loss 0.922356, acc 0.5625
2020-02-08T03:10:08.641990: step 296, loss 0.998413, acc 0.625
2020-02-08T03:10:08.757809: step 297, loss 0.845576, acc 0.5
2020-02-08T03:10:08.878117: step 298, loss 0.843557, acc 0.609375
2020-02-08T03:10:08.994887: step 299, loss 0.713056, acc 0.640625
2020-02-08T03:10:09.107335: step 300, loss 0.833988, acc 0.633333

Evaluation:
2020-02-08T03:10:09.294775: step 300, loss 0.669011, acc 0.625704

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-300

2020-02-08T03:10:10.755011: step 301, loss 0.75914, acc 0.609375
2020-02-08T03:10:10.871766: step 302, loss 0.69041, acc 0.625
2020-02-08T03:10:10.988170: step 303, loss 0.649209, acc 0.703125
2020-02-08T03:10:11.102890: step 304, loss 0.637685, acc 0.65625
2020-02-08T03:10:11.219804: step 305, loss 0.668949, acc 0.703125
2020-02-08T03:10:11.336877: step 306, loss 0.738621, acc 0.65625
2020-02-08T03:10:11.453458: step 307, loss 0.594395, acc 0.703125
2020-02-08T03:10:11.569725: step 308, loss 0.983287, acc 0.546875
2020-02-08T03:10:11.684770: step 309, loss 0.585188, acc 0.734375
2020-02-08T03:10:11.800300: step 310, loss 0.879595, acc 0.546875
2020-02-08T03:10:11.920642: step 311, loss 0.713618, acc 0.671875
2020-02-08T03:10:12.038593: step 312, loss 0.620592, acc 0.640625
2020-02-08T03:10:12.154668: step 313, loss 0.751082, acc 0.6875
2020-02-08T03:10:12.275338: step 314, loss 0.946075, acc 0.578125
2020-02-08T03:10:12.392476: step 315, loss 0.801339, acc 0.5625
2020-02-08T03:10:12.507702: step 316, loss 0.52377, acc 0.75
2020-02-08T03:10:12.625499: step 317, loss 0.832602, acc 0.59375
2020-02-08T03:10:12.740743: step 318, loss 0.655161, acc 0.625
2020-02-08T03:10:12.857885: step 319, loss 0.831539, acc 0.609375
2020-02-08T03:10:12.974947: step 320, loss 0.726824, acc 0.65625
2020-02-08T03:10:13.090868: step 321, loss 0.776725, acc 0.640625
2020-02-08T03:10:13.203752: step 322, loss 0.7424, acc 0.640625
2020-02-08T03:10:13.323680: step 323, loss 0.813965, acc 0.640625
2020-02-08T03:10:13.442839: step 324, loss 0.625694, acc 0.671875
2020-02-08T03:10:13.559789: step 325, loss 0.584303, acc 0.671875
2020-02-08T03:10:13.677996: step 326, loss 0.607558, acc 0.71875
2020-02-08T03:10:13.796943: step 327, loss 0.742525, acc 0.609375
2020-02-08T03:10:13.914956: step 328, loss 0.633079, acc 0.6875
2020-02-08T03:10:14.032555: step 329, loss 0.727089, acc 0.65625
2020-02-08T03:10:14.148615: step 330, loss 0.654816, acc 0.59375
2020-02-08T03:10:14.266379: step 331, loss 0.637515, acc 0.640625
2020-02-08T03:10:14.382748: step 332, loss 0.768479, acc 0.640625
2020-02-08T03:10:14.496998: step 333, loss 0.580313, acc 0.703125
2020-02-08T03:10:14.613803: step 334, loss 0.706021, acc 0.640625
2020-02-08T03:10:14.730506: step 335, loss 0.562324, acc 0.703125
2020-02-08T03:10:14.843455: step 336, loss 0.71448, acc 0.59375
2020-02-08T03:10:14.960808: step 337, loss 0.750079, acc 0.609375
2020-02-08T03:10:15.077978: step 338, loss 0.811875, acc 0.625
2020-02-08T03:10:15.192263: step 339, loss 0.689818, acc 0.609375
2020-02-08T03:10:15.307733: step 340, loss 0.608932, acc 0.671875
2020-02-08T03:10:15.425115: step 341, loss 0.668617, acc 0.71875
2020-02-08T03:10:15.542764: step 342, loss 0.579992, acc 0.734375
2020-02-08T03:10:15.659108: step 343, loss 0.609051, acc 0.75
2020-02-08T03:10:15.777363: step 344, loss 0.614179, acc 0.609375
2020-02-08T03:10:15.893544: step 345, loss 0.593011, acc 0.65625
2020-02-08T03:10:16.011404: step 346, loss 0.535591, acc 0.734375
2020-02-08T03:10:16.129252: step 347, loss 0.74456, acc 0.640625
2020-02-08T03:10:16.243919: step 348, loss 0.575815, acc 0.765625
2020-02-08T03:10:16.360586: step 349, loss 0.749287, acc 0.59375
2020-02-08T03:10:16.483179: step 350, loss 0.525695, acc 0.8125
2020-02-08T03:10:16.598651: step 351, loss 0.528688, acc 0.703125
2020-02-08T03:10:16.715373: step 352, loss 0.655005, acc 0.65625
2020-02-08T03:10:16.836623: step 353, loss 0.680526, acc 0.65625
2020-02-08T03:10:16.951634: step 354, loss 0.668396, acc 0.625
2020-02-08T03:10:17.069562: step 355, loss 0.557591, acc 0.703125
2020-02-08T03:10:17.188891: step 356, loss 0.705193, acc 0.625
2020-02-08T03:10:17.304527: step 357, loss 0.735052, acc 0.640625
2020-02-08T03:10:17.422416: step 358, loss 0.638779, acc 0.703125
2020-02-08T03:10:17.538983: step 359, loss 0.467563, acc 0.75
2020-02-08T03:10:17.653270: step 360, loss 0.597173, acc 0.75
2020-02-08T03:10:17.766596: step 361, loss 0.628856, acc 0.59375
2020-02-08T03:10:17.885218: step 362, loss 0.703763, acc 0.625
2020-02-08T03:10:18.000449: step 363, loss 0.691173, acc 0.703125
2020-02-08T03:10:18.118206: step 364, loss 0.639991, acc 0.6875
2020-02-08T03:10:18.236684: step 365, loss 0.680894, acc 0.703125
2020-02-08T03:10:18.352862: step 366, loss 0.768347, acc 0.609375
2020-02-08T03:10:18.470335: step 367, loss 0.701145, acc 0.703125
2020-02-08T03:10:18.585079: step 368, loss 0.734528, acc 0.578125
2020-02-08T03:10:18.698923: step 369, loss 0.696668, acc 0.625
2020-02-08T03:10:18.817089: step 370, loss 0.823233, acc 0.5625
2020-02-08T03:10:18.932140: step 371, loss 0.682488, acc 0.65625
2020-02-08T03:10:19.046420: step 372, loss 0.577849, acc 0.734375
2020-02-08T03:10:19.163761: step 373, loss 0.47068, acc 0.71875
2020-02-08T03:10:19.282302: step 374, loss 0.808582, acc 0.59375
2020-02-08T03:10:19.396506: step 375, loss 0.745808, acc 0.59375
2020-02-08T03:10:19.514552: step 376, loss 0.590285, acc 0.71875
2020-02-08T03:10:19.635770: step 377, loss 0.653055, acc 0.734375
2020-02-08T03:10:19.751454: step 378, loss 0.746022, acc 0.65625
2020-02-08T03:10:19.871541: step 379, loss 0.61602, acc 0.734375
2020-02-08T03:10:19.987975: step 380, loss 0.540297, acc 0.75
2020-02-08T03:10:20.103518: step 381, loss 0.798072, acc 0.578125
2020-02-08T03:10:20.222174: step 382, loss 0.480965, acc 0.75
2020-02-08T03:10:20.339108: step 383, loss 0.672458, acc 0.671875
2020-02-08T03:10:20.453916: step 384, loss 0.799361, acc 0.53125
2020-02-08T03:10:20.570808: step 385, loss 0.658691, acc 0.6875
2020-02-08T03:10:20.685385: step 386, loss 0.563351, acc 0.6875
2020-02-08T03:10:20.798638: step 387, loss 0.502321, acc 0.765625
2020-02-08T03:10:20.915614: step 388, loss 0.584821, acc 0.734375
2020-02-08T03:10:21.031589: step 389, loss 0.558653, acc 0.6875
2020-02-08T03:10:21.147823: step 390, loss 0.709526, acc 0.609375
2020-02-08T03:10:21.266616: step 391, loss 0.568505, acc 0.71875
2020-02-08T03:10:21.384682: step 392, loss 0.708918, acc 0.640625
2020-02-08T03:10:21.499112: step 393, loss 0.869178, acc 0.578125
2020-02-08T03:10:21.613818: step 394, loss 0.717587, acc 0.609375
2020-02-08T03:10:21.745716: step 395, loss 0.587399, acc 0.6875
2020-02-08T03:10:21.868783: step 396, loss 0.752033, acc 0.53125
2020-02-08T03:10:21.983955: step 397, loss 0.788551, acc 0.625
2020-02-08T03:10:22.097832: step 398, loss 0.546149, acc 0.765625
2020-02-08T03:10:22.213396: step 399, loss 0.794791, acc 0.5625
2020-02-08T03:10:22.327690: step 400, loss 0.658774, acc 0.671875

Evaluation:
2020-02-08T03:10:22.518036: step 400, loss 0.647517, acc 0.629456

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-400

2020-02-08T03:10:23.957900: step 401, loss 0.609351, acc 0.625
2020-02-08T03:10:24.075086: step 402, loss 0.477936, acc 0.796875
2020-02-08T03:10:24.195181: step 403, loss 0.55696, acc 0.78125
2020-02-08T03:10:24.309181: step 404, loss 0.537224, acc 0.703125
2020-02-08T03:10:24.428040: step 405, loss 0.565506, acc 0.78125
2020-02-08T03:10:24.543281: step 406, loss 0.538668, acc 0.734375
2020-02-08T03:10:24.659517: step 407, loss 0.656263, acc 0.609375
2020-02-08T03:10:24.777964: step 408, loss 0.749572, acc 0.546875
2020-02-08T03:10:24.895483: step 409, loss 0.63747, acc 0.703125
2020-02-08T03:10:25.013077: step 410, loss 0.594629, acc 0.6875
2020-02-08T03:10:25.130922: step 411, loss 0.739355, acc 0.609375
2020-02-08T03:10:25.247520: step 412, loss 0.74848, acc 0.640625
2020-02-08T03:10:25.365053: step 413, loss 0.710981, acc 0.640625
2020-02-08T03:10:25.482409: step 414, loss 0.689099, acc 0.75
2020-02-08T03:10:25.597090: step 415, loss 0.809066, acc 0.609375
2020-02-08T03:10:25.715173: step 416, loss 0.775707, acc 0.625
2020-02-08T03:10:25.832077: step 417, loss 0.707543, acc 0.640625
2020-02-08T03:10:25.947410: step 418, loss 0.622619, acc 0.640625
2020-02-08T03:10:26.064744: step 419, loss 0.70737, acc 0.65625
2020-02-08T03:10:26.178685: step 420, loss 0.675687, acc 0.625
2020-02-08T03:10:26.295483: step 421, loss 0.540611, acc 0.75
2020-02-08T03:10:26.411819: step 422, loss 0.515656, acc 0.765625
2020-02-08T03:10:26.528115: step 423, loss 0.524252, acc 0.671875
2020-02-08T03:10:26.646085: step 424, loss 0.606997, acc 0.734375
2020-02-08T03:10:26.764095: step 425, loss 0.554926, acc 0.71875
2020-02-08T03:10:26.879250: step 426, loss 0.460221, acc 0.734375
2020-02-08T03:10:26.997884: step 427, loss 0.792307, acc 0.5625
2020-02-08T03:10:27.112564: step 428, loss 0.662522, acc 0.640625
2020-02-08T03:10:27.229403: step 429, loss 0.593264, acc 0.6875
2020-02-08T03:10:27.343427: step 430, loss 0.610337, acc 0.65625
2020-02-08T03:10:27.460593: step 431, loss 0.725979, acc 0.640625
2020-02-08T03:10:27.576501: step 432, loss 0.793865, acc 0.6875
2020-02-08T03:10:27.691733: step 433, loss 0.752337, acc 0.609375
2020-02-08T03:10:27.810188: step 434, loss 0.535764, acc 0.71875
2020-02-08T03:10:27.926499: step 435, loss 0.60056, acc 0.65625
2020-02-08T03:10:28.043049: step 436, loss 0.57412, acc 0.71875
2020-02-08T03:10:28.158441: step 437, loss 0.617693, acc 0.671875
2020-02-08T03:10:28.276182: step 438, loss 0.674044, acc 0.65625
2020-02-08T03:10:28.392224: step 439, loss 0.700757, acc 0.6875
2020-02-08T03:10:28.507363: step 440, loss 0.753787, acc 0.609375
2020-02-08T03:10:28.626943: step 441, loss 0.632465, acc 0.625
2020-02-08T03:10:28.744220: step 442, loss 0.624998, acc 0.625
2020-02-08T03:10:28.861962: step 443, loss 0.639122, acc 0.671875
2020-02-08T03:10:28.978012: step 444, loss 0.630236, acc 0.625
2020-02-08T03:10:29.094500: step 445, loss 0.631036, acc 0.703125
2020-02-08T03:10:29.214520: step 446, loss 0.59282, acc 0.703125
2020-02-08T03:10:29.335195: step 447, loss 0.673022, acc 0.671875
2020-02-08T03:10:29.451193: step 448, loss 0.686558, acc 0.671875
2020-02-08T03:10:29.569469: step 449, loss 0.603817, acc 0.734375
2020-02-08T03:10:29.685037: step 450, loss 0.805736, acc 0.6
2020-02-08T03:10:29.801576: step 451, loss 0.672046, acc 0.625
2020-02-08T03:10:29.918480: step 452, loss 0.622172, acc 0.640625
2020-02-08T03:10:30.035401: step 453, loss 0.467667, acc 0.8125
2020-02-08T03:10:30.149420: step 454, loss 0.566202, acc 0.6875
2020-02-08T03:10:30.265305: step 455, loss 0.585705, acc 0.65625
2020-02-08T03:10:30.382661: step 456, loss 0.670686, acc 0.625
2020-02-08T03:10:30.496100: step 457, loss 0.554695, acc 0.6875
2020-02-08T03:10:30.613487: step 458, loss 0.61035, acc 0.703125
2020-02-08T03:10:30.730632: step 459, loss 0.586303, acc 0.71875
2020-02-08T03:10:30.848213: step 460, loss 0.659711, acc 0.65625
2020-02-08T03:10:30.965776: step 461, loss 0.647279, acc 0.625
2020-02-08T03:10:31.082513: step 462, loss 0.498305, acc 0.78125
2020-02-08T03:10:31.197759: step 463, loss 0.552732, acc 0.703125
2020-02-08T03:10:31.310802: step 464, loss 0.52222, acc 0.734375
2020-02-08T03:10:31.427524: step 465, loss 0.637891, acc 0.609375
2020-02-08T03:10:31.544950: step 466, loss 0.681493, acc 0.65625
2020-02-08T03:10:31.658353: step 467, loss 0.621126, acc 0.6875
2020-02-08T03:10:31.776584: step 468, loss 0.655641, acc 0.609375
2020-02-08T03:10:31.892644: step 469, loss 0.576127, acc 0.6875
2020-02-08T03:10:32.005807: step 470, loss 0.474395, acc 0.796875
2020-02-08T03:10:32.122712: step 471, loss 0.670324, acc 0.640625
2020-02-08T03:10:32.238236: step 472, loss 0.566236, acc 0.75
2020-02-08T03:10:32.351746: step 473, loss 0.693823, acc 0.609375
2020-02-08T03:10:32.470994: step 474, loss 0.606282, acc 0.671875
2020-02-08T03:10:32.589898: step 475, loss 0.556175, acc 0.65625
2020-02-08T03:10:32.704690: step 476, loss 0.63767, acc 0.71875
2020-02-08T03:10:32.821374: step 477, loss 0.605495, acc 0.6875
2020-02-08T03:10:32.937512: step 478, loss 0.582175, acc 0.671875
2020-02-08T03:10:33.055387: step 479, loss 0.500636, acc 0.703125
2020-02-08T03:10:33.170901: step 480, loss 0.558578, acc 0.75
2020-02-08T03:10:33.286997: step 481, loss 0.626101, acc 0.625
2020-02-08T03:10:33.404361: step 482, loss 0.615067, acc 0.78125
2020-02-08T03:10:33.523235: step 483, loss 0.520307, acc 0.75
2020-02-08T03:10:33.641014: step 484, loss 0.456249, acc 0.796875
2020-02-08T03:10:33.758845: step 485, loss 0.649818, acc 0.671875
2020-02-08T03:10:33.882504: step 486, loss 0.620019, acc 0.703125
2020-02-08T03:10:33.998241: step 487, loss 0.638643, acc 0.71875
2020-02-08T03:10:34.116117: step 488, loss 0.634508, acc 0.625
2020-02-08T03:10:34.236007: step 489, loss 0.636552, acc 0.6875
2020-02-08T03:10:34.351178: step 490, loss 0.503136, acc 0.734375
2020-02-08T03:10:34.467597: step 491, loss 0.473452, acc 0.765625
2020-02-08T03:10:34.584264: step 492, loss 0.691571, acc 0.671875
2020-02-08T03:10:34.701896: step 493, loss 0.657958, acc 0.734375
2020-02-08T03:10:34.820175: step 494, loss 0.560121, acc 0.75
2020-02-08T03:10:34.936136: step 495, loss 0.578161, acc 0.71875
2020-02-08T03:10:35.050337: step 496, loss 0.449456, acc 0.734375
2020-02-08T03:10:35.166174: step 497, loss 0.615889, acc 0.5625
2020-02-08T03:10:35.281787: step 498, loss 0.639634, acc 0.671875
2020-02-08T03:10:35.398642: step 499, loss 0.638589, acc 0.640625
2020-02-08T03:10:35.513541: step 500, loss 0.595061, acc 0.625

Evaluation:
2020-02-08T03:10:35.704558: step 500, loss 0.619983, acc 0.663227

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-500

2020-02-08T03:10:37.203893: step 501, loss 0.545918, acc 0.703125
2020-02-08T03:10:37.320357: step 502, loss 0.641288, acc 0.640625
2020-02-08T03:10:37.438063: step 503, loss 0.579739, acc 0.734375
2020-02-08T03:10:37.555186: step 504, loss 0.541401, acc 0.78125
2020-02-08T03:10:37.670467: step 505, loss 0.520076, acc 0.75
2020-02-08T03:10:37.787151: step 506, loss 0.519613, acc 0.75
2020-02-08T03:10:37.905144: step 507, loss 0.571796, acc 0.71875
2020-02-08T03:10:38.023331: step 508, loss 0.525672, acc 0.75
2020-02-08T03:10:38.140248: step 509, loss 0.597813, acc 0.6875
2020-02-08T03:10:38.255874: step 510, loss 0.471066, acc 0.765625
2020-02-08T03:10:38.372263: step 511, loss 0.561635, acc 0.6875
2020-02-08T03:10:38.487857: step 512, loss 0.61786, acc 0.6875
2020-02-08T03:10:38.606147: step 513, loss 0.552117, acc 0.6875
2020-02-08T03:10:38.724681: step 514, loss 0.800986, acc 0.53125
2020-02-08T03:10:38.840100: step 515, loss 0.556777, acc 0.734375
2020-02-08T03:10:38.957552: step 516, loss 0.606607, acc 0.671875
2020-02-08T03:10:39.074558: step 517, loss 0.515197, acc 0.765625
2020-02-08T03:10:39.191092: step 518, loss 0.521321, acc 0.734375
2020-02-08T03:10:39.305170: step 519, loss 0.502688, acc 0.78125
2020-02-08T03:10:39.423013: step 520, loss 0.501357, acc 0.796875
2020-02-08T03:10:39.540704: step 521, loss 0.600209, acc 0.671875
2020-02-08T03:10:39.657809: step 522, loss 0.596851, acc 0.65625
2020-02-08T03:10:39.776489: step 523, loss 0.635205, acc 0.65625
2020-02-08T03:10:39.894061: step 524, loss 0.48517, acc 0.765625
2020-02-08T03:10:40.011723: step 525, loss 0.636338, acc 0.65625
2020-02-08T03:10:40.126999: step 526, loss 0.41687, acc 0.8125
2020-02-08T03:10:40.243002: step 527, loss 0.536011, acc 0.75
2020-02-08T03:10:40.359522: step 528, loss 0.523027, acc 0.71875
2020-02-08T03:10:40.477370: step 529, loss 0.501568, acc 0.734375
2020-02-08T03:10:40.593504: step 530, loss 0.485497, acc 0.8125
2020-02-08T03:10:40.708656: step 531, loss 0.582654, acc 0.703125
2020-02-08T03:10:40.824447: step 532, loss 0.547677, acc 0.734375
2020-02-08T03:10:40.939339: step 533, loss 0.470852, acc 0.796875
2020-02-08T03:10:41.056310: step 534, loss 0.558695, acc 0.703125
2020-02-08T03:10:41.173887: step 535, loss 0.53676, acc 0.78125
2020-02-08T03:10:41.289918: step 536, loss 0.73335, acc 0.59375
2020-02-08T03:10:41.407319: step 537, loss 0.483733, acc 0.734375
2020-02-08T03:10:41.523177: step 538, loss 0.555011, acc 0.734375
2020-02-08T03:10:41.643360: step 539, loss 0.641748, acc 0.609375
2020-02-08T03:10:41.760021: step 540, loss 0.675758, acc 0.625
2020-02-08T03:10:41.876108: step 541, loss 0.516191, acc 0.75
2020-02-08T03:10:41.993379: step 542, loss 0.502275, acc 0.734375
2020-02-08T03:10:42.111393: step 543, loss 0.581086, acc 0.703125
2020-02-08T03:10:42.228451: step 544, loss 0.664241, acc 0.65625
2020-02-08T03:10:42.345928: step 545, loss 0.599036, acc 0.671875
2020-02-08T03:10:42.461069: step 546, loss 0.576376, acc 0.75
2020-02-08T03:10:42.579525: step 547, loss 0.604164, acc 0.65625
2020-02-08T03:10:42.699157: step 548, loss 0.617138, acc 0.703125
2020-02-08T03:10:42.815098: step 549, loss 0.640795, acc 0.578125
2020-02-08T03:10:42.932823: step 550, loss 0.582884, acc 0.703125
2020-02-08T03:10:43.047132: step 551, loss 0.55729, acc 0.671875
2020-02-08T03:10:43.163007: step 552, loss 0.489944, acc 0.75
2020-02-08T03:10:43.280191: step 553, loss 0.588517, acc 0.75
2020-02-08T03:10:43.397775: step 554, loss 0.500812, acc 0.765625
2020-02-08T03:10:43.514783: step 555, loss 0.635093, acc 0.671875
2020-02-08T03:10:43.632978: step 556, loss 0.574226, acc 0.71875
2020-02-08T03:10:43.747047: step 557, loss 0.487768, acc 0.796875
2020-02-08T03:10:43.864581: step 558, loss 0.594544, acc 0.71875
2020-02-08T03:10:43.980696: step 559, loss 0.451897, acc 0.828125
2020-02-08T03:10:44.097044: step 560, loss 0.693116, acc 0.625
2020-02-08T03:10:44.215120: step 561, loss 0.595916, acc 0.671875
2020-02-08T03:10:44.330871: step 562, loss 0.430363, acc 0.796875
2020-02-08T03:10:44.446328: step 563, loss 0.537335, acc 0.71875
2020-02-08T03:10:44.563249: step 564, loss 0.614225, acc 0.640625
2020-02-08T03:10:44.684629: step 565, loss 0.630036, acc 0.640625
2020-02-08T03:10:44.800071: step 566, loss 0.548733, acc 0.75
2020-02-08T03:10:44.918994: step 567, loss 0.453834, acc 0.796875
2020-02-08T03:10:45.034014: step 568, loss 0.489644, acc 0.796875
2020-02-08T03:10:45.151771: step 569, loss 0.598447, acc 0.6875
2020-02-08T03:10:45.267573: step 570, loss 0.538146, acc 0.75
2020-02-08T03:10:45.385125: step 571, loss 0.57211, acc 0.703125
2020-02-08T03:10:45.502297: step 572, loss 0.581335, acc 0.703125
2020-02-08T03:10:45.618383: step 573, loss 0.53104, acc 0.71875
2020-02-08T03:10:45.734900: step 574, loss 0.554955, acc 0.703125
2020-02-08T03:10:45.850378: step 575, loss 0.625612, acc 0.71875
2020-02-08T03:10:45.967952: step 576, loss 0.503019, acc 0.734375
2020-02-08T03:10:46.086469: step 577, loss 0.670125, acc 0.609375
2020-02-08T03:10:46.202009: step 578, loss 0.706598, acc 0.625
2020-02-08T03:10:46.318135: step 579, loss 0.563068, acc 0.75
2020-02-08T03:10:46.435052: step 580, loss 0.697757, acc 0.640625
2020-02-08T03:10:46.548855: step 581, loss 0.54771, acc 0.6875
2020-02-08T03:10:46.664354: step 582, loss 0.640002, acc 0.65625
2020-02-08T03:10:46.782003: step 583, loss 0.542798, acc 0.734375
2020-02-08T03:10:46.900382: step 584, loss 0.639757, acc 0.703125
2020-02-08T03:10:47.019705: step 585, loss 0.562001, acc 0.6875
2020-02-08T03:10:47.133883: step 586, loss 0.49474, acc 0.78125
2020-02-08T03:10:47.249362: step 587, loss 0.510508, acc 0.734375
2020-02-08T03:10:47.368622: step 588, loss 0.574507, acc 0.703125
2020-02-08T03:10:47.485412: step 589, loss 0.537315, acc 0.6875
2020-02-08T03:10:47.599653: step 590, loss 0.629209, acc 0.671875
2020-02-08T03:10:47.716685: step 591, loss 0.54683, acc 0.65625
2020-02-08T03:10:47.838479: step 592, loss 0.62814, acc 0.703125
2020-02-08T03:10:47.952577: step 593, loss 0.610436, acc 0.71875
2020-02-08T03:10:48.067740: step 594, loss 0.512464, acc 0.78125
2020-02-08T03:10:48.183082: step 595, loss 0.507198, acc 0.734375
2020-02-08T03:10:48.300213: step 596, loss 0.628224, acc 0.734375
2020-02-08T03:10:48.420290: step 597, loss 0.439846, acc 0.828125
2020-02-08T03:10:48.537455: step 598, loss 0.516951, acc 0.765625
2020-02-08T03:10:48.650721: step 599, loss 0.578077, acc 0.6875
2020-02-08T03:10:48.763697: step 600, loss 0.530536, acc 0.733333

Evaluation:
2020-02-08T03:10:48.950573: step 600, loss 0.645899, acc 0.622889

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-600

2020-02-08T03:10:50.386543: step 601, loss 0.555524, acc 0.71875
2020-02-08T03:10:50.502644: step 602, loss 0.668208, acc 0.625
2020-02-08T03:10:50.615967: step 603, loss 0.540083, acc 0.71875
2020-02-08T03:10:50.732912: step 604, loss 0.527231, acc 0.703125
2020-02-08T03:10:50.850279: step 605, loss 0.484764, acc 0.796875
2020-02-08T03:10:50.968722: step 606, loss 0.559032, acc 0.703125
2020-02-08T03:10:51.086639: step 607, loss 0.488289, acc 0.734375
2020-02-08T03:10:51.201060: step 608, loss 0.57777, acc 0.75
2020-02-08T03:10:51.316942: step 609, loss 0.530965, acc 0.734375
2020-02-08T03:10:51.621595: step 610, loss 0.575151, acc 0.796875
2020-02-08T03:10:51.747231: step 611, loss 0.483359, acc 0.6875
2020-02-08T03:10:51.865100: step 612, loss 0.435204, acc 0.796875
2020-02-08T03:10:51.981711: step 613, loss 0.564218, acc 0.765625
2020-02-08T03:10:52.097698: step 614, loss 0.665778, acc 0.65625
2020-02-08T03:10:52.216243: step 615, loss 0.575777, acc 0.703125
2020-02-08T03:10:52.332789: step 616, loss 0.435447, acc 0.84375
2020-02-08T03:10:52.446513: step 617, loss 0.625767, acc 0.671875
2020-02-08T03:10:52.562600: step 618, loss 0.387448, acc 0.8125
2020-02-08T03:10:52.681017: step 619, loss 0.434981, acc 0.796875
2020-02-08T03:10:52.799947: step 620, loss 0.595738, acc 0.765625
2020-02-08T03:10:52.917611: step 621, loss 0.506109, acc 0.6875
2020-02-08T03:10:53.036162: step 622, loss 0.557928, acc 0.71875
2020-02-08T03:10:53.151423: step 623, loss 0.461516, acc 0.84375
2020-02-08T03:10:53.272224: step 624, loss 0.589453, acc 0.6875
2020-02-08T03:10:53.388319: step 625, loss 0.499479, acc 0.703125
2020-02-08T03:10:53.504332: step 626, loss 0.617749, acc 0.6875
2020-02-08T03:10:53.622143: step 627, loss 0.358066, acc 0.875
2020-02-08T03:10:53.737339: step 628, loss 0.59328, acc 0.734375
2020-02-08T03:10:53.854254: step 629, loss 0.482992, acc 0.765625
2020-02-08T03:10:53.967551: step 630, loss 0.614866, acc 0.671875
2020-02-08T03:10:54.083871: step 631, loss 0.429994, acc 0.765625
2020-02-08T03:10:54.197812: step 632, loss 0.516249, acc 0.78125
2020-02-08T03:10:54.311672: step 633, loss 0.516633, acc 0.71875
2020-02-08T03:10:54.427758: step 634, loss 0.416744, acc 0.84375
2020-02-08T03:10:54.545033: step 635, loss 0.615677, acc 0.625
2020-02-08T03:10:54.661319: step 636, loss 0.505916, acc 0.765625
2020-02-08T03:10:54.777918: step 637, loss 0.503306, acc 0.734375
2020-02-08T03:10:54.895385: step 638, loss 0.320454, acc 0.890625
2020-02-08T03:10:55.012265: step 639, loss 0.595321, acc 0.65625
2020-02-08T03:10:55.128996: step 640, loss 0.607141, acc 0.734375
2020-02-08T03:10:55.245296: step 641, loss 0.707454, acc 0.71875
2020-02-08T03:10:55.362880: step 642, loss 0.516629, acc 0.78125
2020-02-08T03:10:55.480563: step 643, loss 0.486274, acc 0.796875
2020-02-08T03:10:55.597179: step 644, loss 0.579505, acc 0.65625
2020-02-08T03:10:55.715053: step 645, loss 0.560991, acc 0.71875
2020-02-08T03:10:55.830182: step 646, loss 0.410868, acc 0.8125
2020-02-08T03:10:55.946247: step 647, loss 0.547326, acc 0.75
2020-02-08T03:10:56.061426: step 648, loss 0.414219, acc 0.84375
2020-02-08T03:10:56.178141: step 649, loss 0.616393, acc 0.6875
2020-02-08T03:10:56.295187: step 650, loss 0.439081, acc 0.796875
2020-02-08T03:10:56.414664: step 651, loss 0.519509, acc 0.78125
2020-02-08T03:10:56.531042: step 652, loss 0.469228, acc 0.8125
2020-02-08T03:10:56.645183: step 653, loss 0.406812, acc 0.859375
2020-02-08T03:10:56.762611: step 654, loss 0.643222, acc 0.703125
2020-02-08T03:10:56.881748: step 655, loss 0.498325, acc 0.796875
2020-02-08T03:10:56.996704: step 656, loss 0.538569, acc 0.703125
2020-02-08T03:10:57.114679: step 657, loss 0.473943, acc 0.75
2020-02-08T03:10:57.231879: step 658, loss 0.495913, acc 0.78125
2020-02-08T03:10:57.349743: step 659, loss 0.408176, acc 0.859375
2020-02-08T03:10:57.465790: step 660, loss 0.546553, acc 0.765625
2020-02-08T03:10:57.583855: step 661, loss 0.571053, acc 0.71875
2020-02-08T03:10:57.700436: step 662, loss 0.302221, acc 0.921875
2020-02-08T03:10:57.815772: step 663, loss 0.605059, acc 0.6875
2020-02-08T03:10:57.933879: step 664, loss 0.529143, acc 0.71875
2020-02-08T03:10:58.050228: step 665, loss 0.560768, acc 0.703125
2020-02-08T03:10:58.166989: step 666, loss 0.461153, acc 0.796875
2020-02-08T03:10:58.283850: step 667, loss 0.584544, acc 0.6875
2020-02-08T03:10:58.400604: step 668, loss 0.499346, acc 0.765625
2020-02-08T03:10:58.515511: step 669, loss 0.527128, acc 0.78125
2020-02-08T03:10:58.632209: step 670, loss 0.492427, acc 0.734375
2020-02-08T03:10:58.745989: step 671, loss 0.541119, acc 0.71875
2020-02-08T03:10:58.861175: step 672, loss 0.479927, acc 0.765625
2020-02-08T03:10:58.976795: step 673, loss 0.41438, acc 0.859375
2020-02-08T03:10:59.090482: step 674, loss 0.540955, acc 0.75
2020-02-08T03:10:59.208598: step 675, loss 0.457923, acc 0.75
2020-02-08T03:10:59.323905: step 676, loss 0.465873, acc 0.75
2020-02-08T03:10:59.439998: step 677, loss 0.410893, acc 0.8125
2020-02-08T03:10:59.555358: step 678, loss 0.446684, acc 0.8125
2020-02-08T03:10:59.673243: step 679, loss 0.44173, acc 0.796875
2020-02-08T03:10:59.789638: step 680, loss 0.481588, acc 0.75
2020-02-08T03:10:59.906940: step 681, loss 0.526899, acc 0.78125
2020-02-08T03:11:00.024480: step 682, loss 0.486278, acc 0.765625
2020-02-08T03:11:00.140948: step 683, loss 0.536326, acc 0.71875
2020-02-08T03:11:00.259038: step 684, loss 0.531557, acc 0.703125
2020-02-08T03:11:00.376646: step 685, loss 0.399255, acc 0.78125
2020-02-08T03:11:00.495134: step 686, loss 0.563451, acc 0.75
2020-02-08T03:11:00.613335: step 687, loss 0.51317, acc 0.671875
2020-02-08T03:11:00.731180: step 688, loss 0.553328, acc 0.75
2020-02-08T03:11:00.849020: step 689, loss 0.449831, acc 0.75
2020-02-08T03:11:00.962928: step 690, loss 0.614581, acc 0.6875
2020-02-08T03:11:01.079314: step 691, loss 0.400237, acc 0.8125
2020-02-08T03:11:01.195732: step 692, loss 0.504138, acc 0.71875
2020-02-08T03:11:01.309633: step 693, loss 0.433921, acc 0.78125
2020-02-08T03:11:01.426629: step 694, loss 0.461009, acc 0.796875
2020-02-08T03:11:01.540613: step 695, loss 0.605219, acc 0.6875
2020-02-08T03:11:01.657424: step 696, loss 0.5337, acc 0.703125
2020-02-08T03:11:01.779259: step 697, loss 0.513829, acc 0.734375
2020-02-08T03:11:01.894448: step 698, loss 0.463572, acc 0.78125
2020-02-08T03:11:02.010830: step 699, loss 0.575758, acc 0.6875
2020-02-08T03:11:02.127941: step 700, loss 0.50694, acc 0.78125

Evaluation:
2020-02-08T03:11:02.316093: step 700, loss 0.615206, acc 0.672608

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-700

2020-02-08T03:11:03.917500: step 701, loss 0.548285, acc 0.71875
2020-02-08T03:11:04.035798: step 702, loss 0.505038, acc 0.703125
2020-02-08T03:11:04.151364: step 703, loss 0.663436, acc 0.671875
2020-02-08T03:11:04.269539: step 704, loss 0.641825, acc 0.75
2020-02-08T03:11:04.387139: step 705, loss 0.414522, acc 0.796875
2020-02-08T03:11:04.503083: step 706, loss 0.411066, acc 0.828125
2020-02-08T03:11:04.619020: step 707, loss 0.460685, acc 0.75
2020-02-08T03:11:04.739223: step 708, loss 0.488627, acc 0.8125
2020-02-08T03:11:04.855131: step 709, loss 0.655221, acc 0.640625
2020-02-08T03:11:04.976703: step 710, loss 0.565684, acc 0.703125
2020-02-08T03:11:05.092117: step 711, loss 0.434136, acc 0.78125
2020-02-08T03:11:05.208532: step 712, loss 0.539962, acc 0.75
2020-02-08T03:11:05.327970: step 713, loss 0.493621, acc 0.78125
2020-02-08T03:11:05.448442: step 714, loss 0.525517, acc 0.734375
2020-02-08T03:11:05.563842: step 715, loss 0.553171, acc 0.703125
2020-02-08T03:11:05.683836: step 716, loss 0.47585, acc 0.765625
2020-02-08T03:11:05.804145: step 717, loss 0.442276, acc 0.8125
2020-02-08T03:11:05.919221: step 718, loss 0.453991, acc 0.796875
2020-02-08T03:11:06.033389: step 719, loss 0.449569, acc 0.8125
2020-02-08T03:11:06.147529: step 720, loss 0.460776, acc 0.78125
2020-02-08T03:11:06.263391: step 721, loss 0.432159, acc 0.8125
2020-02-08T03:11:06.380348: step 722, loss 0.539527, acc 0.71875
2020-02-08T03:11:06.496544: step 723, loss 0.50581, acc 0.78125
2020-02-08T03:11:06.611261: step 724, loss 0.384572, acc 0.828125
2020-02-08T03:11:06.728764: step 725, loss 0.521849, acc 0.78125
2020-02-08T03:11:06.846527: step 726, loss 0.631736, acc 0.625
2020-02-08T03:11:06.963176: step 727, loss 0.480716, acc 0.796875
2020-02-08T03:11:07.081068: step 728, loss 0.411812, acc 0.8125
2020-02-08T03:11:07.198548: step 729, loss 0.613342, acc 0.640625
2020-02-08T03:11:07.314829: step 730, loss 0.463933, acc 0.796875
2020-02-08T03:11:07.430211: step 731, loss 0.488493, acc 0.734375
2020-02-08T03:11:07.544876: step 732, loss 0.486542, acc 0.8125
2020-02-08T03:11:07.659526: step 733, loss 0.489004, acc 0.8125
2020-02-08T03:11:07.775866: step 734, loss 0.462931, acc 0.765625
2020-02-08T03:11:07.891359: step 735, loss 0.564091, acc 0.71875
2020-02-08T03:11:08.007556: step 736, loss 0.49172, acc 0.75
2020-02-08T03:11:08.127870: step 737, loss 0.451988, acc 0.8125
2020-02-08T03:11:08.244607: step 738, loss 0.44177, acc 0.796875
2020-02-08T03:11:08.359910: step 739, loss 0.583912, acc 0.703125
2020-02-08T03:11:08.477596: step 740, loss 0.464527, acc 0.796875
2020-02-08T03:11:08.594775: step 741, loss 0.528411, acc 0.75
2020-02-08T03:11:08.710002: step 742, loss 0.604008, acc 0.6875
2020-02-08T03:11:08.833405: step 743, loss 0.454672, acc 0.8125
2020-02-08T03:11:08.948738: step 744, loss 0.556305, acc 0.71875
2020-02-08T03:11:09.062365: step 745, loss 0.530844, acc 0.71875
2020-02-08T03:11:09.180384: step 746, loss 0.429096, acc 0.8125
2020-02-08T03:11:09.295974: step 747, loss 0.470685, acc 0.765625
2020-02-08T03:11:09.411717: step 748, loss 0.47366, acc 0.78125
2020-02-08T03:11:09.530073: step 749, loss 0.497926, acc 0.734375
2020-02-08T03:11:09.642992: step 750, loss 0.467306, acc 0.783333
2020-02-08T03:11:09.762758: step 751, loss 0.421065, acc 0.796875
2020-02-08T03:11:09.880430: step 752, loss 0.458412, acc 0.75
2020-02-08T03:11:09.996683: step 753, loss 0.493754, acc 0.75
2020-02-08T03:11:10.113019: step 754, loss 0.461527, acc 0.75
2020-02-08T03:11:10.227982: step 755, loss 0.482459, acc 0.75
2020-02-08T03:11:10.343205: step 756, loss 0.412596, acc 0.8125
2020-02-08T03:11:10.458077: step 757, loss 0.465987, acc 0.734375
2020-02-08T03:11:10.576202: step 758, loss 0.460672, acc 0.78125
2020-02-08T03:11:10.691382: step 759, loss 0.419867, acc 0.8125
2020-02-08T03:11:10.807189: step 760, loss 0.396639, acc 0.859375
2020-02-08T03:11:10.924564: step 761, loss 0.474127, acc 0.75
2020-02-08T03:11:11.038450: step 762, loss 0.452097, acc 0.765625
2020-02-08T03:11:11.152458: step 763, loss 0.475152, acc 0.78125
2020-02-08T03:11:11.271265: step 764, loss 0.53857, acc 0.71875
2020-02-08T03:11:11.388516: step 765, loss 0.498322, acc 0.71875
2020-02-08T03:11:11.503044: step 766, loss 0.379076, acc 0.84375
2020-02-08T03:11:11.621011: step 767, loss 0.387133, acc 0.8125
2020-02-08T03:11:11.739178: step 768, loss 0.419536, acc 0.828125
2020-02-08T03:11:11.856326: step 769, loss 0.38413, acc 0.796875
2020-02-08T03:11:11.975470: step 770, loss 0.432338, acc 0.765625
2020-02-08T03:11:12.092881: step 771, loss 0.347526, acc 0.859375
2020-02-08T03:11:12.205725: step 772, loss 0.347749, acc 0.90625
2020-02-08T03:11:12.323880: step 773, loss 0.432341, acc 0.828125
2020-02-08T03:11:12.441057: step 774, loss 0.369797, acc 0.84375
2020-02-08T03:11:12.558567: step 775, loss 0.334589, acc 0.875
2020-02-08T03:11:12.675213: step 776, loss 0.461929, acc 0.75
2020-02-08T03:11:12.792044: step 777, loss 0.536571, acc 0.78125
2020-02-08T03:11:12.908796: step 778, loss 0.472832, acc 0.75
2020-02-08T03:11:13.029987: step 779, loss 0.387095, acc 0.875
2020-02-08T03:11:13.143613: step 780, loss 0.496829, acc 0.75
2020-02-08T03:11:13.260535: step 781, loss 0.490742, acc 0.8125
2020-02-08T03:11:13.375258: step 782, loss 0.284224, acc 0.890625
2020-02-08T03:11:13.490171: step 783, loss 0.480667, acc 0.734375
2020-02-08T03:11:13.605686: step 784, loss 0.357451, acc 0.828125
2020-02-08T03:11:13.724872: step 785, loss 0.478734, acc 0.8125
2020-02-08T03:11:13.841184: step 786, loss 0.466074, acc 0.75
2020-02-08T03:11:13.961618: step 787, loss 0.362166, acc 0.84375
2020-02-08T03:11:14.079811: step 788, loss 0.452276, acc 0.8125
2020-02-08T03:11:14.195632: step 789, loss 0.479824, acc 0.78125
2020-02-08T03:11:14.312291: step 790, loss 0.476913, acc 0.828125
2020-02-08T03:11:14.429778: step 791, loss 0.279267, acc 0.890625
2020-02-08T03:11:14.547745: step 792, loss 0.518704, acc 0.78125
2020-02-08T03:11:14.664459: step 793, loss 0.420065, acc 0.796875
2020-02-08T03:11:14.779732: step 794, loss 0.387183, acc 0.796875
2020-02-08T03:11:14.895398: step 795, loss 0.388274, acc 0.8125
2020-02-08T03:11:15.014377: step 796, loss 0.426454, acc 0.75
2020-02-08T03:11:15.131653: step 797, loss 0.462609, acc 0.796875
2020-02-08T03:11:15.247121: step 798, loss 0.580232, acc 0.71875
2020-02-08T03:11:15.364618: step 799, loss 0.474275, acc 0.734375
2020-02-08T03:11:15.483056: step 800, loss 0.411243, acc 0.84375

Evaluation:
2020-02-08T03:11:15.680164: step 800, loss 0.603292, acc 0.678236

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-800

2020-02-08T03:11:17.216896: step 801, loss 0.505795, acc 0.734375
2020-02-08T03:11:17.335406: step 802, loss 0.511976, acc 0.75
2020-02-08T03:11:17.451879: step 803, loss 0.509122, acc 0.71875
2020-02-08T03:11:17.566242: step 804, loss 0.501763, acc 0.78125
2020-02-08T03:11:17.685164: step 805, loss 0.460662, acc 0.796875
2020-02-08T03:11:17.798988: step 806, loss 0.391771, acc 0.78125
2020-02-08T03:11:17.915463: step 807, loss 0.354057, acc 0.84375
2020-02-08T03:11:18.031680: step 808, loss 0.426833, acc 0.78125
2020-02-08T03:11:18.147893: step 809, loss 0.495325, acc 0.828125
2020-02-08T03:11:18.265112: step 810, loss 0.507765, acc 0.765625
2020-02-08T03:11:18.382955: step 811, loss 0.516675, acc 0.734375
2020-02-08T03:11:18.497761: step 812, loss 0.464639, acc 0.75
2020-02-08T03:11:18.616962: step 813, loss 0.448012, acc 0.859375
2020-02-08T03:11:18.735837: step 814, loss 0.434079, acc 0.828125
2020-02-08T03:11:18.852112: step 815, loss 0.600843, acc 0.703125
2020-02-08T03:11:18.967514: step 816, loss 0.429833, acc 0.796875
2020-02-08T03:11:19.089096: step 817, loss 0.329395, acc 0.890625
2020-02-08T03:11:19.204713: step 818, loss 0.465919, acc 0.828125
2020-02-08T03:11:19.324704: step 819, loss 0.356633, acc 0.90625
2020-02-08T03:11:19.441980: step 820, loss 0.544819, acc 0.828125
2020-02-08T03:11:19.558783: step 821, loss 0.412457, acc 0.828125
2020-02-08T03:11:19.675623: step 822, loss 0.403738, acc 0.796875
2020-02-08T03:11:19.791347: step 823, loss 0.371266, acc 0.890625
2020-02-08T03:11:19.906407: step 824, loss 0.365614, acc 0.78125
2020-02-08T03:11:20.022137: step 825, loss 0.476083, acc 0.75
2020-02-08T03:11:20.139307: step 826, loss 0.353253, acc 0.796875
2020-02-08T03:11:20.254842: step 827, loss 0.395948, acc 0.796875
2020-02-08T03:11:20.371220: step 828, loss 0.356434, acc 0.84375
2020-02-08T03:11:20.488353: step 829, loss 0.364735, acc 0.84375
2020-02-08T03:11:20.605972: step 830, loss 0.417948, acc 0.828125
2020-02-08T03:11:20.730380: step 831, loss 0.42341, acc 0.796875
2020-02-08T03:11:20.845080: step 832, loss 0.416802, acc 0.765625
2020-02-08T03:11:20.960128: step 833, loss 0.373264, acc 0.84375
2020-02-08T03:11:21.077664: step 834, loss 0.493446, acc 0.734375
2020-02-08T03:11:21.195086: step 835, loss 0.475059, acc 0.796875
2020-02-08T03:11:21.310297: step 836, loss 0.394347, acc 0.828125
2020-02-08T03:11:21.423801: step 837, loss 0.384957, acc 0.859375
2020-02-08T03:11:21.578189: step 838, loss 0.448647, acc 0.71875
2020-02-08T03:11:21.703874: step 839, loss 0.350352, acc 0.875
2020-02-08T03:11:21.821282: step 840, loss 0.453907, acc 0.78125
2020-02-08T03:11:21.936772: step 841, loss 0.613869, acc 0.6875
2020-02-08T03:11:22.050581: step 842, loss 0.508466, acc 0.75
2020-02-08T03:11:22.167871: step 843, loss 0.452453, acc 0.8125
2020-02-08T03:11:22.285831: step 844, loss 0.375238, acc 0.90625
2020-02-08T03:11:22.402133: step 845, loss 0.494711, acc 0.78125
2020-02-08T03:11:22.516464: step 846, loss 0.350294, acc 0.859375
2020-02-08T03:11:22.632962: step 847, loss 0.418686, acc 0.796875
2020-02-08T03:11:22.748582: step 848, loss 0.288055, acc 0.90625
2020-02-08T03:11:22.867178: step 849, loss 0.496315, acc 0.75
2020-02-08T03:11:22.983369: step 850, loss 0.404369, acc 0.828125
2020-02-08T03:11:23.098196: step 851, loss 0.537365, acc 0.765625
2020-02-08T03:11:23.214990: step 852, loss 0.307216, acc 0.90625
2020-02-08T03:11:23.334278: step 853, loss 0.426229, acc 0.828125
2020-02-08T03:11:23.453081: step 854, loss 0.518546, acc 0.734375
2020-02-08T03:11:23.572113: step 855, loss 0.439322, acc 0.8125
2020-02-08T03:11:23.691985: step 856, loss 0.629689, acc 0.671875
2020-02-08T03:11:23.811622: step 857, loss 0.314883, acc 0.859375
2020-02-08T03:11:23.929298: step 858, loss 0.452972, acc 0.765625
2020-02-08T03:11:24.043415: step 859, loss 0.547013, acc 0.78125
2020-02-08T03:11:24.159178: step 860, loss 0.425675, acc 0.859375
2020-02-08T03:11:24.276078: step 861, loss 0.439541, acc 0.796875
2020-02-08T03:11:24.391373: step 862, loss 0.489838, acc 0.75
2020-02-08T03:11:24.509019: step 863, loss 0.422102, acc 0.765625
2020-02-08T03:11:24.625953: step 864, loss 0.551882, acc 0.71875
2020-02-08T03:11:24.741171: step 865, loss 0.491274, acc 0.71875
2020-02-08T03:11:24.854891: step 866, loss 0.339367, acc 0.8125
2020-02-08T03:11:24.974009: step 867, loss 0.386158, acc 0.8125
2020-02-08T03:11:25.089463: step 868, loss 0.456972, acc 0.734375
2020-02-08T03:11:25.202841: step 869, loss 0.296785, acc 0.890625
2020-02-08T03:11:25.324663: step 870, loss 0.476815, acc 0.75
2020-02-08T03:11:25.441883: step 871, loss 0.544549, acc 0.828125
2020-02-08T03:11:25.559267: step 872, loss 0.383919, acc 0.828125
2020-02-08T03:11:25.678890: step 873, loss 0.390796, acc 0.84375
2020-02-08T03:11:25.795132: step 874, loss 0.58037, acc 0.78125
2020-02-08T03:11:25.911253: step 875, loss 0.45946, acc 0.734375
2020-02-08T03:11:26.029324: step 876, loss 0.368559, acc 0.84375
2020-02-08T03:11:26.145152: step 877, loss 0.417289, acc 0.84375
2020-02-08T03:11:26.261109: step 878, loss 0.429595, acc 0.78125
2020-02-08T03:11:26.378147: step 879, loss 0.606434, acc 0.71875
2020-02-08T03:11:26.494916: step 880, loss 0.442248, acc 0.765625
2020-02-08T03:11:26.616399: step 881, loss 0.469571, acc 0.796875
2020-02-08T03:11:26.741487: step 882, loss 0.372025, acc 0.8125
2020-02-08T03:11:26.880295: step 883, loss 0.477126, acc 0.75
2020-02-08T03:11:27.004046: step 884, loss 0.416522, acc 0.828125
2020-02-08T03:11:27.129722: step 885, loss 0.54536, acc 0.765625
2020-02-08T03:11:27.250323: step 886, loss 0.569683, acc 0.703125
2020-02-08T03:11:27.364894: step 887, loss 0.571995, acc 0.75
2020-02-08T03:11:27.483306: step 888, loss 0.563029, acc 0.71875
2020-02-08T03:11:27.597830: step 889, loss 0.359116, acc 0.84375
2020-02-08T03:11:27.713429: step 890, loss 0.251632, acc 0.9375
2020-02-08T03:11:27.834149: step 891, loss 0.494194, acc 0.78125
2020-02-08T03:11:27.951783: step 892, loss 0.538327, acc 0.6875
2020-02-08T03:11:28.067677: step 893, loss 0.559341, acc 0.734375
2020-02-08T03:11:28.184102: step 894, loss 0.508032, acc 0.703125
2020-02-08T03:11:28.298684: step 895, loss 0.343267, acc 0.875
2020-02-08T03:11:28.416589: step 896, loss 0.354341, acc 0.875
2020-02-08T03:11:28.533791: step 897, loss 0.445135, acc 0.765625
2020-02-08T03:11:28.649048: step 898, loss 0.290319, acc 0.875
2020-02-08T03:11:28.767515: step 899, loss 0.425817, acc 0.78125
2020-02-08T03:11:28.880066: step 900, loss 0.500058, acc 0.683333

Evaluation:
2020-02-08T03:11:29.071963: step 900, loss 0.592162, acc 0.682927

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-900

2020-02-08T03:11:30.563189: step 901, loss 0.320336, acc 0.875
2020-02-08T03:11:30.677893: step 902, loss 0.2816, acc 0.875
2020-02-08T03:11:30.794145: step 903, loss 0.306282, acc 0.859375
2020-02-08T03:11:30.910286: step 904, loss 0.351281, acc 0.859375
2020-02-08T03:11:31.029444: step 905, loss 0.376302, acc 0.8125
2020-02-08T03:11:31.143993: step 906, loss 0.299583, acc 0.875
2020-02-08T03:11:31.257777: step 907, loss 0.369393, acc 0.84375
2020-02-08T03:11:31.374659: step 908, loss 0.274052, acc 0.875
2020-02-08T03:11:31.491344: step 909, loss 0.461538, acc 0.78125
2020-02-08T03:11:31.603299: step 910, loss 0.436475, acc 0.78125
2020-02-08T03:11:31.719698: step 911, loss 0.353812, acc 0.859375
2020-02-08T03:11:31.836331: step 912, loss 0.393364, acc 0.8125
2020-02-08T03:11:31.953114: step 913, loss 0.381665, acc 0.8125
2020-02-08T03:11:32.071764: step 914, loss 0.462257, acc 0.796875
2020-02-08T03:11:32.189552: step 915, loss 0.343085, acc 0.8125
2020-02-08T03:11:32.308797: step 916, loss 0.43092, acc 0.796875
2020-02-08T03:11:32.425357: step 917, loss 0.378673, acc 0.828125
2020-02-08T03:11:32.540879: step 918, loss 0.328334, acc 0.859375
2020-02-08T03:11:32.654760: step 919, loss 0.315709, acc 0.828125
2020-02-08T03:11:32.770294: step 920, loss 0.31673, acc 0.875
2020-02-08T03:11:32.886696: step 921, loss 0.442819, acc 0.8125
2020-02-08T03:11:33.002004: step 922, loss 0.329885, acc 0.859375
2020-02-08T03:11:33.120400: step 923, loss 0.389566, acc 0.828125
2020-02-08T03:11:33.235664: step 924, loss 0.299327, acc 0.890625
2020-02-08T03:11:33.352310: step 925, loss 0.390388, acc 0.8125
2020-02-08T03:11:33.470085: step 926, loss 0.291626, acc 0.890625
2020-02-08T03:11:33.585424: step 927, loss 0.481848, acc 0.75
2020-02-08T03:11:33.701279: step 928, loss 0.376783, acc 0.8125
2020-02-08T03:11:33.816581: step 929, loss 0.193601, acc 0.953125
2020-02-08T03:11:33.933526: step 930, loss 0.302898, acc 0.90625
2020-02-08T03:11:34.048386: step 931, loss 0.344363, acc 0.890625
2020-02-08T03:11:34.163727: step 932, loss 0.373065, acc 0.859375
2020-02-08T03:11:34.280505: step 933, loss 0.33772, acc 0.890625
2020-02-08T03:11:34.396163: step 934, loss 0.311219, acc 0.890625
2020-02-08T03:11:34.511065: step 935, loss 0.303054, acc 0.84375
2020-02-08T03:11:34.626182: step 936, loss 0.440729, acc 0.828125
2020-02-08T03:11:34.744354: step 937, loss 0.335523, acc 0.84375
2020-02-08T03:11:34.858536: step 938, loss 0.485897, acc 0.765625
2020-02-08T03:11:34.977020: step 939, loss 0.351416, acc 0.890625
2020-02-08T03:11:35.093094: step 940, loss 0.307016, acc 0.890625
2020-02-08T03:11:35.209644: step 941, loss 0.402661, acc 0.828125
2020-02-08T03:11:35.328517: step 942, loss 0.361203, acc 0.84375
2020-02-08T03:11:35.443220: step 943, loss 0.374449, acc 0.859375
2020-02-08T03:11:35.561374: step 944, loss 0.415031, acc 0.796875
2020-02-08T03:11:35.681078: step 945, loss 0.352547, acc 0.859375
2020-02-08T03:11:35.799071: step 946, loss 0.404896, acc 0.796875
2020-02-08T03:11:35.915811: step 947, loss 0.257885, acc 0.90625
2020-02-08T03:11:36.032567: step 948, loss 0.363194, acc 0.875
2020-02-08T03:11:36.147624: step 949, loss 0.356422, acc 0.828125
2020-02-08T03:11:36.263653: step 950, loss 0.323456, acc 0.859375
2020-02-08T03:11:36.384853: step 951, loss 0.389932, acc 0.765625
2020-02-08T03:11:36.501348: step 952, loss 0.351372, acc 0.859375
2020-02-08T03:11:36.621051: step 953, loss 0.400905, acc 0.828125
2020-02-08T03:11:36.740589: step 954, loss 0.366032, acc 0.875
2020-02-08T03:11:36.854857: step 955, loss 0.364264, acc 0.84375
2020-02-08T03:11:36.973884: step 956, loss 0.54544, acc 0.765625
2020-02-08T03:11:37.091130: step 957, loss 0.346132, acc 0.828125
2020-02-08T03:11:37.205595: step 958, loss 0.351608, acc 0.84375
2020-02-08T03:11:37.322183: step 959, loss 0.593675, acc 0.734375
2020-02-08T03:11:37.435819: step 960, loss 0.380696, acc 0.78125
2020-02-08T03:11:37.550846: step 961, loss 0.35856, acc 0.8125
2020-02-08T03:11:37.669683: step 962, loss 0.324932, acc 0.828125
2020-02-08T03:11:37.788379: step 963, loss 0.371265, acc 0.8125
2020-02-08T03:11:37.904767: step 964, loss 0.31391, acc 0.859375
2020-02-08T03:11:38.026187: step 965, loss 0.328376, acc 0.890625
2020-02-08T03:11:38.140181: step 966, loss 0.418997, acc 0.796875
2020-02-08T03:11:38.256617: step 967, loss 0.454379, acc 0.78125
2020-02-08T03:11:38.375984: step 968, loss 0.402275, acc 0.828125
2020-02-08T03:11:38.493636: step 969, loss 0.371462, acc 0.828125
2020-02-08T03:11:38.606627: step 970, loss 0.35941, acc 0.828125
2020-02-08T03:11:38.726287: step 971, loss 0.468886, acc 0.8125
2020-02-08T03:11:38.842973: step 972, loss 0.36485, acc 0.828125
2020-02-08T03:11:38.956836: step 973, loss 0.444088, acc 0.765625
2020-02-08T03:11:39.075795: step 974, loss 0.384422, acc 0.796875
2020-02-08T03:11:39.190987: step 975, loss 0.368385, acc 0.84375
2020-02-08T03:11:39.308361: step 976, loss 0.236624, acc 0.90625
2020-02-08T03:11:39.426525: step 977, loss 0.230075, acc 0.90625
2020-02-08T03:11:39.542074: step 978, loss 0.330514, acc 0.890625
2020-02-08T03:11:39.658083: step 979, loss 0.371186, acc 0.859375
2020-02-08T03:11:39.775741: step 980, loss 0.413658, acc 0.8125
2020-02-08T03:11:39.893218: step 981, loss 0.341674, acc 0.84375
2020-02-08T03:11:40.008925: step 982, loss 0.384987, acc 0.828125
2020-02-08T03:11:40.125885: step 983, loss 0.407364, acc 0.8125
2020-02-08T03:11:40.243633: step 984, loss 0.29603, acc 0.890625
2020-02-08T03:11:40.358603: step 985, loss 0.306583, acc 0.84375
2020-02-08T03:11:40.475090: step 986, loss 0.362801, acc 0.828125
2020-02-08T03:11:40.592780: step 987, loss 0.30257, acc 0.875
2020-02-08T03:11:40.705941: step 988, loss 0.570406, acc 0.703125
2020-02-08T03:11:40.823925: step 989, loss 0.305929, acc 0.875
2020-02-08T03:11:40.939140: step 990, loss 0.32103, acc 0.84375
2020-02-08T03:11:41.054730: step 991, loss 0.379549, acc 0.796875
2020-02-08T03:11:41.171167: step 992, loss 0.383377, acc 0.828125
2020-02-08T03:11:41.287165: step 993, loss 0.380113, acc 0.828125
2020-02-08T03:11:41.401528: step 994, loss 0.358413, acc 0.8125
2020-02-08T03:11:41.520269: step 995, loss 0.342361, acc 0.859375
2020-02-08T03:11:41.636136: step 996, loss 0.338282, acc 0.8125
2020-02-08T03:11:41.752895: step 997, loss 0.338762, acc 0.8125
2020-02-08T03:11:41.870915: step 998, loss 0.445271, acc 0.75
2020-02-08T03:11:41.990573: step 999, loss 0.348862, acc 0.875
2020-02-08T03:11:42.108122: step 1000, loss 0.443366, acc 0.734375

Evaluation:
2020-02-08T03:11:42.293614: step 1000, loss 0.595415, acc 0.706379

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1000

2020-02-08T03:11:43.789461: step 1001, loss 0.279404, acc 0.859375
2020-02-08T03:11:43.907815: step 1002, loss 0.31494, acc 0.84375
2020-02-08T03:11:44.025386: step 1003, loss 0.476904, acc 0.765625
2020-02-08T03:11:44.142346: step 1004, loss 0.373612, acc 0.859375
2020-02-08T03:11:44.259346: step 1005, loss 0.406202, acc 0.828125
2020-02-08T03:11:44.374244: step 1006, loss 0.351349, acc 0.84375
2020-02-08T03:11:44.487869: step 1007, loss 0.399792, acc 0.84375
2020-02-08T03:11:44.605665: step 1008, loss 0.334147, acc 0.890625
2020-02-08T03:11:44.725270: step 1009, loss 0.357518, acc 0.890625
2020-02-08T03:11:44.843436: step 1010, loss 0.347262, acc 0.875
2020-02-08T03:11:44.958748: step 1011, loss 0.198515, acc 0.96875
2020-02-08T03:11:45.075866: step 1012, loss 0.323141, acc 0.8125
2020-02-08T03:11:45.192024: step 1013, loss 0.391682, acc 0.859375
2020-02-08T03:11:45.309530: step 1014, loss 0.326201, acc 0.8125
2020-02-08T03:11:45.425540: step 1015, loss 0.455349, acc 0.78125
2020-02-08T03:11:45.540919: step 1016, loss 0.393953, acc 0.828125
2020-02-08T03:11:45.653428: step 1017, loss 0.408303, acc 0.8125
2020-02-08T03:11:45.770459: step 1018, loss 0.425439, acc 0.796875
2020-02-08T03:11:45.888635: step 1019, loss 0.277931, acc 0.859375
2020-02-08T03:11:46.004029: step 1020, loss 0.398223, acc 0.8125
2020-02-08T03:11:46.120049: step 1021, loss 0.474302, acc 0.75
2020-02-08T03:11:46.238090: step 1022, loss 0.383718, acc 0.796875
2020-02-08T03:11:46.353315: step 1023, loss 0.453685, acc 0.8125
2020-02-08T03:11:46.471064: step 1024, loss 0.348708, acc 0.859375
2020-02-08T03:11:46.586630: step 1025, loss 0.415883, acc 0.796875
2020-02-08T03:11:46.703457: step 1026, loss 0.429866, acc 0.828125
2020-02-08T03:11:46.820678: step 1027, loss 0.401459, acc 0.84375
2020-02-08T03:11:46.934313: step 1028, loss 0.452822, acc 0.796875
2020-02-08T03:11:47.050485: step 1029, loss 0.371739, acc 0.796875
2020-02-08T03:11:47.166779: step 1030, loss 0.347302, acc 0.84375
2020-02-08T03:11:47.284063: step 1031, loss 0.341869, acc 0.84375
2020-02-08T03:11:47.399100: step 1032, loss 0.346585, acc 0.875
2020-02-08T03:11:47.513554: step 1033, loss 0.395931, acc 0.828125
2020-02-08T03:11:47.629559: step 1034, loss 0.416911, acc 0.828125
2020-02-08T03:11:47.746487: step 1035, loss 0.335177, acc 0.828125
2020-02-08T03:11:47.865517: step 1036, loss 0.355115, acc 0.828125
2020-02-08T03:11:47.982140: step 1037, loss 0.377868, acc 0.828125
2020-02-08T03:11:48.098105: step 1038, loss 0.317915, acc 0.875
2020-02-08T03:11:48.214186: step 1039, loss 0.403656, acc 0.859375
2020-02-08T03:11:48.333449: step 1040, loss 0.459363, acc 0.78125
2020-02-08T03:11:48.450551: step 1041, loss 0.344953, acc 0.859375
2020-02-08T03:11:48.567717: step 1042, loss 0.427373, acc 0.78125
2020-02-08T03:11:48.686127: step 1043, loss 0.381979, acc 0.84375
2020-02-08T03:11:48.801215: step 1044, loss 0.583871, acc 0.71875
2020-02-08T03:11:48.916819: step 1045, loss 0.435397, acc 0.765625
2020-02-08T03:11:49.033914: step 1046, loss 0.39768, acc 0.8125
2020-02-08T03:11:49.149132: step 1047, loss 0.451372, acc 0.734375
2020-02-08T03:11:49.265098: step 1048, loss 0.409923, acc 0.8125
2020-02-08T03:11:49.383546: step 1049, loss 0.230469, acc 0.921875
2020-02-08T03:11:49.495052: step 1050, loss 0.456156, acc 0.783333
2020-02-08T03:11:49.614162: step 1051, loss 0.304513, acc 0.921875
2020-02-08T03:11:49.730902: step 1052, loss 0.28317, acc 0.921875
2020-02-08T03:11:49.844443: step 1053, loss 0.384261, acc 0.859375
2020-02-08T03:11:49.966029: step 1054, loss 0.356442, acc 0.875
2020-02-08T03:11:50.081306: step 1055, loss 0.375326, acc 0.8125
2020-02-08T03:11:50.199070: step 1056, loss 0.333534, acc 0.859375
2020-02-08T03:11:50.316079: step 1057, loss 0.324357, acc 0.828125
2020-02-08T03:11:50.431901: step 1058, loss 0.310468, acc 0.859375
2020-02-08T03:11:50.547765: step 1059, loss 0.26182, acc 0.875
2020-02-08T03:11:50.665005: step 1060, loss 0.231377, acc 0.90625
2020-02-08T03:11:50.780312: step 1061, loss 0.298197, acc 0.875
2020-02-08T03:11:50.898728: step 1062, loss 0.344122, acc 0.796875
2020-02-08T03:11:51.012766: step 1063, loss 0.358248, acc 0.90625
2020-02-08T03:11:51.129261: step 1064, loss 0.312746, acc 0.859375
2020-02-08T03:11:51.245505: step 1065, loss 0.29526, acc 0.875
2020-02-08T03:11:51.362670: step 1066, loss 0.278899, acc 0.890625
2020-02-08T03:11:51.477712: step 1067, loss 0.365992, acc 0.796875
2020-02-08T03:11:51.719504: step 1068, loss 0.302615, acc 0.9375
2020-02-08T03:11:51.849451: step 1069, loss 0.362668, acc 0.875
2020-02-08T03:11:51.966043: step 1070, loss 0.263488, acc 0.890625
2020-02-08T03:11:52.083624: step 1071, loss 0.247508, acc 0.953125
2020-02-08T03:11:52.199712: step 1072, loss 0.29822, acc 0.890625
2020-02-08T03:11:52.317311: step 1073, loss 0.245721, acc 0.90625
2020-02-08T03:11:52.433145: step 1074, loss 0.368024, acc 0.796875
2020-02-08T03:11:52.548389: step 1075, loss 0.279586, acc 0.875
2020-02-08T03:11:52.665260: step 1076, loss 0.368851, acc 0.796875
2020-02-08T03:11:52.785293: step 1077, loss 0.377492, acc 0.796875
2020-02-08T03:11:52.901143: step 1078, loss 0.271375, acc 0.875
2020-02-08T03:11:53.018388: step 1079, loss 0.187176, acc 0.9375
2020-02-08T03:11:53.136940: step 1080, loss 0.401018, acc 0.828125
2020-02-08T03:11:53.254648: step 1081, loss 0.258947, acc 0.9375
2020-02-08T03:11:53.373208: step 1082, loss 0.237955, acc 0.90625
2020-02-08T03:11:53.490358: step 1083, loss 0.3438, acc 0.84375
2020-02-08T03:11:53.607111: step 1084, loss 0.378269, acc 0.796875
2020-02-08T03:11:53.725763: step 1085, loss 0.419068, acc 0.796875
2020-02-08T03:11:53.846957: step 1086, loss 0.311954, acc 0.859375
2020-02-08T03:11:53.963532: step 1087, loss 0.367025, acc 0.859375
2020-02-08T03:11:54.081405: step 1088, loss 0.269741, acc 0.90625
2020-02-08T03:11:54.199431: step 1089, loss 0.21427, acc 0.9375
2020-02-08T03:11:54.314204: step 1090, loss 0.265531, acc 0.890625
2020-02-08T03:11:54.433701: step 1091, loss 0.340496, acc 0.859375
2020-02-08T03:11:54.549658: step 1092, loss 0.320106, acc 0.84375
2020-02-08T03:11:54.668347: step 1093, loss 0.201861, acc 0.90625
2020-02-08T03:11:54.783281: step 1094, loss 0.302508, acc 0.859375
2020-02-08T03:11:54.899485: step 1095, loss 0.392865, acc 0.8125
2020-02-08T03:11:55.015720: step 1096, loss 0.340316, acc 0.859375
2020-02-08T03:11:55.132502: step 1097, loss 0.217723, acc 0.921875
2020-02-08T03:11:55.246766: step 1098, loss 0.260272, acc 0.90625
2020-02-08T03:11:55.362287: step 1099, loss 0.23382, acc 0.90625
2020-02-08T03:11:55.479962: step 1100, loss 0.316117, acc 0.84375

Evaluation:
2020-02-08T03:11:55.668152: step 1100, loss 0.585657, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1100

2020-02-08T03:11:57.436892: step 1101, loss 0.320351, acc 0.875
2020-02-08T03:11:57.552790: step 1102, loss 0.352419, acc 0.859375
2020-02-08T03:11:57.667126: step 1103, loss 0.236331, acc 0.90625
2020-02-08T03:11:57.784115: step 1104, loss 0.264375, acc 0.875
2020-02-08T03:11:57.899447: step 1105, loss 0.271749, acc 0.875
2020-02-08T03:11:58.016111: step 1106, loss 0.232344, acc 0.90625
2020-02-08T03:11:58.140183: step 1107, loss 0.422678, acc 0.84375
2020-02-08T03:11:58.258132: step 1108, loss 0.338015, acc 0.859375
2020-02-08T03:11:58.416013: step 1109, loss 0.284116, acc 0.859375
2020-02-08T03:11:58.567155: step 1110, loss 0.286299, acc 0.890625
2020-02-08T03:11:58.698243: step 1111, loss 0.305504, acc 0.859375
2020-02-08T03:11:58.830979: step 1112, loss 0.263167, acc 0.921875
2020-02-08T03:11:58.961725: step 1113, loss 0.324488, acc 0.875
2020-02-08T03:11:59.101186: step 1114, loss 0.30985, acc 0.859375
2020-02-08T03:11:59.234334: step 1115, loss 0.335896, acc 0.8125
2020-02-08T03:11:59.367570: step 1116, loss 0.262216, acc 0.890625
2020-02-08T03:11:59.501195: step 1117, loss 0.349386, acc 0.796875
2020-02-08T03:11:59.634094: step 1118, loss 0.344974, acc 0.828125
2020-02-08T03:11:59.769763: step 1119, loss 0.299559, acc 0.859375
2020-02-08T03:11:59.899278: step 1120, loss 0.345348, acc 0.78125
2020-02-08T03:12:00.035968: step 1121, loss 0.27691, acc 0.859375
2020-02-08T03:12:00.157385: step 1122, loss 0.232133, acc 0.9375
2020-02-08T03:12:00.286551: step 1123, loss 0.199525, acc 0.953125
2020-02-08T03:12:00.416676: step 1124, loss 0.28088, acc 0.890625
2020-02-08T03:12:00.547178: step 1125, loss 0.241092, acc 0.921875
2020-02-08T03:12:00.677811: step 1126, loss 0.329364, acc 0.859375
2020-02-08T03:12:00.808663: step 1127, loss 0.338735, acc 0.828125
2020-02-08T03:12:00.941222: step 1128, loss 0.345189, acc 0.875
2020-02-08T03:12:01.075877: step 1129, loss 0.280791, acc 0.875
2020-02-08T03:12:01.204881: step 1130, loss 0.306462, acc 0.859375
2020-02-08T03:12:01.335723: step 1131, loss 0.307243, acc 0.890625
2020-02-08T03:12:01.465640: step 1132, loss 0.391843, acc 0.765625
2020-02-08T03:12:01.605169: step 1133, loss 0.197573, acc 0.9375
2020-02-08T03:12:01.741899: step 1134, loss 0.218556, acc 0.921875
2020-02-08T03:12:01.882205: step 1135, loss 0.26853, acc 0.875
2020-02-08T03:12:02.036318: step 1136, loss 0.327226, acc 0.84375
2020-02-08T03:12:02.187826: step 1137, loss 0.241296, acc 0.921875
2020-02-08T03:12:02.316165: step 1138, loss 0.344181, acc 0.796875
2020-02-08T03:12:02.449263: step 1139, loss 0.295602, acc 0.90625
2020-02-08T03:12:02.592417: step 1140, loss 0.263677, acc 0.890625
2020-02-08T03:12:02.734888: step 1141, loss 0.250457, acc 0.921875
2020-02-08T03:12:02.874870: step 1142, loss 0.357956, acc 0.875
2020-02-08T03:12:03.009247: step 1143, loss 0.294545, acc 0.875
2020-02-08T03:12:03.143294: step 1144, loss 0.280612, acc 0.84375
2020-02-08T03:12:03.281568: step 1145, loss 0.27741, acc 0.890625
2020-02-08T03:12:03.419635: step 1146, loss 0.22369, acc 0.90625
2020-02-08T03:12:03.553752: step 1147, loss 0.242504, acc 0.890625
2020-02-08T03:12:03.688157: step 1148, loss 0.407495, acc 0.796875
2020-02-08T03:12:03.822065: step 1149, loss 0.434548, acc 0.828125
2020-02-08T03:12:03.965734: step 1150, loss 0.347579, acc 0.84375
2020-02-08T03:12:04.114668: step 1151, loss 0.335322, acc 0.84375
2020-02-08T03:12:04.253698: step 1152, loss 0.300183, acc 0.859375
2020-02-08T03:12:04.390394: step 1153, loss 0.322649, acc 0.84375
2020-02-08T03:12:04.533952: step 1154, loss 0.242363, acc 0.90625
2020-02-08T03:12:04.672945: step 1155, loss 0.369424, acc 0.859375
2020-02-08T03:12:04.812750: step 1156, loss 0.253647, acc 0.859375
2020-02-08T03:12:04.951769: step 1157, loss 0.298522, acc 0.859375
2020-02-08T03:12:05.090881: step 1158, loss 0.381526, acc 0.859375
2020-02-08T03:12:05.229672: step 1159, loss 0.246079, acc 0.921875
2020-02-08T03:12:05.365020: step 1160, loss 0.352768, acc 0.890625
2020-02-08T03:12:05.500076: step 1161, loss 0.269195, acc 0.890625
2020-02-08T03:12:05.640801: step 1162, loss 0.292488, acc 0.890625
2020-02-08T03:12:05.768280: step 1163, loss 0.357915, acc 0.859375
2020-02-08T03:12:05.906751: step 1164, loss 0.310944, acc 0.859375
2020-02-08T03:12:06.030192: step 1165, loss 0.288859, acc 0.890625
2020-02-08T03:12:06.157607: step 1166, loss 0.263079, acc 0.875
2020-02-08T03:12:06.282716: step 1167, loss 0.332722, acc 0.875
2020-02-08T03:12:06.404069: step 1168, loss 0.288139, acc 0.875
2020-02-08T03:12:06.530455: step 1169, loss 0.325431, acc 0.84375
2020-02-08T03:12:06.654841: step 1170, loss 0.40016, acc 0.828125
2020-02-08T03:12:06.780700: step 1171, loss 0.240919, acc 0.921875
2020-02-08T03:12:06.908748: step 1172, loss 0.325504, acc 0.875
2020-02-08T03:12:07.031149: step 1173, loss 0.363985, acc 0.78125
2020-02-08T03:12:07.155678: step 1174, loss 0.26475, acc 0.875
2020-02-08T03:12:07.280505: step 1175, loss 0.314199, acc 0.859375
2020-02-08T03:12:07.406288: step 1176, loss 0.282689, acc 0.84375
2020-02-08T03:12:07.532384: step 1177, loss 0.348987, acc 0.8125
2020-02-08T03:12:07.657550: step 1178, loss 0.340075, acc 0.84375
2020-02-08T03:12:07.777497: step 1179, loss 0.300402, acc 0.828125
2020-02-08T03:12:07.896661: step 1180, loss 0.326593, acc 0.875
2020-02-08T03:12:08.021937: step 1181, loss 0.327673, acc 0.8125
2020-02-08T03:12:08.140651: step 1182, loss 0.36704, acc 0.8125
2020-02-08T03:12:08.259891: step 1183, loss 0.430409, acc 0.828125
2020-02-08T03:12:08.375104: step 1184, loss 0.310907, acc 0.828125
2020-02-08T03:12:08.494437: step 1185, loss 0.269871, acc 0.875
2020-02-08T03:12:08.614683: step 1186, loss 0.264428, acc 0.890625
2020-02-08T03:12:08.737977: step 1187, loss 0.215698, acc 0.921875
2020-02-08T03:12:08.854516: step 1188, loss 0.199173, acc 0.921875
2020-02-08T03:12:08.976341: step 1189, loss 0.476335, acc 0.796875
2020-02-08T03:12:09.097576: step 1190, loss 0.252155, acc 0.890625
2020-02-08T03:12:09.216218: step 1191, loss 0.337197, acc 0.84375
2020-02-08T03:12:09.346347: step 1192, loss 0.411857, acc 0.796875
2020-02-08T03:12:09.472441: step 1193, loss 0.221416, acc 0.890625
2020-02-08T03:12:09.598421: step 1194, loss 0.375061, acc 0.8125
2020-02-08T03:12:09.719152: step 1195, loss 0.366522, acc 0.84375
2020-02-08T03:12:09.837329: step 1196, loss 0.306712, acc 0.84375
2020-02-08T03:12:09.959587: step 1197, loss 0.37051, acc 0.828125
2020-02-08T03:12:10.080212: step 1198, loss 0.405219, acc 0.859375
2020-02-08T03:12:10.196853: step 1199, loss 0.320492, acc 0.875
2020-02-08T03:12:10.310054: step 1200, loss 0.245424, acc 0.9

Evaluation:
2020-02-08T03:12:10.499443: step 1200, loss 0.581321, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1200

2020-02-08T03:12:12.002429: step 1201, loss 0.205597, acc 0.890625
2020-02-08T03:12:12.122152: step 1202, loss 0.222535, acc 0.90625
2020-02-08T03:12:12.240301: step 1203, loss 0.207935, acc 0.9375
2020-02-08T03:12:12.354233: step 1204, loss 0.234856, acc 0.9375
2020-02-08T03:12:12.472884: step 1205, loss 0.172943, acc 0.953125
2020-02-08T03:12:12.588848: step 1206, loss 0.289947, acc 0.875
2020-02-08T03:12:12.703901: step 1207, loss 0.197519, acc 0.90625
2020-02-08T03:12:12.822879: step 1208, loss 0.254714, acc 0.90625
2020-02-08T03:12:12.943656: step 1209, loss 0.166596, acc 0.9375
2020-02-08T03:12:13.061823: step 1210, loss 0.371976, acc 0.890625
2020-02-08T03:12:13.179175: step 1211, loss 0.266415, acc 0.921875
2020-02-08T03:12:13.295025: step 1212, loss 0.223503, acc 0.90625
2020-02-08T03:12:13.411621: step 1213, loss 0.160904, acc 0.9375
2020-02-08T03:12:13.527966: step 1214, loss 0.201825, acc 0.890625
2020-02-08T03:12:13.643418: step 1215, loss 0.271135, acc 0.875
2020-02-08T03:12:13.761709: step 1216, loss 0.244995, acc 0.890625
2020-02-08T03:12:13.883721: step 1217, loss 0.300242, acc 0.890625
2020-02-08T03:12:14.000701: step 1218, loss 0.2664, acc 0.90625
2020-02-08T03:12:14.119447: step 1219, loss 0.368808, acc 0.84375
2020-02-08T03:12:14.238236: step 1220, loss 0.196006, acc 0.9375
2020-02-08T03:12:14.354362: step 1221, loss 0.25643, acc 0.90625
2020-02-08T03:12:14.469105: step 1222, loss 0.250547, acc 0.875
2020-02-08T03:12:14.584777: step 1223, loss 0.391432, acc 0.78125
2020-02-08T03:12:14.699407: step 1224, loss 0.295361, acc 0.859375
2020-02-08T03:12:14.816262: step 1225, loss 0.231636, acc 0.921875
2020-02-08T03:12:14.936360: step 1226, loss 0.220299, acc 0.921875
2020-02-08T03:12:15.053050: step 1227, loss 0.117374, acc 0.96875
2020-02-08T03:12:15.171808: step 1228, loss 0.212579, acc 0.90625
2020-02-08T03:12:15.289387: step 1229, loss 0.146418, acc 0.953125
2020-02-08T03:12:15.404753: step 1230, loss 0.234928, acc 0.90625
2020-02-08T03:12:15.522723: step 1231, loss 0.2762, acc 0.875
2020-02-08T03:12:15.642010: step 1232, loss 0.230067, acc 0.921875
2020-02-08T03:12:15.757442: step 1233, loss 0.253783, acc 0.90625
2020-02-08T03:12:15.874774: step 1234, loss 0.153091, acc 0.921875
2020-02-08T03:12:15.992115: step 1235, loss 0.27158, acc 0.84375
2020-02-08T03:12:16.109400: step 1236, loss 0.184143, acc 0.921875
2020-02-08T03:12:16.227283: step 1237, loss 0.175678, acc 0.90625
2020-02-08T03:12:16.344616: step 1238, loss 0.243192, acc 0.875
2020-02-08T03:12:16.462245: step 1239, loss 0.320301, acc 0.875
2020-02-08T03:12:16.578426: step 1240, loss 0.224359, acc 0.90625
2020-02-08T03:12:16.694486: step 1241, loss 0.219597, acc 0.90625
2020-02-08T03:12:16.812601: step 1242, loss 0.132017, acc 0.953125
2020-02-08T03:12:16.930135: step 1243, loss 0.271637, acc 0.84375
2020-02-08T03:12:17.047680: step 1244, loss 0.268482, acc 0.921875
2020-02-08T03:12:17.162438: step 1245, loss 0.231168, acc 0.921875
2020-02-08T03:12:17.278098: step 1246, loss 0.368316, acc 0.859375
2020-02-08T03:12:17.393599: step 1247, loss 0.212855, acc 0.90625
2020-02-08T03:12:17.508327: step 1248, loss 0.199304, acc 0.9375
2020-02-08T03:12:17.625586: step 1249, loss 0.306897, acc 0.828125
2020-02-08T03:12:17.741678: step 1250, loss 0.236131, acc 0.90625
2020-02-08T03:12:17.857165: step 1251, loss 0.231807, acc 0.90625
2020-02-08T03:12:17.978001: step 1252, loss 0.314669, acc 0.90625
2020-02-08T03:12:18.094309: step 1253, loss 0.235131, acc 0.921875
2020-02-08T03:12:18.211445: step 1254, loss 0.258893, acc 0.921875
2020-02-08T03:12:18.329434: step 1255, loss 0.238741, acc 0.90625
2020-02-08T03:12:18.444514: step 1256, loss 0.256732, acc 0.890625
2020-02-08T03:12:18.561402: step 1257, loss 0.201218, acc 0.90625
2020-02-08T03:12:18.679685: step 1258, loss 0.373222, acc 0.84375
2020-02-08T03:12:18.795367: step 1259, loss 0.351521, acc 0.859375
2020-02-08T03:12:18.913298: step 1260, loss 0.144545, acc 0.953125
2020-02-08T03:12:19.033564: step 1261, loss 0.27389, acc 0.90625
2020-02-08T03:12:19.148130: step 1262, loss 0.201531, acc 0.90625
2020-02-08T03:12:19.264405: step 1263, loss 0.259699, acc 0.84375
2020-02-08T03:12:19.382633: step 1264, loss 0.23916, acc 0.90625
2020-02-08T03:12:19.499200: step 1265, loss 0.26549, acc 0.828125
2020-02-08T03:12:19.617508: step 1266, loss 0.206025, acc 0.90625
2020-02-08T03:12:19.735497: step 1267, loss 0.2892, acc 0.828125
2020-02-08T03:12:19.851280: step 1268, loss 0.253894, acc 0.859375
2020-02-08T03:12:19.969820: step 1269, loss 0.344941, acc 0.828125
2020-02-08T03:12:20.085264: step 1270, loss 0.179425, acc 0.921875
2020-02-08T03:12:20.199750: step 1271, loss 0.469851, acc 0.84375
2020-02-08T03:12:20.319208: step 1272, loss 0.228355, acc 0.859375
2020-02-08T03:12:20.436408: step 1273, loss 0.416225, acc 0.78125
2020-02-08T03:12:20.551278: step 1274, loss 0.253727, acc 0.921875
2020-02-08T03:12:20.669821: step 1275, loss 0.168382, acc 0.9375
2020-02-08T03:12:20.789048: step 1276, loss 0.249463, acc 0.90625
2020-02-08T03:12:20.906177: step 1277, loss 0.220557, acc 0.921875
2020-02-08T03:12:21.023975: step 1278, loss 0.242935, acc 0.890625
2020-02-08T03:12:21.142075: step 1279, loss 0.229751, acc 0.890625
2020-02-08T03:12:21.262230: step 1280, loss 0.254827, acc 0.875
2020-02-08T03:12:21.378986: step 1281, loss 0.242601, acc 0.890625
2020-02-08T03:12:21.546227: step 1282, loss 0.216488, acc 0.921875
2020-02-08T03:12:21.673399: step 1283, loss 0.155432, acc 0.953125
2020-02-08T03:12:21.791929: step 1284, loss 0.223367, acc 0.875
2020-02-08T03:12:21.909422: step 1285, loss 0.223305, acc 0.921875
2020-02-08T03:12:22.026053: step 1286, loss 0.11096, acc 0.984375
2020-02-08T03:12:22.144593: step 1287, loss 0.221832, acc 0.921875
2020-02-08T03:12:22.257703: step 1288, loss 0.184763, acc 0.9375
2020-02-08T03:12:22.375662: step 1289, loss 0.241283, acc 0.90625
2020-02-08T03:12:22.494465: step 1290, loss 0.176158, acc 0.953125
2020-02-08T03:12:22.610985: step 1291, loss 0.284767, acc 0.90625
2020-02-08T03:12:22.732509: step 1292, loss 0.224175, acc 0.90625
2020-02-08T03:12:22.849539: step 1293, loss 0.185192, acc 0.90625
2020-02-08T03:12:22.968392: step 1294, loss 0.225848, acc 0.9375
2020-02-08T03:12:23.086312: step 1295, loss 0.193099, acc 0.921875
2020-02-08T03:12:23.207534: step 1296, loss 0.256735, acc 0.875
2020-02-08T03:12:23.327603: step 1297, loss 0.289922, acc 0.890625
2020-02-08T03:12:23.444954: step 1298, loss 0.211418, acc 0.875
2020-02-08T03:12:23.563475: step 1299, loss 0.331514, acc 0.84375
2020-02-08T03:12:23.680457: step 1300, loss 0.310337, acc 0.890625

Evaluation:
2020-02-08T03:12:23.872313: step 1300, loss 0.609147, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1300

2020-02-08T03:12:25.407083: step 1301, loss 0.218693, acc 0.921875
2020-02-08T03:12:25.525609: step 1302, loss 0.255264, acc 0.890625
2020-02-08T03:12:25.641783: step 1303, loss 0.246669, acc 0.90625
2020-02-08T03:12:25.759000: step 1304, loss 0.284246, acc 0.875
2020-02-08T03:12:25.874819: step 1305, loss 0.299441, acc 0.859375
2020-02-08T03:12:25.990555: step 1306, loss 0.182919, acc 0.953125
2020-02-08T03:12:26.106788: step 1307, loss 0.380623, acc 0.859375
2020-02-08T03:12:26.226556: step 1308, loss 0.204672, acc 0.921875
2020-02-08T03:12:26.345025: step 1309, loss 0.368657, acc 0.828125
2020-02-08T03:12:26.463067: step 1310, loss 0.26006, acc 0.890625
2020-02-08T03:12:26.581673: step 1311, loss 0.201361, acc 0.90625
2020-02-08T03:12:26.698673: step 1312, loss 0.329737, acc 0.875
2020-02-08T03:12:26.813341: step 1313, loss 0.293693, acc 0.859375
2020-02-08T03:12:26.931630: step 1314, loss 0.191912, acc 0.921875
2020-02-08T03:12:27.046102: step 1315, loss 0.241246, acc 0.921875
2020-02-08T03:12:27.161173: step 1316, loss 0.443243, acc 0.71875
2020-02-08T03:12:27.279300: step 1317, loss 0.275094, acc 0.875
2020-02-08T03:12:27.396828: step 1318, loss 0.244833, acc 0.90625
2020-02-08T03:12:27.515723: step 1319, loss 0.258812, acc 0.921875
2020-02-08T03:12:27.630789: step 1320, loss 0.325661, acc 0.796875
2020-02-08T03:12:27.746964: step 1321, loss 0.365497, acc 0.84375
2020-02-08T03:12:27.861777: step 1322, loss 0.217468, acc 0.90625
2020-02-08T03:12:27.979984: step 1323, loss 0.199942, acc 0.921875
2020-02-08T03:12:28.096438: step 1324, loss 0.348526, acc 0.828125
2020-02-08T03:12:28.212409: step 1325, loss 0.330646, acc 0.84375
2020-02-08T03:12:28.330021: step 1326, loss 0.283586, acc 0.859375
2020-02-08T03:12:28.445713: step 1327, loss 0.206756, acc 0.90625
2020-02-08T03:12:28.564170: step 1328, loss 0.202814, acc 0.90625
2020-02-08T03:12:28.678967: step 1329, loss 0.259279, acc 0.9375
2020-02-08T03:12:28.796635: step 1330, loss 0.375142, acc 0.8125
2020-02-08T03:12:28.911263: step 1331, loss 0.145895, acc 0.953125
2020-02-08T03:12:29.029109: step 1332, loss 0.279799, acc 0.859375
2020-02-08T03:12:29.147790: step 1333, loss 0.229656, acc 0.859375
2020-02-08T03:12:29.264705: step 1334, loss 0.327647, acc 0.859375
2020-02-08T03:12:29.383425: step 1335, loss 0.33006, acc 0.890625
2020-02-08T03:12:29.502045: step 1336, loss 0.215598, acc 0.890625
2020-02-08T03:12:29.619458: step 1337, loss 0.178466, acc 0.953125
2020-02-08T03:12:29.737576: step 1338, loss 0.254863, acc 0.859375
2020-02-08T03:12:29.853197: step 1339, loss 0.227016, acc 0.9375
2020-02-08T03:12:29.972246: step 1340, loss 0.243825, acc 0.890625
2020-02-08T03:12:30.090008: step 1341, loss 0.153374, acc 0.953125
2020-02-08T03:12:30.204502: step 1342, loss 0.184847, acc 0.9375
2020-02-08T03:12:30.321006: step 1343, loss 0.195468, acc 0.9375
2020-02-08T03:12:30.438270: step 1344, loss 0.319446, acc 0.90625
2020-02-08T03:12:30.552775: step 1345, loss 0.275432, acc 0.890625
2020-02-08T03:12:30.668148: step 1346, loss 0.185988, acc 0.953125
2020-02-08T03:12:30.783223: step 1347, loss 0.191154, acc 0.921875
2020-02-08T03:12:30.900940: step 1348, loss 0.275355, acc 0.890625
2020-02-08T03:12:31.016445: step 1349, loss 0.252059, acc 0.921875
2020-02-08T03:12:31.131137: step 1350, loss 0.156322, acc 0.95
2020-02-08T03:12:31.249394: step 1351, loss 0.203899, acc 0.9375
2020-02-08T03:12:31.366602: step 1352, loss 0.171413, acc 0.953125
2020-02-08T03:12:31.486113: step 1353, loss 0.18316, acc 0.9375
2020-02-08T03:12:31.601675: step 1354, loss 0.243715, acc 0.875
2020-02-08T03:12:31.717890: step 1355, loss 0.160574, acc 0.953125
2020-02-08T03:12:31.838754: step 1356, loss 0.261303, acc 0.875
2020-02-08T03:12:31.956058: step 1357, loss 0.138975, acc 0.96875
2020-02-08T03:12:32.072516: step 1358, loss 0.275592, acc 0.875
2020-02-08T03:12:32.189521: step 1359, loss 0.140378, acc 0.96875
2020-02-08T03:12:32.304951: step 1360, loss 0.290739, acc 0.90625
2020-02-08T03:12:32.423791: step 1361, loss 0.130226, acc 0.953125
2020-02-08T03:12:32.541485: step 1362, loss 0.2323, acc 0.90625
2020-02-08T03:12:32.656402: step 1363, loss 0.144616, acc 0.9375
2020-02-08T03:12:32.771567: step 1364, loss 0.216643, acc 0.875
2020-02-08T03:12:32.888793: step 1365, loss 0.242938, acc 0.921875
2020-02-08T03:12:33.005370: step 1366, loss 0.266827, acc 0.90625
2020-02-08T03:12:33.121697: step 1367, loss 0.152971, acc 0.953125
2020-02-08T03:12:33.239052: step 1368, loss 0.221902, acc 0.90625
2020-02-08T03:12:33.357090: step 1369, loss 0.217949, acc 0.90625
2020-02-08T03:12:33.473125: step 1370, loss 0.208468, acc 0.90625
2020-02-08T03:12:33.591478: step 1371, loss 0.181762, acc 0.953125
2020-02-08T03:12:33.703347: step 1372, loss 0.144229, acc 0.953125
2020-02-08T03:12:33.819143: step 1373, loss 0.172994, acc 0.921875
2020-02-08T03:12:33.935275: step 1374, loss 0.245321, acc 0.90625
2020-02-08T03:12:34.050637: step 1375, loss 0.251008, acc 0.875
2020-02-08T03:12:34.165462: step 1376, loss 0.196183, acc 0.9375
2020-02-08T03:12:34.282871: step 1377, loss 0.156339, acc 0.921875
2020-02-08T03:12:34.399555: step 1378, loss 0.235829, acc 0.90625
2020-02-08T03:12:34.518122: step 1379, loss 0.140905, acc 0.953125
2020-02-08T03:12:34.635191: step 1380, loss 0.193995, acc 0.9375
2020-02-08T03:12:34.753434: step 1381, loss 0.164387, acc 0.953125
2020-02-08T03:12:34.869496: step 1382, loss 0.158778, acc 0.953125
2020-02-08T03:12:34.985332: step 1383, loss 0.227662, acc 0.921875
2020-02-08T03:12:35.104160: step 1384, loss 0.170403, acc 0.9375
2020-02-08T03:12:35.220910: step 1385, loss 0.230319, acc 0.90625
2020-02-08T03:12:35.340580: step 1386, loss 0.0895226, acc 1
2020-02-08T03:12:35.458344: step 1387, loss 0.101104, acc 0.984375
2020-02-08T03:12:35.574697: step 1388, loss 0.247201, acc 0.90625
2020-02-08T03:12:35.692177: step 1389, loss 0.1837, acc 0.90625
2020-02-08T03:12:35.808599: step 1390, loss 0.183851, acc 0.921875
2020-02-08T03:12:35.923145: step 1391, loss 0.184052, acc 0.9375
2020-02-08T03:12:36.040414: step 1392, loss 0.191172, acc 0.953125
2020-02-08T03:12:36.158064: step 1393, loss 0.223288, acc 0.921875
2020-02-08T03:12:36.277030: step 1394, loss 0.187916, acc 0.890625
2020-02-08T03:12:36.394141: step 1395, loss 0.224767, acc 0.890625
2020-02-08T03:12:36.513092: step 1396, loss 0.258407, acc 0.875
2020-02-08T03:12:36.628888: step 1397, loss 0.29573, acc 0.859375
2020-02-08T03:12:36.745749: step 1398, loss 0.187288, acc 0.921875
2020-02-08T03:12:36.864796: step 1399, loss 0.204351, acc 0.921875
2020-02-08T03:12:36.981396: step 1400, loss 0.250159, acc 0.890625

Evaluation:
2020-02-08T03:12:37.171304: step 1400, loss 0.622964, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1400

2020-02-08T03:12:38.706252: step 1401, loss 0.117173, acc 0.96875
2020-02-08T03:12:38.825127: step 1402, loss 0.338039, acc 0.875
2020-02-08T03:12:38.943219: step 1403, loss 0.220179, acc 0.953125
2020-02-08T03:12:39.060598: step 1404, loss 0.173027, acc 0.9375
2020-02-08T03:12:39.177449: step 1405, loss 0.097211, acc 0.984375
2020-02-08T03:12:39.296172: step 1406, loss 0.158663, acc 0.953125
2020-02-08T03:12:39.411428: step 1407, loss 0.164773, acc 0.953125
2020-02-08T03:12:39.527812: step 1408, loss 0.117065, acc 1
2020-02-08T03:12:39.644493: step 1409, loss 0.269789, acc 0.921875
2020-02-08T03:12:39.761479: step 1410, loss 0.176499, acc 0.9375
2020-02-08T03:12:39.877011: step 1411, loss 0.14621, acc 0.96875
2020-02-08T03:12:39.994082: step 1412, loss 0.214909, acc 0.921875
2020-02-08T03:12:40.108545: step 1413, loss 0.170377, acc 0.90625
2020-02-08T03:12:40.222108: step 1414, loss 0.208974, acc 0.921875
2020-02-08T03:12:40.341927: step 1415, loss 0.17145, acc 0.9375
2020-02-08T03:12:40.460380: step 1416, loss 0.175576, acc 0.921875
2020-02-08T03:12:40.579892: step 1417, loss 0.0938625, acc 1
2020-02-08T03:12:40.698959: step 1418, loss 0.119683, acc 0.953125
2020-02-08T03:12:40.821396: step 1419, loss 0.0977964, acc 0.984375
2020-02-08T03:12:40.937822: step 1420, loss 0.206687, acc 0.890625
2020-02-08T03:12:41.054824: step 1421, loss 0.226152, acc 0.859375
2020-02-08T03:12:41.172771: step 1422, loss 0.142291, acc 0.96875
2020-02-08T03:12:41.292179: step 1423, loss 0.192683, acc 0.953125
2020-02-08T03:12:41.410697: step 1424, loss 0.325945, acc 0.84375
2020-02-08T03:12:41.525230: step 1425, loss 0.241602, acc 0.90625
2020-02-08T03:12:41.642603: step 1426, loss 0.156683, acc 0.9375
2020-02-08T03:12:41.759952: step 1427, loss 0.188605, acc 0.90625
2020-02-08T03:12:41.876297: step 1428, loss 0.0888245, acc 0.96875
2020-02-08T03:12:41.995200: step 1429, loss 0.132957, acc 0.96875
2020-02-08T03:12:42.110734: step 1430, loss 0.145397, acc 0.953125
2020-02-08T03:12:42.227674: step 1431, loss 0.160809, acc 0.9375
2020-02-08T03:12:42.343321: step 1432, loss 0.224075, acc 0.890625
2020-02-08T03:12:42.463693: step 1433, loss 0.189604, acc 0.9375
2020-02-08T03:12:42.580371: step 1434, loss 0.231579, acc 0.890625
2020-02-08T03:12:42.700806: step 1435, loss 0.21831, acc 0.890625
2020-02-08T03:12:42.816897: step 1436, loss 0.186967, acc 0.9375
2020-02-08T03:12:42.933451: step 1437, loss 0.154547, acc 0.90625
2020-02-08T03:12:43.051770: step 1438, loss 0.258825, acc 0.890625
2020-02-08T03:12:43.165199: step 1439, loss 0.282251, acc 0.890625
2020-02-08T03:12:43.282056: step 1440, loss 0.218382, acc 0.9375
2020-02-08T03:12:43.400155: step 1441, loss 0.110186, acc 0.9375
2020-02-08T03:12:43.516112: step 1442, loss 0.12164, acc 0.984375
2020-02-08T03:12:43.632922: step 1443, loss 0.247227, acc 0.890625
2020-02-08T03:12:43.750833: step 1444, loss 0.344261, acc 0.875
2020-02-08T03:12:43.870975: step 1445, loss 0.138613, acc 0.953125
2020-02-08T03:12:43.988861: step 1446, loss 0.189265, acc 0.921875
2020-02-08T03:12:44.105555: step 1447, loss 0.321982, acc 0.875
2020-02-08T03:12:44.221564: step 1448, loss 0.167045, acc 0.921875
2020-02-08T03:12:44.338650: step 1449, loss 0.187871, acc 0.96875
2020-02-08T03:12:44.455861: step 1450, loss 0.153909, acc 0.9375
2020-02-08T03:12:44.573903: step 1451, loss 0.146984, acc 0.953125
2020-02-08T03:12:44.690981: step 1452, loss 0.156823, acc 0.9375
2020-02-08T03:12:44.811273: step 1453, loss 0.0906838, acc 0.984375
2020-02-08T03:12:44.928523: step 1454, loss 0.166219, acc 0.9375
2020-02-08T03:12:45.047966: step 1455, loss 0.193772, acc 0.921875
2020-02-08T03:12:45.164863: step 1456, loss 0.173836, acc 0.921875
2020-02-08T03:12:45.280125: step 1457, loss 0.134909, acc 0.953125
2020-02-08T03:12:45.396133: step 1458, loss 0.21971, acc 0.890625
2020-02-08T03:12:45.511528: step 1459, loss 0.18351, acc 0.921875
2020-02-08T03:12:45.626898: step 1460, loss 0.265084, acc 0.859375
2020-02-08T03:12:45.744275: step 1461, loss 0.166431, acc 0.90625
2020-02-08T03:12:45.859614: step 1462, loss 0.153112, acc 0.953125
2020-02-08T03:12:45.977905: step 1463, loss 0.129486, acc 0.96875
2020-02-08T03:12:46.096076: step 1464, loss 0.220557, acc 0.9375
2020-02-08T03:12:46.215849: step 1465, loss 0.241036, acc 0.9375
2020-02-08T03:12:46.333477: step 1466, loss 0.0955283, acc 0.984375
2020-02-08T03:12:46.448651: step 1467, loss 0.222593, acc 0.9375
2020-02-08T03:12:46.566884: step 1468, loss 0.136203, acc 0.9375
2020-02-08T03:12:46.685063: step 1469, loss 0.233335, acc 0.921875
2020-02-08T03:12:46.802349: step 1470, loss 0.244554, acc 0.828125
2020-02-08T03:12:46.919137: step 1471, loss 0.210681, acc 0.90625
2020-02-08T03:12:47.036944: step 1472, loss 0.21385, acc 0.90625
2020-02-08T03:12:47.151138: step 1473, loss 0.12722, acc 0.921875
2020-02-08T03:12:47.266898: step 1474, loss 0.184708, acc 0.921875
2020-02-08T03:12:47.383118: step 1475, loss 0.226993, acc 0.921875
2020-02-08T03:12:47.500680: step 1476, loss 0.262179, acc 0.859375
2020-02-08T03:12:47.614004: step 1477, loss 0.238217, acc 0.90625
2020-02-08T03:12:47.732056: step 1478, loss 0.195674, acc 0.921875
2020-02-08T03:12:47.846302: step 1479, loss 0.109229, acc 0.984375
2020-02-08T03:12:47.962497: step 1480, loss 0.124649, acc 0.953125
2020-02-08T03:12:48.085002: step 1481, loss 0.242969, acc 0.90625
2020-02-08T03:12:48.202490: step 1482, loss 0.113931, acc 0.96875
2020-02-08T03:12:48.318386: step 1483, loss 0.192787, acc 0.953125
2020-02-08T03:12:48.436408: step 1484, loss 0.144512, acc 0.9375
2020-02-08T03:12:48.553755: step 1485, loss 0.165876, acc 0.9375
2020-02-08T03:12:48.674369: step 1486, loss 0.285477, acc 0.859375
2020-02-08T03:12:48.793272: step 1487, loss 0.213458, acc 0.890625
2020-02-08T03:12:48.912140: step 1488, loss 0.201434, acc 0.90625
2020-02-08T03:12:49.028653: step 1489, loss 0.271771, acc 0.890625
2020-02-08T03:12:49.145097: step 1490, loss 0.130014, acc 0.953125
2020-02-08T03:12:49.262017: step 1491, loss 0.113613, acc 0.953125
2020-02-08T03:12:49.376473: step 1492, loss 0.196732, acc 0.890625
2020-02-08T03:12:49.494932: step 1493, loss 0.235836, acc 0.890625
2020-02-08T03:12:49.611727: step 1494, loss 0.138868, acc 0.96875
2020-02-08T03:12:49.729864: step 1495, loss 0.24877, acc 0.875
2020-02-08T03:12:49.845382: step 1496, loss 0.218893, acc 0.9375
2020-02-08T03:12:49.961629: step 1497, loss 0.252892, acc 0.859375
2020-02-08T03:12:50.085303: step 1498, loss 0.359419, acc 0.84375
2020-02-08T03:12:50.202366: step 1499, loss 0.21181, acc 0.9375
2020-02-08T03:12:50.313221: step 1500, loss 0.3424, acc 0.833333

Evaluation:
2020-02-08T03:12:50.499361: step 1500, loss 0.631694, acc 0.73546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1500

2020-02-08T03:12:51.987011: step 1501, loss 0.116719, acc 0.96875
2020-02-08T03:12:52.167680: step 1502, loss 0.147587, acc 0.953125
2020-02-08T03:12:52.296030: step 1503, loss 0.15085, acc 0.953125
2020-02-08T03:12:52.411272: step 1504, loss 0.116905, acc 0.953125
2020-02-08T03:12:52.528294: step 1505, loss 0.206071, acc 0.921875
2020-02-08T03:12:52.646360: step 1506, loss 0.138526, acc 0.96875
2020-02-08T03:12:52.762517: step 1507, loss 0.18049, acc 0.921875
2020-02-08T03:12:52.882004: step 1508, loss 0.140439, acc 0.984375
2020-02-08T03:12:52.997989: step 1509, loss 0.125594, acc 0.9375
2020-02-08T03:12:53.114079: step 1510, loss 0.147857, acc 0.953125
2020-02-08T03:12:53.231558: step 1511, loss 0.137789, acc 0.96875
2020-02-08T03:12:53.348904: step 1512, loss 0.143946, acc 0.96875
2020-02-08T03:12:53.467276: step 1513, loss 0.128378, acc 0.96875
2020-02-08T03:12:53.589518: step 1514, loss 0.176459, acc 0.953125
2020-02-08T03:12:53.706365: step 1515, loss 0.0680397, acc 1
2020-02-08T03:12:53.822707: step 1516, loss 0.159003, acc 0.9375
2020-02-08T03:12:53.938838: step 1517, loss 0.10893, acc 0.953125
2020-02-08T03:12:54.054150: step 1518, loss 0.14703, acc 0.953125
2020-02-08T03:12:54.169604: step 1519, loss 0.132848, acc 0.953125
2020-02-08T03:12:54.283474: step 1520, loss 0.145677, acc 0.953125
2020-02-08T03:12:54.399455: step 1521, loss 0.12088, acc 0.953125
2020-02-08T03:12:54.516230: step 1522, loss 0.154307, acc 0.921875
2020-02-08T03:12:54.632844: step 1523, loss 0.147363, acc 0.9375
2020-02-08T03:12:54.748545: step 1524, loss 0.131761, acc 0.96875
2020-02-08T03:12:54.867291: step 1525, loss 0.111922, acc 0.96875
2020-02-08T03:12:54.982896: step 1526, loss 0.0903132, acc 0.984375
2020-02-08T03:12:55.098944: step 1527, loss 0.115034, acc 0.9375
2020-02-08T03:12:55.213528: step 1528, loss 0.169444, acc 0.953125
2020-02-08T03:12:55.333296: step 1529, loss 0.102691, acc 0.984375
2020-02-08T03:12:55.452499: step 1530, loss 0.11284, acc 0.984375
2020-02-08T03:12:55.568886: step 1531, loss 0.165189, acc 0.953125
2020-02-08T03:12:55.684452: step 1532, loss 0.171694, acc 0.921875
2020-02-08T03:12:55.800168: step 1533, loss 0.144748, acc 0.96875
2020-02-08T03:12:55.917703: step 1534, loss 0.157651, acc 0.921875
2020-02-08T03:12:56.037489: step 1535, loss 0.158061, acc 0.921875
2020-02-08T03:12:56.152925: step 1536, loss 0.101169, acc 0.96875
2020-02-08T03:12:56.268335: step 1537, loss 0.161647, acc 0.90625
2020-02-08T03:12:56.387015: step 1538, loss 0.0699056, acc 0.96875
2020-02-08T03:12:56.502965: step 1539, loss 0.143558, acc 0.953125
2020-02-08T03:12:56.617638: step 1540, loss 0.254626, acc 0.875
2020-02-08T03:12:56.736830: step 1541, loss 0.116728, acc 0.953125
2020-02-08T03:12:56.853687: step 1542, loss 0.172189, acc 0.921875
2020-02-08T03:12:56.971864: step 1543, loss 0.123544, acc 0.953125
2020-02-08T03:12:57.090641: step 1544, loss 0.0772841, acc 0.984375
2020-02-08T03:12:57.208622: step 1545, loss 0.16044, acc 0.921875
2020-02-08T03:12:57.323831: step 1546, loss 0.179476, acc 0.921875
2020-02-08T03:12:57.441566: step 1547, loss 0.124345, acc 0.953125
2020-02-08T03:12:57.556377: step 1548, loss 0.209796, acc 0.90625
2020-02-08T03:12:57.677122: step 1549, loss 0.120287, acc 0.96875
2020-02-08T03:12:57.792696: step 1550, loss 0.150574, acc 0.953125
2020-02-08T03:12:57.912049: step 1551, loss 0.15314, acc 0.953125
2020-02-08T03:12:58.037896: step 1552, loss 0.197052, acc 0.890625
2020-02-08T03:12:58.151830: step 1553, loss 0.165476, acc 0.921875
2020-02-08T03:12:58.269763: step 1554, loss 0.137154, acc 0.9375
2020-02-08T03:12:58.389769: step 1555, loss 0.112189, acc 0.953125
2020-02-08T03:12:58.503207: step 1556, loss 0.0815918, acc 0.984375
2020-02-08T03:12:58.620146: step 1557, loss 0.0907823, acc 0.96875
2020-02-08T03:12:58.739968: step 1558, loss 0.237827, acc 0.90625
2020-02-08T03:12:58.854547: step 1559, loss 0.140482, acc 0.953125
2020-02-08T03:12:58.971157: step 1560, loss 0.234263, acc 0.90625
2020-02-08T03:12:59.093270: step 1561, loss 0.164828, acc 0.921875
2020-02-08T03:12:59.209596: step 1562, loss 0.179188, acc 0.9375
2020-02-08T03:12:59.328880: step 1563, loss 0.137062, acc 0.96875
2020-02-08T03:12:59.445081: step 1564, loss 0.180064, acc 0.921875
2020-02-08T03:12:59.560907: step 1565, loss 0.178853, acc 0.921875
2020-02-08T03:12:59.679609: step 1566, loss 0.113275, acc 0.9375
2020-02-08T03:12:59.799437: step 1567, loss 0.175148, acc 0.921875
2020-02-08T03:12:59.917272: step 1568, loss 0.123286, acc 0.9375
2020-02-08T03:13:00.034789: step 1569, loss 0.0944915, acc 0.984375
2020-02-08T03:13:00.150048: step 1570, loss 0.195409, acc 0.90625
2020-02-08T03:13:00.267882: step 1571, loss 0.159838, acc 0.921875
2020-02-08T03:13:00.387851: step 1572, loss 0.117987, acc 0.9375
2020-02-08T03:13:00.506275: step 1573, loss 0.109942, acc 0.953125
2020-02-08T03:13:00.623356: step 1574, loss 0.12298, acc 0.9375
2020-02-08T03:13:00.742140: step 1575, loss 0.0783431, acc 0.953125
2020-02-08T03:13:00.861639: step 1576, loss 0.131848, acc 0.96875
2020-02-08T03:13:00.978866: step 1577, loss 0.0990265, acc 0.984375
2020-02-08T03:13:01.098360: step 1578, loss 0.182229, acc 0.890625
2020-02-08T03:13:01.214641: step 1579, loss 0.171408, acc 0.921875
2020-02-08T03:13:01.331258: step 1580, loss 0.0733493, acc 0.984375
2020-02-08T03:13:01.447990: step 1581, loss 0.149761, acc 0.953125
2020-02-08T03:13:01.565518: step 1582, loss 0.103087, acc 0.96875
2020-02-08T03:13:01.682373: step 1583, loss 0.212474, acc 0.890625
2020-02-08T03:13:01.799567: step 1584, loss 0.127822, acc 0.9375
2020-02-08T03:13:01.916053: step 1585, loss 0.17863, acc 0.953125
2020-02-08T03:13:02.035115: step 1586, loss 0.0788314, acc 0.96875
2020-02-08T03:13:02.148840: step 1587, loss 0.0512016, acc 1
2020-02-08T03:13:02.265819: step 1588, loss 0.145515, acc 0.9375
2020-02-08T03:13:02.383317: step 1589, loss 0.211673, acc 0.90625
2020-02-08T03:13:02.498665: step 1590, loss 0.102893, acc 0.984375
2020-02-08T03:13:02.613854: step 1591, loss 0.126326, acc 0.9375
2020-02-08T03:13:02.732360: step 1592, loss 0.215564, acc 0.921875
2020-02-08T03:13:02.851056: step 1593, loss 0.205071, acc 0.921875
2020-02-08T03:13:02.967031: step 1594, loss 0.0985711, acc 0.96875
2020-02-08T03:13:03.085800: step 1595, loss 0.235211, acc 0.90625
2020-02-08T03:13:03.201592: step 1596, loss 0.0935793, acc 0.984375
2020-02-08T03:13:03.318418: step 1597, loss 0.0999879, acc 0.96875
2020-02-08T03:13:03.438751: step 1598, loss 0.12169, acc 0.953125
2020-02-08T03:13:03.553411: step 1599, loss 0.141061, acc 0.9375
2020-02-08T03:13:03.669483: step 1600, loss 0.0840373, acc 0.96875

Evaluation:
2020-02-08T03:13:03.857861: step 1600, loss 0.655033, acc 0.738274

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1600

2020-02-08T03:13:05.796063: step 1601, loss 0.241738, acc 0.890625
2020-02-08T03:13:05.913220: step 1602, loss 0.114032, acc 0.953125
2020-02-08T03:13:06.031109: step 1603, loss 0.181147, acc 0.921875
2020-02-08T03:13:06.145817: step 1604, loss 0.165347, acc 0.9375
2020-02-08T03:13:06.261063: step 1605, loss 0.18706, acc 0.953125
2020-02-08T03:13:06.376012: step 1606, loss 0.240877, acc 0.921875
2020-02-08T03:13:06.492872: step 1607, loss 0.110683, acc 0.9375
2020-02-08T03:13:06.607239: step 1608, loss 0.124193, acc 0.984375
2020-02-08T03:13:06.728017: step 1609, loss 0.102907, acc 0.953125
2020-02-08T03:13:06.850877: step 1610, loss 0.134496, acc 0.96875
2020-02-08T03:13:06.968341: step 1611, loss 0.118066, acc 0.9375
2020-02-08T03:13:07.087191: step 1612, loss 0.141596, acc 0.953125
2020-02-08T03:13:07.202219: step 1613, loss 0.263848, acc 0.859375
2020-02-08T03:13:07.320034: step 1614, loss 0.148955, acc 0.9375
2020-02-08T03:13:07.435461: step 1615, loss 0.194774, acc 0.90625
2020-02-08T03:13:07.548590: step 1616, loss 0.182462, acc 0.921875
2020-02-08T03:13:07.664228: step 1617, loss 0.107583, acc 0.9375
2020-02-08T03:13:07.782707: step 1618, loss 0.208449, acc 0.890625
2020-02-08T03:13:07.896173: step 1619, loss 0.179471, acc 0.921875
2020-02-08T03:13:08.014384: step 1620, loss 0.169775, acc 0.890625
2020-02-08T03:13:08.131831: step 1621, loss 0.172816, acc 0.921875
2020-02-08T03:13:08.249692: step 1622, loss 0.0827746, acc 1
2020-02-08T03:13:08.369145: step 1623, loss 0.138123, acc 0.953125
2020-02-08T03:13:08.485965: step 1624, loss 0.187847, acc 0.90625
2020-02-08T03:13:08.603628: step 1625, loss 0.0937772, acc 0.953125
2020-02-08T03:13:08.719016: step 1626, loss 0.158534, acc 0.921875
2020-02-08T03:13:08.837656: step 1627, loss 0.160713, acc 0.90625
2020-02-08T03:13:08.954471: step 1628, loss 0.185789, acc 0.921875
2020-02-08T03:13:09.072569: step 1629, loss 0.159397, acc 0.953125
2020-02-08T03:13:09.189889: step 1630, loss 0.114334, acc 0.953125
2020-02-08T03:13:09.304925: step 1631, loss 0.13317, acc 0.96875
2020-02-08T03:13:09.421914: step 1632, loss 0.133372, acc 0.953125
2020-02-08T03:13:09.541562: step 1633, loss 0.188785, acc 0.90625
2020-02-08T03:13:09.657746: step 1634, loss 0.213822, acc 0.9375
2020-02-08T03:13:09.776758: step 1635, loss 0.0993135, acc 0.9375
2020-02-08T03:13:09.894029: step 1636, loss 0.255904, acc 0.890625
2020-02-08T03:13:10.010591: step 1637, loss 0.185993, acc 0.90625
2020-02-08T03:13:10.129099: step 1638, loss 0.0774179, acc 0.96875
2020-02-08T03:13:10.243824: step 1639, loss 0.0900082, acc 0.96875
2020-02-08T03:13:10.357698: step 1640, loss 0.191893, acc 0.890625
2020-02-08T03:13:10.471923: step 1641, loss 0.095988, acc 0.96875
2020-02-08T03:13:10.590542: step 1642, loss 0.146794, acc 0.96875
2020-02-08T03:13:10.705433: step 1643, loss 0.221518, acc 0.9375
2020-02-08T03:13:10.825476: step 1644, loss 0.123626, acc 0.921875
2020-02-08T03:13:10.943701: step 1645, loss 0.152258, acc 0.921875
2020-02-08T03:13:11.060356: step 1646, loss 0.18045, acc 0.9375
2020-02-08T03:13:11.177618: step 1647, loss 0.0841133, acc 0.9375
2020-02-08T03:13:11.292698: step 1648, loss 0.108507, acc 0.953125
2020-02-08T03:13:11.408737: step 1649, loss 0.154882, acc 0.953125
2020-02-08T03:13:11.520621: step 1650, loss 0.179564, acc 0.95
2020-02-08T03:13:11.638342: step 1651, loss 0.069742, acc 0.984375
2020-02-08T03:13:11.752339: step 1652, loss 0.149678, acc 0.921875
2020-02-08T03:13:11.869544: step 1653, loss 0.109194, acc 0.953125
2020-02-08T03:13:11.985056: step 1654, loss 0.139693, acc 0.96875
2020-02-08T03:13:12.101325: step 1655, loss 0.1444, acc 0.9375
2020-02-08T03:13:12.219240: step 1656, loss 0.0704445, acc 0.984375
2020-02-08T03:13:12.335984: step 1657, loss 0.146068, acc 0.921875
2020-02-08T03:13:12.453248: step 1658, loss 0.0398217, acc 1
2020-02-08T03:13:12.571378: step 1659, loss 0.117484, acc 0.921875
2020-02-08T03:13:12.688102: step 1660, loss 0.124825, acc 0.953125
2020-02-08T03:13:12.802613: step 1661, loss 0.0482652, acc 1
2020-02-08T03:13:12.919515: step 1662, loss 0.119841, acc 0.9375
2020-02-08T03:13:13.037151: step 1663, loss 0.0489155, acc 1
2020-02-08T03:13:13.154907: step 1664, loss 0.118961, acc 0.953125
2020-02-08T03:13:13.272300: step 1665, loss 0.122819, acc 0.96875
2020-02-08T03:13:13.389099: step 1666, loss 0.10338, acc 0.96875
2020-02-08T03:13:13.503226: step 1667, loss 0.110564, acc 0.984375
2020-02-08T03:13:13.621596: step 1668, loss 0.0652095, acc 0.96875
2020-02-08T03:13:13.740000: step 1669, loss 0.113329, acc 0.9375
2020-02-08T03:13:13.858816: step 1670, loss 0.110606, acc 0.953125
2020-02-08T03:13:13.973899: step 1671, loss 0.108534, acc 0.984375
2020-02-08T03:13:14.089846: step 1672, loss 0.0503933, acc 1
2020-02-08T03:13:14.206490: step 1673, loss 0.137316, acc 0.9375
2020-02-08T03:13:14.325168: step 1674, loss 0.126464, acc 0.9375
2020-02-08T03:13:14.444750: step 1675, loss 0.102296, acc 0.96875
2020-02-08T03:13:14.563921: step 1676, loss 0.136807, acc 0.921875
2020-02-08T03:13:14.681658: step 1677, loss 0.109068, acc 0.953125
2020-02-08T03:13:14.796892: step 1678, loss 0.169131, acc 0.921875
2020-02-08T03:13:14.917121: step 1679, loss 0.0942408, acc 0.984375
2020-02-08T03:13:15.035880: step 1680, loss 0.141695, acc 0.953125
2020-02-08T03:13:15.151952: step 1681, loss 0.132229, acc 0.953125
2020-02-08T03:13:15.266352: step 1682, loss 0.12824, acc 0.953125
2020-02-08T03:13:15.384356: step 1683, loss 0.0941309, acc 0.96875
2020-02-08T03:13:15.501733: step 1684, loss 0.273495, acc 0.890625
2020-02-08T03:13:15.619960: step 1685, loss 0.165322, acc 0.953125
2020-02-08T03:13:15.738213: step 1686, loss 0.157013, acc 0.953125
2020-02-08T03:13:15.853779: step 1687, loss 0.0894584, acc 0.953125
2020-02-08T03:13:15.971399: step 1688, loss 0.074507, acc 0.984375
2020-02-08T03:13:16.089051: step 1689, loss 0.0910721, acc 0.96875
2020-02-08T03:13:16.203390: step 1690, loss 0.0677405, acc 0.96875
2020-02-08T03:13:16.320339: step 1691, loss 0.0820203, acc 0.96875
2020-02-08T03:13:16.436137: step 1692, loss 0.106393, acc 0.96875
2020-02-08T03:13:16.552301: step 1693, loss 0.13538, acc 0.96875
2020-02-08T03:13:16.669392: step 1694, loss 0.0702953, acc 0.984375
2020-02-08T03:13:16.785940: step 1695, loss 0.104331, acc 0.96875
2020-02-08T03:13:16.902491: step 1696, loss 0.128447, acc 0.984375
2020-02-08T03:13:17.017985: step 1697, loss 0.0678846, acc 1
2020-02-08T03:13:17.133985: step 1698, loss 0.0475708, acc 1
2020-02-08T03:13:17.249126: step 1699, loss 0.0737264, acc 0.984375
2020-02-08T03:13:17.365615: step 1700, loss 0.129988, acc 0.9375

Evaluation:
2020-02-08T03:13:17.550689: step 1700, loss 0.677236, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1700

2020-02-08T03:13:19.067835: step 1701, loss 0.124905, acc 0.96875
2020-02-08T03:13:19.186387: step 1702, loss 0.0745666, acc 0.984375
2020-02-08T03:13:19.303180: step 1703, loss 0.155153, acc 0.9375
2020-02-08T03:13:19.417787: step 1704, loss 0.177873, acc 0.984375
2020-02-08T03:13:19.535070: step 1705, loss 0.124243, acc 0.9375
2020-02-08T03:13:19.649182: step 1706, loss 0.137232, acc 0.953125
2020-02-08T03:13:19.764779: step 1707, loss 0.0755382, acc 0.96875
2020-02-08T03:13:19.878693: step 1708, loss 0.146374, acc 0.953125
2020-02-08T03:13:19.994977: step 1709, loss 0.0895013, acc 0.984375
2020-02-08T03:13:20.110690: step 1710, loss 0.147989, acc 0.9375
2020-02-08T03:13:20.227151: step 1711, loss 0.0673484, acc 1
2020-02-08T03:13:20.344019: step 1712, loss 0.112413, acc 0.953125
2020-02-08T03:13:20.461497: step 1713, loss 0.185283, acc 0.9375
2020-02-08T03:13:20.579454: step 1714, loss 0.215248, acc 0.921875
2020-02-08T03:13:20.694224: step 1715, loss 0.0927775, acc 0.96875
2020-02-08T03:13:20.810287: step 1716, loss 0.11334, acc 0.984375
2020-02-08T03:13:20.929224: step 1717, loss 0.229378, acc 0.90625
2020-02-08T03:13:21.046545: step 1718, loss 0.0783313, acc 0.984375
2020-02-08T03:13:21.160262: step 1719, loss 0.12505, acc 0.921875
2020-02-08T03:13:21.275816: step 1720, loss 0.0686558, acc 0.96875
2020-02-08T03:13:21.388428: step 1721, loss 0.170358, acc 0.953125
2020-02-08T03:13:21.503018: step 1722, loss 0.217475, acc 0.890625
2020-02-08T03:13:21.634517: step 1723, loss 0.108347, acc 0.96875
2020-02-08T03:13:21.764252: step 1724, loss 0.105185, acc 0.96875
2020-02-08T03:13:21.880006: step 1725, loss 0.114472, acc 0.96875
2020-02-08T03:13:21.993682: step 1726, loss 0.130766, acc 0.9375
2020-02-08T03:13:22.109833: step 1727, loss 0.142608, acc 0.953125
2020-02-08T03:13:22.226097: step 1728, loss 0.0900832, acc 0.984375
2020-02-08T03:13:22.340367: step 1729, loss 0.199935, acc 0.921875
2020-02-08T03:13:22.455214: step 1730, loss 0.125169, acc 0.9375
2020-02-08T03:13:22.570929: step 1731, loss 0.0622179, acc 1
2020-02-08T03:13:22.686612: step 1732, loss 0.170238, acc 0.9375
2020-02-08T03:13:22.801410: step 1733, loss 0.105002, acc 0.96875
2020-02-08T03:13:22.917944: step 1734, loss 0.106443, acc 0.96875
2020-02-08T03:13:23.036397: step 1735, loss 0.0806845, acc 0.984375
2020-02-08T03:13:23.153496: step 1736, loss 0.108993, acc 0.984375
2020-02-08T03:13:23.271075: step 1737, loss 0.0766326, acc 0.953125
2020-02-08T03:13:23.391038: step 1738, loss 0.131862, acc 0.9375
2020-02-08T03:13:23.504185: step 1739, loss 0.0461828, acc 0.984375
2020-02-08T03:13:23.618834: step 1740, loss 0.0557369, acc 0.984375
2020-02-08T03:13:23.734756: step 1741, loss 0.206463, acc 0.9375
2020-02-08T03:13:23.850397: step 1742, loss 0.0562845, acc 0.984375
2020-02-08T03:13:23.968784: step 1743, loss 0.0773586, acc 0.984375
2020-02-08T03:13:24.083959: step 1744, loss 0.120405, acc 0.953125
2020-02-08T03:13:24.200303: step 1745, loss 0.146764, acc 0.9375
2020-02-08T03:13:24.319506: step 1746, loss 0.248494, acc 0.921875
2020-02-08T03:13:24.442062: step 1747, loss 0.143908, acc 0.9375
2020-02-08T03:13:24.555163: step 1748, loss 0.0918785, acc 0.96875
2020-02-08T03:13:24.673566: step 1749, loss 0.210674, acc 0.9375
2020-02-08T03:13:24.791252: step 1750, loss 0.0735933, acc 0.96875
2020-02-08T03:13:24.906115: step 1751, loss 0.0987486, acc 0.953125
2020-02-08T03:13:25.025125: step 1752, loss 0.0676411, acc 1
2020-02-08T03:13:25.142109: step 1753, loss 0.0852679, acc 0.953125
2020-02-08T03:13:25.258550: step 1754, loss 0.133982, acc 0.953125
2020-02-08T03:13:25.376895: step 1755, loss 0.0611091, acc 0.984375
2020-02-08T03:13:25.493050: step 1756, loss 0.12493, acc 0.96875
2020-02-08T03:13:25.610487: step 1757, loss 0.0842211, acc 0.984375
2020-02-08T03:13:25.727476: step 1758, loss 0.149389, acc 0.9375
2020-02-08T03:13:25.843143: step 1759, loss 0.112872, acc 0.953125
2020-02-08T03:13:25.960960: step 1760, loss 0.0893779, acc 0.96875
2020-02-08T03:13:26.077492: step 1761, loss 0.0358861, acc 1
2020-02-08T03:13:26.196221: step 1762, loss 0.124217, acc 0.953125
2020-02-08T03:13:26.312671: step 1763, loss 0.181523, acc 0.9375
2020-02-08T03:13:26.431232: step 1764, loss 0.169908, acc 0.921875
2020-02-08T03:13:26.547624: step 1765, loss 0.0642959, acc 0.984375
2020-02-08T03:13:26.662877: step 1766, loss 0.0402279, acc 1
2020-02-08T03:13:26.779560: step 1767, loss 0.0385461, acc 0.984375
2020-02-08T03:13:26.895775: step 1768, loss 0.144387, acc 0.96875
2020-02-08T03:13:27.011307: step 1769, loss 0.0913378, acc 0.953125
2020-02-08T03:13:27.129379: step 1770, loss 0.0839631, acc 0.96875
2020-02-08T03:13:27.249065: step 1771, loss 0.145436, acc 0.9375
2020-02-08T03:13:27.367916: step 1772, loss 0.0476876, acc 0.984375
2020-02-08T03:13:27.485401: step 1773, loss 0.121097, acc 0.9375
2020-02-08T03:13:27.599462: step 1774, loss 0.050359, acc 1
2020-02-08T03:13:27.718495: step 1775, loss 0.0765089, acc 0.984375
2020-02-08T03:13:27.835695: step 1776, loss 0.177133, acc 0.9375
2020-02-08T03:13:27.949954: step 1777, loss 0.11542, acc 0.96875
2020-02-08T03:13:28.067932: step 1778, loss 0.0836791, acc 0.984375
2020-02-08T03:13:28.186408: step 1779, loss 0.150639, acc 0.953125
2020-02-08T03:13:28.300087: step 1780, loss 0.0374773, acc 1
2020-02-08T03:13:28.413298: step 1781, loss 0.136393, acc 0.90625
2020-02-08T03:13:28.528470: step 1782, loss 0.0851245, acc 0.984375
2020-02-08T03:13:28.644393: step 1783, loss 0.0778755, acc 0.96875
2020-02-08T03:13:28.760463: step 1784, loss 0.165405, acc 0.921875
2020-02-08T03:13:28.877403: step 1785, loss 0.0671752, acc 0.984375
2020-02-08T03:13:28.997181: step 1786, loss 0.13741, acc 0.90625
2020-02-08T03:13:29.113831: step 1787, loss 0.114273, acc 0.953125
2020-02-08T03:13:29.232879: step 1788, loss 0.0651135, acc 0.96875
2020-02-08T03:13:29.347926: step 1789, loss 0.124061, acc 0.953125
2020-02-08T03:13:29.464268: step 1790, loss 0.052763, acc 1
2020-02-08T03:13:29.581913: step 1791, loss 0.0833386, acc 0.96875
2020-02-08T03:13:29.695587: step 1792, loss 0.13387, acc 0.953125
2020-02-08T03:13:29.811650: step 1793, loss 0.142625, acc 0.953125
2020-02-08T03:13:29.930024: step 1794, loss 0.127432, acc 0.921875
2020-02-08T03:13:30.046657: step 1795, loss 0.0755415, acc 0.953125
2020-02-08T03:13:30.164286: step 1796, loss 0.109721, acc 0.984375
2020-02-08T03:13:30.281389: step 1797, loss 0.149521, acc 0.921875
2020-02-08T03:13:30.398368: step 1798, loss 0.157163, acc 0.921875
2020-02-08T03:13:30.514607: step 1799, loss 0.103725, acc 0.96875
2020-02-08T03:13:30.627332: step 1800, loss 0.0648989, acc 0.983333

Evaluation:
2020-02-08T03:13:30.814328: step 1800, loss 0.705238, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1800

2020-02-08T03:13:32.324148: step 1801, loss 0.0317483, acc 1
2020-02-08T03:13:32.439954: step 1802, loss 0.102378, acc 0.96875
2020-02-08T03:13:32.552629: step 1803, loss 0.133929, acc 0.953125
2020-02-08T03:13:32.665751: step 1804, loss 0.15094, acc 0.90625
2020-02-08T03:13:32.782689: step 1805, loss 0.079442, acc 0.96875
2020-02-08T03:13:32.900304: step 1806, loss 0.0602566, acc 0.984375
2020-02-08T03:13:33.017606: step 1807, loss 0.0372603, acc 1
2020-02-08T03:13:33.136273: step 1808, loss 0.132514, acc 0.96875
2020-02-08T03:13:33.250448: step 1809, loss 0.216983, acc 0.921875
2020-02-08T03:13:33.372411: step 1810, loss 0.0900981, acc 0.984375
2020-02-08T03:13:33.492769: step 1811, loss 0.0734886, acc 0.96875
2020-02-08T03:13:33.611365: step 1812, loss 0.0663354, acc 0.984375
2020-02-08T03:13:33.728683: step 1813, loss 0.0568684, acc 0.96875
2020-02-08T03:13:33.845375: step 1814, loss 0.060678, acc 0.984375
2020-02-08T03:13:33.962193: step 1815, loss 0.0841891, acc 0.984375
2020-02-08T03:13:34.081869: step 1816, loss 0.0517204, acc 1
2020-02-08T03:13:34.199420: step 1817, loss 0.0529975, acc 0.984375
2020-02-08T03:13:34.316722: step 1818, loss 0.0917833, acc 0.96875
2020-02-08T03:13:34.434740: step 1819, loss 0.139696, acc 0.96875
2020-02-08T03:13:34.550058: step 1820, loss 0.0653523, acc 0.984375
2020-02-08T03:13:34.664866: step 1821, loss 0.0411404, acc 0.984375
2020-02-08T03:13:34.780927: step 1822, loss 0.0625028, acc 0.984375
2020-02-08T03:13:34.897772: step 1823, loss 0.0729394, acc 0.96875
2020-02-08T03:13:35.015164: step 1824, loss 0.0749556, acc 0.96875
2020-02-08T03:13:35.132522: step 1825, loss 0.117275, acc 0.953125
2020-02-08T03:13:35.249731: step 1826, loss 0.0397206, acc 0.984375
2020-02-08T03:13:35.365078: step 1827, loss 0.0711479, acc 0.96875
2020-02-08T03:13:35.482611: step 1828, loss 0.024868, acc 1
2020-02-08T03:13:35.598878: step 1829, loss 0.128268, acc 0.9375
2020-02-08T03:13:35.714136: step 1830, loss 0.0539611, acc 0.96875
2020-02-08T03:13:35.832214: step 1831, loss 0.0964331, acc 0.96875
2020-02-08T03:13:35.947680: step 1832, loss 0.0529876, acc 0.984375
2020-02-08T03:13:36.063040: step 1833, loss 0.0456311, acc 0.984375
2020-02-08T03:13:36.182299: step 1834, loss 0.082059, acc 0.96875
2020-02-08T03:13:36.298871: step 1835, loss 0.0352957, acc 0.984375
2020-02-08T03:13:36.413125: step 1836, loss 0.0614978, acc 0.984375
2020-02-08T03:13:36.532606: step 1837, loss 0.089069, acc 0.96875
2020-02-08T03:13:36.648089: step 1838, loss 0.0780682, acc 0.953125
2020-02-08T03:13:36.765845: step 1839, loss 0.0815006, acc 0.96875
2020-02-08T03:13:36.883160: step 1840, loss 0.0777564, acc 0.96875
2020-02-08T03:13:36.997278: step 1841, loss 0.0948787, acc 0.953125
2020-02-08T03:13:37.115368: step 1842, loss 0.0401128, acc 1
2020-02-08T03:13:37.233938: step 1843, loss 0.107689, acc 0.953125
2020-02-08T03:13:37.351103: step 1844, loss 0.0396978, acc 1
2020-02-08T03:13:37.471346: step 1845, loss 0.0697024, acc 0.984375
2020-02-08T03:13:37.592236: step 1846, loss 0.0511388, acc 0.984375
2020-02-08T03:13:37.707451: step 1847, loss 0.0369615, acc 1
2020-02-08T03:13:37.823585: step 1848, loss 0.0922109, acc 0.953125
2020-02-08T03:13:37.940950: step 1849, loss 0.219912, acc 0.90625
2020-02-08T03:13:38.056326: step 1850, loss 0.0739734, acc 0.96875
2020-02-08T03:13:38.171311: step 1851, loss 0.0721873, acc 0.96875
2020-02-08T03:13:38.287253: step 1852, loss 0.0358514, acc 1
2020-02-08T03:13:38.399777: step 1853, loss 0.0389199, acc 1
2020-02-08T03:13:38.515192: step 1854, loss 0.0934445, acc 0.984375
2020-02-08T03:13:38.632493: step 1855, loss 0.125372, acc 0.984375
2020-02-08T03:13:38.748622: step 1856, loss 0.0787412, acc 0.96875
2020-02-08T03:13:38.862409: step 1857, loss 0.119478, acc 0.9375
2020-02-08T03:13:38.979714: step 1858, loss 0.0336247, acc 1
2020-02-08T03:13:39.099103: step 1859, loss 0.0848074, acc 0.953125
2020-02-08T03:13:39.215458: step 1860, loss 0.0874382, acc 0.96875
2020-02-08T03:13:39.330606: step 1861, loss 0.102507, acc 0.953125
2020-02-08T03:13:39.445671: step 1862, loss 0.094328, acc 0.953125
2020-02-08T03:13:39.561088: step 1863, loss 0.105421, acc 0.96875
2020-02-08T03:13:39.677204: step 1864, loss 0.0514956, acc 0.984375
2020-02-08T03:13:39.794701: step 1865, loss 0.0687837, acc 0.96875
2020-02-08T03:13:39.909805: step 1866, loss 0.0415566, acc 1
2020-02-08T03:13:40.030795: step 1867, loss 0.0918965, acc 0.953125
2020-02-08T03:13:40.148957: step 1868, loss 0.0914833, acc 0.96875
2020-02-08T03:13:40.264508: step 1869, loss 0.0305387, acc 1
2020-02-08T03:13:40.381362: step 1870, loss 0.0675301, acc 0.96875
2020-02-08T03:13:40.499254: step 1871, loss 0.0518289, acc 1
2020-02-08T03:13:40.615269: step 1872, loss 0.127577, acc 0.953125
2020-02-08T03:13:40.736259: step 1873, loss 0.105578, acc 0.96875
2020-02-08T03:13:40.852403: step 1874, loss 0.155369, acc 0.921875
2020-02-08T03:13:40.973450: step 1875, loss 0.0252009, acc 1
2020-02-08T03:13:41.093104: step 1876, loss 0.0977427, acc 0.96875
2020-02-08T03:13:41.208531: step 1877, loss 0.0515666, acc 0.96875
2020-02-08T03:13:41.326427: step 1878, loss 0.124022, acc 0.953125
2020-02-08T03:13:41.440481: step 1879, loss 0.0822571, acc 0.984375
2020-02-08T03:13:41.552658: step 1880, loss 0.0986914, acc 0.953125
2020-02-08T03:13:41.669975: step 1881, loss 0.131895, acc 0.953125
2020-02-08T03:13:41.785748: step 1882, loss 0.11268, acc 0.96875
2020-02-08T03:13:41.901062: step 1883, loss 0.0903322, acc 0.96875
2020-02-08T03:13:42.015316: step 1884, loss 0.0868786, acc 0.984375
2020-02-08T03:13:42.133614: step 1885, loss 0.140667, acc 0.953125
2020-02-08T03:13:42.248109: step 1886, loss 0.0308801, acc 0.984375
2020-02-08T03:13:42.368392: step 1887, loss 0.0935083, acc 0.953125
2020-02-08T03:13:42.486127: step 1888, loss 0.0800045, acc 0.96875
2020-02-08T03:13:42.604465: step 1889, loss 0.0617237, acc 0.984375
2020-02-08T03:13:42.721843: step 1890, loss 0.148453, acc 0.953125
2020-02-08T03:13:42.835192: step 1891, loss 0.1171, acc 0.953125
2020-02-08T03:13:42.949270: step 1892, loss 0.100797, acc 0.96875
2020-02-08T03:13:43.066163: step 1893, loss 0.140259, acc 0.9375
2020-02-08T03:13:43.180492: step 1894, loss 0.127123, acc 0.953125
2020-02-08T03:13:43.298992: step 1895, loss 0.0508472, acc 1
2020-02-08T03:13:43.414659: step 1896, loss 0.112987, acc 0.953125
2020-02-08T03:13:43.531760: step 1897, loss 0.0336351, acc 1
2020-02-08T03:13:43.647300: step 1898, loss 0.0558755, acc 0.984375
2020-02-08T03:13:43.764395: step 1899, loss 0.0955189, acc 0.96875
2020-02-08T03:13:43.885270: step 1900, loss 0.0826867, acc 0.96875

Evaluation:
2020-02-08T03:13:44.075023: step 1900, loss 0.732845, acc 0.737336

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-1900

2020-02-08T03:13:45.618485: step 1901, loss 0.032828, acc 0.984375
2020-02-08T03:13:45.734712: step 1902, loss 0.0987641, acc 0.96875
2020-02-08T03:13:45.852581: step 1903, loss 0.102785, acc 0.96875
2020-02-08T03:13:45.971567: step 1904, loss 0.0359607, acc 0.984375
2020-02-08T03:13:46.088615: step 1905, loss 0.0827024, acc 0.96875
2020-02-08T03:13:46.203271: step 1906, loss 0.0726656, acc 0.984375
2020-02-08T03:13:46.321353: step 1907, loss 0.127109, acc 0.921875
2020-02-08T03:13:46.440673: step 1908, loss 0.0649067, acc 0.96875
2020-02-08T03:13:46.554477: step 1909, loss 0.0384592, acc 1
2020-02-08T03:13:46.671589: step 1910, loss 0.0296226, acc 1
2020-02-08T03:13:46.789441: step 1911, loss 0.10464, acc 0.96875
2020-02-08T03:13:46.905924: step 1912, loss 0.0995916, acc 0.96875
2020-02-08T03:13:47.022996: step 1913, loss 0.115222, acc 0.96875
2020-02-08T03:13:47.141426: step 1914, loss 0.121368, acc 0.953125
2020-02-08T03:13:47.256624: step 1915, loss 0.116557, acc 0.953125
2020-02-08T03:13:47.375478: step 1916, loss 0.130343, acc 0.953125
2020-02-08T03:13:47.492440: step 1917, loss 0.103942, acc 0.953125
2020-02-08T03:13:47.611748: step 1918, loss 0.0751611, acc 0.96875
2020-02-08T03:13:47.729523: step 1919, loss 0.0877414, acc 0.984375
2020-02-08T03:13:47.849437: step 1920, loss 0.123064, acc 0.953125
2020-02-08T03:13:47.969168: step 1921, loss 0.12597, acc 0.96875
2020-02-08T03:13:48.089111: step 1922, loss 0.103851, acc 0.953125
2020-02-08T03:13:48.205498: step 1923, loss 0.104158, acc 0.9375
2020-02-08T03:13:48.323826: step 1924, loss 0.0700701, acc 0.96875
2020-02-08T03:13:48.440791: step 1925, loss 0.0737743, acc 0.96875
2020-02-08T03:13:48.557030: step 1926, loss 0.0499009, acc 1
2020-02-08T03:13:48.672664: step 1927, loss 0.0316979, acc 1
2020-02-08T03:13:48.790160: step 1928, loss 0.105945, acc 0.9375
2020-02-08T03:13:48.905512: step 1929, loss 0.123827, acc 0.984375
2020-02-08T03:13:49.023301: step 1930, loss 0.0403727, acc 1
2020-02-08T03:13:49.140425: step 1931, loss 0.0972158, acc 0.96875
2020-02-08T03:13:49.256135: step 1932, loss 0.0908273, acc 0.984375
2020-02-08T03:13:49.370977: step 1933, loss 0.201503, acc 0.96875
2020-02-08T03:13:49.486252: step 1934, loss 0.140247, acc 0.96875
2020-02-08T03:13:49.601122: step 1935, loss 0.0902499, acc 0.953125
2020-02-08T03:13:49.716925: step 1936, loss 0.0823134, acc 0.96875
2020-02-08T03:13:49.831809: step 1937, loss 0.0476261, acc 0.984375
2020-02-08T03:13:49.949657: step 1938, loss 0.0979673, acc 0.953125
2020-02-08T03:13:50.067163: step 1939, loss 0.141269, acc 0.953125
2020-02-08T03:13:50.182435: step 1940, loss 0.0800024, acc 0.984375
2020-02-08T03:13:50.297225: step 1941, loss 0.125911, acc 0.953125
2020-02-08T03:13:50.413319: step 1942, loss 0.0636396, acc 0.96875
2020-02-08T03:13:50.526381: step 1943, loss 0.077041, acc 0.984375
2020-02-08T03:13:50.641733: step 1944, loss 0.0710742, acc 0.96875
2020-02-08T03:13:50.757528: step 1945, loss 0.108198, acc 0.953125
2020-02-08T03:13:50.876254: step 1946, loss 0.138301, acc 0.921875
2020-02-08T03:13:50.992914: step 1947, loss 0.070285, acc 0.96875
2020-02-08T03:13:51.112313: step 1948, loss 0.0659245, acc 0.984375
2020-02-08T03:13:51.231970: step 1949, loss 0.0598489, acc 0.984375
2020-02-08T03:13:51.347127: step 1950, loss 0.0874481, acc 0.983333
2020-02-08T03:13:51.464276: step 1951, loss 0.0473798, acc 0.984375
2020-02-08T03:13:51.705053: step 1952, loss 0.0639814, acc 0.96875
2020-02-08T03:13:51.827079: step 1953, loss 0.0510958, acc 0.96875
2020-02-08T03:13:51.947888: step 1954, loss 0.0892207, acc 0.984375
2020-02-08T03:13:52.065040: step 1955, loss 0.0470755, acc 0.984375
2020-02-08T03:13:52.183623: step 1956, loss 0.0804592, acc 0.984375
2020-02-08T03:13:52.302714: step 1957, loss 0.0340568, acc 1
2020-02-08T03:13:52.419099: step 1958, loss 0.0786125, acc 0.984375
2020-02-08T03:13:52.535069: step 1959, loss 0.092293, acc 0.96875
2020-02-08T03:13:52.651517: step 1960, loss 0.0809937, acc 0.96875
2020-02-08T03:13:52.768493: step 1961, loss 0.0940469, acc 0.96875
2020-02-08T03:13:52.885906: step 1962, loss 0.0519125, acc 0.984375
2020-02-08T03:13:53.001159: step 1963, loss 0.149145, acc 0.96875
2020-02-08T03:13:53.121370: step 1964, loss 0.056734, acc 0.984375
2020-02-08T03:13:53.236385: step 1965, loss 0.0717299, acc 0.96875
2020-02-08T03:13:53.354582: step 1966, loss 0.0259622, acc 1
2020-02-08T03:13:53.470306: step 1967, loss 0.0366894, acc 0.984375
2020-02-08T03:13:53.588755: step 1968, loss 0.0382439, acc 0.984375
2020-02-08T03:13:53.706628: step 1969, loss 0.067362, acc 0.984375
2020-02-08T03:13:53.820508: step 1970, loss 0.0491087, acc 0.984375
2020-02-08T03:13:53.937785: step 1971, loss 0.0766841, acc 0.96875
2020-02-08T03:13:54.052466: step 1972, loss 0.0381612, acc 0.984375
2020-02-08T03:13:54.167230: step 1973, loss 0.061341, acc 0.984375
2020-02-08T03:13:54.285002: step 1974, loss 0.0341213, acc 0.984375
2020-02-08T03:13:54.402214: step 1975, loss 0.0937026, acc 0.96875
2020-02-08T03:13:54.521371: step 1976, loss 0.0127946, acc 1
2020-02-08T03:13:54.637951: step 1977, loss 0.0812963, acc 0.96875
2020-02-08T03:13:54.755127: step 1978, loss 0.107892, acc 0.953125
2020-02-08T03:13:54.871283: step 1979, loss 0.0764095, acc 0.984375
2020-02-08T03:13:54.986460: step 1980, loss 0.0707995, acc 0.96875
2020-02-08T03:13:55.102664: step 1981, loss 0.0457219, acc 0.984375
2020-02-08T03:13:55.217210: step 1982, loss 0.0339735, acc 1
2020-02-08T03:13:55.333680: step 1983, loss 0.019211, acc 1
2020-02-08T03:13:55.450300: step 1984, loss 0.0576359, acc 0.953125
2020-02-08T03:13:55.565951: step 1985, loss 0.0656318, acc 0.96875
2020-02-08T03:13:55.683661: step 1986, loss 0.131701, acc 0.921875
2020-02-08T03:13:55.800337: step 1987, loss 0.0318717, acc 1
2020-02-08T03:13:55.915966: step 1988, loss 0.0845403, acc 0.984375
2020-02-08T03:13:56.036213: step 1989, loss 0.0210871, acc 1
2020-02-08T03:13:56.151536: step 1990, loss 0.075225, acc 0.96875
2020-02-08T03:13:56.269612: step 1991, loss 0.033629, acc 1
2020-02-08T03:13:56.387935: step 1992, loss 0.0215535, acc 1
2020-02-08T03:13:56.503806: step 1993, loss 0.0429117, acc 0.984375
2020-02-08T03:13:56.622084: step 1994, loss 0.0556368, acc 0.984375
2020-02-08T03:13:56.737167: step 1995, loss 0.0547223, acc 0.96875
2020-02-08T03:13:56.853045: step 1996, loss 0.0451947, acc 0.984375
2020-02-08T03:13:56.970582: step 1997, loss 0.0392724, acc 1
2020-02-08T03:13:57.086407: step 1998, loss 0.0511403, acc 1
2020-02-08T03:13:57.204911: step 1999, loss 0.119573, acc 0.96875
2020-02-08T03:13:57.323086: step 2000, loss 0.0351996, acc 1

Evaluation:
2020-02-08T03:13:57.512687: step 2000, loss 0.758257, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2000

2020-02-08T03:13:59.059194: step 2001, loss 0.0820547, acc 0.96875
2020-02-08T03:13:59.178799: step 2002, loss 0.148854, acc 0.9375
2020-02-08T03:13:59.299018: step 2003, loss 0.0656638, acc 0.984375
2020-02-08T03:13:59.418200: step 2004, loss 0.0443436, acc 1
2020-02-08T03:13:59.535688: step 2005, loss 0.127911, acc 0.9375
2020-02-08T03:13:59.652111: step 2006, loss 0.132825, acc 0.96875
2020-02-08T03:13:59.774665: step 2007, loss 0.0445137, acc 0.984375
2020-02-08T03:13:59.894537: step 2008, loss 0.0423777, acc 0.984375
2020-02-08T03:14:00.011746: step 2009, loss 0.113786, acc 0.953125
2020-02-08T03:14:00.130725: step 2010, loss 0.0337466, acc 0.984375
2020-02-08T03:14:00.248298: step 2011, loss 0.0502923, acc 0.984375
2020-02-08T03:14:00.363642: step 2012, loss 0.0528969, acc 1
2020-02-08T03:14:00.479667: step 2013, loss 0.0808157, acc 0.953125
2020-02-08T03:14:00.594123: step 2014, loss 0.0732473, acc 0.984375
2020-02-08T03:14:00.709162: step 2015, loss 0.164373, acc 0.9375
2020-02-08T03:14:00.825308: step 2016, loss 0.122863, acc 0.9375
2020-02-08T03:14:00.944487: step 2017, loss 0.0517826, acc 1
2020-02-08T03:14:01.057510: step 2018, loss 0.0786461, acc 0.953125
2020-02-08T03:14:01.176469: step 2019, loss 0.119569, acc 0.953125
2020-02-08T03:14:01.294711: step 2020, loss 0.165137, acc 0.96875
2020-02-08T03:14:01.410734: step 2021, loss 0.124775, acc 0.953125
2020-02-08T03:14:01.527911: step 2022, loss 0.035946, acc 1
2020-02-08T03:14:01.644537: step 2023, loss 0.0384521, acc 0.984375
2020-02-08T03:14:01.759653: step 2024, loss 0.0415359, acc 0.984375
2020-02-08T03:14:01.878886: step 2025, loss 0.0569773, acc 0.96875
2020-02-08T03:14:01.994774: step 2026, loss 0.0359568, acc 0.984375
2020-02-08T03:14:02.109197: step 2027, loss 0.119115, acc 0.953125
2020-02-08T03:14:02.228054: step 2028, loss 0.151483, acc 0.921875
2020-02-08T03:14:02.345619: step 2029, loss 0.0420135, acc 1
2020-02-08T03:14:02.462500: step 2030, loss 0.034216, acc 0.984375
2020-02-08T03:14:02.577835: step 2031, loss 0.0343915, acc 0.984375
2020-02-08T03:14:02.694288: step 2032, loss 0.0414036, acc 0.984375
2020-02-08T03:14:02.808874: step 2033, loss 0.0934724, acc 0.96875
2020-02-08T03:14:02.925487: step 2034, loss 0.128679, acc 0.9375
2020-02-08T03:14:03.043428: step 2035, loss 0.140218, acc 0.953125
2020-02-08T03:14:03.160777: step 2036, loss 0.0461184, acc 1
2020-02-08T03:14:03.280521: step 2037, loss 0.117119, acc 0.96875
2020-02-08T03:14:03.397670: step 2038, loss 0.0767537, acc 0.953125
2020-02-08T03:14:03.511453: step 2039, loss 0.0811777, acc 0.96875
2020-02-08T03:14:03.627344: step 2040, loss 0.0164854, acc 1
2020-02-08T03:14:03.741803: step 2041, loss 0.100624, acc 0.984375
2020-02-08T03:14:03.857942: step 2042, loss 0.0594436, acc 1
2020-02-08T03:14:03.975388: step 2043, loss 0.0373597, acc 0.984375
2020-02-08T03:14:04.092499: step 2044, loss 0.0865633, acc 0.96875
2020-02-08T03:14:04.209521: step 2045, loss 0.115733, acc 0.984375
2020-02-08T03:14:04.326319: step 2046, loss 0.0642252, acc 0.984375
2020-02-08T03:14:04.442669: step 2047, loss 0.0393338, acc 0.984375
2020-02-08T03:14:04.558764: step 2048, loss 0.042451, acc 1
2020-02-08T03:14:04.676894: step 2049, loss 0.0468254, acc 0.984375
2020-02-08T03:14:04.795538: step 2050, loss 0.0232497, acc 1
2020-02-08T03:14:04.910498: step 2051, loss 0.0809334, acc 0.984375
2020-02-08T03:14:05.027963: step 2052, loss 0.103676, acc 0.984375
2020-02-08T03:14:05.144718: step 2053, loss 0.126618, acc 0.953125
2020-02-08T03:14:05.257995: step 2054, loss 0.116192, acc 0.96875
2020-02-08T03:14:05.373802: step 2055, loss 0.128232, acc 0.953125
2020-02-08T03:14:05.492071: step 2056, loss 0.0727811, acc 0.984375
2020-02-08T03:14:05.606004: step 2057, loss 0.0373092, acc 0.984375
2020-02-08T03:14:05.723788: step 2058, loss 0.0545243, acc 0.984375
2020-02-08T03:14:05.839460: step 2059, loss 0.0760554, acc 0.984375
2020-02-08T03:14:05.954369: step 2060, loss 0.065231, acc 0.96875
2020-02-08T03:14:06.074906: step 2061, loss 0.0294632, acc 1
2020-02-08T03:14:06.191746: step 2062, loss 0.0400084, acc 0.984375
2020-02-08T03:14:06.307081: step 2063, loss 0.0453611, acc 0.96875
2020-02-08T03:14:06.424453: step 2064, loss 0.06103, acc 0.984375
2020-02-08T03:14:06.538384: step 2065, loss 0.0646266, acc 0.984375
2020-02-08T03:14:06.652416: step 2066, loss 0.096039, acc 0.953125
2020-02-08T03:14:06.769115: step 2067, loss 0.169537, acc 0.953125
2020-02-08T03:14:06.885109: step 2068, loss 0.0606833, acc 0.984375
2020-02-08T03:14:07.004907: step 2069, loss 0.108843, acc 0.953125
2020-02-08T03:14:07.120102: step 2070, loss 0.0720569, acc 0.96875
2020-02-08T03:14:07.235537: step 2071, loss 0.0538689, acc 0.984375
2020-02-08T03:14:07.351859: step 2072, loss 0.0871915, acc 0.96875
2020-02-08T03:14:07.468368: step 2073, loss 0.0955704, acc 0.984375
2020-02-08T03:14:07.586517: step 2074, loss 0.0266517, acc 1
2020-02-08T03:14:07.704592: step 2075, loss 0.0424232, acc 0.96875
2020-02-08T03:14:07.819271: step 2076, loss 0.0300766, acc 1
2020-02-08T03:14:07.936022: step 2077, loss 0.0734099, acc 0.953125
2020-02-08T03:14:08.054242: step 2078, loss 0.0761831, acc 0.96875
2020-02-08T03:14:08.172758: step 2079, loss 0.15226, acc 0.96875
2020-02-08T03:14:08.288699: step 2080, loss 0.14322, acc 0.921875
2020-02-08T03:14:08.404878: step 2081, loss 0.0943349, acc 0.953125
2020-02-08T03:14:08.523853: step 2082, loss 0.0650093, acc 0.984375
2020-02-08T03:14:08.642138: step 2083, loss 0.145965, acc 0.96875
2020-02-08T03:14:08.758305: step 2084, loss 0.0810362, acc 0.96875
2020-02-08T03:14:08.875904: step 2085, loss 0.033719, acc 1
2020-02-08T03:14:08.991545: step 2086, loss 0.0362734, acc 1
2020-02-08T03:14:09.107920: step 2087, loss 0.0833678, acc 0.96875
2020-02-08T03:14:09.225999: step 2088, loss 0.0678208, acc 0.96875
2020-02-08T03:14:09.340468: step 2089, loss 0.060059, acc 0.96875
2020-02-08T03:14:09.457448: step 2090, loss 0.0191654, acc 1
2020-02-08T03:14:09.575305: step 2091, loss 0.0848943, acc 0.953125
2020-02-08T03:14:09.691602: step 2092, loss 0.0285858, acc 1
2020-02-08T03:14:09.807695: step 2093, loss 0.0281668, acc 1
2020-02-08T03:14:09.924017: step 2094, loss 0.104003, acc 0.96875
2020-02-08T03:14:10.038897: step 2095, loss 0.0703253, acc 0.96875
2020-02-08T03:14:10.155323: step 2096, loss 0.0906236, acc 0.96875
2020-02-08T03:14:10.270444: step 2097, loss 0.0283942, acc 1
2020-02-08T03:14:10.385471: step 2098, loss 0.0936118, acc 0.953125
2020-02-08T03:14:10.501930: step 2099, loss 0.07175, acc 0.984375
2020-02-08T03:14:10.611958: step 2100, loss 0.081888, acc 0.983333

Evaluation:
2020-02-08T03:14:10.799828: step 2100, loss 0.780522, acc 0.741088

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2100

2020-02-08T03:14:12.334921: step 2101, loss 0.0330202, acc 1
2020-02-08T03:14:12.450210: step 2102, loss 0.0363742, acc 1
2020-02-08T03:14:12.565902: step 2103, loss 0.0489754, acc 0.984375
2020-02-08T03:14:12.680659: step 2104, loss 0.0295869, acc 1
2020-02-08T03:14:12.798029: step 2105, loss 0.0280848, acc 1
2020-02-08T03:14:12.912543: step 2106, loss 0.06969, acc 0.96875
2020-02-08T03:14:13.027459: step 2107, loss 0.0363223, acc 0.984375
2020-02-08T03:14:13.144641: step 2108, loss 0.0314762, acc 1
2020-02-08T03:14:13.262020: step 2109, loss 0.0169653, acc 1
2020-02-08T03:14:13.378244: step 2110, loss 0.0376117, acc 0.984375
2020-02-08T03:14:13.493026: step 2111, loss 0.0736846, acc 0.96875
2020-02-08T03:14:13.607067: step 2112, loss 0.0359828, acc 0.984375
2020-02-08T03:14:13.724487: step 2113, loss 0.0377925, acc 0.984375
2020-02-08T03:14:13.841154: step 2114, loss 0.0394542, acc 0.984375
2020-02-08T03:14:13.957484: step 2115, loss 0.164245, acc 0.9375
2020-02-08T03:14:14.073653: step 2116, loss 0.0757077, acc 0.984375
2020-02-08T03:14:14.191293: step 2117, loss 0.0384697, acc 0.984375
2020-02-08T03:14:14.310547: step 2118, loss 0.0234404, acc 1
2020-02-08T03:14:14.428498: step 2119, loss 0.0341043, acc 0.984375
2020-02-08T03:14:14.546807: step 2120, loss 0.0366014, acc 0.984375
2020-02-08T03:14:14.664710: step 2121, loss 0.0335081, acc 0.984375
2020-02-08T03:14:14.781002: step 2122, loss 0.0212587, acc 1
2020-02-08T03:14:14.897994: step 2123, loss 0.0449068, acc 1
2020-02-08T03:14:15.013046: step 2124, loss 0.0628449, acc 0.984375
2020-02-08T03:14:15.126619: step 2125, loss 0.0146819, acc 1
2020-02-08T03:14:15.243561: step 2126, loss 0.0265928, acc 1
2020-02-08T03:14:15.358031: step 2127, loss 0.0446666, acc 1
2020-02-08T03:14:15.475062: step 2128, loss 0.0297081, acc 1
2020-02-08T03:14:15.596628: step 2129, loss 0.0220907, acc 1
2020-02-08T03:14:15.716127: step 2130, loss 0.0342792, acc 0.984375
2020-02-08T03:14:15.832915: step 2131, loss 0.127321, acc 0.984375
2020-02-08T03:14:15.948741: step 2132, loss 0.0348426, acc 1
2020-02-08T03:14:16.066925: step 2133, loss 0.0362946, acc 0.984375
2020-02-08T03:14:16.185194: step 2134, loss 0.040027, acc 0.984375
2020-02-08T03:14:16.301931: step 2135, loss 0.0178619, acc 1
2020-02-08T03:14:16.418466: step 2136, loss 0.0463722, acc 1
2020-02-08T03:14:16.537200: step 2137, loss 0.0243878, acc 1
2020-02-08T03:14:16.654680: step 2138, loss 0.073397, acc 0.984375
2020-02-08T03:14:16.775586: step 2139, loss 0.0681118, acc 0.984375
2020-02-08T03:14:16.892960: step 2140, loss 0.0833521, acc 0.984375
2020-02-08T03:14:17.009558: step 2141, loss 0.0346977, acc 0.984375
2020-02-08T03:14:17.130320: step 2142, loss 0.0376203, acc 0.984375
2020-02-08T03:14:17.248112: step 2143, loss 0.0533768, acc 0.984375
2020-02-08T03:14:17.367698: step 2144, loss 0.0104616, acc 1
2020-02-08T03:14:17.486067: step 2145, loss 0.040543, acc 0.984375
2020-02-08T03:14:17.601564: step 2146, loss 0.040892, acc 0.984375
2020-02-08T03:14:17.718865: step 2147, loss 0.103909, acc 0.96875
2020-02-08T03:14:17.834423: step 2148, loss 0.0815534, acc 0.96875
2020-02-08T03:14:17.951465: step 2149, loss 0.0495178, acc 0.984375
2020-02-08T03:14:18.070233: step 2150, loss 0.0206862, acc 1
2020-02-08T03:14:18.186771: step 2151, loss 0.0740188, acc 0.96875
2020-02-08T03:14:18.300826: step 2152, loss 0.021757, acc 0.984375
2020-02-08T03:14:18.418557: step 2153, loss 0.0436921, acc 0.96875
2020-02-08T03:14:18.542158: step 2154, loss 0.0217573, acc 1
2020-02-08T03:14:18.659751: step 2155, loss 0.0727641, acc 0.953125
2020-02-08T03:14:18.775066: step 2156, loss 0.0289066, acc 1
2020-02-08T03:14:18.892971: step 2157, loss 0.125266, acc 0.953125
2020-02-08T03:14:19.009923: step 2158, loss 0.0624329, acc 0.984375
2020-02-08T03:14:19.128989: step 2159, loss 0.062385, acc 0.96875
2020-02-08T03:14:19.247551: step 2160, loss 0.0247877, acc 1
2020-02-08T03:14:19.366642: step 2161, loss 0.0384493, acc 0.984375
2020-02-08T03:14:19.483941: step 2162, loss 0.102718, acc 0.953125
2020-02-08T03:14:19.601449: step 2163, loss 0.0785981, acc 0.96875
2020-02-08T03:14:19.718488: step 2164, loss 0.0333354, acc 1
2020-02-08T03:14:19.835374: step 2165, loss 0.0797923, acc 0.96875
2020-02-08T03:14:19.951828: step 2166, loss 0.111845, acc 0.953125
2020-02-08T03:14:20.067238: step 2167, loss 0.0426734, acc 0.984375
2020-02-08T03:14:20.183177: step 2168, loss 0.087389, acc 0.96875
2020-02-08T03:14:20.298593: step 2169, loss 0.0495995, acc 0.96875
2020-02-08T03:14:20.415283: step 2170, loss 0.0806421, acc 0.96875
2020-02-08T03:14:20.534423: step 2171, loss 0.0252934, acc 1
2020-02-08T03:14:20.649823: step 2172, loss 0.0637252, acc 0.984375
2020-02-08T03:14:20.769532: step 2173, loss 0.135587, acc 0.953125
2020-02-08T03:14:20.887403: step 2174, loss 0.068001, acc 0.96875
2020-02-08T03:14:21.003105: step 2175, loss 0.0838922, acc 0.96875
2020-02-08T03:14:21.121715: step 2176, loss 0.0118316, acc 1
2020-02-08T03:14:21.238817: step 2177, loss 0.0956866, acc 0.96875
2020-02-08T03:14:21.637802: step 2178, loss 0.0291597, acc 1
2020-02-08T03:14:21.758024: step 2179, loss 0.0148042, acc 1
2020-02-08T03:14:21.877334: step 2180, loss 0.0366171, acc 1
2020-02-08T03:14:21.995081: step 2181, loss 0.0248831, acc 1
2020-02-08T03:14:22.113398: step 2182, loss 0.0262837, acc 1
2020-02-08T03:14:22.231864: step 2183, loss 0.112463, acc 0.96875
2020-02-08T03:14:22.348238: step 2184, loss 0.0508637, acc 0.96875
2020-02-08T03:14:22.465554: step 2185, loss 0.0396521, acc 1
2020-02-08T03:14:22.583374: step 2186, loss 0.040897, acc 1
2020-02-08T03:14:22.699834: step 2187, loss 0.0345426, acc 1
2020-02-08T03:14:22.816753: step 2188, loss 0.0733681, acc 0.96875
2020-02-08T03:14:22.935524: step 2189, loss 0.0283102, acc 1
2020-02-08T03:14:23.052320: step 2190, loss 0.0358752, acc 0.984375
2020-02-08T03:14:23.170519: step 2191, loss 0.0947257, acc 0.953125
2020-02-08T03:14:23.286717: step 2192, loss 0.0209137, acc 1
2020-02-08T03:14:23.404070: step 2193, loss 0.0821632, acc 0.953125
2020-02-08T03:14:23.521426: step 2194, loss 0.0362998, acc 1
2020-02-08T03:14:23.639359: step 2195, loss 0.0467646, acc 0.984375
2020-02-08T03:14:23.755681: step 2196, loss 0.117191, acc 0.984375
2020-02-08T03:14:23.873118: step 2197, loss 0.0331063, acc 1
2020-02-08T03:14:23.989157: step 2198, loss 0.0309848, acc 1
2020-02-08T03:14:24.104315: step 2199, loss 0.0425255, acc 0.984375
2020-02-08T03:14:24.219431: step 2200, loss 0.0571735, acc 0.984375

Evaluation:
2020-02-08T03:14:24.406103: step 2200, loss 0.813577, acc 0.738274

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2200

2020-02-08T03:14:25.902538: step 2201, loss 0.00973304, acc 1
2020-02-08T03:14:26.024160: step 2202, loss 0.0819581, acc 0.96875
2020-02-08T03:14:26.140996: step 2203, loss 0.081152, acc 0.984375
2020-02-08T03:14:26.256139: step 2204, loss 0.0367732, acc 1
2020-02-08T03:14:26.373828: step 2205, loss 0.00752993, acc 1
2020-02-08T03:14:26.490564: step 2206, loss 0.0890742, acc 0.96875
2020-02-08T03:14:26.605152: step 2207, loss 0.138788, acc 0.921875
2020-02-08T03:14:26.722666: step 2208, loss 0.0635857, acc 0.984375
2020-02-08T03:14:26.838909: step 2209, loss 0.140662, acc 0.9375
2020-02-08T03:14:26.952226: step 2210, loss 0.0339872, acc 0.984375
2020-02-08T03:14:27.073323: step 2211, loss 0.0541801, acc 0.984375
2020-02-08T03:14:27.194546: step 2212, loss 0.0716871, acc 0.96875
2020-02-08T03:14:27.310851: step 2213, loss 0.0287066, acc 1
2020-02-08T03:14:27.433225: step 2214, loss 0.0379746, acc 1
2020-02-08T03:14:27.551778: step 2215, loss 0.145997, acc 0.953125
2020-02-08T03:14:27.666906: step 2216, loss 0.0556007, acc 0.984375
2020-02-08T03:14:27.784340: step 2217, loss 0.0666667, acc 0.96875
2020-02-08T03:14:27.899392: step 2218, loss 0.0298255, acc 0.984375
2020-02-08T03:14:28.017757: step 2219, loss 0.101249, acc 0.9375
2020-02-08T03:14:28.133737: step 2220, loss 0.0891338, acc 0.984375
2020-02-08T03:14:28.249288: step 2221, loss 0.062084, acc 1
2020-02-08T03:14:28.367309: step 2222, loss 0.109674, acc 0.953125
2020-02-08T03:14:28.485209: step 2223, loss 0.0549396, acc 0.984375
2020-02-08T03:14:28.602066: step 2224, loss 0.041882, acc 0.984375
2020-02-08T03:14:28.720795: step 2225, loss 0.0782745, acc 0.953125
2020-02-08T03:14:28.840279: step 2226, loss 0.0244155, acc 0.984375
2020-02-08T03:14:28.955166: step 2227, loss 0.0437999, acc 0.984375
2020-02-08T03:14:29.075328: step 2228, loss 0.0250983, acc 1
2020-02-08T03:14:29.194616: step 2229, loss 0.042057, acc 0.984375
2020-02-08T03:14:29.310921: step 2230, loss 0.0593904, acc 0.96875
2020-02-08T03:14:29.426637: step 2231, loss 0.0940743, acc 0.96875
2020-02-08T03:14:29.543302: step 2232, loss 0.0873737, acc 0.96875
2020-02-08T03:14:29.658058: step 2233, loss 0.0357417, acc 0.984375
2020-02-08T03:14:29.775641: step 2234, loss 0.133352, acc 0.953125
2020-02-08T03:14:29.893325: step 2235, loss 0.037347, acc 0.984375
2020-02-08T03:14:30.009230: step 2236, loss 0.0251712, acc 1
2020-02-08T03:14:30.128428: step 2237, loss 0.0804681, acc 0.9375
2020-02-08T03:14:30.251796: step 2238, loss 0.0665874, acc 0.96875
2020-02-08T03:14:30.373255: step 2239, loss 0.0377144, acc 1
2020-02-08T03:14:30.488456: step 2240, loss 0.0618918, acc 0.96875
2020-02-08T03:14:30.605740: step 2241, loss 0.0394954, acc 0.984375
2020-02-08T03:14:30.731026: step 2242, loss 0.061346, acc 0.96875
2020-02-08T03:14:30.846004: step 2243, loss 0.065577, acc 0.96875
2020-02-08T03:14:30.963443: step 2244, loss 0.0194766, acc 1
2020-02-08T03:14:31.083622: step 2245, loss 0.0156449, acc 1
2020-02-08T03:14:31.203574: step 2246, loss 0.0837472, acc 0.953125
2020-02-08T03:14:31.320125: step 2247, loss 0.0581324, acc 0.96875
2020-02-08T03:14:31.438280: step 2248, loss 0.106767, acc 0.96875
2020-02-08T03:14:31.555584: step 2249, loss 0.0491118, acc 0.96875
2020-02-08T03:14:31.665690: step 2250, loss 0.0385008, acc 0.983333
2020-02-08T03:14:31.786923: step 2251, loss 0.0263269, acc 1
2020-02-08T03:14:31.903666: step 2252, loss 0.0736504, acc 0.984375
2020-02-08T03:14:32.021325: step 2253, loss 0.0258345, acc 0.984375
2020-02-08T03:14:32.139691: step 2254, loss 0.0729841, acc 0.96875
2020-02-08T03:14:32.257723: step 2255, loss 0.0111173, acc 1
2020-02-08T03:14:32.375951: step 2256, loss 0.124312, acc 0.96875
2020-02-08T03:14:32.492415: step 2257, loss 0.0284417, acc 0.984375
2020-02-08T03:14:32.608176: step 2258, loss 0.0341648, acc 1
2020-02-08T03:14:32.724316: step 2259, loss 0.0806464, acc 0.984375
2020-02-08T03:14:32.843060: step 2260, loss 0.0148894, acc 1
2020-02-08T03:14:32.987123: step 2261, loss 0.100489, acc 0.921875
2020-02-08T03:14:33.121309: step 2262, loss 0.100141, acc 0.953125
2020-02-08T03:14:33.240760: step 2263, loss 0.0128665, acc 1
2020-02-08T03:14:33.357271: step 2264, loss 0.0231042, acc 1
2020-02-08T03:14:33.474573: step 2265, loss 0.0178221, acc 0.984375
2020-02-08T03:14:33.593354: step 2266, loss 0.0249233, acc 1
2020-02-08T03:14:33.708119: step 2267, loss 0.0707252, acc 0.984375
2020-02-08T03:14:33.825436: step 2268, loss 0.0355268, acc 0.984375
2020-02-08T03:14:33.942146: step 2269, loss 0.0645153, acc 0.96875
2020-02-08T03:14:34.056642: step 2270, loss 0.049404, acc 0.984375
2020-02-08T03:14:34.173977: step 2271, loss 0.100605, acc 0.953125
2020-02-08T03:14:34.290742: step 2272, loss 0.0117016, acc 1
2020-02-08T03:14:34.407090: step 2273, loss 0.0540168, acc 0.984375
2020-02-08T03:14:34.521730: step 2274, loss 0.0660515, acc 0.96875
2020-02-08T03:14:34.643251: step 2275, loss 0.0184154, acc 1
2020-02-08T03:14:34.762027: step 2276, loss 0.0414727, acc 0.96875
2020-02-08T03:14:34.880489: step 2277, loss 0.110742, acc 0.953125
2020-02-08T03:14:34.997150: step 2278, loss 0.0206449, acc 1
2020-02-08T03:14:35.113745: step 2279, loss 0.0399821, acc 0.984375
2020-02-08T03:14:35.231965: step 2280, loss 0.037113, acc 1
2020-02-08T03:14:35.347839: step 2281, loss 0.0406233, acc 0.984375
2020-02-08T03:14:35.462276: step 2282, loss 0.0655945, acc 0.96875
2020-02-08T03:14:35.581025: step 2283, loss 0.0218611, acc 1
2020-02-08T03:14:35.697808: step 2284, loss 0.0267556, acc 1
2020-02-08T03:14:35.813634: step 2285, loss 0.0539457, acc 0.984375
2020-02-08T03:14:35.932116: step 2286, loss 0.0768685, acc 0.96875
2020-02-08T03:14:36.052473: step 2287, loss 0.0422009, acc 0.984375
2020-02-08T03:14:36.168982: step 2288, loss 0.0472448, acc 0.984375
2020-02-08T03:14:36.287182: step 2289, loss 0.0915975, acc 0.953125
2020-02-08T03:14:36.403095: step 2290, loss 0.046437, acc 0.984375
2020-02-08T03:14:36.522165: step 2291, loss 0.0529508, acc 0.96875
2020-02-08T03:14:36.638952: step 2292, loss 0.0806642, acc 0.984375
2020-02-08T03:14:36.753012: step 2293, loss 0.0286905, acc 1
2020-02-08T03:14:36.870823: step 2294, loss 0.0341896, acc 1
2020-02-08T03:14:36.991879: step 2295, loss 0.0497183, acc 0.984375
2020-02-08T03:14:37.108552: step 2296, loss 0.0341064, acc 1
2020-02-08T03:14:37.227800: step 2297, loss 0.0302529, acc 0.984375
2020-02-08T03:14:37.347713: step 2298, loss 0.0489513, acc 0.984375
2020-02-08T03:14:37.462449: step 2299, loss 0.0436747, acc 0.984375
2020-02-08T03:14:37.581313: step 2300, loss 0.0192223, acc 1

Evaluation:
2020-02-08T03:14:37.768573: step 2300, loss 0.839669, acc 0.732645

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2300

2020-02-08T03:14:39.236882: step 2301, loss 0.0460512, acc 0.984375
2020-02-08T03:14:39.353048: step 2302, loss 0.0194996, acc 1
2020-02-08T03:14:39.466913: step 2303, loss 0.0570438, acc 0.96875
2020-02-08T03:14:39.583345: step 2304, loss 0.0256095, acc 1
2020-02-08T03:14:39.699965: step 2305, loss 0.0383645, acc 0.984375
2020-02-08T03:14:39.816916: step 2306, loss 0.0477338, acc 0.984375
2020-02-08T03:14:39.937372: step 2307, loss 0.0294448, acc 1
2020-02-08T03:14:40.051724: step 2308, loss 0.0634128, acc 0.96875
2020-02-08T03:14:40.171117: step 2309, loss 0.059995, acc 0.984375
2020-02-08T03:14:40.288256: step 2310, loss 0.0184567, acc 1
2020-02-08T03:14:40.402987: step 2311, loss 0.0206597, acc 1
2020-02-08T03:14:40.521298: step 2312, loss 0.0228561, acc 1
2020-02-08T03:14:40.639537: step 2313, loss 0.0416674, acc 0.984375
2020-02-08T03:14:40.753125: step 2314, loss 0.0581327, acc 0.96875
2020-02-08T03:14:40.868734: step 2315, loss 0.0344993, acc 1
2020-02-08T03:14:40.989721: step 2316, loss 0.0212984, acc 1
2020-02-08T03:14:41.106579: step 2317, loss 0.125371, acc 0.921875
2020-02-08T03:14:41.221984: step 2318, loss 0.0365949, acc 0.984375
2020-02-08T03:14:41.339430: step 2319, loss 0.0371348, acc 0.984375
2020-02-08T03:14:41.455185: step 2320, loss 0.0202567, acc 1
2020-02-08T03:14:41.570597: step 2321, loss 0.0848198, acc 0.984375
2020-02-08T03:14:41.692951: step 2322, loss 0.0135087, acc 1
2020-02-08T03:14:41.806406: step 2323, loss 0.0799306, acc 0.953125
2020-02-08T03:14:41.924562: step 2324, loss 0.0222547, acc 1
2020-02-08T03:14:42.040040: step 2325, loss 0.0771286, acc 0.984375
2020-02-08T03:14:42.154304: step 2326, loss 0.0519196, acc 0.984375
2020-02-08T03:14:42.268482: step 2327, loss 0.0483306, acc 0.984375
2020-02-08T03:14:42.386451: step 2328, loss 0.0241418, acc 1
2020-02-08T03:14:42.501165: step 2329, loss 0.0123188, acc 1
2020-02-08T03:14:42.616513: step 2330, loss 0.0207417, acc 1
2020-02-08T03:14:42.734896: step 2331, loss 0.0146391, acc 1
2020-02-08T03:14:42.852406: step 2332, loss 0.0752058, acc 0.953125
2020-02-08T03:14:42.968910: step 2333, loss 0.0309044, acc 0.984375
2020-02-08T03:14:43.086615: step 2334, loss 0.0374945, acc 0.984375
2020-02-08T03:14:43.203759: step 2335, loss 0.0448445, acc 0.96875
2020-02-08T03:14:43.322270: step 2336, loss 0.0341153, acc 1
2020-02-08T03:14:43.439799: step 2337, loss 0.104684, acc 0.96875
2020-02-08T03:14:43.556393: step 2338, loss 0.0265176, acc 0.984375
2020-02-08T03:14:43.672524: step 2339, loss 0.116125, acc 0.96875
2020-02-08T03:14:43.789407: step 2340, loss 0.110907, acc 0.96875
2020-02-08T03:14:43.905079: step 2341, loss 0.0437415, acc 0.984375
2020-02-08T03:14:44.020510: step 2342, loss 0.0238362, acc 1
2020-02-08T03:14:44.138759: step 2343, loss 0.0173007, acc 1
2020-02-08T03:14:44.255918: step 2344, loss 0.0356829, acc 0.984375
2020-02-08T03:14:44.378126: step 2345, loss 0.0558242, acc 0.984375
2020-02-08T03:14:44.497006: step 2346, loss 0.0266434, acc 1
2020-02-08T03:14:44.611177: step 2347, loss 0.0119251, acc 1
2020-02-08T03:14:44.725800: step 2348, loss 0.111149, acc 0.96875
2020-02-08T03:14:44.843014: step 2349, loss 0.0337953, acc 1
2020-02-08T03:14:44.957755: step 2350, loss 0.0558198, acc 0.96875
2020-02-08T03:14:45.073310: step 2351, loss 0.0473959, acc 0.984375
2020-02-08T03:14:45.192022: step 2352, loss 0.0762047, acc 0.984375
2020-02-08T03:14:45.308572: step 2353, loss 0.0337065, acc 0.984375
2020-02-08T03:14:45.427262: step 2354, loss 0.0412531, acc 0.984375
2020-02-08T03:14:45.543220: step 2355, loss 0.0277305, acc 0.984375
2020-02-08T03:14:45.657154: step 2356, loss 0.0730324, acc 0.96875
2020-02-08T03:14:45.771853: step 2357, loss 0.0473262, acc 0.984375
2020-02-08T03:14:45.889908: step 2358, loss 0.0268789, acc 1
2020-02-08T03:14:46.003132: step 2359, loss 0.0211809, acc 1
2020-02-08T03:14:46.120924: step 2360, loss 0.0677126, acc 0.984375
2020-02-08T03:14:46.237617: step 2361, loss 0.085722, acc 0.96875
2020-02-08T03:14:46.352835: step 2362, loss 0.0482853, acc 0.96875
2020-02-08T03:14:46.470157: step 2363, loss 0.0323595, acc 0.984375
2020-02-08T03:14:46.588915: step 2364, loss 0.0256584, acc 1
2020-02-08T03:14:46.705850: step 2365, loss 0.0690019, acc 0.96875
2020-02-08T03:14:46.823710: step 2366, loss 0.0425295, acc 0.984375
2020-02-08T03:14:46.942370: step 2367, loss 0.070197, acc 0.96875
2020-02-08T03:14:47.061209: step 2368, loss 0.0491227, acc 0.984375
2020-02-08T03:14:47.182007: step 2369, loss 0.0503806, acc 0.984375
2020-02-08T03:14:47.298153: step 2370, loss 0.0587371, acc 0.984375
2020-02-08T03:14:47.413054: step 2371, loss 0.0282516, acc 1
2020-02-08T03:14:47.536182: step 2372, loss 0.0543571, acc 0.96875
2020-02-08T03:14:47.651882: step 2373, loss 0.0920514, acc 0.953125
2020-02-08T03:14:47.767992: step 2374, loss 0.0242211, acc 0.984375
2020-02-08T03:14:47.885083: step 2375, loss 0.104398, acc 0.9375
2020-02-08T03:14:48.000416: step 2376, loss 0.0169488, acc 1
2020-02-08T03:14:48.115055: step 2377, loss 0.0634259, acc 0.984375
2020-02-08T03:14:48.233216: step 2378, loss 0.0935678, acc 0.96875
2020-02-08T03:14:48.349555: step 2379, loss 0.072945, acc 0.96875
2020-02-08T03:14:48.465440: step 2380, loss 0.0970994, acc 0.96875
2020-02-08T03:14:48.582772: step 2381, loss 0.0288827, acc 1
2020-02-08T03:14:48.700831: step 2382, loss 0.0460944, acc 0.984375
2020-02-08T03:14:48.819896: step 2383, loss 0.165914, acc 0.921875
2020-02-08T03:14:48.934732: step 2384, loss 0.0865779, acc 0.96875
2020-02-08T03:14:49.050394: step 2385, loss 0.108774, acc 0.953125
2020-02-08T03:14:49.167200: step 2386, loss 0.105048, acc 0.953125
2020-02-08T03:14:49.283743: step 2387, loss 0.0249277, acc 0.984375
2020-02-08T03:14:49.400803: step 2388, loss 0.0455849, acc 0.953125
2020-02-08T03:14:49.517849: step 2389, loss 0.0232024, acc 1
2020-02-08T03:14:49.635837: step 2390, loss 0.0247699, acc 1
2020-02-08T03:14:49.751486: step 2391, loss 0.0538034, acc 0.984375
2020-02-08T03:14:49.870930: step 2392, loss 0.0479786, acc 0.96875
2020-02-08T03:14:49.989848: step 2393, loss 0.0524913, acc 1
2020-02-08T03:14:50.107044: step 2394, loss 0.0668202, acc 0.984375
2020-02-08T03:14:50.225454: step 2395, loss 0.0344227, acc 0.984375
2020-02-08T03:14:50.342220: step 2396, loss 0.0731892, acc 0.984375
2020-02-08T03:14:50.457331: step 2397, loss 0.0398943, acc 1
2020-02-08T03:14:50.574744: step 2398, loss 0.0378226, acc 0.984375
2020-02-08T03:14:50.696647: step 2399, loss 0.0257557, acc 0.984375
2020-02-08T03:14:50.806175: step 2400, loss 0.0637892, acc 0.966667

Evaluation:
2020-02-08T03:14:50.992646: step 2400, loss 0.853737, acc 0.742964

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2400

2020-02-08T03:14:52.490868: step 2401, loss 0.0185905, acc 0.984375
2020-02-08T03:14:52.653415: step 2402, loss 0.029356, acc 0.984375
2020-02-08T03:14:52.784173: step 2403, loss 0.0849371, acc 0.96875
2020-02-08T03:14:52.901425: step 2404, loss 0.059139, acc 0.96875
2020-02-08T03:14:53.017477: step 2405, loss 0.0151946, acc 1
2020-02-08T03:14:53.137311: step 2406, loss 0.0165167, acc 1
2020-02-08T03:14:53.254750: step 2407, loss 0.0978684, acc 0.96875
2020-02-08T03:14:53.374210: step 2408, loss 0.0517503, acc 0.953125
2020-02-08T03:14:53.493175: step 2409, loss 0.0132985, acc 1
2020-02-08T03:14:53.611714: step 2410, loss 0.0466595, acc 0.984375
2020-02-08T03:14:53.727642: step 2411, loss 0.0472882, acc 0.96875
2020-02-08T03:14:53.844052: step 2412, loss 0.0327426, acc 0.984375
2020-02-08T03:14:53.962627: step 2413, loss 0.0360746, acc 0.984375
2020-02-08T03:14:54.079562: step 2414, loss 0.0258919, acc 1
2020-02-08T03:14:54.200392: step 2415, loss 0.026283, acc 0.984375
2020-02-08T03:14:54.316471: step 2416, loss 0.0679826, acc 0.984375
2020-02-08T03:14:54.439055: step 2417, loss 0.0129055, acc 1
2020-02-08T03:14:54.553639: step 2418, loss 0.018561, acc 1
2020-02-08T03:14:54.673016: step 2419, loss 0.0552277, acc 0.984375
2020-02-08T03:14:54.789554: step 2420, loss 0.132729, acc 0.953125
2020-02-08T03:14:54.904055: step 2421, loss 0.0870968, acc 0.96875
2020-02-08T03:14:55.018277: step 2422, loss 0.0393407, acc 0.984375
2020-02-08T03:14:55.136296: step 2423, loss 0.0723848, acc 0.96875
2020-02-08T03:14:55.252893: step 2424, loss 0.0321515, acc 0.984375
2020-02-08T03:14:55.365760: step 2425, loss 0.0824638, acc 0.953125
2020-02-08T03:14:55.483530: step 2426, loss 0.0303351, acc 0.984375
2020-02-08T03:14:55.599575: step 2427, loss 0.0425989, acc 0.96875
2020-02-08T03:14:55.716417: step 2428, loss 0.0529083, acc 0.984375
2020-02-08T03:14:55.834871: step 2429, loss 0.0274813, acc 0.984375
2020-02-08T03:14:55.949907: step 2430, loss 0.0353463, acc 1
2020-02-08T03:14:56.065563: step 2431, loss 0.0523882, acc 0.984375
2020-02-08T03:14:56.182466: step 2432, loss 0.0646667, acc 0.96875
2020-02-08T03:14:56.296870: step 2433, loss 0.0398172, acc 0.984375
2020-02-08T03:14:56.412125: step 2434, loss 0.0362045, acc 1
2020-02-08T03:14:56.531765: step 2435, loss 0.0223334, acc 1
2020-02-08T03:14:56.647164: step 2436, loss 0.00902642, acc 1
2020-02-08T03:14:56.764026: step 2437, loss 0.0631341, acc 0.984375
2020-02-08T03:14:56.885542: step 2438, loss 0.0280526, acc 1
2020-02-08T03:14:57.004011: step 2439, loss 0.0282699, acc 1
2020-02-08T03:14:57.119881: step 2440, loss 0.00830768, acc 1
2020-02-08T03:14:57.239180: step 2441, loss 0.026247, acc 0.984375
2020-02-08T03:14:57.356239: step 2442, loss 0.0262014, acc 1
2020-02-08T03:14:57.475132: step 2443, loss 0.0453524, acc 0.96875
2020-02-08T03:14:57.593759: step 2444, loss 0.0190959, acc 1
2020-02-08T03:14:57.707213: step 2445, loss 0.0364747, acc 0.984375
2020-02-08T03:14:57.824389: step 2446, loss 0.00692353, acc 1
2020-02-08T03:14:57.942080: step 2447, loss 0.0281042, acc 0.984375
2020-02-08T03:14:58.055236: step 2448, loss 0.0120217, acc 1
2020-02-08T03:14:58.170103: step 2449, loss 0.0257627, acc 1
2020-02-08T03:14:58.284193: step 2450, loss 0.0436051, acc 0.984375
2020-02-08T03:14:58.394704: step 2451, loss 0.0204899, acc 1
2020-02-08T03:14:58.511215: step 2452, loss 0.0553764, acc 0.984375
2020-02-08T03:14:58.630032: step 2453, loss 0.0681285, acc 0.96875
2020-02-08T03:14:58.746159: step 2454, loss 0.0128815, acc 1
2020-02-08T03:14:58.862889: step 2455, loss 0.0648929, acc 0.96875
2020-02-08T03:14:58.980638: step 2456, loss 0.0142088, acc 1
2020-02-08T03:14:59.097549: step 2457, loss 0.0780392, acc 0.96875
2020-02-08T03:14:59.228658: step 2458, loss 0.0555601, acc 0.984375
2020-02-08T03:14:59.356117: step 2459, loss 0.0555763, acc 0.96875
2020-02-08T03:14:59.483158: step 2460, loss 0.0590178, acc 0.96875
2020-02-08T03:14:59.610861: step 2461, loss 0.104873, acc 0.953125
2020-02-08T03:14:59.735760: step 2462, loss 0.0424231, acc 0.984375
2020-02-08T03:14:59.866381: step 2463, loss 0.0355249, acc 0.984375
2020-02-08T03:14:59.994430: step 2464, loss 0.0277565, acc 1
2020-02-08T03:15:00.118466: step 2465, loss 0.0813016, acc 0.96875
2020-02-08T03:15:00.237721: step 2466, loss 0.019398, acc 1
2020-02-08T03:15:00.356386: step 2467, loss 0.0358065, acc 1
2020-02-08T03:15:00.475551: step 2468, loss 0.0307218, acc 1
2020-02-08T03:15:00.593290: step 2469, loss 0.0239045, acc 1
2020-02-08T03:15:00.711438: step 2470, loss 0.00915869, acc 1
2020-02-08T03:15:00.832777: step 2471, loss 0.0249218, acc 1
2020-02-08T03:15:00.947717: step 2472, loss 0.0866975, acc 0.984375
2020-02-08T03:15:01.064990: step 2473, loss 0.022432, acc 1
2020-02-08T03:15:01.181820: step 2474, loss 0.0234684, acc 1
2020-02-08T03:15:01.297881: step 2475, loss 0.0192936, acc 0.984375
2020-02-08T03:15:01.414960: step 2476, loss 0.014335, acc 1
2020-02-08T03:15:01.531076: step 2477, loss 0.0285649, acc 0.984375
2020-02-08T03:15:01.651135: step 2478, loss 0.00864337, acc 1
2020-02-08T03:15:01.768219: step 2479, loss 0.122646, acc 0.953125
2020-02-08T03:15:01.885610: step 2480, loss 0.0380937, acc 0.984375
2020-02-08T03:15:02.001534: step 2481, loss 0.0312169, acc 0.984375
2020-02-08T03:15:02.118306: step 2482, loss 0.0345447, acc 0.984375
2020-02-08T03:15:02.233974: step 2483, loss 0.039837, acc 0.984375
2020-02-08T03:15:02.348324: step 2484, loss 0.078016, acc 0.953125
2020-02-08T03:15:02.466743: step 2485, loss 0.0337552, acc 0.984375
2020-02-08T03:15:02.584621: step 2486, loss 0.043068, acc 0.984375
2020-02-08T03:15:02.701853: step 2487, loss 0.0389928, acc 0.984375
2020-02-08T03:15:02.820170: step 2488, loss 0.0556721, acc 0.984375
2020-02-08T03:15:02.936297: step 2489, loss 0.0115994, acc 1
2020-02-08T03:15:03.052080: step 2490, loss 0.0182978, acc 1
2020-02-08T03:15:03.171057: step 2491, loss 0.0406173, acc 0.984375
2020-02-08T03:15:03.286939: step 2492, loss 0.0144236, acc 1
2020-02-08T03:15:03.407421: step 2493, loss 0.0129004, acc 1
2020-02-08T03:15:03.525218: step 2494, loss 0.0201111, acc 1
2020-02-08T03:15:03.642524: step 2495, loss 0.0819758, acc 0.96875
2020-02-08T03:15:03.762734: step 2496, loss 0.0475892, acc 0.984375
2020-02-08T03:15:03.879375: step 2497, loss 0.0170917, acc 1
2020-02-08T03:15:03.996671: step 2498, loss 0.0341277, acc 0.984375
2020-02-08T03:15:04.114435: step 2499, loss 0.0299977, acc 1
2020-02-08T03:15:04.233825: step 2500, loss 0.0279229, acc 1

Evaluation:
2020-02-08T03:15:04.421837: step 2500, loss 0.900355, acc 0.744841

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2500

2020-02-08T03:15:05.983656: step 2501, loss 0.0158813, acc 1
2020-02-08T03:15:06.102863: step 2502, loss 0.0809595, acc 0.96875
2020-02-08T03:15:06.222245: step 2503, loss 0.0230123, acc 1
2020-02-08T03:15:06.338791: step 2504, loss 0.0272481, acc 1
2020-02-08T03:15:06.456242: step 2505, loss 0.0177488, acc 1
2020-02-08T03:15:06.573894: step 2506, loss 0.0280942, acc 0.984375
2020-02-08T03:15:06.688631: step 2507, loss 0.0650725, acc 0.984375
2020-02-08T03:15:06.805011: step 2508, loss 0.0566227, acc 0.96875
2020-02-08T03:15:06.921016: step 2509, loss 0.0209283, acc 1
2020-02-08T03:15:07.038898: step 2510, loss 0.0113466, acc 1
2020-02-08T03:15:07.153723: step 2511, loss 0.0611236, acc 0.96875
2020-02-08T03:15:07.269112: step 2512, loss 0.0361672, acc 0.984375
2020-02-08T03:15:07.388947: step 2513, loss 0.0212527, acc 1
2020-02-08T03:15:07.505713: step 2514, loss 0.0127809, acc 1
2020-02-08T03:15:07.623999: step 2515, loss 0.00921142, acc 1
2020-02-08T03:15:07.744538: step 2516, loss 0.0276614, acc 1
2020-02-08T03:15:07.863225: step 2517, loss 0.0366824, acc 0.984375
2020-02-08T03:15:07.981318: step 2518, loss 0.0420023, acc 0.96875
2020-02-08T03:15:08.098664: step 2519, loss 0.0847338, acc 0.9375
2020-02-08T03:15:08.216024: step 2520, loss 0.0161474, acc 1
2020-02-08T03:15:08.332884: step 2521, loss 0.0238632, acc 1
2020-02-08T03:15:08.450357: step 2522, loss 0.0121837, acc 1
2020-02-08T03:15:08.562878: step 2523, loss 0.0256578, acc 1
2020-02-08T03:15:08.684264: step 2524, loss 0.0319935, acc 1
2020-02-08T03:15:08.800243: step 2525, loss 0.0445792, acc 0.984375
2020-02-08T03:15:08.914924: step 2526, loss 0.034087, acc 0.984375
2020-02-08T03:15:09.032713: step 2527, loss 0.0379449, acc 1
2020-02-08T03:15:09.149257: step 2528, loss 0.0381682, acc 0.984375
2020-02-08T03:15:09.264012: step 2529, loss 0.0359567, acc 0.984375
2020-02-08T03:15:09.386053: step 2530, loss 0.0462657, acc 0.984375
2020-02-08T03:15:09.503293: step 2531, loss 0.014053, acc 1
2020-02-08T03:15:09.624428: step 2532, loss 0.0415525, acc 0.96875
2020-02-08T03:15:09.745326: step 2533, loss 0.011953, acc 1
2020-02-08T03:15:09.864431: step 2534, loss 0.0269978, acc 1
2020-02-08T03:15:09.986355: step 2535, loss 0.0593239, acc 0.96875
2020-02-08T03:15:10.109302: step 2536, loss 0.0355042, acc 0.984375
2020-02-08T03:15:10.226000: step 2537, loss 0.0324467, acc 0.984375
2020-02-08T03:15:10.434285: step 2538, loss 0.0728729, acc 0.984375
2020-02-08T03:15:10.563555: step 2539, loss 0.0372203, acc 1
2020-02-08T03:15:10.695521: step 2540, loss 0.0368573, acc 1
2020-02-08T03:15:10.841418: step 2541, loss 0.0151385, acc 1
2020-02-08T03:15:10.986062: step 2542, loss 0.101465, acc 0.96875
2020-02-08T03:15:11.124218: step 2543, loss 0.132467, acc 0.953125
2020-02-08T03:15:11.258034: step 2544, loss 0.0231672, acc 1
2020-02-08T03:15:11.387534: step 2545, loss 0.0313654, acc 0.984375
2020-02-08T03:15:11.519148: step 2546, loss 0.107163, acc 0.96875
2020-02-08T03:15:11.652228: step 2547, loss 0.0214614, acc 1
2020-02-08T03:15:11.796033: step 2548, loss 0.0181603, acc 1
2020-02-08T03:15:11.928021: step 2549, loss 0.0320447, acc 1
2020-02-08T03:15:12.056821: step 2550, loss 0.0778668, acc 0.966667
2020-02-08T03:15:12.194860: step 2551, loss 0.030547, acc 0.984375
2020-02-08T03:15:12.329193: step 2552, loss 0.0217259, acc 1
2020-02-08T03:15:12.461113: step 2553, loss 0.0118348, acc 1
2020-02-08T03:15:12.597702: step 2554, loss 0.0150713, acc 1
2020-02-08T03:15:12.736665: step 2555, loss 0.0202218, acc 1
2020-02-08T03:15:12.869265: step 2556, loss 0.0305873, acc 0.984375
2020-02-08T03:15:13.004844: step 2557, loss 0.0100298, acc 1
2020-02-08T03:15:13.142754: step 2558, loss 0.00984115, acc 1
2020-02-08T03:15:13.286487: step 2559, loss 0.0470736, acc 0.96875
2020-02-08T03:15:13.436871: step 2560, loss 0.0430482, acc 0.984375
2020-02-08T03:15:13.577005: step 2561, loss 0.0378749, acc 0.984375
2020-02-08T03:15:13.711022: step 2562, loss 0.0798094, acc 0.96875
2020-02-08T03:15:13.847278: step 2563, loss 0.00878434, acc 1
2020-02-08T03:15:13.986591: step 2564, loss 0.0243766, acc 1
2020-02-08T03:15:14.124342: step 2565, loss 0.0199268, acc 1
2020-02-08T03:15:14.252484: step 2566, loss 0.0245465, acc 1
2020-02-08T03:15:14.388901: step 2567, loss 0.0185939, acc 1
2020-02-08T03:15:14.526358: step 2568, loss 0.0523678, acc 0.96875
2020-02-08T03:15:14.661890: step 2569, loss 0.0698059, acc 0.953125
2020-02-08T03:15:14.797630: step 2570, loss 0.00690393, acc 1
2020-02-08T03:15:14.939623: step 2571, loss 0.0142993, acc 1
2020-02-08T03:15:15.080664: step 2572, loss 0.0258879, acc 1
2020-02-08T03:15:15.220734: step 2573, loss 0.0069716, acc 1
2020-02-08T03:15:15.358532: step 2574, loss 0.02121, acc 1
2020-02-08T03:15:15.496335: step 2575, loss 0.0171344, acc 1
2020-02-08T03:15:15.637446: step 2576, loss 0.064305, acc 0.953125
2020-02-08T03:15:15.775118: step 2577, loss 0.0149473, acc 1
2020-02-08T03:15:15.912515: step 2578, loss 0.0206726, acc 1
2020-02-08T03:15:16.047492: step 2579, loss 0.0218366, acc 1
2020-02-08T03:15:16.181416: step 2580, loss 0.0269681, acc 1
2020-02-08T03:15:16.318491: step 2581, loss 0.0462354, acc 0.984375
2020-02-08T03:15:16.453499: step 2582, loss 0.0718474, acc 0.96875
2020-02-08T03:15:16.591748: step 2583, loss 0.01579, acc 1
2020-02-08T03:15:16.730760: step 2584, loss 0.0175662, acc 1
2020-02-08T03:15:16.870068: step 2585, loss 0.0183363, acc 1
2020-02-08T03:15:17.009951: step 2586, loss 0.00898679, acc 1
2020-02-08T03:15:17.148494: step 2587, loss 0.0465194, acc 0.984375
2020-02-08T03:15:17.285447: step 2588, loss 0.0393594, acc 0.984375
2020-02-08T03:15:17.409932: step 2589, loss 0.0193309, acc 1
2020-02-08T03:15:17.532831: step 2590, loss 0.0351324, acc 1
2020-02-08T03:15:17.669366: step 2591, loss 0.0269976, acc 1
2020-02-08T03:15:17.795912: step 2592, loss 0.0915122, acc 0.953125
2020-02-08T03:15:17.924696: step 2593, loss 0.0310678, acc 0.984375
2020-02-08T03:15:18.067321: step 2594, loss 0.0166883, acc 1
2020-02-08T03:15:18.206860: step 2595, loss 0.0191239, acc 1
2020-02-08T03:15:18.358176: step 2596, loss 0.0109733, acc 1
2020-02-08T03:15:18.487989: step 2597, loss 0.0177342, acc 1
2020-02-08T03:15:18.629631: step 2598, loss 0.0373927, acc 0.984375
2020-02-08T03:15:18.766955: step 2599, loss 0.0692373, acc 0.984375
2020-02-08T03:15:18.894957: step 2600, loss 0.0608336, acc 0.953125

Evaluation:
2020-02-08T03:15:19.099367: step 2600, loss 0.931386, acc 0.743902

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2600

2020-02-08T03:15:20.684149: step 2601, loss 0.024014, acc 0.984375
2020-02-08T03:15:20.800937: step 2602, loss 0.0156239, acc 1
2020-02-08T03:15:20.916160: step 2603, loss 0.178176, acc 0.96875
2020-02-08T03:15:21.038780: step 2604, loss 0.0274091, acc 0.984375
2020-02-08T03:15:21.160734: step 2605, loss 0.00772084, acc 1
2020-02-08T03:15:21.283447: step 2606, loss 0.0130469, acc 1
2020-02-08T03:15:21.539762: step 2607, loss 0.00756262, acc 1
2020-02-08T03:15:21.666854: step 2608, loss 0.0219589, acc 1
2020-02-08T03:15:21.781849: step 2609, loss 0.0114048, acc 1
2020-02-08T03:15:21.896692: step 2610, loss 0.0142674, acc 1
2020-02-08T03:15:22.011583: step 2611, loss 0.0135023, acc 1
2020-02-08T03:15:22.129234: step 2612, loss 0.030969, acc 0.984375
2020-02-08T03:15:22.247734: step 2613, loss 0.0322626, acc 1
2020-02-08T03:15:22.365448: step 2614, loss 0.0177803, acc 1
2020-02-08T03:15:22.482437: step 2615, loss 0.0460474, acc 0.984375
2020-02-08T03:15:22.598249: step 2616, loss 0.0991058, acc 0.96875
2020-02-08T03:15:22.716995: step 2617, loss 0.00914234, acc 1
2020-02-08T03:15:22.835450: step 2618, loss 0.0219063, acc 1
2020-02-08T03:15:22.951131: step 2619, loss 0.0121523, acc 1
2020-02-08T03:15:23.065620: step 2620, loss 0.0923298, acc 0.953125
2020-02-08T03:15:23.181768: step 2621, loss 0.0107132, acc 1
2020-02-08T03:15:23.297892: step 2622, loss 0.0401866, acc 0.984375
2020-02-08T03:15:23.414646: step 2623, loss 0.0288623, acc 1
2020-02-08T03:15:23.531104: step 2624, loss 0.015285, acc 1
2020-02-08T03:15:23.646679: step 2625, loss 0.0107033, acc 1
2020-02-08T03:15:23.762118: step 2626, loss 0.0325105, acc 0.984375
2020-02-08T03:15:23.879976: step 2627, loss 0.0134699, acc 1
2020-02-08T03:15:23.998523: step 2628, loss 0.00705119, acc 1
2020-02-08T03:15:24.115016: step 2629, loss 0.0466556, acc 0.96875
2020-02-08T03:15:24.232212: step 2630, loss 0.0122882, acc 1
2020-02-08T03:15:24.349694: step 2631, loss 0.0480845, acc 0.984375
2020-02-08T03:15:24.467377: step 2632, loss 0.00911278, acc 1
2020-02-08T03:15:24.584663: step 2633, loss 0.0254192, acc 0.984375
2020-02-08T03:15:24.701644: step 2634, loss 0.046666, acc 0.984375
2020-02-08T03:15:24.817726: step 2635, loss 0.0662266, acc 0.96875
2020-02-08T03:15:24.935713: step 2636, loss 0.0100456, acc 1
2020-02-08T03:15:25.049309: step 2637, loss 0.00538146, acc 1
2020-02-08T03:15:25.169258: step 2638, loss 0.0347457, acc 0.984375
2020-02-08T03:15:25.286773: step 2639, loss 0.0236347, acc 0.984375
2020-02-08T03:15:25.402035: step 2640, loss 0.0171503, acc 1
2020-02-08T03:15:25.525296: step 2641, loss 0.0140719, acc 1
2020-02-08T03:15:25.643746: step 2642, loss 0.0262216, acc 1
2020-02-08T03:15:25.759169: step 2643, loss 0.00993982, acc 1
2020-02-08T03:15:25.878806: step 2644, loss 0.0280457, acc 1
2020-02-08T03:15:25.996156: step 2645, loss 0.0173106, acc 1
2020-02-08T03:15:26.116727: step 2646, loss 0.0128124, acc 1
2020-02-08T03:15:26.234751: step 2647, loss 0.0255604, acc 0.984375
2020-02-08T03:15:26.350956: step 2648, loss 0.00907587, acc 1
2020-02-08T03:15:26.478190: step 2649, loss 0.0565001, acc 0.96875
2020-02-08T03:15:26.594955: step 2650, loss 0.0216998, acc 0.984375
2020-02-08T03:15:26.712761: step 2651, loss 0.0103218, acc 1
2020-02-08T03:15:26.829465: step 2652, loss 0.040657, acc 0.984375
2020-02-08T03:15:26.946057: step 2653, loss 0.0537538, acc 0.984375
2020-02-08T03:15:27.062398: step 2654, loss 0.00892542, acc 1
2020-02-08T03:15:27.180873: step 2655, loss 0.0197897, acc 1
2020-02-08T03:15:27.296845: step 2656, loss 0.00605643, acc 1
2020-02-08T03:15:27.409444: step 2657, loss 0.0144513, acc 1
2020-02-08T03:15:27.522410: step 2658, loss 0.127201, acc 0.953125
2020-02-08T03:15:27.637956: step 2659, loss 0.0399125, acc 0.984375
2020-02-08T03:15:27.752904: step 2660, loss 0.0426792, acc 1
2020-02-08T03:15:27.868867: step 2661, loss 0.0233348, acc 1
2020-02-08T03:15:27.985565: step 2662, loss 0.0253224, acc 1
2020-02-08T03:15:28.099995: step 2663, loss 0.0641125, acc 0.96875
2020-02-08T03:15:28.215054: step 2664, loss 0.00944866, acc 1
2020-02-08T03:15:28.333249: step 2665, loss 0.0126514, acc 1
2020-02-08T03:15:28.449423: step 2666, loss 0.0362771, acc 0.984375
2020-02-08T03:15:28.562392: step 2667, loss 0.00697596, acc 1
2020-02-08T03:15:28.678629: step 2668, loss 0.0546883, acc 0.984375
2020-02-08T03:15:28.795563: step 2669, loss 0.0208494, acc 1
2020-02-08T03:15:28.910512: step 2670, loss 0.0244722, acc 1
2020-02-08T03:15:29.027794: step 2671, loss 0.0567654, acc 0.96875
2020-02-08T03:15:29.143898: step 2672, loss 0.00825583, acc 1
2020-02-08T03:15:29.258662: step 2673, loss 0.0178079, acc 1
2020-02-08T03:15:29.374129: step 2674, loss 0.0152659, acc 1
2020-02-08T03:15:29.492589: step 2675, loss 0.0351817, acc 0.984375
2020-02-08T03:15:29.606251: step 2676, loss 0.00636163, acc 1
2020-02-08T03:15:29.721436: step 2677, loss 0.0528628, acc 0.984375
2020-02-08T03:15:29.837339: step 2678, loss 0.0619302, acc 0.96875
2020-02-08T03:15:29.953283: step 2679, loss 0.0363573, acc 0.984375
2020-02-08T03:15:30.072080: step 2680, loss 0.0287115, acc 0.984375
2020-02-08T03:15:30.188923: step 2681, loss 0.0230274, acc 1
2020-02-08T03:15:30.304193: step 2682, loss 0.0332391, acc 0.984375
2020-02-08T03:15:30.419185: step 2683, loss 0.0205465, acc 1
2020-02-08T03:15:30.537074: step 2684, loss 0.021732, acc 1
2020-02-08T03:15:30.652877: step 2685, loss 0.0211934, acc 1
2020-02-08T03:15:30.770050: step 2686, loss 0.0271309, acc 0.984375
2020-02-08T03:15:30.886618: step 2687, loss 0.0146903, acc 1
2020-02-08T03:15:31.002316: step 2688, loss 0.113586, acc 0.96875
2020-02-08T03:15:31.115672: step 2689, loss 0.04835, acc 0.96875
2020-02-08T03:15:31.230774: step 2690, loss 0.0153203, acc 1
2020-02-08T03:15:31.347043: step 2691, loss 0.0314083, acc 1
2020-02-08T03:15:31.463438: step 2692, loss 0.0739474, acc 0.96875
2020-02-08T03:15:31.586139: step 2693, loss 0.0478577, acc 0.984375
2020-02-08T03:15:31.703068: step 2694, loss 0.0234739, acc 1
2020-02-08T03:15:31.820179: step 2695, loss 0.0552255, acc 0.984375
2020-02-08T03:15:31.937626: step 2696, loss 0.0125546, acc 1
2020-02-08T03:15:32.054148: step 2697, loss 0.0303048, acc 0.984375
2020-02-08T03:15:32.170843: step 2698, loss 0.0624264, acc 0.984375
2020-02-08T03:15:32.288932: step 2699, loss 0.0785892, acc 0.984375
2020-02-08T03:15:32.400439: step 2700, loss 0.0204603, acc 1

Evaluation:
2020-02-08T03:15:32.591421: step 2700, loss 0.962294, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2700

2020-02-08T03:15:34.117299: step 2701, loss 0.0462949, acc 0.984375
2020-02-08T03:15:34.235041: step 2702, loss 0.0129461, acc 1
2020-02-08T03:15:34.352628: step 2703, loss 0.083074, acc 0.984375
2020-02-08T03:15:34.467350: step 2704, loss 0.00982257, acc 1
2020-02-08T03:15:34.584335: step 2705, loss 0.00479799, acc 1
2020-02-08T03:15:34.700802: step 2706, loss 0.0178772, acc 1
2020-02-08T03:15:34.817386: step 2707, loss 0.0203336, acc 1
2020-02-08T03:15:34.935861: step 2708, loss 0.0350874, acc 0.96875
2020-02-08T03:15:35.054654: step 2709, loss 0.0108645, acc 1
2020-02-08T03:15:35.172010: step 2710, loss 0.0160674, acc 1
2020-02-08T03:15:35.289170: step 2711, loss 0.0172356, acc 1
2020-02-08T03:15:35.407532: step 2712, loss 0.0148033, acc 1
2020-02-08T03:15:35.524937: step 2713, loss 0.00913053, acc 1
2020-02-08T03:15:35.640721: step 2714, loss 0.0165775, acc 1
2020-02-08T03:15:35.758206: step 2715, loss 0.0138043, acc 1
2020-02-08T03:15:35.879002: step 2716, loss 0.0247036, acc 1
2020-02-08T03:15:35.996210: step 2717, loss 0.00579317, acc 1
2020-02-08T03:15:36.109177: step 2718, loss 0.0535442, acc 0.984375
2020-02-08T03:15:36.225628: step 2719, loss 0.00760353, acc 1
2020-02-08T03:15:36.344517: step 2720, loss 0.0227269, acc 0.984375
2020-02-08T03:15:36.459600: step 2721, loss 0.00970806, acc 1
2020-02-08T03:15:36.576948: step 2722, loss 0.0192693, acc 1
2020-02-08T03:15:36.695486: step 2723, loss 0.0202544, acc 0.984375
2020-02-08T03:15:36.811992: step 2724, loss 0.0120293, acc 1
2020-02-08T03:15:36.929138: step 2725, loss 0.0181102, acc 0.984375
2020-02-08T03:15:37.047299: step 2726, loss 0.0096417, acc 1
2020-02-08T03:15:37.163699: step 2727, loss 0.00956004, acc 1
2020-02-08T03:15:37.282671: step 2728, loss 0.0390913, acc 0.984375
2020-02-08T03:15:37.398373: step 2729, loss 0.0174345, acc 1
2020-02-08T03:15:37.513816: step 2730, loss 0.00558493, acc 1
2020-02-08T03:15:37.630054: step 2731, loss 0.0175164, acc 1
2020-02-08T03:15:37.746081: step 2732, loss 0.00530133, acc 1
2020-02-08T03:15:37.860918: step 2733, loss 0.0131628, acc 1
2020-02-08T03:15:37.980520: step 2734, loss 0.0208825, acc 1
2020-02-08T03:15:38.096905: step 2735, loss 0.0179221, acc 0.984375
2020-02-08T03:15:38.212493: step 2736, loss 0.00315504, acc 1
2020-02-08T03:15:38.331602: step 2737, loss 0.0245439, acc 0.984375
2020-02-08T03:15:38.447156: step 2738, loss 0.00692039, acc 1
2020-02-08T03:15:38.561070: step 2739, loss 0.0380549, acc 0.984375
2020-02-08T03:15:38.675918: step 2740, loss 0.00506062, acc 1
2020-02-08T03:15:38.794521: step 2741, loss 0.0111312, acc 1
2020-02-08T03:15:38.909532: step 2742, loss 0.0132337, acc 1
2020-02-08T03:15:39.026121: step 2743, loss 0.0230943, acc 1
2020-02-08T03:15:39.145113: step 2744, loss 0.119004, acc 0.96875
2020-02-08T03:15:39.262657: step 2745, loss 0.0194877, acc 1
2020-02-08T03:15:39.377801: step 2746, loss 0.0135747, acc 1
2020-02-08T03:15:39.495204: step 2747, loss 0.0382473, acc 0.984375
2020-02-08T03:15:39.611961: step 2748, loss 0.048224, acc 0.96875
2020-02-08T03:15:39.729907: step 2749, loss 0.0357316, acc 0.984375
2020-02-08T03:15:39.847272: step 2750, loss 0.0200917, acc 1
2020-02-08T03:15:39.962836: step 2751, loss 0.0166917, acc 1
2020-02-08T03:15:40.084351: step 2752, loss 0.0150985, acc 1
2020-02-08T03:15:40.201713: step 2753, loss 0.0267716, acc 0.984375
2020-02-08T03:15:40.317355: step 2754, loss 0.0225092, acc 1
2020-02-08T03:15:40.433443: step 2755, loss 0.0108496, acc 1
2020-02-08T03:15:40.548616: step 2756, loss 0.0987326, acc 0.96875
2020-02-08T03:15:40.665563: step 2757, loss 0.00370106, acc 1
2020-02-08T03:15:40.783057: step 2758, loss 0.0421254, acc 0.96875
2020-02-08T03:15:40.902095: step 2759, loss 0.0359487, acc 0.984375
2020-02-08T03:15:41.017969: step 2760, loss 0.0277798, acc 0.984375
2020-02-08T03:15:41.136385: step 2761, loss 0.0875696, acc 0.984375
2020-02-08T03:15:41.253105: step 2762, loss 0.0278984, acc 0.984375
2020-02-08T03:15:41.368953: step 2763, loss 0.0349764, acc 0.984375
2020-02-08T03:15:41.485617: step 2764, loss 0.0281408, acc 0.984375
2020-02-08T03:15:41.600040: step 2765, loss 0.00781433, acc 1
2020-02-08T03:15:41.715024: step 2766, loss 0.0103095, acc 1
2020-02-08T03:15:41.831436: step 2767, loss 0.0154042, acc 1
2020-02-08T03:15:41.947843: step 2768, loss 0.00598781, acc 1
2020-02-08T03:15:42.063123: step 2769, loss 0.0259933, acc 0.984375
2020-02-08T03:15:42.181041: step 2770, loss 0.011196, acc 1
2020-02-08T03:15:42.299006: step 2771, loss 0.0236021, acc 1
2020-02-08T03:15:42.416051: step 2772, loss 0.0500984, acc 0.984375
2020-02-08T03:15:42.533032: step 2773, loss 0.0272324, acc 0.984375
2020-02-08T03:15:42.651884: step 2774, loss 0.00750893, acc 1
2020-02-08T03:15:42.768381: step 2775, loss 0.00298243, acc 1
2020-02-08T03:15:42.886380: step 2776, loss 0.00620679, acc 1
2020-02-08T03:15:43.002683: step 2777, loss 0.00724565, acc 1
2020-02-08T03:15:43.117080: step 2778, loss 0.0397323, acc 0.984375
2020-02-08T03:15:43.232440: step 2779, loss 0.0366889, acc 0.984375
2020-02-08T03:15:43.350344: step 2780, loss 0.0517469, acc 0.96875
2020-02-08T03:15:43.463923: step 2781, loss 0.012379, acc 1
2020-02-08T03:15:43.578526: step 2782, loss 0.020391, acc 1
2020-02-08T03:15:43.696089: step 2783, loss 0.00747308, acc 1
2020-02-08T03:15:43.811902: step 2784, loss 0.0544333, acc 0.984375
2020-02-08T03:15:43.926525: step 2785, loss 0.0101771, acc 1
2020-02-08T03:15:44.043324: step 2786, loss 0.0117395, acc 1
2020-02-08T03:15:44.159602: step 2787, loss 0.00376988, acc 1
2020-02-08T03:15:44.274189: step 2788, loss 0.00333152, acc 1
2020-02-08T03:15:44.390941: step 2789, loss 0.0233284, acc 1
2020-02-08T03:15:44.507450: step 2790, loss 0.00489506, acc 1
2020-02-08T03:15:44.621148: step 2791, loss 0.0160378, acc 1
2020-02-08T03:15:44.736402: step 2792, loss 0.0145439, acc 1
2020-02-08T03:15:44.849595: step 2793, loss 0.0102124, acc 1
2020-02-08T03:15:44.965738: step 2794, loss 0.00422979, acc 1
2020-02-08T03:15:45.082505: step 2795, loss 0.0144101, acc 1
2020-02-08T03:15:45.199975: step 2796, loss 0.0162413, acc 1
2020-02-08T03:15:45.316041: step 2797, loss 0.0133446, acc 1
2020-02-08T03:15:45.432763: step 2798, loss 0.0239755, acc 1
2020-02-08T03:15:45.549613: step 2799, loss 0.0118027, acc 1
2020-02-08T03:15:45.665009: step 2800, loss 0.00876165, acc 1

Evaluation:
2020-02-08T03:15:45.849978: step 2800, loss 0.998228, acc 0.736398

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2800

2020-02-08T03:15:47.374835: step 2801, loss 0.0270111, acc 0.984375
2020-02-08T03:15:47.492949: step 2802, loss 0.0820176, acc 0.984375
2020-02-08T03:15:47.608679: step 2803, loss 0.0093693, acc 1
2020-02-08T03:15:47.727125: step 2804, loss 0.02397, acc 0.984375
2020-02-08T03:15:47.843928: step 2805, loss 0.0110163, acc 1
2020-02-08T03:15:47.960571: step 2806, loss 0.0183715, acc 1
2020-02-08T03:15:48.075667: step 2807, loss 0.0118707, acc 1
2020-02-08T03:15:48.190629: step 2808, loss 0.0287857, acc 0.984375
2020-02-08T03:15:48.308436: step 2809, loss 0.0387551, acc 0.984375
2020-02-08T03:15:48.425879: step 2810, loss 0.00980052, acc 1
2020-02-08T03:15:48.540903: step 2811, loss 0.0527512, acc 0.984375
2020-02-08T03:15:48.659945: step 2812, loss 0.0304404, acc 1
2020-02-08T03:15:48.775607: step 2813, loss 0.0139145, acc 1
2020-02-08T03:15:48.891364: step 2814, loss 0.00891958, acc 1
2020-02-08T03:15:49.008048: step 2815, loss 0.0158096, acc 1
2020-02-08T03:15:49.124542: step 2816, loss 0.102576, acc 0.96875
2020-02-08T03:15:49.244746: step 2817, loss 0.00652544, acc 1
2020-02-08T03:15:49.359428: step 2818, loss 0.034395, acc 0.984375
2020-02-08T03:15:49.476857: step 2819, loss 0.0273693, acc 0.984375
2020-02-08T03:15:49.595442: step 2820, loss 0.0184587, acc 1
2020-02-08T03:15:49.708980: step 2821, loss 0.0223488, acc 1
2020-02-08T03:15:49.826391: step 2822, loss 0.0216419, acc 1
2020-02-08T03:15:49.942324: step 2823, loss 0.0205632, acc 1
2020-02-08T03:15:50.058526: step 2824, loss 0.0301255, acc 0.984375
2020-02-08T03:15:50.175332: step 2825, loss 0.0114544, acc 1
2020-02-08T03:15:50.292528: step 2826, loss 0.0317275, acc 1
2020-02-08T03:15:50.411462: step 2827, loss 0.00638878, acc 1
2020-02-08T03:15:50.527742: step 2828, loss 0.0433221, acc 0.984375
2020-02-08T03:15:50.644908: step 2829, loss 0.0109806, acc 1
2020-02-08T03:15:50.763680: step 2830, loss 0.0131176, acc 1
2020-02-08T03:15:50.881605: step 2831, loss 0.018809, acc 1
2020-02-08T03:15:50.997476: step 2832, loss 0.0202643, acc 1
2020-02-08T03:15:51.113133: step 2833, loss 0.0297983, acc 0.984375
2020-02-08T03:15:51.231377: step 2834, loss 0.0264986, acc 0.984375
2020-02-08T03:15:51.746798: step 2835, loss 0.0655257, acc 0.96875
2020-02-08T03:15:51.875313: step 2836, loss 0.0360632, acc 0.984375
2020-02-08T03:15:51.995104: step 2837, loss 0.0180403, acc 1
2020-02-08T03:15:52.113126: step 2838, loss 0.0151258, acc 1
2020-02-08T03:15:52.230915: step 2839, loss 0.0200768, acc 1
2020-02-08T03:15:52.345955: step 2840, loss 0.0136278, acc 1
2020-02-08T03:15:52.464537: step 2841, loss 0.015824, acc 1
2020-02-08T03:15:52.580103: step 2842, loss 0.0493211, acc 0.96875
2020-02-08T03:15:52.694815: step 2843, loss 0.0181599, acc 0.984375
2020-02-08T03:15:52.812654: step 2844, loss 0.0184207, acc 1
2020-02-08T03:15:52.930580: step 2845, loss 0.0596838, acc 0.96875
2020-02-08T03:15:53.047216: step 2846, loss 0.00977933, acc 1
2020-02-08T03:15:53.165541: step 2847, loss 0.0525841, acc 0.984375
2020-02-08T03:15:53.283515: step 2848, loss 0.00636279, acc 1
2020-02-08T03:15:53.400378: step 2849, loss 0.0112362, acc 1
2020-02-08T03:15:53.516224: step 2850, loss 0.010541, acc 1
2020-02-08T03:15:53.637500: step 2851, loss 0.0107805, acc 1
2020-02-08T03:15:53.754375: step 2852, loss 0.0195734, acc 0.984375
2020-02-08T03:15:53.871705: step 2853, loss 0.0170407, acc 1
2020-02-08T03:15:53.990098: step 2854, loss 0.011337, acc 1
2020-02-08T03:15:54.108178: step 2855, loss 0.0389787, acc 0.984375
2020-02-08T03:15:54.224981: step 2856, loss 0.0237758, acc 0.984375
2020-02-08T03:15:54.342942: step 2857, loss 0.00579714, acc 1
2020-02-08T03:15:54.459666: step 2858, loss 0.0104302, acc 1
2020-02-08T03:15:54.575760: step 2859, loss 0.00946709, acc 1
2020-02-08T03:15:54.692450: step 2860, loss 0.0473191, acc 0.984375
2020-02-08T03:15:54.809031: step 2861, loss 0.00660703, acc 1
2020-02-08T03:15:54.926294: step 2862, loss 0.0236642, acc 0.984375
2020-02-08T03:15:55.043328: step 2863, loss 0.00526672, acc 1
2020-02-08T03:15:55.160387: step 2864, loss 0.0995709, acc 0.953125
2020-02-08T03:15:55.278481: step 2865, loss 0.0184828, acc 1
2020-02-08T03:15:55.396052: step 2866, loss 0.00377208, acc 1
2020-02-08T03:15:55.512151: step 2867, loss 0.00479728, acc 1
2020-02-08T03:15:55.627365: step 2868, loss 0.013853, acc 1
2020-02-08T03:15:55.744731: step 2869, loss 0.00940971, acc 1
2020-02-08T03:15:55.859910: step 2870, loss 0.00727176, acc 1
2020-02-08T03:15:55.981130: step 2871, loss 0.00690826, acc 1
2020-02-08T03:15:56.098351: step 2872, loss 0.0200518, acc 1
2020-02-08T03:15:56.213656: step 2873, loss 0.00542866, acc 1
2020-02-08T03:15:56.331803: step 2874, loss 0.00818522, acc 1
2020-02-08T03:15:56.449535: step 2875, loss 0.031324, acc 0.984375
2020-02-08T03:15:56.566327: step 2876, loss 0.00582679, acc 1
2020-02-08T03:15:56.680119: step 2877, loss 0.0217043, acc 1
2020-02-08T03:15:56.797033: step 2878, loss 0.0162309, acc 1
2020-02-08T03:15:56.912966: step 2879, loss 0.00938221, acc 1
2020-02-08T03:15:57.032188: step 2880, loss 0.0201228, acc 0.984375
2020-02-08T03:15:57.151403: step 2881, loss 0.0320448, acc 0.984375
2020-02-08T03:15:57.267751: step 2882, loss 0.0279593, acc 0.984375
2020-02-08T03:15:57.384723: step 2883, loss 0.0110596, acc 1
2020-02-08T03:15:57.501297: step 2884, loss 0.00890651, acc 1
2020-02-08T03:15:57.616572: step 2885, loss 0.0184093, acc 1
2020-02-08T03:15:57.733978: step 2886, loss 0.020235, acc 1
2020-02-08T03:15:57.851102: step 2887, loss 0.0280814, acc 0.984375
2020-02-08T03:15:57.966997: step 2888, loss 0.0181817, acc 0.984375
2020-02-08T03:15:58.084639: step 2889, loss 0.0324298, acc 0.984375
2020-02-08T03:15:58.202779: step 2890, loss 0.0118593, acc 1
2020-02-08T03:15:58.319231: step 2891, loss 0.015546, acc 1
2020-02-08T03:15:58.438558: step 2892, loss 0.0108592, acc 1
2020-02-08T03:15:58.555360: step 2893, loss 0.00606457, acc 1
2020-02-08T03:15:58.669902: step 2894, loss 0.0121857, acc 1
2020-02-08T03:15:58.784735: step 2895, loss 0.0186837, acc 1
2020-02-08T03:15:58.902726: step 2896, loss 0.0164951, acc 1
2020-02-08T03:15:59.019818: step 2897, loss 0.00756265, acc 1
2020-02-08T03:15:59.138036: step 2898, loss 0.0212077, acc 1
2020-02-08T03:15:59.255867: step 2899, loss 0.0429227, acc 0.984375
2020-02-08T03:15:59.369788: step 2900, loss 0.0353161, acc 0.984375

Evaluation:
2020-02-08T03:15:59.555236: step 2900, loss 1.01431, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-2900

2020-02-08T03:16:01.103275: step 2901, loss 0.00517055, acc 1
2020-02-08T03:16:01.218667: step 2902, loss 0.0302828, acc 0.984375
2020-02-08T03:16:01.335855: step 2903, loss 0.0633966, acc 0.984375
2020-02-08T03:16:01.452428: step 2904, loss 0.0113343, acc 1
2020-02-08T03:16:01.567439: step 2905, loss 0.0462213, acc 0.96875
2020-02-08T03:16:01.685440: step 2906, loss 0.0169474, acc 1
2020-02-08T03:16:01.803865: step 2907, loss 0.0341156, acc 0.984375
2020-02-08T03:16:01.919001: step 2908, loss 0.0376324, acc 0.984375
2020-02-08T03:16:02.036977: step 2909, loss 0.00819755, acc 1
2020-02-08T03:16:02.153671: step 2910, loss 0.00552507, acc 1
2020-02-08T03:16:02.271005: step 2911, loss 0.0101639, acc 1
2020-02-08T03:16:02.389196: step 2912, loss 0.0516043, acc 0.984375
2020-02-08T03:16:02.505387: step 2913, loss 0.0187953, acc 0.984375
2020-02-08T03:16:02.627628: step 2914, loss 0.0157012, acc 0.984375
2020-02-08T03:16:02.742450: step 2915, loss 0.0251634, acc 0.984375
2020-02-08T03:16:02.857372: step 2916, loss 0.0123471, acc 1
2020-02-08T03:16:02.971616: step 2917, loss 0.0283629, acc 0.984375
2020-02-08T03:16:03.088341: step 2918, loss 0.0140513, acc 1
2020-02-08T03:16:03.203594: step 2919, loss 0.00536107, acc 1
2020-02-08T03:16:03.319835: step 2920, loss 0.00619446, acc 1
2020-02-08T03:16:03.436558: step 2921, loss 0.00722731, acc 1
2020-02-08T03:16:03.554903: step 2922, loss 0.0154964, acc 1
2020-02-08T03:16:03.670007: step 2923, loss 0.0130636, acc 1
2020-02-08T03:16:03.788054: step 2924, loss 0.0030844, acc 1
2020-02-08T03:16:03.904252: step 2925, loss 0.00814283, acc 1
2020-02-08T03:16:04.017614: step 2926, loss 0.00815241, acc 1
2020-02-08T03:16:04.135008: step 2927, loss 0.0139821, acc 1
2020-02-08T03:16:04.253908: step 2928, loss 0.0111138, acc 1
2020-02-08T03:16:04.372058: step 2929, loss 0.0144821, acc 1
2020-02-08T03:16:04.490954: step 2930, loss 0.0161067, acc 1
2020-02-08T03:16:04.607565: step 2931, loss 0.0195335, acc 1
2020-02-08T03:16:04.722626: step 2932, loss 0.00898281, acc 1
2020-02-08T03:16:04.840908: step 2933, loss 0.0188121, acc 1
2020-02-08T03:16:04.956215: step 2934, loss 0.0232411, acc 0.984375
2020-02-08T03:16:05.071873: step 2935, loss 0.017019, acc 1
2020-02-08T03:16:05.188211: step 2936, loss 0.00821016, acc 1
2020-02-08T03:16:05.305414: step 2937, loss 0.0349077, acc 0.984375
2020-02-08T03:16:05.420372: step 2938, loss 0.018696, acc 1
2020-02-08T03:16:05.536116: step 2939, loss 0.0120738, acc 1
2020-02-08T03:16:05.654644: step 2940, loss 0.0181698, acc 0.984375
2020-02-08T03:16:05.767738: step 2941, loss 0.00684815, acc 1
2020-02-08T03:16:05.885790: step 2942, loss 0.0186208, acc 1
2020-02-08T03:16:06.003864: step 2943, loss 0.0070827, acc 1
2020-02-08T03:16:06.120193: step 2944, loss 0.0199022, acc 0.984375
2020-02-08T03:16:06.238607: step 2945, loss 0.0463478, acc 0.984375
2020-02-08T03:16:06.353406: step 2946, loss 0.0479714, acc 0.984375
2020-02-08T03:16:06.466672: step 2947, loss 0.021824, acc 1
2020-02-08T03:16:06.582060: step 2948, loss 0.0587818, acc 0.96875
2020-02-08T03:16:06.699032: step 2949, loss 0.0125856, acc 1
2020-02-08T03:16:06.814600: step 2950, loss 0.00371051, acc 1
2020-02-08T03:16:06.933867: step 2951, loss 0.0106688, acc 1
2020-02-08T03:16:07.053007: step 2952, loss 0.014225, acc 1
2020-02-08T03:16:07.168219: step 2953, loss 0.0343863, acc 0.984375
2020-02-08T03:16:07.284639: step 2954, loss 0.00593242, acc 1
2020-02-08T03:16:07.404228: step 2955, loss 0.0273762, acc 0.984375
2020-02-08T03:16:07.518452: step 2956, loss 0.0383659, acc 0.984375
2020-02-08T03:16:07.633847: step 2957, loss 0.006077, acc 1
2020-02-08T03:16:07.750830: step 2958, loss 0.037684, acc 0.984375
2020-02-08T03:16:07.868717: step 2959, loss 0.0140081, acc 1
2020-02-08T03:16:07.987881: step 2960, loss 0.00481658, acc 1
2020-02-08T03:16:08.103689: step 2961, loss 0.00619224, acc 1
2020-02-08T03:16:08.220782: step 2962, loss 0.00245068, acc 1
2020-02-08T03:16:08.340601: step 2963, loss 0.010154, acc 1
2020-02-08T03:16:08.456674: step 2964, loss 0.0135188, acc 1
2020-02-08T03:16:08.574844: step 2965, loss 0.0125914, acc 1
2020-02-08T03:16:08.695098: step 2966, loss 0.0482366, acc 0.96875
2020-02-08T03:16:08.811663: step 2967, loss 0.00992976, acc 1
2020-02-08T03:16:08.932372: step 2968, loss 0.0243923, acc 0.984375
2020-02-08T03:16:09.052404: step 2969, loss 0.00769271, acc 1
2020-02-08T03:16:09.168554: step 2970, loss 0.0381284, acc 0.984375
2020-02-08T03:16:09.285575: step 2971, loss 0.0309453, acc 0.984375
2020-02-08T03:16:09.407251: step 2972, loss 0.00486421, acc 1
2020-02-08T03:16:09.524875: step 2973, loss 0.00411502, acc 1
2020-02-08T03:16:09.643034: step 2974, loss 0.0108932, acc 1
2020-02-08T03:16:09.761084: step 2975, loss 0.0162047, acc 1
2020-02-08T03:16:09.877244: step 2976, loss 0.05181, acc 0.984375
2020-02-08T03:16:09.996983: step 2977, loss 0.00924745, acc 1
2020-02-08T03:16:10.113303: step 2978, loss 0.0354901, acc 0.984375
2020-02-08T03:16:10.232838: step 2979, loss 0.00436262, acc 1
2020-02-08T03:16:10.354627: step 2980, loss 0.0611515, acc 0.984375
2020-02-08T03:16:10.471663: step 2981, loss 0.00264702, acc 1
2020-02-08T03:16:10.584927: step 2982, loss 0.0146169, acc 1
2020-02-08T03:16:10.703681: step 2983, loss 0.00241027, acc 1
2020-02-08T03:16:10.817487: step 2984, loss 0.00517935, acc 1
2020-02-08T03:16:10.932914: step 2985, loss 0.00798297, acc 1
2020-02-08T03:16:11.053042: step 2986, loss 0.0302345, acc 0.984375
2020-02-08T03:16:11.168534: step 2987, loss 0.0372059, acc 0.984375
2020-02-08T03:16:11.285463: step 2988, loss 0.00520366, acc 1
2020-02-08T03:16:11.402209: step 2989, loss 0.0540155, acc 0.984375
2020-02-08T03:16:11.518039: step 2990, loss 0.00937312, acc 1
2020-02-08T03:16:11.635176: step 2991, loss 0.0376474, acc 0.984375
2020-02-08T03:16:11.752443: step 2992, loss 0.0206695, acc 0.984375
2020-02-08T03:16:11.870377: step 2993, loss 0.00651008, acc 1
2020-02-08T03:16:11.989096: step 2994, loss 0.0137756, acc 1
2020-02-08T03:16:12.105233: step 2995, loss 0.0105857, acc 1
2020-02-08T03:16:12.224202: step 2996, loss 0.0181214, acc 1
2020-02-08T03:16:12.339498: step 2997, loss 0.013241, acc 1
2020-02-08T03:16:12.455679: step 2998, loss 0.00976726, acc 1
2020-02-08T03:16:12.571797: step 2999, loss 0.0113787, acc 1
2020-02-08T03:16:12.685443: step 3000, loss 0.00663397, acc 1

Evaluation:
2020-02-08T03:16:12.872362: step 3000, loss 1.05599, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102569/checkpoints/model-3000

