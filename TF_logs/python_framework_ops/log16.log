WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:02:22.138455 4658638272 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:02:22.138726 4658638272 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:02:22.138835 4658638272 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 03:02:22.664576 4658638272 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 03:02:22.664808 4658638272 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 03:02:22.665008: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 03:02:22.677639: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb5531918a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 03:02:22.677660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 03:02:22.678021 4658638272 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 03:02:22.681278 4658638272 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 03:02:22.694474 4658638272 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 03:02:22.708328 4658638272 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 03:02:22.731299 4658638272 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 03:02:22.741111 4658638272 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 03:02:22.741575 4658638272 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 03:02:22.758607 4658638272 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 03:02:22.760965 4658638272 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 03:02:22.785730 4658638272 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 03:02:23.026669 4658638272 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 03:02:23.026901 4658638272 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 03:02:23.032147 4658638272 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 03:02:23.056432 4658638272 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 03:02:23.057569 4658638272 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 03:02:23.072976 4658638272 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 03:02:23.074042 4658638272 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 03:02:23.088524 4658638272 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 03:02:23.090243 4658638272 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 03:02:23.110497 4658638272 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 03:02:23.111561 4658638272 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 03:02:23.125680 4658638272 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 03:02:23.126746 4658638272 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 03:02:23.143007 4658638272 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 03:02:23.144872 4658638272 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 03:02:23.166368 4658638272 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 03:02:23.167433 4658638272 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 03:02:23.181708 4658638272 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 03:02:23.182772 4658638272 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 03:02:23.203905 4658638272 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 03:02:23.205853 4658638272 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 03:02:23.211606 4658638272 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 03:02:23.655272 4658638272 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 03:02:23.655472 4658638272 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 03:02:23.826181 4658638272 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 03:02:24.480293 4658638272 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 03:03:47.977671 4658638272 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143

2020-02-08T03:02:24.479748: step 1, loss 5.59378, acc 0.484375
2020-02-08T03:02:24.630160: step 2, loss 3.8931, acc 0.515625
2020-02-08T03:02:24.769330: step 3, loss 3.78859, acc 0.515625
2020-02-08T03:02:24.909681: step 4, loss 2.01338, acc 0.640625
2020-02-08T03:02:25.036071: step 5, loss 1.89475, acc 0.53125
2020-02-08T03:02:25.166523: step 6, loss 2.50621, acc 0.375
2020-02-08T03:02:25.300064: step 7, loss 2.41454, acc 0.375
2020-02-08T03:02:25.433058: step 8, loss 2.31429, acc 0.515625
2020-02-08T03:02:25.563889: step 9, loss 2.97916, acc 0.421875
2020-02-08T03:02:25.694317: step 10, loss 1.68516, acc 0.53125
2020-02-08T03:02:25.828366: step 11, loss 2.38176, acc 0.4375
2020-02-08T03:02:25.953314: step 12, loss 2.80311, acc 0.421875
2020-02-08T03:02:26.087371: step 13, loss 1.83474, acc 0.515625
2020-02-08T03:02:26.219926: step 14, loss 2.09529, acc 0.515625
2020-02-08T03:02:26.353268: step 15, loss 1.64312, acc 0.546875
2020-02-08T03:02:26.485982: step 16, loss 1.60178, acc 0.53125
2020-02-08T03:02:26.628439: step 17, loss 1.56078, acc 0.578125
2020-02-08T03:02:26.766862: step 18, loss 2.25001, acc 0.46875
2020-02-08T03:02:26.910541: step 19, loss 1.90944, acc 0.53125
2020-02-08T03:02:27.050974: step 20, loss 1.59578, acc 0.59375
2020-02-08T03:02:27.187145: step 21, loss 1.73656, acc 0.59375
2020-02-08T03:02:27.323796: step 22, loss 1.99515, acc 0.421875
2020-02-08T03:02:27.461006: step 23, loss 2.07864, acc 0.515625
2020-02-08T03:02:27.596410: step 24, loss 1.42874, acc 0.625
2020-02-08T03:02:27.729932: step 25, loss 1.65973, acc 0.578125
2020-02-08T03:02:27.879374: step 26, loss 1.9058, acc 0.5
2020-02-08T03:02:28.017077: step 27, loss 1.80775, acc 0.515625
2020-02-08T03:02:28.154485: step 28, loss 1.75019, acc 0.546875
2020-02-08T03:02:28.293561: step 29, loss 1.79712, acc 0.546875
2020-02-08T03:02:28.433987: step 30, loss 1.36864, acc 0.640625
2020-02-08T03:02:28.572624: step 31, loss 2.1894, acc 0.515625
2020-02-08T03:02:28.711297: step 32, loss 1.41419, acc 0.5625
2020-02-08T03:02:28.848583: step 33, loss 1.8382, acc 0.46875
2020-02-08T03:02:28.985715: step 34, loss 1.81694, acc 0.578125
2020-02-08T03:02:29.122035: step 35, loss 2.32574, acc 0.4375
2020-02-08T03:02:29.260841: step 36, loss 2.26956, acc 0.4375
2020-02-08T03:02:29.400948: step 37, loss 2.15993, acc 0.484375
2020-02-08T03:02:29.541087: step 38, loss 1.92614, acc 0.46875
2020-02-08T03:02:29.680397: step 39, loss 1.95795, acc 0.484375
2020-02-08T03:02:29.820665: step 40, loss 2.30442, acc 0.4375
2020-02-08T03:02:29.958821: step 41, loss 2.15402, acc 0.46875
2020-02-08T03:02:30.094050: step 42, loss 1.9412, acc 0.421875
2020-02-08T03:02:30.231075: step 43, loss 1.67255, acc 0.53125
2020-02-08T03:02:30.366218: step 44, loss 1.64562, acc 0.546875
2020-02-08T03:02:30.506382: step 45, loss 2.09922, acc 0.484375
2020-02-08T03:02:30.641872: step 46, loss 1.67433, acc 0.5625
2020-02-08T03:02:30.781110: step 47, loss 2.04492, acc 0.5
2020-02-08T03:02:30.921464: step 48, loss 2.14656, acc 0.4375
2020-02-08T03:02:31.064363: step 49, loss 1.85482, acc 0.53125
2020-02-08T03:02:31.198662: step 50, loss 1.25939, acc 0.640625
2020-02-08T03:02:31.334335: step 51, loss 1.44529, acc 0.5
2020-02-08T03:02:31.467996: step 52, loss 1.6418, acc 0.4375
2020-02-08T03:02:31.591141: step 53, loss 1.66639, acc 0.546875
2020-02-08T03:02:31.729508: step 54, loss 1.81577, acc 0.5
2020-02-08T03:02:31.876970: step 55, loss 2.04988, acc 0.46875
2020-02-08T03:02:32.017378: step 56, loss 2.12769, acc 0.5
2020-02-08T03:02:32.160938: step 57, loss 2.24026, acc 0.5625
2020-02-08T03:02:32.285192: step 58, loss 1.36637, acc 0.640625
2020-02-08T03:02:32.402723: step 59, loss 1.37236, acc 0.5625
2020-02-08T03:02:32.520422: step 60, loss 1.38157, acc 0.515625
2020-02-08T03:02:32.637739: step 61, loss 2.38193, acc 0.40625
2020-02-08T03:02:32.774384: step 62, loss 2.02273, acc 0.46875
2020-02-08T03:02:32.902395: step 63, loss 1.88752, acc 0.53125
2020-02-08T03:02:33.018466: step 64, loss 1.1808, acc 0.578125
2020-02-08T03:02:33.135216: step 65, loss 1.40881, acc 0.5625
2020-02-08T03:02:33.256298: step 66, loss 1.191, acc 0.5625
2020-02-08T03:02:33.378506: step 67, loss 1.70272, acc 0.546875
2020-02-08T03:02:33.501762: step 68, loss 1.50109, acc 0.53125
2020-02-08T03:02:33.630515: step 69, loss 1.6901, acc 0.5
2020-02-08T03:02:33.752001: step 70, loss 1.71762, acc 0.421875
2020-02-08T03:02:33.878013: step 71, loss 1.81729, acc 0.515625
2020-02-08T03:02:33.994393: step 72, loss 1.48507, acc 0.53125
2020-02-08T03:02:34.117455: step 73, loss 1.78346, acc 0.53125
2020-02-08T03:02:34.233612: step 74, loss 1.62694, acc 0.515625
2020-02-08T03:02:34.354862: step 75, loss 1.43291, acc 0.53125
2020-02-08T03:02:34.475360: step 76, loss 1.73011, acc 0.546875
2020-02-08T03:02:34.591494: step 77, loss 1.23551, acc 0.5625
2020-02-08T03:02:34.709929: step 78, loss 1.86287, acc 0.578125
2020-02-08T03:02:34.830389: step 79, loss 1.5351, acc 0.53125
2020-02-08T03:02:34.946261: step 80, loss 1.41998, acc 0.484375
2020-02-08T03:02:35.065928: step 81, loss 1.63579, acc 0.5625
2020-02-08T03:02:35.181312: step 82, loss 1.5569, acc 0.484375
2020-02-08T03:02:35.304468: step 83, loss 1.59708, acc 0.5625
2020-02-08T03:02:35.424024: step 84, loss 1.20563, acc 0.609375
2020-02-08T03:02:35.539871: step 85, loss 1.53482, acc 0.5
2020-02-08T03:02:35.657993: step 86, loss 1.73735, acc 0.515625
2020-02-08T03:02:35.779519: step 87, loss 1.79312, acc 0.546875
2020-02-08T03:02:35.893980: step 88, loss 1.79108, acc 0.453125
2020-02-08T03:02:36.012659: step 89, loss 2.00214, acc 0.46875
2020-02-08T03:02:36.128508: step 90, loss 1.73855, acc 0.5
2020-02-08T03:02:36.244891: step 91, loss 1.51122, acc 0.546875
2020-02-08T03:02:36.365864: step 92, loss 1.62696, acc 0.484375
2020-02-08T03:02:36.482968: step 93, loss 1.65475, acc 0.625
2020-02-08T03:02:36.601967: step 94, loss 1.23815, acc 0.625
2020-02-08T03:02:36.721923: step 95, loss 1.46972, acc 0.578125
2020-02-08T03:02:36.842498: step 96, loss 1.43715, acc 0.59375
2020-02-08T03:02:36.963332: step 97, loss 1.64037, acc 0.5
2020-02-08T03:02:37.080726: step 98, loss 1.78412, acc 0.40625
2020-02-08T03:02:37.197656: step 99, loss 2.30374, acc 0.40625
2020-02-08T03:02:37.316436: step 100, loss 1.19899, acc 0.578125

Evaluation:
2020-02-08T03:02:37.555123: step 100, loss 0.836831, acc 0.577861

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-100

2020-02-08T03:02:40.513615: step 101, loss 1.57332, acc 0.484375
2020-02-08T03:02:40.631431: step 102, loss 1.81533, acc 0.46875
2020-02-08T03:02:40.753477: step 103, loss 1.1162, acc 0.671875
2020-02-08T03:02:40.873143: step 104, loss 1.50031, acc 0.59375
2020-02-08T03:02:40.987342: step 105, loss 1.67142, acc 0.46875
2020-02-08T03:02:41.106240: step 106, loss 1.68057, acc 0.5625
2020-02-08T03:02:41.224059: step 107, loss 1.56394, acc 0.53125
2020-02-08T03:02:41.339138: step 108, loss 1.27629, acc 0.578125
2020-02-08T03:02:41.457185: step 109, loss 1.23092, acc 0.578125
2020-02-08T03:02:41.575850: step 110, loss 1.26638, acc 0.59375
2020-02-08T03:02:41.691156: step 111, loss 1.49405, acc 0.546875
2020-02-08T03:02:41.815736: step 112, loss 1.45605, acc 0.578125
2020-02-08T03:02:41.931788: step 113, loss 1.93455, acc 0.484375
2020-02-08T03:02:42.046298: step 114, loss 1.19029, acc 0.625
2020-02-08T03:02:42.163293: step 115, loss 1.8407, acc 0.46875
2020-02-08T03:02:42.280208: step 116, loss 1.50874, acc 0.453125
2020-02-08T03:02:42.397157: step 117, loss 1.53423, acc 0.5625
2020-02-08T03:02:42.513931: step 118, loss 1.21673, acc 0.609375
2020-02-08T03:02:42.632066: step 119, loss 1.58016, acc 0.546875
2020-02-08T03:02:42.751524: step 120, loss 1.36259, acc 0.53125
2020-02-08T03:02:42.869020: step 121, loss 1.36565, acc 0.546875
2020-02-08T03:02:42.984888: step 122, loss 1.84644, acc 0.46875
2020-02-08T03:02:43.102703: step 123, loss 1.32425, acc 0.640625
2020-02-08T03:02:43.216767: step 124, loss 1.29005, acc 0.53125
2020-02-08T03:02:43.333309: step 125, loss 1.34802, acc 0.546875
2020-02-08T03:02:43.449916: step 126, loss 1.75711, acc 0.53125
2020-02-08T03:02:43.567717: step 127, loss 1.55553, acc 0.578125
2020-02-08T03:02:43.684064: step 128, loss 1.30424, acc 0.53125
2020-02-08T03:02:43.804989: step 129, loss 1.44721, acc 0.578125
2020-02-08T03:02:43.923229: step 130, loss 1.00872, acc 0.640625
2020-02-08T03:02:44.042041: step 131, loss 1.04835, acc 0.59375
2020-02-08T03:02:44.161391: step 132, loss 1.53555, acc 0.53125
2020-02-08T03:02:44.278521: step 133, loss 1.48738, acc 0.515625
2020-02-08T03:02:44.392989: step 134, loss 1.56327, acc 0.484375
2020-02-08T03:02:44.510688: step 135, loss 1.22894, acc 0.625
2020-02-08T03:02:44.628488: step 136, loss 1.51907, acc 0.5
2020-02-08T03:02:44.745006: step 137, loss 1.24004, acc 0.5625
2020-02-08T03:02:44.864424: step 138, loss 1.49418, acc 0.453125
2020-02-08T03:02:44.978664: step 139, loss 1.93003, acc 0.46875
2020-02-08T03:02:45.092777: step 140, loss 1.48957, acc 0.46875
2020-02-08T03:02:45.212063: step 141, loss 1.48534, acc 0.53125
2020-02-08T03:02:45.328173: step 142, loss 1.44417, acc 0.484375
2020-02-08T03:02:45.444266: step 143, loss 1.12994, acc 0.65625
2020-02-08T03:02:45.561781: step 144, loss 1.40658, acc 0.53125
2020-02-08T03:02:45.681161: step 145, loss 1.43718, acc 0.5625
2020-02-08T03:02:45.803168: step 146, loss 1.33398, acc 0.53125
2020-02-08T03:02:45.918852: step 147, loss 1.30695, acc 0.515625
2020-02-08T03:02:46.038212: step 148, loss 1.48863, acc 0.5625
2020-02-08T03:02:46.154101: step 149, loss 0.887364, acc 0.65625
2020-02-08T03:02:46.267108: step 150, loss 1.31866, acc 0.55
2020-02-08T03:02:46.383864: step 151, loss 1.39396, acc 0.625
2020-02-08T03:02:46.501258: step 152, loss 0.926555, acc 0.671875
2020-02-08T03:02:46.620720: step 153, loss 0.998865, acc 0.65625
2020-02-08T03:02:46.735929: step 154, loss 0.996109, acc 0.609375
2020-02-08T03:02:46.855791: step 155, loss 1.16941, acc 0.578125
2020-02-08T03:02:46.972550: step 156, loss 1.0545, acc 0.578125
2020-02-08T03:02:47.087947: step 157, loss 1.053, acc 0.640625
2020-02-08T03:02:47.206342: step 158, loss 1.32737, acc 0.53125
2020-02-08T03:02:47.322509: step 159, loss 0.873901, acc 0.703125
2020-02-08T03:02:47.439421: step 160, loss 0.91702, acc 0.65625
2020-02-08T03:02:47.557683: step 161, loss 1.08815, acc 0.609375
2020-02-08T03:02:47.673916: step 162, loss 0.972797, acc 0.59375
2020-02-08T03:02:47.793171: step 163, loss 1.28907, acc 0.5625
2020-02-08T03:02:47.910575: step 164, loss 0.789762, acc 0.671875
2020-02-08T03:02:48.026043: step 165, loss 0.926527, acc 0.65625
2020-02-08T03:02:48.143109: step 166, loss 1.28574, acc 0.453125
2020-02-08T03:02:48.259697: step 167, loss 1.24785, acc 0.59375
2020-02-08T03:02:48.375621: step 168, loss 1.23463, acc 0.53125
2020-02-08T03:02:48.491730: step 169, loss 0.914487, acc 0.609375
2020-02-08T03:02:48.609652: step 170, loss 1.38205, acc 0.5625
2020-02-08T03:02:48.725835: step 171, loss 1.02178, acc 0.625
2020-02-08T03:02:48.849215: step 172, loss 1.18758, acc 0.578125
2020-02-08T03:02:48.966656: step 173, loss 1.38359, acc 0.546875
2020-02-08T03:02:49.083862: step 174, loss 1.00476, acc 0.671875
2020-02-08T03:02:49.200749: step 175, loss 0.859175, acc 0.609375
2020-02-08T03:02:49.316505: step 176, loss 1.1665, acc 0.546875
2020-02-08T03:02:49.435294: step 177, loss 1.10656, acc 0.546875
2020-02-08T03:02:49.550419: step 178, loss 1.44422, acc 0.5
2020-02-08T03:02:49.667632: step 179, loss 0.650061, acc 0.734375
2020-02-08T03:02:49.784033: step 180, loss 0.971116, acc 0.65625
2020-02-08T03:02:49.901019: step 181, loss 1.0553, acc 0.640625
2020-02-08T03:02:50.017779: step 182, loss 1.09612, acc 0.5625
2020-02-08T03:02:50.132283: step 183, loss 1.18572, acc 0.578125
2020-02-08T03:02:50.247631: step 184, loss 1.23042, acc 0.640625
2020-02-08T03:02:50.366005: step 185, loss 1.13536, acc 0.578125
2020-02-08T03:02:50.481223: step 186, loss 0.926484, acc 0.75
2020-02-08T03:02:50.594788: step 187, loss 1.3735, acc 0.5
2020-02-08T03:02:50.716066: step 188, loss 1.00201, acc 0.609375
2020-02-08T03:02:50.835663: step 189, loss 0.709471, acc 0.734375
2020-02-08T03:02:50.952345: step 190, loss 1.00513, acc 0.546875
2020-02-08T03:02:51.070751: step 191, loss 1.05713, acc 0.546875
2020-02-08T03:02:51.188001: step 192, loss 1.06036, acc 0.625
2020-02-08T03:02:51.299982: step 193, loss 1.23824, acc 0.53125
2020-02-08T03:02:51.513572: step 194, loss 1.12833, acc 0.546875
2020-02-08T03:02:51.644767: step 195, loss 1.15084, acc 0.578125
2020-02-08T03:02:51.763641: step 196, loss 1.16362, acc 0.65625
2020-02-08T03:02:51.879142: step 197, loss 1.37716, acc 0.546875
2020-02-08T03:02:51.995953: step 198, loss 1.09547, acc 0.578125
2020-02-08T03:02:52.116942: step 199, loss 1.28547, acc 0.546875
2020-02-08T03:02:52.231449: step 200, loss 0.726747, acc 0.640625

Evaluation:
2020-02-08T03:02:52.419579: step 200, loss 0.725365, acc 0.586304

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-200

2020-02-08T03:02:53.909409: step 201, loss 0.753038, acc 0.71875
2020-02-08T03:02:54.026693: step 202, loss 0.792141, acc 0.640625
2020-02-08T03:02:54.141212: step 203, loss 0.883176, acc 0.640625
2020-02-08T03:02:54.258806: step 204, loss 1.02039, acc 0.453125
2020-02-08T03:02:54.375643: step 205, loss 0.924963, acc 0.65625
2020-02-08T03:02:54.492868: step 206, loss 1.27729, acc 0.5
2020-02-08T03:02:54.608621: step 207, loss 1.04356, acc 0.5625
2020-02-08T03:02:54.724230: step 208, loss 0.820303, acc 0.65625
2020-02-08T03:02:54.841262: step 209, loss 0.881682, acc 0.59375
2020-02-08T03:02:54.958132: step 210, loss 0.910561, acc 0.625
2020-02-08T03:02:55.072589: step 211, loss 1.05856, acc 0.546875
2020-02-08T03:02:55.189277: step 212, loss 1.21367, acc 0.546875
2020-02-08T03:02:55.308944: step 213, loss 0.983128, acc 0.53125
2020-02-08T03:02:55.427977: step 214, loss 1.049, acc 0.546875
2020-02-08T03:02:55.541328: step 215, loss 0.811547, acc 0.6875
2020-02-08T03:02:55.658447: step 216, loss 0.998351, acc 0.5625
2020-02-08T03:02:55.773161: step 217, loss 1.2722, acc 0.484375
2020-02-08T03:02:55.888982: step 218, loss 1.00169, acc 0.671875
2020-02-08T03:02:56.007466: step 219, loss 0.856815, acc 0.625
2020-02-08T03:02:56.124920: step 220, loss 0.782145, acc 0.625
2020-02-08T03:02:56.240699: step 221, loss 0.975037, acc 0.609375
2020-02-08T03:02:56.359929: step 222, loss 0.731829, acc 0.59375
2020-02-08T03:02:56.476007: step 223, loss 1.09075, acc 0.625
2020-02-08T03:02:56.589387: step 224, loss 0.698761, acc 0.671875
2020-02-08T03:02:56.707493: step 225, loss 1.05151, acc 0.578125
2020-02-08T03:02:56.824529: step 226, loss 1.02506, acc 0.625
2020-02-08T03:02:56.940153: step 227, loss 1.01318, acc 0.5625
2020-02-08T03:02:57.056868: step 228, loss 1.11562, acc 0.578125
2020-02-08T03:02:57.175410: step 229, loss 0.949991, acc 0.546875
2020-02-08T03:02:57.288906: step 230, loss 0.696897, acc 0.71875
2020-02-08T03:02:57.406386: step 231, loss 1.03307, acc 0.578125
2020-02-08T03:02:57.524155: step 232, loss 0.920788, acc 0.578125
2020-02-08T03:02:57.641154: step 233, loss 1.06014, acc 0.671875
2020-02-08T03:02:57.758024: step 234, loss 0.664559, acc 0.75
2020-02-08T03:02:57.873003: step 235, loss 0.650067, acc 0.734375
2020-02-08T03:02:57.987609: step 236, loss 0.730885, acc 0.609375
2020-02-08T03:02:58.105630: step 237, loss 0.957425, acc 0.59375
2020-02-08T03:02:58.221377: step 238, loss 0.823365, acc 0.671875
2020-02-08T03:02:58.335638: step 239, loss 0.812604, acc 0.59375
2020-02-08T03:02:58.451987: step 240, loss 0.726568, acc 0.6875
2020-02-08T03:02:58.568739: step 241, loss 1.1331, acc 0.59375
2020-02-08T03:02:58.686707: step 242, loss 1.19762, acc 0.5625
2020-02-08T03:02:58.807350: step 243, loss 0.826127, acc 0.671875
2020-02-08T03:02:58.924048: step 244, loss 0.895558, acc 0.671875
2020-02-08T03:02:59.039773: step 245, loss 0.77775, acc 0.609375
2020-02-08T03:02:59.154297: step 246, loss 0.821179, acc 0.578125
2020-02-08T03:02:59.269614: step 247, loss 0.952419, acc 0.625
2020-02-08T03:02:59.383569: step 248, loss 1.06232, acc 0.546875
2020-02-08T03:02:59.500147: step 249, loss 0.857177, acc 0.578125
2020-02-08T03:02:59.616817: step 250, loss 1.19856, acc 0.515625
2020-02-08T03:02:59.732645: step 251, loss 1.03211, acc 0.59375
2020-02-08T03:02:59.854476: step 252, loss 0.990749, acc 0.625
2020-02-08T03:02:59.972314: step 253, loss 0.79637, acc 0.640625
2020-02-08T03:03:00.087502: step 254, loss 1.05732, acc 0.578125
2020-02-08T03:03:00.203202: step 255, loss 0.725065, acc 0.625
2020-02-08T03:03:00.323713: step 256, loss 0.738992, acc 0.578125
2020-02-08T03:03:00.440042: step 257, loss 0.918826, acc 0.65625
2020-02-08T03:03:00.557292: step 258, loss 0.910943, acc 0.625
2020-02-08T03:03:00.676031: step 259, loss 0.933073, acc 0.59375
2020-02-08T03:03:00.794747: step 260, loss 0.989028, acc 0.59375
2020-02-08T03:03:00.911816: step 261, loss 0.992625, acc 0.5
2020-02-08T03:03:01.028334: step 262, loss 0.794234, acc 0.609375
2020-02-08T03:03:01.144097: step 263, loss 0.948485, acc 0.609375
2020-02-08T03:03:01.263786: step 264, loss 0.905315, acc 0.640625
2020-02-08T03:03:01.381258: step 265, loss 0.957773, acc 0.5625
2020-02-08T03:03:01.495727: step 266, loss 0.916521, acc 0.609375
2020-02-08T03:03:01.610719: step 267, loss 0.817099, acc 0.59375
2020-02-08T03:03:01.725000: step 268, loss 0.801994, acc 0.609375
2020-02-08T03:03:01.845428: step 269, loss 0.915627, acc 0.578125
2020-02-08T03:03:01.961374: step 270, loss 0.566785, acc 0.703125
2020-02-08T03:03:02.077723: step 271, loss 0.86889, acc 0.640625
2020-02-08T03:03:02.194903: step 272, loss 1.09345, acc 0.546875
2020-02-08T03:03:02.309473: step 273, loss 1.02086, acc 0.53125
2020-02-08T03:03:02.425734: step 274, loss 0.993288, acc 0.671875
2020-02-08T03:03:02.540222: step 275, loss 0.88909, acc 0.609375
2020-02-08T03:03:02.654485: step 276, loss 0.919407, acc 0.609375
2020-02-08T03:03:02.771092: step 277, loss 0.801608, acc 0.703125
2020-02-08T03:03:02.888163: step 278, loss 0.997108, acc 0.578125
2020-02-08T03:03:03.006584: step 279, loss 1.00301, acc 0.578125
2020-02-08T03:03:03.123328: step 280, loss 0.726939, acc 0.703125
2020-02-08T03:03:03.244866: step 281, loss 1.24528, acc 0.484375
2020-02-08T03:03:03.360585: step 282, loss 0.705082, acc 0.671875
2020-02-08T03:03:03.477347: step 283, loss 0.95031, acc 0.5
2020-02-08T03:03:03.596502: step 284, loss 0.820933, acc 0.59375
2020-02-08T03:03:03.712021: step 285, loss 0.70768, acc 0.671875
2020-02-08T03:03:03.830350: step 286, loss 0.989992, acc 0.671875
2020-02-08T03:03:03.945899: step 287, loss 0.744835, acc 0.59375
2020-02-08T03:03:04.064235: step 288, loss 0.930072, acc 0.5625
2020-02-08T03:03:04.180110: step 289, loss 0.819795, acc 0.609375
2020-02-08T03:03:04.295372: step 290, loss 0.604936, acc 0.75
2020-02-08T03:03:04.410008: step 291, loss 0.738666, acc 0.671875
2020-02-08T03:03:04.527727: step 292, loss 1.05319, acc 0.578125
2020-02-08T03:03:04.643990: step 293, loss 0.885355, acc 0.5625
2020-02-08T03:03:04.762809: step 294, loss 0.609052, acc 0.671875
2020-02-08T03:03:04.880042: step 295, loss 0.657367, acc 0.6875
2020-02-08T03:03:04.997075: step 296, loss 0.775288, acc 0.59375
2020-02-08T03:03:05.113517: step 297, loss 0.726887, acc 0.640625
2020-02-08T03:03:05.232138: step 298, loss 0.934967, acc 0.5625
2020-02-08T03:03:05.349508: step 299, loss 0.867347, acc 0.578125
2020-02-08T03:03:05.463718: step 300, loss 0.68992, acc 0.733333

Evaluation:
2020-02-08T03:03:05.651868: step 300, loss 0.648084, acc 0.621951

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-300

2020-02-08T03:03:07.733588: step 301, loss 0.568512, acc 0.75
2020-02-08T03:03:07.854404: step 302, loss 0.618959, acc 0.75
2020-02-08T03:03:07.972365: step 303, loss 0.636512, acc 0.71875
2020-02-08T03:03:08.088732: step 304, loss 0.551526, acc 0.6875
2020-02-08T03:03:08.203813: step 305, loss 1.07195, acc 0.53125
2020-02-08T03:03:08.321246: step 306, loss 0.835533, acc 0.59375
2020-02-08T03:03:08.439084: step 307, loss 0.498114, acc 0.765625
2020-02-08T03:03:08.552404: step 308, loss 0.86847, acc 0.609375
2020-02-08T03:03:08.667836: step 309, loss 0.618933, acc 0.734375
2020-02-08T03:03:08.786094: step 310, loss 0.675694, acc 0.734375
2020-02-08T03:03:08.903323: step 311, loss 0.697106, acc 0.671875
2020-02-08T03:03:09.018288: step 312, loss 0.572212, acc 0.71875
2020-02-08T03:03:09.133546: step 313, loss 0.793541, acc 0.65625
2020-02-08T03:03:09.249796: step 314, loss 0.69562, acc 0.6875
2020-02-08T03:03:09.366408: step 315, loss 0.717381, acc 0.640625
2020-02-08T03:03:09.484977: step 316, loss 0.647065, acc 0.71875
2020-02-08T03:03:09.600345: step 317, loss 0.858888, acc 0.671875
2020-02-08T03:03:09.715760: step 318, loss 0.951495, acc 0.59375
2020-02-08T03:03:09.834091: step 319, loss 0.775909, acc 0.609375
2020-02-08T03:03:09.950550: step 320, loss 0.634025, acc 0.65625
2020-02-08T03:03:10.065064: step 321, loss 0.877232, acc 0.59375
2020-02-08T03:03:10.184888: step 322, loss 0.731552, acc 0.65625
2020-02-08T03:03:10.301099: step 323, loss 0.700357, acc 0.703125
2020-02-08T03:03:10.418522: step 324, loss 0.776491, acc 0.59375
2020-02-08T03:03:10.535315: step 325, loss 0.808457, acc 0.59375
2020-02-08T03:03:10.651331: step 326, loss 0.525851, acc 0.671875
2020-02-08T03:03:10.768550: step 327, loss 0.629875, acc 0.703125
2020-02-08T03:03:10.885712: step 328, loss 0.737196, acc 0.75
2020-02-08T03:03:10.999829: step 329, loss 0.669938, acc 0.6875
2020-02-08T03:03:11.118977: step 330, loss 0.704361, acc 0.625
2020-02-08T03:03:11.235884: step 331, loss 0.556609, acc 0.734375
2020-02-08T03:03:11.352794: step 332, loss 0.698249, acc 0.53125
2020-02-08T03:03:11.469213: step 333, loss 0.706387, acc 0.671875
2020-02-08T03:03:11.586018: step 334, loss 0.60341, acc 0.671875
2020-02-08T03:03:11.703545: step 335, loss 0.883583, acc 0.625
2020-02-08T03:03:11.824923: step 336, loss 0.722931, acc 0.640625
2020-02-08T03:03:11.938609: step 337, loss 0.747635, acc 0.5625
2020-02-08T03:03:12.056137: step 338, loss 0.603336, acc 0.671875
2020-02-08T03:03:12.172887: step 339, loss 0.601614, acc 0.734375
2020-02-08T03:03:12.286665: step 340, loss 0.69245, acc 0.6875
2020-02-08T03:03:12.402970: step 341, loss 0.66108, acc 0.671875
2020-02-08T03:03:12.519129: step 342, loss 0.857051, acc 0.640625
2020-02-08T03:03:12.634061: step 343, loss 0.600607, acc 0.703125
2020-02-08T03:03:12.752675: step 344, loss 0.737818, acc 0.65625
2020-02-08T03:03:12.871600: step 345, loss 0.638649, acc 0.6875
2020-02-08T03:03:12.988127: step 346, loss 0.641686, acc 0.640625
2020-02-08T03:03:13.103709: step 347, loss 0.601943, acc 0.703125
2020-02-08T03:03:13.221923: step 348, loss 0.739013, acc 0.671875
2020-02-08T03:03:13.335151: step 349, loss 0.577628, acc 0.703125
2020-02-08T03:03:13.454208: step 350, loss 0.54426, acc 0.734375
2020-02-08T03:03:13.572608: step 351, loss 0.499386, acc 0.734375
2020-02-08T03:03:13.688156: step 352, loss 0.661199, acc 0.671875
2020-02-08T03:03:13.812420: step 353, loss 0.64138, acc 0.734375
2020-02-08T03:03:13.930011: step 354, loss 0.630496, acc 0.703125
2020-02-08T03:03:14.045823: step 355, loss 0.496814, acc 0.78125
2020-02-08T03:03:14.162616: step 356, loss 0.576536, acc 0.71875
2020-02-08T03:03:14.279296: step 357, loss 0.776268, acc 0.640625
2020-02-08T03:03:14.393375: step 358, loss 0.797628, acc 0.65625
2020-02-08T03:03:14.511161: step 359, loss 0.905298, acc 0.609375
2020-02-08T03:03:14.625422: step 360, loss 0.735407, acc 0.625
2020-02-08T03:03:14.742496: step 361, loss 0.604671, acc 0.703125
2020-02-08T03:03:14.863478: step 362, loss 0.682968, acc 0.703125
2020-02-08T03:03:14.979464: step 363, loss 0.677864, acc 0.75
2020-02-08T03:03:15.095702: step 364, loss 0.825871, acc 0.59375
2020-02-08T03:03:15.212507: step 365, loss 0.823252, acc 0.671875
2020-02-08T03:03:15.329790: step 366, loss 0.709473, acc 0.65625
2020-02-08T03:03:15.444000: step 367, loss 0.768322, acc 0.625
2020-02-08T03:03:15.559439: step 368, loss 0.717518, acc 0.625
2020-02-08T03:03:15.677252: step 369, loss 0.628052, acc 0.6875
2020-02-08T03:03:15.796445: step 370, loss 0.65388, acc 0.71875
2020-02-08T03:03:15.915244: step 371, loss 0.611879, acc 0.6875
2020-02-08T03:03:16.031508: step 372, loss 0.646133, acc 0.703125
2020-02-08T03:03:16.151787: step 373, loss 0.751185, acc 0.671875
2020-02-08T03:03:16.269210: step 374, loss 0.834777, acc 0.546875
2020-02-08T03:03:16.387115: step 375, loss 0.541504, acc 0.71875
2020-02-08T03:03:16.510274: step 376, loss 0.749456, acc 0.65625
2020-02-08T03:03:16.627371: step 377, loss 0.637356, acc 0.6875
2020-02-08T03:03:16.745580: step 378, loss 0.702813, acc 0.640625
2020-02-08T03:03:16.861637: step 379, loss 0.714731, acc 0.609375
2020-02-08T03:03:16.979716: step 380, loss 0.561439, acc 0.75
2020-02-08T03:03:17.095444: step 381, loss 0.669565, acc 0.703125
2020-02-08T03:03:17.210938: step 382, loss 0.728603, acc 0.609375
2020-02-08T03:03:17.326728: step 383, loss 0.659986, acc 0.65625
2020-02-08T03:03:17.446178: step 384, loss 0.70168, acc 0.671875
2020-02-08T03:03:17.564365: step 385, loss 0.763383, acc 0.65625
2020-02-08T03:03:17.679996: step 386, loss 0.85526, acc 0.625
2020-02-08T03:03:17.801665: step 387, loss 0.390814, acc 0.859375
2020-02-08T03:03:17.920511: step 388, loss 0.771857, acc 0.65625
2020-02-08T03:03:18.035877: step 389, loss 0.707444, acc 0.609375
2020-02-08T03:03:18.153157: step 390, loss 0.650589, acc 0.703125
2020-02-08T03:03:18.275133: step 391, loss 0.6639, acc 0.703125
2020-02-08T03:03:18.390701: step 392, loss 0.804683, acc 0.640625
2020-02-08T03:03:18.505330: step 393, loss 0.643037, acc 0.71875
2020-02-08T03:03:18.621650: step 394, loss 0.606927, acc 0.71875
2020-02-08T03:03:18.739609: step 395, loss 0.677471, acc 0.640625
2020-02-08T03:03:18.856278: step 396, loss 0.811095, acc 0.609375
2020-02-08T03:03:18.972728: step 397, loss 0.766926, acc 0.640625
2020-02-08T03:03:19.087438: step 398, loss 0.667971, acc 0.703125
2020-02-08T03:03:19.208346: step 399, loss 0.484322, acc 0.765625
2020-02-08T03:03:19.325328: step 400, loss 0.684107, acc 0.6875

Evaluation:
2020-02-08T03:03:19.514210: step 400, loss 0.646913, acc 0.611632

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-400

2020-02-08T03:03:20.962458: step 401, loss 0.707337, acc 0.671875
2020-02-08T03:03:21.079530: step 402, loss 0.575758, acc 0.734375
2020-02-08T03:03:21.193255: step 403, loss 0.719528, acc 0.625
2020-02-08T03:03:21.307912: step 404, loss 0.757261, acc 0.671875
2020-02-08T03:03:21.556511: step 405, loss 0.726344, acc 0.65625
2020-02-08T03:03:21.676565: step 406, loss 0.713139, acc 0.625
2020-02-08T03:03:21.793896: step 407, loss 0.624068, acc 0.75
2020-02-08T03:03:21.915077: step 408, loss 0.655159, acc 0.609375
2020-02-08T03:03:22.030054: step 409, loss 0.700212, acc 0.671875
2020-02-08T03:03:22.145966: step 410, loss 0.789342, acc 0.609375
2020-02-08T03:03:22.265517: step 411, loss 0.632699, acc 0.703125
2020-02-08T03:03:22.381763: step 412, loss 0.642478, acc 0.71875
2020-02-08T03:03:22.496650: step 413, loss 0.554859, acc 0.671875
2020-02-08T03:03:22.614843: step 414, loss 0.69854, acc 0.625
2020-02-08T03:03:22.730049: step 415, loss 0.669227, acc 0.59375
2020-02-08T03:03:22.844644: step 416, loss 0.908977, acc 0.578125
2020-02-08T03:03:22.961683: step 417, loss 0.585602, acc 0.703125
2020-02-08T03:03:23.077523: step 418, loss 0.652969, acc 0.703125
2020-02-08T03:03:23.191137: step 419, loss 0.926532, acc 0.625
2020-02-08T03:03:23.308413: step 420, loss 0.679905, acc 0.609375
2020-02-08T03:03:23.428438: step 421, loss 0.702476, acc 0.640625
2020-02-08T03:03:23.546211: step 422, loss 0.493441, acc 0.734375
2020-02-08T03:03:23.663141: step 423, loss 0.530813, acc 0.75
2020-02-08T03:03:23.779621: step 424, loss 0.870026, acc 0.578125
2020-02-08T03:03:23.895772: step 425, loss 0.61097, acc 0.65625
2020-02-08T03:03:24.013806: step 426, loss 0.621263, acc 0.640625
2020-02-08T03:03:24.131228: step 427, loss 0.599284, acc 0.640625
2020-02-08T03:03:24.248268: step 428, loss 0.680364, acc 0.671875
2020-02-08T03:03:24.362119: step 429, loss 0.641458, acc 0.65625
2020-02-08T03:03:24.477906: step 430, loss 0.788077, acc 0.578125
2020-02-08T03:03:24.592539: step 431, loss 0.626336, acc 0.6875
2020-02-08T03:03:24.715018: step 432, loss 0.598501, acc 0.65625
2020-02-08T03:03:24.830277: step 433, loss 0.687356, acc 0.6875
2020-02-08T03:03:24.947058: step 434, loss 0.749586, acc 0.640625
2020-02-08T03:03:25.066232: step 435, loss 0.821103, acc 0.5625
2020-02-08T03:03:25.181541: step 436, loss 0.599131, acc 0.65625
2020-02-08T03:03:25.308063: step 437, loss 0.752204, acc 0.625
2020-02-08T03:03:25.428290: step 438, loss 0.592118, acc 0.625
2020-02-08T03:03:25.543591: step 439, loss 0.532053, acc 0.734375
2020-02-08T03:03:25.661018: step 440, loss 0.667318, acc 0.71875
2020-02-08T03:03:25.777070: step 441, loss 0.793129, acc 0.625
2020-02-08T03:03:25.897848: step 442, loss 0.687591, acc 0.578125
2020-02-08T03:03:26.016090: step 443, loss 0.716341, acc 0.609375
2020-02-08T03:03:26.136477: step 444, loss 0.654571, acc 0.578125
2020-02-08T03:03:26.255384: step 445, loss 0.748623, acc 0.671875
2020-02-08T03:03:26.375017: step 446, loss 0.702421, acc 0.609375
2020-02-08T03:03:26.489445: step 447, loss 0.732784, acc 0.609375
2020-02-08T03:03:26.609008: step 448, loss 0.685209, acc 0.640625
2020-02-08T03:03:26.728322: step 449, loss 0.948268, acc 0.5
2020-02-08T03:03:26.840518: step 450, loss 0.70607, acc 0.6
2020-02-08T03:03:26.961371: step 451, loss 0.543973, acc 0.75
2020-02-08T03:03:27.078473: step 452, loss 0.58164, acc 0.6875
2020-02-08T03:03:27.194480: step 453, loss 0.512995, acc 0.765625
2020-02-08T03:03:27.315302: step 454, loss 0.587426, acc 0.671875
2020-02-08T03:03:27.431439: step 455, loss 0.545702, acc 0.71875
2020-02-08T03:03:27.548250: step 456, loss 0.511132, acc 0.765625
2020-02-08T03:03:27.664744: step 457, loss 0.813732, acc 0.5625
2020-02-08T03:03:27.781866: step 458, loss 0.59849, acc 0.65625
2020-02-08T03:03:27.899744: step 459, loss 0.691792, acc 0.671875
2020-02-08T03:03:28.020589: step 460, loss 0.552475, acc 0.734375
2020-02-08T03:03:28.135096: step 461, loss 0.625015, acc 0.6875
2020-02-08T03:03:28.250191: step 462, loss 0.740594, acc 0.609375
2020-02-08T03:03:28.365753: step 463, loss 0.433926, acc 0.78125
2020-02-08T03:03:28.483124: step 464, loss 0.671183, acc 0.6875
2020-02-08T03:03:28.599069: step 465, loss 0.545537, acc 0.75
2020-02-08T03:03:28.714820: step 466, loss 0.575213, acc 0.671875
2020-02-08T03:03:28.830529: step 467, loss 0.682148, acc 0.640625
2020-02-08T03:03:28.948031: step 468, loss 0.452843, acc 0.75
2020-02-08T03:03:29.064277: step 469, loss 0.602116, acc 0.6875
2020-02-08T03:03:29.180565: step 470, loss 0.661995, acc 0.65625
2020-02-08T03:03:29.299363: step 471, loss 0.605158, acc 0.734375
2020-02-08T03:03:29.419345: step 472, loss 0.731881, acc 0.5625
2020-02-08T03:03:29.534485: step 473, loss 0.667131, acc 0.734375
2020-02-08T03:03:29.647543: step 474, loss 0.5571, acc 0.6875
2020-02-08T03:03:29.764314: step 475, loss 0.55453, acc 0.75
2020-02-08T03:03:29.882493: step 476, loss 0.547873, acc 0.765625
2020-02-08T03:03:29.997221: step 477, loss 0.686589, acc 0.703125
2020-02-08T03:03:30.111777: step 478, loss 0.615211, acc 0.734375
2020-02-08T03:03:30.225629: step 479, loss 0.639261, acc 0.703125
2020-02-08T03:03:30.341340: step 480, loss 0.597204, acc 0.6875
2020-02-08T03:03:30.459142: step 481, loss 0.570471, acc 0.71875
2020-02-08T03:03:30.576960: step 482, loss 0.762303, acc 0.609375
2020-02-08T03:03:30.690843: step 483, loss 0.633576, acc 0.65625
2020-02-08T03:03:30.807967: step 484, loss 0.563704, acc 0.71875
2020-02-08T03:03:30.925929: step 485, loss 0.669825, acc 0.671875
2020-02-08T03:03:31.039135: step 486, loss 0.681402, acc 0.609375
2020-02-08T03:03:31.156372: step 487, loss 0.541854, acc 0.75
2020-02-08T03:03:31.274672: step 488, loss 0.539958, acc 0.75
2020-02-08T03:03:31.390077: step 489, loss 0.496025, acc 0.75
2020-02-08T03:03:31.508543: step 490, loss 0.601794, acc 0.71875
2020-02-08T03:03:31.624992: step 491, loss 0.563349, acc 0.734375
2020-02-08T03:03:31.738674: step 492, loss 0.566102, acc 0.765625
2020-02-08T03:03:31.856722: step 493, loss 0.648306, acc 0.609375
2020-02-08T03:03:31.971622: step 494, loss 0.469553, acc 0.75
2020-02-08T03:03:32.086869: step 495, loss 0.633496, acc 0.609375
2020-02-08T03:03:32.202567: step 496, loss 0.765802, acc 0.546875
2020-02-08T03:03:32.321598: step 497, loss 0.612087, acc 0.703125
2020-02-08T03:03:32.435291: step 498, loss 0.561862, acc 0.71875
2020-02-08T03:03:32.548517: step 499, loss 0.596685, acc 0.703125
2020-02-08T03:03:32.662639: step 500, loss 0.568411, acc 0.703125

Evaluation:
2020-02-08T03:03:32.848576: step 500, loss 0.619781, acc 0.645403

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-500

2020-02-08T03:03:34.331532: step 501, loss 0.576669, acc 0.609375
2020-02-08T03:03:34.448191: step 502, loss 0.625927, acc 0.625
2020-02-08T03:03:34.565373: step 503, loss 0.677209, acc 0.703125
2020-02-08T03:03:34.680885: step 504, loss 0.57145, acc 0.75
2020-02-08T03:03:34.798790: step 505, loss 0.450719, acc 0.78125
2020-02-08T03:03:34.916105: step 506, loss 0.709367, acc 0.625
2020-02-08T03:03:35.031284: step 507, loss 0.638798, acc 0.65625
2020-02-08T03:03:35.146551: step 508, loss 0.500265, acc 0.78125
2020-02-08T03:03:35.264232: step 509, loss 0.579787, acc 0.75
2020-02-08T03:03:35.379957: step 510, loss 0.586863, acc 0.75
2020-02-08T03:03:35.496937: step 511, loss 0.479754, acc 0.78125
2020-02-08T03:03:35.612104: step 512, loss 0.535188, acc 0.71875
2020-02-08T03:03:35.727904: step 513, loss 0.578663, acc 0.71875
2020-02-08T03:03:35.843951: step 514, loss 0.686749, acc 0.609375
2020-02-08T03:03:35.959174: step 515, loss 0.608031, acc 0.625
2020-02-08T03:03:36.075328: step 516, loss 0.533772, acc 0.671875
2020-02-08T03:03:36.190511: step 517, loss 0.543931, acc 0.734375
2020-02-08T03:03:36.308001: step 518, loss 0.55999, acc 0.734375
2020-02-08T03:03:36.426442: step 519, loss 0.667439, acc 0.65625
2020-02-08T03:03:36.540710: step 520, loss 0.606691, acc 0.71875
2020-02-08T03:03:36.662271: step 521, loss 0.619752, acc 0.703125
2020-02-08T03:03:36.778129: step 522, loss 0.650581, acc 0.640625
2020-02-08T03:03:36.894088: step 523, loss 0.528297, acc 0.734375
2020-02-08T03:03:37.012829: step 524, loss 0.517058, acc 0.71875
2020-02-08T03:03:37.128197: step 525, loss 0.592807, acc 0.703125
2020-02-08T03:03:37.243266: step 526, loss 0.545588, acc 0.71875
2020-02-08T03:03:37.362534: step 527, loss 0.49008, acc 0.8125
2020-02-08T03:03:37.480295: step 528, loss 0.590765, acc 0.703125
2020-02-08T03:03:37.593938: step 529, loss 0.541527, acc 0.78125
2020-02-08T03:03:37.711389: step 530, loss 0.553225, acc 0.703125
2020-02-08T03:03:37.828432: step 531, loss 0.552932, acc 0.6875
2020-02-08T03:03:37.945139: step 532, loss 0.624154, acc 0.6875
2020-02-08T03:03:38.067049: step 533, loss 0.497418, acc 0.75
2020-02-08T03:03:38.182019: step 534, loss 0.440511, acc 0.828125
2020-02-08T03:03:38.296444: step 535, loss 0.615172, acc 0.6875
2020-02-08T03:03:38.410951: step 536, loss 0.777142, acc 0.578125
2020-02-08T03:03:38.527359: step 537, loss 0.546526, acc 0.71875
2020-02-08T03:03:38.643847: step 538, loss 0.703875, acc 0.65625
2020-02-08T03:03:38.760720: step 539, loss 0.600062, acc 0.671875
2020-02-08T03:03:38.877210: step 540, loss 0.591134, acc 0.671875
2020-02-08T03:03:38.993001: step 541, loss 0.542134, acc 0.703125
2020-02-08T03:03:39.110967: step 542, loss 0.410707, acc 0.859375
2020-02-08T03:03:39.228446: step 543, loss 0.452899, acc 0.75
2020-02-08T03:03:39.346332: step 544, loss 0.573338, acc 0.578125
2020-02-08T03:03:39.464130: step 545, loss 0.51803, acc 0.75
2020-02-08T03:03:39.583508: step 546, loss 0.530698, acc 0.75
2020-02-08T03:03:39.703316: step 547, loss 0.628389, acc 0.734375
2020-02-08T03:03:39.822576: step 548, loss 0.547682, acc 0.78125
2020-02-08T03:03:39.939726: step 549, loss 0.533402, acc 0.703125
2020-02-08T03:03:40.058124: step 550, loss 0.585418, acc 0.71875
2020-02-08T03:03:40.178164: step 551, loss 0.541959, acc 0.734375
2020-02-08T03:03:40.295007: step 552, loss 0.550788, acc 0.75
2020-02-08T03:03:40.410546: step 553, loss 0.561488, acc 0.75
2020-02-08T03:03:40.525813: step 554, loss 0.600014, acc 0.65625
2020-02-08T03:03:40.644040: step 555, loss 0.735416, acc 0.640625
2020-02-08T03:03:40.761385: step 556, loss 0.685531, acc 0.671875
2020-02-08T03:03:40.876988: step 557, loss 0.543842, acc 0.734375
2020-02-08T03:03:40.997925: step 558, loss 0.545505, acc 0.703125
2020-02-08T03:03:41.114656: step 559, loss 0.493729, acc 0.71875
2020-02-08T03:03:41.231848: step 560, loss 0.648324, acc 0.65625
2020-02-08T03:03:41.348727: step 561, loss 0.595287, acc 0.703125
2020-02-08T03:03:41.465115: step 562, loss 0.513873, acc 0.765625
2020-02-08T03:03:41.580081: step 563, loss 0.604932, acc 0.6875
2020-02-08T03:03:41.693508: step 564, loss 0.628918, acc 0.65625
2020-02-08T03:03:41.810242: step 565, loss 0.537819, acc 0.75
2020-02-08T03:03:41.927229: step 566, loss 0.549397, acc 0.640625
2020-02-08T03:03:42.043400: step 567, loss 0.59483, acc 0.703125
2020-02-08T03:03:42.159969: step 568, loss 0.620112, acc 0.703125
2020-02-08T03:03:42.275559: step 569, loss 0.415301, acc 0.765625
2020-02-08T03:03:42.391623: step 570, loss 0.526928, acc 0.65625
2020-02-08T03:03:42.505883: step 571, loss 0.633607, acc 0.671875
2020-02-08T03:03:42.620976: step 572, loss 0.511648, acc 0.75
2020-02-08T03:03:42.734726: step 573, loss 0.692647, acc 0.625
2020-02-08T03:03:42.852026: step 574, loss 0.564368, acc 0.640625
2020-02-08T03:03:42.970274: step 575, loss 0.566973, acc 0.703125
2020-02-08T03:03:43.084016: step 576, loss 0.425223, acc 0.8125
2020-02-08T03:03:43.198776: step 577, loss 0.630664, acc 0.65625
2020-02-08T03:03:43.316712: step 578, loss 0.600521, acc 0.640625
2020-02-08T03:03:43.433300: step 579, loss 0.672879, acc 0.59375
2020-02-08T03:03:43.551381: step 580, loss 0.641434, acc 0.625
2020-02-08T03:03:43.666764: step 581, loss 0.582035, acc 0.640625
2020-02-08T03:03:43.784231: step 582, loss 0.728765, acc 0.65625
2020-02-08T03:03:43.903740: step 583, loss 0.552031, acc 0.796875
2020-02-08T03:03:44.021551: step 584, loss 0.498844, acc 0.71875
2020-02-08T03:03:44.137309: step 585, loss 0.462819, acc 0.734375
2020-02-08T03:03:44.255305: step 586, loss 0.557227, acc 0.71875
2020-02-08T03:03:44.373372: step 587, loss 0.597979, acc 0.734375
2020-02-08T03:03:44.490890: step 588, loss 0.71055, acc 0.6875
2020-02-08T03:03:44.606964: step 589, loss 0.511958, acc 0.75
2020-02-08T03:03:44.721899: step 590, loss 0.512223, acc 0.75
2020-02-08T03:03:44.836531: step 591, loss 0.610066, acc 0.703125
2020-02-08T03:03:44.953454: step 592, loss 0.506215, acc 0.765625
2020-02-08T03:03:45.070326: step 593, loss 0.520605, acc 0.796875
2020-02-08T03:03:45.184168: step 594, loss 0.598109, acc 0.703125
2020-02-08T03:03:45.300226: step 595, loss 0.541121, acc 0.703125
2020-02-08T03:03:45.419521: step 596, loss 0.657231, acc 0.640625
2020-02-08T03:03:45.534726: step 597, loss 0.623926, acc 0.6875
2020-02-08T03:03:45.650293: step 598, loss 0.47513, acc 0.796875
2020-02-08T03:03:45.767420: step 599, loss 0.601197, acc 0.65625
2020-02-08T03:03:45.880025: step 600, loss 0.43768, acc 0.766667

Evaluation:
2020-02-08T03:03:46.068983: step 600, loss 0.684878, acc 0.599437

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-600

2020-02-08T03:03:48.199579: step 601, loss 0.626168, acc 0.640625
2020-02-08T03:03:48.318451: step 602, loss 0.603415, acc 0.71875
2020-02-08T03:03:48.433591: step 603, loss 0.434007, acc 0.828125
2020-02-08T03:03:48.546624: step 604, loss 0.516524, acc 0.71875
2020-02-08T03:03:48.662900: step 605, loss 0.56025, acc 0.78125
2020-02-08T03:03:48.777838: step 606, loss 0.46942, acc 0.734375
2020-02-08T03:03:48.892177: step 607, loss 0.447968, acc 0.796875
2020-02-08T03:03:49.009153: step 608, loss 0.584999, acc 0.71875
2020-02-08T03:03:49.127118: step 609, loss 0.549473, acc 0.78125
2020-02-08T03:03:49.245351: step 610, loss 0.467726, acc 0.796875
2020-02-08T03:03:49.363701: step 611, loss 0.447752, acc 0.765625
2020-02-08T03:03:49.480822: step 612, loss 0.552014, acc 0.6875
2020-02-08T03:03:49.596728: step 613, loss 0.50271, acc 0.765625
2020-02-08T03:03:49.714670: step 614, loss 0.666513, acc 0.671875
2020-02-08T03:03:49.831429: step 615, loss 0.421163, acc 0.8125
2020-02-08T03:03:49.946965: step 616, loss 0.486506, acc 0.8125
2020-02-08T03:03:50.067900: step 617, loss 0.512395, acc 0.765625
2020-02-08T03:03:50.183051: step 618, loss 0.590288, acc 0.703125
2020-02-08T03:03:50.299627: step 619, loss 0.497638, acc 0.734375
2020-02-08T03:03:50.418225: step 620, loss 0.614271, acc 0.703125
2020-02-08T03:03:50.532959: step 621, loss 0.485743, acc 0.734375
2020-02-08T03:03:50.652213: step 622, loss 0.549334, acc 0.6875
2020-02-08T03:03:50.769392: step 623, loss 0.479182, acc 0.765625
2020-02-08T03:03:50.887343: step 624, loss 0.563093, acc 0.703125
2020-02-08T03:03:51.005607: step 625, loss 0.442206, acc 0.8125
2020-02-08T03:03:51.121946: step 626, loss 0.618011, acc 0.640625
2020-02-08T03:03:51.237495: step 627, loss 0.551257, acc 0.703125
2020-02-08T03:03:51.351891: step 628, loss 0.460431, acc 0.765625
2020-02-08T03:03:51.567032: step 629, loss 0.568212, acc 0.71875
2020-02-08T03:03:51.689994: step 630, loss 0.400802, acc 0.8125
2020-02-08T03:03:51.805413: step 631, loss 0.509771, acc 0.78125
2020-02-08T03:03:51.922989: step 632, loss 0.511738, acc 0.78125
2020-02-08T03:03:52.039075: step 633, loss 0.54614, acc 0.796875
2020-02-08T03:03:52.158360: step 634, loss 0.517427, acc 0.71875
2020-02-08T03:03:52.275975: step 635, loss 0.528766, acc 0.796875
2020-02-08T03:03:52.396498: step 636, loss 0.462092, acc 0.765625
2020-02-08T03:03:52.514897: step 637, loss 0.540519, acc 0.796875
2020-02-08T03:03:52.631184: step 638, loss 0.453902, acc 0.734375
2020-02-08T03:03:52.748302: step 639, loss 0.572239, acc 0.765625
2020-02-08T03:03:52.865593: step 640, loss 0.506287, acc 0.703125
2020-02-08T03:03:52.983952: step 641, loss 0.456752, acc 0.78125
2020-02-08T03:03:53.099745: step 642, loss 0.541566, acc 0.703125
2020-02-08T03:03:53.215677: step 643, loss 0.519232, acc 0.734375
2020-02-08T03:03:53.332294: step 644, loss 0.551046, acc 0.71875
2020-02-08T03:03:53.450066: step 645, loss 0.690094, acc 0.625
2020-02-08T03:03:53.565687: step 646, loss 0.567312, acc 0.734375
2020-02-08T03:03:53.683008: step 647, loss 0.528585, acc 0.703125
2020-02-08T03:03:53.798734: step 648, loss 0.496379, acc 0.75
2020-02-08T03:03:53.916242: step 649, loss 0.433917, acc 0.828125
2020-02-08T03:03:54.032719: step 650, loss 0.502639, acc 0.71875
2020-02-08T03:03:54.151034: step 651, loss 0.607357, acc 0.703125
2020-02-08T03:03:54.271456: step 652, loss 0.482225, acc 0.859375
2020-02-08T03:03:54.386826: step 653, loss 0.465763, acc 0.71875
2020-02-08T03:03:54.502532: step 654, loss 0.451811, acc 0.765625
2020-02-08T03:03:54.619817: step 655, loss 0.487249, acc 0.734375
2020-02-08T03:03:54.734642: step 656, loss 0.534912, acc 0.765625
2020-02-08T03:03:54.850867: step 657, loss 0.490543, acc 0.765625
2020-02-08T03:03:54.969472: step 658, loss 0.498552, acc 0.765625
2020-02-08T03:03:55.082950: step 659, loss 0.473659, acc 0.75
2020-02-08T03:03:55.197522: step 660, loss 0.466322, acc 0.765625
2020-02-08T03:03:55.319542: step 661, loss 0.637849, acc 0.6875
2020-02-08T03:03:55.435583: step 662, loss 0.351148, acc 0.859375
2020-02-08T03:03:55.552645: step 663, loss 0.537139, acc 0.6875
2020-02-08T03:03:55.668696: step 664, loss 0.522298, acc 0.71875
2020-02-08T03:03:55.783403: step 665, loss 0.567999, acc 0.703125
2020-02-08T03:03:55.898956: step 666, loss 0.501527, acc 0.703125
2020-02-08T03:03:56.013424: step 667, loss 0.649628, acc 0.671875
2020-02-08T03:03:56.129407: step 668, loss 0.496173, acc 0.765625
2020-02-08T03:03:56.245451: step 669, loss 0.540386, acc 0.78125
2020-02-08T03:03:56.361929: step 670, loss 0.5339, acc 0.734375
2020-02-08T03:03:56.477459: step 671, loss 0.641409, acc 0.625
2020-02-08T03:03:56.595963: step 672, loss 0.538605, acc 0.765625
2020-02-08T03:03:56.715485: step 673, loss 0.536346, acc 0.671875
2020-02-08T03:03:56.831717: step 674, loss 0.525593, acc 0.71875
2020-02-08T03:03:56.945985: step 675, loss 0.566102, acc 0.75
2020-02-08T03:03:57.061775: step 676, loss 0.714436, acc 0.6875
2020-02-08T03:03:57.179515: step 677, loss 0.463293, acc 0.765625
2020-02-08T03:03:57.296320: step 678, loss 0.492788, acc 0.765625
2020-02-08T03:03:57.416056: step 679, loss 0.481517, acc 0.796875
2020-02-08T03:03:57.533597: step 680, loss 0.526703, acc 0.75
2020-02-08T03:03:57.647628: step 681, loss 0.456858, acc 0.796875
2020-02-08T03:03:57.763825: step 682, loss 0.63763, acc 0.671875
2020-02-08T03:03:57.879794: step 683, loss 0.546558, acc 0.75
2020-02-08T03:03:57.999433: step 684, loss 0.581132, acc 0.734375
2020-02-08T03:03:58.120995: step 685, loss 0.628169, acc 0.65625
2020-02-08T03:03:58.235638: step 686, loss 0.605006, acc 0.65625
2020-02-08T03:03:58.353893: step 687, loss 0.462447, acc 0.765625
2020-02-08T03:03:58.473194: step 688, loss 0.59804, acc 0.65625
2020-02-08T03:03:58.586723: step 689, loss 0.425037, acc 0.796875
2020-02-08T03:03:58.704966: step 690, loss 0.39765, acc 0.8125
2020-02-08T03:03:58.823038: step 691, loss 0.608125, acc 0.671875
2020-02-08T03:03:58.937621: step 692, loss 0.668101, acc 0.671875
2020-02-08T03:03:59.050563: step 693, loss 0.457912, acc 0.78125
2020-02-08T03:03:59.164802: step 694, loss 0.571629, acc 0.671875
2020-02-08T03:03:59.280779: step 695, loss 0.38893, acc 0.8125
2020-02-08T03:03:59.395747: step 696, loss 0.542816, acc 0.71875
2020-02-08T03:03:59.513537: step 697, loss 0.467556, acc 0.765625
2020-02-08T03:03:59.630361: step 698, loss 0.475872, acc 0.734375
2020-02-08T03:03:59.750923: step 699, loss 0.429408, acc 0.8125
2020-02-08T03:03:59.870312: step 700, loss 0.626952, acc 0.75

Evaluation:
2020-02-08T03:04:00.057360: step 700, loss 0.600005, acc 0.666041

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-700

2020-02-08T03:04:01.620163: step 701, loss 0.417464, acc 0.8125
2020-02-08T03:04:01.733989: step 702, loss 0.49356, acc 0.75
2020-02-08T03:04:01.850349: step 703, loss 0.53064, acc 0.75
2020-02-08T03:04:01.965339: step 704, loss 0.445923, acc 0.78125
2020-02-08T03:04:02.080241: step 705, loss 0.501561, acc 0.765625
2020-02-08T03:04:02.197121: step 706, loss 0.470083, acc 0.765625
2020-02-08T03:04:02.315912: step 707, loss 0.520926, acc 0.75
2020-02-08T03:04:02.433302: step 708, loss 0.395008, acc 0.84375
2020-02-08T03:04:02.548188: step 709, loss 0.542376, acc 0.734375
2020-02-08T03:04:02.663352: step 710, loss 0.501337, acc 0.75
2020-02-08T03:04:02.778877: step 711, loss 0.397366, acc 0.765625
2020-02-08T03:04:02.894672: step 712, loss 0.431497, acc 0.765625
2020-02-08T03:04:03.013042: step 713, loss 0.58365, acc 0.734375
2020-02-08T03:04:03.128884: step 714, loss 0.470974, acc 0.78125
2020-02-08T03:04:03.250983: step 715, loss 0.56539, acc 0.71875
2020-02-08T03:04:03.367502: step 716, loss 0.460135, acc 0.78125
2020-02-08T03:04:03.484373: step 717, loss 0.555073, acc 0.71875
2020-02-08T03:04:03.602936: step 718, loss 0.652348, acc 0.625
2020-02-08T03:04:03.720480: step 719, loss 0.505963, acc 0.78125
2020-02-08T03:04:03.837925: step 720, loss 0.480591, acc 0.703125
2020-02-08T03:04:03.956870: step 721, loss 0.595696, acc 0.6875
2020-02-08T03:04:04.074758: step 722, loss 0.527541, acc 0.734375
2020-02-08T03:04:04.191698: step 723, loss 0.455306, acc 0.75
2020-02-08T03:04:04.309422: step 724, loss 0.572732, acc 0.671875
2020-02-08T03:04:04.425518: step 725, loss 0.663604, acc 0.6875
2020-02-08T03:04:04.538372: step 726, loss 0.613266, acc 0.71875
2020-02-08T03:04:04.655664: step 727, loss 0.526946, acc 0.734375
2020-02-08T03:04:04.774608: step 728, loss 0.438853, acc 0.796875
2020-02-08T03:04:04.892292: step 729, loss 0.524133, acc 0.734375
2020-02-08T03:04:05.007543: step 730, loss 0.453171, acc 0.765625
2020-02-08T03:04:05.122588: step 731, loss 0.656695, acc 0.59375
2020-02-08T03:04:05.235663: step 732, loss 0.471884, acc 0.796875
2020-02-08T03:04:05.352856: step 733, loss 0.508384, acc 0.765625
2020-02-08T03:04:05.466786: step 734, loss 0.435257, acc 0.828125
2020-02-08T03:04:05.581727: step 735, loss 0.49587, acc 0.71875
2020-02-08T03:04:05.698375: step 736, loss 0.56686, acc 0.71875
2020-02-08T03:04:05.813079: step 737, loss 0.591944, acc 0.703125
2020-02-08T03:04:05.928511: step 738, loss 0.549338, acc 0.6875
2020-02-08T03:04:06.040560: step 739, loss 0.524206, acc 0.6875
2020-02-08T03:04:06.159755: step 740, loss 0.55122, acc 0.703125
2020-02-08T03:04:06.276696: step 741, loss 0.566853, acc 0.703125
2020-02-08T03:04:06.400026: step 742, loss 0.565113, acc 0.703125
2020-02-08T03:04:06.518174: step 743, loss 0.445495, acc 0.78125
2020-02-08T03:04:06.641855: step 744, loss 0.539961, acc 0.703125
2020-02-08T03:04:06.758388: step 745, loss 0.60645, acc 0.6875
2020-02-08T03:04:06.873492: step 746, loss 0.531745, acc 0.6875
2020-02-08T03:04:06.989154: step 747, loss 0.496026, acc 0.78125
2020-02-08T03:04:07.106388: step 748, loss 0.497042, acc 0.75
2020-02-08T03:04:07.222882: step 749, loss 0.436662, acc 0.75
2020-02-08T03:04:07.338184: step 750, loss 0.349631, acc 0.883333
2020-02-08T03:04:07.459340: step 751, loss 0.390202, acc 0.8125
2020-02-08T03:04:07.577057: step 752, loss 0.503402, acc 0.65625
2020-02-08T03:04:07.690519: step 753, loss 0.363708, acc 0.828125
2020-02-08T03:04:07.810629: step 754, loss 0.351504, acc 0.84375
2020-02-08T03:04:07.928067: step 755, loss 0.436904, acc 0.859375
2020-02-08T03:04:08.043499: step 756, loss 0.488339, acc 0.75
2020-02-08T03:04:08.160483: step 757, loss 0.355983, acc 0.875
2020-02-08T03:04:08.276184: step 758, loss 0.42073, acc 0.78125
2020-02-08T03:04:08.390337: step 759, loss 0.573222, acc 0.671875
2020-02-08T03:04:08.506526: step 760, loss 0.384589, acc 0.796875
2020-02-08T03:04:08.621844: step 761, loss 0.447198, acc 0.8125
2020-02-08T03:04:08.735885: step 762, loss 0.384276, acc 0.875
2020-02-08T03:04:08.855819: step 763, loss 0.467381, acc 0.8125
2020-02-08T03:04:08.974192: step 764, loss 0.473599, acc 0.75
2020-02-08T03:04:09.091840: step 765, loss 0.411699, acc 0.78125
2020-02-08T03:04:09.210026: step 766, loss 0.399079, acc 0.828125
2020-02-08T03:04:09.326101: step 767, loss 0.466814, acc 0.734375
2020-02-08T03:04:09.441970: step 768, loss 0.441145, acc 0.796875
2020-02-08T03:04:09.559161: step 769, loss 0.352512, acc 0.859375
2020-02-08T03:04:09.676915: step 770, loss 0.410343, acc 0.8125
2020-02-08T03:04:09.795128: step 771, loss 0.367952, acc 0.84375
2020-02-08T03:04:09.910319: step 772, loss 0.445867, acc 0.828125
2020-02-08T03:04:10.027382: step 773, loss 0.36869, acc 0.796875
2020-02-08T03:04:10.143527: step 774, loss 0.363428, acc 0.8125
2020-02-08T03:04:10.256726: step 775, loss 0.422237, acc 0.75
2020-02-08T03:04:10.373714: step 776, loss 0.401955, acc 0.84375
2020-02-08T03:04:10.490333: step 777, loss 0.652297, acc 0.65625
2020-02-08T03:04:10.608508: step 778, loss 0.355147, acc 0.828125
2020-02-08T03:04:10.725726: step 779, loss 0.41741, acc 0.8125
2020-02-08T03:04:10.839981: step 780, loss 0.437676, acc 0.8125
2020-02-08T03:04:10.957424: step 781, loss 0.409396, acc 0.78125
2020-02-08T03:04:11.073905: step 782, loss 0.501587, acc 0.796875
2020-02-08T03:04:11.193389: step 783, loss 0.407573, acc 0.84375
2020-02-08T03:04:11.310706: step 784, loss 0.534161, acc 0.796875
2020-02-08T03:04:11.426978: step 785, loss 0.416032, acc 0.8125
2020-02-08T03:04:11.544027: step 786, loss 0.369319, acc 0.828125
2020-02-08T03:04:11.659982: step 787, loss 0.353917, acc 0.90625
2020-02-08T03:04:11.775352: step 788, loss 0.433837, acc 0.84375
2020-02-08T03:04:11.893457: step 789, loss 0.461942, acc 0.75
2020-02-08T03:04:12.008803: step 790, loss 0.435798, acc 0.8125
2020-02-08T03:04:12.124945: step 791, loss 0.302526, acc 0.875
2020-02-08T03:04:12.241855: step 792, loss 0.447204, acc 0.796875
2020-02-08T03:04:12.358683: step 793, loss 0.430178, acc 0.796875
2020-02-08T03:04:12.475746: step 794, loss 0.478689, acc 0.765625
2020-02-08T03:04:12.593275: step 795, loss 0.410199, acc 0.796875
2020-02-08T03:04:12.709731: step 796, loss 0.441512, acc 0.796875
2020-02-08T03:04:12.826054: step 797, loss 0.418159, acc 0.796875
2020-02-08T03:04:12.942985: step 798, loss 0.437985, acc 0.765625
2020-02-08T03:04:13.059584: step 799, loss 0.408122, acc 0.765625
2020-02-08T03:04:13.175148: step 800, loss 0.469032, acc 0.75

Evaluation:
2020-02-08T03:04:13.366915: step 800, loss 0.595156, acc 0.663227

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-800

2020-02-08T03:04:14.919487: step 801, loss 0.381535, acc 0.859375
2020-02-08T03:04:15.036252: step 802, loss 0.416293, acc 0.8125
2020-02-08T03:04:15.152184: step 803, loss 0.451092, acc 0.796875
2020-02-08T03:04:15.269598: step 804, loss 0.509502, acc 0.75
2020-02-08T03:04:15.384469: step 805, loss 0.442872, acc 0.71875
2020-02-08T03:04:15.500411: step 806, loss 0.340018, acc 0.84375
2020-02-08T03:04:15.617528: step 807, loss 0.408524, acc 0.78125
2020-02-08T03:04:15.735340: step 808, loss 0.382913, acc 0.828125
2020-02-08T03:04:15.851106: step 809, loss 0.450352, acc 0.78125
2020-02-08T03:04:15.966130: step 810, loss 0.553175, acc 0.75
2020-02-08T03:04:16.082164: step 811, loss 0.516741, acc 0.75
2020-02-08T03:04:16.198352: step 812, loss 0.403409, acc 0.8125
2020-02-08T03:04:16.316186: step 813, loss 0.398177, acc 0.796875
2020-02-08T03:04:16.435330: step 814, loss 0.422051, acc 0.765625
2020-02-08T03:04:16.551412: step 815, loss 0.549371, acc 0.75
2020-02-08T03:04:16.667014: step 816, loss 0.463583, acc 0.796875
2020-02-08T03:04:16.782955: step 817, loss 0.335237, acc 0.859375
2020-02-08T03:04:16.901156: step 818, loss 0.39219, acc 0.8125
2020-02-08T03:04:17.019264: step 819, loss 0.535701, acc 0.734375
2020-02-08T03:04:17.137871: step 820, loss 0.484861, acc 0.78125
2020-02-08T03:04:17.254889: step 821, loss 0.588199, acc 0.71875
2020-02-08T03:04:17.372372: step 822, loss 0.399025, acc 0.8125
2020-02-08T03:04:17.489695: step 823, loss 0.452229, acc 0.8125
2020-02-08T03:04:17.604923: step 824, loss 0.312328, acc 0.84375
2020-02-08T03:04:17.723668: step 825, loss 0.457662, acc 0.78125
2020-02-08T03:04:17.842509: step 826, loss 0.468666, acc 0.765625
2020-02-08T03:04:17.961623: step 827, loss 0.507958, acc 0.75
2020-02-08T03:04:18.077513: step 828, loss 0.500438, acc 0.75
2020-02-08T03:04:18.193282: step 829, loss 0.443564, acc 0.796875
2020-02-08T03:04:18.310946: step 830, loss 0.544161, acc 0.796875
2020-02-08T03:04:18.429282: step 831, loss 0.411698, acc 0.78125
2020-02-08T03:04:18.544680: step 832, loss 0.452208, acc 0.78125
2020-02-08T03:04:18.658517: step 833, loss 0.467254, acc 0.75
2020-02-08T03:04:18.775550: step 834, loss 0.387881, acc 0.84375
2020-02-08T03:04:18.893686: step 835, loss 0.514909, acc 0.734375
2020-02-08T03:04:19.010982: step 836, loss 0.576596, acc 0.71875
2020-02-08T03:04:19.127826: step 837, loss 0.374433, acc 0.796875
2020-02-08T03:04:19.249056: step 838, loss 0.488266, acc 0.765625
2020-02-08T03:04:19.366654: step 839, loss 0.322886, acc 0.875
2020-02-08T03:04:19.481063: step 840, loss 0.562406, acc 0.703125
2020-02-08T03:04:19.597546: step 841, loss 0.574545, acc 0.671875
2020-02-08T03:04:19.715167: step 842, loss 0.414374, acc 0.765625
2020-02-08T03:04:19.832626: step 843, loss 0.484259, acc 0.765625
2020-02-08T03:04:19.948959: step 844, loss 0.399255, acc 0.8125
2020-02-08T03:04:20.066317: step 845, loss 0.50705, acc 0.75
2020-02-08T03:04:20.181574: step 846, loss 0.375947, acc 0.84375
2020-02-08T03:04:20.296915: step 847, loss 0.533026, acc 0.71875
2020-02-08T03:04:20.414490: step 848, loss 0.451695, acc 0.765625
2020-02-08T03:04:20.528994: step 849, loss 0.385893, acc 0.828125
2020-02-08T03:04:20.642979: step 850, loss 0.554742, acc 0.78125
2020-02-08T03:04:20.759886: step 851, loss 0.55551, acc 0.765625
2020-02-08T03:04:20.877565: step 852, loss 0.477633, acc 0.78125
2020-02-08T03:04:20.994242: step 853, loss 0.476192, acc 0.796875
2020-02-08T03:04:21.112745: step 854, loss 0.523851, acc 0.765625
2020-02-08T03:04:21.230846: step 855, loss 0.432686, acc 0.828125
2020-02-08T03:04:21.343913: step 856, loss 0.603181, acc 0.671875
2020-02-08T03:04:21.713360: step 857, loss 0.340964, acc 0.859375
2020-02-08T03:04:21.840360: step 858, loss 0.46934, acc 0.734375
2020-02-08T03:04:21.960529: step 859, loss 0.367774, acc 0.8125
2020-02-08T03:04:22.079142: step 860, loss 0.367413, acc 0.75
2020-02-08T03:04:22.194389: step 861, loss 0.543808, acc 0.734375
2020-02-08T03:04:22.312799: step 862, loss 0.464812, acc 0.734375
2020-02-08T03:04:22.429430: step 863, loss 0.307173, acc 0.875
2020-02-08T03:04:22.546476: step 864, loss 0.511878, acc 0.734375
2020-02-08T03:04:22.664729: step 865, loss 0.557646, acc 0.734375
2020-02-08T03:04:22.779876: step 866, loss 0.451385, acc 0.828125
2020-02-08T03:04:22.894006: step 867, loss 0.537307, acc 0.6875
2020-02-08T03:04:23.012711: step 868, loss 0.528003, acc 0.75
2020-02-08T03:04:23.127504: step 869, loss 0.436566, acc 0.8125
2020-02-08T03:04:23.245481: step 870, loss 0.454649, acc 0.78125
2020-02-08T03:04:23.362714: step 871, loss 0.469485, acc 0.8125
2020-02-08T03:04:23.482142: step 872, loss 0.379366, acc 0.8125
2020-02-08T03:04:23.598492: step 873, loss 0.522777, acc 0.8125
2020-02-08T03:04:23.713904: step 874, loss 0.47142, acc 0.734375
2020-02-08T03:04:23.832211: step 875, loss 0.329432, acc 0.90625
2020-02-08T03:04:23.945238: step 876, loss 0.39759, acc 0.84375
2020-02-08T03:04:24.061311: step 877, loss 0.564629, acc 0.75
2020-02-08T03:04:24.178227: step 878, loss 0.475297, acc 0.75
2020-02-08T03:04:24.296579: step 879, loss 0.70041, acc 0.65625
2020-02-08T03:04:24.412181: step 880, loss 0.45115, acc 0.796875
2020-02-08T03:04:24.528759: step 881, loss 0.482134, acc 0.734375
2020-02-08T03:04:24.643769: step 882, loss 0.527514, acc 0.765625
2020-02-08T03:04:24.762529: step 883, loss 0.501073, acc 0.703125
2020-02-08T03:04:24.879119: step 884, loss 0.493913, acc 0.8125
2020-02-08T03:04:24.994213: step 885, loss 0.395083, acc 0.859375
2020-02-08T03:04:25.110498: step 886, loss 0.455782, acc 0.796875
2020-02-08T03:04:25.228404: step 887, loss 0.552744, acc 0.734375
2020-02-08T03:04:25.343759: step 888, loss 0.629737, acc 0.703125
2020-02-08T03:04:25.460250: step 889, loss 0.407761, acc 0.84375
2020-02-08T03:04:25.577571: step 890, loss 0.356338, acc 0.875
2020-02-08T03:04:25.698698: step 891, loss 0.40311, acc 0.8125
2020-02-08T03:04:25.814851: step 892, loss 0.452878, acc 0.796875
2020-02-08T03:04:25.930912: step 893, loss 0.455462, acc 0.734375
2020-02-08T03:04:26.046191: step 894, loss 0.590724, acc 0.6875
2020-02-08T03:04:26.162475: step 895, loss 0.367445, acc 0.828125
2020-02-08T03:04:26.277208: step 896, loss 0.300708, acc 0.875
2020-02-08T03:04:26.392361: step 897, loss 0.426949, acc 0.75
2020-02-08T03:04:26.508657: step 898, loss 0.42521, acc 0.78125
2020-02-08T03:04:26.624870: step 899, loss 0.432524, acc 0.828125
2020-02-08T03:04:26.736477: step 900, loss 0.508816, acc 0.75

Evaluation:
2020-02-08T03:04:26.922003: step 900, loss 0.577874, acc 0.694184

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-900

2020-02-08T03:04:29.731555: step 901, loss 0.414508, acc 0.8125
2020-02-08T03:04:29.848789: step 902, loss 0.313835, acc 0.859375
2020-02-08T03:04:29.964305: step 903, loss 0.34159, acc 0.828125
2020-02-08T03:04:30.079268: step 904, loss 0.319432, acc 0.890625
2020-02-08T03:04:30.194656: step 905, loss 0.435807, acc 0.78125
2020-02-08T03:04:30.310060: step 906, loss 0.426287, acc 0.765625
2020-02-08T03:04:30.425652: step 907, loss 0.363443, acc 0.890625
2020-02-08T03:04:30.540787: step 908, loss 0.394329, acc 0.78125
2020-02-08T03:04:30.657300: step 909, loss 0.415433, acc 0.796875
2020-02-08T03:04:30.773374: step 910, loss 0.39539, acc 0.78125
2020-02-08T03:04:30.888411: step 911, loss 0.326744, acc 0.859375
2020-02-08T03:04:31.005482: step 912, loss 0.354965, acc 0.84375
2020-02-08T03:04:31.122533: step 913, loss 0.405464, acc 0.75
2020-02-08T03:04:31.241628: step 914, loss 0.40746, acc 0.765625
2020-02-08T03:04:31.358706: step 915, loss 0.442133, acc 0.765625
2020-02-08T03:04:31.476078: step 916, loss 0.355016, acc 0.859375
2020-02-08T03:04:31.592171: step 917, loss 0.401481, acc 0.8125
2020-02-08T03:04:31.707721: step 918, loss 0.478939, acc 0.84375
2020-02-08T03:04:31.824571: step 919, loss 0.414792, acc 0.875
2020-02-08T03:04:31.938857: step 920, loss 0.380953, acc 0.890625
2020-02-08T03:04:32.055493: step 921, loss 0.349832, acc 0.84375
2020-02-08T03:04:32.170750: step 922, loss 0.294791, acc 0.90625
2020-02-08T03:04:32.285657: step 923, loss 0.428574, acc 0.78125
2020-02-08T03:04:32.404535: step 924, loss 0.311535, acc 0.875
2020-02-08T03:04:32.522508: step 925, loss 0.359745, acc 0.859375
2020-02-08T03:04:32.639379: step 926, loss 0.346059, acc 0.859375
2020-02-08T03:04:32.754816: step 927, loss 0.407585, acc 0.84375
2020-02-08T03:04:32.874052: step 928, loss 0.327715, acc 0.84375
2020-02-08T03:04:33.016152: step 929, loss 0.391828, acc 0.796875
2020-02-08T03:04:33.134078: step 930, loss 0.424165, acc 0.75
2020-02-08T03:04:33.248642: step 931, loss 0.361773, acc 0.8125
2020-02-08T03:04:33.363387: step 932, loss 0.343632, acc 0.859375
2020-02-08T03:04:33.475391: step 933, loss 0.316937, acc 0.859375
2020-02-08T03:04:33.592355: step 934, loss 0.382653, acc 0.796875
2020-02-08T03:04:33.708289: step 935, loss 0.441749, acc 0.8125
2020-02-08T03:04:33.823876: step 936, loss 0.484805, acc 0.8125
2020-02-08T03:04:33.939434: step 937, loss 0.431581, acc 0.828125
2020-02-08T03:04:34.056433: step 938, loss 0.485775, acc 0.796875
2020-02-08T03:04:34.172652: step 939, loss 0.322943, acc 0.875
2020-02-08T03:04:34.288884: step 940, loss 0.401765, acc 0.765625
2020-02-08T03:04:34.404623: step 941, loss 0.343651, acc 0.84375
2020-02-08T03:04:34.522551: step 942, loss 0.374358, acc 0.8125
2020-02-08T03:04:34.641578: step 943, loss 0.329263, acc 0.859375
2020-02-08T03:04:34.756587: step 944, loss 0.343067, acc 0.890625
2020-02-08T03:04:34.872286: step 945, loss 0.355353, acc 0.8125
2020-02-08T03:04:34.986478: step 946, loss 0.422652, acc 0.8125
2020-02-08T03:04:35.101752: step 947, loss 0.315763, acc 0.890625
2020-02-08T03:04:35.217309: step 948, loss 0.486055, acc 0.71875
2020-02-08T03:04:35.331485: step 949, loss 0.32969, acc 0.859375
2020-02-08T03:04:35.446321: step 950, loss 0.397751, acc 0.84375
2020-02-08T03:04:35.563058: step 951, loss 0.332002, acc 0.859375
2020-02-08T03:04:35.679306: step 952, loss 0.446834, acc 0.84375
2020-02-08T03:04:35.794764: step 953, loss 0.499906, acc 0.78125
2020-02-08T03:04:35.913186: step 954, loss 0.398868, acc 0.8125
2020-02-08T03:04:36.028489: step 955, loss 0.398973, acc 0.8125
2020-02-08T03:04:36.146925: step 956, loss 0.423712, acc 0.828125
2020-02-08T03:04:36.262676: step 957, loss 0.281649, acc 0.90625
2020-02-08T03:04:36.378501: step 958, loss 0.346261, acc 0.828125
2020-02-08T03:04:36.493419: step 959, loss 0.382588, acc 0.828125
2020-02-08T03:04:36.608655: step 960, loss 0.442961, acc 0.765625
2020-02-08T03:04:36.721863: step 961, loss 0.43685, acc 0.796875
2020-02-08T03:04:36.838485: step 962, loss 0.268195, acc 0.890625
2020-02-08T03:04:36.954323: step 963, loss 0.317982, acc 0.875
2020-02-08T03:04:37.070933: step 964, loss 0.351578, acc 0.84375
2020-02-08T03:04:37.188525: step 965, loss 0.463319, acc 0.78125
2020-02-08T03:04:37.308531: step 966, loss 0.428077, acc 0.796875
2020-02-08T03:04:37.424740: step 967, loss 0.286657, acc 0.875
2020-02-08T03:04:37.542452: step 968, loss 0.417815, acc 0.796875
2020-02-08T03:04:37.659403: step 969, loss 0.479139, acc 0.703125
2020-02-08T03:04:37.776032: step 970, loss 0.459121, acc 0.78125
2020-02-08T03:04:37.891791: step 971, loss 0.451572, acc 0.765625
2020-02-08T03:04:38.009583: step 972, loss 0.37313, acc 0.84375
2020-02-08T03:04:38.127623: step 973, loss 0.306672, acc 0.875
2020-02-08T03:04:38.245626: step 974, loss 0.436918, acc 0.78125
2020-02-08T03:04:38.360882: step 975, loss 0.325563, acc 0.875
2020-02-08T03:04:38.476444: step 976, loss 0.295369, acc 0.875
2020-02-08T03:04:38.592232: step 977, loss 0.549831, acc 0.75
2020-02-08T03:04:38.707914: step 978, loss 0.312832, acc 0.796875
2020-02-08T03:04:38.828152: step 979, loss 0.448748, acc 0.8125
2020-02-08T03:04:38.948446: step 980, loss 0.323537, acc 0.84375
2020-02-08T03:04:39.073907: step 981, loss 0.483413, acc 0.78125
2020-02-08T03:04:39.188532: step 982, loss 0.265189, acc 0.890625
2020-02-08T03:04:39.305274: step 983, loss 0.55604, acc 0.78125
2020-02-08T03:04:39.425438: step 984, loss 0.402707, acc 0.84375
2020-02-08T03:04:39.540209: step 985, loss 0.393051, acc 0.8125
2020-02-08T03:04:39.657875: step 986, loss 0.423038, acc 0.78125
2020-02-08T03:04:39.775306: step 987, loss 0.301983, acc 0.875
2020-02-08T03:04:39.892669: step 988, loss 0.337634, acc 0.859375
2020-02-08T03:04:40.011693: step 989, loss 0.306755, acc 0.828125
2020-02-08T03:04:40.127911: step 990, loss 0.313157, acc 0.875
2020-02-08T03:04:40.241884: step 991, loss 0.393821, acc 0.84375
2020-02-08T03:04:40.358721: step 992, loss 0.387734, acc 0.859375
2020-02-08T03:04:40.476251: step 993, loss 0.345079, acc 0.859375
2020-02-08T03:04:40.592117: step 994, loss 0.386743, acc 0.8125
2020-02-08T03:04:40.711707: step 995, loss 0.478575, acc 0.796875
2020-02-08T03:04:40.829522: step 996, loss 0.351125, acc 0.796875
2020-02-08T03:04:40.947443: step 997, loss 0.276541, acc 0.84375
2020-02-08T03:04:41.063955: step 998, loss 0.327718, acc 0.828125
2020-02-08T03:04:41.181099: step 999, loss 0.428704, acc 0.796875
2020-02-08T03:04:41.296910: step 1000, loss 0.527933, acc 0.734375

Evaluation:
2020-02-08T03:04:41.483881: step 1000, loss 0.595859, acc 0.706379

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1000

2020-02-08T03:04:43.905142: step 1001, loss 0.475722, acc 0.796875
2020-02-08T03:04:44.022596: step 1002, loss 0.331539, acc 0.859375
2020-02-08T03:04:44.137658: step 1003, loss 0.44058, acc 0.78125
2020-02-08T03:04:44.251271: step 1004, loss 0.419709, acc 0.78125
2020-02-08T03:04:44.367873: step 1005, loss 0.264229, acc 0.921875
2020-02-08T03:04:44.483405: step 1006, loss 0.551499, acc 0.65625
2020-02-08T03:04:44.599757: step 1007, loss 0.358274, acc 0.796875
2020-02-08T03:04:44.716545: step 1008, loss 0.43955, acc 0.84375
2020-02-08T03:04:44.830845: step 1009, loss 0.451511, acc 0.765625
2020-02-08T03:04:44.948709: step 1010, loss 0.369251, acc 0.859375
2020-02-08T03:04:45.065522: step 1011, loss 0.351083, acc 0.84375
2020-02-08T03:04:45.180526: step 1012, loss 0.413885, acc 0.796875
2020-02-08T03:04:45.296314: step 1013, loss 0.323089, acc 0.875
2020-02-08T03:04:45.414615: step 1014, loss 0.431276, acc 0.78125
2020-02-08T03:04:45.531894: step 1015, loss 0.551904, acc 0.75
2020-02-08T03:04:45.647334: step 1016, loss 0.487896, acc 0.84375
2020-02-08T03:04:45.765102: step 1017, loss 0.490181, acc 0.828125
2020-02-08T03:04:45.881918: step 1018, loss 0.341319, acc 0.828125
2020-02-08T03:04:45.998199: step 1019, loss 0.340879, acc 0.875
2020-02-08T03:04:46.114882: step 1020, loss 0.34699, acc 0.84375
2020-02-08T03:04:46.231197: step 1021, loss 0.525427, acc 0.78125
2020-02-08T03:04:46.343995: step 1022, loss 0.464558, acc 0.796875
2020-02-08T03:04:46.461486: step 1023, loss 0.40117, acc 0.8125
2020-02-08T03:04:46.583047: step 1024, loss 0.490673, acc 0.78125
2020-02-08T03:04:46.699558: step 1025, loss 0.388904, acc 0.8125
2020-02-08T03:04:46.813913: step 1026, loss 0.480048, acc 0.78125
2020-02-08T03:04:46.931538: step 1027, loss 0.28999, acc 0.890625
2020-02-08T03:04:47.047728: step 1028, loss 0.401253, acc 0.8125
2020-02-08T03:04:47.168893: step 1029, loss 0.375701, acc 0.828125
2020-02-08T03:04:47.284624: step 1030, loss 0.324433, acc 0.8125
2020-02-08T03:04:47.402318: step 1031, loss 0.450374, acc 0.78125
2020-02-08T03:04:47.519259: step 1032, loss 0.431502, acc 0.84375
2020-02-08T03:04:47.634497: step 1033, loss 0.383701, acc 0.8125
2020-02-08T03:04:47.749667: step 1034, loss 0.405289, acc 0.765625
2020-02-08T03:04:47.866784: step 1035, loss 0.445602, acc 0.78125
2020-02-08T03:04:47.982604: step 1036, loss 0.325942, acc 0.828125
2020-02-08T03:04:48.094424: step 1037, loss 0.508049, acc 0.78125
2020-02-08T03:04:48.212327: step 1038, loss 0.399387, acc 0.859375
2020-02-08T03:04:48.328282: step 1039, loss 0.405694, acc 0.8125
2020-02-08T03:04:48.445037: step 1040, loss 0.457156, acc 0.75
2020-02-08T03:04:48.563333: step 1041, loss 0.423162, acc 0.828125
2020-02-08T03:04:48.680742: step 1042, loss 0.354665, acc 0.84375
2020-02-08T03:04:48.796276: step 1043, loss 0.286973, acc 0.921875
2020-02-08T03:04:48.912020: step 1044, loss 0.525414, acc 0.78125
2020-02-08T03:04:49.028239: step 1045, loss 0.358268, acc 0.78125
2020-02-08T03:04:49.142274: step 1046, loss 0.439719, acc 0.8125
2020-02-08T03:04:49.258858: step 1047, loss 0.446737, acc 0.75
2020-02-08T03:04:49.376126: step 1048, loss 0.407469, acc 0.84375
2020-02-08T03:04:49.493442: step 1049, loss 0.287607, acc 0.890625
2020-02-08T03:04:49.607580: step 1050, loss 0.309965, acc 0.866667
2020-02-08T03:04:49.728509: step 1051, loss 0.343744, acc 0.8125
2020-02-08T03:04:49.842126: step 1052, loss 0.336335, acc 0.90625
2020-02-08T03:04:49.960309: step 1053, loss 0.33088, acc 0.859375
2020-02-08T03:04:50.075771: step 1054, loss 0.286811, acc 0.890625
2020-02-08T03:04:50.190513: step 1055, loss 0.367011, acc 0.765625
2020-02-08T03:04:50.310422: step 1056, loss 0.318305, acc 0.875
2020-02-08T03:04:50.427890: step 1057, loss 0.271831, acc 0.875
2020-02-08T03:04:50.544533: step 1058, loss 0.519301, acc 0.78125
2020-02-08T03:04:50.664977: step 1059, loss 0.295442, acc 0.875
2020-02-08T03:04:50.781831: step 1060, loss 0.368185, acc 0.8125
2020-02-08T03:04:50.896788: step 1061, loss 0.276482, acc 0.890625
2020-02-08T03:04:51.015212: step 1062, loss 0.294625, acc 0.875
2020-02-08T03:04:51.132916: step 1063, loss 0.318699, acc 0.84375
2020-02-08T03:04:51.249905: step 1064, loss 0.409961, acc 0.796875
2020-02-08T03:04:51.363896: step 1065, loss 0.315803, acc 0.890625
2020-02-08T03:04:51.707288: step 1066, loss 0.249394, acc 0.890625
2020-02-08T03:04:51.834439: step 1067, loss 0.316359, acc 0.859375
2020-02-08T03:04:51.951973: step 1068, loss 0.462194, acc 0.78125
2020-02-08T03:04:52.069091: step 1069, loss 0.368567, acc 0.765625
2020-02-08T03:04:52.183784: step 1070, loss 0.322318, acc 0.875
2020-02-08T03:04:52.297026: step 1071, loss 0.240889, acc 0.890625
2020-02-08T03:04:52.412219: step 1072, loss 0.478484, acc 0.78125
2020-02-08T03:04:52.528357: step 1073, loss 0.39053, acc 0.828125
2020-02-08T03:04:52.644223: step 1074, loss 0.301934, acc 0.890625
2020-02-08T03:04:52.761262: step 1075, loss 0.313946, acc 0.859375
2020-02-08T03:04:52.878306: step 1076, loss 0.27021, acc 0.890625
2020-02-08T03:04:52.993395: step 1077, loss 0.313405, acc 0.875
2020-02-08T03:04:53.110055: step 1078, loss 0.378886, acc 0.8125
2020-02-08T03:04:53.230487: step 1079, loss 0.386105, acc 0.828125
2020-02-08T03:04:53.345406: step 1080, loss 0.416719, acc 0.8125
2020-02-08T03:04:53.464001: step 1081, loss 0.333182, acc 0.875
2020-02-08T03:04:53.581582: step 1082, loss 0.242125, acc 0.90625
2020-02-08T03:04:53.696839: step 1083, loss 0.24038, acc 0.921875
2020-02-08T03:04:53.813720: step 1084, loss 0.341821, acc 0.84375
2020-02-08T03:04:53.929566: step 1085, loss 0.377445, acc 0.84375
2020-02-08T03:04:54.046827: step 1086, loss 0.387274, acc 0.8125
2020-02-08T03:04:54.164305: step 1087, loss 0.227259, acc 0.921875
2020-02-08T03:04:54.285581: step 1088, loss 0.26463, acc 0.890625
2020-02-08T03:04:54.406105: step 1089, loss 0.190823, acc 0.9375
2020-02-08T03:04:54.524548: step 1090, loss 0.27974, acc 0.875
2020-02-08T03:04:54.639031: step 1091, loss 0.321051, acc 0.828125
2020-02-08T03:04:54.757183: step 1092, loss 0.302566, acc 0.875
2020-02-08T03:04:54.875106: step 1093, loss 0.311316, acc 0.859375
2020-02-08T03:04:54.989801: step 1094, loss 0.354663, acc 0.8125
2020-02-08T03:04:55.106027: step 1095, loss 0.290606, acc 0.84375
2020-02-08T03:04:55.221579: step 1096, loss 0.335392, acc 0.890625
2020-02-08T03:04:55.336140: step 1097, loss 0.231954, acc 0.890625
2020-02-08T03:04:55.452097: step 1098, loss 0.22553, acc 0.9375
2020-02-08T03:04:55.569194: step 1099, loss 0.309671, acc 0.84375
2020-02-08T03:04:55.683977: step 1100, loss 0.305067, acc 0.90625

Evaluation:
2020-02-08T03:04:55.871102: step 1100, loss 0.566848, acc 0.701689

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1100

2020-02-08T03:04:58.577616: step 1101, loss 0.286439, acc 0.890625
2020-02-08T03:04:58.692903: step 1102, loss 0.346861, acc 0.84375
2020-02-08T03:04:58.810010: step 1103, loss 0.288263, acc 0.859375
2020-02-08T03:04:58.927912: step 1104, loss 0.439401, acc 0.8125
2020-02-08T03:04:59.043542: step 1105, loss 0.231956, acc 0.90625
2020-02-08T03:04:59.164871: step 1106, loss 0.249269, acc 0.921875
2020-02-08T03:04:59.280514: step 1107, loss 0.30146, acc 0.875
2020-02-08T03:04:59.397189: step 1108, loss 0.32755, acc 0.84375
2020-02-08T03:04:59.515120: step 1109, loss 0.182951, acc 0.96875
2020-02-08T03:04:59.632434: step 1110, loss 0.344582, acc 0.859375
2020-02-08T03:04:59.750011: step 1111, loss 0.319659, acc 0.890625
2020-02-08T03:04:59.868737: step 1112, loss 0.253582, acc 0.84375
2020-02-08T03:04:59.985809: step 1113, loss 0.375432, acc 0.8125
2020-02-08T03:05:00.103960: step 1114, loss 0.324865, acc 0.859375
2020-02-08T03:05:00.220719: step 1115, loss 0.275633, acc 0.90625
2020-02-08T03:05:00.336446: step 1116, loss 0.276031, acc 0.875
2020-02-08T03:05:00.454244: step 1117, loss 0.390537, acc 0.796875
2020-02-08T03:05:00.570130: step 1118, loss 0.345137, acc 0.796875
2020-02-08T03:05:00.687330: step 1119, loss 0.240782, acc 0.890625
2020-02-08T03:05:00.803650: step 1120, loss 0.314796, acc 0.875
2020-02-08T03:05:00.920199: step 1121, loss 0.238268, acc 0.90625
2020-02-08T03:05:01.035773: step 1122, loss 0.323535, acc 0.828125
2020-02-08T03:05:01.153940: step 1123, loss 0.329302, acc 0.875
2020-02-08T03:05:01.270752: step 1124, loss 0.310464, acc 0.859375
2020-02-08T03:05:01.387325: step 1125, loss 0.278062, acc 0.875
2020-02-08T03:05:01.511479: step 1126, loss 0.429485, acc 0.78125
2020-02-08T03:05:01.627725: step 1127, loss 0.352922, acc 0.796875
2020-02-08T03:05:01.742424: step 1128, loss 0.291036, acc 0.875
2020-02-08T03:05:01.857036: step 1129, loss 0.474419, acc 0.796875
2020-02-08T03:05:01.973190: step 1130, loss 0.430505, acc 0.8125
2020-02-08T03:05:02.086855: step 1131, loss 0.272706, acc 0.875
2020-02-08T03:05:02.204684: step 1132, loss 0.491861, acc 0.8125
2020-02-08T03:05:02.324260: step 1133, loss 0.290349, acc 0.859375
2020-02-08T03:05:02.438494: step 1134, loss 0.3157, acc 0.859375
2020-02-08T03:05:02.554618: step 1135, loss 0.338498, acc 0.796875
2020-02-08T03:05:02.671556: step 1136, loss 0.27706, acc 0.8125
2020-02-08T03:05:02.787148: step 1137, loss 0.319292, acc 0.828125
2020-02-08T03:05:02.904020: step 1138, loss 0.2248, acc 0.9375
2020-02-08T03:05:03.022764: step 1139, loss 0.272714, acc 0.875
2020-02-08T03:05:03.136140: step 1140, loss 0.183041, acc 0.96875
2020-02-08T03:05:03.255368: step 1141, loss 0.241593, acc 0.890625
2020-02-08T03:05:03.373097: step 1142, loss 0.27779, acc 0.859375
2020-02-08T03:05:03.488049: step 1143, loss 0.205535, acc 0.953125
2020-02-08T03:05:03.604774: step 1144, loss 0.380744, acc 0.8125
2020-02-08T03:05:03.720501: step 1145, loss 0.215522, acc 0.90625
2020-02-08T03:05:03.835912: step 1146, loss 0.326045, acc 0.875
2020-02-08T03:05:03.956717: step 1147, loss 0.228004, acc 0.9375
2020-02-08T03:05:04.074552: step 1148, loss 0.320495, acc 0.828125
2020-02-08T03:05:04.191325: step 1149, loss 0.394348, acc 0.828125
2020-02-08T03:05:04.308461: step 1150, loss 0.410302, acc 0.859375
2020-02-08T03:05:04.424703: step 1151, loss 0.278932, acc 0.890625
2020-02-08T03:05:04.540926: step 1152, loss 0.229539, acc 0.90625
2020-02-08T03:05:04.655651: step 1153, loss 0.39507, acc 0.875
2020-02-08T03:05:04.774603: step 1154, loss 0.298727, acc 0.890625
2020-02-08T03:05:04.890694: step 1155, loss 0.351213, acc 0.890625
2020-02-08T03:05:05.006841: step 1156, loss 0.238347, acc 0.890625
2020-02-08T03:05:05.123741: step 1157, loss 0.360092, acc 0.84375
2020-02-08T03:05:05.240021: step 1158, loss 0.258865, acc 0.9375
2020-02-08T03:05:05.359127: step 1159, loss 0.237599, acc 0.90625
2020-02-08T03:05:05.474836: step 1160, loss 0.304119, acc 0.859375
2020-02-08T03:05:05.590816: step 1161, loss 0.401328, acc 0.8125
2020-02-08T03:05:05.707475: step 1162, loss 0.298569, acc 0.875
2020-02-08T03:05:05.823748: step 1163, loss 0.438433, acc 0.8125
2020-02-08T03:05:05.939274: step 1164, loss 0.381567, acc 0.796875
2020-02-08T03:05:06.054980: step 1165, loss 0.326127, acc 0.828125
2020-02-08T03:05:06.172556: step 1166, loss 0.306127, acc 0.875
2020-02-08T03:05:06.286007: step 1167, loss 0.356366, acc 0.8125
2020-02-08T03:05:06.405110: step 1168, loss 0.380008, acc 0.84375
2020-02-08T03:05:06.524654: step 1169, loss 0.288865, acc 0.84375
2020-02-08T03:05:06.645658: step 1170, loss 0.311473, acc 0.875
2020-02-08T03:05:06.764672: step 1171, loss 0.312848, acc 0.890625
2020-02-08T03:05:06.881991: step 1172, loss 0.243039, acc 0.9375
2020-02-08T03:05:06.997359: step 1173, loss 0.413952, acc 0.75
2020-02-08T03:05:07.114921: step 1174, loss 0.257361, acc 0.90625
2020-02-08T03:05:07.232852: step 1175, loss 0.340025, acc 0.8125
2020-02-08T03:05:07.349326: step 1176, loss 0.192833, acc 0.9375
2020-02-08T03:05:07.468444: step 1177, loss 0.427981, acc 0.859375
2020-02-08T03:05:07.583102: step 1178, loss 0.509328, acc 0.75
2020-02-08T03:05:07.700992: step 1179, loss 0.323612, acc 0.84375
2020-02-08T03:05:07.817258: step 1180, loss 0.279508, acc 0.90625
2020-02-08T03:05:07.935452: step 1181, loss 0.304546, acc 0.828125
2020-02-08T03:05:08.053899: step 1182, loss 0.368709, acc 0.859375
2020-02-08T03:05:08.173810: step 1183, loss 0.360268, acc 0.8125
2020-02-08T03:05:08.287411: step 1184, loss 0.273607, acc 0.890625
2020-02-08T03:05:08.406123: step 1185, loss 0.265454, acc 0.90625
2020-02-08T03:05:08.524358: step 1186, loss 0.36036, acc 0.8125
2020-02-08T03:05:08.639335: step 1187, loss 0.343794, acc 0.828125
2020-02-08T03:05:08.758688: step 1188, loss 0.375159, acc 0.8125
2020-02-08T03:05:08.875611: step 1189, loss 0.30884, acc 0.875
2020-02-08T03:05:08.995510: step 1190, loss 0.374603, acc 0.84375
2020-02-08T03:05:09.114695: step 1191, loss 0.266632, acc 0.875
2020-02-08T03:05:09.230265: step 1192, loss 0.513671, acc 0.765625
2020-02-08T03:05:09.348736: step 1193, loss 0.309123, acc 0.828125
2020-02-08T03:05:09.465821: step 1194, loss 0.360608, acc 0.859375
2020-02-08T03:05:09.580525: step 1195, loss 0.382102, acc 0.8125
2020-02-08T03:05:09.696961: step 1196, loss 0.331302, acc 0.890625
2020-02-08T03:05:09.813826: step 1197, loss 0.220415, acc 0.921875
2020-02-08T03:05:09.929303: step 1198, loss 0.337727, acc 0.890625
2020-02-08T03:05:10.046284: step 1199, loss 0.385014, acc 0.8125
2020-02-08T03:05:10.158573: step 1200, loss 0.222948, acc 0.866667

Evaluation:
2020-02-08T03:05:10.343872: step 1200, loss 0.580392, acc 0.712008

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1200

2020-02-08T03:05:12.377880: step 1201, loss 0.285139, acc 0.890625
2020-02-08T03:05:12.492319: step 1202, loss 0.297422, acc 0.84375
2020-02-08T03:05:12.609753: step 1203, loss 0.271358, acc 0.890625
2020-02-08T03:05:12.726827: step 1204, loss 0.308137, acc 0.859375
2020-02-08T03:05:12.841982: step 1205, loss 0.253326, acc 0.9375
2020-02-08T03:05:12.959329: step 1206, loss 0.210681, acc 0.921875
2020-02-08T03:05:13.076608: step 1207, loss 0.242521, acc 0.90625
2020-02-08T03:05:13.192217: step 1208, loss 0.246249, acc 0.90625
2020-02-08T03:05:13.309887: step 1209, loss 0.212812, acc 0.9375
2020-02-08T03:05:13.426784: step 1210, loss 0.338627, acc 0.84375
2020-02-08T03:05:13.541777: step 1211, loss 0.214542, acc 0.890625
2020-02-08T03:05:13.660575: step 1212, loss 0.236115, acc 0.90625
2020-02-08T03:05:13.776997: step 1213, loss 0.228879, acc 0.890625
2020-02-08T03:05:13.888745: step 1214, loss 0.167573, acc 0.953125
2020-02-08T03:05:14.002905: step 1215, loss 0.282962, acc 0.890625
2020-02-08T03:05:14.120455: step 1216, loss 0.322265, acc 0.875
2020-02-08T03:05:14.237879: step 1217, loss 0.209999, acc 0.921875
2020-02-08T03:05:14.352122: step 1218, loss 0.195597, acc 0.9375
2020-02-08T03:05:14.468056: step 1219, loss 0.264648, acc 0.9375
2020-02-08T03:05:14.584414: step 1220, loss 0.247537, acc 0.90625
2020-02-08T03:05:14.699142: step 1221, loss 0.232881, acc 0.890625
2020-02-08T03:05:14.815314: step 1222, loss 0.256787, acc 0.890625
2020-02-08T03:05:14.931603: step 1223, loss 0.204136, acc 0.9375
2020-02-08T03:05:15.050342: step 1224, loss 0.311593, acc 0.84375
2020-02-08T03:05:15.168422: step 1225, loss 0.235984, acc 0.890625
2020-02-08T03:05:15.284263: step 1226, loss 0.232985, acc 0.890625
2020-02-08T03:05:15.400669: step 1227, loss 0.161732, acc 0.9375
2020-02-08T03:05:15.517357: step 1228, loss 0.340404, acc 0.828125
2020-02-08T03:05:15.633751: step 1229, loss 0.24962, acc 0.875
2020-02-08T03:05:15.749177: step 1230, loss 0.191225, acc 0.9375
2020-02-08T03:05:15.865304: step 1231, loss 0.301317, acc 0.90625
2020-02-08T03:05:15.981434: step 1232, loss 0.328199, acc 0.890625
2020-02-08T03:05:16.095815: step 1233, loss 0.254825, acc 0.890625
2020-02-08T03:05:16.212799: step 1234, loss 0.202764, acc 0.921875
2020-02-08T03:05:16.329426: step 1235, loss 0.22033, acc 0.890625
2020-02-08T03:05:16.445374: step 1236, loss 0.211851, acc 0.9375
2020-02-08T03:05:16.562158: step 1237, loss 0.23359, acc 0.921875
2020-02-08T03:05:16.678811: step 1238, loss 0.169811, acc 0.953125
2020-02-08T03:05:16.797260: step 1239, loss 0.223774, acc 0.90625
2020-02-08T03:05:16.912285: step 1240, loss 0.146661, acc 0.953125
2020-02-08T03:05:17.028912: step 1241, loss 0.312887, acc 0.890625
2020-02-08T03:05:17.141217: step 1242, loss 0.246855, acc 0.90625
2020-02-08T03:05:17.257280: step 1243, loss 0.26663, acc 0.90625
2020-02-08T03:05:17.376599: step 1244, loss 0.266708, acc 0.875
2020-02-08T03:05:17.493335: step 1245, loss 0.341041, acc 0.828125
2020-02-08T03:05:17.609699: step 1246, loss 0.363267, acc 0.875
2020-02-08T03:05:17.724846: step 1247, loss 0.151417, acc 0.953125
2020-02-08T03:05:17.839489: step 1248, loss 0.37238, acc 0.828125
2020-02-08T03:05:17.951793: step 1249, loss 0.237561, acc 0.875
2020-02-08T03:05:18.069233: step 1250, loss 0.213321, acc 0.921875
2020-02-08T03:05:18.187128: step 1251, loss 0.283131, acc 0.890625
2020-02-08T03:05:18.302294: step 1252, loss 0.208408, acc 0.90625
2020-02-08T03:05:18.423734: step 1253, loss 0.177201, acc 0.921875
2020-02-08T03:05:18.539115: step 1254, loss 0.301889, acc 0.84375
2020-02-08T03:05:18.652651: step 1255, loss 0.343398, acc 0.875
2020-02-08T03:05:18.769033: step 1256, loss 0.316471, acc 0.890625
2020-02-08T03:05:18.885365: step 1257, loss 0.186764, acc 0.9375
2020-02-08T03:05:19.001298: step 1258, loss 0.266316, acc 0.859375
2020-02-08T03:05:19.118382: step 1259, loss 0.156231, acc 0.9375
2020-02-08T03:05:19.235997: step 1260, loss 0.251256, acc 0.890625
2020-02-08T03:05:19.354146: step 1261, loss 0.194316, acc 0.9375
2020-02-08T03:05:19.470819: step 1262, loss 0.228653, acc 0.90625
2020-02-08T03:05:19.585267: step 1263, loss 0.244439, acc 0.875
2020-02-08T03:05:19.700837: step 1264, loss 0.235022, acc 0.9375
2020-02-08T03:05:19.817271: step 1265, loss 0.327605, acc 0.875
2020-02-08T03:05:19.931635: step 1266, loss 0.232261, acc 0.875
2020-02-08T03:05:20.045879: step 1267, loss 0.260836, acc 0.90625
2020-02-08T03:05:20.163123: step 1268, loss 0.344312, acc 0.890625
2020-02-08T03:05:20.278245: step 1269, loss 0.330067, acc 0.859375
2020-02-08T03:05:20.390750: step 1270, loss 0.187192, acc 0.90625
2020-02-08T03:05:20.509053: step 1271, loss 0.232057, acc 0.90625
2020-02-08T03:05:20.625674: step 1272, loss 0.233674, acc 0.90625
2020-02-08T03:05:20.741241: step 1273, loss 0.436527, acc 0.796875
2020-02-08T03:05:20.861591: step 1274, loss 0.203648, acc 0.921875
2020-02-08T03:05:20.976210: step 1275, loss 0.201581, acc 0.90625
2020-02-08T03:05:21.090684: step 1276, loss 0.292089, acc 0.859375
2020-02-08T03:05:21.207198: step 1277, loss 0.296356, acc 0.8125
2020-02-08T03:05:21.321714: step 1278, loss 0.187547, acc 0.953125
2020-02-08T03:05:21.542219: step 1279, loss 0.359557, acc 0.84375
2020-02-08T03:05:21.662561: step 1280, loss 0.202884, acc 0.90625
2020-02-08T03:05:21.780504: step 1281, loss 0.248163, acc 0.921875
2020-02-08T03:05:21.894581: step 1282, loss 0.312533, acc 0.875
2020-02-08T03:05:22.013415: step 1283, loss 0.198154, acc 0.9375
2020-02-08T03:05:22.129549: step 1284, loss 0.215761, acc 0.875
2020-02-08T03:05:22.243994: step 1285, loss 0.32441, acc 0.859375
2020-02-08T03:05:22.361618: step 1286, loss 0.179878, acc 0.921875
2020-02-08T03:05:22.477144: step 1287, loss 0.301637, acc 0.890625
2020-02-08T03:05:22.592344: step 1288, loss 0.247118, acc 0.890625
2020-02-08T03:05:22.710860: step 1289, loss 0.129571, acc 0.984375
2020-02-08T03:05:22.828005: step 1290, loss 0.175513, acc 0.9375
2020-02-08T03:05:22.944853: step 1291, loss 0.201022, acc 0.9375
2020-02-08T03:05:23.060925: step 1292, loss 0.214874, acc 0.90625
2020-02-08T03:05:23.176592: step 1293, loss 0.265115, acc 0.921875
2020-02-08T03:05:23.291355: step 1294, loss 0.237383, acc 0.875
2020-02-08T03:05:23.411787: step 1295, loss 0.359609, acc 0.828125
2020-02-08T03:05:23.529234: step 1296, loss 0.180376, acc 0.90625
2020-02-08T03:05:23.644503: step 1297, loss 0.359789, acc 0.859375
2020-02-08T03:05:23.762712: step 1298, loss 0.241655, acc 0.875
2020-02-08T03:05:23.879087: step 1299, loss 0.29405, acc 0.890625
2020-02-08T03:05:23.993465: step 1300, loss 0.380148, acc 0.84375

Evaluation:
2020-02-08T03:05:24.180007: step 1300, loss 0.579486, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1300

2020-02-08T03:05:25.752011: step 1301, loss 0.19392, acc 0.9375
2020-02-08T03:05:25.868252: step 1302, loss 0.193214, acc 0.921875
2020-02-08T03:05:25.984240: step 1303, loss 0.254888, acc 0.90625
2020-02-08T03:05:26.098658: step 1304, loss 0.361162, acc 0.84375
2020-02-08T03:05:26.213170: step 1305, loss 0.332397, acc 0.84375
2020-02-08T03:05:26.328418: step 1306, loss 0.255984, acc 0.90625
2020-02-08T03:05:26.446304: step 1307, loss 0.316635, acc 0.90625
2020-02-08T03:05:26.563708: step 1308, loss 0.272643, acc 0.921875
2020-02-08T03:05:26.680049: step 1309, loss 0.348081, acc 0.828125
2020-02-08T03:05:26.797980: step 1310, loss 0.272427, acc 0.921875
2020-02-08T03:05:26.913497: step 1311, loss 0.277972, acc 0.84375
2020-02-08T03:05:27.027981: step 1312, loss 0.326322, acc 0.890625
2020-02-08T03:05:27.144519: step 1313, loss 0.255348, acc 0.921875
2020-02-08T03:05:27.261135: step 1314, loss 0.213214, acc 0.9375
2020-02-08T03:05:27.376361: step 1315, loss 0.380607, acc 0.859375
2020-02-08T03:05:27.493784: step 1316, loss 0.378738, acc 0.84375
2020-02-08T03:05:27.611995: step 1317, loss 0.237485, acc 0.90625
2020-02-08T03:05:27.727115: step 1318, loss 0.208971, acc 0.9375
2020-02-08T03:05:27.844371: step 1319, loss 0.24002, acc 0.953125
2020-02-08T03:05:27.965005: step 1320, loss 0.290084, acc 0.84375
2020-02-08T03:05:28.082491: step 1321, loss 0.376974, acc 0.84375
2020-02-08T03:05:28.199453: step 1322, loss 0.299825, acc 0.859375
2020-02-08T03:05:28.315567: step 1323, loss 0.26987, acc 0.90625
2020-02-08T03:05:28.431136: step 1324, loss 0.382625, acc 0.828125
2020-02-08T03:05:28.547054: step 1325, loss 0.274539, acc 0.84375
2020-02-08T03:05:28.664838: step 1326, loss 0.211767, acc 0.875
2020-02-08T03:05:28.779500: step 1327, loss 0.324315, acc 0.859375
2020-02-08T03:05:28.891624: step 1328, loss 0.174086, acc 0.96875
2020-02-08T03:05:29.011287: step 1329, loss 0.30118, acc 0.875
2020-02-08T03:05:29.126932: step 1330, loss 0.289024, acc 0.890625
2020-02-08T03:05:29.244338: step 1331, loss 0.32121, acc 0.859375
2020-02-08T03:05:29.361686: step 1332, loss 0.332232, acc 0.84375
2020-02-08T03:05:29.480044: step 1333, loss 0.276577, acc 0.8125
2020-02-08T03:05:29.595708: step 1334, loss 0.32416, acc 0.875
2020-02-08T03:05:29.711098: step 1335, loss 0.387453, acc 0.828125
2020-02-08T03:05:29.824930: step 1336, loss 0.30858, acc 0.890625
2020-02-08T03:05:29.938532: step 1337, loss 0.197584, acc 0.90625
2020-02-08T03:05:30.056188: step 1338, loss 0.473017, acc 0.828125
2020-02-08T03:05:30.172939: step 1339, loss 0.253528, acc 0.90625
2020-02-08T03:05:30.287316: step 1340, loss 0.212402, acc 0.9375
2020-02-08T03:05:30.403541: step 1341, loss 0.224007, acc 0.921875
2020-02-08T03:05:30.520967: step 1342, loss 0.401923, acc 0.8125
2020-02-08T03:05:30.640313: step 1343, loss 0.256087, acc 0.890625
2020-02-08T03:05:30.757504: step 1344, loss 0.152922, acc 0.9375
2020-02-08T03:05:30.873709: step 1345, loss 0.261353, acc 0.859375
2020-02-08T03:05:30.990275: step 1346, loss 0.333903, acc 0.875
2020-02-08T03:05:31.105403: step 1347, loss 0.222702, acc 0.90625
2020-02-08T03:05:31.224047: step 1348, loss 0.243916, acc 0.921875
2020-02-08T03:05:31.340608: step 1349, loss 0.256612, acc 0.875
2020-02-08T03:05:31.454833: step 1350, loss 0.187176, acc 0.883333
2020-02-08T03:05:31.574428: step 1351, loss 0.197591, acc 0.921875
2020-02-08T03:05:31.692241: step 1352, loss 0.204217, acc 0.9375
2020-02-08T03:05:31.808417: step 1353, loss 0.105894, acc 0.96875
2020-02-08T03:05:31.925903: step 1354, loss 0.149554, acc 0.921875
2020-02-08T03:05:32.040373: step 1355, loss 0.214522, acc 0.921875
2020-02-08T03:05:32.155819: step 1356, loss 0.12866, acc 0.984375
2020-02-08T03:05:32.271890: step 1357, loss 0.213596, acc 0.9375
2020-02-08T03:05:32.386230: step 1358, loss 0.270911, acc 0.859375
2020-02-08T03:05:32.501170: step 1359, loss 0.198749, acc 0.890625
2020-02-08T03:05:32.618498: step 1360, loss 0.197936, acc 0.9375
2020-02-08T03:05:32.734135: step 1361, loss 0.275152, acc 0.890625
2020-02-08T03:05:32.848340: step 1362, loss 0.172807, acc 0.96875
2020-02-08T03:05:32.965140: step 1363, loss 0.151361, acc 0.921875
2020-02-08T03:05:33.081987: step 1364, loss 0.193286, acc 0.921875
2020-02-08T03:05:33.195189: step 1365, loss 0.243182, acc 0.875
2020-02-08T03:05:33.312748: step 1366, loss 0.331113, acc 0.875
2020-02-08T03:05:33.430877: step 1367, loss 0.173252, acc 0.9375
2020-02-08T03:05:33.548208: step 1368, loss 0.128817, acc 0.984375
2020-02-08T03:05:33.665208: step 1369, loss 0.144593, acc 0.953125
2020-02-08T03:05:33.781592: step 1370, loss 0.276222, acc 0.828125
2020-02-08T03:05:33.893947: step 1371, loss 0.16007, acc 0.953125
2020-02-08T03:05:34.008628: step 1372, loss 0.178946, acc 0.96875
2020-02-08T03:05:34.125111: step 1373, loss 0.227547, acc 0.921875
2020-02-08T03:05:34.239533: step 1374, loss 0.173033, acc 0.9375
2020-02-08T03:05:34.356054: step 1375, loss 0.226845, acc 0.921875
2020-02-08T03:05:34.476434: step 1376, loss 0.271922, acc 0.875
2020-02-08T03:05:34.591274: step 1377, loss 0.148179, acc 0.953125
2020-02-08T03:05:34.710684: step 1378, loss 0.238469, acc 0.90625
2020-02-08T03:05:34.826594: step 1379, loss 0.275944, acc 0.875
2020-02-08T03:05:34.943747: step 1380, loss 0.103185, acc 0.96875
2020-02-08T03:05:35.060800: step 1381, loss 0.310766, acc 0.84375
2020-02-08T03:05:35.177363: step 1382, loss 0.183574, acc 0.9375
2020-02-08T03:05:35.291084: step 1383, loss 0.208389, acc 0.90625
2020-02-08T03:05:35.410242: step 1384, loss 0.271558, acc 0.890625
2020-02-08T03:05:35.529001: step 1385, loss 0.227813, acc 0.921875
2020-02-08T03:05:35.713203: step 1386, loss 0.242681, acc 0.875
2020-02-08T03:05:35.879828: step 1387, loss 0.187906, acc 0.9375
2020-02-08T03:05:36.011732: step 1388, loss 0.22627, acc 0.859375
2020-02-08T03:05:36.156700: step 1389, loss 0.171853, acc 0.9375
2020-02-08T03:05:36.294277: step 1390, loss 0.0926308, acc 1
2020-02-08T03:05:36.432336: step 1391, loss 0.217672, acc 0.921875
2020-02-08T03:05:36.567464: step 1392, loss 0.228998, acc 0.859375
2020-02-08T03:05:36.699346: step 1393, loss 0.25142, acc 0.9375
2020-02-08T03:05:36.831667: step 1394, loss 0.192759, acc 0.9375
2020-02-08T03:05:36.962249: step 1395, loss 0.251317, acc 0.890625
2020-02-08T03:05:37.112199: step 1396, loss 0.292867, acc 0.890625
2020-02-08T03:05:37.240681: step 1397, loss 0.148585, acc 0.9375
2020-02-08T03:05:37.371405: step 1398, loss 0.21965, acc 0.90625
2020-02-08T03:05:37.504822: step 1399, loss 0.236499, acc 0.875
2020-02-08T03:05:37.634434: step 1400, loss 0.236648, acc 0.90625

Evaluation:
2020-02-08T03:05:37.846728: step 1400, loss 0.585895, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1400

2020-02-08T03:05:39.386820: step 1401, loss 0.175779, acc 0.953125
2020-02-08T03:05:39.518491: step 1402, loss 0.238205, acc 0.90625
2020-02-08T03:05:39.651084: step 1403, loss 0.328783, acc 0.859375
2020-02-08T03:05:39.784380: step 1404, loss 0.19946, acc 0.921875
2020-02-08T03:05:39.921173: step 1405, loss 0.172666, acc 0.9375
2020-02-08T03:05:40.056530: step 1406, loss 0.180251, acc 0.953125
2020-02-08T03:05:40.193326: step 1407, loss 0.176081, acc 0.953125
2020-02-08T03:05:40.332635: step 1408, loss 0.251755, acc 0.875
2020-02-08T03:05:40.481300: step 1409, loss 0.393499, acc 0.859375
2020-02-08T03:05:40.629486: step 1410, loss 0.224111, acc 0.90625
2020-02-08T03:05:40.755152: step 1411, loss 0.235149, acc 0.90625
2020-02-08T03:05:40.884195: step 1412, loss 0.293756, acc 0.84375
2020-02-08T03:05:41.021143: step 1413, loss 0.195075, acc 0.921875
2020-02-08T03:05:41.155794: step 1414, loss 0.2013, acc 0.921875
2020-02-08T03:05:41.290787: step 1415, loss 0.264002, acc 0.890625
2020-02-08T03:05:41.430815: step 1416, loss 0.304045, acc 0.875
2020-02-08T03:05:41.572702: step 1417, loss 0.231726, acc 0.90625
2020-02-08T03:05:41.712049: step 1418, loss 0.148879, acc 0.9375
2020-02-08T03:05:41.854138: step 1419, loss 0.164125, acc 0.921875
2020-02-08T03:05:41.994416: step 1420, loss 0.230863, acc 0.921875
2020-02-08T03:05:42.135108: step 1421, loss 0.192148, acc 0.875
2020-02-08T03:05:42.275599: step 1422, loss 0.216265, acc 0.90625
2020-02-08T03:05:42.414918: step 1423, loss 0.16091, acc 0.953125
2020-02-08T03:05:42.552750: step 1424, loss 0.288709, acc 0.828125
2020-02-08T03:05:42.686864: step 1425, loss 0.195743, acc 0.953125
2020-02-08T03:05:42.812705: step 1426, loss 0.244118, acc 0.859375
2020-02-08T03:05:42.952305: step 1427, loss 0.1611, acc 0.953125
2020-02-08T03:05:43.093145: step 1428, loss 0.168028, acc 0.953125
2020-02-08T03:05:43.231617: step 1429, loss 0.199703, acc 0.9375
2020-02-08T03:05:43.368272: step 1430, loss 0.179271, acc 0.921875
2020-02-08T03:05:43.506743: step 1431, loss 0.270699, acc 0.921875
2020-02-08T03:05:43.645646: step 1432, loss 0.233064, acc 0.90625
2020-02-08T03:05:43.788349: step 1433, loss 0.198111, acc 0.921875
2020-02-08T03:05:43.916508: step 1434, loss 0.201765, acc 0.90625
2020-02-08T03:05:44.049535: step 1435, loss 0.122844, acc 0.953125
2020-02-08T03:05:44.175266: step 1436, loss 0.147106, acc 0.953125
2020-02-08T03:05:44.303635: step 1437, loss 0.248906, acc 0.921875
2020-02-08T03:05:44.429266: step 1438, loss 0.180481, acc 0.9375
2020-02-08T03:05:44.554487: step 1439, loss 0.228794, acc 0.890625
2020-02-08T03:05:44.683992: step 1440, loss 0.271278, acc 0.90625
2020-02-08T03:05:44.813161: step 1441, loss 0.253441, acc 0.875
2020-02-08T03:05:44.939760: step 1442, loss 0.126349, acc 0.96875
2020-02-08T03:05:45.085233: step 1443, loss 0.345572, acc 0.828125
2020-02-08T03:05:45.230419: step 1444, loss 0.18817, acc 0.890625
2020-02-08T03:05:45.364501: step 1445, loss 0.0805742, acc 0.984375
2020-02-08T03:05:45.492761: step 1446, loss 0.165323, acc 0.921875
2020-02-08T03:05:45.632725: step 1447, loss 0.196778, acc 0.90625
2020-02-08T03:05:45.767855: step 1448, loss 0.186484, acc 0.921875
2020-02-08T03:05:45.883045: step 1449, loss 0.307872, acc 0.84375
2020-02-08T03:05:46.003240: step 1450, loss 0.256875, acc 0.9375
2020-02-08T03:05:46.117484: step 1451, loss 0.365617, acc 0.828125
2020-02-08T03:05:46.236255: step 1452, loss 0.17429, acc 0.921875
2020-02-08T03:05:46.361360: step 1453, loss 0.153345, acc 0.953125
2020-02-08T03:05:46.488696: step 1454, loss 0.246392, acc 0.890625
2020-02-08T03:05:46.608503: step 1455, loss 0.207057, acc 0.890625
2020-02-08T03:05:46.727251: step 1456, loss 0.26055, acc 0.875
2020-02-08T03:05:46.843351: step 1457, loss 0.153111, acc 0.9375
2020-02-08T03:05:46.960676: step 1458, loss 0.256028, acc 0.859375
2020-02-08T03:05:47.079516: step 1459, loss 0.277986, acc 0.90625
2020-02-08T03:05:47.194487: step 1460, loss 0.196874, acc 0.90625
2020-02-08T03:05:47.313113: step 1461, loss 0.246884, acc 0.890625
2020-02-08T03:05:47.430538: step 1462, loss 0.165983, acc 0.96875
2020-02-08T03:05:47.544154: step 1463, loss 0.199407, acc 0.921875
2020-02-08T03:05:47.661491: step 1464, loss 0.27695, acc 0.84375
2020-02-08T03:05:47.781502: step 1465, loss 0.190229, acc 0.953125
2020-02-08T03:05:47.899549: step 1466, loss 0.136639, acc 0.96875
2020-02-08T03:05:48.018368: step 1467, loss 0.185819, acc 0.890625
2020-02-08T03:05:48.135479: step 1468, loss 0.1274, acc 0.9375
2020-02-08T03:05:48.256668: step 1469, loss 0.221054, acc 0.875
2020-02-08T03:05:48.376685: step 1470, loss 0.137304, acc 0.96875
2020-02-08T03:05:48.503131: step 1471, loss 0.197598, acc 0.90625
2020-02-08T03:05:48.620319: step 1472, loss 0.219841, acc 0.890625
2020-02-08T03:05:48.735786: step 1473, loss 0.205165, acc 0.890625
2020-02-08T03:05:48.851364: step 1474, loss 0.224094, acc 0.890625
2020-02-08T03:05:48.968810: step 1475, loss 0.220257, acc 0.921875
2020-02-08T03:05:49.083497: step 1476, loss 0.170462, acc 0.9375
2020-02-08T03:05:49.200111: step 1477, loss 0.20461, acc 0.921875
2020-02-08T03:05:49.318623: step 1478, loss 0.256794, acc 0.90625
2020-02-08T03:05:49.437130: step 1479, loss 0.303973, acc 0.828125
2020-02-08T03:05:49.550960: step 1480, loss 0.228528, acc 0.921875
2020-02-08T03:05:49.666486: step 1481, loss 0.186436, acc 0.953125
2020-02-08T03:05:49.785398: step 1482, loss 0.184738, acc 0.90625
2020-02-08T03:05:49.908231: step 1483, loss 0.187462, acc 0.9375
2020-02-08T03:05:50.038787: step 1484, loss 0.12515, acc 0.953125
2020-02-08T03:05:50.156975: step 1485, loss 0.215317, acc 0.9375
2020-02-08T03:05:50.276085: step 1486, loss 0.146878, acc 0.953125
2020-02-08T03:05:50.391624: step 1487, loss 0.130399, acc 0.9375
2020-02-08T03:05:50.507376: step 1488, loss 0.168932, acc 0.921875
2020-02-08T03:05:50.623937: step 1489, loss 0.189818, acc 0.921875
2020-02-08T03:05:50.739140: step 1490, loss 0.235925, acc 0.875
2020-02-08T03:05:50.855009: step 1491, loss 0.188618, acc 0.953125
2020-02-08T03:05:50.971405: step 1492, loss 0.166358, acc 0.9375
2020-02-08T03:05:51.086585: step 1493, loss 0.31674, acc 0.84375
2020-02-08T03:05:51.202105: step 1494, loss 0.206397, acc 0.90625
2020-02-08T03:05:51.322195: step 1495, loss 0.249368, acc 0.921875
2020-02-08T03:05:51.436485: step 1496, loss 0.195191, acc 0.9375
2020-02-08T03:05:51.567512: step 1497, loss 0.225236, acc 0.890625
2020-02-08T03:05:51.690843: step 1498, loss 0.29445, acc 0.875
2020-02-08T03:05:51.805739: step 1499, loss 0.198458, acc 0.90625
2020-02-08T03:05:51.919887: step 1500, loss 0.161416, acc 0.933333

Evaluation:
2020-02-08T03:05:52.111254: step 1500, loss 0.597159, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1500

2020-02-08T03:05:54.280904: step 1501, loss 0.127587, acc 0.921875
2020-02-08T03:05:54.395701: step 1502, loss 0.236889, acc 0.921875
2020-02-08T03:05:54.511727: step 1503, loss 0.10875, acc 0.9375
2020-02-08T03:05:54.628694: step 1504, loss 0.13125, acc 0.9375
2020-02-08T03:05:54.742726: step 1505, loss 0.127674, acc 0.953125
2020-02-08T03:05:54.860574: step 1506, loss 0.225322, acc 0.875
2020-02-08T03:05:54.976769: step 1507, loss 0.176978, acc 0.953125
2020-02-08T03:05:55.089738: step 1508, loss 0.157243, acc 0.9375
2020-02-08T03:05:55.207942: step 1509, loss 0.14551, acc 0.953125
2020-02-08T03:05:55.325620: step 1510, loss 0.112899, acc 1
2020-02-08T03:05:55.441650: step 1511, loss 0.112267, acc 0.953125
2020-02-08T03:05:55.557605: step 1512, loss 0.170235, acc 0.9375
2020-02-08T03:05:55.675918: step 1513, loss 0.126566, acc 0.96875
2020-02-08T03:05:55.791118: step 1514, loss 0.208887, acc 0.890625
2020-02-08T03:05:55.909402: step 1515, loss 0.15157, acc 0.953125
2020-02-08T03:05:56.028277: step 1516, loss 0.184715, acc 0.90625
2020-02-08T03:05:56.145003: step 1517, loss 0.171822, acc 0.9375
2020-02-08T03:05:56.264931: step 1518, loss 0.123976, acc 0.96875
2020-02-08T03:05:56.379236: step 1519, loss 0.117706, acc 0.953125
2020-02-08T03:05:56.492283: step 1520, loss 0.113856, acc 0.96875
2020-02-08T03:05:56.605967: step 1521, loss 0.133688, acc 0.96875
2020-02-08T03:05:56.724759: step 1522, loss 0.133693, acc 0.9375
2020-02-08T03:05:56.841432: step 1523, loss 0.189743, acc 0.890625
2020-02-08T03:05:56.957621: step 1524, loss 0.184736, acc 0.921875
2020-02-08T03:05:57.074299: step 1525, loss 0.115655, acc 0.96875
2020-02-08T03:05:57.190000: step 1526, loss 0.139236, acc 0.96875
2020-02-08T03:05:57.303071: step 1527, loss 0.168598, acc 0.921875
2020-02-08T03:05:57.420767: step 1528, loss 0.217417, acc 0.859375
2020-02-08T03:05:57.538554: step 1529, loss 0.185373, acc 0.921875
2020-02-08T03:05:57.653545: step 1530, loss 0.192164, acc 0.921875
2020-02-08T03:05:57.768933: step 1531, loss 0.152804, acc 0.9375
2020-02-08T03:05:57.884354: step 1532, loss 0.141816, acc 0.96875
2020-02-08T03:05:57.999773: step 1533, loss 0.17123, acc 0.921875
2020-02-08T03:05:58.116582: step 1534, loss 0.156445, acc 0.953125
2020-02-08T03:05:58.233471: step 1535, loss 0.187588, acc 0.921875
2020-02-08T03:05:58.352598: step 1536, loss 0.209268, acc 0.9375
2020-02-08T03:05:58.472784: step 1537, loss 0.205788, acc 0.90625
2020-02-08T03:05:58.587920: step 1538, loss 0.163322, acc 0.9375
2020-02-08T03:05:58.709395: step 1539, loss 0.131293, acc 0.953125
2020-02-08T03:05:58.828455: step 1540, loss 0.0630605, acc 0.984375
2020-02-08T03:05:58.944061: step 1541, loss 0.0966247, acc 0.96875
2020-02-08T03:05:59.063254: step 1542, loss 0.171402, acc 0.90625
2020-02-08T03:05:59.180608: step 1543, loss 0.183757, acc 0.921875
2020-02-08T03:05:59.295009: step 1544, loss 0.153312, acc 0.953125
2020-02-08T03:05:59.411633: step 1545, loss 0.140928, acc 0.921875
2020-02-08T03:05:59.528623: step 1546, loss 0.168868, acc 0.9375
2020-02-08T03:05:59.645190: step 1547, loss 0.148862, acc 0.921875
2020-02-08T03:05:59.764016: step 1548, loss 0.207744, acc 0.921875
2020-02-08T03:05:59.881287: step 1549, loss 0.137694, acc 0.953125
2020-02-08T03:05:59.995868: step 1550, loss 0.147353, acc 0.921875
2020-02-08T03:06:00.120616: step 1551, loss 0.144531, acc 0.96875
2020-02-08T03:06:00.237900: step 1552, loss 0.124471, acc 0.953125
2020-02-08T03:06:00.354807: step 1553, loss 0.373142, acc 0.828125
2020-02-08T03:06:00.473139: step 1554, loss 0.176546, acc 0.921875
2020-02-08T03:06:00.588689: step 1555, loss 0.148363, acc 0.9375
2020-02-08T03:06:00.705678: step 1556, loss 0.127656, acc 0.984375
2020-02-08T03:06:00.824128: step 1557, loss 0.0978648, acc 0.953125
2020-02-08T03:06:00.940653: step 1558, loss 0.195911, acc 0.9375
2020-02-08T03:06:01.062096: step 1559, loss 0.107927, acc 0.9375
2020-02-08T03:06:01.180625: step 1560, loss 0.120516, acc 0.953125
2020-02-08T03:06:01.297833: step 1561, loss 0.0993116, acc 0.984375
2020-02-08T03:06:01.418639: step 1562, loss 0.144556, acc 0.96875
2020-02-08T03:06:01.533561: step 1563, loss 0.13272, acc 0.921875
2020-02-08T03:06:01.647846: step 1564, loss 0.130394, acc 0.9375
2020-02-08T03:06:01.763786: step 1565, loss 0.129262, acc 0.9375
2020-02-08T03:06:01.882331: step 1566, loss 0.0661964, acc 0.953125
2020-02-08T03:06:01.997396: step 1567, loss 0.102944, acc 0.9375
2020-02-08T03:06:02.113235: step 1568, loss 0.15447, acc 0.953125
2020-02-08T03:06:02.229494: step 1569, loss 0.259849, acc 0.890625
2020-02-08T03:06:02.343652: step 1570, loss 0.218996, acc 0.890625
2020-02-08T03:06:02.461909: step 1571, loss 0.126644, acc 0.953125
2020-02-08T03:06:02.577571: step 1572, loss 0.135273, acc 0.9375
2020-02-08T03:06:02.692552: step 1573, loss 0.222253, acc 0.90625
2020-02-08T03:06:02.807085: step 1574, loss 0.147579, acc 0.921875
2020-02-08T03:06:02.923297: step 1575, loss 0.150281, acc 0.921875
2020-02-08T03:06:03.039929: step 1576, loss 0.153695, acc 0.9375
2020-02-08T03:06:03.156487: step 1577, loss 0.122884, acc 0.953125
2020-02-08T03:06:03.273359: step 1578, loss 0.276969, acc 0.90625
2020-02-08T03:06:03.391306: step 1579, loss 0.15395, acc 0.953125
2020-02-08T03:06:03.508036: step 1580, loss 0.165125, acc 0.890625
2020-02-08T03:06:03.624602: step 1581, loss 0.0969548, acc 0.96875
2020-02-08T03:06:03.738093: step 1582, loss 0.254627, acc 0.875
2020-02-08T03:06:03.856848: step 1583, loss 0.300709, acc 0.859375
2020-02-08T03:06:03.971526: step 1584, loss 0.144959, acc 0.9375
2020-02-08T03:06:04.086897: step 1585, loss 0.319311, acc 0.875
2020-02-08T03:06:04.202312: step 1586, loss 0.12752, acc 0.9375
2020-02-08T03:06:04.317558: step 1587, loss 0.20161, acc 0.921875
2020-02-08T03:06:04.434140: step 1588, loss 0.180755, acc 0.921875
2020-02-08T03:06:04.550508: step 1589, loss 0.114219, acc 0.953125
2020-02-08T03:06:04.670119: step 1590, loss 0.0744636, acc 0.96875
2020-02-08T03:06:04.783520: step 1591, loss 0.187505, acc 0.9375
2020-02-08T03:06:04.899425: step 1592, loss 0.247073, acc 0.921875
2020-02-08T03:06:05.016682: step 1593, loss 0.156797, acc 0.953125
2020-02-08T03:06:05.131498: step 1594, loss 0.241816, acc 0.890625
2020-02-08T03:06:05.248199: step 1595, loss 0.24821, acc 0.890625
2020-02-08T03:06:05.365975: step 1596, loss 0.106918, acc 0.96875
2020-02-08T03:06:05.484684: step 1597, loss 0.158707, acc 0.9375
2020-02-08T03:06:05.602715: step 1598, loss 0.123203, acc 0.953125
2020-02-08T03:06:05.717872: step 1599, loss 0.222542, acc 0.90625
2020-02-08T03:06:05.835026: step 1600, loss 0.0742912, acc 0.96875

Evaluation:
2020-02-08T03:06:06.021163: step 1600, loss 0.618204, acc 0.716698

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1600

2020-02-08T03:06:07.536265: step 1601, loss 0.211141, acc 0.9375
2020-02-08T03:06:07.655599: step 1602, loss 0.135966, acc 0.9375
2020-02-08T03:06:07.769209: step 1603, loss 0.0940631, acc 0.984375
2020-02-08T03:06:07.886349: step 1604, loss 0.238455, acc 0.875
2020-02-08T03:06:08.003772: step 1605, loss 0.166019, acc 0.953125
2020-02-08T03:06:08.120434: step 1606, loss 0.303901, acc 0.875
2020-02-08T03:06:08.234814: step 1607, loss 0.118361, acc 0.96875
2020-02-08T03:06:08.349941: step 1608, loss 0.336059, acc 0.859375
2020-02-08T03:06:08.469695: step 1609, loss 0.198895, acc 0.953125
2020-02-08T03:06:08.584663: step 1610, loss 0.092144, acc 0.984375
2020-02-08T03:06:08.698574: step 1611, loss 0.206628, acc 0.953125
2020-02-08T03:06:08.816389: step 1612, loss 0.113705, acc 0.96875
2020-02-08T03:06:08.932510: step 1613, loss 0.279996, acc 0.890625
2020-02-08T03:06:09.048948: step 1614, loss 0.219613, acc 0.875
2020-02-08T03:06:09.165906: step 1615, loss 0.190711, acc 0.921875
2020-02-08T03:06:09.280898: step 1616, loss 0.140448, acc 0.953125
2020-02-08T03:06:09.398192: step 1617, loss 0.287343, acc 0.84375
2020-02-08T03:06:09.513891: step 1618, loss 0.176123, acc 0.921875
2020-02-08T03:06:09.629174: step 1619, loss 0.0883926, acc 0.984375
2020-02-08T03:06:09.747652: step 1620, loss 0.115961, acc 0.984375
2020-02-08T03:06:09.862998: step 1621, loss 0.0925361, acc 1
2020-02-08T03:06:09.978221: step 1622, loss 0.10355, acc 0.96875
2020-02-08T03:06:10.090833: step 1623, loss 0.133726, acc 0.96875
2020-02-08T03:06:10.206214: step 1624, loss 0.116513, acc 0.9375
2020-02-08T03:06:10.323677: step 1625, loss 0.0817425, acc 0.96875
2020-02-08T03:06:10.439977: step 1626, loss 0.14978, acc 0.90625
2020-02-08T03:06:10.554931: step 1627, loss 0.174929, acc 0.96875
2020-02-08T03:06:10.672265: step 1628, loss 0.134186, acc 0.9375
2020-02-08T03:06:10.787471: step 1629, loss 0.0956525, acc 0.96875
2020-02-08T03:06:10.902858: step 1630, loss 0.215982, acc 0.90625
2020-02-08T03:06:11.018663: step 1631, loss 0.147122, acc 0.953125
2020-02-08T03:06:11.134550: step 1632, loss 0.157112, acc 0.953125
2020-02-08T03:06:11.247981: step 1633, loss 0.150215, acc 0.953125
2020-02-08T03:06:11.362489: step 1634, loss 0.230334, acc 0.859375
2020-02-08T03:06:11.479727: step 1635, loss 0.134157, acc 0.921875
2020-02-08T03:06:11.596814: step 1636, loss 0.221135, acc 0.890625
2020-02-08T03:06:11.714750: step 1637, loss 0.206527, acc 0.90625
2020-02-08T03:06:11.833012: step 1638, loss 0.188853, acc 0.953125
2020-02-08T03:06:11.951538: step 1639, loss 0.228208, acc 0.9375
2020-02-08T03:06:12.068312: step 1640, loss 0.138393, acc 0.953125
2020-02-08T03:06:12.185881: step 1641, loss 0.16321, acc 0.921875
2020-02-08T03:06:12.301534: step 1642, loss 0.287753, acc 0.90625
2020-02-08T03:06:12.420511: step 1643, loss 0.168474, acc 0.953125
2020-02-08T03:06:12.537107: step 1644, loss 0.170919, acc 0.9375
2020-02-08T03:06:12.650523: step 1645, loss 0.196722, acc 0.90625
2020-02-08T03:06:12.767819: step 1646, loss 0.108651, acc 0.96875
2020-02-08T03:06:12.884937: step 1647, loss 0.188559, acc 0.9375
2020-02-08T03:06:13.001433: step 1648, loss 0.152624, acc 0.953125
2020-02-08T03:06:13.118999: step 1649, loss 0.267606, acc 0.90625
2020-02-08T03:06:13.231387: step 1650, loss 0.153399, acc 0.9
2020-02-08T03:06:13.350572: step 1651, loss 0.140186, acc 0.953125
2020-02-08T03:06:13.468605: step 1652, loss 0.107863, acc 0.984375
2020-02-08T03:06:13.584027: step 1653, loss 0.0922271, acc 0.96875
2020-02-08T03:06:13.700911: step 1654, loss 0.0907018, acc 0.984375
2020-02-08T03:06:13.817636: step 1655, loss 0.162882, acc 0.9375
2020-02-08T03:06:13.933543: step 1656, loss 0.128194, acc 0.96875
2020-02-08T03:06:14.050629: step 1657, loss 0.0895889, acc 0.96875
2020-02-08T03:06:14.164750: step 1658, loss 0.0894728, acc 0.9375
2020-02-08T03:06:14.279740: step 1659, loss 0.0684978, acc 0.984375
2020-02-08T03:06:14.394045: step 1660, loss 0.0591498, acc 1
2020-02-08T03:06:14.511140: step 1661, loss 0.0782575, acc 0.984375
2020-02-08T03:06:14.629032: step 1662, loss 0.135142, acc 0.953125
2020-02-08T03:06:14.744305: step 1663, loss 0.0871633, acc 0.96875
2020-02-08T03:06:14.860672: step 1664, loss 0.105718, acc 0.9375
2020-02-08T03:06:14.978231: step 1665, loss 0.094824, acc 0.96875
2020-02-08T03:06:15.093940: step 1666, loss 0.131161, acc 0.96875
2020-02-08T03:06:15.210902: step 1667, loss 0.130952, acc 0.921875
2020-02-08T03:06:15.326400: step 1668, loss 0.152192, acc 0.921875
2020-02-08T03:06:15.443430: step 1669, loss 0.0769765, acc 0.984375
2020-02-08T03:06:15.559598: step 1670, loss 0.176044, acc 0.953125
2020-02-08T03:06:15.675383: step 1671, loss 0.10834, acc 0.9375
2020-02-08T03:06:15.794388: step 1672, loss 0.099658, acc 0.96875
2020-02-08T03:06:15.909747: step 1673, loss 0.109756, acc 0.96875
2020-02-08T03:06:16.025870: step 1674, loss 0.0798553, acc 0.96875
2020-02-08T03:06:16.145948: step 1675, loss 0.135486, acc 0.9375
2020-02-08T03:06:16.262215: step 1676, loss 0.157801, acc 0.953125
2020-02-08T03:06:16.377156: step 1677, loss 0.130205, acc 0.953125
2020-02-08T03:06:16.494399: step 1678, loss 0.101244, acc 0.96875
2020-02-08T03:06:16.613379: step 1679, loss 0.109144, acc 0.96875
2020-02-08T03:06:16.730127: step 1680, loss 0.175195, acc 0.90625
2020-02-08T03:06:16.846244: step 1681, loss 0.0952757, acc 0.96875
2020-02-08T03:06:16.964370: step 1682, loss 0.153326, acc 0.9375
2020-02-08T03:06:17.080543: step 1683, loss 0.086353, acc 0.953125
2020-02-08T03:06:17.196135: step 1684, loss 0.129257, acc 0.9375
2020-02-08T03:06:17.313225: step 1685, loss 0.1481, acc 0.96875
2020-02-08T03:06:17.430054: step 1686, loss 0.19367, acc 0.890625
2020-02-08T03:06:17.547131: step 1687, loss 0.0547397, acc 1
2020-02-08T03:06:17.663620: step 1688, loss 0.132863, acc 0.953125
2020-02-08T03:06:17.779207: step 1689, loss 0.202164, acc 0.921875
2020-02-08T03:06:17.895268: step 1690, loss 0.120581, acc 0.96875
2020-02-08T03:06:18.009859: step 1691, loss 0.0981175, acc 0.9375
2020-02-08T03:06:18.125562: step 1692, loss 0.173751, acc 0.9375
2020-02-08T03:06:18.243221: step 1693, loss 0.164171, acc 0.9375
2020-02-08T03:06:18.357748: step 1694, loss 0.0919962, acc 0.984375
2020-02-08T03:06:18.473939: step 1695, loss 0.0728857, acc 0.984375
2020-02-08T03:06:18.590166: step 1696, loss 0.137711, acc 0.90625
2020-02-08T03:06:18.707928: step 1697, loss 0.0909626, acc 0.96875
2020-02-08T03:06:18.823402: step 1698, loss 0.187315, acc 0.921875
2020-02-08T03:06:18.939617: step 1699, loss 0.142728, acc 0.953125
2020-02-08T03:06:19.056748: step 1700, loss 0.143418, acc 0.953125

Evaluation:
2020-02-08T03:06:19.248334: step 1700, loss 0.700602, acc 0.705441

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1700

2020-02-08T03:06:20.953057: step 1701, loss 0.161086, acc 0.9375
2020-02-08T03:06:21.070680: step 1702, loss 0.102344, acc 0.984375
2020-02-08T03:06:21.187768: step 1703, loss 0.288056, acc 0.921875
2020-02-08T03:06:21.303627: step 1704, loss 0.129959, acc 0.9375
2020-02-08T03:06:21.417083: step 1705, loss 0.188275, acc 0.90625
2020-02-08T03:06:21.634471: step 1706, loss 0.0556012, acc 0.984375
2020-02-08T03:06:21.757753: step 1707, loss 0.112032, acc 0.953125
2020-02-08T03:06:21.872382: step 1708, loss 0.09244, acc 0.953125
2020-02-08T03:06:21.991948: step 1709, loss 0.0758516, acc 0.96875
2020-02-08T03:06:22.108388: step 1710, loss 0.132236, acc 0.9375
2020-02-08T03:06:22.225549: step 1711, loss 0.0945481, acc 0.96875
2020-02-08T03:06:22.340993: step 1712, loss 0.0639823, acc 0.984375
2020-02-08T03:06:22.458615: step 1713, loss 0.0706799, acc 0.984375
2020-02-08T03:06:22.575535: step 1714, loss 0.169504, acc 0.890625
2020-02-08T03:06:22.694457: step 1715, loss 0.0893591, acc 0.953125
2020-02-08T03:06:22.813434: step 1716, loss 0.180297, acc 0.96875
2020-02-08T03:06:22.931974: step 1717, loss 0.150892, acc 0.953125
2020-02-08T03:06:23.048049: step 1718, loss 0.19117, acc 0.90625
2020-02-08T03:06:23.167711: step 1719, loss 0.149051, acc 0.90625
2020-02-08T03:06:23.284056: step 1720, loss 0.0908536, acc 0.96875
2020-02-08T03:06:23.399511: step 1721, loss 0.0944102, acc 0.96875
2020-02-08T03:06:23.517139: step 1722, loss 0.224439, acc 0.859375
2020-02-08T03:06:23.634248: step 1723, loss 0.193713, acc 0.953125
2020-02-08T03:06:23.747930: step 1724, loss 0.143119, acc 0.9375
2020-02-08T03:06:23.866361: step 1725, loss 0.182347, acc 0.90625
2020-02-08T03:06:23.984838: step 1726, loss 0.176874, acc 0.90625
2020-02-08T03:06:24.098814: step 1727, loss 0.186952, acc 0.921875
2020-02-08T03:06:24.214599: step 1728, loss 0.0897155, acc 0.96875
2020-02-08T03:06:24.332457: step 1729, loss 0.174856, acc 0.953125
2020-02-08T03:06:24.447153: step 1730, loss 0.174239, acc 0.90625
2020-02-08T03:06:24.563911: step 1731, loss 0.135811, acc 0.9375
2020-02-08T03:06:24.680847: step 1732, loss 0.148647, acc 0.921875
2020-02-08T03:06:24.795652: step 1733, loss 0.124659, acc 0.953125
2020-02-08T03:06:24.911103: step 1734, loss 0.167965, acc 0.9375
2020-02-08T03:06:25.028106: step 1735, loss 0.145637, acc 0.953125
2020-02-08T03:06:25.141466: step 1736, loss 0.126071, acc 0.9375
2020-02-08T03:06:25.258933: step 1737, loss 0.0970897, acc 0.953125
2020-02-08T03:06:25.376838: step 1738, loss 0.12179, acc 0.96875
2020-02-08T03:06:25.494311: step 1739, loss 0.130728, acc 0.953125
2020-02-08T03:06:25.613529: step 1740, loss 0.179073, acc 0.9375
2020-02-08T03:06:25.732842: step 1741, loss 0.159759, acc 0.921875
2020-02-08T03:06:25.849419: step 1742, loss 0.16253, acc 0.9375
2020-02-08T03:06:25.969363: step 1743, loss 0.213832, acc 0.9375
2020-02-08T03:06:26.086343: step 1744, loss 0.102145, acc 0.96875
2020-02-08T03:06:26.203499: step 1745, loss 0.0427386, acc 1
2020-02-08T03:06:26.319077: step 1746, loss 0.194946, acc 0.96875
2020-02-08T03:06:26.437286: step 1747, loss 0.139419, acc 0.9375
2020-02-08T03:06:26.553699: step 1748, loss 0.191812, acc 0.921875
2020-02-08T03:06:26.671700: step 1749, loss 0.141407, acc 0.90625
2020-02-08T03:06:26.788241: step 1750, loss 0.118567, acc 0.953125
2020-02-08T03:06:26.904369: step 1751, loss 0.140896, acc 0.96875
2020-02-08T03:06:27.023947: step 1752, loss 0.0809239, acc 0.96875
2020-02-08T03:06:27.140682: step 1753, loss 0.112946, acc 0.984375
2020-02-08T03:06:27.261386: step 1754, loss 0.0644299, acc 1
2020-02-08T03:06:27.379462: step 1755, loss 0.0963461, acc 0.96875
2020-02-08T03:06:27.494246: step 1756, loss 0.216309, acc 0.890625
2020-02-08T03:06:27.616043: step 1757, loss 0.0614977, acc 1
2020-02-08T03:06:27.733950: step 1758, loss 0.0607036, acc 1
2020-02-08T03:06:27.850857: step 1759, loss 0.149927, acc 0.9375
2020-02-08T03:06:27.969600: step 1760, loss 0.0895487, acc 0.96875
2020-02-08T03:06:28.087568: step 1761, loss 0.19178, acc 0.921875
2020-02-08T03:06:28.204863: step 1762, loss 0.10049, acc 0.984375
2020-02-08T03:06:28.324380: step 1763, loss 0.188147, acc 0.90625
2020-02-08T03:06:28.438694: step 1764, loss 0.168891, acc 0.921875
2020-02-08T03:06:28.556903: step 1765, loss 0.0953184, acc 0.96875
2020-02-08T03:06:28.675996: step 1766, loss 0.0550693, acc 0.984375
2020-02-08T03:06:28.790284: step 1767, loss 0.132768, acc 0.953125
2020-02-08T03:06:28.907729: step 1768, loss 0.112049, acc 0.9375
2020-02-08T03:06:29.024700: step 1769, loss 0.154215, acc 0.921875
2020-02-08T03:06:29.142132: step 1770, loss 0.104829, acc 0.953125
2020-02-08T03:06:29.265074: step 1771, loss 0.22385, acc 0.921875
2020-02-08T03:06:29.383674: step 1772, loss 0.166765, acc 0.9375
2020-02-08T03:06:29.503535: step 1773, loss 0.0805444, acc 0.96875
2020-02-08T03:06:29.621626: step 1774, loss 0.0969743, acc 0.96875
2020-02-08T03:06:29.736217: step 1775, loss 0.223167, acc 0.90625
2020-02-08T03:06:29.857481: step 1776, loss 0.130429, acc 0.953125
2020-02-08T03:06:29.973535: step 1777, loss 0.117981, acc 0.953125
2020-02-08T03:06:30.088213: step 1778, loss 0.260636, acc 0.953125
2020-02-08T03:06:30.203674: step 1779, loss 0.188552, acc 0.90625
2020-02-08T03:06:30.320885: step 1780, loss 0.129006, acc 0.953125
2020-02-08T03:06:30.437756: step 1781, loss 0.0920176, acc 0.96875
2020-02-08T03:06:30.552067: step 1782, loss 0.128453, acc 0.96875
2020-02-08T03:06:30.668817: step 1783, loss 0.12717, acc 0.9375
2020-02-08T03:06:30.782760: step 1784, loss 0.0729116, acc 0.984375
2020-02-08T03:06:30.900765: step 1785, loss 0.191058, acc 0.9375
2020-02-08T03:06:31.018574: step 1786, loss 0.0766506, acc 1
2020-02-08T03:06:31.137369: step 1787, loss 0.177775, acc 0.9375
2020-02-08T03:06:31.251257: step 1788, loss 0.109821, acc 0.953125
2020-02-08T03:06:31.368644: step 1789, loss 0.178014, acc 0.921875
2020-02-08T03:06:31.483166: step 1790, loss 0.058806, acc 1
2020-02-08T03:06:31.599892: step 1791, loss 0.0579355, acc 0.984375
2020-02-08T03:06:31.718878: step 1792, loss 0.0743053, acc 0.984375
2020-02-08T03:06:31.838952: step 1793, loss 0.0945757, acc 0.984375
2020-02-08T03:06:31.954563: step 1794, loss 0.210561, acc 0.890625
2020-02-08T03:06:32.070201: step 1795, loss 0.183458, acc 0.953125
2020-02-08T03:06:32.185726: step 1796, loss 0.155354, acc 0.921875
2020-02-08T03:06:32.302710: step 1797, loss 0.0868205, acc 0.96875
2020-02-08T03:06:32.419397: step 1798, loss 0.0997785, acc 0.953125
2020-02-08T03:06:32.535216: step 1799, loss 0.082625, acc 0.96875
2020-02-08T03:06:32.645793: step 1800, loss 0.115805, acc 0.95

Evaluation:
2020-02-08T03:06:32.832999: step 1800, loss 0.651266, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1800

2020-02-08T03:06:34.964490: step 1801, loss 0.126715, acc 0.921875
2020-02-08T03:06:35.081779: step 1802, loss 0.066135, acc 0.984375
2020-02-08T03:06:35.200690: step 1803, loss 0.0707398, acc 0.984375
2020-02-08T03:06:35.319060: step 1804, loss 0.0384224, acc 1
2020-02-08T03:06:35.437194: step 1805, loss 0.119275, acc 0.953125
2020-02-08T03:06:35.553062: step 1806, loss 0.0814718, acc 0.984375
2020-02-08T03:06:35.670143: step 1807, loss 0.059446, acc 0.96875
2020-02-08T03:06:35.788208: step 1808, loss 0.126931, acc 0.9375
2020-02-08T03:06:35.904774: step 1809, loss 0.157116, acc 0.953125
2020-02-08T03:06:36.022642: step 1810, loss 0.155502, acc 0.96875
2020-02-08T03:06:36.137602: step 1811, loss 0.0880474, acc 0.953125
2020-02-08T03:06:36.256372: step 1812, loss 0.051711, acc 1
2020-02-08T03:06:36.378906: step 1813, loss 0.106264, acc 0.96875
2020-02-08T03:06:36.495094: step 1814, loss 0.0442576, acc 1
2020-02-08T03:06:36.614186: step 1815, loss 0.0723842, acc 0.984375
2020-02-08T03:06:36.731403: step 1816, loss 0.179207, acc 0.9375
2020-02-08T03:06:36.844780: step 1817, loss 0.0827429, acc 0.984375
2020-02-08T03:06:36.962493: step 1818, loss 0.0696982, acc 1
2020-02-08T03:06:37.079955: step 1819, loss 0.140529, acc 0.96875
2020-02-08T03:06:37.194754: step 1820, loss 0.0601979, acc 0.984375
2020-02-08T03:06:37.316189: step 1821, loss 0.0803478, acc 0.96875
2020-02-08T03:06:37.433326: step 1822, loss 0.0813762, acc 0.96875
2020-02-08T03:06:37.551527: step 1823, loss 0.10745, acc 0.96875
2020-02-08T03:06:37.672261: step 1824, loss 0.032471, acc 1
2020-02-08T03:06:37.788695: step 1825, loss 0.111364, acc 0.9375
2020-02-08T03:06:37.904929: step 1826, loss 0.055348, acc 0.984375
2020-02-08T03:06:38.025290: step 1827, loss 0.0654529, acc 0.984375
2020-02-08T03:06:38.142146: step 1828, loss 0.042438, acc 0.984375
2020-02-08T03:06:38.263989: step 1829, loss 0.151726, acc 0.90625
2020-02-08T03:06:38.379654: step 1830, loss 0.0880565, acc 0.96875
2020-02-08T03:06:38.495116: step 1831, loss 0.087311, acc 0.984375
2020-02-08T03:06:38.614654: step 1832, loss 0.046423, acc 0.984375
2020-02-08T03:06:38.735398: step 1833, loss 0.117647, acc 0.96875
2020-02-08T03:06:38.852123: step 1834, loss 0.214454, acc 0.921875
2020-02-08T03:06:38.967420: step 1835, loss 0.049317, acc 0.984375
2020-02-08T03:06:39.086190: step 1836, loss 0.119824, acc 0.953125
2020-02-08T03:06:39.204166: step 1837, loss 0.101165, acc 0.96875
2020-02-08T03:06:39.324878: step 1838, loss 0.22685, acc 0.875
2020-02-08T03:06:39.443118: step 1839, loss 0.0820421, acc 1
2020-02-08T03:06:39.564665: step 1840, loss 0.104247, acc 0.953125
2020-02-08T03:06:39.685124: step 1841, loss 0.21682, acc 0.9375
2020-02-08T03:06:39.803089: step 1842, loss 0.126432, acc 0.984375
2020-02-08T03:06:39.925615: step 1843, loss 0.124043, acc 0.953125
2020-02-08T03:06:40.041417: step 1844, loss 0.0552972, acc 1
2020-02-08T03:06:40.160193: step 1845, loss 0.120155, acc 0.96875
2020-02-08T03:06:40.277154: step 1846, loss 0.101691, acc 0.953125
2020-02-08T03:06:40.391836: step 1847, loss 0.0757952, acc 0.96875
2020-02-08T03:06:40.510364: step 1848, loss 0.085766, acc 0.96875
2020-02-08T03:06:40.626591: step 1849, loss 0.184175, acc 0.90625
2020-02-08T03:06:40.741617: step 1850, loss 0.0908656, acc 0.96875
2020-02-08T03:06:40.860576: step 1851, loss 0.123544, acc 0.9375
2020-02-08T03:06:40.977030: step 1852, loss 0.166941, acc 0.953125
2020-02-08T03:06:41.093911: step 1853, loss 0.211089, acc 0.953125
2020-02-08T03:06:41.212544: step 1854, loss 0.0663136, acc 0.984375
2020-02-08T03:06:41.329951: step 1855, loss 0.145108, acc 0.921875
2020-02-08T03:06:41.445333: step 1856, loss 0.129236, acc 0.9375
2020-02-08T03:06:41.562211: step 1857, loss 0.133046, acc 0.953125
2020-02-08T03:06:41.678218: step 1858, loss 0.089977, acc 0.984375
2020-02-08T03:06:41.790819: step 1859, loss 0.120519, acc 0.9375
2020-02-08T03:06:41.906665: step 1860, loss 0.101139, acc 0.96875
2020-02-08T03:06:42.022121: step 1861, loss 0.0338683, acc 1
2020-02-08T03:06:42.137735: step 1862, loss 0.0673022, acc 0.984375
2020-02-08T03:06:42.252583: step 1863, loss 0.158233, acc 0.953125
2020-02-08T03:06:42.370263: step 1864, loss 0.0739324, acc 0.984375
2020-02-08T03:06:42.485672: step 1865, loss 0.123785, acc 0.9375
2020-02-08T03:06:42.599924: step 1866, loss 0.0723463, acc 0.984375
2020-02-08T03:06:42.716299: step 1867, loss 0.0585804, acc 0.984375
2020-02-08T03:06:42.834359: step 1868, loss 0.0922994, acc 0.984375
2020-02-08T03:06:42.950444: step 1869, loss 0.05242, acc 1
2020-02-08T03:06:43.068315: step 1870, loss 0.0859303, acc 0.96875
2020-02-08T03:06:43.185090: step 1871, loss 0.141007, acc 0.953125
2020-02-08T03:06:43.298768: step 1872, loss 0.0936788, acc 0.96875
2020-02-08T03:06:43.417868: step 1873, loss 0.178471, acc 0.9375
2020-02-08T03:06:43.532112: step 1874, loss 0.113262, acc 0.984375
2020-02-08T03:06:43.647621: step 1875, loss 0.11486, acc 0.96875
2020-02-08T03:06:43.765721: step 1876, loss 0.107528, acc 0.953125
2020-02-08T03:06:43.882291: step 1877, loss 0.119207, acc 0.953125
2020-02-08T03:06:43.998853: step 1878, loss 0.153092, acc 0.953125
2020-02-08T03:06:44.117107: step 1879, loss 0.0895089, acc 0.984375
2020-02-08T03:06:44.236663: step 1880, loss 0.0824718, acc 0.984375
2020-02-08T03:06:44.352246: step 1881, loss 0.0563835, acc 1
2020-02-08T03:06:44.471571: step 1882, loss 0.0563588, acc 0.984375
2020-02-08T03:06:44.588122: step 1883, loss 0.0879292, acc 0.96875
2020-02-08T03:06:44.704144: step 1884, loss 0.0951191, acc 0.96875
2020-02-08T03:06:44.820704: step 1885, loss 0.0734607, acc 0.96875
2020-02-08T03:06:44.937211: step 1886, loss 0.0597073, acc 0.984375
2020-02-08T03:06:45.054884: step 1887, loss 0.0503936, acc 1
2020-02-08T03:06:45.170625: step 1888, loss 0.0927521, acc 0.96875
2020-02-08T03:06:45.286074: step 1889, loss 0.120749, acc 0.96875
2020-02-08T03:06:45.403672: step 1890, loss 0.0664468, acc 0.984375
2020-02-08T03:06:45.521397: step 1891, loss 0.0465992, acc 1
2020-02-08T03:06:45.637758: step 1892, loss 0.0764209, acc 0.96875
2020-02-08T03:06:45.754018: step 1893, loss 0.092253, acc 0.9375
2020-02-08T03:06:45.873056: step 1894, loss 0.0566335, acc 0.984375
2020-02-08T03:06:45.989578: step 1895, loss 0.131171, acc 0.9375
2020-02-08T03:06:46.106302: step 1896, loss 0.115262, acc 0.96875
2020-02-08T03:06:46.224195: step 1897, loss 0.0366718, acc 1
2020-02-08T03:06:46.339947: step 1898, loss 0.134466, acc 0.96875
2020-02-08T03:06:46.457368: step 1899, loss 0.155654, acc 0.921875
2020-02-08T03:06:46.574128: step 1900, loss 0.0592833, acc 0.984375

Evaluation:
2020-02-08T03:06:46.764507: step 1900, loss 0.685814, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-1900

2020-02-08T03:06:48.297717: step 1901, loss 0.0784613, acc 0.96875
2020-02-08T03:06:48.415774: step 1902, loss 0.0540055, acc 0.984375
2020-02-08T03:06:48.532485: step 1903, loss 0.1284, acc 0.953125
2020-02-08T03:06:48.647983: step 1904, loss 0.0596651, acc 0.984375
2020-02-08T03:06:48.766501: step 1905, loss 0.170504, acc 0.921875
2020-02-08T03:06:48.881655: step 1906, loss 0.0785814, acc 0.984375
2020-02-08T03:06:48.994295: step 1907, loss 0.10012, acc 0.96875
2020-02-08T03:06:49.111046: step 1908, loss 0.086102, acc 0.953125
2020-02-08T03:06:49.232289: step 1909, loss 0.0992044, acc 0.984375
2020-02-08T03:06:49.349927: step 1910, loss 0.0665249, acc 0.96875
2020-02-08T03:06:49.468225: step 1911, loss 0.089102, acc 0.984375
2020-02-08T03:06:49.583214: step 1912, loss 0.0874722, acc 0.96875
2020-02-08T03:06:49.699446: step 1913, loss 0.0844203, acc 0.96875
2020-02-08T03:06:49.816102: step 1914, loss 0.0531369, acc 0.984375
2020-02-08T03:06:49.934194: step 1915, loss 0.0894509, acc 0.96875
2020-02-08T03:06:50.051029: step 1916, loss 0.0510393, acc 0.984375
2020-02-08T03:06:50.166738: step 1917, loss 0.0691942, acc 1
2020-02-08T03:06:50.282590: step 1918, loss 0.146841, acc 0.921875
2020-02-08T03:06:50.398323: step 1919, loss 0.0810356, acc 0.984375
2020-02-08T03:06:50.516733: step 1920, loss 0.136211, acc 0.953125
2020-02-08T03:06:50.634325: step 1921, loss 0.0770709, acc 0.96875
2020-02-08T03:06:50.753737: step 1922, loss 0.106542, acc 0.96875
2020-02-08T03:06:50.869839: step 1923, loss 0.0910863, acc 0.96875
2020-02-08T03:06:50.986615: step 1924, loss 0.0822661, acc 0.96875
2020-02-08T03:06:51.104177: step 1925, loss 0.187268, acc 0.921875
2020-02-08T03:06:51.218128: step 1926, loss 0.0739513, acc 0.96875
2020-02-08T03:06:51.333116: step 1927, loss 0.13426, acc 0.9375
2020-02-08T03:06:51.447156: step 1928, loss 0.136135, acc 0.96875
2020-02-08T03:06:51.592886: step 1929, loss 0.0638306, acc 0.984375
2020-02-08T03:06:51.715300: step 1930, loss 0.159499, acc 0.953125
2020-02-08T03:06:51.833384: step 1931, loss 0.0973449, acc 0.953125
2020-02-08T03:06:51.946633: step 1932, loss 0.0814056, acc 0.96875
2020-02-08T03:06:52.064416: step 1933, loss 0.122164, acc 0.9375
2020-02-08T03:06:52.181301: step 1934, loss 0.140091, acc 0.953125
2020-02-08T03:06:52.297112: step 1935, loss 0.122542, acc 0.953125
2020-02-08T03:06:52.413145: step 1936, loss 0.0995368, acc 0.953125
2020-02-08T03:06:52.531803: step 1937, loss 0.106473, acc 0.984375
2020-02-08T03:06:52.648552: step 1938, loss 0.0970989, acc 0.96875
2020-02-08T03:06:52.766689: step 1939, loss 0.0422088, acc 1
2020-02-08T03:06:52.881951: step 1940, loss 0.122033, acc 0.953125
2020-02-08T03:06:52.999937: step 1941, loss 0.0932813, acc 0.953125
2020-02-08T03:06:53.119831: step 1942, loss 0.0555453, acc 0.96875
2020-02-08T03:06:53.236050: step 1943, loss 0.116572, acc 0.96875
2020-02-08T03:06:53.351067: step 1944, loss 0.126334, acc 0.90625
2020-02-08T03:06:53.465985: step 1945, loss 0.0464695, acc 1
2020-02-08T03:06:53.582693: step 1946, loss 0.229667, acc 0.890625
2020-02-08T03:06:53.697487: step 1947, loss 0.183574, acc 0.9375
2020-02-08T03:06:53.813959: step 1948, loss 0.16548, acc 0.96875
2020-02-08T03:06:53.932196: step 1949, loss 0.12736, acc 0.953125
2020-02-08T03:06:54.045110: step 1950, loss 0.0974384, acc 0.966667
2020-02-08T03:06:54.164196: step 1951, loss 0.0740131, acc 0.984375
2020-02-08T03:06:54.281761: step 1952, loss 0.0791967, acc 0.984375
2020-02-08T03:06:54.395394: step 1953, loss 0.0342471, acc 1
2020-02-08T03:06:54.513071: step 1954, loss 0.0829453, acc 0.953125
2020-02-08T03:06:54.630114: step 1955, loss 0.0902816, acc 0.984375
2020-02-08T03:06:54.746515: step 1956, loss 0.0825141, acc 0.984375
2020-02-08T03:06:54.863581: step 1957, loss 0.0493953, acc 0.96875
2020-02-08T03:06:54.980561: step 1958, loss 0.117281, acc 0.953125
2020-02-08T03:06:55.094825: step 1959, loss 0.0459407, acc 0.984375
2020-02-08T03:06:55.211685: step 1960, loss 0.0697657, acc 0.96875
2020-02-08T03:06:55.330488: step 1961, loss 0.0887486, acc 0.953125
2020-02-08T03:06:55.449237: step 1962, loss 0.0784122, acc 0.96875
2020-02-08T03:06:55.570295: step 1963, loss 0.026093, acc 0.984375
2020-02-08T03:06:55.684797: step 1964, loss 0.0492714, acc 0.984375
2020-02-08T03:06:55.802680: step 1965, loss 0.0746119, acc 0.984375
2020-02-08T03:06:55.920936: step 1966, loss 0.0537334, acc 0.984375
2020-02-08T03:06:56.038163: step 1967, loss 0.0297479, acc 1
2020-02-08T03:06:56.156460: step 1968, loss 0.0585279, acc 1
2020-02-08T03:06:56.272734: step 1969, loss 0.0946331, acc 0.96875
2020-02-08T03:06:56.387867: step 1970, loss 0.0766735, acc 0.96875
2020-02-08T03:06:56.503785: step 1971, loss 0.0701408, acc 0.984375
2020-02-08T03:06:56.618660: step 1972, loss 0.0487663, acc 1
2020-02-08T03:06:56.731850: step 1973, loss 0.106741, acc 0.953125
2020-02-08T03:06:56.848889: step 1974, loss 0.0258897, acc 1
2020-02-08T03:06:56.965192: step 1975, loss 0.11796, acc 0.9375
2020-02-08T03:06:57.081154: step 1976, loss 0.148822, acc 0.953125
2020-02-08T03:06:57.197613: step 1977, loss 0.0818986, acc 0.984375
2020-02-08T03:06:57.313726: step 1978, loss 0.0233523, acc 1
2020-02-08T03:06:57.431368: step 1979, loss 0.0770045, acc 0.984375
2020-02-08T03:06:57.546880: step 1980, loss 0.0771702, acc 0.96875
2020-02-08T03:06:57.660928: step 1981, loss 0.0452145, acc 1
2020-02-08T03:06:57.777334: step 1982, loss 0.0647801, acc 0.984375
2020-02-08T03:06:57.893906: step 1983, loss 0.0988941, acc 0.953125
2020-02-08T03:06:58.008188: step 1984, loss 0.172409, acc 0.96875
2020-02-08T03:06:58.123117: step 1985, loss 0.0519248, acc 0.984375
2020-02-08T03:06:58.238099: step 1986, loss 0.0806572, acc 0.96875
2020-02-08T03:06:58.352996: step 1987, loss 0.0907872, acc 0.96875
2020-02-08T03:06:58.470483: step 1988, loss 0.148444, acc 0.953125
2020-02-08T03:06:58.584495: step 1989, loss 0.133146, acc 0.953125
2020-02-08T03:06:58.701695: step 1990, loss 0.069083, acc 0.984375
2020-02-08T03:06:58.819928: step 1991, loss 0.0987509, acc 0.953125
2020-02-08T03:06:58.934927: step 1992, loss 0.0528154, acc 0.984375
2020-02-08T03:06:59.051532: step 1993, loss 0.0957127, acc 0.953125
2020-02-08T03:06:59.169503: step 1994, loss 0.0418332, acc 0.984375
2020-02-08T03:06:59.287504: step 1995, loss 0.0461862, acc 0.984375
2020-02-08T03:06:59.403033: step 1996, loss 0.106111, acc 0.9375
2020-02-08T03:06:59.520001: step 1997, loss 0.0293117, acc 1
2020-02-08T03:06:59.635633: step 1998, loss 0.0975522, acc 0.96875
2020-02-08T03:06:59.750375: step 1999, loss 0.0420045, acc 0.984375
2020-02-08T03:06:59.867285: step 2000, loss 0.112534, acc 0.953125

Evaluation:
2020-02-08T03:07:00.058333: step 2000, loss 0.736672, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2000

2020-02-08T03:07:01.574495: step 2001, loss 0.0419334, acc 0.984375
2020-02-08T03:07:01.689517: step 2002, loss 0.0549735, acc 0.984375
2020-02-08T03:07:01.807981: step 2003, loss 0.0451135, acc 0.984375
2020-02-08T03:07:01.927001: step 2004, loss 0.0694875, acc 0.96875
2020-02-08T03:07:02.040492: step 2005, loss 0.0550552, acc 0.984375
2020-02-08T03:07:02.158853: step 2006, loss 0.0540867, acc 0.96875
2020-02-08T03:07:02.275474: step 2007, loss 0.152989, acc 0.96875
2020-02-08T03:07:02.391240: step 2008, loss 0.096982, acc 0.953125
2020-02-08T03:07:02.506073: step 2009, loss 0.106716, acc 0.953125
2020-02-08T03:07:02.623705: step 2010, loss 0.030674, acc 1
2020-02-08T03:07:02.738390: step 2011, loss 0.0331245, acc 1
2020-02-08T03:07:02.853500: step 2012, loss 0.0655376, acc 0.96875
2020-02-08T03:07:02.971007: step 2013, loss 0.0264581, acc 1
2020-02-08T03:07:03.087766: step 2014, loss 0.150361, acc 0.9375
2020-02-08T03:07:03.201544: step 2015, loss 0.109205, acc 0.953125
2020-02-08T03:07:03.318083: step 2016, loss 0.067838, acc 0.984375
2020-02-08T03:07:03.435094: step 2017, loss 0.12749, acc 0.953125
2020-02-08T03:07:03.552555: step 2018, loss 0.0887489, acc 0.96875
2020-02-08T03:07:03.668746: step 2019, loss 0.101217, acc 0.96875
2020-02-08T03:07:03.785129: step 2020, loss 0.128262, acc 0.953125
2020-02-08T03:07:03.900105: step 2021, loss 0.0913058, acc 0.96875
2020-02-08T03:07:04.018580: step 2022, loss 0.0664982, acc 0.96875
2020-02-08T03:07:04.135763: step 2023, loss 0.146971, acc 0.953125
2020-02-08T03:07:04.252774: step 2024, loss 0.0895129, acc 0.96875
2020-02-08T03:07:04.373577: step 2025, loss 0.0983544, acc 0.953125
2020-02-08T03:07:04.490476: step 2026, loss 0.0645183, acc 0.96875
2020-02-08T03:07:04.606048: step 2027, loss 0.0702986, acc 0.96875
2020-02-08T03:07:04.722899: step 2028, loss 0.0480521, acc 1
2020-02-08T03:07:04.837757: step 2029, loss 0.0418901, acc 1
2020-02-08T03:07:04.953538: step 2030, loss 0.0620497, acc 0.984375
2020-02-08T03:07:05.070350: step 2031, loss 0.0801362, acc 0.96875
2020-02-08T03:07:05.186575: step 2032, loss 0.0895364, acc 0.96875
2020-02-08T03:07:05.301630: step 2033, loss 0.198886, acc 0.953125
2020-02-08T03:07:05.419397: step 2034, loss 0.0917764, acc 0.953125
2020-02-08T03:07:05.536629: step 2035, loss 0.163393, acc 0.953125
2020-02-08T03:07:05.653658: step 2036, loss 0.0649998, acc 0.984375
2020-02-08T03:07:05.772873: step 2037, loss 0.0729937, acc 0.984375
2020-02-08T03:07:05.889739: step 2038, loss 0.115971, acc 0.96875
2020-02-08T03:07:06.009500: step 2039, loss 0.0502363, acc 0.984375
2020-02-08T03:07:06.125126: step 2040, loss 0.0348786, acc 1
2020-02-08T03:07:06.239705: step 2041, loss 0.0495086, acc 0.984375
2020-02-08T03:07:06.356166: step 2042, loss 0.0703063, acc 0.96875
2020-02-08T03:07:06.473697: step 2043, loss 0.081665, acc 0.984375
2020-02-08T03:07:06.590550: step 2044, loss 0.0555786, acc 0.984375
2020-02-08T03:07:06.705549: step 2045, loss 0.0994811, acc 0.984375
2020-02-08T03:07:06.821528: step 2046, loss 0.0469112, acc 1
2020-02-08T03:07:06.936885: step 2047, loss 0.0736631, acc 0.96875
2020-02-08T03:07:07.051435: step 2048, loss 0.0696132, acc 0.984375
2020-02-08T03:07:07.166805: step 2049, loss 0.125053, acc 0.953125
2020-02-08T03:07:07.283706: step 2050, loss 0.212226, acc 0.90625
2020-02-08T03:07:07.398589: step 2051, loss 0.0403165, acc 0.984375
2020-02-08T03:07:07.521187: step 2052, loss 0.12864, acc 0.9375
2020-02-08T03:07:07.636521: step 2053, loss 0.0435783, acc 1
2020-02-08T03:07:07.753089: step 2054, loss 0.0493625, acc 0.984375
2020-02-08T03:07:07.873042: step 2055, loss 0.0480656, acc 0.984375
2020-02-08T03:07:07.987912: step 2056, loss 0.0863682, acc 0.96875
2020-02-08T03:07:08.101946: step 2057, loss 0.053664, acc 0.984375
2020-02-08T03:07:08.220271: step 2058, loss 0.0797375, acc 0.96875
2020-02-08T03:07:08.336056: step 2059, loss 0.0445182, acc 0.984375
2020-02-08T03:07:08.452111: step 2060, loss 0.0769829, acc 0.96875
2020-02-08T03:07:08.570452: step 2061, loss 0.0300699, acc 1
2020-02-08T03:07:08.686536: step 2062, loss 0.065234, acc 0.984375
2020-02-08T03:07:08.800140: step 2063, loss 0.0550531, acc 0.984375
2020-02-08T03:07:08.917851: step 2064, loss 0.0821532, acc 0.953125
2020-02-08T03:07:09.035045: step 2065, loss 0.0976312, acc 0.96875
2020-02-08T03:07:09.150406: step 2066, loss 0.0647698, acc 0.984375
2020-02-08T03:07:09.269239: step 2067, loss 0.12426, acc 0.9375
2020-02-08T03:07:09.386506: step 2068, loss 0.0963166, acc 0.96875
2020-02-08T03:07:09.502793: step 2069, loss 0.0864166, acc 0.984375
2020-02-08T03:07:09.621273: step 2070, loss 0.104457, acc 0.953125
2020-02-08T03:07:09.737553: step 2071, loss 0.0429087, acc 0.984375
2020-02-08T03:07:09.853401: step 2072, loss 0.15973, acc 0.921875
2020-02-08T03:07:09.969004: step 2073, loss 0.0947062, acc 0.96875
2020-02-08T03:07:10.083937: step 2074, loss 0.0912876, acc 0.96875
2020-02-08T03:07:10.203833: step 2075, loss 0.0456635, acc 0.984375
2020-02-08T03:07:10.319547: step 2076, loss 0.0772514, acc 0.96875
2020-02-08T03:07:10.436086: step 2077, loss 0.0410282, acc 0.984375
2020-02-08T03:07:10.554807: step 2078, loss 0.101957, acc 0.953125
2020-02-08T03:07:10.672122: step 2079, loss 0.0964528, acc 0.96875
2020-02-08T03:07:10.789321: step 2080, loss 0.071973, acc 0.96875
2020-02-08T03:07:10.904150: step 2081, loss 0.0972526, acc 0.953125
2020-02-08T03:07:11.019398: step 2082, loss 0.0993221, acc 0.9375
2020-02-08T03:07:11.135823: step 2083, loss 0.0686625, acc 0.96875
2020-02-08T03:07:11.249706: step 2084, loss 0.083025, acc 0.984375
2020-02-08T03:07:11.366645: step 2085, loss 0.10227, acc 0.953125
2020-02-08T03:07:11.482271: step 2086, loss 0.153584, acc 0.9375
2020-02-08T03:07:11.598335: step 2087, loss 0.124644, acc 0.96875
2020-02-08T03:07:11.718378: step 2088, loss 0.109408, acc 0.96875
2020-02-08T03:07:11.835588: step 2089, loss 0.0447348, acc 0.984375
2020-02-08T03:07:11.952921: step 2090, loss 0.075442, acc 0.984375
2020-02-08T03:07:12.067898: step 2091, loss 0.0507309, acc 0.984375
2020-02-08T03:07:12.183120: step 2092, loss 0.124421, acc 0.953125
2020-02-08T03:07:12.298609: step 2093, loss 0.0462826, acc 1
2020-02-08T03:07:12.416605: step 2094, loss 0.0909156, acc 0.953125
2020-02-08T03:07:12.534629: step 2095, loss 0.0886544, acc 0.96875
2020-02-08T03:07:12.652784: step 2096, loss 0.108581, acc 0.96875
2020-02-08T03:07:12.769477: step 2097, loss 0.0861025, acc 0.96875
2020-02-08T03:07:12.886082: step 2098, loss 0.0267045, acc 1
2020-02-08T03:07:13.000902: step 2099, loss 0.102865, acc 0.921875
2020-02-08T03:07:13.114314: step 2100, loss 0.0997897, acc 0.95

Evaluation:
2020-02-08T03:07:13.297983: step 2100, loss 0.762573, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2100

2020-02-08T03:07:15.523537: step 2101, loss 0.0617388, acc 0.96875
2020-02-08T03:07:15.639292: step 2102, loss 0.0720835, acc 0.984375
2020-02-08T03:07:15.755815: step 2103, loss 0.0384918, acc 0.984375
2020-02-08T03:07:15.875699: step 2104, loss 0.0931859, acc 0.96875
2020-02-08T03:07:15.990869: step 2105, loss 0.0774939, acc 0.953125
2020-02-08T03:07:16.107824: step 2106, loss 0.056271, acc 1
2020-02-08T03:07:16.223268: step 2107, loss 0.0645845, acc 0.984375
2020-02-08T03:07:16.338672: step 2108, loss 0.0512526, acc 1
2020-02-08T03:07:16.454405: step 2109, loss 0.0478126, acc 0.984375
2020-02-08T03:07:16.572437: step 2110, loss 0.0761194, acc 0.96875
2020-02-08T03:07:16.689643: step 2111, loss 0.038981, acc 1
2020-02-08T03:07:16.807700: step 2112, loss 0.0524684, acc 0.984375
2020-02-08T03:07:16.925928: step 2113, loss 0.0483695, acc 0.984375
2020-02-08T03:07:17.042561: step 2114, loss 0.0302504, acc 1
2020-02-08T03:07:17.161235: step 2115, loss 0.109172, acc 0.953125
2020-02-08T03:07:17.278102: step 2116, loss 0.0906804, acc 0.953125
2020-02-08T03:07:17.394013: step 2117, loss 0.080213, acc 0.984375
2020-02-08T03:07:17.512773: step 2118, loss 0.0958843, acc 0.953125
2020-02-08T03:07:17.631714: step 2119, loss 0.05083, acc 0.984375
2020-02-08T03:07:17.750442: step 2120, loss 0.0498053, acc 0.984375
2020-02-08T03:07:17.868292: step 2121, loss 0.0259988, acc 1
2020-02-08T03:07:17.984132: step 2122, loss 0.0252782, acc 1
2020-02-08T03:07:18.100936: step 2123, loss 0.0925481, acc 0.96875
2020-02-08T03:07:18.215707: step 2124, loss 0.0481884, acc 0.984375
2020-02-08T03:07:18.329240: step 2125, loss 0.0646096, acc 0.96875
2020-02-08T03:07:18.443693: step 2126, loss 0.0397454, acc 1
2020-02-08T03:07:18.560039: step 2127, loss 0.114615, acc 0.953125
2020-02-08T03:07:18.677206: step 2128, loss 0.0301128, acc 1
2020-02-08T03:07:18.791141: step 2129, loss 0.064703, acc 0.96875
2020-02-08T03:07:18.909286: step 2130, loss 0.108397, acc 0.96875
2020-02-08T03:07:19.027791: step 2131, loss 0.0728727, acc 0.96875
2020-02-08T03:07:19.144680: step 2132, loss 0.0244432, acc 1
2020-02-08T03:07:19.261954: step 2133, loss 0.0398984, acc 0.984375
2020-02-08T03:07:19.378544: step 2134, loss 0.0164058, acc 1
2020-02-08T03:07:19.491166: step 2135, loss 0.0767092, acc 0.96875
2020-02-08T03:07:19.607823: step 2136, loss 0.0784405, acc 0.984375
2020-02-08T03:07:19.727325: step 2137, loss 0.0637936, acc 0.984375
2020-02-08T03:07:19.844176: step 2138, loss 0.0850198, acc 0.953125
2020-02-08T03:07:19.962291: step 2139, loss 0.0356778, acc 0.984375
2020-02-08T03:07:20.078237: step 2140, loss 0.0559825, acc 0.984375
2020-02-08T03:07:20.193479: step 2141, loss 0.0527997, acc 0.984375
2020-02-08T03:07:20.309334: step 2142, loss 0.0226447, acc 1
2020-02-08T03:07:20.424947: step 2143, loss 0.0884675, acc 0.953125
2020-02-08T03:07:20.539750: step 2144, loss 0.0337719, acc 1
2020-02-08T03:07:20.657442: step 2145, loss 0.0602859, acc 0.96875
2020-02-08T03:07:20.773601: step 2146, loss 0.0497761, acc 0.984375
2020-02-08T03:07:20.890305: step 2147, loss 0.0848085, acc 0.984375
2020-02-08T03:07:21.007413: step 2148, loss 0.0276272, acc 1
2020-02-08T03:07:21.125241: step 2149, loss 0.0510726, acc 0.984375
2020-02-08T03:07:21.239686: step 2150, loss 0.0720397, acc 0.953125
2020-02-08T03:07:21.354335: step 2151, loss 0.12389, acc 0.953125
2020-02-08T03:07:21.611729: step 2152, loss 0.0236991, acc 1
2020-02-08T03:07:21.736431: step 2153, loss 0.0386549, acc 0.984375
2020-02-08T03:07:21.854423: step 2154, loss 0.0430015, acc 1
2020-02-08T03:07:21.970473: step 2155, loss 0.088741, acc 0.953125
2020-02-08T03:07:22.085120: step 2156, loss 0.0560363, acc 0.96875
2020-02-08T03:07:22.199872: step 2157, loss 0.0444222, acc 0.984375
2020-02-08T03:07:22.316640: step 2158, loss 0.0387135, acc 0.984375
2020-02-08T03:07:22.434447: step 2159, loss 0.0813809, acc 0.96875
2020-02-08T03:07:22.552265: step 2160, loss 0.0953844, acc 0.96875
2020-02-08T03:07:22.668231: step 2161, loss 0.0443988, acc 1
2020-02-08T03:07:22.786603: step 2162, loss 0.0496592, acc 0.984375
2020-02-08T03:07:22.901984: step 2163, loss 0.104042, acc 0.953125
2020-02-08T03:07:23.019772: step 2164, loss 0.0791025, acc 0.96875
2020-02-08T03:07:23.133460: step 2165, loss 0.168021, acc 0.953125
2020-02-08T03:07:23.252876: step 2166, loss 0.0443699, acc 0.984375
2020-02-08T03:07:23.368664: step 2167, loss 0.0544684, acc 0.984375
2020-02-08T03:07:23.483296: step 2168, loss 0.0139843, acc 1
2020-02-08T03:07:23.599185: step 2169, loss 0.0298319, acc 1
2020-02-08T03:07:23.717100: step 2170, loss 0.0743577, acc 0.984375
2020-02-08T03:07:23.833078: step 2171, loss 0.164843, acc 0.96875
2020-02-08T03:07:23.947658: step 2172, loss 0.152679, acc 0.9375
2020-02-08T03:07:24.064490: step 2173, loss 0.0329617, acc 1
2020-02-08T03:07:24.180760: step 2174, loss 0.0478412, acc 0.984375
2020-02-08T03:07:24.295055: step 2175, loss 0.0557604, acc 0.984375
2020-02-08T03:07:24.413764: step 2176, loss 0.0417429, acc 0.984375
2020-02-08T03:07:24.529619: step 2177, loss 0.0333844, acc 0.984375
2020-02-08T03:07:24.646430: step 2178, loss 0.0659509, acc 0.953125
2020-02-08T03:07:24.763017: step 2179, loss 0.0382195, acc 0.984375
2020-02-08T03:07:24.880437: step 2180, loss 0.0429092, acc 1
2020-02-08T03:07:24.998432: step 2181, loss 0.260436, acc 0.9375
2020-02-08T03:07:25.113554: step 2182, loss 0.0688525, acc 0.984375
2020-02-08T03:07:25.230043: step 2183, loss 0.0697463, acc 0.96875
2020-02-08T03:07:25.344261: step 2184, loss 0.12629, acc 0.96875
2020-02-08T03:07:25.464264: step 2185, loss 0.141535, acc 0.96875
2020-02-08T03:07:25.582444: step 2186, loss 0.0485458, acc 0.984375
2020-02-08T03:07:25.696297: step 2187, loss 0.0274497, acc 1
2020-02-08T03:07:25.813573: step 2188, loss 0.0323677, acc 1
2020-02-08T03:07:25.931350: step 2189, loss 0.0686986, acc 0.96875
2020-02-08T03:07:26.050270: step 2190, loss 0.037559, acc 0.984375
2020-02-08T03:07:26.168835: step 2191, loss 0.0451203, acc 1
2020-02-08T03:07:26.283373: step 2192, loss 0.0295353, acc 1
2020-02-08T03:07:26.397691: step 2193, loss 0.0478559, acc 0.984375
2020-02-08T03:07:26.514780: step 2194, loss 0.0496902, acc 0.96875
2020-02-08T03:07:26.631421: step 2195, loss 0.016641, acc 1
2020-02-08T03:07:26.746953: step 2196, loss 0.065815, acc 0.984375
2020-02-08T03:07:26.864277: step 2197, loss 0.0598071, acc 0.96875
2020-02-08T03:07:26.982771: step 2198, loss 0.121745, acc 0.9375
2020-02-08T03:07:27.099451: step 2199, loss 0.0469781, acc 0.984375
2020-02-08T03:07:27.212813: step 2200, loss 0.111706, acc 0.953125

Evaluation:
2020-02-08T03:07:27.404419: step 2200, loss 0.778208, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2200

2020-02-08T03:07:28.920229: step 2201, loss 0.13882, acc 0.953125
2020-02-08T03:07:29.036552: step 2202, loss 0.0414973, acc 1
2020-02-08T03:07:29.151986: step 2203, loss 0.0229456, acc 1
2020-02-08T03:07:29.267095: step 2204, loss 0.0546382, acc 0.984375
2020-02-08T03:07:29.383675: step 2205, loss 0.0480671, acc 0.96875
2020-02-08T03:07:29.498746: step 2206, loss 0.0732481, acc 0.953125
2020-02-08T03:07:29.616552: step 2207, loss 0.0803766, acc 0.96875
2020-02-08T03:07:29.734051: step 2208, loss 0.0746845, acc 0.96875
2020-02-08T03:07:29.852038: step 2209, loss 0.0413624, acc 0.984375
2020-02-08T03:07:29.970105: step 2210, loss 0.0731744, acc 0.953125
2020-02-08T03:07:30.084343: step 2211, loss 0.0262174, acc 0.984375
2020-02-08T03:07:30.201036: step 2212, loss 0.117359, acc 0.921875
2020-02-08T03:07:30.317269: step 2213, loss 0.0704847, acc 0.984375
2020-02-08T03:07:30.431693: step 2214, loss 0.115416, acc 0.953125
2020-02-08T03:07:30.548743: step 2215, loss 0.0719735, acc 0.953125
2020-02-08T03:07:30.665153: step 2216, loss 0.131696, acc 0.9375
2020-02-08T03:07:30.782586: step 2217, loss 0.0780703, acc 0.953125
2020-02-08T03:07:30.898002: step 2218, loss 0.0467827, acc 0.984375
2020-02-08T03:07:31.015281: step 2219, loss 0.15018, acc 0.953125
2020-02-08T03:07:31.133022: step 2220, loss 0.0850713, acc 0.984375
2020-02-08T03:07:31.251894: step 2221, loss 0.0238985, acc 1
2020-02-08T03:07:31.369424: step 2222, loss 0.090866, acc 0.953125
2020-02-08T03:07:31.484529: step 2223, loss 0.0531108, acc 0.984375
2020-02-08T03:07:31.600803: step 2224, loss 0.0640345, acc 0.984375
2020-02-08T03:07:31.716317: step 2225, loss 0.0956733, acc 0.9375
2020-02-08T03:07:31.833625: step 2226, loss 0.10629, acc 0.953125
2020-02-08T03:07:31.951198: step 2227, loss 0.112328, acc 0.953125
2020-02-08T03:07:32.067138: step 2228, loss 0.0488411, acc 0.96875
2020-02-08T03:07:32.185441: step 2229, loss 0.116452, acc 0.96875
2020-02-08T03:07:32.301096: step 2230, loss 0.0458483, acc 0.984375
2020-02-08T03:07:32.414641: step 2231, loss 0.035569, acc 1
2020-02-08T03:07:32.531445: step 2232, loss 0.0643688, acc 0.984375
2020-02-08T03:07:32.648627: step 2233, loss 0.0750888, acc 0.984375
2020-02-08T03:07:32.764255: step 2234, loss 0.0876163, acc 0.953125
2020-02-08T03:07:32.880907: step 2235, loss 0.0633186, acc 0.96875
2020-02-08T03:07:32.996190: step 2236, loss 0.0301293, acc 0.984375
2020-02-08T03:07:33.113631: step 2237, loss 0.0620424, acc 0.984375
2020-02-08T03:07:33.229221: step 2238, loss 0.0754738, acc 0.96875
2020-02-08T03:07:33.348031: step 2239, loss 0.0372248, acc 1
2020-02-08T03:07:33.464849: step 2240, loss 0.0616497, acc 0.984375
2020-02-08T03:07:33.583635: step 2241, loss 0.0577905, acc 0.984375
2020-02-08T03:07:33.699350: step 2242, loss 0.0473466, acc 1
2020-02-08T03:07:33.817111: step 2243, loss 0.0814742, acc 0.96875
2020-02-08T03:07:33.932885: step 2244, loss 0.0565218, acc 0.96875
2020-02-08T03:07:34.052168: step 2245, loss 0.130524, acc 0.921875
2020-02-08T03:07:34.170476: step 2246, loss 0.0943439, acc 0.953125
2020-02-08T03:07:34.285554: step 2247, loss 0.0920395, acc 0.953125
2020-02-08T03:07:34.402658: step 2248, loss 0.119702, acc 0.984375
2020-02-08T03:07:34.519946: step 2249, loss 0.0475221, acc 0.984375
2020-02-08T03:07:34.632832: step 2250, loss 0.0925135, acc 0.983333
2020-02-08T03:07:34.752141: step 2251, loss 0.0489888, acc 0.984375
2020-02-08T03:07:34.869683: step 2252, loss 0.0205563, acc 1
2020-02-08T03:07:34.987703: step 2253, loss 0.00888049, acc 1
2020-02-08T03:07:35.103280: step 2254, loss 0.161474, acc 0.9375
2020-02-08T03:07:35.218631: step 2255, loss 0.0352982, acc 0.984375
2020-02-08T03:07:35.334328: step 2256, loss 0.143593, acc 0.9375
2020-02-08T03:07:35.451857: step 2257, loss 0.0168613, acc 1
2020-02-08T03:07:35.570214: step 2258, loss 0.0253576, acc 1
2020-02-08T03:07:35.687937: step 2259, loss 0.0233658, acc 1
2020-02-08T03:07:35.803750: step 2260, loss 0.0827482, acc 0.96875
2020-02-08T03:07:35.922606: step 2261, loss 0.0533926, acc 0.96875
2020-02-08T03:07:36.038891: step 2262, loss 0.0488953, acc 0.984375
2020-02-08T03:07:36.157392: step 2263, loss 0.0487871, acc 0.984375
2020-02-08T03:07:36.274917: step 2264, loss 0.0281775, acc 0.984375
2020-02-08T03:07:36.390713: step 2265, loss 0.0391645, acc 0.984375
2020-02-08T03:07:36.505423: step 2266, loss 0.153875, acc 0.96875
2020-02-08T03:07:36.623138: step 2267, loss 0.0414181, acc 1
2020-02-08T03:07:36.738645: step 2268, loss 0.0435706, acc 0.984375
2020-02-08T03:07:36.856654: step 2269, loss 0.0506419, acc 0.984375
2020-02-08T03:07:36.971877: step 2270, loss 0.0857654, acc 0.953125
2020-02-08T03:07:37.087549: step 2271, loss 0.0532822, acc 0.984375
2020-02-08T03:07:37.202604: step 2272, loss 0.0173948, acc 1
2020-02-08T03:07:37.320956: step 2273, loss 0.0654446, acc 0.984375
2020-02-08T03:07:37.437319: step 2274, loss 0.0656507, acc 0.984375
2020-02-08T03:07:37.550219: step 2275, loss 0.0409837, acc 0.984375
2020-02-08T03:07:37.667954: step 2276, loss 0.0722103, acc 0.953125
2020-02-08T03:07:37.782972: step 2277, loss 0.0490142, acc 0.96875
2020-02-08T03:07:37.897058: step 2278, loss 0.0391811, acc 0.984375
2020-02-08T03:07:38.013175: step 2279, loss 0.0589223, acc 0.96875
2020-02-08T03:07:38.130374: step 2280, loss 0.0690325, acc 0.984375
2020-02-08T03:07:38.247563: step 2281, loss 0.0388702, acc 0.984375
2020-02-08T03:07:38.365901: step 2282, loss 0.0467318, acc 0.984375
2020-02-08T03:07:38.482000: step 2283, loss 0.0222306, acc 1
2020-02-08T03:07:38.597569: step 2284, loss 0.0125583, acc 1
2020-02-08T03:07:38.715140: step 2285, loss 0.0268857, acc 1
2020-02-08T03:07:38.831541: step 2286, loss 0.0445607, acc 0.96875
2020-02-08T03:07:38.949794: step 2287, loss 0.0297649, acc 1
2020-02-08T03:07:39.071303: step 2288, loss 0.0184371, acc 1
2020-02-08T03:07:39.194003: step 2289, loss 0.042817, acc 1
2020-02-08T03:07:39.311851: step 2290, loss 0.0340504, acc 0.984375
2020-02-08T03:07:39.428411: step 2291, loss 0.0583137, acc 0.984375
2020-02-08T03:07:39.543749: step 2292, loss 0.0543577, acc 0.96875
2020-02-08T03:07:39.660504: step 2293, loss 0.0239407, acc 1
2020-02-08T03:07:39.778547: step 2294, loss 0.126351, acc 0.9375
2020-02-08T03:07:39.892961: step 2295, loss 0.0582134, acc 0.96875
2020-02-08T03:07:40.010438: step 2296, loss 0.057258, acc 0.96875
2020-02-08T03:07:40.126833: step 2297, loss 0.0590014, acc 0.984375
2020-02-08T03:07:40.244012: step 2298, loss 0.0824016, acc 0.953125
2020-02-08T03:07:40.358851: step 2299, loss 0.023078, acc 0.984375
2020-02-08T03:07:40.474841: step 2300, loss 0.0612517, acc 0.96875

Evaluation:
2020-02-08T03:07:40.664115: step 2300, loss 0.81154, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2300

2020-02-08T03:07:42.176138: step 2301, loss 0.0176819, acc 1
2020-02-08T03:07:42.291990: step 2302, loss 0.0187697, acc 1
2020-02-08T03:07:42.409019: step 2303, loss 0.0376364, acc 1
2020-02-08T03:07:42.525739: step 2304, loss 0.0524157, acc 0.96875
2020-02-08T03:07:42.643408: step 2305, loss 0.015102, acc 1
2020-02-08T03:07:42.760354: step 2306, loss 0.0618547, acc 0.96875
2020-02-08T03:07:42.876325: step 2307, loss 0.0465561, acc 0.96875
2020-02-08T03:07:42.989667: step 2308, loss 0.0635614, acc 0.96875
2020-02-08T03:07:43.106465: step 2309, loss 0.0276315, acc 0.984375
2020-02-08T03:07:43.227169: step 2310, loss 0.0140722, acc 1
2020-02-08T03:07:43.350599: step 2311, loss 0.0366212, acc 0.984375
2020-02-08T03:07:43.469083: step 2312, loss 0.0252737, acc 1
2020-02-08T03:07:43.598337: step 2313, loss 0.0633983, acc 0.984375
2020-02-08T03:07:43.714006: step 2314, loss 0.0303074, acc 0.984375
2020-02-08T03:07:43.834077: step 2315, loss 0.0238919, acc 1
2020-02-08T03:07:43.948812: step 2316, loss 0.0238055, acc 1
2020-02-08T03:07:44.063726: step 2317, loss 0.0421213, acc 1
2020-02-08T03:07:44.184331: step 2318, loss 0.0197045, acc 1
2020-02-08T03:07:44.298319: step 2319, loss 0.0250612, acc 1
2020-02-08T03:07:44.414010: step 2320, loss 0.0219325, acc 1
2020-02-08T03:07:44.533522: step 2321, loss 0.0581496, acc 0.96875
2020-02-08T03:07:44.648721: step 2322, loss 0.0562894, acc 0.96875
2020-02-08T03:07:44.766717: step 2323, loss 0.0305078, acc 1
2020-02-08T03:07:44.882455: step 2324, loss 0.0468357, acc 0.984375
2020-02-08T03:07:44.999628: step 2325, loss 0.0514794, acc 0.984375
2020-02-08T03:07:45.122253: step 2326, loss 0.0309788, acc 0.984375
2020-02-08T03:07:45.238029: step 2327, loss 0.0413179, acc 0.984375
2020-02-08T03:07:45.354990: step 2328, loss 0.0912397, acc 0.96875
2020-02-08T03:07:45.472467: step 2329, loss 0.0359107, acc 0.96875
2020-02-08T03:07:45.589094: step 2330, loss 0.142502, acc 0.953125
2020-02-08T03:07:45.703837: step 2331, loss 0.0314756, acc 0.984375
2020-02-08T03:07:45.820118: step 2332, loss 0.0433705, acc 0.96875
2020-02-08T03:07:45.936622: step 2333, loss 0.0427473, acc 0.984375
2020-02-08T03:07:46.053877: step 2334, loss 0.0533364, acc 0.96875
2020-02-08T03:07:46.171511: step 2335, loss 0.0280357, acc 1
2020-02-08T03:07:46.285457: step 2336, loss 0.028481, acc 1
2020-02-08T03:07:46.401707: step 2337, loss 0.0497544, acc 0.984375
2020-02-08T03:07:46.518888: step 2338, loss 0.0220067, acc 1
2020-02-08T03:07:46.635197: step 2339, loss 0.114784, acc 0.953125
2020-02-08T03:07:46.751119: step 2340, loss 0.0519295, acc 0.96875
2020-02-08T03:07:46.865117: step 2341, loss 0.0272525, acc 1
2020-02-08T03:07:46.980582: step 2342, loss 0.0382516, acc 0.984375
2020-02-08T03:07:47.096178: step 2343, loss 0.0483228, acc 0.96875
2020-02-08T03:07:47.209846: step 2344, loss 0.0869296, acc 0.96875
2020-02-08T03:07:47.324629: step 2345, loss 0.0778081, acc 0.96875
2020-02-08T03:07:47.440264: step 2346, loss 0.0498138, acc 0.984375
2020-02-08T03:07:47.555862: step 2347, loss 0.0192753, acc 0.984375
2020-02-08T03:07:47.674889: step 2348, loss 0.0307793, acc 1
2020-02-08T03:07:47.795426: step 2349, loss 0.0399595, acc 1
2020-02-08T03:07:47.914617: step 2350, loss 0.0291223, acc 1
2020-02-08T03:07:48.031347: step 2351, loss 0.0610104, acc 0.984375
2020-02-08T03:07:48.147419: step 2352, loss 0.0601264, acc 0.984375
2020-02-08T03:07:48.263877: step 2353, loss 0.0395442, acc 0.984375
2020-02-08T03:07:48.380136: step 2354, loss 0.0280822, acc 1
2020-02-08T03:07:48.495376: step 2355, loss 0.00844147, acc 1
2020-02-08T03:07:48.613606: step 2356, loss 0.0329844, acc 0.984375
2020-02-08T03:07:48.730233: step 2357, loss 0.0336282, acc 0.984375
2020-02-08T03:07:48.846550: step 2358, loss 0.0184373, acc 1
2020-02-08T03:07:48.964699: step 2359, loss 0.0464609, acc 1
2020-02-08T03:07:49.080973: step 2360, loss 0.0248509, acc 1
2020-02-08T03:07:49.198050: step 2361, loss 0.0734879, acc 0.96875
2020-02-08T03:07:49.315967: step 2362, loss 0.0885101, acc 0.953125
2020-02-08T03:07:49.433147: step 2363, loss 0.0783269, acc 0.953125
2020-02-08T03:07:49.548570: step 2364, loss 0.025221, acc 1
2020-02-08T03:07:49.665854: step 2365, loss 0.0131416, acc 1
2020-02-08T03:07:49.782454: step 2366, loss 0.059024, acc 0.984375
2020-02-08T03:07:49.898857: step 2367, loss 0.0188663, acc 1
2020-02-08T03:07:50.015964: step 2368, loss 0.134043, acc 0.9375
2020-02-08T03:07:50.132311: step 2369, loss 0.0647044, acc 0.953125
2020-02-08T03:07:50.250105: step 2370, loss 0.0327252, acc 0.984375
2020-02-08T03:07:50.366407: step 2371, loss 0.0341514, acc 0.984375
2020-02-08T03:07:50.483234: step 2372, loss 0.0244115, acc 1
2020-02-08T03:07:50.599153: step 2373, loss 0.0759332, acc 0.953125
2020-02-08T03:07:50.715773: step 2374, loss 0.0537953, acc 0.984375
2020-02-08T03:07:50.834826: step 2375, loss 0.0254214, acc 0.984375
2020-02-08T03:07:50.951844: step 2376, loss 0.0203621, acc 1
2020-02-08T03:07:51.068281: step 2377, loss 0.0501356, acc 0.96875
2020-02-08T03:07:51.186178: step 2378, loss 0.0341306, acc 0.984375
2020-02-08T03:07:51.657331: step 2379, loss 0.0560485, acc 0.96875
2020-02-08T03:07:51.781974: step 2380, loss 0.0201747, acc 1
2020-02-08T03:07:51.910018: step 2381, loss 0.0884507, acc 0.984375
2020-02-08T03:07:52.026191: step 2382, loss 0.0503618, acc 0.984375
2020-02-08T03:07:52.141032: step 2383, loss 0.0665973, acc 0.953125
2020-02-08T03:07:52.254942: step 2384, loss 0.0230764, acc 1
2020-02-08T03:07:52.373292: step 2385, loss 0.0633309, acc 0.953125
2020-02-08T03:07:52.486413: step 2386, loss 0.0408025, acc 0.984375
2020-02-08T03:07:52.604085: step 2387, loss 0.0417373, acc 0.984375
2020-02-08T03:07:52.720137: step 2388, loss 0.0334931, acc 0.984375
2020-02-08T03:07:52.841041: step 2389, loss 0.016972, acc 1
2020-02-08T03:07:52.958097: step 2390, loss 0.0381179, acc 0.984375
2020-02-08T03:07:53.075204: step 2391, loss 0.176012, acc 0.953125
2020-02-08T03:07:53.190694: step 2392, loss 0.0703486, acc 0.984375
2020-02-08T03:07:53.304341: step 2393, loss 0.0213941, acc 1
2020-02-08T03:07:53.417971: step 2394, loss 0.0677657, acc 0.96875
2020-02-08T03:07:53.533594: step 2395, loss 0.0320509, acc 1
2020-02-08T03:07:53.652150: step 2396, loss 0.0757082, acc 0.984375
2020-02-08T03:07:53.770647: step 2397, loss 0.0749146, acc 0.953125
2020-02-08T03:07:53.886880: step 2398, loss 0.0851023, acc 0.953125
2020-02-08T03:07:54.002112: step 2399, loss 0.0235387, acc 1
2020-02-08T03:07:54.116261: step 2400, loss 0.0726093, acc 0.966667

Evaluation:
2020-02-08T03:07:54.307713: step 2400, loss 0.831933, acc 0.731707

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2400

2020-02-08T03:07:55.890386: step 2401, loss 0.101829, acc 0.96875
2020-02-08T03:07:56.009328: step 2402, loss 0.037927, acc 0.984375
2020-02-08T03:07:56.127565: step 2403, loss 0.0374817, acc 1
2020-02-08T03:07:56.245607: step 2404, loss 0.0150396, acc 1
2020-02-08T03:07:56.362168: step 2405, loss 0.0465757, acc 0.984375
2020-02-08T03:07:56.478883: step 2406, loss 0.0172982, acc 1
2020-02-08T03:07:56.597087: step 2407, loss 0.0393866, acc 0.984375
2020-02-08T03:07:56.716078: step 2408, loss 0.111688, acc 0.96875
2020-02-08T03:07:56.833862: step 2409, loss 0.022969, acc 1
2020-02-08T03:07:56.950925: step 2410, loss 0.0416317, acc 0.984375
2020-02-08T03:07:57.068620: step 2411, loss 0.0588826, acc 0.96875
2020-02-08T03:07:57.183273: step 2412, loss 0.032871, acc 0.984375
2020-02-08T03:07:57.298242: step 2413, loss 0.0850186, acc 0.953125
2020-02-08T03:07:57.413870: step 2414, loss 0.0147896, acc 1
2020-02-08T03:07:57.532259: step 2415, loss 0.0171702, acc 1
2020-02-08T03:07:57.649253: step 2416, loss 0.0377135, acc 0.984375
2020-02-08T03:07:57.766564: step 2417, loss 0.0355928, acc 0.984375
2020-02-08T03:07:57.885243: step 2418, loss 0.0556018, acc 0.984375
2020-02-08T03:07:58.002832: step 2419, loss 0.0244399, acc 0.984375
2020-02-08T03:07:58.120309: step 2420, loss 0.0791337, acc 0.96875
2020-02-08T03:07:58.238679: step 2421, loss 0.0325245, acc 0.984375
2020-02-08T03:07:58.354009: step 2422, loss 0.0840071, acc 0.96875
2020-02-08T03:07:58.471207: step 2423, loss 0.027053, acc 1
2020-02-08T03:07:58.587818: step 2424, loss 0.0769346, acc 0.96875
2020-02-08T03:07:58.702595: step 2425, loss 0.0169916, acc 1
2020-02-08T03:07:58.821089: step 2426, loss 0.0133993, acc 1
2020-02-08T03:07:58.937854: step 2427, loss 0.0181834, acc 1
2020-02-08T03:07:59.049200: step 2428, loss 0.0464196, acc 0.984375
2020-02-08T03:07:59.168539: step 2429, loss 0.0500256, acc 0.96875
2020-02-08T03:07:59.288441: step 2430, loss 0.0227009, acc 1
2020-02-08T03:07:59.406862: step 2431, loss 0.0459863, acc 0.984375
2020-02-08T03:07:59.522791: step 2432, loss 0.0187918, acc 1
2020-02-08T03:07:59.640817: step 2433, loss 0.0281451, acc 1
2020-02-08T03:07:59.756857: step 2434, loss 0.0415634, acc 0.984375
2020-02-08T03:07:59.874170: step 2435, loss 0.0312276, acc 1
2020-02-08T03:07:59.991044: step 2436, loss 0.0572234, acc 0.96875
2020-02-08T03:08:00.106314: step 2437, loss 0.0792065, acc 0.953125
2020-02-08T03:08:00.223580: step 2438, loss 0.0518201, acc 0.984375
2020-02-08T03:08:00.339766: step 2439, loss 0.00818401, acc 1
2020-02-08T03:08:00.456841: step 2440, loss 0.0426249, acc 0.984375
2020-02-08T03:08:00.573600: step 2441, loss 0.0366476, acc 0.984375
2020-02-08T03:08:00.689563: step 2442, loss 0.0723523, acc 0.984375
2020-02-08T03:08:00.806067: step 2443, loss 0.0163677, acc 1
2020-02-08T03:08:00.925109: step 2444, loss 0.0221796, acc 1
2020-02-08T03:08:01.039235: step 2445, loss 0.0437343, acc 0.96875
2020-02-08T03:08:01.155345: step 2446, loss 0.0133392, acc 1
2020-02-08T03:08:01.270912: step 2447, loss 0.0102209, acc 1
2020-02-08T03:08:01.386054: step 2448, loss 0.0241794, acc 1
2020-02-08T03:08:01.504566: step 2449, loss 0.0277006, acc 0.984375
2020-02-08T03:08:01.621407: step 2450, loss 0.0212603, acc 1
2020-02-08T03:08:01.737192: step 2451, loss 0.0336649, acc 0.96875
2020-02-08T03:08:01.857745: step 2452, loss 0.033287, acc 1
2020-02-08T03:08:01.973578: step 2453, loss 0.0241968, acc 0.984375
2020-02-08T03:08:02.088340: step 2454, loss 0.0190414, acc 0.984375
2020-02-08T03:08:02.203090: step 2455, loss 0.0450055, acc 0.984375
2020-02-08T03:08:02.321901: step 2456, loss 0.0632663, acc 0.96875
2020-02-08T03:08:02.436923: step 2457, loss 0.0171429, acc 1
2020-02-08T03:08:02.555761: step 2458, loss 0.0307519, acc 0.984375
2020-02-08T03:08:02.674304: step 2459, loss 0.0166951, acc 1
2020-02-08T03:08:02.792300: step 2460, loss 0.0482141, acc 0.984375
2020-02-08T03:08:02.909770: step 2461, loss 0.0167895, acc 1
2020-02-08T03:08:03.027973: step 2462, loss 0.0456889, acc 0.984375
2020-02-08T03:08:03.142718: step 2463, loss 0.0518788, acc 0.96875
2020-02-08T03:08:03.262515: step 2464, loss 0.0301667, acc 1
2020-02-08T03:08:03.380772: step 2465, loss 0.0279762, acc 1
2020-02-08T03:08:03.493960: step 2466, loss 0.0196824, acc 1
2020-02-08T03:08:03.613170: step 2467, loss 0.0478956, acc 1
2020-02-08T03:08:03.730887: step 2468, loss 0.112812, acc 0.953125
2020-02-08T03:08:03.845089: step 2469, loss 0.042446, acc 0.984375
2020-02-08T03:08:03.961805: step 2470, loss 0.011945, acc 1
2020-02-08T03:08:04.077952: step 2471, loss 0.0371149, acc 0.984375
2020-02-08T03:08:04.191843: step 2472, loss 0.0132866, acc 1
2020-02-08T03:08:04.313945: step 2473, loss 0.0385392, acc 0.984375
2020-02-08T03:08:04.430942: step 2474, loss 0.0179498, acc 0.984375
2020-02-08T03:08:04.547401: step 2475, loss 0.0355099, acc 0.984375
2020-02-08T03:08:04.666478: step 2476, loss 0.0248407, acc 1
2020-02-08T03:08:04.781990: step 2477, loss 0.0184655, acc 1
2020-02-08T03:08:04.896446: step 2478, loss 0.0211866, acc 1
2020-02-08T03:08:05.015072: step 2479, loss 0.0450701, acc 0.984375
2020-02-08T03:08:05.129984: step 2480, loss 0.0514485, acc 0.984375
2020-02-08T03:08:05.245185: step 2481, loss 0.0417206, acc 1
2020-02-08T03:08:05.362118: step 2482, loss 0.0326486, acc 0.984375
2020-02-08T03:08:05.479526: step 2483, loss 0.0331299, acc 0.984375
2020-02-08T03:08:05.592703: step 2484, loss 0.0468832, acc 0.984375
2020-02-08T03:08:05.710843: step 2485, loss 0.0615584, acc 0.953125
2020-02-08T03:08:05.829492: step 2486, loss 0.0141943, acc 1
2020-02-08T03:08:05.944431: step 2487, loss 0.0399271, acc 0.984375
2020-02-08T03:08:06.061764: step 2488, loss 0.0642883, acc 0.953125
2020-02-08T03:08:06.178371: step 2489, loss 0.0705443, acc 0.984375
2020-02-08T03:08:06.292717: step 2490, loss 0.0129284, acc 1
2020-02-08T03:08:06.409270: step 2491, loss 0.102287, acc 0.9375
2020-02-08T03:08:06.526183: step 2492, loss 0.057834, acc 0.984375
2020-02-08T03:08:06.641477: step 2493, loss 0.0103359, acc 1
2020-02-08T03:08:06.758346: step 2494, loss 0.0251878, acc 1
2020-02-08T03:08:06.876077: step 2495, loss 0.0442382, acc 0.984375
2020-02-08T03:08:06.991881: step 2496, loss 0.0198771, acc 1
2020-02-08T03:08:07.111170: step 2497, loss 0.0364893, acc 0.984375
2020-02-08T03:08:07.228727: step 2498, loss 0.0228639, acc 1
2020-02-08T03:08:07.345121: step 2499, loss 0.0311139, acc 1
2020-02-08T03:08:07.462057: step 2500, loss 0.0780882, acc 0.953125

Evaluation:
2020-02-08T03:08:07.648694: step 2500, loss 0.880811, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2500

2020-02-08T03:08:09.183336: step 2501, loss 0.0118686, acc 1
2020-02-08T03:08:09.297693: step 2502, loss 0.0378003, acc 0.984375
2020-02-08T03:08:09.415097: step 2503, loss 0.071629, acc 0.953125
2020-02-08T03:08:09.533673: step 2504, loss 0.0206666, acc 1
2020-02-08T03:08:09.650335: step 2505, loss 0.0287812, acc 0.984375
2020-02-08T03:08:09.768324: step 2506, loss 0.0683558, acc 0.953125
2020-02-08T03:08:09.886161: step 2507, loss 0.0446303, acc 0.96875
2020-02-08T03:08:10.001999: step 2508, loss 0.0234688, acc 1
2020-02-08T03:08:10.118400: step 2509, loss 0.0132026, acc 1
2020-02-08T03:08:10.234408: step 2510, loss 0.00892814, acc 1
2020-02-08T03:08:10.367237: step 2511, loss 0.0550789, acc 0.96875
2020-02-08T03:08:10.486914: step 2512, loss 0.0164365, acc 1
2020-02-08T03:08:10.604429: step 2513, loss 0.0749882, acc 0.96875
2020-02-08T03:08:10.724414: step 2514, loss 0.0212237, acc 1
2020-02-08T03:08:10.849270: step 2515, loss 0.0597309, acc 0.953125
2020-02-08T03:08:10.967050: step 2516, loss 0.00637856, acc 1
2020-02-08T03:08:11.083765: step 2517, loss 0.029814, acc 0.984375
2020-02-08T03:08:11.207096: step 2518, loss 0.0250066, acc 0.984375
2020-02-08T03:08:11.328655: step 2519, loss 0.049956, acc 0.984375
2020-02-08T03:08:11.444721: step 2520, loss 0.0758702, acc 0.96875
2020-02-08T03:08:11.562511: step 2521, loss 0.0189315, acc 1
2020-02-08T03:08:11.680185: step 2522, loss 0.0591623, acc 0.96875
2020-02-08T03:08:11.795517: step 2523, loss 0.0156703, acc 1
2020-02-08T03:08:11.910775: step 2524, loss 0.109007, acc 0.984375
2020-02-08T03:08:12.029024: step 2525, loss 0.0423426, acc 0.96875
2020-02-08T03:08:12.146125: step 2526, loss 0.0455868, acc 0.984375
2020-02-08T03:08:12.261971: step 2527, loss 0.0127696, acc 1
2020-02-08T03:08:12.379240: step 2528, loss 0.0273338, acc 1
2020-02-08T03:08:12.493370: step 2529, loss 0.045802, acc 0.96875
2020-02-08T03:08:12.611754: step 2530, loss 0.0196026, acc 1
2020-02-08T03:08:12.729102: step 2531, loss 0.0096864, acc 1
2020-02-08T03:08:12.843172: step 2532, loss 0.0293552, acc 1
2020-02-08T03:08:12.960643: step 2533, loss 0.0158959, acc 1
2020-02-08T03:08:13.079288: step 2534, loss 0.0393552, acc 0.984375
2020-02-08T03:08:13.195004: step 2535, loss 0.00674505, acc 1
2020-02-08T03:08:13.313998: step 2536, loss 0.0303109, acc 1
2020-02-08T03:08:13.430049: step 2537, loss 0.0505034, acc 0.96875
2020-02-08T03:08:13.545392: step 2538, loss 0.00891219, acc 1
2020-02-08T03:08:13.661039: step 2539, loss 0.0534174, acc 0.96875
2020-02-08T03:08:13.777191: step 2540, loss 0.017571, acc 1
2020-02-08T03:08:13.895166: step 2541, loss 0.0435923, acc 0.96875
2020-02-08T03:08:14.013598: step 2542, loss 0.100567, acc 0.96875
2020-02-08T03:08:14.131164: step 2543, loss 0.0354794, acc 0.984375
2020-02-08T03:08:14.248109: step 2544, loss 0.0156724, acc 1
2020-02-08T03:08:14.367414: step 2545, loss 0.0360678, acc 0.984375
2020-02-08T03:08:14.483022: step 2546, loss 0.124126, acc 0.96875
2020-02-08T03:08:14.596694: step 2547, loss 0.0563869, acc 0.984375
2020-02-08T03:08:14.714098: step 2548, loss 0.0145887, acc 1
2020-02-08T03:08:14.831656: step 2549, loss 0.024017, acc 1
2020-02-08T03:08:14.942977: step 2550, loss 0.0204653, acc 1
2020-02-08T03:08:15.061283: step 2551, loss 0.0117783, acc 1
2020-02-08T03:08:15.177434: step 2552, loss 0.0652171, acc 0.984375
2020-02-08T03:08:15.292903: step 2553, loss 0.0927797, acc 0.984375
2020-02-08T03:08:15.410498: step 2554, loss 0.00510233, acc 1
2020-02-08T03:08:15.527292: step 2555, loss 0.0200756, acc 1
2020-02-08T03:08:15.643754: step 2556, loss 0.00823762, acc 1
2020-02-08T03:08:15.761426: step 2557, loss 0.03192, acc 0.984375
2020-02-08T03:08:15.877697: step 2558, loss 0.0361303, acc 0.984375
2020-02-08T03:08:15.994172: step 2559, loss 0.0126313, acc 1
2020-02-08T03:08:16.109775: step 2560, loss 0.0305647, acc 0.984375
2020-02-08T03:08:16.226850: step 2561, loss 0.0382597, acc 0.984375
2020-02-08T03:08:16.342484: step 2562, loss 0.0362655, acc 1
2020-02-08T03:08:16.460913: step 2563, loss 0.0378038, acc 0.984375
2020-02-08T03:08:16.579918: step 2564, loss 0.0971226, acc 0.96875
2020-02-08T03:08:16.696269: step 2565, loss 0.0824886, acc 0.984375
2020-02-08T03:08:16.814364: step 2566, loss 0.0596985, acc 0.96875
2020-02-08T03:08:16.931958: step 2567, loss 0.0268217, acc 0.984375
2020-02-08T03:08:17.050731: step 2568, loss 0.0306941, acc 0.984375
2020-02-08T03:08:17.167327: step 2569, loss 0.11701, acc 0.96875
2020-02-08T03:08:17.284701: step 2570, loss 0.0234238, acc 1
2020-02-08T03:08:17.401619: step 2571, loss 0.0107183, acc 1
2020-02-08T03:08:17.517788: step 2572, loss 0.0519672, acc 0.984375
2020-02-08T03:08:17.634765: step 2573, loss 0.0263576, acc 1
2020-02-08T03:08:17.750359: step 2574, loss 0.00974937, acc 1
2020-02-08T03:08:17.866423: step 2575, loss 0.0416782, acc 0.984375
2020-02-08T03:08:17.984136: step 2576, loss 0.00556449, acc 1
2020-02-08T03:08:18.099300: step 2577, loss 0.0161897, acc 1
2020-02-08T03:08:18.216979: step 2578, loss 0.0277711, acc 0.984375
2020-02-08T03:08:18.336587: step 2579, loss 0.0197799, acc 1
2020-02-08T03:08:18.454189: step 2580, loss 0.0318764, acc 0.984375
2020-02-08T03:08:18.570826: step 2581, loss 0.0295252, acc 1
2020-02-08T03:08:18.687748: step 2582, loss 0.0113738, acc 1
2020-02-08T03:08:18.805916: step 2583, loss 0.0608742, acc 0.96875
2020-02-08T03:08:18.924218: step 2584, loss 0.0143166, acc 1
2020-02-08T03:08:19.040214: step 2585, loss 0.0168398, acc 1
2020-02-08T03:08:19.155500: step 2586, loss 0.0214, acc 1
2020-02-08T03:08:19.274486: step 2587, loss 0.0240441, acc 0.984375
2020-02-08T03:08:19.390397: step 2588, loss 0.0366672, acc 1
2020-02-08T03:08:19.506571: step 2589, loss 0.0256984, acc 0.984375
2020-02-08T03:08:19.623433: step 2590, loss 0.0224658, acc 1
2020-02-08T03:08:19.740036: step 2591, loss 0.0240521, acc 1
2020-02-08T03:08:19.858327: step 2592, loss 0.0194749, acc 1
2020-02-08T03:08:19.975819: step 2593, loss 0.0347911, acc 0.984375
2020-02-08T03:08:20.088627: step 2594, loss 0.0517519, acc 0.984375
2020-02-08T03:08:20.203614: step 2595, loss 0.0313067, acc 0.984375
2020-02-08T03:08:20.320268: step 2596, loss 0.00867686, acc 1
2020-02-08T03:08:20.437490: step 2597, loss 0.025661, acc 1
2020-02-08T03:08:20.551491: step 2598, loss 0.0103201, acc 1
2020-02-08T03:08:20.667328: step 2599, loss 0.0135931, acc 1
2020-02-08T03:08:20.785691: step 2600, loss 0.0343244, acc 0.984375

Evaluation:
2020-02-08T03:08:20.974377: step 2600, loss 0.916549, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2600

2020-02-08T03:08:22.473383: step 2601, loss 0.014949, acc 1
2020-02-08T03:08:22.591567: step 2602, loss 0.0722047, acc 0.953125
2020-02-08T03:08:22.709291: step 2603, loss 0.0152126, acc 1
2020-02-08T03:08:22.841674: step 2604, loss 0.00852494, acc 1
2020-02-08T03:08:22.968456: step 2605, loss 0.0193229, acc 1
2020-02-08T03:08:23.083622: step 2606, loss 0.0344813, acc 0.984375
2020-02-08T03:08:23.202702: step 2607, loss 0.0114495, acc 1
2020-02-08T03:08:23.318924: step 2608, loss 0.0110487, acc 1
2020-02-08T03:08:23.434871: step 2609, loss 0.0261238, acc 0.984375
2020-02-08T03:08:23.549039: step 2610, loss 0.0134092, acc 1
2020-02-08T03:08:23.666025: step 2611, loss 0.0247496, acc 0.984375
2020-02-08T03:08:23.781476: step 2612, loss 0.04057, acc 0.96875
2020-02-08T03:08:23.896318: step 2613, loss 0.028438, acc 0.984375
2020-02-08T03:08:24.015091: step 2614, loss 0.0358355, acc 1
2020-02-08T03:08:24.133843: step 2615, loss 0.0236946, acc 1
2020-02-08T03:08:24.249085: step 2616, loss 0.0732729, acc 0.984375
2020-02-08T03:08:24.367089: step 2617, loss 0.0187202, acc 1
2020-02-08T03:08:24.484043: step 2618, loss 0.076804, acc 0.984375
2020-02-08T03:08:24.601129: step 2619, loss 0.0347612, acc 1
2020-02-08T03:08:24.716940: step 2620, loss 0.0167307, acc 1
2020-02-08T03:08:24.834466: step 2621, loss 0.0301184, acc 0.984375
2020-02-08T03:08:24.949749: step 2622, loss 0.0401189, acc 0.984375
2020-02-08T03:08:25.063692: step 2623, loss 0.010421, acc 1
2020-02-08T03:08:25.179888: step 2624, loss 0.013654, acc 1
2020-02-08T03:08:25.293899: step 2625, loss 0.0142252, acc 1
2020-02-08T03:08:25.412221: step 2626, loss 0.0113288, acc 1
2020-02-08T03:08:25.533226: step 2627, loss 0.0074663, acc 1
2020-02-08T03:08:25.650276: step 2628, loss 0.0152879, acc 1
2020-02-08T03:08:25.766734: step 2629, loss 0.0149978, acc 1
2020-02-08T03:08:25.886171: step 2630, loss 0.0348403, acc 0.984375
2020-02-08T03:08:26.001019: step 2631, loss 0.0165869, acc 1
2020-02-08T03:08:26.116775: step 2632, loss 0.0444194, acc 0.96875
2020-02-08T03:08:26.233125: step 2633, loss 0.0238483, acc 1
2020-02-08T03:08:26.348483: step 2634, loss 0.0115604, acc 1
2020-02-08T03:08:26.467419: step 2635, loss 0.0160981, acc 1
2020-02-08T03:08:26.584299: step 2636, loss 0.0595663, acc 0.984375
2020-02-08T03:08:26.699650: step 2637, loss 0.112299, acc 0.96875
2020-02-08T03:08:26.816972: step 2638, loss 0.101684, acc 0.953125
2020-02-08T03:08:26.937473: step 2639, loss 0.0205424, acc 0.984375
2020-02-08T03:08:27.054006: step 2640, loss 0.0281317, acc 0.984375
2020-02-08T03:08:27.171606: step 2641, loss 0.0419151, acc 0.984375
2020-02-08T03:08:27.289647: step 2642, loss 0.0745089, acc 0.953125
2020-02-08T03:08:27.406658: step 2643, loss 0.0367932, acc 0.96875
2020-02-08T03:08:27.522588: step 2644, loss 0.00919724, acc 1
2020-02-08T03:08:27.639010: step 2645, loss 0.0418284, acc 0.984375
2020-02-08T03:08:27.755355: step 2646, loss 0.00654835, acc 1
2020-02-08T03:08:27.874705: step 2647, loss 0.0885708, acc 0.96875
2020-02-08T03:08:27.993074: step 2648, loss 0.0291739, acc 1
2020-02-08T03:08:28.112661: step 2649, loss 0.0107943, acc 1
2020-02-08T03:08:28.232165: step 2650, loss 0.0178986, acc 1
2020-02-08T03:08:28.347197: step 2651, loss 0.0538579, acc 0.96875
2020-02-08T03:08:28.468144: step 2652, loss 0.0369862, acc 0.984375
2020-02-08T03:08:28.587213: step 2653, loss 0.0255519, acc 0.984375
2020-02-08T03:08:28.702833: step 2654, loss 0.0072894, acc 1
2020-02-08T03:08:28.819067: step 2655, loss 0.0156492, acc 1
2020-02-08T03:08:28.933722: step 2656, loss 0.0395527, acc 0.984375
2020-02-08T03:08:29.048045: step 2657, loss 0.0510319, acc 0.984375
2020-02-08T03:08:29.165616: step 2658, loss 0.00588289, acc 1
2020-02-08T03:08:29.280623: step 2659, loss 0.0184183, acc 1
2020-02-08T03:08:29.394468: step 2660, loss 0.060808, acc 0.953125
2020-02-08T03:08:29.509720: step 2661, loss 0.0181542, acc 1
2020-02-08T03:08:29.626483: step 2662, loss 0.0223686, acc 0.984375
2020-02-08T03:08:29.741267: step 2663, loss 0.028727, acc 1
2020-02-08T03:08:29.861642: step 2664, loss 0.00976483, acc 1
2020-02-08T03:08:29.977921: step 2665, loss 0.0404001, acc 0.96875
2020-02-08T03:08:30.094950: step 2666, loss 0.0372972, acc 0.984375
2020-02-08T03:08:30.214935: step 2667, loss 0.069022, acc 0.984375
2020-02-08T03:08:30.331754: step 2668, loss 0.0173863, acc 1
2020-02-08T03:08:30.448435: step 2669, loss 0.0211926, acc 0.984375
2020-02-08T03:08:30.566252: step 2670, loss 0.0603914, acc 0.984375
2020-02-08T03:08:30.682994: step 2671, loss 0.00712803, acc 1
2020-02-08T03:08:30.797893: step 2672, loss 0.0428531, acc 0.984375
2020-02-08T03:08:30.914662: step 2673, loss 0.0151181, acc 1
2020-02-08T03:08:31.034719: step 2674, loss 0.0818842, acc 0.96875
2020-02-08T03:08:31.148578: step 2675, loss 0.0202522, acc 1
2020-02-08T03:08:31.266103: step 2676, loss 0.0150754, acc 1
2020-02-08T03:08:31.386555: step 2677, loss 0.00829307, acc 1
2020-02-08T03:08:31.502601: step 2678, loss 0.0566906, acc 0.953125
2020-02-08T03:08:31.621144: step 2679, loss 0.0204535, acc 1
2020-02-08T03:08:31.737864: step 2680, loss 0.0730881, acc 0.953125
2020-02-08T03:08:31.855746: step 2681, loss 0.0127997, acc 1
2020-02-08T03:08:31.975453: step 2682, loss 0.00989354, acc 1
2020-02-08T03:08:32.090492: step 2683, loss 0.0955463, acc 0.96875
2020-02-08T03:08:32.209036: step 2684, loss 0.0232324, acc 1
2020-02-08T03:08:32.325224: step 2685, loss 0.0323572, acc 0.984375
2020-02-08T03:08:32.440392: step 2686, loss 0.0274241, acc 1
2020-02-08T03:08:32.555626: step 2687, loss 0.0411379, acc 0.984375
2020-02-08T03:08:32.675035: step 2688, loss 0.0124264, acc 1
2020-02-08T03:08:32.791534: step 2689, loss 0.0217732, acc 1
2020-02-08T03:08:32.908070: step 2690, loss 0.0232455, acc 1
2020-02-08T03:08:33.026951: step 2691, loss 0.0360221, acc 1
2020-02-08T03:08:33.142928: step 2692, loss 0.0615154, acc 0.984375
2020-02-08T03:08:33.261506: step 2693, loss 0.0479227, acc 0.984375
2020-02-08T03:08:33.380598: step 2694, loss 0.0224471, acc 1
2020-02-08T03:08:33.495578: step 2695, loss 0.0346613, acc 1
2020-02-08T03:08:33.610146: step 2696, loss 0.0362635, acc 0.984375
2020-02-08T03:08:33.727825: step 2697, loss 0.0468601, acc 0.984375
2020-02-08T03:08:33.844500: step 2698, loss 0.0294594, acc 1
2020-02-08T03:08:33.960582: step 2699, loss 0.030473, acc 0.984375
2020-02-08T03:08:34.076371: step 2700, loss 0.0674922, acc 0.966667

Evaluation:
2020-02-08T03:08:34.265291: step 2700, loss 0.926816, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2700

2020-02-08T03:08:35.777734: step 2701, loss 0.0115636, acc 1
2020-02-08T03:08:35.893900: step 2702, loss 0.0119097, acc 1
2020-02-08T03:08:36.010000: step 2703, loss 0.00768505, acc 1
2020-02-08T03:08:36.127533: step 2704, loss 0.0299889, acc 0.984375
2020-02-08T03:08:36.243104: step 2705, loss 0.0203389, acc 1
2020-02-08T03:08:36.360612: step 2706, loss 0.0478383, acc 0.96875
2020-02-08T03:08:36.477942: step 2707, loss 0.0205999, acc 1
2020-02-08T03:08:36.592315: step 2708, loss 0.0395678, acc 0.984375
2020-02-08T03:08:36.706232: step 2709, loss 0.00428732, acc 1
2020-02-08T03:08:36.823191: step 2710, loss 0.0137075, acc 1
2020-02-08T03:08:36.939443: step 2711, loss 0.0154679, acc 1
2020-02-08T03:08:37.053291: step 2712, loss 0.0252862, acc 0.984375
2020-02-08T03:08:37.168526: step 2713, loss 0.0428546, acc 0.984375
2020-02-08T03:08:37.282746: step 2714, loss 0.0420555, acc 0.984375
2020-02-08T03:08:37.401447: step 2715, loss 0.0219292, acc 1
2020-02-08T03:08:37.519829: step 2716, loss 0.0193883, acc 1
2020-02-08T03:08:37.634755: step 2717, loss 0.0118637, acc 1
2020-02-08T03:08:37.748396: step 2718, loss 0.0216286, acc 1
2020-02-08T03:08:37.865680: step 2719, loss 0.00899853, acc 1
2020-02-08T03:08:37.984538: step 2720, loss 0.0528027, acc 0.984375
2020-02-08T03:08:38.100469: step 2721, loss 0.0134636, acc 1
2020-02-08T03:08:38.216917: step 2722, loss 0.0109734, acc 1
2020-02-08T03:08:38.332689: step 2723, loss 0.0067708, acc 1
2020-02-08T03:08:38.446529: step 2724, loss 0.0204389, acc 1
2020-02-08T03:08:38.562131: step 2725, loss 0.0255794, acc 0.984375
2020-02-08T03:08:38.683978: step 2726, loss 0.00505836, acc 1
2020-02-08T03:08:38.797880: step 2727, loss 0.0168316, acc 1
2020-02-08T03:08:38.914355: step 2728, loss 0.00840927, acc 1
2020-02-08T03:08:39.030590: step 2729, loss 0.00985654, acc 1
2020-02-08T03:08:39.149680: step 2730, loss 0.0480663, acc 0.984375
2020-02-08T03:08:39.268465: step 2731, loss 0.0178975, acc 1
2020-02-08T03:08:39.390940: step 2732, loss 0.0231555, acc 0.984375
2020-02-08T03:08:39.511124: step 2733, loss 0.0349073, acc 0.984375
2020-02-08T03:08:39.625034: step 2734, loss 0.030546, acc 1
2020-02-08T03:08:39.742821: step 2735, loss 0.0209459, acc 1
2020-02-08T03:08:39.858515: step 2736, loss 0.00455802, acc 1
2020-02-08T03:08:39.973603: step 2737, loss 0.00383352, acc 1
2020-02-08T03:08:40.088023: step 2738, loss 0.00966335, acc 1
2020-02-08T03:08:40.202561: step 2739, loss 0.00700942, acc 1
2020-02-08T03:08:40.320789: step 2740, loss 0.0221707, acc 1
2020-02-08T03:08:40.437019: step 2741, loss 0.0162756, acc 1
2020-02-08T03:08:40.551911: step 2742, loss 0.0169667, acc 1
2020-02-08T03:08:40.667412: step 2743, loss 0.0125726, acc 1
2020-02-08T03:08:40.784837: step 2744, loss 0.0192851, acc 1
2020-02-08T03:08:40.901674: step 2745, loss 0.0264782, acc 1
2020-02-08T03:08:41.019847: step 2746, loss 0.0155167, acc 1
2020-02-08T03:08:41.134656: step 2747, loss 0.0136922, acc 1
2020-02-08T03:08:41.251903: step 2748, loss 0.00959628, acc 1
2020-02-08T03:08:41.371056: step 2749, loss 0.0141243, acc 0.984375
2020-02-08T03:08:41.485391: step 2750, loss 0.0113807, acc 1
2020-02-08T03:08:41.601383: step 2751, loss 0.0181435, acc 1
2020-02-08T03:08:41.716673: step 2752, loss 0.0149808, acc 1
2020-02-08T03:08:41.831845: step 2753, loss 0.015692, acc 1
2020-02-08T03:08:41.949824: step 2754, loss 0.0142426, acc 1
2020-02-08T03:08:42.065354: step 2755, loss 0.0116906, acc 1
2020-02-08T03:08:42.181072: step 2756, loss 0.0268882, acc 1
2020-02-08T03:08:42.293971: step 2757, loss 0.0227541, acc 1
2020-02-08T03:08:42.411325: step 2758, loss 0.0104436, acc 1
2020-02-08T03:08:42.529196: step 2759, loss 0.00489637, acc 1
2020-02-08T03:08:42.646176: step 2760, loss 0.0470717, acc 0.984375
2020-02-08T03:08:42.761482: step 2761, loss 0.0134028, acc 1
2020-02-08T03:08:42.878468: step 2762, loss 0.0089425, acc 1
2020-02-08T03:08:42.992603: step 2763, loss 0.0141097, acc 1
2020-02-08T03:08:43.108325: step 2764, loss 0.0505389, acc 0.96875
2020-02-08T03:08:43.223564: step 2765, loss 0.0473618, acc 0.984375
2020-02-08T03:08:43.339916: step 2766, loss 0.0134701, acc 1
2020-02-08T03:08:43.455453: step 2767, loss 0.0199311, acc 0.984375
2020-02-08T03:08:43.571079: step 2768, loss 0.017448, acc 1
2020-02-08T03:08:43.689321: step 2769, loss 0.0456874, acc 0.984375
2020-02-08T03:08:43.805769: step 2770, loss 0.0152165, acc 1
2020-02-08T03:08:43.923647: step 2771, loss 0.0248909, acc 1
2020-02-08T03:08:44.041890: step 2772, loss 0.0530188, acc 0.984375
2020-02-08T03:08:44.159475: step 2773, loss 0.0230313, acc 1
2020-02-08T03:08:44.278215: step 2774, loss 0.00482294, acc 1
2020-02-08T03:08:44.395710: step 2775, loss 0.0502365, acc 0.96875
2020-02-08T03:08:44.513601: step 2776, loss 0.0452755, acc 0.984375
2020-02-08T03:08:44.628456: step 2777, loss 0.033235, acc 0.96875
2020-02-08T03:08:44.746370: step 2778, loss 0.00678656, acc 1
2020-02-08T03:08:44.864133: step 2779, loss 0.0422565, acc 1
2020-02-08T03:08:44.982791: step 2780, loss 0.0294366, acc 1
2020-02-08T03:08:45.101344: step 2781, loss 0.0134274, acc 1
2020-02-08T03:08:45.217959: step 2782, loss 0.00730484, acc 1
2020-02-08T03:08:45.335542: step 2783, loss 0.0107563, acc 1
2020-02-08T03:08:45.453019: step 2784, loss 0.0433384, acc 0.984375
2020-02-08T03:08:45.568165: step 2785, loss 0.0183393, acc 1
2020-02-08T03:08:45.684964: step 2786, loss 0.00901752, acc 1
2020-02-08T03:08:45.802711: step 2787, loss 0.0182502, acc 1
2020-02-08T03:08:45.922876: step 2788, loss 0.0160502, acc 1
2020-02-08T03:08:46.039606: step 2789, loss 0.00805309, acc 1
2020-02-08T03:08:46.159418: step 2790, loss 0.0483326, acc 0.984375
2020-02-08T03:08:46.277855: step 2791, loss 0.0377924, acc 0.96875
2020-02-08T03:08:46.391396: step 2792, loss 0.0522494, acc 0.984375
2020-02-08T03:08:46.508101: step 2793, loss 0.0581032, acc 0.953125
2020-02-08T03:08:46.626364: step 2794, loss 0.00789166, acc 1
2020-02-08T03:08:46.744402: step 2795, loss 0.0250947, acc 1
2020-02-08T03:08:46.861221: step 2796, loss 0.0612978, acc 0.984375
2020-02-08T03:08:46.982017: step 2797, loss 0.0121011, acc 1
2020-02-08T03:08:47.096975: step 2798, loss 0.081681, acc 0.984375
2020-02-08T03:08:47.212246: step 2799, loss 0.0124726, acc 1
2020-02-08T03:08:47.328156: step 2800, loss 0.022238, acc 1

Evaluation:
2020-02-08T03:08:47.516693: step 2800, loss 0.967826, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2800

2020-02-08T03:08:48.984055: step 2801, loss 0.013833, acc 1
2020-02-08T03:08:49.099532: step 2802, loss 0.0603542, acc 0.984375
2020-02-08T03:08:49.216452: step 2803, loss 0.0146737, acc 1
2020-02-08T03:08:49.332902: step 2804, loss 0.0414431, acc 0.96875
2020-02-08T03:08:49.447526: step 2805, loss 0.0110469, acc 1
2020-02-08T03:08:49.564584: step 2806, loss 0.0151026, acc 1
2020-02-08T03:08:49.682008: step 2807, loss 0.0151517, acc 1
2020-02-08T03:08:49.797057: step 2808, loss 0.0598125, acc 0.96875
2020-02-08T03:08:49.915030: step 2809, loss 0.00959054, acc 1
2020-02-08T03:08:50.031905: step 2810, loss 0.0353471, acc 0.984375
2020-02-08T03:08:50.150052: step 2811, loss 0.103226, acc 0.96875
2020-02-08T03:08:50.269962: step 2812, loss 0.0369503, acc 0.984375
2020-02-08T03:08:50.391069: step 2813, loss 0.0328531, acc 0.984375
2020-02-08T03:08:50.597594: step 2814, loss 0.00738095, acc 1
2020-02-08T03:08:50.742520: step 2815, loss 0.0173674, acc 1
2020-02-08T03:08:50.872388: step 2816, loss 0.0128279, acc 1
2020-02-08T03:08:51.012647: step 2817, loss 0.0102645, acc 1
2020-02-08T03:08:51.144410: step 2818, loss 0.0335521, acc 1
2020-02-08T03:08:51.277511: step 2819, loss 0.0219114, acc 1
2020-02-08T03:08:51.624389: step 2820, loss 0.0180891, acc 1
2020-02-08T03:08:51.769935: step 2821, loss 0.00615108, acc 1
2020-02-08T03:08:51.902052: step 2822, loss 0.0122012, acc 1
2020-02-08T03:08:52.030568: step 2823, loss 0.0094305, acc 1
2020-02-08T03:08:52.167699: step 2824, loss 0.0294726, acc 0.984375
2020-02-08T03:08:52.295370: step 2825, loss 0.0168623, acc 1
2020-02-08T03:08:52.421194: step 2826, loss 0.00594602, acc 1
2020-02-08T03:08:52.551010: step 2827, loss 0.0260823, acc 1
2020-02-08T03:08:52.680266: step 2828, loss 0.0478322, acc 0.96875
2020-02-08T03:08:52.813199: step 2829, loss 0.0132834, acc 1
2020-02-08T03:08:52.945180: step 2830, loss 0.0179383, acc 1
2020-02-08T03:08:53.083632: step 2831, loss 0.0109978, acc 1
2020-02-08T03:08:53.212608: step 2832, loss 0.0061177, acc 1
2020-02-08T03:08:53.340072: step 2833, loss 0.00750328, acc 1
2020-02-08T03:08:53.460573: step 2834, loss 0.0222011, acc 0.984375
2020-02-08T03:08:53.593265: step 2835, loss 0.0116758, acc 1
2020-02-08T03:08:53.719258: step 2836, loss 0.0954564, acc 0.96875
2020-02-08T03:08:53.841774: step 2837, loss 0.0237755, acc 0.984375
2020-02-08T03:08:53.979647: step 2838, loss 0.0105212, acc 1
2020-02-08T03:08:54.114627: step 2839, loss 0.0140219, acc 1
2020-02-08T03:08:54.247466: step 2840, loss 0.0305953, acc 0.984375
2020-02-08T03:08:54.393364: step 2841, loss 0.018777, acc 1
2020-02-08T03:08:54.536620: step 2842, loss 0.00760447, acc 1
2020-02-08T03:08:54.668639: step 2843, loss 0.0114889, acc 1
2020-02-08T03:08:54.796925: step 2844, loss 0.0320053, acc 0.984375
2020-02-08T03:08:54.939386: step 2845, loss 0.0489984, acc 0.984375
2020-02-08T03:08:55.077849: step 2846, loss 0.017413, acc 1
2020-02-08T03:08:55.221109: step 2847, loss 0.013499, acc 1
2020-02-08T03:08:55.357417: step 2848, loss 0.0501683, acc 0.984375
2020-02-08T03:08:55.496776: step 2849, loss 0.0876614, acc 0.984375
2020-02-08T03:08:55.629656: step 2850, loss 0.0218612, acc 1
2020-02-08T03:08:55.777932: step 2851, loss 0.0571784, acc 0.96875
2020-02-08T03:08:55.918604: step 2852, loss 0.0043813, acc 1
2020-02-08T03:08:56.060008: step 2853, loss 0.00658008, acc 1
2020-02-08T03:08:56.198851: step 2854, loss 0.0065167, acc 1
2020-02-08T03:08:56.340907: step 2855, loss 0.024452, acc 0.984375
2020-02-08T03:08:56.478818: step 2856, loss 0.00663045, acc 1
2020-02-08T03:08:56.616965: step 2857, loss 0.00426574, acc 1
2020-02-08T03:08:56.758114: step 2858, loss 0.00904656, acc 1
2020-02-08T03:08:56.898275: step 2859, loss 0.0591734, acc 0.96875
2020-02-08T03:08:57.039306: step 2860, loss 0.00310585, acc 1
2020-02-08T03:08:57.176882: step 2861, loss 0.0271218, acc 0.984375
2020-02-08T03:08:57.310467: step 2862, loss 0.0199998, acc 1
2020-02-08T03:08:57.449851: step 2863, loss 0.0170582, acc 1
2020-02-08T03:08:57.587526: step 2864, loss 0.0953262, acc 0.96875
2020-02-08T03:08:57.727770: step 2865, loss 0.037446, acc 0.984375
2020-02-08T03:08:57.858506: step 2866, loss 0.0104049, acc 1
2020-02-08T03:08:57.988976: step 2867, loss 0.0231204, acc 0.984375
2020-02-08T03:08:58.128369: step 2868, loss 0.0114971, acc 1
2020-02-08T03:08:58.268341: step 2869, loss 0.00911611, acc 1
2020-02-08T03:08:58.406547: step 2870, loss 0.0103464, acc 1
2020-02-08T03:08:58.541567: step 2871, loss 0.0265218, acc 0.984375
2020-02-08T03:08:58.676085: step 2872, loss 0.0202664, acc 1
2020-02-08T03:08:58.812147: step 2873, loss 0.0107968, acc 1
2020-02-08T03:08:58.952046: step 2874, loss 0.0283268, acc 0.984375
2020-02-08T03:08:59.078508: step 2875, loss 0.0169015, acc 1
2020-02-08T03:08:59.203969: step 2876, loss 0.0163465, acc 1
2020-02-08T03:08:59.331565: step 2877, loss 0.0225764, acc 0.984375
2020-02-08T03:08:59.461825: step 2878, loss 0.0199031, acc 1
2020-02-08T03:08:59.578636: step 2879, loss 0.0137287, acc 1
2020-02-08T03:08:59.695927: step 2880, loss 0.0173336, acc 1
2020-02-08T03:08:59.815465: step 2881, loss 0.0531581, acc 0.984375
2020-02-08T03:08:59.937239: step 2882, loss 0.0149536, acc 1
2020-02-08T03:09:00.066279: step 2883, loss 0.029083, acc 0.984375
2020-02-08T03:09:00.188173: step 2884, loss 0.00935483, acc 1
2020-02-08T03:09:00.306920: step 2885, loss 0.0124143, acc 1
2020-02-08T03:09:00.425055: step 2886, loss 0.0160011, acc 1
2020-02-08T03:09:00.541903: step 2887, loss 0.0215805, acc 0.984375
2020-02-08T03:09:00.663888: step 2888, loss 0.0344633, acc 0.984375
2020-02-08T03:09:00.785558: step 2889, loss 0.0055286, acc 1
2020-02-08T03:09:00.908218: step 2890, loss 0.0107161, acc 1
2020-02-08T03:09:01.038010: step 2891, loss 0.0189742, acc 1
2020-02-08T03:09:01.160974: step 2892, loss 0.00785106, acc 1
2020-02-08T03:09:01.280168: step 2893, loss 0.00735659, acc 1
2020-02-08T03:09:01.396700: step 2894, loss 0.00579523, acc 1
2020-02-08T03:09:01.529736: step 2895, loss 0.0143887, acc 1
2020-02-08T03:09:01.648067: step 2896, loss 0.0100926, acc 1
2020-02-08T03:09:01.765451: step 2897, loss 0.00718788, acc 1
2020-02-08T03:09:01.885901: step 2898, loss 0.0138923, acc 1
2020-02-08T03:09:02.002668: step 2899, loss 0.0120702, acc 1
2020-02-08T03:09:02.122591: step 2900, loss 0.0173913, acc 1

Evaluation:
2020-02-08T03:09:02.309749: step 2900, loss 0.979597, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-2900

2020-02-08T03:09:03.926173: step 2901, loss 0.00936689, acc 1
2020-02-08T03:09:04.042919: step 2902, loss 0.0130884, acc 1
2020-02-08T03:09:04.161179: step 2903, loss 0.0136779, acc 1
2020-02-08T03:09:04.278835: step 2904, loss 0.00780851, acc 1
2020-02-08T03:09:04.393969: step 2905, loss 0.0561745, acc 0.96875
2020-02-08T03:09:04.510753: step 2906, loss 0.023033, acc 1
2020-02-08T03:09:04.627436: step 2907, loss 0.0137718, acc 1
2020-02-08T03:09:04.745337: step 2908, loss 0.0156718, acc 1
2020-02-08T03:09:04.863185: step 2909, loss 0.0503336, acc 0.984375
2020-02-08T03:09:04.980055: step 2910, loss 0.0509853, acc 0.984375
2020-02-08T03:09:05.096426: step 2911, loss 0.00947722, acc 1
2020-02-08T03:09:05.214553: step 2912, loss 0.0170082, acc 1
2020-02-08T03:09:05.333318: step 2913, loss 0.0182348, acc 1
2020-02-08T03:09:05.449316: step 2914, loss 0.00522533, acc 1
2020-02-08T03:09:05.568104: step 2915, loss 0.0117046, acc 1
2020-02-08T03:09:05.683745: step 2916, loss 0.00735612, acc 1
2020-02-08T03:09:05.807305: step 2917, loss 0.0233732, acc 0.984375
2020-02-08T03:09:05.927889: step 2918, loss 0.0140962, acc 1
2020-02-08T03:09:06.045507: step 2919, loss 0.0519409, acc 0.984375
2020-02-08T03:09:06.163862: step 2920, loss 0.00909701, acc 1
2020-02-08T03:09:06.282513: step 2921, loss 0.05401, acc 0.96875
2020-02-08T03:09:06.399153: step 2922, loss 0.0309644, acc 0.984375
2020-02-08T03:09:06.517701: step 2923, loss 0.00834895, acc 1
2020-02-08T03:09:06.635411: step 2924, loss 0.0110117, acc 1
2020-02-08T03:09:06.752392: step 2925, loss 0.0082677, acc 1
2020-02-08T03:09:06.872404: step 2926, loss 0.0138052, acc 1
2020-02-08T03:09:06.989291: step 2927, loss 0.00424631, acc 1
2020-02-08T03:09:07.106887: step 2928, loss 0.0354082, acc 0.984375
2020-02-08T03:09:07.223508: step 2929, loss 0.0324714, acc 0.984375
2020-02-08T03:09:07.339520: step 2930, loss 0.0387817, acc 0.984375
2020-02-08T03:09:07.455914: step 2931, loss 0.0338489, acc 1
2020-02-08T03:09:07.573603: step 2932, loss 0.0168239, acc 1
2020-02-08T03:09:07.690846: step 2933, loss 0.00538124, acc 1
2020-02-08T03:09:07.809286: step 2934, loss 0.0272576, acc 1
2020-02-08T03:09:07.929009: step 2935, loss 0.0268794, acc 0.984375
2020-02-08T03:09:08.046036: step 2936, loss 0.0177847, acc 1
2020-02-08T03:09:08.163558: step 2937, loss 0.040804, acc 0.984375
2020-02-08T03:09:08.282325: step 2938, loss 0.051927, acc 0.984375
2020-02-08T03:09:08.397674: step 2939, loss 0.0419034, acc 0.984375
2020-02-08T03:09:08.515178: step 2940, loss 0.0112968, acc 1
2020-02-08T03:09:08.631146: step 2941, loss 0.0551845, acc 0.96875
2020-02-08T03:09:08.747809: step 2942, loss 0.0158891, acc 1
2020-02-08T03:09:08.867374: step 2943, loss 0.0363182, acc 0.984375
2020-02-08T03:09:08.984996: step 2944, loss 0.0371469, acc 0.984375
2020-02-08T03:09:09.100138: step 2945, loss 0.0399173, acc 0.96875
2020-02-08T03:09:09.219421: step 2946, loss 0.00524657, acc 1
2020-02-08T03:09:09.336079: step 2947, loss 0.042647, acc 0.984375
2020-02-08T03:09:09.455482: step 2948, loss 0.0408319, acc 0.984375
2020-02-08T03:09:09.575942: step 2949, loss 0.0375464, acc 0.984375
2020-02-08T03:09:09.694379: step 2950, loss 0.0241573, acc 1
2020-02-08T03:09:09.812668: step 2951, loss 0.0141332, acc 1
2020-02-08T03:09:09.930852: step 2952, loss 0.00814569, acc 1
2020-02-08T03:09:10.047527: step 2953, loss 0.0179345, acc 1
2020-02-08T03:09:10.163400: step 2954, loss 0.00556172, acc 1
2020-02-08T03:09:10.280515: step 2955, loss 0.0112952, acc 1
2020-02-08T03:09:10.396806: step 2956, loss 0.0378294, acc 0.984375
2020-02-08T03:09:10.512801: step 2957, loss 0.00832665, acc 1
2020-02-08T03:09:10.630467: step 2958, loss 0.0200754, acc 0.984375
2020-02-08T03:09:10.743928: step 2959, loss 0.0312449, acc 0.984375
2020-02-08T03:09:10.863386: step 2960, loss 0.0235671, acc 1
2020-02-08T03:09:10.980331: step 2961, loss 0.00867436, acc 1
2020-02-08T03:09:11.096506: step 2962, loss 0.0125087, acc 1
2020-02-08T03:09:11.213412: step 2963, loss 0.0131535, acc 1
2020-02-08T03:09:11.332444: step 2964, loss 0.0573518, acc 0.984375
2020-02-08T03:09:11.448698: step 2965, loss 0.00592223, acc 1
2020-02-08T03:09:11.571502: step 2966, loss 0.0137746, acc 1
2020-02-08T03:09:11.687475: step 2967, loss 0.0369207, acc 0.984375
2020-02-08T03:09:11.802544: step 2968, loss 0.0152053, acc 1
2020-02-08T03:09:11.919497: step 2969, loss 0.0410655, acc 0.984375
2020-02-08T03:09:12.035655: step 2970, loss 0.0536678, acc 0.984375
2020-02-08T03:09:12.152232: step 2971, loss 0.0205752, acc 0.984375
2020-02-08T03:09:12.270063: step 2972, loss 0.00948217, acc 1
2020-02-08T03:09:12.386276: step 2973, loss 0.0245935, acc 0.984375
2020-02-08T03:09:12.503838: step 2974, loss 0.00638827, acc 1
2020-02-08T03:09:12.619129: step 2975, loss 0.0500467, acc 0.984375
2020-02-08T03:09:12.737193: step 2976, loss 0.0134418, acc 1
2020-02-08T03:09:12.852811: step 2977, loss 0.00966484, acc 1
2020-02-08T03:09:12.969804: step 2978, loss 0.0248001, acc 1
2020-02-08T03:09:13.086338: step 2979, loss 0.00980064, acc 1
2020-02-08T03:09:13.202155: step 2980, loss 0.0172468, acc 1
2020-02-08T03:09:13.318487: step 2981, loss 0.0217272, acc 0.984375
2020-02-08T03:09:13.436500: step 2982, loss 0.0245119, acc 1
2020-02-08T03:09:13.552760: step 2983, loss 0.0152589, acc 0.984375
2020-02-08T03:09:13.672521: step 2984, loss 0.0334608, acc 0.96875
2020-02-08T03:09:13.789073: step 2985, loss 0.00295618, acc 1
2020-02-08T03:09:13.908829: step 2986, loss 0.0189705, acc 1
2020-02-08T03:09:14.028025: step 2987, loss 0.0583688, acc 0.984375
2020-02-08T03:09:14.145081: step 2988, loss 0.00728453, acc 1
2020-02-08T03:09:14.262955: step 2989, loss 0.0215565, acc 1
2020-02-08T03:09:14.379687: step 2990, loss 0.00821606, acc 1
2020-02-08T03:09:14.494609: step 2991, loss 0.0244383, acc 1
2020-02-08T03:09:14.613830: step 2992, loss 0.0197729, acc 1
2020-02-08T03:09:14.732124: step 2993, loss 0.0221381, acc 1
2020-02-08T03:09:14.845701: step 2994, loss 0.0530669, acc 0.984375
2020-02-08T03:09:14.963469: step 2995, loss 0.00476494, acc 1
2020-02-08T03:09:15.078429: step 2996, loss 0.0638309, acc 0.953125
2020-02-08T03:09:15.194623: step 2997, loss 0.0116452, acc 1
2020-02-08T03:09:15.310799: step 2998, loss 0.0201912, acc 0.984375
2020-02-08T03:09:15.429810: step 2999, loss 0.0312665, acc 1
2020-02-08T03:09:15.543213: step 3000, loss 0.0235923, acc 1

Evaluation:
2020-02-08T03:09:15.731053: step 3000, loss 1.02654, acc 0.731707

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102143/checkpoints/model-3000

