WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:41:21.507023 4585827776 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:41:21.507312 4585827776 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:41:21.507452 4585827776 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:41:22.018497 4585827776 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:41:22.018742 4585827776 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:41:22.018951: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:41:22.031293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff168a551a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:41:22.031315: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:41:22.031674 4585827776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:41:22.034905 4585827776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:41:22.047053 4585827776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:41:22.061176 4585827776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:41:22.084111 4585827776 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:41:22.092177 4585827776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:41:22.092395 4585827776 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:41:22.108753 4585827776 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:41:22.112607 4585827776 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:41:22.138551 4585827776 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:41:22.380060 4585827776 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:41:22.380292 4585827776 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:41:22.385487 4585827776 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:41:22.409006 4585827776 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:41:22.410666 4585827776 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:41:22.426038 4585827776 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:41:22.427090 4585827776 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:41:22.441087 4585827776 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:41:22.442121 4585827776 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:41:22.463636 4585827776 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:41:22.464712 4585827776 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:41:22.479333 4585827776 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:41:22.480377 4585827776 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:41:22.495041 4585827776 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:41:22.496885 4585827776 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:41:22.517077 4585827776 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:41:22.518143 4585827776 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:41:22.532130 4585827776 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:41:22.533166 4585827776 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:41:22.549685 4585827776 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:41:22.551522 4585827776 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:41:22.557241 4585827776 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:41:22.869635 4585827776 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:41:22.869820 4585827776 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:41:23.016131 4585827776 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:41:23.582746 4585827776 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:42:48.602694 4585827776 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882

2020-02-08T02:41:23.582317: step 1, loss 2.40985, acc 0.296875
2020-02-08T02:41:23.717221: step 2, loss 1.88803, acc 0.53125
2020-02-08T02:41:23.834086: step 3, loss 2.09975, acc 0.515625
2020-02-08T02:41:23.951583: step 4, loss 1.69481, acc 0.53125
2020-02-08T02:41:24.071602: step 5, loss 1.64011, acc 0.578125
2020-02-08T02:41:24.187593: step 6, loss 1.80595, acc 0.484375
2020-02-08T02:41:24.305668: step 7, loss 2.30366, acc 0.453125
2020-02-08T02:41:24.426665: step 8, loss 1.73415, acc 0.53125
2020-02-08T02:41:24.542865: step 9, loss 2.07423, acc 0.4375
2020-02-08T02:41:24.661117: step 10, loss 1.40703, acc 0.625
2020-02-08T02:41:24.781736: step 11, loss 1.4136, acc 0.640625
2020-02-08T02:41:24.898233: step 12, loss 1.43058, acc 0.609375
2020-02-08T02:41:25.015884: step 13, loss 1.95021, acc 0.578125
2020-02-08T02:41:25.133942: step 14, loss 2.24068, acc 0.5
2020-02-08T02:41:25.250723: step 15, loss 2.18218, acc 0.515625
2020-02-08T02:41:25.369588: step 16, loss 2.38813, acc 0.4375
2020-02-08T02:41:25.483346: step 17, loss 1.75782, acc 0.46875
2020-02-08T02:41:25.600505: step 18, loss 1.98587, acc 0.515625
2020-02-08T02:41:25.717988: step 19, loss 1.83442, acc 0.5
2020-02-08T02:41:25.835602: step 20, loss 1.88179, acc 0.4375
2020-02-08T02:41:25.954404: step 21, loss 2.16824, acc 0.46875
2020-02-08T02:41:26.070471: step 22, loss 1.2519, acc 0.59375
2020-02-08T02:41:26.188654: step 23, loss 1.60774, acc 0.5625
2020-02-08T02:41:26.306589: step 24, loss 2.03495, acc 0.453125
2020-02-08T02:41:26.423486: step 25, loss 1.94158, acc 0.515625
2020-02-08T02:41:26.539594: step 26, loss 2.01169, acc 0.5
2020-02-08T02:41:26.654916: step 27, loss 2.0839, acc 0.40625
2020-02-08T02:41:26.777613: step 28, loss 2.15649, acc 0.4375
2020-02-08T02:41:26.891351: step 29, loss 1.61569, acc 0.546875
2020-02-08T02:41:27.010046: step 30, loss 1.79927, acc 0.546875
2020-02-08T02:41:27.128245: step 31, loss 1.53379, acc 0.5
2020-02-08T02:41:27.244862: step 32, loss 1.4141, acc 0.5625
2020-02-08T02:41:27.360642: step 33, loss 1.29013, acc 0.640625
2020-02-08T02:41:27.476735: step 34, loss 2.02897, acc 0.375
2020-02-08T02:41:27.591233: step 35, loss 2.11555, acc 0.53125
2020-02-08T02:41:27.708128: step 36, loss 1.42826, acc 0.546875
2020-02-08T02:41:27.824787: step 37, loss 1.69832, acc 0.484375
2020-02-08T02:41:27.942189: step 38, loss 1.54704, acc 0.5625
2020-02-08T02:41:28.057145: step 39, loss 1.85812, acc 0.4375
2020-02-08T02:41:28.174174: step 40, loss 1.98441, acc 0.515625
2020-02-08T02:41:28.291031: step 41, loss 1.74139, acc 0.5
2020-02-08T02:41:28.406266: step 42, loss 1.6561, acc 0.53125
2020-02-08T02:41:28.523421: step 43, loss 1.98465, acc 0.4375
2020-02-08T02:41:28.641197: step 44, loss 1.0616, acc 0.609375
2020-02-08T02:41:28.764077: step 45, loss 1.63858, acc 0.546875
2020-02-08T02:41:28.880465: step 46, loss 1.87299, acc 0.5
2020-02-08T02:41:28.997310: step 47, loss 1.8082, acc 0.515625
2020-02-08T02:41:29.112450: step 48, loss 1.25428, acc 0.5625
2020-02-08T02:41:29.230977: step 49, loss 1.97624, acc 0.546875
2020-02-08T02:41:29.347830: step 50, loss 1.80997, acc 0.4375
2020-02-08T02:41:29.463000: step 51, loss 1.66837, acc 0.546875
2020-02-08T02:41:29.581663: step 52, loss 1.36857, acc 0.546875
2020-02-08T02:41:29.697648: step 53, loss 1.61381, acc 0.5625
2020-02-08T02:41:29.819225: step 54, loss 1.76009, acc 0.46875
2020-02-08T02:41:29.935958: step 55, loss 1.91867, acc 0.5
2020-02-08T02:41:30.051942: step 56, loss 1.25233, acc 0.546875
2020-02-08T02:41:30.167784: step 57, loss 1.78913, acc 0.53125
2020-02-08T02:41:30.286854: step 58, loss 1.73023, acc 0.484375
2020-02-08T02:41:30.404294: step 59, loss 1.65178, acc 0.53125
2020-02-08T02:41:30.523015: step 60, loss 1.44909, acc 0.484375
2020-02-08T02:41:30.641009: step 61, loss 2.169, acc 0.453125
2020-02-08T02:41:30.765184: step 62, loss 1.39631, acc 0.5625
2020-02-08T02:41:30.883363: step 63, loss 1.18412, acc 0.640625
2020-02-08T02:41:31.001232: step 64, loss 1.6682, acc 0.421875
2020-02-08T02:41:31.118623: step 65, loss 1.51764, acc 0.515625
2020-02-08T02:41:31.235276: step 66, loss 1.51854, acc 0.578125
2020-02-08T02:41:31.352705: step 67, loss 1.59177, acc 0.5
2020-02-08T02:41:31.470662: step 68, loss 1.36189, acc 0.53125
2020-02-08T02:41:31.590041: step 69, loss 1.48348, acc 0.484375
2020-02-08T02:41:31.707280: step 70, loss 1.23452, acc 0.625
2020-02-08T02:41:31.825165: step 71, loss 1.29027, acc 0.578125
2020-02-08T02:41:31.943284: step 72, loss 2.17327, acc 0.4375
2020-02-08T02:41:32.062341: step 73, loss 1.47585, acc 0.625
2020-02-08T02:41:32.179522: step 74, loss 1.72081, acc 0.453125
2020-02-08T02:41:32.297959: step 75, loss 1.4463, acc 0.5625
2020-02-08T02:41:32.413762: step 76, loss 1.71486, acc 0.46875
2020-02-08T02:41:32.532990: step 77, loss 1.21714, acc 0.59375
2020-02-08T02:41:32.650924: step 78, loss 1.66834, acc 0.46875
2020-02-08T02:41:32.772886: step 79, loss 1.54281, acc 0.53125
2020-02-08T02:41:32.889930: step 80, loss 1.76288, acc 0.453125
2020-02-08T02:41:33.006164: step 81, loss 1.26485, acc 0.546875
2020-02-08T02:41:33.124967: step 82, loss 1.18836, acc 0.59375
2020-02-08T02:41:33.242284: step 83, loss 1.77669, acc 0.453125
2020-02-08T02:41:33.360127: step 84, loss 0.877425, acc 0.671875
2020-02-08T02:41:33.476132: step 85, loss 1.71735, acc 0.5
2020-02-08T02:41:33.590754: step 86, loss 1.80338, acc 0.515625
2020-02-08T02:41:33.709328: step 87, loss 1.49622, acc 0.421875
2020-02-08T02:41:33.825873: step 88, loss 1.62394, acc 0.484375
2020-02-08T02:41:33.943793: step 89, loss 1.18941, acc 0.625
2020-02-08T02:41:34.061629: step 90, loss 1.59449, acc 0.546875
2020-02-08T02:41:34.182969: step 91, loss 1.49684, acc 0.5625
2020-02-08T02:41:34.299147: step 92, loss 1.33254, acc 0.515625
2020-02-08T02:41:34.417455: step 93, loss 1.4451, acc 0.625
2020-02-08T02:41:34.532651: step 94, loss 1.81546, acc 0.5
2020-02-08T02:41:34.649081: step 95, loss 1.67539, acc 0.46875
2020-02-08T02:41:34.771084: step 96, loss 1.46195, acc 0.53125
2020-02-08T02:41:34.889232: step 97, loss 1.2784, acc 0.5625
2020-02-08T02:41:35.005365: step 98, loss 1.32095, acc 0.53125
2020-02-08T02:41:35.124467: step 99, loss 1.63463, acc 0.546875
2020-02-08T02:41:35.240208: step 100, loss 1.73803, acc 0.484375

Evaluation:
2020-02-08T02:41:35.475796: step 100, loss 1.19407, acc 0.527205

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-100

2020-02-08T02:41:38.646198: step 101, loss 1.30869, acc 0.609375
2020-02-08T02:41:38.766397: step 102, loss 1.44308, acc 0.5625
2020-02-08T02:41:38.885997: step 103, loss 1.17226, acc 0.578125
2020-02-08T02:41:39.003407: step 104, loss 1.29769, acc 0.53125
2020-02-08T02:41:39.122753: step 105, loss 1.09504, acc 0.625
2020-02-08T02:41:39.238774: step 106, loss 1.31029, acc 0.546875
2020-02-08T02:41:39.357050: step 107, loss 1.42173, acc 0.53125
2020-02-08T02:41:39.473657: step 108, loss 0.992858, acc 0.546875
2020-02-08T02:41:39.590998: step 109, loss 1.88124, acc 0.5
2020-02-08T02:41:39.710198: step 110, loss 1.05289, acc 0.640625
2020-02-08T02:41:39.826426: step 111, loss 1.11699, acc 0.640625
2020-02-08T02:41:39.942086: step 112, loss 1.04102, acc 0.640625
2020-02-08T02:41:40.060971: step 113, loss 1.26367, acc 0.546875
2020-02-08T02:41:40.183221: step 114, loss 1.22192, acc 0.59375
2020-02-08T02:41:40.300291: step 115, loss 1.41863, acc 0.453125
2020-02-08T02:41:40.416581: step 116, loss 1.29702, acc 0.5625
2020-02-08T02:41:40.531517: step 117, loss 1.18764, acc 0.59375
2020-02-08T02:41:40.647238: step 118, loss 1.59367, acc 0.453125
2020-02-08T02:41:40.770553: step 119, loss 1.23278, acc 0.59375
2020-02-08T02:41:40.887916: step 120, loss 1.35006, acc 0.5625
2020-02-08T02:41:41.004134: step 121, loss 1.53326, acc 0.53125
2020-02-08T02:41:41.120985: step 122, loss 1.33479, acc 0.453125
2020-02-08T02:41:41.240151: step 123, loss 1.18377, acc 0.625
2020-02-08T02:41:41.359726: step 124, loss 1.50255, acc 0.515625
2020-02-08T02:41:41.475262: step 125, loss 1.51348, acc 0.515625
2020-02-08T02:41:41.593645: step 126, loss 1.38168, acc 0.46875
2020-02-08T02:41:41.713279: step 127, loss 1.13251, acc 0.515625
2020-02-08T02:41:41.830787: step 128, loss 0.969213, acc 0.640625
2020-02-08T02:41:41.947737: step 129, loss 1.0957, acc 0.578125
2020-02-08T02:41:42.064543: step 130, loss 1.09862, acc 0.640625
2020-02-08T02:41:42.181436: step 131, loss 1.50379, acc 0.5
2020-02-08T02:41:42.297633: step 132, loss 1.25521, acc 0.609375
2020-02-08T02:41:42.414464: step 133, loss 1.08575, acc 0.453125
2020-02-08T02:41:42.531836: step 134, loss 1.43968, acc 0.46875
2020-02-08T02:41:42.650137: step 135, loss 0.997954, acc 0.671875
2020-02-08T02:41:42.773649: step 136, loss 1.18692, acc 0.53125
2020-02-08T02:41:42.889794: step 137, loss 1.16965, acc 0.4375
2020-02-08T02:41:43.012770: step 138, loss 1.20882, acc 0.546875
2020-02-08T02:41:43.129631: step 139, loss 1.28488, acc 0.53125
2020-02-08T02:41:43.248090: step 140, loss 1.29203, acc 0.515625
2020-02-08T02:41:43.371830: step 141, loss 1.31012, acc 0.546875
2020-02-08T02:41:43.488590: step 142, loss 1.10111, acc 0.59375
2020-02-08T02:41:43.607838: step 143, loss 1.29551, acc 0.515625
2020-02-08T02:41:43.725310: step 144, loss 1.14461, acc 0.5625
2020-02-08T02:41:43.841920: step 145, loss 1.29365, acc 0.4375
2020-02-08T02:41:43.960680: step 146, loss 1.16538, acc 0.515625
2020-02-08T02:41:44.077325: step 147, loss 1.24374, acc 0.5625
2020-02-08T02:41:44.195522: step 148, loss 1.5007, acc 0.453125
2020-02-08T02:41:44.315557: step 149, loss 0.941155, acc 0.65625
2020-02-08T02:41:44.429877: step 150, loss 1.28271, acc 0.516667
2020-02-08T02:41:44.549080: step 151, loss 1.15778, acc 0.578125
2020-02-08T02:41:44.667832: step 152, loss 0.749388, acc 0.75
2020-02-08T02:41:44.786703: step 153, loss 1.21987, acc 0.484375
2020-02-08T02:41:44.905530: step 154, loss 0.87823, acc 0.65625
2020-02-08T02:41:45.021397: step 155, loss 0.953027, acc 0.546875
2020-02-08T02:41:45.136100: step 156, loss 0.661761, acc 0.6875
2020-02-08T02:41:45.253363: step 157, loss 1.08248, acc 0.65625
2020-02-08T02:41:45.371021: step 158, loss 0.80531, acc 0.6875
2020-02-08T02:41:45.487435: step 159, loss 0.822977, acc 0.625
2020-02-08T02:41:45.603559: step 160, loss 1.38221, acc 0.46875
2020-02-08T02:41:45.724484: step 161, loss 0.837872, acc 0.625
2020-02-08T02:41:45.840606: step 162, loss 1.17459, acc 0.5625
2020-02-08T02:41:45.959014: step 163, loss 0.91927, acc 0.59375
2020-02-08T02:41:46.076807: step 164, loss 0.667158, acc 0.671875
2020-02-08T02:41:46.191824: step 165, loss 0.740837, acc 0.625
2020-02-08T02:41:46.309529: step 166, loss 0.956011, acc 0.625
2020-02-08T02:41:46.427725: step 167, loss 1.027, acc 0.546875
2020-02-08T02:41:46.541722: step 168, loss 0.930985, acc 0.53125
2020-02-08T02:41:46.659077: step 169, loss 0.879972, acc 0.59375
2020-02-08T02:41:46.780412: step 170, loss 1.03204, acc 0.625
2020-02-08T02:41:46.896976: step 171, loss 1.01016, acc 0.625
2020-02-08T02:41:47.014569: step 172, loss 1.05161, acc 0.609375
2020-02-08T02:41:47.130560: step 173, loss 0.992519, acc 0.546875
2020-02-08T02:41:47.245428: step 174, loss 0.981984, acc 0.578125
2020-02-08T02:41:47.362743: step 175, loss 0.746677, acc 0.6875
2020-02-08T02:41:47.478947: step 176, loss 0.828875, acc 0.625
2020-02-08T02:41:47.595759: step 177, loss 1.00955, acc 0.59375
2020-02-08T02:41:47.712977: step 178, loss 0.867303, acc 0.578125
2020-02-08T02:41:47.832068: step 179, loss 0.890623, acc 0.53125
2020-02-08T02:41:47.947551: step 180, loss 1.03455, acc 0.5625
2020-02-08T02:41:48.062976: step 181, loss 0.778084, acc 0.65625
2020-02-08T02:41:48.180496: step 182, loss 0.961823, acc 0.59375
2020-02-08T02:41:48.297129: step 183, loss 1.02725, acc 0.546875
2020-02-08T02:41:48.414850: step 184, loss 0.670796, acc 0.703125
2020-02-08T02:41:48.532106: step 185, loss 1.18031, acc 0.53125
2020-02-08T02:41:48.646062: step 186, loss 0.863138, acc 0.65625
2020-02-08T02:41:48.768982: step 187, loss 0.878896, acc 0.5625
2020-02-08T02:41:48.885086: step 188, loss 1.07056, acc 0.59375
2020-02-08T02:41:48.999126: step 189, loss 0.918507, acc 0.53125
2020-02-08T02:41:49.117031: step 190, loss 1.14346, acc 0.53125
2020-02-08T02:41:49.233441: step 191, loss 0.730603, acc 0.625
2020-02-08T02:41:49.346907: step 192, loss 1.20184, acc 0.515625
2020-02-08T02:41:49.466021: step 193, loss 0.760858, acc 0.671875
2020-02-08T02:41:49.584198: step 194, loss 0.963543, acc 0.578125
2020-02-08T02:41:49.700126: step 195, loss 1.24739, acc 0.46875
2020-02-08T02:41:49.821658: step 196, loss 0.925732, acc 0.5
2020-02-08T02:41:49.939238: step 197, loss 1.11225, acc 0.5625
2020-02-08T02:41:50.055520: step 198, loss 1.26561, acc 0.390625
2020-02-08T02:41:50.172901: step 199, loss 0.750157, acc 0.6875
2020-02-08T02:41:50.287571: step 200, loss 0.910164, acc 0.671875

Evaluation:
2020-02-08T02:41:50.474435: step 200, loss 0.682887, acc 0.570356

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-200

2020-02-08T02:41:51.963617: step 201, loss 0.815591, acc 0.625
2020-02-08T02:41:52.079673: step 202, loss 0.644645, acc 0.671875
2020-02-08T02:41:52.194900: step 203, loss 0.868478, acc 0.625
2020-02-08T02:41:52.367839: step 204, loss 0.878158, acc 0.59375
2020-02-08T02:41:52.482950: step 205, loss 0.859511, acc 0.546875
2020-02-08T02:41:52.599365: step 206, loss 0.798363, acc 0.671875
2020-02-08T02:41:52.732354: step 207, loss 0.751532, acc 0.640625
2020-02-08T02:41:52.861311: step 208, loss 0.721633, acc 0.640625
2020-02-08T02:41:52.982216: step 209, loss 0.756573, acc 0.640625
2020-02-08T02:41:53.098334: step 210, loss 0.970114, acc 0.578125
2020-02-08T02:41:53.217539: step 211, loss 0.913513, acc 0.578125
2020-02-08T02:41:53.336040: step 212, loss 1.24163, acc 0.484375
2020-02-08T02:41:53.452568: step 213, loss 0.981599, acc 0.609375
2020-02-08T02:41:53.571973: step 214, loss 0.901937, acc 0.515625
2020-02-08T02:41:53.687321: step 215, loss 0.965106, acc 0.53125
2020-02-08T02:41:53.810357: step 216, loss 0.987431, acc 0.59375
2020-02-08T02:41:53.927068: step 217, loss 0.913461, acc 0.59375
2020-02-08T02:41:54.043575: step 218, loss 0.524803, acc 0.78125
2020-02-08T02:41:54.163637: step 219, loss 1.14814, acc 0.40625
2020-02-08T02:41:54.281228: step 220, loss 0.963822, acc 0.640625
2020-02-08T02:41:54.398879: step 221, loss 0.72405, acc 0.59375
2020-02-08T02:41:54.515630: step 222, loss 0.878398, acc 0.59375
2020-02-08T02:41:54.632330: step 223, loss 0.994401, acc 0.578125
2020-02-08T02:41:54.750072: step 224, loss 0.787573, acc 0.578125
2020-02-08T02:41:54.867912: step 225, loss 0.694992, acc 0.65625
2020-02-08T02:41:54.985320: step 226, loss 1.00666, acc 0.546875
2020-02-08T02:41:55.106027: step 227, loss 0.918253, acc 0.59375
2020-02-08T02:41:55.224568: step 228, loss 0.780033, acc 0.6875
2020-02-08T02:41:55.342018: step 229, loss 0.68974, acc 0.703125
2020-02-08T02:41:55.460226: step 230, loss 0.694187, acc 0.609375
2020-02-08T02:41:55.578137: step 231, loss 0.779261, acc 0.625
2020-02-08T02:41:55.692117: step 232, loss 0.766321, acc 0.625
2020-02-08T02:41:55.813546: step 233, loss 0.874904, acc 0.625
2020-02-08T02:41:55.928258: step 234, loss 0.750413, acc 0.71875
2020-02-08T02:41:56.042757: step 235, loss 0.918422, acc 0.59375
2020-02-08T02:41:56.160010: step 236, loss 0.817493, acc 0.546875
2020-02-08T02:41:56.277727: step 237, loss 0.99231, acc 0.5
2020-02-08T02:41:56.395076: step 238, loss 0.84252, acc 0.5625
2020-02-08T02:41:56.511307: step 239, loss 0.680439, acc 0.703125
2020-02-08T02:41:56.627839: step 240, loss 0.864732, acc 0.59375
2020-02-08T02:41:56.743916: step 241, loss 0.75624, acc 0.578125
2020-02-08T02:41:56.862087: step 242, loss 0.844415, acc 0.578125
2020-02-08T02:41:56.980873: step 243, loss 0.940319, acc 0.59375
2020-02-08T02:41:57.097502: step 244, loss 1.00574, acc 0.578125
2020-02-08T02:41:57.214525: step 245, loss 0.838653, acc 0.640625
2020-02-08T02:41:57.331866: step 246, loss 0.859638, acc 0.5625
2020-02-08T02:41:57.448512: step 247, loss 0.783095, acc 0.59375
2020-02-08T02:41:57.568333: step 248, loss 0.810876, acc 0.578125
2020-02-08T02:41:57.685479: step 249, loss 1.1206, acc 0.5
2020-02-08T02:41:57.807446: step 250, loss 0.758001, acc 0.609375
2020-02-08T02:41:57.925141: step 251, loss 0.650674, acc 0.6875
2020-02-08T02:41:58.039921: step 252, loss 0.894438, acc 0.5625
2020-02-08T02:41:58.157222: step 253, loss 0.820406, acc 0.578125
2020-02-08T02:41:58.275262: step 254, loss 0.880067, acc 0.578125
2020-02-08T02:41:58.393486: step 255, loss 0.690993, acc 0.625
2020-02-08T02:41:58.512966: step 256, loss 0.751357, acc 0.640625
2020-02-08T02:41:58.629811: step 257, loss 0.816958, acc 0.59375
2020-02-08T02:41:58.747928: step 258, loss 0.940515, acc 0.53125
2020-02-08T02:41:58.867063: step 259, loss 0.973136, acc 0.546875
2020-02-08T02:41:58.984437: step 260, loss 0.786054, acc 0.59375
2020-02-08T02:41:59.099450: step 261, loss 0.591803, acc 0.640625
2020-02-08T02:41:59.216298: step 262, loss 0.828485, acc 0.609375
2020-02-08T02:41:59.331278: step 263, loss 0.814129, acc 0.65625
2020-02-08T02:41:59.449396: step 264, loss 0.686846, acc 0.6875
2020-02-08T02:41:59.566284: step 265, loss 0.949085, acc 0.5
2020-02-08T02:41:59.683298: step 266, loss 0.750843, acc 0.65625
2020-02-08T02:41:59.804060: step 267, loss 0.724707, acc 0.65625
2020-02-08T02:41:59.925894: step 268, loss 0.614135, acc 0.640625
2020-02-08T02:42:00.041470: step 269, loss 0.664186, acc 0.6875
2020-02-08T02:42:00.158277: step 270, loss 0.730094, acc 0.625
2020-02-08T02:42:00.276325: step 271, loss 0.701234, acc 0.671875
2020-02-08T02:42:00.391501: step 272, loss 0.519384, acc 0.6875
2020-02-08T02:42:00.505139: step 273, loss 0.766701, acc 0.640625
2020-02-08T02:42:00.622655: step 274, loss 0.817015, acc 0.625
2020-02-08T02:42:00.738964: step 275, loss 0.726036, acc 0.6875
2020-02-08T02:42:00.858978: step 276, loss 0.8668, acc 0.515625
2020-02-08T02:42:00.977737: step 277, loss 0.717036, acc 0.640625
2020-02-08T02:42:01.095491: step 278, loss 0.747971, acc 0.5625
2020-02-08T02:42:01.214578: step 279, loss 0.690049, acc 0.734375
2020-02-08T02:42:01.332053: step 280, loss 0.78391, acc 0.625
2020-02-08T02:42:01.447677: step 281, loss 0.785136, acc 0.625
2020-02-08T02:42:01.568218: step 282, loss 0.837411, acc 0.65625
2020-02-08T02:42:01.684485: step 283, loss 0.736834, acc 0.640625
2020-02-08T02:42:01.808056: step 284, loss 0.831791, acc 0.5
2020-02-08T02:42:01.925393: step 285, loss 0.766099, acc 0.640625
2020-02-08T02:42:02.039607: step 286, loss 0.904807, acc 0.578125
2020-02-08T02:42:02.155977: step 287, loss 0.786945, acc 0.578125
2020-02-08T02:42:02.273494: step 288, loss 0.778925, acc 0.65625
2020-02-08T02:42:02.389209: step 289, loss 0.743198, acc 0.546875
2020-02-08T02:42:02.505172: step 290, loss 0.797307, acc 0.625
2020-02-08T02:42:02.621704: step 291, loss 0.579056, acc 0.6875
2020-02-08T02:42:02.737721: step 292, loss 0.899361, acc 0.625
2020-02-08T02:42:02.853732: step 293, loss 0.857339, acc 0.59375
2020-02-08T02:42:02.971126: step 294, loss 0.797572, acc 0.515625
2020-02-08T02:42:03.087620: step 295, loss 0.738336, acc 0.59375
2020-02-08T02:42:03.203702: step 296, loss 0.630513, acc 0.6875
2020-02-08T02:42:03.322640: step 297, loss 0.597073, acc 0.65625
2020-02-08T02:42:03.439017: step 298, loss 0.580429, acc 0.703125
2020-02-08T02:42:03.556661: step 299, loss 0.739165, acc 0.609375
2020-02-08T02:42:03.669247: step 300, loss 0.743079, acc 0.566667

Evaluation:
2020-02-08T02:42:03.863231: step 300, loss 0.659467, acc 0.628518

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-300

2020-02-08T02:42:06.673418: step 301, loss 0.762912, acc 0.65625
2020-02-08T02:42:06.793211: step 302, loss 0.556746, acc 0.703125
2020-02-08T02:42:06.911176: step 303, loss 0.756627, acc 0.53125
2020-02-08T02:42:07.031094: step 304, loss 0.591215, acc 0.6875
2020-02-08T02:42:07.148694: step 305, loss 0.970904, acc 0.515625
2020-02-08T02:42:07.268762: step 306, loss 0.571996, acc 0.75
2020-02-08T02:42:07.386373: step 307, loss 0.672378, acc 0.609375
2020-02-08T02:42:07.505762: step 308, loss 0.778645, acc 0.5625
2020-02-08T02:42:07.622853: step 309, loss 0.661235, acc 0.625
2020-02-08T02:42:07.741224: step 310, loss 0.716255, acc 0.625
2020-02-08T02:42:07.855970: step 311, loss 0.654465, acc 0.734375
2020-02-08T02:42:07.974042: step 312, loss 0.707061, acc 0.671875
2020-02-08T02:42:08.088894: step 313, loss 0.580063, acc 0.703125
2020-02-08T02:42:08.205176: step 314, loss 0.688818, acc 0.65625
2020-02-08T02:42:08.323536: step 315, loss 0.693025, acc 0.640625
2020-02-08T02:42:08.439657: step 316, loss 0.767879, acc 0.625
2020-02-08T02:42:08.557257: step 317, loss 0.673513, acc 0.625
2020-02-08T02:42:08.673650: step 318, loss 0.707992, acc 0.625
2020-02-08T02:42:08.792099: step 319, loss 0.705905, acc 0.65625
2020-02-08T02:42:08.913079: step 320, loss 0.77875, acc 0.640625
2020-02-08T02:42:09.027564: step 321, loss 0.590378, acc 0.703125
2020-02-08T02:42:09.142303: step 322, loss 0.594655, acc 0.765625
2020-02-08T02:42:09.259229: step 323, loss 0.600513, acc 0.734375
2020-02-08T02:42:09.376708: step 324, loss 0.671653, acc 0.703125
2020-02-08T02:42:09.492653: step 325, loss 0.610546, acc 0.6875
2020-02-08T02:42:09.609920: step 326, loss 0.57746, acc 0.765625
2020-02-08T02:42:09.729102: step 327, loss 0.606236, acc 0.71875
2020-02-08T02:42:09.844899: step 328, loss 0.588364, acc 0.78125
2020-02-08T02:42:09.960810: step 329, loss 0.650476, acc 0.703125
2020-02-08T02:42:10.076387: step 330, loss 0.629461, acc 0.703125
2020-02-08T02:42:10.190011: step 331, loss 0.59178, acc 0.734375
2020-02-08T02:42:10.310076: step 332, loss 0.776127, acc 0.578125
2020-02-08T02:42:10.427897: step 333, loss 0.734905, acc 0.609375
2020-02-08T02:42:10.543971: step 334, loss 0.669263, acc 0.625
2020-02-08T02:42:10.662053: step 335, loss 0.61117, acc 0.6875
2020-02-08T02:42:10.781110: step 336, loss 0.649153, acc 0.703125
2020-02-08T02:42:10.896847: step 337, loss 0.587432, acc 0.65625
2020-02-08T02:42:11.015900: step 338, loss 0.777334, acc 0.625
2020-02-08T02:42:11.130875: step 339, loss 0.711715, acc 0.671875
2020-02-08T02:42:11.247201: step 340, loss 0.585445, acc 0.703125
2020-02-08T02:42:11.362873: step 341, loss 0.627629, acc 0.75
2020-02-08T02:42:11.481230: step 342, loss 0.654616, acc 0.59375
2020-02-08T02:42:11.596380: step 343, loss 0.576142, acc 0.640625
2020-02-08T02:42:11.714762: step 344, loss 0.640707, acc 0.65625
2020-02-08T02:42:11.833712: step 345, loss 0.717066, acc 0.65625
2020-02-08T02:42:11.951597: step 346, loss 0.689168, acc 0.640625
2020-02-08T02:42:12.070020: step 347, loss 0.618908, acc 0.625
2020-02-08T02:42:12.185476: step 348, loss 0.564366, acc 0.734375
2020-02-08T02:42:12.302120: step 349, loss 0.625035, acc 0.65625
2020-02-08T02:42:12.418003: step 350, loss 0.686316, acc 0.609375
2020-02-08T02:42:12.535139: step 351, loss 0.63587, acc 0.671875
2020-02-08T02:42:12.650405: step 352, loss 0.476655, acc 0.765625
2020-02-08T02:42:12.770686: step 353, loss 0.594652, acc 0.734375
2020-02-08T02:42:12.888049: step 354, loss 0.691859, acc 0.640625
2020-02-08T02:42:13.004590: step 355, loss 0.571247, acc 0.71875
2020-02-08T02:42:13.123889: step 356, loss 0.619975, acc 0.71875
2020-02-08T02:42:13.239437: step 357, loss 0.664917, acc 0.734375
2020-02-08T02:42:13.355685: step 358, loss 0.568286, acc 0.6875
2020-02-08T02:42:13.473538: step 359, loss 0.629294, acc 0.65625
2020-02-08T02:42:13.589582: step 360, loss 0.579047, acc 0.703125
2020-02-08T02:42:13.708292: step 361, loss 0.82755, acc 0.640625
2020-02-08T02:42:13.826106: step 362, loss 0.650261, acc 0.671875
2020-02-08T02:42:13.941870: step 363, loss 0.714567, acc 0.640625
2020-02-08T02:42:14.057903: step 364, loss 0.531832, acc 0.703125
2020-02-08T02:42:14.174435: step 365, loss 0.655105, acc 0.6875
2020-02-08T02:42:14.288450: step 366, loss 0.630267, acc 0.640625
2020-02-08T02:42:14.407175: step 367, loss 0.720238, acc 0.609375
2020-02-08T02:42:14.523993: step 368, loss 0.763838, acc 0.59375
2020-02-08T02:42:14.640789: step 369, loss 0.571118, acc 0.71875
2020-02-08T02:42:14.762074: step 370, loss 0.587743, acc 0.703125
2020-02-08T02:42:14.878029: step 371, loss 0.731045, acc 0.609375
2020-02-08T02:42:14.997819: step 372, loss 0.585721, acc 0.625
2020-02-08T02:42:15.114062: step 373, loss 0.671767, acc 0.65625
2020-02-08T02:42:15.230588: step 374, loss 0.647405, acc 0.6875
2020-02-08T02:42:15.345692: step 375, loss 0.700149, acc 0.578125
2020-02-08T02:42:15.462896: step 376, loss 0.729944, acc 0.625
2020-02-08T02:42:15.579569: step 377, loss 0.556227, acc 0.796875
2020-02-08T02:42:15.693151: step 378, loss 0.896049, acc 0.546875
2020-02-08T02:42:15.813659: step 379, loss 0.652779, acc 0.671875
2020-02-08T02:42:15.930366: step 380, loss 0.61402, acc 0.703125
2020-02-08T02:42:16.047557: step 381, loss 0.643207, acc 0.65625
2020-02-08T02:42:16.163822: step 382, loss 0.546911, acc 0.734375
2020-02-08T02:42:16.284413: step 383, loss 0.59155, acc 0.765625
2020-02-08T02:42:16.401243: step 384, loss 0.704946, acc 0.671875
2020-02-08T02:42:16.518977: step 385, loss 0.754816, acc 0.65625
2020-02-08T02:42:16.634771: step 386, loss 0.567952, acc 0.703125
2020-02-08T02:42:16.755324: step 387, loss 0.62299, acc 0.671875
2020-02-08T02:42:16.871120: step 388, loss 0.545745, acc 0.71875
2020-02-08T02:42:16.986256: step 389, loss 0.588925, acc 0.71875
2020-02-08T02:42:17.104410: step 390, loss 0.694776, acc 0.625
2020-02-08T02:42:17.222251: step 391, loss 0.779943, acc 0.546875
2020-02-08T02:42:17.338564: step 392, loss 0.638965, acc 0.625
2020-02-08T02:42:17.454347: step 393, loss 0.613293, acc 0.671875
2020-02-08T02:42:17.571223: step 394, loss 0.477511, acc 0.71875
2020-02-08T02:42:17.686829: step 395, loss 0.635137, acc 0.703125
2020-02-08T02:42:17.809216: step 396, loss 0.72699, acc 0.578125
2020-02-08T02:42:17.927419: step 397, loss 0.68585, acc 0.703125
2020-02-08T02:42:18.044598: step 398, loss 0.664736, acc 0.6875
2020-02-08T02:42:18.161914: step 399, loss 0.582446, acc 0.671875
2020-02-08T02:42:18.277161: step 400, loss 0.599732, acc 0.6875

Evaluation:
2020-02-08T02:42:18.467942: step 400, loss 0.634865, acc 0.635084

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-400

2020-02-08T02:42:20.268580: step 401, loss 0.541227, acc 0.703125
2020-02-08T02:42:20.384783: step 402, loss 0.480285, acc 0.78125
2020-02-08T02:42:20.499559: step 403, loss 0.538689, acc 0.6875
2020-02-08T02:42:20.614243: step 404, loss 0.693286, acc 0.609375
2020-02-08T02:42:20.732375: step 405, loss 0.651891, acc 0.65625
2020-02-08T02:42:20.849704: step 406, loss 0.63217, acc 0.703125
2020-02-08T02:42:20.965793: step 407, loss 0.632624, acc 0.671875
2020-02-08T02:42:21.081951: step 408, loss 0.582997, acc 0.65625
2020-02-08T02:42:21.199726: step 409, loss 0.673834, acc 0.65625
2020-02-08T02:42:21.474337: step 410, loss 0.654944, acc 0.609375
2020-02-08T02:42:21.608344: step 411, loss 0.803999, acc 0.625
2020-02-08T02:42:21.726791: step 412, loss 0.587911, acc 0.640625
2020-02-08T02:42:21.843662: step 413, loss 0.654491, acc 0.625
2020-02-08T02:42:21.962883: step 414, loss 0.546609, acc 0.75
2020-02-08T02:42:22.079621: step 415, loss 0.734081, acc 0.65625
2020-02-08T02:42:22.193375: step 416, loss 0.543759, acc 0.765625
2020-02-08T02:42:22.310429: step 417, loss 0.594303, acc 0.765625
2020-02-08T02:42:22.430014: step 418, loss 0.453941, acc 0.8125
2020-02-08T02:42:22.546677: step 419, loss 0.640097, acc 0.734375
2020-02-08T02:42:22.660298: step 420, loss 0.709728, acc 0.609375
2020-02-08T02:42:22.779715: step 421, loss 0.648431, acc 0.640625
2020-02-08T02:42:22.896201: step 422, loss 0.642957, acc 0.609375
2020-02-08T02:42:23.012453: step 423, loss 0.671729, acc 0.671875
2020-02-08T02:42:23.128734: step 424, loss 0.566489, acc 0.671875
2020-02-08T02:42:23.246476: step 425, loss 0.773407, acc 0.65625
2020-02-08T02:42:23.360315: step 426, loss 0.777327, acc 0.5625
2020-02-08T02:42:23.475513: step 427, loss 0.715696, acc 0.546875
2020-02-08T02:42:23.592797: step 428, loss 0.684989, acc 0.625
2020-02-08T02:42:23.710135: step 429, loss 0.605343, acc 0.65625
2020-02-08T02:42:23.829690: step 430, loss 0.58015, acc 0.75
2020-02-08T02:42:23.946811: step 431, loss 0.519264, acc 0.734375
2020-02-08T02:42:24.063551: step 432, loss 0.533652, acc 0.703125
2020-02-08T02:42:24.177239: step 433, loss 0.670665, acc 0.59375
2020-02-08T02:42:24.294418: step 434, loss 0.818193, acc 0.53125
2020-02-08T02:42:24.409051: step 435, loss 0.718484, acc 0.59375
2020-02-08T02:42:24.526624: step 436, loss 0.603524, acc 0.6875
2020-02-08T02:42:24.643087: step 437, loss 0.691901, acc 0.71875
2020-02-08T02:42:24.762570: step 438, loss 0.659031, acc 0.671875
2020-02-08T02:42:24.879616: step 439, loss 0.591963, acc 0.6875
2020-02-08T02:42:24.997810: step 440, loss 0.522067, acc 0.734375
2020-02-08T02:42:25.117059: step 441, loss 0.642152, acc 0.65625
2020-02-08T02:42:25.233292: step 442, loss 0.679175, acc 0.65625
2020-02-08T02:42:25.350882: step 443, loss 0.710041, acc 0.546875
2020-02-08T02:42:25.463522: step 444, loss 0.636479, acc 0.6875
2020-02-08T02:42:25.581320: step 445, loss 0.64963, acc 0.6875
2020-02-08T02:42:25.699821: step 446, loss 0.731561, acc 0.59375
2020-02-08T02:42:25.817577: step 447, loss 0.680588, acc 0.65625
2020-02-08T02:42:25.935440: step 448, loss 0.665101, acc 0.640625
2020-02-08T02:42:26.049055: step 449, loss 0.550928, acc 0.671875
2020-02-08T02:42:26.161133: step 450, loss 0.650936, acc 0.6
2020-02-08T02:42:26.279297: step 451, loss 0.684644, acc 0.671875
2020-02-08T02:42:26.395656: step 452, loss 0.496563, acc 0.828125
2020-02-08T02:42:26.512984: step 453, loss 0.710713, acc 0.578125
2020-02-08T02:42:26.628794: step 454, loss 0.64585, acc 0.671875
2020-02-08T02:42:26.746476: step 455, loss 0.615195, acc 0.65625
2020-02-08T02:42:26.864067: step 456, loss 0.437743, acc 0.78125
2020-02-08T02:42:26.979990: step 457, loss 0.574059, acc 0.703125
2020-02-08T02:42:27.097046: step 458, loss 0.468021, acc 0.796875
2020-02-08T02:42:27.215114: step 459, loss 0.631776, acc 0.671875
2020-02-08T02:42:27.330570: step 460, loss 0.513288, acc 0.796875
2020-02-08T02:42:27.446136: step 461, loss 0.59609, acc 0.75
2020-02-08T02:42:27.561864: step 462, loss 0.590659, acc 0.671875
2020-02-08T02:42:27.679097: step 463, loss 0.595659, acc 0.734375
2020-02-08T02:42:27.797932: step 464, loss 0.551175, acc 0.640625
2020-02-08T02:42:27.911198: step 465, loss 0.526015, acc 0.6875
2020-02-08T02:42:28.028514: step 466, loss 0.547327, acc 0.6875
2020-02-08T02:42:28.144052: step 467, loss 0.504584, acc 0.6875
2020-02-08T02:42:28.261589: step 468, loss 0.508117, acc 0.765625
2020-02-08T02:42:28.376968: step 469, loss 0.58026, acc 0.671875
2020-02-08T02:42:28.493546: step 470, loss 0.529109, acc 0.78125
2020-02-08T02:42:28.610865: step 471, loss 0.587407, acc 0.703125
2020-02-08T02:42:28.729322: step 472, loss 0.602825, acc 0.65625
2020-02-08T02:42:28.848879: step 473, loss 0.528205, acc 0.75
2020-02-08T02:42:28.966318: step 474, loss 0.665566, acc 0.640625
2020-02-08T02:42:29.084792: step 475, loss 0.575822, acc 0.671875
2020-02-08T02:42:29.201009: step 476, loss 0.615883, acc 0.6875
2020-02-08T02:42:29.318277: step 477, loss 0.540469, acc 0.71875
2020-02-08T02:42:29.433803: step 478, loss 0.426857, acc 0.84375
2020-02-08T02:42:29.548536: step 479, loss 0.542494, acc 0.8125
2020-02-08T02:42:29.662641: step 480, loss 0.515553, acc 0.765625
2020-02-08T02:42:29.783051: step 481, loss 0.650717, acc 0.625
2020-02-08T02:42:29.898640: step 482, loss 0.59382, acc 0.703125
2020-02-08T02:42:30.015989: step 483, loss 0.644777, acc 0.6875
2020-02-08T02:42:30.133255: step 484, loss 0.58957, acc 0.75
2020-02-08T02:42:30.250329: step 485, loss 0.637928, acc 0.640625
2020-02-08T02:42:30.367125: step 486, loss 0.534897, acc 0.78125
2020-02-08T02:42:30.484539: step 487, loss 0.573499, acc 0.734375
2020-02-08T02:42:30.601718: step 488, loss 0.5211, acc 0.703125
2020-02-08T02:42:30.718305: step 489, loss 0.54961, acc 0.734375
2020-02-08T02:42:30.834458: step 490, loss 0.474567, acc 0.765625
2020-02-08T02:42:30.947112: step 491, loss 0.533374, acc 0.703125
2020-02-08T02:42:31.065161: step 492, loss 0.491208, acc 0.71875
2020-02-08T02:42:31.182290: step 493, loss 0.666195, acc 0.671875
2020-02-08T02:42:31.298647: step 494, loss 0.560888, acc 0.703125
2020-02-08T02:42:31.417275: step 495, loss 0.561659, acc 0.765625
2020-02-08T02:42:31.538124: step 496, loss 0.638507, acc 0.703125
2020-02-08T02:42:31.654738: step 497, loss 0.540809, acc 0.6875
2020-02-08T02:42:31.778006: step 498, loss 0.694537, acc 0.671875
2020-02-08T02:42:31.893451: step 499, loss 0.493686, acc 0.75
2020-02-08T02:42:32.010429: step 500, loss 0.630057, acc 0.59375

Evaluation:
2020-02-08T02:42:32.197356: step 500, loss 0.62771, acc 0.645403

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-500

2020-02-08T02:42:34.038499: step 501, loss 0.618665, acc 0.59375
2020-02-08T02:42:34.151088: step 502, loss 0.596163, acc 0.671875
2020-02-08T02:42:34.267085: step 503, loss 0.640914, acc 0.671875
2020-02-08T02:42:34.383002: step 504, loss 0.468921, acc 0.84375
2020-02-08T02:42:34.498518: step 505, loss 0.618683, acc 0.640625
2020-02-08T02:42:34.617187: step 506, loss 0.621895, acc 0.71875
2020-02-08T02:42:34.742111: step 507, loss 0.569268, acc 0.703125
2020-02-08T02:42:34.948878: step 508, loss 0.635617, acc 0.65625
2020-02-08T02:42:35.136098: step 509, loss 0.497842, acc 0.796875
2020-02-08T02:42:35.263645: step 510, loss 0.677799, acc 0.640625
2020-02-08T02:42:35.387864: step 511, loss 0.534747, acc 0.765625
2020-02-08T02:42:35.528294: step 512, loss 0.516128, acc 0.71875
2020-02-08T02:42:35.668098: step 513, loss 0.644444, acc 0.71875
2020-02-08T02:42:35.805635: step 514, loss 0.563428, acc 0.734375
2020-02-08T02:42:35.936828: step 515, loss 0.644355, acc 0.609375
2020-02-08T02:42:36.069386: step 516, loss 0.610537, acc 0.640625
2020-02-08T02:42:36.200221: step 517, loss 0.584005, acc 0.671875
2020-02-08T02:42:36.320565: step 518, loss 0.659033, acc 0.609375
2020-02-08T02:42:36.439589: step 519, loss 0.678508, acc 0.625
2020-02-08T02:42:36.579886: step 520, loss 0.631227, acc 0.6875
2020-02-08T02:42:36.705022: step 521, loss 0.554252, acc 0.65625
2020-02-08T02:42:36.833189: step 522, loss 0.670695, acc 0.671875
2020-02-08T02:42:36.963450: step 523, loss 0.567237, acc 0.6875
2020-02-08T02:42:37.093698: step 524, loss 0.543102, acc 0.703125
2020-02-08T02:42:37.224045: step 525, loss 0.742004, acc 0.671875
2020-02-08T02:42:37.357652: step 526, loss 0.56661, acc 0.734375
2020-02-08T02:42:37.489099: step 527, loss 0.467655, acc 0.78125
2020-02-08T02:42:37.624313: step 528, loss 0.546756, acc 0.734375
2020-02-08T02:42:37.758800: step 529, loss 0.484167, acc 0.765625
2020-02-08T02:42:37.886826: step 530, loss 0.586774, acc 0.734375
2020-02-08T02:42:38.019497: step 531, loss 0.632153, acc 0.671875
2020-02-08T02:42:38.156681: step 532, loss 0.673513, acc 0.625
2020-02-08T02:42:38.297690: step 533, loss 0.518135, acc 0.75
2020-02-08T02:42:38.435913: step 534, loss 0.48268, acc 0.796875
2020-02-08T02:42:38.580989: step 535, loss 0.536063, acc 0.78125
2020-02-08T02:42:38.720735: step 536, loss 0.604285, acc 0.703125
2020-02-08T02:42:38.862827: step 537, loss 0.646023, acc 0.65625
2020-02-08T02:42:38.989486: step 538, loss 0.518525, acc 0.671875
2020-02-08T02:42:39.128844: step 539, loss 0.536947, acc 0.765625
2020-02-08T02:42:39.273757: step 540, loss 0.614848, acc 0.640625
2020-02-08T02:42:39.410216: step 541, loss 0.541791, acc 0.71875
2020-02-08T02:42:39.544687: step 542, loss 0.468037, acc 0.734375
2020-02-08T02:42:39.683171: step 543, loss 0.56018, acc 0.671875
2020-02-08T02:42:39.828124: step 544, loss 0.526903, acc 0.796875
2020-02-08T02:42:39.968768: step 545, loss 0.691885, acc 0.671875
2020-02-08T02:42:40.108810: step 546, loss 0.59414, acc 0.75
2020-02-08T02:42:40.257489: step 547, loss 0.613318, acc 0.65625
2020-02-08T02:42:40.394504: step 548, loss 0.482387, acc 0.796875
2020-02-08T02:42:40.529802: step 549, loss 0.556962, acc 0.71875
2020-02-08T02:42:40.670260: step 550, loss 0.510788, acc 0.734375
2020-02-08T02:42:40.812870: step 551, loss 0.500706, acc 0.796875
2020-02-08T02:42:40.952672: step 552, loss 0.704479, acc 0.625
2020-02-08T02:42:41.087122: step 553, loss 0.666634, acc 0.640625
2020-02-08T02:42:41.222044: step 554, loss 0.57476, acc 0.65625
2020-02-08T02:42:41.355247: step 555, loss 0.507354, acc 0.6875
2020-02-08T02:42:41.487545: step 556, loss 0.55663, acc 0.6875
2020-02-08T02:42:41.623326: step 557, loss 0.512678, acc 0.78125
2020-02-08T02:42:41.770032: step 558, loss 0.549881, acc 0.703125
2020-02-08T02:42:41.903319: step 559, loss 0.516819, acc 0.71875
2020-02-08T02:42:42.040727: step 560, loss 0.53033, acc 0.75
2020-02-08T02:42:42.178507: step 561, loss 0.573245, acc 0.703125
2020-02-08T02:42:42.316912: step 562, loss 0.537124, acc 0.75
2020-02-08T02:42:42.448339: step 563, loss 0.567802, acc 0.671875
2020-02-08T02:42:42.583251: step 564, loss 0.451275, acc 0.75
2020-02-08T02:42:42.723263: step 565, loss 0.586134, acc 0.6875
2020-02-08T02:42:42.861944: step 566, loss 0.601317, acc 0.671875
2020-02-08T02:42:42.998396: step 567, loss 0.532432, acc 0.765625
2020-02-08T02:42:43.136757: step 568, loss 0.589731, acc 0.65625
2020-02-08T02:42:43.270632: step 569, loss 0.550338, acc 0.703125
2020-02-08T02:42:43.409414: step 570, loss 0.442173, acc 0.796875
2020-02-08T02:42:43.546790: step 571, loss 0.554927, acc 0.71875
2020-02-08T02:42:43.670006: step 572, loss 0.494441, acc 0.75
2020-02-08T02:42:43.791546: step 573, loss 0.591134, acc 0.671875
2020-02-08T02:42:43.912430: step 574, loss 0.49157, acc 0.78125
2020-02-08T02:42:44.039392: step 575, loss 0.510659, acc 0.71875
2020-02-08T02:42:44.164273: step 576, loss 0.531592, acc 0.765625
2020-02-08T02:42:44.282829: step 577, loss 0.489199, acc 0.703125
2020-02-08T02:42:44.402685: step 578, loss 0.63255, acc 0.640625
2020-02-08T02:42:44.529342: step 579, loss 0.594224, acc 0.671875
2020-02-08T02:42:44.647273: step 580, loss 0.606476, acc 0.71875
2020-02-08T02:42:44.767805: step 581, loss 0.576607, acc 0.71875
2020-02-08T02:42:44.882713: step 582, loss 0.680668, acc 0.671875
2020-02-08T02:42:45.000531: step 583, loss 0.597126, acc 0.671875
2020-02-08T02:42:45.118889: step 584, loss 0.575465, acc 0.734375
2020-02-08T02:42:45.237631: step 585, loss 0.541356, acc 0.6875
2020-02-08T02:42:45.356643: step 586, loss 0.491414, acc 0.71875
2020-02-08T02:42:45.477759: step 587, loss 0.554311, acc 0.6875
2020-02-08T02:42:45.596230: step 588, loss 0.611614, acc 0.6875
2020-02-08T02:42:45.717109: step 589, loss 0.447424, acc 0.828125
2020-02-08T02:42:45.835159: step 590, loss 0.58311, acc 0.703125
2020-02-08T02:42:45.955322: step 591, loss 0.613997, acc 0.65625
2020-02-08T02:42:46.078085: step 592, loss 0.548061, acc 0.671875
2020-02-08T02:42:46.193325: step 593, loss 0.481108, acc 0.75
2020-02-08T02:42:46.316598: step 594, loss 0.584335, acc 0.625
2020-02-08T02:42:46.434052: step 595, loss 0.486248, acc 0.78125
2020-02-08T02:42:46.563603: step 596, loss 0.560772, acc 0.6875
2020-02-08T02:42:46.686788: step 597, loss 0.561702, acc 0.703125
2020-02-08T02:42:46.811621: step 598, loss 0.476811, acc 0.765625
2020-02-08T02:42:46.931197: step 599, loss 0.587042, acc 0.6875
2020-02-08T02:42:47.049213: step 600, loss 0.575503, acc 0.666667

Evaluation:
2020-02-08T02:42:47.239637: step 600, loss 0.627792, acc 0.624765

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-600

2020-02-08T02:42:48.792018: step 601, loss 0.549765, acc 0.71875
2020-02-08T02:42:48.909178: step 602, loss 0.62851, acc 0.6875
2020-02-08T02:42:49.024684: step 603, loss 0.470604, acc 0.796875
2020-02-08T02:42:49.139165: step 604, loss 0.446762, acc 0.765625
2020-02-08T02:42:49.256368: step 605, loss 0.605248, acc 0.640625
2020-02-08T02:42:49.373286: step 606, loss 0.490424, acc 0.765625
2020-02-08T02:42:49.487488: step 607, loss 0.57696, acc 0.703125
2020-02-08T02:42:49.603931: step 608, loss 0.550886, acc 0.734375
2020-02-08T02:42:49.724466: step 609, loss 0.590665, acc 0.6875
2020-02-08T02:42:49.839634: step 610, loss 0.471009, acc 0.75
2020-02-08T02:42:49.960400: step 611, loss 0.495991, acc 0.796875
2020-02-08T02:42:50.080049: step 612, loss 0.451904, acc 0.828125
2020-02-08T02:42:50.196226: step 613, loss 0.479868, acc 0.765625
2020-02-08T02:42:50.313883: step 614, loss 0.538404, acc 0.765625
2020-02-08T02:42:50.429526: step 615, loss 0.506175, acc 0.765625
2020-02-08T02:42:50.544262: step 616, loss 0.482632, acc 0.765625
2020-02-08T02:42:50.668128: step 617, loss 0.593612, acc 0.65625
2020-02-08T02:42:50.787530: step 618, loss 0.553186, acc 0.78125
2020-02-08T02:42:50.902386: step 619, loss 0.43325, acc 0.8125
2020-02-08T02:42:51.019235: step 620, loss 0.548715, acc 0.75
2020-02-08T02:42:51.133992: step 621, loss 0.562551, acc 0.671875
2020-02-08T02:42:51.249787: step 622, loss 0.428903, acc 0.78125
2020-02-08T02:42:51.524523: step 623, loss 0.544392, acc 0.765625
2020-02-08T02:42:51.656038: step 624, loss 0.585415, acc 0.765625
2020-02-08T02:42:51.778834: step 625, loss 0.571494, acc 0.71875
2020-02-08T02:42:51.892407: step 626, loss 0.498264, acc 0.765625
2020-02-08T02:42:52.010034: step 627, loss 0.415467, acc 0.828125
2020-02-08T02:42:52.126782: step 628, loss 0.436981, acc 0.765625
2020-02-08T02:42:52.243254: step 629, loss 0.554375, acc 0.71875
2020-02-08T02:42:52.359528: step 630, loss 0.578276, acc 0.671875
2020-02-08T02:42:52.479461: step 631, loss 0.515966, acc 0.765625
2020-02-08T02:42:52.597223: step 632, loss 0.613281, acc 0.703125
2020-02-08T02:42:52.718486: step 633, loss 0.454736, acc 0.765625
2020-02-08T02:42:52.835697: step 634, loss 0.554276, acc 0.75
2020-02-08T02:42:52.950701: step 635, loss 0.569965, acc 0.6875
2020-02-08T02:42:53.067957: step 636, loss 0.461247, acc 0.796875
2020-02-08T02:42:53.183751: step 637, loss 0.602575, acc 0.6875
2020-02-08T02:42:53.299432: step 638, loss 0.431628, acc 0.78125
2020-02-08T02:42:53.415500: step 639, loss 0.580955, acc 0.6875
2020-02-08T02:42:53.532705: step 640, loss 0.338657, acc 0.90625
2020-02-08T02:42:53.647743: step 641, loss 0.587934, acc 0.671875
2020-02-08T02:42:53.769949: step 642, loss 0.446128, acc 0.765625
2020-02-08T02:42:53.886131: step 643, loss 0.489873, acc 0.75
2020-02-08T02:42:54.003362: step 644, loss 0.511916, acc 0.75
2020-02-08T02:42:54.118616: step 645, loss 0.518591, acc 0.734375
2020-02-08T02:42:54.236328: step 646, loss 0.371192, acc 0.828125
2020-02-08T02:42:54.351049: step 647, loss 0.544947, acc 0.734375
2020-02-08T02:42:54.468421: step 648, loss 0.475746, acc 0.765625
2020-02-08T02:42:54.583093: step 649, loss 0.414804, acc 0.765625
2020-02-08T02:42:54.697014: step 650, loss 0.45839, acc 0.765625
2020-02-08T02:42:54.818340: step 651, loss 0.58926, acc 0.75
2020-02-08T02:42:54.935096: step 652, loss 0.525737, acc 0.734375
2020-02-08T02:42:55.053478: step 653, loss 0.485816, acc 0.75
2020-02-08T02:42:55.168690: step 654, loss 0.493496, acc 0.734375
2020-02-08T02:42:55.285555: step 655, loss 0.482858, acc 0.78125
2020-02-08T02:42:55.400830: step 656, loss 0.445649, acc 0.796875
2020-02-08T02:42:55.517734: step 657, loss 0.492011, acc 0.75
2020-02-08T02:42:55.635047: step 658, loss 0.517934, acc 0.75
2020-02-08T02:42:55.753016: step 659, loss 0.514609, acc 0.71875
2020-02-08T02:42:55.868952: step 660, loss 0.373817, acc 0.828125
2020-02-08T02:42:55.986816: step 661, loss 0.448464, acc 0.890625
2020-02-08T02:42:56.104017: step 662, loss 0.486251, acc 0.734375
2020-02-08T02:42:56.220982: step 663, loss 0.51706, acc 0.734375
2020-02-08T02:42:56.335795: step 664, loss 0.511852, acc 0.796875
2020-02-08T02:42:56.451304: step 665, loss 0.543877, acc 0.734375
2020-02-08T02:42:56.567157: step 666, loss 0.483877, acc 0.765625
2020-02-08T02:42:56.682911: step 667, loss 0.523066, acc 0.75
2020-02-08T02:42:56.802496: step 668, loss 0.484002, acc 0.828125
2020-02-08T02:42:56.920991: step 669, loss 0.64656, acc 0.65625
2020-02-08T02:42:57.036606: step 670, loss 0.565635, acc 0.765625
2020-02-08T02:42:57.151841: step 671, loss 0.522599, acc 0.78125
2020-02-08T02:42:57.268846: step 672, loss 0.505467, acc 0.734375
2020-02-08T02:42:57.386992: step 673, loss 0.540733, acc 0.734375
2020-02-08T02:42:57.503211: step 674, loss 0.548762, acc 0.65625
2020-02-08T02:42:57.619104: step 675, loss 0.489529, acc 0.75
2020-02-08T02:42:57.734158: step 676, loss 0.705342, acc 0.5625
2020-02-08T02:42:57.852098: step 677, loss 0.557038, acc 0.65625
2020-02-08T02:42:57.967190: step 678, loss 0.433144, acc 0.78125
2020-02-08T02:42:58.085938: step 679, loss 0.505867, acc 0.734375
2020-02-08T02:42:58.201937: step 680, loss 0.511866, acc 0.75
2020-02-08T02:42:58.319407: step 681, loss 0.511426, acc 0.703125
2020-02-08T02:42:58.437153: step 682, loss 0.45413, acc 0.78125
2020-02-08T02:42:58.550076: step 683, loss 0.524169, acc 0.71875
2020-02-08T02:42:58.667986: step 684, loss 0.630444, acc 0.6875
2020-02-08T02:42:58.786438: step 685, loss 0.516912, acc 0.8125
2020-02-08T02:42:58.902596: step 686, loss 0.590082, acc 0.765625
2020-02-08T02:42:59.022557: step 687, loss 0.576391, acc 0.734375
2020-02-08T02:42:59.138190: step 688, loss 0.601805, acc 0.703125
2020-02-08T02:42:59.252490: step 689, loss 0.458988, acc 0.75
2020-02-08T02:42:59.370100: step 690, loss 0.533078, acc 0.734375
2020-02-08T02:42:59.485363: step 691, loss 0.349918, acc 0.890625
2020-02-08T02:42:59.601745: step 692, loss 0.579497, acc 0.734375
2020-02-08T02:42:59.719614: step 693, loss 0.408386, acc 0.78125
2020-02-08T02:42:59.835539: step 694, loss 0.503181, acc 0.75
2020-02-08T02:42:59.951250: step 695, loss 0.479509, acc 0.765625
2020-02-08T02:43:00.064848: step 696, loss 0.493017, acc 0.765625
2020-02-08T02:43:00.182019: step 697, loss 0.416505, acc 0.859375
2020-02-08T02:43:00.298035: step 698, loss 0.586883, acc 0.703125
2020-02-08T02:43:00.418005: step 699, loss 0.518401, acc 0.765625
2020-02-08T02:43:00.535218: step 700, loss 0.652103, acc 0.6875

Evaluation:
2020-02-08T02:43:00.726860: step 700, loss 0.59516, acc 0.670732

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-700

2020-02-08T02:43:02.308287: step 701, loss 0.687342, acc 0.640625
2020-02-08T02:43:02.425528: step 702, loss 0.49471, acc 0.734375
2020-02-08T02:43:02.539451: step 703, loss 0.540801, acc 0.703125
2020-02-08T02:43:02.655744: step 704, loss 0.526497, acc 0.734375
2020-02-08T02:43:02.776957: step 705, loss 0.408236, acc 0.859375
2020-02-08T02:43:02.891272: step 706, loss 0.526522, acc 0.828125
2020-02-08T02:43:03.006744: step 707, loss 0.44855, acc 0.765625
2020-02-08T02:43:03.124631: step 708, loss 0.530768, acc 0.75
2020-02-08T02:43:03.240648: step 709, loss 0.546216, acc 0.71875
2020-02-08T02:43:03.357626: step 710, loss 0.479432, acc 0.765625
2020-02-08T02:43:03.475121: step 711, loss 0.457611, acc 0.78125
2020-02-08T02:43:03.591605: step 712, loss 0.57677, acc 0.671875
2020-02-08T02:43:03.711937: step 713, loss 0.434036, acc 0.796875
2020-02-08T02:43:03.828961: step 714, loss 0.544487, acc 0.71875
2020-02-08T02:43:03.944454: step 715, loss 0.399298, acc 0.875
2020-02-08T02:43:04.060471: step 716, loss 0.408416, acc 0.8125
2020-02-08T02:43:04.179006: step 717, loss 0.48303, acc 0.796875
2020-02-08T02:43:04.294542: step 718, loss 0.535613, acc 0.734375
2020-02-08T02:43:04.413038: step 719, loss 0.419933, acc 0.78125
2020-02-08T02:43:04.531309: step 720, loss 0.495888, acc 0.703125
2020-02-08T02:43:04.648605: step 721, loss 0.54756, acc 0.703125
2020-02-08T02:43:04.768156: step 722, loss 0.532238, acc 0.75
2020-02-08T02:43:04.883963: step 723, loss 0.576143, acc 0.6875
2020-02-08T02:43:04.999267: step 724, loss 0.632319, acc 0.65625
2020-02-08T02:43:05.116675: step 725, loss 0.719765, acc 0.671875
2020-02-08T02:43:05.231340: step 726, loss 0.470578, acc 0.78125
2020-02-08T02:43:05.348120: step 727, loss 0.448832, acc 0.703125
2020-02-08T02:43:05.463188: step 728, loss 0.483931, acc 0.734375
2020-02-08T02:43:05.583268: step 729, loss 0.407936, acc 0.765625
2020-02-08T02:43:05.702218: step 730, loss 0.522096, acc 0.8125
2020-02-08T02:43:05.820783: step 731, loss 0.44024, acc 0.765625
2020-02-08T02:43:05.935337: step 732, loss 0.460257, acc 0.84375
2020-02-08T02:43:06.051032: step 733, loss 0.42577, acc 0.796875
2020-02-08T02:43:06.166106: step 734, loss 0.433329, acc 0.78125
2020-02-08T02:43:06.282043: step 735, loss 0.471753, acc 0.71875
2020-02-08T02:43:06.396231: step 736, loss 0.505794, acc 0.734375
2020-02-08T02:43:06.512589: step 737, loss 0.53862, acc 0.75
2020-02-08T02:43:06.630695: step 738, loss 0.511036, acc 0.796875
2020-02-08T02:43:06.750888: step 739, loss 0.504612, acc 0.75
2020-02-08T02:43:06.871218: step 740, loss 0.562421, acc 0.71875
2020-02-08T02:43:06.984589: step 741, loss 0.55123, acc 0.6875
2020-02-08T02:43:07.103950: step 742, loss 0.53671, acc 0.6875
2020-02-08T02:43:07.219746: step 743, loss 0.49858, acc 0.796875
2020-02-08T02:43:07.337385: step 744, loss 0.422373, acc 0.8125
2020-02-08T02:43:07.453139: step 745, loss 0.650429, acc 0.609375
2020-02-08T02:43:07.571846: step 746, loss 0.413984, acc 0.859375
2020-02-08T02:43:07.687674: step 747, loss 0.451925, acc 0.75
2020-02-08T02:43:07.809130: step 748, loss 0.36075, acc 0.84375
2020-02-08T02:43:07.925627: step 749, loss 0.505647, acc 0.765625
2020-02-08T02:43:08.037406: step 750, loss 0.390824, acc 0.883333
2020-02-08T02:43:08.157843: step 751, loss 0.559386, acc 0.71875
2020-02-08T02:43:08.276742: step 752, loss 0.509514, acc 0.78125
2020-02-08T02:43:08.391171: step 753, loss 0.402175, acc 0.796875
2020-02-08T02:43:08.507287: step 754, loss 0.423993, acc 0.8125
2020-02-08T02:43:08.624859: step 755, loss 0.413689, acc 0.8125
2020-02-08T02:43:08.741443: step 756, loss 0.491104, acc 0.734375
2020-02-08T02:43:08.855427: step 757, loss 0.420382, acc 0.765625
2020-02-08T02:43:08.973614: step 758, loss 0.502952, acc 0.765625
2020-02-08T02:43:09.089852: step 759, loss 0.498885, acc 0.734375
2020-02-08T02:43:09.208046: step 760, loss 0.439035, acc 0.8125
2020-02-08T02:43:09.325942: step 761, loss 0.440523, acc 0.796875
2020-02-08T02:43:09.442180: step 762, loss 0.364469, acc 0.828125
2020-02-08T02:43:09.559781: step 763, loss 0.440333, acc 0.828125
2020-02-08T02:43:09.677711: step 764, loss 0.314327, acc 0.859375
2020-02-08T02:43:09.795964: step 765, loss 0.424423, acc 0.78125
2020-02-08T02:43:09.912787: step 766, loss 0.436697, acc 0.796875
2020-02-08T02:43:10.031473: step 767, loss 0.353116, acc 0.8125
2020-02-08T02:43:10.145046: step 768, loss 0.304184, acc 0.890625
2020-02-08T02:43:10.261479: step 769, loss 0.386651, acc 0.8125
2020-02-08T02:43:10.379659: step 770, loss 0.479652, acc 0.71875
2020-02-08T02:43:10.497410: step 771, loss 0.418859, acc 0.8125
2020-02-08T02:43:10.614541: step 772, loss 0.424071, acc 0.84375
2020-02-08T02:43:10.731516: step 773, loss 0.442801, acc 0.828125
2020-02-08T02:43:10.849535: step 774, loss 0.35267, acc 0.875
2020-02-08T02:43:10.965750: step 775, loss 0.430331, acc 0.78125
2020-02-08T02:43:11.082587: step 776, loss 0.412229, acc 0.8125
2020-02-08T02:43:11.197302: step 777, loss 0.542489, acc 0.75
2020-02-08T02:43:11.310716: step 778, loss 0.458751, acc 0.8125
2020-02-08T02:43:11.425833: step 779, loss 0.393717, acc 0.765625
2020-02-08T02:43:11.541194: step 780, loss 0.420022, acc 0.8125
2020-02-08T02:43:11.655000: step 781, loss 0.363012, acc 0.875
2020-02-08T02:43:11.773343: step 782, loss 0.552145, acc 0.734375
2020-02-08T02:43:11.889896: step 783, loss 0.446781, acc 0.78125
2020-02-08T02:43:12.007176: step 784, loss 0.425882, acc 0.828125
2020-02-08T02:43:12.122760: step 785, loss 0.437981, acc 0.8125
2020-02-08T02:43:12.238075: step 786, loss 0.449512, acc 0.8125
2020-02-08T02:43:12.355902: step 787, loss 0.414897, acc 0.796875
2020-02-08T02:43:12.473347: step 788, loss 0.498355, acc 0.765625
2020-02-08T02:43:12.590065: step 789, loss 0.376249, acc 0.828125
2020-02-08T02:43:12.707982: step 790, loss 0.415378, acc 0.765625
2020-02-08T02:43:12.825935: step 791, loss 0.402063, acc 0.859375
2020-02-08T02:43:12.943257: step 792, loss 0.464049, acc 0.78125
2020-02-08T02:43:13.056881: step 793, loss 0.325313, acc 0.875
2020-02-08T02:43:13.174357: step 794, loss 0.518965, acc 0.734375
2020-02-08T02:43:13.292286: step 795, loss 0.417301, acc 0.84375
2020-02-08T02:43:13.408624: step 796, loss 0.46058, acc 0.765625
2020-02-08T02:43:13.525857: step 797, loss 0.459877, acc 0.796875
2020-02-08T02:43:13.644382: step 798, loss 0.466532, acc 0.78125
2020-02-08T02:43:13.765308: step 799, loss 0.309763, acc 0.875
2020-02-08T02:43:13.881629: step 800, loss 0.451307, acc 0.78125

Evaluation:
2020-02-08T02:43:14.072735: step 800, loss 0.598465, acc 0.662289

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-800

2020-02-08T02:43:15.945373: step 801, loss 0.398856, acc 0.84375
2020-02-08T02:43:16.059486: step 802, loss 0.54527, acc 0.734375
2020-02-08T02:43:16.175768: step 803, loss 0.47186, acc 0.75
2020-02-08T02:43:16.289217: step 804, loss 0.440968, acc 0.796875
2020-02-08T02:43:16.407079: step 805, loss 0.546201, acc 0.734375
2020-02-08T02:43:16.523660: step 806, loss 0.537395, acc 0.78125
2020-02-08T02:43:16.640835: step 807, loss 0.471094, acc 0.765625
2020-02-08T02:43:16.762304: step 808, loss 0.378262, acc 0.8125
2020-02-08T02:43:16.879341: step 809, loss 0.435009, acc 0.859375
2020-02-08T02:43:16.997123: step 810, loss 0.507352, acc 0.71875
2020-02-08T02:43:17.112685: step 811, loss 0.471434, acc 0.8125
2020-02-08T02:43:17.230512: step 812, loss 0.519469, acc 0.765625
2020-02-08T02:43:17.347229: step 813, loss 0.382245, acc 0.828125
2020-02-08T02:43:17.465482: step 814, loss 0.432816, acc 0.75
2020-02-08T02:43:17.582652: step 815, loss 0.459717, acc 0.828125
2020-02-08T02:43:17.699099: step 816, loss 0.493774, acc 0.78125
2020-02-08T02:43:17.818126: step 817, loss 0.395029, acc 0.796875
2020-02-08T02:43:17.937183: step 818, loss 0.394768, acc 0.828125
2020-02-08T02:43:18.056221: step 819, loss 0.468139, acc 0.71875
2020-02-08T02:43:18.172688: step 820, loss 0.465291, acc 0.8125
2020-02-08T02:43:18.287498: step 821, loss 0.456656, acc 0.78125
2020-02-08T02:43:18.404188: step 822, loss 0.424886, acc 0.796875
2020-02-08T02:43:18.519871: step 823, loss 0.342489, acc 0.859375
2020-02-08T02:43:18.635524: step 824, loss 0.493266, acc 0.703125
2020-02-08T02:43:18.754887: step 825, loss 0.459513, acc 0.75
2020-02-08T02:43:18.870425: step 826, loss 0.448834, acc 0.796875
2020-02-08T02:43:18.987319: step 827, loss 0.441558, acc 0.828125
2020-02-08T02:43:19.104753: step 828, loss 0.488914, acc 0.765625
2020-02-08T02:43:19.223478: step 829, loss 0.398065, acc 0.796875
2020-02-08T02:43:19.340968: step 830, loss 0.443897, acc 0.8125
2020-02-08T02:43:19.459335: step 831, loss 0.365242, acc 0.859375
2020-02-08T02:43:19.575689: step 832, loss 0.333692, acc 0.875
2020-02-08T02:43:19.694537: step 833, loss 0.414983, acc 0.765625
2020-02-08T02:43:19.819356: step 834, loss 0.453052, acc 0.8125
2020-02-08T02:43:19.941004: step 835, loss 0.383246, acc 0.828125
2020-02-08T02:43:20.062218: step 836, loss 0.458836, acc 0.78125
2020-02-08T02:43:20.181524: step 837, loss 0.528442, acc 0.765625
2020-02-08T02:43:20.301643: step 838, loss 0.419737, acc 0.78125
2020-02-08T02:43:20.421093: step 839, loss 0.199124, acc 0.921875
2020-02-08T02:43:20.535460: step 840, loss 0.424686, acc 0.78125
2020-02-08T02:43:20.665195: step 841, loss 0.511839, acc 0.734375
2020-02-08T02:43:20.782706: step 842, loss 0.402714, acc 0.78125
2020-02-08T02:43:20.902280: step 843, loss 0.497524, acc 0.734375
2020-02-08T02:43:21.017966: step 844, loss 0.50021, acc 0.75
2020-02-08T02:43:21.136088: step 845, loss 0.457299, acc 0.75
2020-02-08T02:43:21.250895: step 846, loss 0.499267, acc 0.78125
2020-02-08T02:43:21.719965: step 847, loss 0.422424, acc 0.78125
2020-02-08T02:43:21.841423: step 848, loss 0.431817, acc 0.828125
2020-02-08T02:43:21.962074: step 849, loss 0.327819, acc 0.84375
2020-02-08T02:43:22.079966: step 850, loss 0.417229, acc 0.796875
2020-02-08T02:43:22.197260: step 851, loss 0.464125, acc 0.78125
2020-02-08T02:43:22.314576: step 852, loss 0.501436, acc 0.765625
2020-02-08T02:43:22.432660: step 853, loss 0.552626, acc 0.71875
2020-02-08T02:43:22.549596: step 854, loss 0.495584, acc 0.75
2020-02-08T02:43:22.667490: step 855, loss 0.358281, acc 0.859375
2020-02-08T02:43:22.787578: step 856, loss 0.554324, acc 0.75
2020-02-08T02:43:22.905657: step 857, loss 0.485223, acc 0.78125
2020-02-08T02:43:23.020154: step 858, loss 0.537627, acc 0.75
2020-02-08T02:43:23.136476: step 859, loss 0.384316, acc 0.796875
2020-02-08T02:43:23.251414: step 860, loss 0.349784, acc 0.828125
2020-02-08T02:43:23.366716: step 861, loss 0.508377, acc 0.828125
2020-02-08T02:43:23.485388: step 862, loss 0.38616, acc 0.796875
2020-02-08T02:43:23.603099: step 863, loss 0.386045, acc 0.84375
2020-02-08T02:43:23.725350: step 864, loss 0.60079, acc 0.703125
2020-02-08T02:43:23.850482: step 865, loss 0.384537, acc 0.84375
2020-02-08T02:43:23.970525: step 866, loss 0.385154, acc 0.796875
2020-02-08T02:43:24.087871: step 867, loss 0.492855, acc 0.75
2020-02-08T02:43:24.203690: step 868, loss 0.558612, acc 0.6875
2020-02-08T02:43:24.322520: step 869, loss 0.462157, acc 0.765625
2020-02-08T02:43:24.438472: step 870, loss 0.360252, acc 0.84375
2020-02-08T02:43:24.554204: step 871, loss 0.507165, acc 0.796875
2020-02-08T02:43:24.673151: step 872, loss 0.283641, acc 0.90625
2020-02-08T02:43:24.792176: step 873, loss 0.442701, acc 0.78125
2020-02-08T02:43:24.909661: step 874, loss 0.378477, acc 0.796875
2020-02-08T02:43:25.025711: step 875, loss 0.409033, acc 0.78125
2020-02-08T02:43:25.140950: step 876, loss 0.42485, acc 0.75
2020-02-08T02:43:25.258817: step 877, loss 0.471493, acc 0.78125
2020-02-08T02:43:25.377850: step 878, loss 0.437991, acc 0.78125
2020-02-08T02:43:25.495095: step 879, loss 0.513872, acc 0.734375
2020-02-08T02:43:25.612037: step 880, loss 0.433686, acc 0.796875
2020-02-08T02:43:25.732748: step 881, loss 0.432542, acc 0.828125
2020-02-08T02:43:25.850403: step 882, loss 0.450654, acc 0.765625
2020-02-08T02:43:25.971275: step 883, loss 0.429209, acc 0.8125
2020-02-08T02:43:26.089119: step 884, loss 0.346321, acc 0.84375
2020-02-08T02:43:26.210877: step 885, loss 0.461274, acc 0.765625
2020-02-08T02:43:26.332568: step 886, loss 0.457303, acc 0.75
2020-02-08T02:43:26.448839: step 887, loss 0.453207, acc 0.796875
2020-02-08T02:43:26.568068: step 888, loss 0.495384, acc 0.765625
2020-02-08T02:43:26.689170: step 889, loss 0.364234, acc 0.859375
2020-02-08T02:43:26.812533: step 890, loss 0.336948, acc 0.875
2020-02-08T02:43:26.929860: step 891, loss 0.407702, acc 0.78125
2020-02-08T02:43:27.046353: step 892, loss 0.572399, acc 0.765625
2020-02-08T02:43:27.164892: step 893, loss 0.500587, acc 0.734375
2020-02-08T02:43:27.282027: step 894, loss 0.474944, acc 0.734375
2020-02-08T02:43:27.399626: step 895, loss 0.442444, acc 0.796875
2020-02-08T02:43:27.517177: step 896, loss 0.421744, acc 0.8125
2020-02-08T02:43:27.634851: step 897, loss 0.525447, acc 0.78125
2020-02-08T02:43:27.757573: step 898, loss 0.305385, acc 0.875
2020-02-08T02:43:27.884914: step 899, loss 0.318768, acc 0.8125
2020-02-08T02:43:27.996923: step 900, loss 0.412486, acc 0.8

Evaluation:
2020-02-08T02:43:28.186646: step 900, loss 0.573406, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-900

2020-02-08T02:43:30.622047: step 901, loss 0.371859, acc 0.828125
2020-02-08T02:43:30.740059: step 902, loss 0.329016, acc 0.84375
2020-02-08T02:43:30.861065: step 903, loss 0.204684, acc 0.9375
2020-02-08T02:43:30.979893: step 904, loss 0.414271, acc 0.828125
2020-02-08T02:43:31.095607: step 905, loss 0.327518, acc 0.890625
2020-02-08T02:43:31.214669: step 906, loss 0.434176, acc 0.828125
2020-02-08T02:43:31.332944: step 907, loss 0.409892, acc 0.8125
2020-02-08T02:43:31.450868: step 908, loss 0.313514, acc 0.875
2020-02-08T02:43:31.566475: step 909, loss 0.391459, acc 0.859375
2020-02-08T02:43:31.683111: step 910, loss 0.446079, acc 0.734375
2020-02-08T02:43:31.805008: step 911, loss 0.332929, acc 0.890625
2020-02-08T02:43:31.923898: step 912, loss 0.457992, acc 0.78125
2020-02-08T02:43:32.047579: step 913, loss 0.281371, acc 0.890625
2020-02-08T02:43:32.163772: step 914, loss 0.360819, acc 0.828125
2020-02-08T02:43:32.281645: step 915, loss 0.316447, acc 0.90625
2020-02-08T02:43:32.397341: step 916, loss 0.306666, acc 0.875
2020-02-08T02:43:32.515270: step 917, loss 0.364352, acc 0.859375
2020-02-08T02:43:32.629471: step 918, loss 0.297025, acc 0.921875
2020-02-08T02:43:32.745629: step 919, loss 0.270892, acc 0.90625
2020-02-08T02:43:32.861880: step 920, loss 0.303267, acc 0.921875
2020-02-08T02:43:32.982955: step 921, loss 0.31534, acc 0.84375
2020-02-08T02:43:33.100887: step 922, loss 0.431177, acc 0.765625
2020-02-08T02:43:33.219255: step 923, loss 0.2992, acc 0.828125
2020-02-08T02:43:33.334782: step 924, loss 0.258025, acc 0.90625
2020-02-08T02:43:33.449790: step 925, loss 0.33919, acc 0.859375
2020-02-08T02:43:33.577481: step 926, loss 0.442673, acc 0.796875
2020-02-08T02:43:33.704382: step 927, loss 0.426903, acc 0.78125
2020-02-08T02:43:33.822163: step 928, loss 0.334925, acc 0.828125
2020-02-08T02:43:33.939816: step 929, loss 0.372479, acc 0.859375
2020-02-08T02:43:34.069824: step 930, loss 0.383297, acc 0.8125
2020-02-08T02:43:34.185995: step 931, loss 0.345104, acc 0.859375
2020-02-08T02:43:34.302657: step 932, loss 0.221578, acc 0.9375
2020-02-08T02:43:34.420260: step 933, loss 0.228457, acc 0.921875
2020-02-08T02:43:34.538835: step 934, loss 0.358353, acc 0.84375
2020-02-08T02:43:34.653331: step 935, loss 0.433655, acc 0.78125
2020-02-08T02:43:34.777137: step 936, loss 0.480674, acc 0.78125
2020-02-08T02:43:34.891977: step 937, loss 0.337276, acc 0.8125
2020-02-08T02:43:35.011252: step 938, loss 0.441118, acc 0.796875
2020-02-08T02:43:35.131363: step 939, loss 0.252286, acc 0.9375
2020-02-08T02:43:35.246794: step 940, loss 0.383098, acc 0.8125
2020-02-08T02:43:35.363726: step 941, loss 0.466489, acc 0.796875
2020-02-08T02:43:35.482114: step 942, loss 0.303729, acc 0.890625
2020-02-08T02:43:35.598942: step 943, loss 0.40474, acc 0.796875
2020-02-08T02:43:35.719472: step 944, loss 0.342753, acc 0.828125
2020-02-08T02:43:35.835413: step 945, loss 0.323905, acc 0.875
2020-02-08T02:43:35.954512: step 946, loss 0.402476, acc 0.84375
2020-02-08T02:43:36.075626: step 947, loss 0.336554, acc 0.875
2020-02-08T02:43:36.190029: step 948, loss 0.42384, acc 0.78125
2020-02-08T02:43:36.305639: step 949, loss 0.408964, acc 0.8125
2020-02-08T02:43:36.422272: step 950, loss 0.428914, acc 0.84375
2020-02-08T02:43:36.537980: step 951, loss 0.334969, acc 0.859375
2020-02-08T02:43:36.657465: step 952, loss 0.432175, acc 0.8125
2020-02-08T02:43:36.778600: step 953, loss 0.350343, acc 0.859375
2020-02-08T02:43:36.893870: step 954, loss 0.473829, acc 0.8125
2020-02-08T02:43:37.014320: step 955, loss 0.332699, acc 0.890625
2020-02-08T02:43:37.131497: step 956, loss 0.341343, acc 0.875
2020-02-08T02:43:37.248229: step 957, loss 0.311267, acc 0.859375
2020-02-08T02:43:37.364487: step 958, loss 0.242476, acc 0.90625
2020-02-08T02:43:37.485039: step 959, loss 0.536593, acc 0.71875
2020-02-08T02:43:37.608702: step 960, loss 0.487415, acc 0.8125
2020-02-08T02:43:37.730250: step 961, loss 0.28525, acc 0.875
2020-02-08T02:43:37.846329: step 962, loss 0.403605, acc 0.8125
2020-02-08T02:43:37.965077: step 963, loss 0.212432, acc 0.90625
2020-02-08T02:43:38.083957: step 964, loss 0.36255, acc 0.8125
2020-02-08T02:43:38.198146: step 965, loss 0.281859, acc 0.875
2020-02-08T02:43:38.314672: step 966, loss 0.352387, acc 0.875
2020-02-08T02:43:38.431197: step 967, loss 0.380444, acc 0.84375
2020-02-08T02:43:38.546220: step 968, loss 0.429925, acc 0.8125
2020-02-08T02:43:38.670911: step 969, loss 0.377865, acc 0.875
2020-02-08T02:43:38.792086: step 970, loss 0.276474, acc 0.859375
2020-02-08T02:43:38.910036: step 971, loss 0.414972, acc 0.8125
2020-02-08T02:43:39.030564: step 972, loss 0.332941, acc 0.859375
2020-02-08T02:43:39.158456: step 973, loss 0.34913, acc 0.84375
2020-02-08T02:43:39.283258: step 974, loss 0.452603, acc 0.75
2020-02-08T02:43:39.401873: step 975, loss 0.398562, acc 0.84375
2020-02-08T02:43:39.523951: step 976, loss 0.256278, acc 0.90625
2020-02-08T02:43:39.640621: step 977, loss 0.371552, acc 0.859375
2020-02-08T02:43:39.762874: step 978, loss 0.275562, acc 0.890625
2020-02-08T02:43:39.879647: step 979, loss 0.417788, acc 0.765625
2020-02-08T02:43:39.995207: step 980, loss 0.363669, acc 0.859375
2020-02-08T02:43:40.112956: step 981, loss 0.251858, acc 0.90625
2020-02-08T02:43:40.229237: step 982, loss 0.31045, acc 0.875
2020-02-08T02:43:40.346823: step 983, loss 0.337386, acc 0.875
2020-02-08T02:43:40.465420: step 984, loss 0.284772, acc 0.890625
2020-02-08T02:43:40.583381: step 985, loss 0.206419, acc 0.921875
2020-02-08T02:43:40.701883: step 986, loss 0.306841, acc 0.875
2020-02-08T02:43:40.824281: step 987, loss 0.439912, acc 0.796875
2020-02-08T02:43:40.946256: step 988, loss 0.417549, acc 0.8125
2020-02-08T02:43:41.065820: step 989, loss 0.35503, acc 0.875
2020-02-08T02:43:41.183468: step 990, loss 0.380205, acc 0.8125
2020-02-08T02:43:41.301756: step 991, loss 0.418654, acc 0.796875
2020-02-08T02:43:41.429921: step 992, loss 0.287222, acc 0.859375
2020-02-08T02:43:41.544950: step 993, loss 0.332003, acc 0.828125
2020-02-08T02:43:41.672709: step 994, loss 0.373307, acc 0.828125
2020-02-08T02:43:41.792422: step 995, loss 0.295471, acc 0.90625
2020-02-08T02:43:41.909780: step 996, loss 0.38771, acc 0.84375
2020-02-08T02:43:42.027839: step 997, loss 0.371863, acc 0.8125
2020-02-08T02:43:42.149334: step 998, loss 0.335909, acc 0.84375
2020-02-08T02:43:42.266474: step 999, loss 0.456402, acc 0.765625
2020-02-08T02:43:42.385517: step 1000, loss 0.373457, acc 0.8125

Evaluation:
2020-02-08T02:43:42.575524: step 1000, loss 0.569728, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1000

2020-02-08T02:43:44.057833: step 1001, loss 0.416776, acc 0.8125
2020-02-08T02:43:44.176982: step 1002, loss 0.363556, acc 0.859375
2020-02-08T02:43:44.292941: step 1003, loss 0.344299, acc 0.84375
2020-02-08T02:43:44.412204: step 1004, loss 0.334288, acc 0.859375
2020-02-08T02:43:44.537505: step 1005, loss 0.327583, acc 0.828125
2020-02-08T02:43:44.656826: step 1006, loss 0.370419, acc 0.859375
2020-02-08T02:43:44.788655: step 1007, loss 0.270172, acc 0.875
2020-02-08T02:43:44.905744: step 1008, loss 0.411818, acc 0.796875
2020-02-08T02:43:45.022128: step 1009, loss 0.319263, acc 0.859375
2020-02-08T02:43:45.138703: step 1010, loss 0.354357, acc 0.84375
2020-02-08T02:43:45.258883: step 1011, loss 0.370523, acc 0.84375
2020-02-08T02:43:45.377347: step 1012, loss 0.330695, acc 0.875
2020-02-08T02:43:45.491392: step 1013, loss 0.357341, acc 0.90625
2020-02-08T02:43:45.607046: step 1014, loss 0.306381, acc 0.859375
2020-02-08T02:43:45.728940: step 1015, loss 0.449783, acc 0.78125
2020-02-08T02:43:45.844376: step 1016, loss 0.314774, acc 0.859375
2020-02-08T02:43:45.960340: step 1017, loss 0.373318, acc 0.8125
2020-02-08T02:43:46.080164: step 1018, loss 0.282382, acc 0.890625
2020-02-08T02:43:46.197595: step 1019, loss 0.366614, acc 0.859375
2020-02-08T02:43:46.313646: step 1020, loss 0.419362, acc 0.796875
2020-02-08T02:43:46.429393: step 1021, loss 0.276335, acc 0.890625
2020-02-08T02:43:46.544716: step 1022, loss 0.285751, acc 0.921875
2020-02-08T02:43:46.666618: step 1023, loss 0.406982, acc 0.828125
2020-02-08T02:43:46.785669: step 1024, loss 0.50212, acc 0.75
2020-02-08T02:43:46.902196: step 1025, loss 0.377927, acc 0.78125
2020-02-08T02:43:47.019382: step 1026, loss 0.428642, acc 0.796875
2020-02-08T02:43:47.135633: step 1027, loss 0.409684, acc 0.78125
2020-02-08T02:43:47.250583: step 1028, loss 0.347249, acc 0.84375
2020-02-08T02:43:47.370053: step 1029, loss 0.378997, acc 0.859375
2020-02-08T02:43:47.485065: step 1030, loss 0.39656, acc 0.84375
2020-02-08T02:43:47.603022: step 1031, loss 0.406974, acc 0.84375
2020-02-08T02:43:47.723040: step 1032, loss 0.562002, acc 0.796875
2020-02-08T02:43:47.838049: step 1033, loss 0.39221, acc 0.8125
2020-02-08T02:43:47.953887: step 1034, loss 0.351551, acc 0.8125
2020-02-08T02:43:48.072548: step 1035, loss 0.342506, acc 0.859375
2020-02-08T02:43:48.187460: step 1036, loss 0.288203, acc 0.921875
2020-02-08T02:43:48.307370: step 1037, loss 0.306943, acc 0.828125
2020-02-08T02:43:48.424195: step 1038, loss 0.48075, acc 0.765625
2020-02-08T02:43:48.539322: step 1039, loss 0.411456, acc 0.828125
2020-02-08T02:43:48.660879: step 1040, loss 0.549342, acc 0.734375
2020-02-08T02:43:48.783570: step 1041, loss 0.373334, acc 0.828125
2020-02-08T02:43:48.900169: step 1042, loss 0.253272, acc 0.9375
2020-02-08T02:43:49.016232: step 1043, loss 0.279618, acc 0.921875
2020-02-08T02:43:49.134963: step 1044, loss 0.424889, acc 0.796875
2020-02-08T02:43:49.249716: step 1045, loss 0.347383, acc 0.84375
2020-02-08T02:43:49.365803: step 1046, loss 0.499944, acc 0.84375
2020-02-08T02:43:49.488767: step 1047, loss 0.434487, acc 0.796875
2020-02-08T02:43:49.609190: step 1048, loss 0.402061, acc 0.84375
2020-02-08T02:43:49.728668: step 1049, loss 0.332278, acc 0.84375
2020-02-08T02:43:49.843720: step 1050, loss 0.337038, acc 0.85
2020-02-08T02:43:49.966313: step 1051, loss 0.203304, acc 0.9375
2020-02-08T02:43:50.081292: step 1052, loss 0.284755, acc 0.890625
2020-02-08T02:43:50.198793: step 1053, loss 0.292281, acc 0.8125
2020-02-08T02:43:50.315994: step 1054, loss 0.29046, acc 0.859375
2020-02-08T02:43:50.431760: step 1055, loss 0.406276, acc 0.8125
2020-02-08T02:43:50.547464: step 1056, loss 0.354253, acc 0.84375
2020-02-08T02:43:50.665396: step 1057, loss 0.237143, acc 0.890625
2020-02-08T02:43:50.787038: step 1058, loss 0.448794, acc 0.828125
2020-02-08T02:43:50.908353: step 1059, loss 0.302742, acc 0.875
2020-02-08T02:43:51.035252: step 1060, loss 0.299029, acc 0.90625
2020-02-08T02:43:51.153335: step 1061, loss 0.260134, acc 0.921875
2020-02-08T02:43:51.270058: step 1062, loss 0.242439, acc 0.921875
2020-02-08T02:43:51.389568: step 1063, loss 0.321251, acc 0.859375
2020-02-08T02:43:51.569661: step 1064, loss 0.338893, acc 0.859375
2020-02-08T02:43:51.694368: step 1065, loss 0.342004, acc 0.8125
2020-02-08T02:43:51.816775: step 1066, loss 0.257372, acc 0.90625
2020-02-08T02:43:51.933273: step 1067, loss 0.23811, acc 0.921875
2020-02-08T02:43:52.051549: step 1068, loss 0.342208, acc 0.875
2020-02-08T02:43:52.170502: step 1069, loss 0.200535, acc 0.9375
2020-02-08T02:43:52.288532: step 1070, loss 0.287808, acc 0.90625
2020-02-08T02:43:52.415592: step 1071, loss 0.18615, acc 0.9375
2020-02-08T02:43:52.533234: step 1072, loss 0.494779, acc 0.765625
2020-02-08T02:43:52.650962: step 1073, loss 0.258256, acc 0.890625
2020-02-08T02:43:52.774083: step 1074, loss 0.337193, acc 0.859375
2020-02-08T02:43:52.891224: step 1075, loss 0.245635, acc 0.875
2020-02-08T02:43:53.010457: step 1076, loss 0.345374, acc 0.84375
2020-02-08T02:43:53.131066: step 1077, loss 0.24889, acc 0.875
2020-02-08T02:43:53.246921: step 1078, loss 0.243342, acc 0.90625
2020-02-08T02:43:53.365583: step 1079, loss 0.417712, acc 0.78125
2020-02-08T02:43:53.484760: step 1080, loss 0.267593, acc 0.90625
2020-02-08T02:43:53.600386: step 1081, loss 0.268651, acc 0.921875
2020-02-08T02:43:53.719078: step 1082, loss 0.190713, acc 0.9375
2020-02-08T02:43:53.834278: step 1083, loss 0.291026, acc 0.890625
2020-02-08T02:43:53.950004: step 1084, loss 0.248351, acc 0.9375
2020-02-08T02:43:54.066063: step 1085, loss 0.494742, acc 0.796875
2020-02-08T02:43:54.185232: step 1086, loss 0.379754, acc 0.859375
2020-02-08T02:43:54.309611: step 1087, loss 0.421192, acc 0.859375
2020-02-08T02:43:54.432955: step 1088, loss 0.261618, acc 0.875
2020-02-08T02:43:54.548746: step 1089, loss 0.325935, acc 0.828125
2020-02-08T02:43:54.665632: step 1090, loss 0.259078, acc 0.921875
2020-02-08T02:43:54.780396: step 1091, loss 0.376498, acc 0.828125
2020-02-08T02:43:54.897335: step 1092, loss 0.450134, acc 0.734375
2020-02-08T02:43:55.016181: step 1093, loss 0.25061, acc 0.90625
2020-02-08T02:43:55.133080: step 1094, loss 0.32612, acc 0.828125
2020-02-08T02:43:55.249079: step 1095, loss 0.322869, acc 0.890625
2020-02-08T02:43:55.369300: step 1096, loss 0.313951, acc 0.859375
2020-02-08T02:43:55.484540: step 1097, loss 0.245581, acc 0.875
2020-02-08T02:43:55.605356: step 1098, loss 0.221632, acc 0.90625
2020-02-08T02:43:55.726584: step 1099, loss 0.340773, acc 0.8125
2020-02-08T02:43:55.843717: step 1100, loss 0.298881, acc 0.875

Evaluation:
2020-02-08T02:43:56.030738: step 1100, loss 0.569362, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1100

2020-02-08T02:43:58.145986: step 1101, loss 0.188669, acc 0.9375
2020-02-08T02:43:58.262566: step 1102, loss 0.307569, acc 0.8125
2020-02-08T02:43:58.375950: step 1103, loss 0.209873, acc 0.921875
2020-02-08T02:43:58.492192: step 1104, loss 0.30415, acc 0.84375
2020-02-08T02:43:58.608793: step 1105, loss 0.22091, acc 0.921875
2020-02-08T02:43:58.727460: step 1106, loss 0.21752, acc 0.9375
2020-02-08T02:43:58.841069: step 1107, loss 0.378587, acc 0.828125
2020-02-08T02:43:58.959581: step 1108, loss 0.316982, acc 0.828125
2020-02-08T02:43:59.076882: step 1109, loss 0.283817, acc 0.921875
2020-02-08T02:43:59.193953: step 1110, loss 0.179967, acc 0.921875
2020-02-08T02:43:59.313077: step 1111, loss 0.240222, acc 0.90625
2020-02-08T02:43:59.431056: step 1112, loss 0.21889, acc 0.9375
2020-02-08T02:43:59.548061: step 1113, loss 0.328737, acc 0.84375
2020-02-08T02:43:59.664808: step 1114, loss 0.258195, acc 0.875
2020-02-08T02:43:59.787416: step 1115, loss 0.504054, acc 0.8125
2020-02-08T02:43:59.907366: step 1116, loss 0.258103, acc 0.90625
2020-02-08T02:44:00.024665: step 1117, loss 0.366129, acc 0.828125
2020-02-08T02:44:00.142154: step 1118, loss 0.349412, acc 0.875
2020-02-08T02:44:00.261781: step 1119, loss 0.236389, acc 0.921875
2020-02-08T02:44:00.377515: step 1120, loss 0.260289, acc 0.890625
2020-02-08T02:44:00.493295: step 1121, loss 0.299102, acc 0.875
2020-02-08T02:44:00.612900: step 1122, loss 0.206287, acc 0.921875
2020-02-08T02:44:00.729497: step 1123, loss 0.351003, acc 0.828125
2020-02-08T02:44:00.844401: step 1124, loss 0.352772, acc 0.859375
2020-02-08T02:44:00.961341: step 1125, loss 0.205426, acc 0.921875
2020-02-08T02:44:01.079256: step 1126, loss 0.424062, acc 0.828125
2020-02-08T02:44:01.194411: step 1127, loss 0.255555, acc 0.890625
2020-02-08T02:44:01.313205: step 1128, loss 0.31855, acc 0.84375
2020-02-08T02:44:01.430103: step 1129, loss 0.371661, acc 0.828125
2020-02-08T02:44:01.546717: step 1130, loss 0.344121, acc 0.859375
2020-02-08T02:44:01.664465: step 1131, loss 0.266499, acc 0.890625
2020-02-08T02:44:01.786831: step 1132, loss 0.308164, acc 0.859375
2020-02-08T02:44:01.903001: step 1133, loss 0.271712, acc 0.875
2020-02-08T02:44:02.022640: step 1134, loss 0.406405, acc 0.796875
2020-02-08T02:44:02.139011: step 1135, loss 0.241277, acc 0.921875
2020-02-08T02:44:02.258413: step 1136, loss 0.241392, acc 0.921875
2020-02-08T02:44:02.374583: step 1137, loss 0.257459, acc 0.875
2020-02-08T02:44:02.488709: step 1138, loss 0.291945, acc 0.875
2020-02-08T02:44:02.603296: step 1139, loss 0.242486, acc 0.890625
2020-02-08T02:44:02.723035: step 1140, loss 0.22148, acc 0.90625
2020-02-08T02:44:02.840239: step 1141, loss 0.281076, acc 0.890625
2020-02-08T02:44:02.958250: step 1142, loss 0.456823, acc 0.765625
2020-02-08T02:44:03.073961: step 1143, loss 0.215303, acc 0.90625
2020-02-08T02:44:03.187128: step 1144, loss 0.313648, acc 0.84375
2020-02-08T02:44:03.302766: step 1145, loss 0.249808, acc 0.890625
2020-02-08T02:44:03.422647: step 1146, loss 0.232155, acc 0.921875
2020-02-08T02:44:03.541509: step 1147, loss 0.342435, acc 0.84375
2020-02-08T02:44:03.659542: step 1148, loss 0.288848, acc 0.890625
2020-02-08T02:44:03.780353: step 1149, loss 0.232782, acc 0.921875
2020-02-08T02:44:03.895556: step 1150, loss 0.310752, acc 0.859375
2020-02-08T02:44:04.013688: step 1151, loss 0.274648, acc 0.921875
2020-02-08T02:44:04.128471: step 1152, loss 0.355173, acc 0.859375
2020-02-08T02:44:04.246544: step 1153, loss 0.203106, acc 0.9375
2020-02-08T02:44:04.364297: step 1154, loss 0.225245, acc 0.890625
2020-02-08T02:44:04.481911: step 1155, loss 0.368361, acc 0.84375
2020-02-08T02:44:04.596965: step 1156, loss 0.362305, acc 0.828125
2020-02-08T02:44:04.715353: step 1157, loss 0.365571, acc 0.796875
2020-02-08T02:44:04.833099: step 1158, loss 0.252259, acc 0.90625
2020-02-08T02:44:04.948601: step 1159, loss 0.191477, acc 0.921875
2020-02-08T02:44:05.066813: step 1160, loss 0.348367, acc 0.84375
2020-02-08T02:44:05.184590: step 1161, loss 0.34497, acc 0.828125
2020-02-08T02:44:05.300695: step 1162, loss 0.330951, acc 0.84375
2020-02-08T02:44:05.416344: step 1163, loss 0.298566, acc 0.859375
2020-02-08T02:44:05.532819: step 1164, loss 0.38936, acc 0.828125
2020-02-08T02:44:05.651218: step 1165, loss 0.347517, acc 0.84375
2020-02-08T02:44:05.773310: step 1166, loss 0.370252, acc 0.8125
2020-02-08T02:44:05.888211: step 1167, loss 0.23462, acc 0.90625
2020-02-08T02:44:06.005826: step 1168, loss 0.328175, acc 0.828125
2020-02-08T02:44:06.120295: step 1169, loss 0.31637, acc 0.828125
2020-02-08T02:44:06.237041: step 1170, loss 0.252999, acc 0.890625
2020-02-08T02:44:06.351161: step 1171, loss 0.246595, acc 0.890625
2020-02-08T02:44:06.466402: step 1172, loss 0.286776, acc 0.859375
2020-02-08T02:44:06.583474: step 1173, loss 0.330843, acc 0.875
2020-02-08T02:44:06.697888: step 1174, loss 0.251686, acc 0.90625
2020-02-08T02:44:06.818165: step 1175, loss 0.36412, acc 0.8125
2020-02-08T02:44:06.936905: step 1176, loss 0.313552, acc 0.828125
2020-02-08T02:44:07.053183: step 1177, loss 0.37261, acc 0.84375
2020-02-08T02:44:07.171821: step 1178, loss 0.285331, acc 0.875
2020-02-08T02:44:07.288162: step 1179, loss 0.320491, acc 0.84375
2020-02-08T02:44:07.402816: step 1180, loss 0.351218, acc 0.84375
2020-02-08T02:44:07.520749: step 1181, loss 0.341331, acc 0.84375
2020-02-08T02:44:07.638766: step 1182, loss 0.233766, acc 0.921875
2020-02-08T02:44:07.761611: step 1183, loss 0.224773, acc 0.921875
2020-02-08T02:44:07.876772: step 1184, loss 0.187294, acc 0.921875
2020-02-08T02:44:07.992897: step 1185, loss 0.259478, acc 0.90625
2020-02-08T02:44:08.113456: step 1186, loss 0.28355, acc 0.875
2020-02-08T02:44:08.231361: step 1187, loss 0.29959, acc 0.90625
2020-02-08T02:44:08.349523: step 1188, loss 0.406877, acc 0.78125
2020-02-08T02:44:08.466185: step 1189, loss 0.485645, acc 0.765625
2020-02-08T02:44:08.584016: step 1190, loss 0.246006, acc 0.90625
2020-02-08T02:44:08.698754: step 1191, loss 0.179705, acc 0.90625
2020-02-08T02:44:08.822665: step 1192, loss 0.257375, acc 0.90625
2020-02-08T02:44:08.939022: step 1193, loss 0.440845, acc 0.84375
2020-02-08T02:44:09.053973: step 1194, loss 0.45505, acc 0.78125
2020-02-08T02:44:09.171952: step 1195, loss 0.229929, acc 0.921875
2020-02-08T02:44:09.290543: step 1196, loss 0.296882, acc 0.875
2020-02-08T02:44:09.405970: step 1197, loss 0.184354, acc 0.921875
2020-02-08T02:44:09.521545: step 1198, loss 0.413422, acc 0.84375
2020-02-08T02:44:09.637429: step 1199, loss 0.428993, acc 0.796875
2020-02-08T02:44:09.757015: step 1200, loss 0.190921, acc 0.916667

Evaluation:
2020-02-08T02:44:09.943838: step 1200, loss 0.572991, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1200

2020-02-08T02:44:11.630767: step 1201, loss 0.319781, acc 0.875
2020-02-08T02:44:11.750575: step 1202, loss 0.291156, acc 0.84375
2020-02-08T02:44:11.866683: step 1203, loss 0.138587, acc 0.96875
2020-02-08T02:44:11.980841: step 1204, loss 0.220465, acc 0.9375
2020-02-08T02:44:12.095494: step 1205, loss 0.200807, acc 0.921875
2020-02-08T02:44:12.213233: step 1206, loss 0.176545, acc 0.9375
2020-02-08T02:44:12.333188: step 1207, loss 0.189596, acc 0.921875
2020-02-08T02:44:12.450812: step 1208, loss 0.251072, acc 0.90625
2020-02-08T02:44:12.575065: step 1209, loss 0.22287, acc 0.9375
2020-02-08T02:44:12.690336: step 1210, loss 0.331771, acc 0.875
2020-02-08T02:44:12.811303: step 1211, loss 0.379419, acc 0.859375
2020-02-08T02:44:12.925662: step 1212, loss 0.184072, acc 0.921875
2020-02-08T02:44:13.040776: step 1213, loss 0.196502, acc 0.90625
2020-02-08T02:44:13.155259: step 1214, loss 0.258858, acc 0.875
2020-02-08T02:44:13.270838: step 1215, loss 0.270741, acc 0.84375
2020-02-08T02:44:13.386028: step 1216, loss 0.455785, acc 0.78125
2020-02-08T02:44:13.501386: step 1217, loss 0.233991, acc 0.890625
2020-02-08T02:44:13.618881: step 1218, loss 0.231156, acc 0.9375
2020-02-08T02:44:13.737228: step 1219, loss 0.319093, acc 0.890625
2020-02-08T02:44:13.852794: step 1220, loss 0.392359, acc 0.890625
2020-02-08T02:44:13.969960: step 1221, loss 0.25866, acc 0.90625
2020-02-08T02:44:14.086873: step 1222, loss 0.196021, acc 0.921875
2020-02-08T02:44:14.199746: step 1223, loss 0.361959, acc 0.859375
2020-02-08T02:44:14.318509: step 1224, loss 0.29463, acc 0.90625
2020-02-08T02:44:14.434041: step 1225, loss 0.22626, acc 0.90625
2020-02-08T02:44:14.548498: step 1226, loss 0.249031, acc 0.9375
2020-02-08T02:44:14.665476: step 1227, loss 0.250713, acc 0.84375
2020-02-08T02:44:14.784240: step 1228, loss 0.316777, acc 0.875
2020-02-08T02:44:14.897743: step 1229, loss 0.266902, acc 0.90625
2020-02-08T02:44:15.013782: step 1230, loss 0.178694, acc 0.90625
2020-02-08T02:44:15.131195: step 1231, loss 0.202321, acc 0.953125
2020-02-08T02:44:15.246455: step 1232, loss 0.241557, acc 0.921875
2020-02-08T02:44:15.364510: step 1233, loss 0.196024, acc 0.9375
2020-02-08T02:44:15.480722: step 1234, loss 0.172349, acc 0.953125
2020-02-08T02:44:15.596294: step 1235, loss 0.229442, acc 0.875
2020-02-08T02:44:15.710800: step 1236, loss 0.209822, acc 0.90625
2020-02-08T02:44:15.829114: step 1237, loss 0.179322, acc 0.9375
2020-02-08T02:44:15.944070: step 1238, loss 0.236231, acc 0.90625
2020-02-08T02:44:16.065746: step 1239, loss 0.127673, acc 0.96875
2020-02-08T02:44:16.182908: step 1240, loss 0.215053, acc 0.90625
2020-02-08T02:44:16.300088: step 1241, loss 0.186731, acc 0.9375
2020-02-08T02:44:16.415670: step 1242, loss 0.138087, acc 0.953125
2020-02-08T02:44:16.532123: step 1243, loss 0.11466, acc 0.984375
2020-02-08T02:44:16.646583: step 1244, loss 0.202257, acc 0.921875
2020-02-08T02:44:16.766936: step 1245, loss 0.194575, acc 0.921875
2020-02-08T02:44:16.882195: step 1246, loss 0.244266, acc 0.890625
2020-02-08T02:44:16.995220: step 1247, loss 0.247272, acc 0.90625
2020-02-08T02:44:17.114549: step 1248, loss 0.196864, acc 0.90625
2020-02-08T02:44:17.231035: step 1249, loss 0.281891, acc 0.875
2020-02-08T02:44:17.346573: step 1250, loss 0.244107, acc 0.859375
2020-02-08T02:44:17.464506: step 1251, loss 0.271648, acc 0.890625
2020-02-08T02:44:17.580647: step 1252, loss 0.199127, acc 0.953125
2020-02-08T02:44:17.691720: step 1253, loss 0.220132, acc 0.890625
2020-02-08T02:44:17.810603: step 1254, loss 0.27808, acc 0.859375
2020-02-08T02:44:17.927851: step 1255, loss 0.28055, acc 0.90625
2020-02-08T02:44:18.042981: step 1256, loss 0.206842, acc 0.90625
2020-02-08T02:44:18.159804: step 1257, loss 0.241142, acc 0.90625
2020-02-08T02:44:18.277505: step 1258, loss 0.254114, acc 0.90625
2020-02-08T02:44:18.394991: step 1259, loss 0.273705, acc 0.859375
2020-02-08T02:44:18.512297: step 1260, loss 0.170612, acc 0.9375
2020-02-08T02:44:18.630520: step 1261, loss 0.186108, acc 0.9375
2020-02-08T02:44:18.748054: step 1262, loss 0.13001, acc 0.953125
2020-02-08T02:44:18.865794: step 1263, loss 0.303683, acc 0.84375
2020-02-08T02:44:18.981109: step 1264, loss 0.144966, acc 0.984375
2020-02-08T02:44:19.097237: step 1265, loss 0.239138, acc 0.859375
2020-02-08T02:44:19.215278: step 1266, loss 0.259169, acc 0.9375
2020-02-08T02:44:19.332630: step 1267, loss 0.227217, acc 0.921875
2020-02-08T02:44:19.447731: step 1268, loss 0.242278, acc 0.90625
2020-02-08T02:44:19.566498: step 1269, loss 0.268933, acc 0.890625
2020-02-08T02:44:19.681835: step 1270, loss 0.309756, acc 0.90625
2020-02-08T02:44:19.801478: step 1271, loss 0.176029, acc 0.921875
2020-02-08T02:44:19.919133: step 1272, loss 0.119562, acc 0.953125
2020-02-08T02:44:20.037783: step 1273, loss 0.282007, acc 0.859375
2020-02-08T02:44:20.159654: step 1274, loss 0.314011, acc 0.859375
2020-02-08T02:44:20.277518: step 1275, loss 0.236614, acc 0.90625
2020-02-08T02:44:20.394528: step 1276, loss 0.379963, acc 0.90625
2020-02-08T02:44:20.513444: step 1277, loss 0.191953, acc 0.890625
2020-02-08T02:44:20.632386: step 1278, loss 0.236071, acc 0.90625
2020-02-08T02:44:20.749221: step 1279, loss 0.19421, acc 0.921875
2020-02-08T02:44:20.865208: step 1280, loss 0.221908, acc 0.921875
2020-02-08T02:44:20.982376: step 1281, loss 0.288071, acc 0.90625
2020-02-08T02:44:21.094114: step 1282, loss 0.210282, acc 0.921875
2020-02-08T02:44:21.213717: step 1283, loss 0.23348, acc 0.9375
2020-02-08T02:44:21.502629: step 1284, loss 0.2969, acc 0.875
2020-02-08T02:44:21.627924: step 1285, loss 0.273521, acc 0.890625
2020-02-08T02:44:21.744461: step 1286, loss 0.199457, acc 0.953125
2020-02-08T02:44:21.863310: step 1287, loss 0.381274, acc 0.875
2020-02-08T02:44:21.982438: step 1288, loss 0.0946128, acc 0.9375
2020-02-08T02:44:22.100640: step 1289, loss 0.189783, acc 0.90625
2020-02-08T02:44:22.217469: step 1290, loss 0.211103, acc 0.90625
2020-02-08T02:44:22.337756: step 1291, loss 0.336594, acc 0.875
2020-02-08T02:44:22.456316: step 1292, loss 0.224135, acc 0.9375
2020-02-08T02:44:22.573460: step 1293, loss 0.259933, acc 0.921875
2020-02-08T02:44:22.689202: step 1294, loss 0.198544, acc 0.90625
2020-02-08T02:44:22.808722: step 1295, loss 0.281133, acc 0.875
2020-02-08T02:44:22.922959: step 1296, loss 0.208697, acc 0.90625
2020-02-08T02:44:23.037029: step 1297, loss 0.336853, acc 0.859375
2020-02-08T02:44:23.154301: step 1298, loss 0.246323, acc 0.90625
2020-02-08T02:44:23.271733: step 1299, loss 0.220113, acc 0.90625
2020-02-08T02:44:23.389084: step 1300, loss 0.302364, acc 0.859375

Evaluation:
2020-02-08T02:44:23.575101: step 1300, loss 0.578786, acc 0.74015

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1300

2020-02-08T02:44:25.203061: step 1301, loss 0.205788, acc 0.90625
2020-02-08T02:44:25.323243: step 1302, loss 0.21765, acc 0.875
2020-02-08T02:44:25.437912: step 1303, loss 0.276507, acc 0.90625
2020-02-08T02:44:25.558692: step 1304, loss 0.185948, acc 0.890625
2020-02-08T02:44:25.675799: step 1305, loss 0.240892, acc 0.921875
2020-02-08T02:44:25.797367: step 1306, loss 0.209953, acc 0.921875
2020-02-08T02:44:25.916347: step 1307, loss 0.252027, acc 0.875
2020-02-08T02:44:26.034645: step 1308, loss 0.183457, acc 0.9375
2020-02-08T02:44:26.147819: step 1309, loss 0.300051, acc 0.875
2020-02-08T02:44:26.265665: step 1310, loss 0.273517, acc 0.875
2020-02-08T02:44:26.382618: step 1311, loss 0.266121, acc 0.875
2020-02-08T02:44:26.497085: step 1312, loss 0.271546, acc 0.90625
2020-02-08T02:44:26.613857: step 1313, loss 0.259268, acc 0.859375
2020-02-08T02:44:26.730358: step 1314, loss 0.250332, acc 0.890625
2020-02-08T02:44:26.846423: step 1315, loss 0.218923, acc 0.90625
2020-02-08T02:44:26.967231: step 1316, loss 0.236015, acc 0.921875
2020-02-08T02:44:27.085122: step 1317, loss 0.349453, acc 0.890625
2020-02-08T02:44:27.200618: step 1318, loss 0.143174, acc 0.96875
2020-02-08T02:44:27.319181: step 1319, loss 0.229724, acc 0.875
2020-02-08T02:44:27.436715: step 1320, loss 0.255179, acc 0.890625
2020-02-08T02:44:27.551342: step 1321, loss 0.194528, acc 0.921875
2020-02-08T02:44:27.669796: step 1322, loss 0.397344, acc 0.859375
2020-02-08T02:44:27.790447: step 1323, loss 0.157962, acc 0.9375
2020-02-08T02:44:27.904669: step 1324, loss 0.264231, acc 0.921875
2020-02-08T02:44:28.022301: step 1325, loss 0.155368, acc 0.96875
2020-02-08T02:44:28.139630: step 1326, loss 0.157815, acc 0.9375
2020-02-08T02:44:28.256311: step 1327, loss 0.313538, acc 0.84375
2020-02-08T02:44:28.375334: step 1328, loss 0.201375, acc 0.953125
2020-02-08T02:44:28.490739: step 1329, loss 0.190108, acc 0.921875
2020-02-08T02:44:28.610651: step 1330, loss 0.308931, acc 0.8125
2020-02-08T02:44:28.728757: step 1331, loss 0.134858, acc 0.921875
2020-02-08T02:44:28.844785: step 1332, loss 0.241731, acc 0.90625
2020-02-08T02:44:28.962632: step 1333, loss 0.14691, acc 0.953125
2020-02-08T02:44:29.108385: step 1334, loss 0.190197, acc 0.9375
2020-02-08T02:44:29.226872: step 1335, loss 0.233895, acc 0.875
2020-02-08T02:44:29.340515: step 1336, loss 0.189292, acc 0.90625
2020-02-08T02:44:29.456827: step 1337, loss 0.218426, acc 0.9375
2020-02-08T02:44:29.570864: step 1338, loss 0.227563, acc 0.921875
2020-02-08T02:44:29.687544: step 1339, loss 0.439694, acc 0.828125
2020-02-08T02:44:29.807842: step 1340, loss 0.272016, acc 0.875
2020-02-08T02:44:29.923058: step 1341, loss 0.21379, acc 0.90625
2020-02-08T02:44:30.039613: step 1342, loss 0.194879, acc 0.921875
2020-02-08T02:44:30.156832: step 1343, loss 0.192204, acc 0.90625
2020-02-08T02:44:30.273157: step 1344, loss 0.268654, acc 0.84375
2020-02-08T02:44:30.389921: step 1345, loss 0.350601, acc 0.84375
2020-02-08T02:44:30.506464: step 1346, loss 0.270521, acc 0.90625
2020-02-08T02:44:30.624333: step 1347, loss 0.251311, acc 0.90625
2020-02-08T02:44:30.739697: step 1348, loss 0.300162, acc 0.859375
2020-02-08T02:44:30.856562: step 1349, loss 0.235506, acc 0.859375
2020-02-08T02:44:30.966353: step 1350, loss 0.268057, acc 0.866667
2020-02-08T02:44:31.085097: step 1351, loss 0.220481, acc 0.921875
2020-02-08T02:44:31.202070: step 1352, loss 0.19198, acc 0.953125
2020-02-08T02:44:31.316193: step 1353, loss 0.230692, acc 0.921875
2020-02-08T02:44:31.431510: step 1354, loss 0.225649, acc 0.921875
2020-02-08T02:44:31.548974: step 1355, loss 0.100065, acc 0.96875
2020-02-08T02:44:31.666544: step 1356, loss 0.185692, acc 0.921875
2020-02-08T02:44:31.786538: step 1357, loss 0.165618, acc 0.90625
2020-02-08T02:44:31.902962: step 1358, loss 0.316399, acc 0.859375
2020-02-08T02:44:32.020303: step 1359, loss 0.367231, acc 0.84375
2020-02-08T02:44:32.137343: step 1360, loss 0.168124, acc 0.921875
2020-02-08T02:44:32.254624: step 1361, loss 0.206655, acc 0.921875
2020-02-08T02:44:32.372092: step 1362, loss 0.21586, acc 0.90625
2020-02-08T02:44:32.489817: step 1363, loss 0.121311, acc 0.984375
2020-02-08T02:44:32.605916: step 1364, loss 0.189364, acc 0.90625
2020-02-08T02:44:32.722551: step 1365, loss 0.137138, acc 0.953125
2020-02-08T02:44:32.839170: step 1366, loss 0.285102, acc 0.890625
2020-02-08T02:44:32.957032: step 1367, loss 0.133859, acc 0.953125
2020-02-08T02:44:33.075126: step 1368, loss 0.0974791, acc 0.984375
2020-02-08T02:44:33.192467: step 1369, loss 0.163841, acc 0.9375
2020-02-08T02:44:33.308849: step 1370, loss 0.16496, acc 0.953125
2020-02-08T02:44:33.426624: step 1371, loss 0.18164, acc 0.9375
2020-02-08T02:44:33.542873: step 1372, loss 0.154774, acc 0.921875
2020-02-08T02:44:33.660239: step 1373, loss 0.119541, acc 0.984375
2020-02-08T02:44:33.780030: step 1374, loss 0.125258, acc 0.96875
2020-02-08T02:44:33.895394: step 1375, loss 0.207039, acc 0.921875
2020-02-08T02:44:34.012805: step 1376, loss 0.121462, acc 0.953125
2020-02-08T02:44:34.130368: step 1377, loss 0.208052, acc 0.90625
2020-02-08T02:44:34.247910: step 1378, loss 0.228542, acc 0.9375
2020-02-08T02:44:34.364363: step 1379, loss 0.142762, acc 0.921875
2020-02-08T02:44:34.479383: step 1380, loss 0.118965, acc 0.953125
2020-02-08T02:44:34.596755: step 1381, loss 0.225867, acc 0.90625
2020-02-08T02:44:34.714209: step 1382, loss 0.184184, acc 0.9375
2020-02-08T02:44:34.829909: step 1383, loss 0.106415, acc 0.96875
2020-02-08T02:44:34.946135: step 1384, loss 0.123086, acc 0.96875
2020-02-08T02:44:35.061722: step 1385, loss 0.184007, acc 0.921875
2020-02-08T02:44:35.181304: step 1386, loss 0.210871, acc 0.921875
2020-02-08T02:44:35.298952: step 1387, loss 0.117673, acc 0.96875
2020-02-08T02:44:35.415674: step 1388, loss 0.213502, acc 0.90625
2020-02-08T02:44:35.532147: step 1389, loss 0.124077, acc 0.9375
2020-02-08T02:44:35.649467: step 1390, loss 0.124804, acc 0.953125
2020-02-08T02:44:35.770856: step 1391, loss 0.28256, acc 0.921875
2020-02-08T02:44:35.888456: step 1392, loss 0.148187, acc 0.953125
2020-02-08T02:44:36.001988: step 1393, loss 0.162723, acc 0.890625
2020-02-08T02:44:36.119110: step 1394, loss 0.126533, acc 0.984375
2020-02-08T02:44:36.235397: step 1395, loss 0.326588, acc 0.890625
2020-02-08T02:44:36.354056: step 1396, loss 0.153856, acc 0.9375
2020-02-08T02:44:36.469903: step 1397, loss 0.228287, acc 0.90625
2020-02-08T02:44:36.590282: step 1398, loss 0.147158, acc 0.9375
2020-02-08T02:44:36.707535: step 1399, loss 0.166015, acc 0.921875
2020-02-08T02:44:36.826672: step 1400, loss 0.14879, acc 0.953125

Evaluation:
2020-02-08T02:44:37.015466: step 1400, loss 0.577359, acc 0.742964

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1400

2020-02-08T02:44:39.844566: step 1401, loss 0.144463, acc 0.953125
2020-02-08T02:44:39.960379: step 1402, loss 0.315009, acc 0.859375
2020-02-08T02:44:40.077438: step 1403, loss 0.239687, acc 0.875
2020-02-08T02:44:40.192850: step 1404, loss 0.219278, acc 0.9375
2020-02-08T02:44:40.307317: step 1405, loss 0.0922211, acc 1
2020-02-08T02:44:40.420995: step 1406, loss 0.165107, acc 0.953125
2020-02-08T02:44:40.537747: step 1407, loss 0.272933, acc 0.859375
2020-02-08T02:44:40.656265: step 1408, loss 0.151686, acc 0.984375
2020-02-08T02:44:40.775480: step 1409, loss 0.213947, acc 0.90625
2020-02-08T02:44:40.893356: step 1410, loss 0.156124, acc 0.953125
2020-02-08T02:44:41.012634: step 1411, loss 0.128193, acc 0.921875
2020-02-08T02:44:41.129347: step 1412, loss 0.251723, acc 0.90625
2020-02-08T02:44:41.244195: step 1413, loss 0.204401, acc 0.90625
2020-02-08T02:44:41.361499: step 1414, loss 0.145526, acc 0.9375
2020-02-08T02:44:41.474741: step 1415, loss 0.1888, acc 0.96875
2020-02-08T02:44:41.594511: step 1416, loss 0.17125, acc 0.9375
2020-02-08T02:44:41.713292: step 1417, loss 0.19737, acc 0.9375
2020-02-08T02:44:41.830855: step 1418, loss 0.184157, acc 0.953125
2020-02-08T02:44:41.950455: step 1419, loss 0.121832, acc 0.953125
2020-02-08T02:44:42.070661: step 1420, loss 0.28446, acc 0.9375
2020-02-08T02:44:42.189083: step 1421, loss 0.164372, acc 0.9375
2020-02-08T02:44:42.304984: step 1422, loss 0.277815, acc 0.859375
2020-02-08T02:44:42.423262: step 1423, loss 0.142288, acc 0.9375
2020-02-08T02:44:42.540148: step 1424, loss 0.203315, acc 0.921875
2020-02-08T02:44:42.656314: step 1425, loss 0.266154, acc 0.828125
2020-02-08T02:44:42.777747: step 1426, loss 0.18303, acc 0.921875
2020-02-08T02:44:42.895025: step 1427, loss 0.192129, acc 0.9375
2020-02-08T02:44:43.011980: step 1428, loss 0.0887749, acc 0.96875
2020-02-08T02:44:43.129525: step 1429, loss 0.103893, acc 0.953125
2020-02-08T02:44:43.244590: step 1430, loss 0.271922, acc 0.875
2020-02-08T02:44:43.358901: step 1431, loss 0.15782, acc 0.9375
2020-02-08T02:44:43.475358: step 1432, loss 0.253962, acc 0.875
2020-02-08T02:44:43.595131: step 1433, loss 0.170169, acc 0.953125
2020-02-08T02:44:43.715038: step 1434, loss 0.109928, acc 0.953125
2020-02-08T02:44:43.840261: step 1435, loss 0.177801, acc 0.9375
2020-02-08T02:44:43.955084: step 1436, loss 0.184402, acc 0.921875
2020-02-08T02:44:44.073672: step 1437, loss 0.234702, acc 0.90625
2020-02-08T02:44:44.189000: step 1438, loss 0.181025, acc 0.953125
2020-02-08T02:44:44.305916: step 1439, loss 0.215553, acc 0.921875
2020-02-08T02:44:44.423620: step 1440, loss 0.232551, acc 0.9375
2020-02-08T02:44:44.541436: step 1441, loss 0.178579, acc 0.921875
2020-02-08T02:44:44.661541: step 1442, loss 0.235739, acc 0.90625
2020-02-08T02:44:44.782116: step 1443, loss 0.261542, acc 0.859375
2020-02-08T02:44:44.897692: step 1444, loss 0.280106, acc 0.890625
2020-02-08T02:44:45.016410: step 1445, loss 0.13793, acc 0.9375
2020-02-08T02:44:45.132956: step 1446, loss 0.10059, acc 0.953125
2020-02-08T02:44:45.247361: step 1447, loss 0.18231, acc 0.9375
2020-02-08T02:44:45.363119: step 1448, loss 0.304101, acc 0.90625
2020-02-08T02:44:45.480938: step 1449, loss 0.19057, acc 0.9375
2020-02-08T02:44:45.596402: step 1450, loss 0.11181, acc 0.953125
2020-02-08T02:44:45.714111: step 1451, loss 0.21383, acc 0.90625
2020-02-08T02:44:45.834386: step 1452, loss 0.154235, acc 0.9375
2020-02-08T02:44:45.950868: step 1453, loss 0.150474, acc 0.9375
2020-02-08T02:44:46.066909: step 1454, loss 0.206748, acc 0.90625
2020-02-08T02:44:46.185706: step 1455, loss 0.21835, acc 0.890625
2020-02-08T02:44:46.300897: step 1456, loss 0.230658, acc 0.890625
2020-02-08T02:44:46.417210: step 1457, loss 0.196334, acc 0.9375
2020-02-08T02:44:46.534779: step 1458, loss 0.176445, acc 0.921875
2020-02-08T02:44:46.649204: step 1459, loss 0.124198, acc 0.96875
2020-02-08T02:44:46.766049: step 1460, loss 0.164048, acc 0.953125
2020-02-08T02:44:46.883741: step 1461, loss 0.275318, acc 0.9375
2020-02-08T02:44:47.001802: step 1462, loss 0.149258, acc 0.953125
2020-02-08T02:44:47.118582: step 1463, loss 0.10614, acc 0.953125
2020-02-08T02:44:47.236984: step 1464, loss 0.243504, acc 0.890625
2020-02-08T02:44:47.352565: step 1465, loss 0.117374, acc 0.984375
2020-02-08T02:44:47.467998: step 1466, loss 0.131361, acc 0.9375
2020-02-08T02:44:47.590298: step 1467, loss 0.259099, acc 0.90625
2020-02-08T02:44:47.706662: step 1468, loss 0.306873, acc 0.921875
2020-02-08T02:44:47.824680: step 1469, loss 0.184658, acc 0.9375
2020-02-08T02:44:47.941166: step 1470, loss 0.166897, acc 0.96875
2020-02-08T02:44:48.058635: step 1471, loss 0.278408, acc 0.921875
2020-02-08T02:44:48.176839: step 1472, loss 0.192219, acc 0.9375
2020-02-08T02:44:48.292059: step 1473, loss 0.15149, acc 0.921875
2020-02-08T02:44:48.407613: step 1474, loss 0.200852, acc 0.9375
2020-02-08T02:44:48.526039: step 1475, loss 0.249883, acc 0.921875
2020-02-08T02:44:48.644800: step 1476, loss 0.187536, acc 0.921875
2020-02-08T02:44:48.765385: step 1477, loss 0.0978074, acc 0.96875
2020-02-08T02:44:48.881624: step 1478, loss 0.297128, acc 0.890625
2020-02-08T02:44:48.998702: step 1479, loss 0.284556, acc 0.90625
2020-02-08T02:44:49.114180: step 1480, loss 0.221056, acc 0.90625
2020-02-08T02:44:49.233198: step 1481, loss 0.145556, acc 0.9375
2020-02-08T02:44:49.349487: step 1482, loss 0.234447, acc 0.921875
2020-02-08T02:44:49.468213: step 1483, loss 0.238441, acc 0.90625
2020-02-08T02:44:49.584785: step 1484, loss 0.144324, acc 0.90625
2020-02-08T02:44:49.703486: step 1485, loss 0.225499, acc 0.875
2020-02-08T02:44:49.822814: step 1486, loss 0.117435, acc 0.9375
2020-02-08T02:44:49.935545: step 1487, loss 0.289541, acc 0.890625
2020-02-08T02:44:50.051639: step 1488, loss 0.250739, acc 0.890625
2020-02-08T02:44:50.168411: step 1489, loss 0.26829, acc 0.890625
2020-02-08T02:44:50.284509: step 1490, loss 0.114597, acc 0.984375
2020-02-08T02:44:50.399265: step 1491, loss 0.167527, acc 0.90625
2020-02-08T02:44:50.516050: step 1492, loss 0.155803, acc 0.9375
2020-02-08T02:44:50.633688: step 1493, loss 0.246899, acc 0.875
2020-02-08T02:44:50.753558: step 1494, loss 0.156153, acc 0.953125
2020-02-08T02:44:50.870905: step 1495, loss 0.173751, acc 0.9375
2020-02-08T02:44:50.987912: step 1496, loss 0.191125, acc 0.90625
2020-02-08T02:44:51.104536: step 1497, loss 0.213295, acc 0.921875
2020-02-08T02:44:51.223947: step 1498, loss 0.194376, acc 0.890625
2020-02-08T02:44:51.337456: step 1499, loss 0.25528, acc 0.890625
2020-02-08T02:44:51.649555: step 1500, loss 0.103724, acc 0.983333

Evaluation:
2020-02-08T02:44:51.851608: step 1500, loss 0.58087, acc 0.757974

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1500

2020-02-08T02:44:53.783181: step 1501, loss 0.0976791, acc 0.953125
2020-02-08T02:44:53.901170: step 1502, loss 0.153261, acc 0.96875
2020-02-08T02:44:54.016609: step 1503, loss 0.0531501, acc 1
2020-02-08T02:44:54.132520: step 1504, loss 0.0891522, acc 0.984375
2020-02-08T02:44:54.250290: step 1505, loss 0.13195, acc 0.953125
2020-02-08T02:44:54.369882: step 1506, loss 0.120712, acc 0.9375
2020-02-08T02:44:54.489197: step 1507, loss 0.13736, acc 0.921875
2020-02-08T02:44:54.606853: step 1508, loss 0.171475, acc 0.921875
2020-02-08T02:44:54.723778: step 1509, loss 0.124592, acc 0.9375
2020-02-08T02:44:54.840376: step 1510, loss 0.196445, acc 0.90625
2020-02-08T02:44:54.955922: step 1511, loss 0.14977, acc 0.921875
2020-02-08T02:44:55.071320: step 1512, loss 0.102259, acc 0.953125
2020-02-08T02:44:55.187797: step 1513, loss 0.133719, acc 0.953125
2020-02-08T02:44:55.302175: step 1514, loss 0.1036, acc 0.96875
2020-02-08T02:44:55.418348: step 1515, loss 0.0893588, acc 0.96875
2020-02-08T02:44:55.533694: step 1516, loss 0.238952, acc 0.921875
2020-02-08T02:44:55.652321: step 1517, loss 0.215059, acc 0.9375
2020-02-08T02:44:55.772790: step 1518, loss 0.109533, acc 0.953125
2020-02-08T02:44:55.889793: step 1519, loss 0.109384, acc 0.984375
2020-02-08T02:44:56.005718: step 1520, loss 0.20966, acc 0.890625
2020-02-08T02:44:56.121563: step 1521, loss 0.112887, acc 0.9375
2020-02-08T02:44:56.238945: step 1522, loss 0.10948, acc 0.953125
2020-02-08T02:44:56.353960: step 1523, loss 0.110661, acc 0.96875
2020-02-08T02:44:56.471180: step 1524, loss 0.128793, acc 0.96875
2020-02-08T02:44:56.588801: step 1525, loss 0.0855651, acc 0.953125
2020-02-08T02:44:56.703920: step 1526, loss 0.0788654, acc 0.984375
2020-02-08T02:44:56.822128: step 1527, loss 0.134233, acc 0.953125
2020-02-08T02:44:56.936511: step 1528, loss 0.189726, acc 0.9375
2020-02-08T02:44:57.054926: step 1529, loss 0.131743, acc 0.96875
2020-02-08T02:44:57.171531: step 1530, loss 0.105202, acc 0.96875
2020-02-08T02:44:57.287125: step 1531, loss 0.114396, acc 0.96875
2020-02-08T02:44:57.402442: step 1532, loss 0.148548, acc 0.9375
2020-02-08T02:44:57.519376: step 1533, loss 0.130739, acc 0.953125
2020-02-08T02:44:57.634937: step 1534, loss 0.112234, acc 0.953125
2020-02-08T02:44:57.754034: step 1535, loss 0.0893829, acc 0.984375
2020-02-08T02:44:57.870506: step 1536, loss 0.171156, acc 0.921875
2020-02-08T02:44:57.987115: step 1537, loss 0.114622, acc 0.984375
2020-02-08T02:44:58.104694: step 1538, loss 0.177576, acc 0.9375
2020-02-08T02:44:58.222046: step 1539, loss 0.133296, acc 0.953125
2020-02-08T02:44:58.338537: step 1540, loss 0.118922, acc 0.96875
2020-02-08T02:44:58.454548: step 1541, loss 0.168611, acc 0.953125
2020-02-08T02:44:58.570632: step 1542, loss 0.0862136, acc 0.984375
2020-02-08T02:44:58.688174: step 1543, loss 0.144826, acc 0.90625
2020-02-08T02:44:58.807242: step 1544, loss 0.0982755, acc 0.96875
2020-02-08T02:44:58.924966: step 1545, loss 0.158491, acc 0.953125
2020-02-08T02:44:59.039264: step 1546, loss 0.166403, acc 0.921875
2020-02-08T02:44:59.158314: step 1547, loss 0.185296, acc 0.9375
2020-02-08T02:44:59.275081: step 1548, loss 0.17714, acc 0.921875
2020-02-08T02:44:59.392950: step 1549, loss 0.214654, acc 0.90625
2020-02-08T02:44:59.511592: step 1550, loss 0.195156, acc 0.90625
2020-02-08T02:44:59.628177: step 1551, loss 0.14842, acc 0.921875
2020-02-08T02:44:59.743537: step 1552, loss 0.20252, acc 0.90625
2020-02-08T02:44:59.857505: step 1553, loss 0.289626, acc 0.90625
2020-02-08T02:44:59.974971: step 1554, loss 0.0868913, acc 0.984375
2020-02-08T02:45:00.091167: step 1555, loss 0.0610944, acc 0.984375
2020-02-08T02:45:00.207036: step 1556, loss 0.0806997, acc 0.96875
2020-02-08T02:45:00.323562: step 1557, loss 0.0413959, acc 1
2020-02-08T02:45:00.441599: step 1558, loss 0.235799, acc 0.875
2020-02-08T02:45:00.558213: step 1559, loss 0.110702, acc 0.953125
2020-02-08T02:45:00.678921: step 1560, loss 0.056413, acc 1
2020-02-08T02:45:00.797695: step 1561, loss 0.0910772, acc 0.953125
2020-02-08T02:45:00.915709: step 1562, loss 0.15071, acc 0.9375
2020-02-08T02:45:01.037418: step 1563, loss 0.116106, acc 0.921875
2020-02-08T02:45:01.155947: step 1564, loss 0.123916, acc 0.96875
2020-02-08T02:45:01.275816: step 1565, loss 0.14954, acc 0.953125
2020-02-08T02:45:01.392910: step 1566, loss 0.101008, acc 0.953125
2020-02-08T02:45:01.505828: step 1567, loss 0.239603, acc 0.921875
2020-02-08T02:45:01.624418: step 1568, loss 0.12091, acc 0.96875
2020-02-08T02:45:01.739598: step 1569, loss 0.204873, acc 0.921875
2020-02-08T02:45:01.854113: step 1570, loss 0.151356, acc 0.921875
2020-02-08T02:45:01.970321: step 1571, loss 0.147068, acc 0.96875
2020-02-08T02:45:02.084831: step 1572, loss 0.179757, acc 0.90625
2020-02-08T02:45:02.202136: step 1573, loss 0.162261, acc 0.9375
2020-02-08T02:45:02.319798: step 1574, loss 0.161933, acc 0.921875
2020-02-08T02:45:02.436794: step 1575, loss 0.0999639, acc 0.96875
2020-02-08T02:45:02.551179: step 1576, loss 0.169845, acc 0.90625
2020-02-08T02:45:02.671228: step 1577, loss 0.0387829, acc 1
2020-02-08T02:45:02.791344: step 1578, loss 0.245459, acc 0.859375
2020-02-08T02:45:02.908260: step 1579, loss 0.152691, acc 0.921875
2020-02-08T02:45:03.024009: step 1580, loss 0.152089, acc 0.9375
2020-02-08T02:45:03.138349: step 1581, loss 0.139913, acc 0.9375
2020-02-08T02:45:03.254937: step 1582, loss 0.142752, acc 0.96875
2020-02-08T02:45:03.368872: step 1583, loss 0.138888, acc 0.9375
2020-02-08T02:45:03.483498: step 1584, loss 0.209534, acc 0.9375
2020-02-08T02:45:03.601416: step 1585, loss 0.129989, acc 0.921875
2020-02-08T02:45:03.720800: step 1586, loss 0.127545, acc 0.9375
2020-02-08T02:45:03.843276: step 1587, loss 0.140258, acc 0.953125
2020-02-08T02:45:03.960621: step 1588, loss 0.0807524, acc 0.96875
2020-02-08T02:45:04.076877: step 1589, loss 0.132152, acc 0.96875
2020-02-08T02:45:04.193704: step 1590, loss 0.143405, acc 0.9375
2020-02-08T02:45:04.311254: step 1591, loss 0.154008, acc 0.9375
2020-02-08T02:45:04.428027: step 1592, loss 0.105855, acc 0.96875
2020-02-08T02:45:04.543180: step 1593, loss 0.165786, acc 0.9375
2020-02-08T02:45:04.658211: step 1594, loss 0.22759, acc 0.90625
2020-02-08T02:45:04.780326: step 1595, loss 0.134135, acc 0.9375
2020-02-08T02:45:04.896141: step 1596, loss 0.0810659, acc 1
2020-02-08T02:45:05.014750: step 1597, loss 0.147369, acc 0.921875
2020-02-08T02:45:05.131687: step 1598, loss 0.0987156, acc 0.96875
2020-02-08T02:45:05.248080: step 1599, loss 0.173238, acc 0.921875
2020-02-08T02:45:05.365506: step 1600, loss 0.157737, acc 0.9375

Evaluation:
2020-02-08T02:45:05.553805: step 1600, loss 0.608778, acc 0.753283

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1600

2020-02-08T02:45:07.040957: step 1601, loss 0.184275, acc 0.953125
2020-02-08T02:45:07.159554: step 1602, loss 0.0822095, acc 0.984375
2020-02-08T02:45:07.276965: step 1603, loss 0.170334, acc 0.953125
2020-02-08T02:45:07.398328: step 1604, loss 0.167813, acc 0.890625
2020-02-08T02:45:07.516062: step 1605, loss 0.134041, acc 0.96875
2020-02-08T02:45:07.633693: step 1606, loss 0.14978, acc 0.9375
2020-02-08T02:45:07.749663: step 1607, loss 0.119395, acc 0.953125
2020-02-08T02:45:07.863650: step 1608, loss 0.116732, acc 0.953125
2020-02-08T02:45:07.979586: step 1609, loss 0.144768, acc 0.953125
2020-02-08T02:45:08.095272: step 1610, loss 0.13822, acc 0.9375
2020-02-08T02:45:08.212381: step 1611, loss 0.138436, acc 0.953125
2020-02-08T02:45:08.330187: step 1612, loss 0.11397, acc 0.96875
2020-02-08T02:45:08.446500: step 1613, loss 0.263621, acc 0.890625
2020-02-08T02:45:08.562531: step 1614, loss 0.146986, acc 0.953125
2020-02-08T02:45:08.679408: step 1615, loss 0.153335, acc 0.9375
2020-02-08T02:45:08.796844: step 1616, loss 0.197368, acc 0.921875
2020-02-08T02:45:08.913839: step 1617, loss 0.196092, acc 0.875
2020-02-08T02:45:09.034000: step 1618, loss 0.0910202, acc 0.96875
2020-02-08T02:45:09.147768: step 1619, loss 0.210216, acc 0.890625
2020-02-08T02:45:09.265611: step 1620, loss 0.128192, acc 0.96875
2020-02-08T02:45:09.382282: step 1621, loss 0.271856, acc 0.9375
2020-02-08T02:45:09.499219: step 1622, loss 0.173356, acc 0.9375
2020-02-08T02:45:09.617245: step 1623, loss 0.223349, acc 0.890625
2020-02-08T02:45:09.734878: step 1624, loss 0.203455, acc 0.890625
2020-02-08T02:45:09.850470: step 1625, loss 0.134746, acc 0.9375
2020-02-08T02:45:09.968643: step 1626, loss 0.0667211, acc 0.984375
2020-02-08T02:45:10.085312: step 1627, loss 0.116097, acc 0.96875
2020-02-08T02:45:10.202720: step 1628, loss 0.0907732, acc 0.953125
2020-02-08T02:45:10.320669: step 1629, loss 0.122598, acc 0.96875
2020-02-08T02:45:10.436251: step 1630, loss 0.0945993, acc 0.96875
2020-02-08T02:45:10.550545: step 1631, loss 0.198094, acc 0.921875
2020-02-08T02:45:10.667605: step 1632, loss 0.122566, acc 0.953125
2020-02-08T02:45:10.787545: step 1633, loss 0.137054, acc 0.9375
2020-02-08T02:45:10.903605: step 1634, loss 0.246177, acc 0.90625
2020-02-08T02:45:11.020058: step 1635, loss 0.0639126, acc 1
2020-02-08T02:45:11.137189: step 1636, loss 0.232082, acc 0.9375
2020-02-08T02:45:11.252872: step 1637, loss 0.157179, acc 0.953125
2020-02-08T02:45:11.371387: step 1638, loss 0.175456, acc 0.9375
2020-02-08T02:45:11.486610: step 1639, loss 0.0801051, acc 0.96875
2020-02-08T02:45:11.599864: step 1640, loss 0.215331, acc 0.9375
2020-02-08T02:45:11.720195: step 1641, loss 0.136115, acc 0.9375
2020-02-08T02:45:11.838004: step 1642, loss 0.123228, acc 0.96875
2020-02-08T02:45:11.952097: step 1643, loss 0.119448, acc 0.953125
2020-02-08T02:45:12.071507: step 1644, loss 0.156779, acc 0.9375
2020-02-08T02:45:12.187571: step 1645, loss 0.168176, acc 0.9375
2020-02-08T02:45:12.300212: step 1646, loss 0.224341, acc 0.890625
2020-02-08T02:45:12.417206: step 1647, loss 0.118591, acc 0.953125
2020-02-08T02:45:12.536245: step 1648, loss 0.147119, acc 0.921875
2020-02-08T02:45:12.651373: step 1649, loss 0.157719, acc 0.953125
2020-02-08T02:45:12.768096: step 1650, loss 0.176367, acc 0.95
2020-02-08T02:45:12.888112: step 1651, loss 0.0781683, acc 0.96875
2020-02-08T02:45:13.005263: step 1652, loss 0.0832612, acc 0.984375
2020-02-08T02:45:13.120934: step 1653, loss 0.125087, acc 0.953125
2020-02-08T02:45:13.238314: step 1654, loss 0.0831544, acc 0.984375
2020-02-08T02:45:13.352613: step 1655, loss 0.0813314, acc 0.984375
2020-02-08T02:45:13.470286: step 1656, loss 0.0974467, acc 0.953125
2020-02-08T02:45:13.588028: step 1657, loss 0.0830809, acc 0.96875
2020-02-08T02:45:13.701769: step 1658, loss 0.132858, acc 0.96875
2020-02-08T02:45:13.821697: step 1659, loss 0.0685575, acc 0.96875
2020-02-08T02:45:13.938239: step 1660, loss 0.0776924, acc 0.96875
2020-02-08T02:45:14.053259: step 1661, loss 0.0953927, acc 0.953125
2020-02-08T02:45:14.170908: step 1662, loss 0.119445, acc 0.9375
2020-02-08T02:45:14.290522: step 1663, loss 0.136001, acc 0.96875
2020-02-08T02:45:14.407614: step 1664, loss 0.0820931, acc 0.984375
2020-02-08T02:45:14.526790: step 1665, loss 0.102917, acc 0.9375
2020-02-08T02:45:14.642863: step 1666, loss 0.077756, acc 0.984375
2020-02-08T02:45:14.763079: step 1667, loss 0.0961344, acc 0.96875
2020-02-08T02:45:14.881388: step 1668, loss 0.104776, acc 0.9375
2020-02-08T02:45:14.997980: step 1669, loss 0.0611173, acc 0.984375
2020-02-08T02:45:15.113042: step 1670, loss 0.0971756, acc 0.953125
2020-02-08T02:45:15.229415: step 1671, loss 0.0531112, acc 0.984375
2020-02-08T02:45:15.345161: step 1672, loss 0.103545, acc 0.984375
2020-02-08T02:45:15.461871: step 1673, loss 0.0723585, acc 1
2020-02-08T02:45:15.579389: step 1674, loss 0.0570862, acc 0.984375
2020-02-08T02:45:15.695790: step 1675, loss 0.12043, acc 0.9375
2020-02-08T02:45:15.814014: step 1676, loss 0.0856176, acc 0.984375
2020-02-08T02:45:15.931439: step 1677, loss 0.0701812, acc 0.96875
2020-02-08T02:45:16.049118: step 1678, loss 0.0861699, acc 0.96875
2020-02-08T02:45:16.164330: step 1679, loss 0.0895523, acc 0.984375
2020-02-08T02:45:16.280264: step 1680, loss 0.0881815, acc 1
2020-02-08T02:45:16.396100: step 1681, loss 0.113552, acc 0.953125
2020-02-08T02:45:16.512547: step 1682, loss 0.132544, acc 0.953125
2020-02-08T02:45:16.632482: step 1683, loss 0.153387, acc 0.953125
2020-02-08T02:45:16.749198: step 1684, loss 0.0918386, acc 0.96875
2020-02-08T02:45:16.866427: step 1685, loss 0.0594562, acc 0.984375
2020-02-08T02:45:16.984252: step 1686, loss 0.0952669, acc 0.984375
2020-02-08T02:45:17.100029: step 1687, loss 0.0341462, acc 0.984375
2020-02-08T02:45:17.215719: step 1688, loss 0.0800521, acc 0.984375
2020-02-08T02:45:17.335463: step 1689, loss 0.063727, acc 1
2020-02-08T02:45:17.451675: step 1690, loss 0.0655457, acc 0.96875
2020-02-08T02:45:17.571830: step 1691, loss 0.0798122, acc 0.953125
2020-02-08T02:45:17.691882: step 1692, loss 0.203469, acc 0.890625
2020-02-08T02:45:17.812822: step 1693, loss 0.215194, acc 0.90625
2020-02-08T02:45:17.931892: step 1694, loss 0.142397, acc 0.96875
2020-02-08T02:45:18.047560: step 1695, loss 0.0446585, acc 1
2020-02-08T02:45:18.166618: step 1696, loss 0.0883756, acc 0.96875
2020-02-08T02:45:18.285653: step 1697, loss 0.153258, acc 0.9375
2020-02-08T02:45:18.399577: step 1698, loss 0.0889443, acc 0.984375
2020-02-08T02:45:18.515557: step 1699, loss 0.16022, acc 0.96875
2020-02-08T02:45:18.633772: step 1700, loss 0.071937, acc 0.984375

Evaluation:
2020-02-08T02:45:18.825109: step 1700, loss 0.640289, acc 0.744841

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1700

2020-02-08T02:45:20.363977: step 1701, loss 0.14964, acc 0.9375
2020-02-08T02:45:20.481106: step 1702, loss 0.170707, acc 0.9375
2020-02-08T02:45:20.598764: step 1703, loss 0.138893, acc 0.90625
2020-02-08T02:45:20.715529: step 1704, loss 0.15042, acc 0.921875
2020-02-08T02:45:20.834576: step 1705, loss 0.119112, acc 0.9375
2020-02-08T02:45:20.950734: step 1706, loss 0.0811149, acc 0.984375
2020-02-08T02:45:21.070608: step 1707, loss 0.157366, acc 0.9375
2020-02-08T02:45:21.186917: step 1708, loss 0.167058, acc 0.953125
2020-02-08T02:45:21.303559: step 1709, loss 0.0379698, acc 1
2020-02-08T02:45:21.524596: step 1710, loss 0.261031, acc 0.90625
2020-02-08T02:45:21.645868: step 1711, loss 0.0671444, acc 1
2020-02-08T02:45:21.766970: step 1712, loss 0.122952, acc 0.953125
2020-02-08T02:45:21.886789: step 1713, loss 0.103702, acc 0.96875
2020-02-08T02:45:22.003709: step 1714, loss 0.325927, acc 0.84375
2020-02-08T02:45:22.125287: step 1715, loss 0.1215, acc 0.9375
2020-02-08T02:45:22.240923: step 1716, loss 0.0766813, acc 0.96875
2020-02-08T02:45:22.356948: step 1717, loss 0.0935857, acc 0.96875
2020-02-08T02:45:22.476938: step 1718, loss 0.0912991, acc 0.953125
2020-02-08T02:45:22.595565: step 1719, loss 0.108594, acc 0.96875
2020-02-08T02:45:22.715497: step 1720, loss 0.0956153, acc 0.96875
2020-02-08T02:45:22.835395: step 1721, loss 0.0623034, acc 0.96875
2020-02-08T02:45:22.952202: step 1722, loss 0.0439456, acc 1
2020-02-08T02:45:23.068615: step 1723, loss 0.0347752, acc 1
2020-02-08T02:45:23.188370: step 1724, loss 0.173647, acc 0.9375
2020-02-08T02:45:23.306155: step 1725, loss 0.244096, acc 0.875
2020-02-08T02:45:23.424306: step 1726, loss 0.105013, acc 0.984375
2020-02-08T02:45:23.541331: step 1727, loss 0.0663177, acc 0.984375
2020-02-08T02:45:23.658777: step 1728, loss 0.18881, acc 0.921875
2020-02-08T02:45:23.778906: step 1729, loss 0.0757969, acc 0.96875
2020-02-08T02:45:23.894506: step 1730, loss 0.156245, acc 0.953125
2020-02-08T02:45:24.011184: step 1731, loss 0.0746403, acc 0.96875
2020-02-08T02:45:24.128057: step 1732, loss 0.124884, acc 0.9375
2020-02-08T02:45:24.242486: step 1733, loss 0.118608, acc 0.96875
2020-02-08T02:45:24.356927: step 1734, loss 0.136289, acc 0.953125
2020-02-08T02:45:24.475064: step 1735, loss 0.0678802, acc 0.984375
2020-02-08T02:45:24.592124: step 1736, loss 0.12479, acc 0.921875
2020-02-08T02:45:24.708544: step 1737, loss 0.157547, acc 0.9375
2020-02-08T02:45:24.827083: step 1738, loss 0.12482, acc 0.953125
2020-02-08T02:45:24.943935: step 1739, loss 0.0841498, acc 0.984375
2020-02-08T02:45:25.061240: step 1740, loss 0.213494, acc 0.9375
2020-02-08T02:45:25.179803: step 1741, loss 0.103289, acc 0.953125
2020-02-08T02:45:25.297590: step 1742, loss 0.108011, acc 0.953125
2020-02-08T02:45:25.414304: step 1743, loss 0.101111, acc 0.96875
2020-02-08T02:45:25.532249: step 1744, loss 0.0661452, acc 0.984375
2020-02-08T02:45:25.648418: step 1745, loss 0.111164, acc 0.953125
2020-02-08T02:45:25.771202: step 1746, loss 0.189245, acc 0.90625
2020-02-08T02:45:25.888702: step 1747, loss 0.0939992, acc 0.953125
2020-02-08T02:45:26.003392: step 1748, loss 0.122687, acc 0.96875
2020-02-08T02:45:26.122141: step 1749, loss 0.108086, acc 0.921875
2020-02-08T02:45:26.240495: step 1750, loss 0.12063, acc 0.953125
2020-02-08T02:45:26.358704: step 1751, loss 0.100495, acc 0.953125
2020-02-08T02:45:26.476360: step 1752, loss 0.122281, acc 0.953125
2020-02-08T02:45:26.592319: step 1753, loss 0.107376, acc 0.9375
2020-02-08T02:45:26.708496: step 1754, loss 0.027439, acc 1
2020-02-08T02:45:26.826865: step 1755, loss 0.0662569, acc 0.984375
2020-02-08T02:45:26.943808: step 1756, loss 0.111061, acc 0.96875
2020-02-08T02:45:27.059213: step 1757, loss 0.126092, acc 0.9375
2020-02-08T02:45:27.176829: step 1758, loss 0.034706, acc 0.984375
2020-02-08T02:45:27.293559: step 1759, loss 0.0934726, acc 0.953125
2020-02-08T02:45:27.407968: step 1760, loss 0.0708187, acc 0.984375
2020-02-08T02:45:27.526732: step 1761, loss 0.0427963, acc 1
2020-02-08T02:45:27.641658: step 1762, loss 0.0675314, acc 0.96875
2020-02-08T02:45:27.760203: step 1763, loss 0.11807, acc 0.9375
2020-02-08T02:45:27.877751: step 1764, loss 0.0899478, acc 0.96875
2020-02-08T02:45:27.994231: step 1765, loss 0.0774879, acc 0.984375
2020-02-08T02:45:28.110536: step 1766, loss 0.148845, acc 0.921875
2020-02-08T02:45:28.228693: step 1767, loss 0.120412, acc 0.9375
2020-02-08T02:45:28.345317: step 1768, loss 0.183417, acc 0.96875
2020-02-08T02:45:28.459911: step 1769, loss 0.178903, acc 0.921875
2020-02-08T02:45:28.579493: step 1770, loss 0.12601, acc 0.953125
2020-02-08T02:45:28.698506: step 1771, loss 0.0603312, acc 0.984375
2020-02-08T02:45:28.818299: step 1772, loss 0.0928459, acc 0.953125
2020-02-08T02:45:28.936688: step 1773, loss 0.189891, acc 0.90625
2020-02-08T02:45:29.054816: step 1774, loss 0.0695721, acc 0.984375
2020-02-08T02:45:29.172539: step 1775, loss 0.19312, acc 0.9375
2020-02-08T02:45:29.288935: step 1776, loss 0.215262, acc 0.90625
2020-02-08T02:45:29.403969: step 1777, loss 0.142111, acc 0.96875
2020-02-08T02:45:29.523959: step 1778, loss 0.0985595, acc 0.953125
2020-02-08T02:45:29.642707: step 1779, loss 0.0906871, acc 0.96875
2020-02-08T02:45:29.762785: step 1780, loss 0.146035, acc 0.9375
2020-02-08T02:45:29.881352: step 1781, loss 0.0885759, acc 0.96875
2020-02-08T02:45:29.998133: step 1782, loss 0.111875, acc 0.9375
2020-02-08T02:45:30.117764: step 1783, loss 0.051079, acc 1
2020-02-08T02:45:30.233442: step 1784, loss 0.10276, acc 0.96875
2020-02-08T02:45:30.348550: step 1785, loss 0.191157, acc 0.90625
2020-02-08T02:45:30.466473: step 1786, loss 0.173677, acc 0.953125
2020-02-08T02:45:30.583517: step 1787, loss 0.171693, acc 0.90625
2020-02-08T02:45:30.698163: step 1788, loss 0.0290239, acc 1
2020-02-08T02:45:30.816430: step 1789, loss 0.12833, acc 0.921875
2020-02-08T02:45:30.936021: step 1790, loss 0.0631381, acc 1
2020-02-08T02:45:31.053040: step 1791, loss 0.148304, acc 0.9375
2020-02-08T02:45:31.171077: step 1792, loss 0.136755, acc 0.953125
2020-02-08T02:45:31.287148: step 1793, loss 0.0595223, acc 0.984375
2020-02-08T02:45:31.402815: step 1794, loss 0.144266, acc 0.953125
2020-02-08T02:45:31.520647: step 1795, loss 0.114553, acc 0.921875
2020-02-08T02:45:31.639046: step 1796, loss 0.10133, acc 0.9375
2020-02-08T02:45:31.758941: step 1797, loss 0.084703, acc 0.96875
2020-02-08T02:45:31.875874: step 1798, loss 0.0761268, acc 0.96875
2020-02-08T02:45:31.992930: step 1799, loss 0.121387, acc 0.953125
2020-02-08T02:45:32.105915: step 1800, loss 0.148525, acc 0.883333

Evaluation:
2020-02-08T02:45:32.297862: step 1800, loss 0.685749, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1800

2020-02-08T02:45:33.804373: step 1801, loss 0.0939604, acc 0.984375
2020-02-08T02:45:33.920554: step 1802, loss 0.0564366, acc 0.984375
2020-02-08T02:45:34.037036: step 1803, loss 0.0472979, acc 1
2020-02-08T02:45:34.152607: step 1804, loss 0.0538851, acc 1
2020-02-08T02:45:34.269492: step 1805, loss 0.0420861, acc 0.984375
2020-02-08T02:45:34.389236: step 1806, loss 0.0798654, acc 0.96875
2020-02-08T02:45:34.507121: step 1807, loss 0.155818, acc 0.96875
2020-02-08T02:45:34.625005: step 1808, loss 0.0820302, acc 0.984375
2020-02-08T02:45:34.742490: step 1809, loss 0.0531076, acc 1
2020-02-08T02:45:34.856116: step 1810, loss 0.112741, acc 0.9375
2020-02-08T02:45:34.974434: step 1811, loss 0.070992, acc 0.96875
2020-02-08T02:45:35.095597: step 1812, loss 0.181745, acc 0.9375
2020-02-08T02:45:35.211167: step 1813, loss 0.105041, acc 0.921875
2020-02-08T02:45:35.329598: step 1814, loss 0.129371, acc 0.921875
2020-02-08T02:45:35.447301: step 1815, loss 0.113313, acc 0.953125
2020-02-08T02:45:35.569293: step 1816, loss 0.0473948, acc 0.96875
2020-02-08T02:45:35.685514: step 1817, loss 0.0721084, acc 0.96875
2020-02-08T02:45:35.809478: step 1818, loss 0.0446016, acc 0.984375
2020-02-08T02:45:35.926548: step 1819, loss 0.17042, acc 0.921875
2020-02-08T02:45:36.043834: step 1820, loss 0.109631, acc 0.953125
2020-02-08T02:45:36.161585: step 1821, loss 0.0791892, acc 0.96875
2020-02-08T02:45:36.281549: step 1822, loss 0.0826833, acc 0.953125
2020-02-08T02:45:36.399690: step 1823, loss 0.188201, acc 0.921875
2020-02-08T02:45:36.520511: step 1824, loss 0.0555127, acc 0.984375
2020-02-08T02:45:36.638196: step 1825, loss 0.0611114, acc 0.96875
2020-02-08T02:45:36.759402: step 1826, loss 0.0778654, acc 0.96875
2020-02-08T02:45:36.878472: step 1827, loss 0.0499206, acc 0.984375
2020-02-08T02:45:36.993424: step 1828, loss 0.043649, acc 0.984375
2020-02-08T02:45:37.108331: step 1829, loss 0.0781997, acc 0.953125
2020-02-08T02:45:37.227800: step 1830, loss 0.103184, acc 0.96875
2020-02-08T02:45:37.347856: step 1831, loss 0.139248, acc 0.953125
2020-02-08T02:45:37.465924: step 1832, loss 0.0850715, acc 0.96875
2020-02-08T02:45:37.583799: step 1833, loss 0.0975306, acc 0.96875
2020-02-08T02:45:37.698311: step 1834, loss 0.105663, acc 0.9375
2020-02-08T02:45:37.821038: step 1835, loss 0.0436318, acc 0.984375
2020-02-08T02:45:37.937972: step 1836, loss 0.0525623, acc 0.984375
2020-02-08T02:45:38.051372: step 1837, loss 0.111757, acc 0.96875
2020-02-08T02:45:38.167447: step 1838, loss 0.0633478, acc 0.96875
2020-02-08T02:45:38.285336: step 1839, loss 0.104244, acc 0.984375
2020-02-08T02:45:38.400845: step 1840, loss 0.0331964, acc 0.984375
2020-02-08T02:45:38.520198: step 1841, loss 0.107534, acc 0.953125
2020-02-08T02:45:38.639379: step 1842, loss 0.162559, acc 0.9375
2020-02-08T02:45:38.760440: step 1843, loss 0.100091, acc 0.96875
2020-02-08T02:45:38.881677: step 1844, loss 0.105941, acc 0.953125
2020-02-08T02:45:38.997896: step 1845, loss 0.096209, acc 0.96875
2020-02-08T02:45:39.119702: step 1846, loss 0.0183927, acc 1
2020-02-08T02:45:39.237178: step 1847, loss 0.0625103, acc 0.984375
2020-02-08T02:45:39.353236: step 1848, loss 0.0909239, acc 0.953125
2020-02-08T02:45:39.469979: step 1849, loss 0.0498638, acc 0.96875
2020-02-08T02:45:39.587344: step 1850, loss 0.042892, acc 0.984375
2020-02-08T02:45:39.701928: step 1851, loss 0.160688, acc 0.9375
2020-02-08T02:45:39.824971: step 1852, loss 0.190009, acc 0.9375
2020-02-08T02:45:39.940222: step 1853, loss 0.0927504, acc 0.9375
2020-02-08T02:45:40.057437: step 1854, loss 0.0689963, acc 0.984375
2020-02-08T02:45:40.180255: step 1855, loss 0.068077, acc 0.984375
2020-02-08T02:45:40.295665: step 1856, loss 0.095837, acc 0.96875
2020-02-08T02:45:40.411846: step 1857, loss 0.109867, acc 0.953125
2020-02-08T02:45:40.530350: step 1858, loss 0.147726, acc 0.9375
2020-02-08T02:45:40.647718: step 1859, loss 0.144914, acc 0.96875
2020-02-08T02:45:40.767475: step 1860, loss 0.139683, acc 0.96875
2020-02-08T02:45:40.885561: step 1861, loss 0.0786108, acc 0.96875
2020-02-08T02:45:41.005477: step 1862, loss 0.0764318, acc 0.96875
2020-02-08T02:45:41.122419: step 1863, loss 0.0626059, acc 0.984375
2020-02-08T02:45:41.240115: step 1864, loss 0.180662, acc 0.921875
2020-02-08T02:45:41.356936: step 1865, loss 0.109272, acc 0.9375
2020-02-08T02:45:41.473800: step 1866, loss 0.0705355, acc 0.96875
2020-02-08T02:45:41.590015: step 1867, loss 0.0330246, acc 1
2020-02-08T02:45:41.705646: step 1868, loss 0.0877925, acc 0.953125
2020-02-08T02:45:41.828004: step 1869, loss 0.049922, acc 0.96875
2020-02-08T02:45:41.947912: step 1870, loss 0.069416, acc 0.984375
2020-02-08T02:45:42.067492: step 1871, loss 0.134547, acc 0.953125
2020-02-08T02:45:42.183720: step 1872, loss 0.0853042, acc 0.953125
2020-02-08T02:45:42.301043: step 1873, loss 0.130512, acc 0.953125
2020-02-08T02:45:42.416093: step 1874, loss 0.0606014, acc 1
2020-02-08T02:45:42.531045: step 1875, loss 0.055596, acc 0.96875
2020-02-08T02:45:42.646759: step 1876, loss 0.0461995, acc 0.984375
2020-02-08T02:45:42.764330: step 1877, loss 0.0501166, acc 0.96875
2020-02-08T02:45:42.882380: step 1878, loss 0.0905279, acc 0.96875
2020-02-08T02:45:42.997693: step 1879, loss 0.082447, acc 0.96875
2020-02-08T02:45:43.114493: step 1880, loss 0.264945, acc 0.953125
2020-02-08T02:45:43.233883: step 1881, loss 0.0437685, acc 1
2020-02-08T02:45:43.349647: step 1882, loss 0.034952, acc 1
2020-02-08T02:45:43.465729: step 1883, loss 0.0577364, acc 0.984375
2020-02-08T02:45:43.584152: step 1884, loss 0.125338, acc 0.953125
2020-02-08T02:45:43.701751: step 1885, loss 0.0282852, acc 1
2020-02-08T02:45:43.820250: step 1886, loss 0.0859328, acc 0.96875
2020-02-08T02:45:43.939638: step 1887, loss 0.117505, acc 0.953125
2020-02-08T02:45:44.056352: step 1888, loss 0.066131, acc 0.984375
2020-02-08T02:45:44.171907: step 1889, loss 0.197732, acc 0.90625
2020-02-08T02:45:44.288958: step 1890, loss 0.149662, acc 0.953125
2020-02-08T02:45:44.406524: step 1891, loss 0.0718237, acc 0.96875
2020-02-08T02:45:44.524804: step 1892, loss 0.061313, acc 0.984375
2020-02-08T02:45:44.641240: step 1893, loss 0.0657956, acc 1
2020-02-08T02:45:44.758674: step 1894, loss 0.0402505, acc 1
2020-02-08T02:45:44.876044: step 1895, loss 0.0302639, acc 0.984375
2020-02-08T02:45:44.991920: step 1896, loss 0.065152, acc 0.96875
2020-02-08T02:45:45.108440: step 1897, loss 0.0716326, acc 0.96875
2020-02-08T02:45:45.226053: step 1898, loss 0.136863, acc 0.9375
2020-02-08T02:45:45.342940: step 1899, loss 0.0624419, acc 1
2020-02-08T02:45:45.461093: step 1900, loss 0.0356881, acc 0.984375

Evaluation:
2020-02-08T02:45:45.651273: step 1900, loss 0.678142, acc 0.753283

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-1900

2020-02-08T02:45:47.178683: step 1901, loss 0.0911175, acc 0.96875
2020-02-08T02:45:47.294882: step 1902, loss 0.0399501, acc 1
2020-02-08T02:45:47.411729: step 1903, loss 0.0913382, acc 0.953125
2020-02-08T02:45:47.527140: step 1904, loss 0.13072, acc 0.9375
2020-02-08T02:45:47.644773: step 1905, loss 0.115357, acc 0.953125
2020-02-08T02:45:47.763790: step 1906, loss 0.0749831, acc 0.984375
2020-02-08T02:45:47.880131: step 1907, loss 0.203527, acc 0.953125
2020-02-08T02:45:47.997728: step 1908, loss 0.108654, acc 0.984375
2020-02-08T02:45:48.112411: step 1909, loss 0.146467, acc 0.953125
2020-02-08T02:45:48.228287: step 1910, loss 0.0735399, acc 0.984375
2020-02-08T02:45:48.344777: step 1911, loss 0.0710812, acc 0.984375
2020-02-08T02:45:48.460864: step 1912, loss 0.0474127, acc 0.96875
2020-02-08T02:45:48.578555: step 1913, loss 0.103183, acc 0.953125
2020-02-08T02:45:48.696388: step 1914, loss 0.152904, acc 0.984375
2020-02-08T02:45:48.814949: step 1915, loss 0.118501, acc 0.9375
2020-02-08T02:45:48.931183: step 1916, loss 0.0356184, acc 1
2020-02-08T02:45:49.049331: step 1917, loss 0.0540738, acc 0.984375
2020-02-08T02:45:49.165853: step 1918, loss 0.0651987, acc 0.96875
2020-02-08T02:45:49.285481: step 1919, loss 0.0761855, acc 0.96875
2020-02-08T02:45:49.403713: step 1920, loss 0.0487625, acc 1
2020-02-08T02:45:49.519925: step 1921, loss 0.042233, acc 0.984375
2020-02-08T02:45:49.636360: step 1922, loss 0.066834, acc 0.96875
2020-02-08T02:45:49.753260: step 1923, loss 0.0798724, acc 0.96875
2020-02-08T02:45:49.871628: step 1924, loss 0.0481031, acc 0.984375
2020-02-08T02:45:49.989073: step 1925, loss 0.0608481, acc 0.96875
2020-02-08T02:45:50.104965: step 1926, loss 0.0799304, acc 0.984375
2020-02-08T02:45:50.222636: step 1927, loss 0.103086, acc 0.953125
2020-02-08T02:45:50.341762: step 1928, loss 0.0272812, acc 1
2020-02-08T02:45:50.458681: step 1929, loss 0.0711754, acc 0.96875
2020-02-08T02:45:50.576738: step 1930, loss 0.0901549, acc 0.96875
2020-02-08T02:45:50.694210: step 1931, loss 0.0820676, acc 0.96875
2020-02-08T02:45:50.817000: step 1932, loss 0.0307311, acc 1
2020-02-08T02:45:50.933544: step 1933, loss 0.0999451, acc 0.953125
2020-02-08T02:45:51.049270: step 1934, loss 0.0894053, acc 0.96875
2020-02-08T02:45:51.167364: step 1935, loss 0.0908925, acc 0.953125
2020-02-08T02:45:51.503604: step 1936, loss 0.241168, acc 0.890625
2020-02-08T02:45:51.631070: step 1937, loss 0.208246, acc 0.90625
2020-02-08T02:45:51.747577: step 1938, loss 0.0752342, acc 0.953125
2020-02-08T02:45:51.864547: step 1939, loss 0.0601956, acc 0.984375
2020-02-08T02:45:51.981998: step 1940, loss 0.112126, acc 0.96875
2020-02-08T02:45:52.096740: step 1941, loss 0.0993608, acc 0.984375
2020-02-08T02:45:52.212502: step 1942, loss 0.0490033, acc 0.984375
2020-02-08T02:45:52.332983: step 1943, loss 0.078682, acc 0.96875
2020-02-08T02:45:52.450238: step 1944, loss 0.146653, acc 0.953125
2020-02-08T02:45:52.567785: step 1945, loss 0.0843885, acc 0.953125
2020-02-08T02:45:52.685553: step 1946, loss 0.100432, acc 0.9375
2020-02-08T02:45:52.804821: step 1947, loss 0.0734779, acc 0.953125
2020-02-08T02:45:52.925227: step 1948, loss 0.166178, acc 0.953125
2020-02-08T02:45:53.043744: step 1949, loss 0.113936, acc 0.953125
2020-02-08T02:45:53.155850: step 1950, loss 0.127429, acc 0.95
2020-02-08T02:45:53.276817: step 1951, loss 0.0322507, acc 1
2020-02-08T02:45:53.393259: step 1952, loss 0.07267, acc 0.96875
2020-02-08T02:45:53.512520: step 1953, loss 0.0979359, acc 0.96875
2020-02-08T02:45:53.635736: step 1954, loss 0.0305901, acc 1
2020-02-08T02:45:53.751890: step 1955, loss 0.0273817, acc 1
2020-02-08T02:45:53.869923: step 1956, loss 0.0380102, acc 0.984375
2020-02-08T02:45:53.990087: step 1957, loss 0.0868798, acc 0.96875
2020-02-08T02:45:54.105435: step 1958, loss 0.135052, acc 0.90625
2020-02-08T02:45:54.223984: step 1959, loss 0.105922, acc 0.96875
2020-02-08T02:45:54.347217: step 1960, loss 0.071875, acc 0.96875
2020-02-08T02:45:54.463788: step 1961, loss 0.043801, acc 1
2020-02-08T02:45:54.636573: step 1962, loss 0.0661596, acc 0.96875
2020-02-08T02:45:54.795329: step 1963, loss 0.0871251, acc 0.96875
2020-02-08T02:45:54.928146: step 1964, loss 0.0874054, acc 0.984375
2020-02-08T02:45:55.059620: step 1965, loss 0.0484034, acc 0.984375
2020-02-08T02:45:55.199087: step 1966, loss 0.0450424, acc 0.984375
2020-02-08T02:45:55.331082: step 1967, loss 0.0519418, acc 0.96875
2020-02-08T02:45:55.461615: step 1968, loss 0.0836418, acc 0.96875
2020-02-08T02:45:55.592460: step 1969, loss 0.0339129, acc 1
2020-02-08T02:45:55.723193: step 1970, loss 0.0324223, acc 1
2020-02-08T02:45:55.856058: step 1971, loss 0.0566365, acc 0.96875
2020-02-08T02:45:55.976926: step 1972, loss 0.071134, acc 0.96875
2020-02-08T02:45:56.112184: step 1973, loss 0.0668605, acc 0.984375
2020-02-08T02:45:56.235450: step 1974, loss 0.0485201, acc 0.984375
2020-02-08T02:45:56.364607: step 1975, loss 0.0990825, acc 0.96875
2020-02-08T02:45:56.493922: step 1976, loss 0.0762785, acc 0.96875
2020-02-08T02:45:56.622928: step 1977, loss 0.0647532, acc 0.984375
2020-02-08T02:45:56.752874: step 1978, loss 0.0710792, acc 0.96875
2020-02-08T02:45:56.884379: step 1979, loss 0.0922252, acc 0.953125
2020-02-08T02:45:57.018458: step 1980, loss 0.07019, acc 0.984375
2020-02-08T02:45:57.150205: step 1981, loss 0.0462348, acc 0.984375
2020-02-08T02:45:57.282899: step 1982, loss 0.0456697, acc 1
2020-02-08T02:45:57.420601: step 1983, loss 0.0325548, acc 1
2020-02-08T02:45:57.553539: step 1984, loss 0.0930061, acc 0.96875
2020-02-08T02:45:57.689294: step 1985, loss 0.112979, acc 0.9375
2020-02-08T02:45:57.833622: step 1986, loss 0.0945747, acc 0.953125
2020-02-08T02:45:57.972783: step 1987, loss 0.132467, acc 0.96875
2020-02-08T02:45:58.124871: step 1988, loss 0.0920443, acc 0.9375
2020-02-08T02:45:58.257019: step 1989, loss 0.0192197, acc 1
2020-02-08T02:45:58.397303: step 1990, loss 0.0637352, acc 0.984375
2020-02-08T02:45:58.535001: step 1991, loss 0.0346474, acc 0.984375
2020-02-08T02:45:58.662737: step 1992, loss 0.0316836, acc 0.984375
2020-02-08T02:45:58.798857: step 1993, loss 0.0627142, acc 0.984375
2020-02-08T02:45:58.940766: step 1994, loss 0.0631053, acc 0.984375
2020-02-08T02:45:59.076967: step 1995, loss 0.0885061, acc 0.984375
2020-02-08T02:45:59.214559: step 1996, loss 0.0310101, acc 1
2020-02-08T02:45:59.353751: step 1997, loss 0.0332226, acc 1
2020-02-08T02:45:59.492135: step 1998, loss 0.103301, acc 0.984375
2020-02-08T02:45:59.633579: step 1999, loss 0.037548, acc 0.984375
2020-02-08T02:45:59.774083: step 2000, loss 0.0660207, acc 0.96875

Evaluation:
2020-02-08T02:45:59.993620: step 2000, loss 0.715659, acc 0.748593

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2000

2020-02-08T02:46:02.323187: step 2001, loss 0.0347872, acc 1
2020-02-08T02:46:02.456440: step 2002, loss 0.0591294, acc 0.984375
2020-02-08T02:46:02.581583: step 2003, loss 0.0323742, acc 0.984375
2020-02-08T02:46:02.705696: step 2004, loss 0.0429925, acc 0.984375
2020-02-08T02:46:02.848147: step 2005, loss 0.0354808, acc 1
2020-02-08T02:46:02.977395: step 2006, loss 0.0837626, acc 0.96875
2020-02-08T02:46:03.103181: step 2007, loss 0.0826046, acc 0.953125
2020-02-08T02:46:03.229256: step 2008, loss 0.0746135, acc 0.96875
2020-02-08T02:46:03.364440: step 2009, loss 0.166018, acc 0.953125
2020-02-08T02:46:03.500159: step 2010, loss 0.0454303, acc 0.984375
2020-02-08T02:46:03.636664: step 2011, loss 0.114367, acc 0.953125
2020-02-08T02:46:03.776670: step 2012, loss 0.171866, acc 0.921875
2020-02-08T02:46:03.914703: step 2013, loss 0.0724575, acc 0.96875
2020-02-08T02:46:04.048708: step 2014, loss 0.0623804, acc 0.984375
2020-02-08T02:46:04.185118: step 2015, loss 0.0435697, acc 1
2020-02-08T02:46:04.318799: step 2016, loss 0.107289, acc 0.9375
2020-02-08T02:46:04.444066: step 2017, loss 0.0569065, acc 0.984375
2020-02-08T02:46:04.570950: step 2018, loss 0.0310782, acc 1
2020-02-08T02:46:04.711597: step 2019, loss 0.0461594, acc 0.96875
2020-02-08T02:46:04.840578: step 2020, loss 0.115069, acc 0.953125
2020-02-08T02:46:04.966135: step 2021, loss 0.0276419, acc 1
2020-02-08T02:46:05.097864: step 2022, loss 0.0975398, acc 0.953125
2020-02-08T02:46:05.216940: step 2023, loss 0.0807068, acc 0.9375
2020-02-08T02:46:05.346806: step 2024, loss 0.134605, acc 0.96875
2020-02-08T02:46:05.481210: step 2025, loss 0.0730407, acc 0.984375
2020-02-08T02:46:05.618628: step 2026, loss 0.0561428, acc 0.984375
2020-02-08T02:46:05.754990: step 2027, loss 0.0607352, acc 0.984375
2020-02-08T02:46:05.874680: step 2028, loss 0.0693978, acc 0.96875
2020-02-08T02:46:05.994822: step 2029, loss 0.0774776, acc 0.984375
2020-02-08T02:46:06.118023: step 2030, loss 0.0501705, acc 1
2020-02-08T02:46:06.237489: step 2031, loss 0.0349461, acc 1
2020-02-08T02:46:06.353255: step 2032, loss 0.159526, acc 0.9375
2020-02-08T02:46:06.473797: step 2033, loss 0.027692, acc 1
2020-02-08T02:46:06.592921: step 2034, loss 0.0346959, acc 1
2020-02-08T02:46:06.714144: step 2035, loss 0.0614482, acc 0.984375
2020-02-08T02:46:06.833234: step 2036, loss 0.0420656, acc 0.984375
2020-02-08T02:46:06.947409: step 2037, loss 0.140411, acc 0.921875
2020-02-08T02:46:07.063999: step 2038, loss 0.0510369, acc 0.984375
2020-02-08T02:46:07.180772: step 2039, loss 0.048188, acc 0.984375
2020-02-08T02:46:07.299135: step 2040, loss 0.0285433, acc 1
2020-02-08T02:46:07.419949: step 2041, loss 0.0310531, acc 1
2020-02-08T02:46:07.534980: step 2042, loss 0.0636551, acc 0.984375
2020-02-08T02:46:07.650427: step 2043, loss 0.0352759, acc 0.984375
2020-02-08T02:46:07.770410: step 2044, loss 0.0401588, acc 0.984375
2020-02-08T02:46:07.886928: step 2045, loss 0.106946, acc 0.953125
2020-02-08T02:46:08.001897: step 2046, loss 0.183494, acc 0.9375
2020-02-08T02:46:08.121367: step 2047, loss 0.0553318, acc 0.984375
2020-02-08T02:46:08.237763: step 2048, loss 0.114954, acc 0.9375
2020-02-08T02:46:08.351789: step 2049, loss 0.128527, acc 0.953125
2020-02-08T02:46:08.467902: step 2050, loss 0.0648651, acc 0.984375
2020-02-08T02:46:08.587102: step 2051, loss 0.0644452, acc 0.984375
2020-02-08T02:46:08.700566: step 2052, loss 0.079439, acc 0.96875
2020-02-08T02:46:08.820389: step 2053, loss 0.0739847, acc 0.96875
2020-02-08T02:46:08.937112: step 2054, loss 0.0273717, acc 1
2020-02-08T02:46:09.051648: step 2055, loss 0.0523906, acc 0.984375
2020-02-08T02:46:09.167217: step 2056, loss 0.0502317, acc 0.984375
2020-02-08T02:46:09.283323: step 2057, loss 0.0670822, acc 0.96875
2020-02-08T02:46:09.399672: step 2058, loss 0.0322669, acc 1
2020-02-08T02:46:09.515516: step 2059, loss 0.0238433, acc 1
2020-02-08T02:46:09.634130: step 2060, loss 0.046915, acc 0.984375
2020-02-08T02:46:09.750703: step 2061, loss 0.0475688, acc 0.96875
2020-02-08T02:46:09.869268: step 2062, loss 0.0876903, acc 0.96875
2020-02-08T02:46:09.985901: step 2063, loss 0.0182422, acc 1
2020-02-08T02:46:10.101145: step 2064, loss 0.0387256, acc 0.984375
2020-02-08T02:46:10.219825: step 2065, loss 0.0517863, acc 0.984375
2020-02-08T02:46:10.338410: step 2066, loss 0.0891568, acc 0.96875
2020-02-08T02:46:10.454947: step 2067, loss 0.0540445, acc 0.984375
2020-02-08T02:46:10.573038: step 2068, loss 0.0816313, acc 0.953125
2020-02-08T02:46:10.690423: step 2069, loss 0.0321365, acc 1
2020-02-08T02:46:10.809656: step 2070, loss 0.0591875, acc 0.96875
2020-02-08T02:46:10.927946: step 2071, loss 0.0426652, acc 0.984375
2020-02-08T02:46:11.044010: step 2072, loss 0.0947989, acc 0.953125
2020-02-08T02:46:11.159728: step 2073, loss 0.0791478, acc 0.984375
2020-02-08T02:46:11.278711: step 2074, loss 0.0743878, acc 0.984375
2020-02-08T02:46:11.396779: step 2075, loss 0.0473454, acc 0.984375
2020-02-08T02:46:11.513682: step 2076, loss 0.037831, acc 0.984375
2020-02-08T02:46:11.630452: step 2077, loss 0.0246403, acc 1
2020-02-08T02:46:11.747999: step 2078, loss 0.0736478, acc 0.96875
2020-02-08T02:46:11.866480: step 2079, loss 0.030365, acc 1
2020-02-08T02:46:11.982534: step 2080, loss 0.140049, acc 0.9375
2020-02-08T02:46:12.098122: step 2081, loss 0.0462228, acc 1
2020-02-08T02:46:12.216387: step 2082, loss 0.0769851, acc 0.953125
2020-02-08T02:46:12.334400: step 2083, loss 0.0505418, acc 0.96875
2020-02-08T02:46:12.449081: step 2084, loss 0.102473, acc 0.953125
2020-02-08T02:46:12.565244: step 2085, loss 0.116142, acc 0.953125
2020-02-08T02:46:12.682775: step 2086, loss 0.0651116, acc 0.953125
2020-02-08T02:46:12.798402: step 2087, loss 0.0382938, acc 1
2020-02-08T02:46:12.914491: step 2088, loss 0.0697918, acc 0.96875
2020-02-08T02:46:13.028938: step 2089, loss 0.127121, acc 0.96875
2020-02-08T02:46:13.144050: step 2090, loss 0.0374926, acc 1
2020-02-08T02:46:13.259007: step 2091, loss 0.0914463, acc 0.953125
2020-02-08T02:46:13.377238: step 2092, loss 0.0544855, acc 0.96875
2020-02-08T02:46:13.494213: step 2093, loss 0.0930278, acc 0.96875
2020-02-08T02:46:13.609063: step 2094, loss 0.122982, acc 0.953125
2020-02-08T02:46:13.728452: step 2095, loss 0.0342605, acc 0.984375
2020-02-08T02:46:13.844619: step 2096, loss 0.169987, acc 0.921875
2020-02-08T02:46:13.958812: step 2097, loss 0.042438, acc 0.984375
2020-02-08T02:46:14.079245: step 2098, loss 0.103242, acc 0.96875
2020-02-08T02:46:14.194992: step 2099, loss 0.112088, acc 0.953125
2020-02-08T02:46:14.309027: step 2100, loss 0.150349, acc 0.95

Evaluation:
2020-02-08T02:46:14.496535: step 2100, loss 0.733187, acc 0.745779

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2100

2020-02-08T02:46:16.696371: step 2101, loss 0.0966504, acc 0.96875
2020-02-08T02:46:16.811785: step 2102, loss 0.0286193, acc 1
2020-02-08T02:46:16.929331: step 2103, loss 0.0397498, acc 0.984375
2020-02-08T02:46:17.046744: step 2104, loss 0.0289477, acc 1
2020-02-08T02:46:17.163834: step 2105, loss 0.0258337, acc 1
2020-02-08T02:46:17.283706: step 2106, loss 0.0784691, acc 0.984375
2020-02-08T02:46:17.400823: step 2107, loss 0.0534781, acc 0.984375
2020-02-08T02:46:17.521048: step 2108, loss 0.0281838, acc 1
2020-02-08T02:46:17.638564: step 2109, loss 0.0795652, acc 0.953125
2020-02-08T02:46:17.754174: step 2110, loss 0.0451185, acc 0.984375
2020-02-08T02:46:17.869363: step 2111, loss 0.0884426, acc 0.96875
2020-02-08T02:46:17.988197: step 2112, loss 0.0413432, acc 0.984375
2020-02-08T02:46:18.102941: step 2113, loss 0.0655286, acc 0.984375
2020-02-08T02:46:18.222300: step 2114, loss 0.0242904, acc 0.984375
2020-02-08T02:46:18.337120: step 2115, loss 0.0452452, acc 0.984375
2020-02-08T02:46:18.453205: step 2116, loss 0.0451957, acc 0.984375
2020-02-08T02:46:18.570805: step 2117, loss 0.0472706, acc 1
2020-02-08T02:46:18.688999: step 2118, loss 0.0449157, acc 0.984375
2020-02-08T02:46:18.804690: step 2119, loss 0.0698202, acc 0.96875
2020-02-08T02:46:18.921315: step 2120, loss 0.0391857, acc 0.984375
2020-02-08T02:46:19.038963: step 2121, loss 0.0358597, acc 1
2020-02-08T02:46:19.152698: step 2122, loss 0.0569391, acc 0.96875
2020-02-08T02:46:19.269513: step 2123, loss 0.0559886, acc 0.984375
2020-02-08T02:46:19.384853: step 2124, loss 0.0154942, acc 1
2020-02-08T02:46:19.497427: step 2125, loss 0.037217, acc 0.984375
2020-02-08T02:46:19.613338: step 2126, loss 0.0302165, acc 1
2020-02-08T02:46:19.731056: step 2127, loss 0.101064, acc 0.953125
2020-02-08T02:46:19.847663: step 2128, loss 0.0900858, acc 0.96875
2020-02-08T02:46:19.967195: step 2129, loss 0.0630444, acc 0.953125
2020-02-08T02:46:20.084761: step 2130, loss 0.0871071, acc 0.984375
2020-02-08T02:46:20.198672: step 2131, loss 0.0321095, acc 1
2020-02-08T02:46:20.314919: step 2132, loss 0.101418, acc 0.984375
2020-02-08T02:46:20.432204: step 2133, loss 0.0527709, acc 0.96875
2020-02-08T02:46:20.546988: step 2134, loss 0.0704651, acc 0.953125
2020-02-08T02:46:20.660711: step 2135, loss 0.0271377, acc 1
2020-02-08T02:46:20.775606: step 2136, loss 0.0375358, acc 1
2020-02-08T02:46:20.892457: step 2137, loss 0.0314536, acc 1
2020-02-08T02:46:21.006409: step 2138, loss 0.0856405, acc 0.96875
2020-02-08T02:46:21.123184: step 2139, loss 0.057639, acc 0.984375
2020-02-08T02:46:21.240169: step 2140, loss 0.103481, acc 0.953125
2020-02-08T02:46:21.355458: step 2141, loss 0.104162, acc 0.96875
2020-02-08T02:46:21.472170: step 2142, loss 0.0392599, acc 0.984375
2020-02-08T02:46:21.605375: step 2143, loss 0.0773423, acc 0.953125
2020-02-08T02:46:21.723598: step 2144, loss 0.0248546, acc 1
2020-02-08T02:46:21.840465: step 2145, loss 0.0749997, acc 0.984375
2020-02-08T02:46:21.955385: step 2146, loss 0.19783, acc 0.9375
2020-02-08T02:46:22.072382: step 2147, loss 0.109493, acc 0.96875
2020-02-08T02:46:22.187070: step 2148, loss 0.0297821, acc 1
2020-02-08T02:46:22.302438: step 2149, loss 0.086781, acc 0.953125
2020-02-08T02:46:22.420526: step 2150, loss 0.0783516, acc 0.96875
2020-02-08T02:46:22.537331: step 2151, loss 0.0753313, acc 0.96875
2020-02-08T02:46:22.651761: step 2152, loss 0.0321365, acc 0.984375
2020-02-08T02:46:22.769838: step 2153, loss 0.0920527, acc 0.96875
2020-02-08T02:46:22.887646: step 2154, loss 0.0533171, acc 0.984375
2020-02-08T02:46:23.003315: step 2155, loss 0.0223028, acc 1
2020-02-08T02:46:23.120371: step 2156, loss 0.034916, acc 1
2020-02-08T02:46:23.237482: step 2157, loss 0.0369963, acc 1
2020-02-08T02:46:23.354769: step 2158, loss 0.0437965, acc 0.984375
2020-02-08T02:46:23.471854: step 2159, loss 0.0382019, acc 1
2020-02-08T02:46:23.590004: step 2160, loss 0.0760062, acc 0.96875
2020-02-08T02:46:23.704597: step 2161, loss 0.0127182, acc 1
2020-02-08T02:46:23.819290: step 2162, loss 0.0823514, acc 0.984375
2020-02-08T02:46:23.940197: step 2163, loss 0.108224, acc 0.9375
2020-02-08T02:46:24.055220: step 2164, loss 0.0704455, acc 0.96875
2020-02-08T02:46:24.174202: step 2165, loss 0.0444471, acc 0.984375
2020-02-08T02:46:24.292162: step 2166, loss 0.0276289, acc 1
2020-02-08T02:46:24.407392: step 2167, loss 0.116908, acc 0.953125
2020-02-08T02:46:24.526250: step 2168, loss 0.0521515, acc 0.984375
2020-02-08T02:46:24.643632: step 2169, loss 0.0190663, acc 1
2020-02-08T02:46:24.759724: step 2170, loss 0.0117167, acc 1
2020-02-08T02:46:24.877169: step 2171, loss 0.0717349, acc 0.96875
2020-02-08T02:46:24.992881: step 2172, loss 0.0683526, acc 0.984375
2020-02-08T02:46:25.106422: step 2173, loss 0.0749563, acc 0.984375
2020-02-08T02:46:25.224643: step 2174, loss 0.0395415, acc 1
2020-02-08T02:46:25.339414: step 2175, loss 0.100575, acc 0.96875
2020-02-08T02:46:25.454442: step 2176, loss 0.035291, acc 0.984375
2020-02-08T02:46:25.570727: step 2177, loss 0.0332598, acc 1
2020-02-08T02:46:25.689263: step 2178, loss 0.171886, acc 0.953125
2020-02-08T02:46:25.806989: step 2179, loss 0.0287126, acc 1
2020-02-08T02:46:25.922980: step 2180, loss 0.0356761, acc 0.984375
2020-02-08T02:46:26.041321: step 2181, loss 0.135645, acc 0.953125
2020-02-08T02:46:26.158211: step 2182, loss 0.0309414, acc 1
2020-02-08T02:46:26.276397: step 2183, loss 0.0958285, acc 0.984375
2020-02-08T02:46:26.392102: step 2184, loss 0.139266, acc 0.96875
2020-02-08T02:46:26.508433: step 2185, loss 0.0318165, acc 0.984375
2020-02-08T02:46:26.624074: step 2186, loss 0.0642167, acc 0.96875
2020-02-08T02:46:26.742490: step 2187, loss 0.0473549, acc 0.96875
2020-02-08T02:46:26.856028: step 2188, loss 0.0291831, acc 1
2020-02-08T02:46:26.970187: step 2189, loss 0.011784, acc 1
2020-02-08T02:46:27.084985: step 2190, loss 0.0338675, acc 0.984375
2020-02-08T02:46:27.200004: step 2191, loss 0.0336483, acc 1
2020-02-08T02:46:27.315274: step 2192, loss 0.0954583, acc 0.953125
2020-02-08T02:46:27.429901: step 2193, loss 0.0356023, acc 1
2020-02-08T02:46:27.546210: step 2194, loss 0.0648797, acc 0.96875
2020-02-08T02:46:27.664217: step 2195, loss 0.0653743, acc 0.96875
2020-02-08T02:46:27.781399: step 2196, loss 0.0309139, acc 1
2020-02-08T02:46:27.898606: step 2197, loss 0.0679624, acc 0.984375
2020-02-08T02:46:28.014595: step 2198, loss 0.0911773, acc 0.953125
2020-02-08T02:46:28.132576: step 2199, loss 0.0364794, acc 1
2020-02-08T02:46:28.247257: step 2200, loss 0.0491344, acc 0.984375

Evaluation:
2020-02-08T02:46:28.435129: step 2200, loss 0.766063, acc 0.752345

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2200

2020-02-08T02:46:29.933927: step 2201, loss 0.0410865, acc 0.984375
2020-02-08T02:46:30.050543: step 2202, loss 0.0968669, acc 0.96875
2020-02-08T02:46:30.166080: step 2203, loss 0.0615867, acc 0.96875
2020-02-08T02:46:30.284254: step 2204, loss 0.111979, acc 0.953125
2020-02-08T02:46:30.403061: step 2205, loss 0.0724838, acc 0.984375
2020-02-08T02:46:30.520190: step 2206, loss 0.123076, acc 0.953125
2020-02-08T02:46:30.640485: step 2207, loss 0.120902, acc 0.953125
2020-02-08T02:46:30.755123: step 2208, loss 0.0343657, acc 1
2020-02-08T02:46:30.869251: step 2209, loss 0.0504569, acc 0.984375
2020-02-08T02:46:30.985703: step 2210, loss 0.112532, acc 0.953125
2020-02-08T02:46:31.099710: step 2211, loss 0.0444592, acc 0.984375
2020-02-08T02:46:31.212770: step 2212, loss 0.127724, acc 0.96875
2020-02-08T02:46:31.329290: step 2213, loss 0.05208, acc 0.984375
2020-02-08T02:46:31.446363: step 2214, loss 0.150491, acc 0.9375
2020-02-08T02:46:31.562378: step 2215, loss 0.0784623, acc 0.984375
2020-02-08T02:46:31.679250: step 2216, loss 0.077115, acc 0.96875
2020-02-08T02:46:31.796505: step 2217, loss 0.0257749, acc 1
2020-02-08T02:46:31.909776: step 2218, loss 0.0622473, acc 0.984375
2020-02-08T02:46:32.025111: step 2219, loss 0.139591, acc 0.953125
2020-02-08T02:46:32.142363: step 2220, loss 0.0788422, acc 0.9375
2020-02-08T02:46:32.254961: step 2221, loss 0.0359791, acc 1
2020-02-08T02:46:32.370676: step 2222, loss 0.0579612, acc 0.984375
2020-02-08T02:46:32.487022: step 2223, loss 0.0232738, acc 1
2020-02-08T02:46:32.602015: step 2224, loss 0.0729691, acc 0.96875
2020-02-08T02:46:32.720435: step 2225, loss 0.0559689, acc 0.984375
2020-02-08T02:46:32.838836: step 2226, loss 0.0268608, acc 0.984375
2020-02-08T02:46:32.953694: step 2227, loss 0.0346794, acc 0.984375
2020-02-08T02:46:33.069340: step 2228, loss 0.0616941, acc 0.96875
2020-02-08T02:46:33.187399: step 2229, loss 0.0335997, acc 1
2020-02-08T02:46:33.304180: step 2230, loss 0.0354138, acc 0.984375
2020-02-08T02:46:33.420043: step 2231, loss 0.10269, acc 0.984375
2020-02-08T02:46:33.535831: step 2232, loss 0.0334397, acc 0.984375
2020-02-08T02:46:33.650696: step 2233, loss 0.057742, acc 0.984375
2020-02-08T02:46:33.766597: step 2234, loss 0.0280471, acc 1
2020-02-08T02:46:33.881759: step 2235, loss 0.0267311, acc 1
2020-02-08T02:46:33.996775: step 2236, loss 0.0448922, acc 0.984375
2020-02-08T02:46:34.109153: step 2237, loss 0.0556469, acc 0.96875
2020-02-08T02:46:34.223101: step 2238, loss 0.132102, acc 0.953125
2020-02-08T02:46:34.339163: step 2239, loss 0.0539744, acc 0.96875
2020-02-08T02:46:34.455312: step 2240, loss 0.0988049, acc 0.96875
2020-02-08T02:46:34.570657: step 2241, loss 0.0623252, acc 0.96875
2020-02-08T02:46:34.685804: step 2242, loss 0.0434741, acc 1
2020-02-08T02:46:34.803172: step 2243, loss 0.094248, acc 0.984375
2020-02-08T02:46:34.919431: step 2244, loss 0.0238695, acc 1
2020-02-08T02:46:35.036241: step 2245, loss 0.0326088, acc 1
2020-02-08T02:46:35.150996: step 2246, loss 0.0398071, acc 0.984375
2020-02-08T02:46:35.266469: step 2247, loss 0.0323367, acc 1
2020-02-08T02:46:35.384837: step 2248, loss 0.0160323, acc 1
2020-02-08T02:46:35.498803: step 2249, loss 0.119173, acc 0.96875
2020-02-08T02:46:35.609907: step 2250, loss 0.0988955, acc 0.966667
2020-02-08T02:46:35.730289: step 2251, loss 0.0112371, acc 1
2020-02-08T02:46:35.846419: step 2252, loss 0.0198814, acc 1
2020-02-08T02:46:35.964438: step 2253, loss 0.0144204, acc 1
2020-02-08T02:46:36.081656: step 2254, loss 0.0376251, acc 0.984375
2020-02-08T02:46:36.197148: step 2255, loss 0.0276776, acc 1
2020-02-08T02:46:36.311888: step 2256, loss 0.0258535, acc 0.984375
2020-02-08T02:46:36.427901: step 2257, loss 0.0420733, acc 0.984375
2020-02-08T02:46:36.542672: step 2258, loss 0.0220242, acc 1
2020-02-08T02:46:36.658743: step 2259, loss 0.0131727, acc 1
2020-02-08T02:46:36.772367: step 2260, loss 0.0352213, acc 0.984375
2020-02-08T02:46:36.890548: step 2261, loss 0.0709756, acc 0.96875
2020-02-08T02:46:37.006504: step 2262, loss 0.0279843, acc 1
2020-02-08T02:46:37.122809: step 2263, loss 0.0768401, acc 0.953125
2020-02-08T02:46:37.240179: step 2264, loss 0.0232284, acc 1
2020-02-08T02:46:37.357378: step 2265, loss 0.0259839, acc 0.984375
2020-02-08T02:46:37.473620: step 2266, loss 0.0432521, acc 0.96875
2020-02-08T02:46:37.588746: step 2267, loss 0.0235418, acc 1
2020-02-08T02:46:37.704657: step 2268, loss 0.0681451, acc 0.953125
2020-02-08T02:46:37.822418: step 2269, loss 0.0793479, acc 0.96875
2020-02-08T02:46:37.939973: step 2270, loss 0.0467424, acc 0.984375
2020-02-08T02:46:38.057244: step 2271, loss 0.0572907, acc 0.96875
2020-02-08T02:46:38.172424: step 2272, loss 0.0227758, acc 0.984375
2020-02-08T02:46:38.290686: step 2273, loss 0.0654108, acc 0.984375
2020-02-08T02:46:38.406197: step 2274, loss 0.0222819, acc 1
2020-02-08T02:46:38.520562: step 2275, loss 0.0137065, acc 1
2020-02-08T02:46:38.635604: step 2276, loss 0.0431162, acc 0.984375
2020-02-08T02:46:38.749745: step 2277, loss 0.0132708, acc 1
2020-02-08T02:46:38.865990: step 2278, loss 0.0198535, acc 1
2020-02-08T02:46:38.978719: step 2279, loss 0.0229412, acc 1
2020-02-08T02:46:39.096809: step 2280, loss 0.0237084, acc 1
2020-02-08T02:46:39.214564: step 2281, loss 0.0545275, acc 0.96875
2020-02-08T02:46:39.331208: step 2282, loss 0.023871, acc 1
2020-02-08T02:46:39.448331: step 2283, loss 0.0562865, acc 0.96875
2020-02-08T02:46:39.563932: step 2284, loss 0.0176513, acc 1
2020-02-08T02:46:39.680822: step 2285, loss 0.0976185, acc 0.96875
2020-02-08T02:46:39.796472: step 2286, loss 0.0212791, acc 1
2020-02-08T02:46:39.911614: step 2287, loss 0.041114, acc 0.984375
2020-02-08T02:46:40.029021: step 2288, loss 0.0354778, acc 1
2020-02-08T02:46:40.143410: step 2289, loss 0.0303774, acc 0.984375
2020-02-08T02:46:40.257030: step 2290, loss 0.0160033, acc 1
2020-02-08T02:46:40.372896: step 2291, loss 0.0291863, acc 0.984375
2020-02-08T02:46:40.486868: step 2292, loss 0.0183475, acc 1
2020-02-08T02:46:40.601487: step 2293, loss 0.0311059, acc 0.984375
2020-02-08T02:46:40.717440: step 2294, loss 0.0532424, acc 0.984375
2020-02-08T02:46:40.835650: step 2295, loss 0.0668634, acc 0.984375
2020-02-08T02:46:40.952571: step 2296, loss 0.0149262, acc 1
2020-02-08T02:46:41.068783: step 2297, loss 0.0589604, acc 0.984375
2020-02-08T02:46:41.185882: step 2298, loss 0.143365, acc 0.96875
2020-02-08T02:46:41.303697: step 2299, loss 0.0399751, acc 0.984375
2020-02-08T02:46:41.420399: step 2300, loss 0.0260557, acc 1

Evaluation:
2020-02-08T02:46:41.608723: step 2300, loss 0.806216, acc 0.745779

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2300

2020-02-08T02:46:43.145644: step 2301, loss 0.0410209, acc 0.984375
2020-02-08T02:46:43.264295: step 2302, loss 0.0181958, acc 1
2020-02-08T02:46:43.382546: step 2303, loss 0.0704558, acc 0.984375
2020-02-08T02:46:43.499116: step 2304, loss 0.0855744, acc 0.953125
2020-02-08T02:46:43.616617: step 2305, loss 0.0345936, acc 0.984375
2020-02-08T02:46:43.734699: step 2306, loss 0.157116, acc 0.953125
2020-02-08T02:46:43.849343: step 2307, loss 0.0668899, acc 0.984375
2020-02-08T02:46:43.963558: step 2308, loss 0.0431752, acc 0.984375
2020-02-08T02:46:44.080412: step 2309, loss 0.0121381, acc 1
2020-02-08T02:46:44.196268: step 2310, loss 0.0540689, acc 0.984375
2020-02-08T02:46:44.311542: step 2311, loss 0.0100008, acc 1
2020-02-08T02:46:44.428602: step 2312, loss 0.0441827, acc 0.984375
2020-02-08T02:46:44.544730: step 2313, loss 0.0323857, acc 0.984375
2020-02-08T02:46:44.660337: step 2314, loss 0.0528051, acc 0.984375
2020-02-08T02:46:44.779012: step 2315, loss 0.00803499, acc 1
2020-02-08T02:46:44.894734: step 2316, loss 0.0630613, acc 0.953125
2020-02-08T02:46:45.010984: step 2317, loss 0.0141242, acc 1
2020-02-08T02:46:45.126854: step 2318, loss 0.0708864, acc 0.96875
2020-02-08T02:46:45.242694: step 2319, loss 0.0112013, acc 1
2020-02-08T02:46:45.358265: step 2320, loss 0.0232457, acc 0.984375
2020-02-08T02:46:45.475782: step 2321, loss 0.019208, acc 1
2020-02-08T02:46:45.593288: step 2322, loss 0.0279801, acc 0.984375
2020-02-08T02:46:45.710688: step 2323, loss 0.0213611, acc 1
2020-02-08T02:46:45.827126: step 2324, loss 0.0492725, acc 0.984375
2020-02-08T02:46:45.942932: step 2325, loss 0.0309256, acc 0.984375
2020-02-08T02:46:46.055985: step 2326, loss 0.0473702, acc 0.984375
2020-02-08T02:46:46.172218: step 2327, loss 0.0298634, acc 1
2020-02-08T02:46:46.287920: step 2328, loss 0.0353101, acc 0.984375
2020-02-08T02:46:46.400962: step 2329, loss 0.127418, acc 0.921875
2020-02-08T02:46:46.516377: step 2330, loss 0.0472957, acc 0.96875
2020-02-08T02:46:46.632619: step 2331, loss 0.018187, acc 1
2020-02-08T02:46:46.749635: step 2332, loss 0.0234927, acc 1
2020-02-08T02:46:46.865446: step 2333, loss 0.0496576, acc 0.984375
2020-02-08T02:46:46.982338: step 2334, loss 0.0217313, acc 1
2020-02-08T02:46:47.099021: step 2335, loss 0.0251572, acc 1
2020-02-08T02:46:47.217497: step 2336, loss 0.0747512, acc 0.96875
2020-02-08T02:46:47.339037: step 2337, loss 0.0355159, acc 1
2020-02-08T02:46:47.454631: step 2338, loss 0.0538889, acc 0.96875
2020-02-08T02:46:47.571504: step 2339, loss 0.073713, acc 0.96875
2020-02-08T02:46:47.690538: step 2340, loss 0.0790037, acc 0.96875
2020-02-08T02:46:47.805534: step 2341, loss 0.121378, acc 0.9375
2020-02-08T02:46:47.920458: step 2342, loss 0.0301774, acc 1
2020-02-08T02:46:48.040322: step 2343, loss 0.0132507, acc 1
2020-02-08T02:46:48.156916: step 2344, loss 0.0362745, acc 0.984375
2020-02-08T02:46:48.272351: step 2345, loss 0.0269883, acc 0.984375
2020-02-08T02:46:48.390128: step 2346, loss 0.0672266, acc 0.96875
2020-02-08T02:46:48.505613: step 2347, loss 0.0746366, acc 0.96875
2020-02-08T02:46:48.623195: step 2348, loss 0.0163436, acc 1
2020-02-08T02:46:48.740191: step 2349, loss 0.067723, acc 0.984375
2020-02-08T02:46:48.854522: step 2350, loss 0.0565433, acc 0.96875
2020-02-08T02:46:48.971265: step 2351, loss 0.0318845, acc 1
2020-02-08T02:46:49.087310: step 2352, loss 0.0143169, acc 1
2020-02-08T02:46:49.204063: step 2353, loss 0.0324871, acc 0.984375
2020-02-08T02:46:49.318517: step 2354, loss 0.0550417, acc 0.984375
2020-02-08T02:46:49.435791: step 2355, loss 0.0388006, acc 0.984375
2020-02-08T02:46:49.550558: step 2356, loss 0.0395464, acc 0.984375
2020-02-08T02:46:49.666011: step 2357, loss 0.0372296, acc 1
2020-02-08T02:46:49.785375: step 2358, loss 0.0473282, acc 0.96875
2020-02-08T02:46:49.900081: step 2359, loss 0.0804177, acc 0.96875
2020-02-08T02:46:50.015035: step 2360, loss 0.0170765, acc 1
2020-02-08T02:46:50.134563: step 2361, loss 0.0209543, acc 1
2020-02-08T02:46:50.249719: step 2362, loss 0.0190594, acc 1
2020-02-08T02:46:50.368475: step 2363, loss 0.0116533, acc 1
2020-02-08T02:46:50.483445: step 2364, loss 0.0167425, acc 1
2020-02-08T02:46:50.598905: step 2365, loss 0.0459845, acc 0.984375
2020-02-08T02:46:50.713416: step 2366, loss 0.0177522, acc 0.984375
2020-02-08T02:46:50.832218: step 2367, loss 0.0399708, acc 0.984375
2020-02-08T02:46:50.947186: step 2368, loss 0.0194287, acc 1
2020-02-08T02:46:51.064195: step 2369, loss 0.0904324, acc 0.96875
2020-02-08T02:46:51.183094: step 2370, loss 0.0622156, acc 0.984375
2020-02-08T02:46:51.295802: step 2371, loss 0.0768832, acc 0.984375
2020-02-08T02:46:51.412790: step 2372, loss 0.0543615, acc 0.984375
2020-02-08T02:46:51.582600: step 2373, loss 0.0551529, acc 0.96875
2020-02-08T02:46:51.704272: step 2374, loss 0.0335696, acc 1
2020-02-08T02:46:51.821389: step 2375, loss 0.0696991, acc 0.984375
2020-02-08T02:46:51.939548: step 2376, loss 0.0114982, acc 1
2020-02-08T02:46:52.055231: step 2377, loss 0.0372473, acc 0.984375
2020-02-08T02:46:52.173958: step 2378, loss 0.0245518, acc 0.984375
2020-02-08T02:46:52.293444: step 2379, loss 0.0547566, acc 0.984375
2020-02-08T02:46:52.408452: step 2380, loss 0.0398192, acc 0.984375
2020-02-08T02:46:52.526930: step 2381, loss 0.0345109, acc 0.984375
2020-02-08T02:46:52.642900: step 2382, loss 0.0954756, acc 0.984375
2020-02-08T02:46:52.756964: step 2383, loss 0.0520688, acc 0.984375
2020-02-08T02:46:52.875083: step 2384, loss 0.0135489, acc 1
2020-02-08T02:46:52.993109: step 2385, loss 0.0436414, acc 1
2020-02-08T02:46:53.106685: step 2386, loss 0.0179411, acc 1
2020-02-08T02:46:53.224056: step 2387, loss 0.0174206, acc 1
2020-02-08T02:46:53.342315: step 2388, loss 0.16336, acc 0.953125
2020-02-08T02:46:53.457510: step 2389, loss 0.0162675, acc 1
2020-02-08T02:46:53.575941: step 2390, loss 0.0734492, acc 0.96875
2020-02-08T02:46:53.692401: step 2391, loss 0.0372077, acc 1
2020-02-08T02:46:53.810438: step 2392, loss 0.0448701, acc 0.96875
2020-02-08T02:46:53.930062: step 2393, loss 0.0430584, acc 0.984375
2020-02-08T02:46:54.046366: step 2394, loss 0.122246, acc 0.9375
2020-02-08T02:46:54.162733: step 2395, loss 0.0829281, acc 0.984375
2020-02-08T02:46:54.278697: step 2396, loss 0.0361438, acc 0.96875
2020-02-08T02:46:54.395616: step 2397, loss 0.0410245, acc 0.984375
2020-02-08T02:46:54.512214: step 2398, loss 0.0982948, acc 0.96875
2020-02-08T02:46:54.628957: step 2399, loss 0.0405965, acc 0.984375
2020-02-08T02:46:54.741531: step 2400, loss 0.0215621, acc 1

Evaluation:
2020-02-08T02:46:54.930393: step 2400, loss 0.813884, acc 0.75985

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2400

2020-02-08T02:46:56.417395: step 2401, loss 0.0286149, acc 0.984375
2020-02-08T02:46:56.537416: step 2402, loss 0.00352166, acc 1
2020-02-08T02:46:56.655335: step 2403, loss 0.00527774, acc 1
2020-02-08T02:46:56.773538: step 2404, loss 0.0323005, acc 0.984375
2020-02-08T02:46:56.888882: step 2405, loss 0.00640227, acc 1
2020-02-08T02:46:57.002900: step 2406, loss 0.0310257, acc 0.984375
2020-02-08T02:46:57.120232: step 2407, loss 0.0711402, acc 0.984375
2020-02-08T02:46:57.237365: step 2408, loss 0.0370955, acc 0.984375
2020-02-08T02:46:57.353027: step 2409, loss 0.0250595, acc 1
2020-02-08T02:46:57.474969: step 2410, loss 0.0352852, acc 0.984375
2020-02-08T02:46:57.592647: step 2411, loss 0.0429857, acc 0.984375
2020-02-08T02:46:57.708719: step 2412, loss 0.025643, acc 1
2020-02-08T02:46:57.825797: step 2413, loss 0.0311502, acc 1
2020-02-08T02:46:57.943478: step 2414, loss 0.0238908, acc 0.984375
2020-02-08T02:46:58.063251: step 2415, loss 0.0118349, acc 1
2020-02-08T02:46:58.179196: step 2416, loss 0.0371034, acc 1
2020-02-08T02:46:58.294597: step 2417, loss 0.0285136, acc 0.984375
2020-02-08T02:46:58.413038: step 2418, loss 0.0439351, acc 0.984375
2020-02-08T02:46:58.530683: step 2419, loss 0.0318063, acc 0.984375
2020-02-08T02:46:58.648660: step 2420, loss 0.0383561, acc 0.96875
2020-02-08T02:46:58.766274: step 2421, loss 0.0228609, acc 1
2020-02-08T02:46:58.885263: step 2422, loss 0.02505, acc 1
2020-02-08T02:46:59.000636: step 2423, loss 0.00608577, acc 1
2020-02-08T02:46:59.115487: step 2424, loss 0.0287832, acc 1
2020-02-08T02:46:59.232596: step 2425, loss 0.0358761, acc 1
2020-02-08T02:46:59.352962: step 2426, loss 0.0141588, acc 1
2020-02-08T02:46:59.471326: step 2427, loss 0.0143573, acc 1
2020-02-08T02:46:59.587614: step 2428, loss 0.0301529, acc 0.984375
2020-02-08T02:46:59.703729: step 2429, loss 0.0157831, acc 1
2020-02-08T02:46:59.820895: step 2430, loss 0.0516498, acc 0.984375
2020-02-08T02:46:59.938004: step 2431, loss 0.0210462, acc 1
2020-02-08T02:47:00.053833: step 2432, loss 0.018192, acc 1
2020-02-08T02:47:00.170363: step 2433, loss 0.0128569, acc 1
2020-02-08T02:47:00.287669: step 2434, loss 0.0352883, acc 0.984375
2020-02-08T02:47:00.402695: step 2435, loss 0.0111334, acc 1
2020-02-08T02:47:00.518865: step 2436, loss 0.00503528, acc 1
2020-02-08T02:47:00.635622: step 2437, loss 0.0149073, acc 1
2020-02-08T02:47:00.755332: step 2438, loss 0.0230229, acc 0.984375
2020-02-08T02:47:00.872978: step 2439, loss 0.0387187, acc 0.984375
2020-02-08T02:47:00.990969: step 2440, loss 0.0234666, acc 0.984375
2020-02-08T02:47:01.107181: step 2441, loss 0.0123428, acc 1
2020-02-08T02:47:01.224767: step 2442, loss 0.0800935, acc 0.953125
2020-02-08T02:47:01.339988: step 2443, loss 0.0275493, acc 0.984375
2020-02-08T02:47:01.454619: step 2444, loss 0.0621066, acc 0.984375
2020-02-08T02:47:01.573466: step 2445, loss 0.0186436, acc 0.984375
2020-02-08T02:47:01.690210: step 2446, loss 0.0368775, acc 1
2020-02-08T02:47:01.806730: step 2447, loss 0.0129513, acc 1
2020-02-08T02:47:01.922073: step 2448, loss 0.0481083, acc 0.984375
2020-02-08T02:47:02.038504: step 2449, loss 0.0630627, acc 0.96875
2020-02-08T02:47:02.154185: step 2450, loss 0.0327798, acc 0.984375
2020-02-08T02:47:02.269812: step 2451, loss 0.0469799, acc 0.984375
2020-02-08T02:47:02.391997: step 2452, loss 0.0214627, acc 1
2020-02-08T02:47:02.507692: step 2453, loss 0.00650908, acc 1
2020-02-08T02:47:02.624431: step 2454, loss 0.0140926, acc 1
2020-02-08T02:47:02.741267: step 2455, loss 0.00977484, acc 1
2020-02-08T02:47:02.854073: step 2456, loss 0.0174859, acc 1
2020-02-08T02:47:02.971268: step 2457, loss 0.0178031, acc 1
2020-02-08T02:47:03.090563: step 2458, loss 0.0189221, acc 1
2020-02-08T02:47:03.204154: step 2459, loss 0.0297556, acc 1
2020-02-08T02:47:03.321373: step 2460, loss 0.0851458, acc 0.984375
2020-02-08T02:47:03.439316: step 2461, loss 0.03142, acc 1
2020-02-08T02:47:03.554248: step 2462, loss 0.0133019, acc 1
2020-02-08T02:47:03.674585: step 2463, loss 0.034911, acc 1
2020-02-08T02:47:03.794509: step 2464, loss 0.0606926, acc 0.984375
2020-02-08T02:47:03.909167: step 2465, loss 0.019409, acc 1
2020-02-08T02:47:04.023387: step 2466, loss 0.0288141, acc 0.984375
2020-02-08T02:47:04.141255: step 2467, loss 0.0106773, acc 1
2020-02-08T02:47:04.259180: step 2468, loss 0.0297639, acc 0.984375
2020-02-08T02:47:04.377343: step 2469, loss 0.0625792, acc 0.984375
2020-02-08T02:47:04.491738: step 2470, loss 0.0305673, acc 1
2020-02-08T02:47:04.606538: step 2471, loss 0.0123349, acc 1
2020-02-08T02:47:04.722819: step 2472, loss 0.0440606, acc 0.984375
2020-02-08T02:47:04.841053: step 2473, loss 0.00567576, acc 1
2020-02-08T02:47:04.957007: step 2474, loss 0.00862304, acc 1
2020-02-08T02:47:05.075319: step 2475, loss 0.0174333, acc 1
2020-02-08T02:47:05.193358: step 2476, loss 0.0379042, acc 0.984375
2020-02-08T02:47:05.310653: step 2477, loss 0.0772811, acc 0.96875
2020-02-08T02:47:05.427432: step 2478, loss 0.0213012, acc 0.984375
2020-02-08T02:47:05.545110: step 2479, loss 0.0243779, acc 0.984375
2020-02-08T02:47:05.662522: step 2480, loss 0.0671942, acc 0.984375
2020-02-08T02:47:05.781936: step 2481, loss 0.0521376, acc 0.984375
2020-02-08T02:47:05.898759: step 2482, loss 0.0120572, acc 1
2020-02-08T02:47:06.014470: step 2483, loss 0.0335187, acc 0.984375
2020-02-08T02:47:06.130720: step 2484, loss 0.0296524, acc 1
2020-02-08T02:47:06.247674: step 2485, loss 0.0273779, acc 0.984375
2020-02-08T02:47:06.365438: step 2486, loss 0.028232, acc 1
2020-02-08T02:47:06.481830: step 2487, loss 0.03123, acc 0.984375
2020-02-08T02:47:06.595453: step 2488, loss 0.0163247, acc 1
2020-02-08T02:47:06.713716: step 2489, loss 0.0080336, acc 1
2020-02-08T02:47:06.832833: step 2490, loss 0.0300938, acc 0.984375
2020-02-08T02:47:06.950037: step 2491, loss 0.0133886, acc 1
2020-02-08T02:47:07.067751: step 2492, loss 0.0551469, acc 1
2020-02-08T02:47:07.187400: step 2493, loss 0.0450742, acc 0.984375
2020-02-08T02:47:07.302997: step 2494, loss 0.0372038, acc 0.96875
2020-02-08T02:47:07.418028: step 2495, loss 0.0289162, acc 1
2020-02-08T02:47:07.536489: step 2496, loss 0.0427584, acc 0.984375
2020-02-08T02:47:07.651755: step 2497, loss 0.0586187, acc 0.984375
2020-02-08T02:47:07.765646: step 2498, loss 0.0488109, acc 0.984375
2020-02-08T02:47:07.887543: step 2499, loss 0.015401, acc 1
2020-02-08T02:47:08.004317: step 2500, loss 0.0715588, acc 0.984375

Evaluation:
2020-02-08T02:47:08.190246: step 2500, loss 0.841725, acc 0.763602

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2500

2020-02-08T02:47:09.997095: step 2501, loss 0.00792568, acc 1
2020-02-08T02:47:10.112975: step 2502, loss 0.0274613, acc 0.984375
2020-02-08T02:47:10.231984: step 2503, loss 0.0127877, acc 1
2020-02-08T02:47:10.348861: step 2504, loss 0.0141469, acc 1
2020-02-08T02:47:10.466281: step 2505, loss 0.0238034, acc 1
2020-02-08T02:47:10.583533: step 2506, loss 0.0211612, acc 0.984375
2020-02-08T02:47:10.698835: step 2507, loss 0.0728543, acc 0.96875
2020-02-08T02:47:10.814265: step 2508, loss 0.0302055, acc 0.984375
2020-02-08T02:47:10.933535: step 2509, loss 0.0160314, acc 1
2020-02-08T02:47:11.049812: step 2510, loss 0.100526, acc 0.96875
2020-02-08T02:47:11.164726: step 2511, loss 0.122604, acc 0.953125
2020-02-08T02:47:11.279007: step 2512, loss 0.0100219, acc 1
2020-02-08T02:47:11.393646: step 2513, loss 0.0299299, acc 0.984375
2020-02-08T02:47:11.510515: step 2514, loss 0.0691376, acc 0.96875
2020-02-08T02:47:11.628370: step 2515, loss 0.0426454, acc 0.984375
2020-02-08T02:47:11.746781: step 2516, loss 0.0140848, acc 1
2020-02-08T02:47:11.861313: step 2517, loss 0.0581324, acc 0.984375
2020-02-08T02:47:11.978621: step 2518, loss 0.0590407, acc 0.96875
2020-02-08T02:47:12.095990: step 2519, loss 0.0454319, acc 0.984375
2020-02-08T02:47:12.211429: step 2520, loss 0.0687593, acc 0.953125
2020-02-08T02:47:12.330140: step 2521, loss 0.0235661, acc 0.984375
2020-02-08T02:47:12.447805: step 2522, loss 0.0332472, acc 0.984375
2020-02-08T02:47:12.562788: step 2523, loss 0.0319163, acc 1
2020-02-08T02:47:12.681129: step 2524, loss 0.0322455, acc 0.984375
2020-02-08T02:47:12.798698: step 2525, loss 0.0309121, acc 0.984375
2020-02-08T02:47:12.914162: step 2526, loss 0.0914696, acc 0.9375
2020-02-08T02:47:13.031581: step 2527, loss 0.0429711, acc 0.984375
2020-02-08T02:47:13.147972: step 2528, loss 0.0311406, acc 0.984375
2020-02-08T02:47:13.263965: step 2529, loss 0.019416, acc 1
2020-02-08T02:47:13.380793: step 2530, loss 0.015251, acc 1
2020-02-08T02:47:13.497144: step 2531, loss 0.0222179, acc 1
2020-02-08T02:47:13.611866: step 2532, loss 0.0271552, acc 1
2020-02-08T02:47:13.730593: step 2533, loss 0.0145095, acc 1
2020-02-08T02:47:13.849075: step 2534, loss 0.0337593, acc 0.984375
2020-02-08T02:47:13.964962: step 2535, loss 0.0170569, acc 1
2020-02-08T02:47:14.082176: step 2536, loss 0.0172404, acc 1
2020-02-08T02:47:14.198325: step 2537, loss 0.0351068, acc 1
2020-02-08T02:47:14.311546: step 2538, loss 0.0252541, acc 1
2020-02-08T02:47:14.428334: step 2539, loss 0.159392, acc 0.96875
2020-02-08T02:47:14.546516: step 2540, loss 0.0191042, acc 0.984375
2020-02-08T02:47:14.663890: step 2541, loss 0.0555421, acc 0.984375
2020-02-08T02:47:14.783300: step 2542, loss 0.0246079, acc 1
2020-02-08T02:47:14.899920: step 2543, loss 0.0432983, acc 0.984375
2020-02-08T02:47:15.018186: step 2544, loss 0.00746213, acc 1
2020-02-08T02:47:15.135062: step 2545, loss 0.0114277, acc 1
2020-02-08T02:47:15.252313: step 2546, loss 0.0518437, acc 0.984375
2020-02-08T02:47:15.368570: step 2547, loss 0.0126758, acc 1
2020-02-08T02:47:15.486208: step 2548, loss 0.0549157, acc 0.984375
2020-02-08T02:47:15.601051: step 2549, loss 0.0395416, acc 0.984375
2020-02-08T02:47:15.712494: step 2550, loss 0.0280953, acc 1
2020-02-08T02:47:15.830158: step 2551, loss 0.0134971, acc 1
2020-02-08T02:47:15.947700: step 2552, loss 0.0825068, acc 0.984375
2020-02-08T02:47:16.063156: step 2553, loss 0.0487325, acc 0.984375
2020-02-08T02:47:16.181631: step 2554, loss 0.0136541, acc 1
2020-02-08T02:47:16.296370: step 2555, loss 0.0259829, acc 0.984375
2020-02-08T02:47:16.412916: step 2556, loss 0.0292508, acc 0.984375
2020-02-08T02:47:16.529585: step 2557, loss 0.0162473, acc 1
2020-02-08T02:47:16.644978: step 2558, loss 0.0146936, acc 1
2020-02-08T02:47:16.760535: step 2559, loss 0.0060399, acc 1
2020-02-08T02:47:16.877809: step 2560, loss 0.00725946, acc 1
2020-02-08T02:47:16.996986: step 2561, loss 0.0145694, acc 1
2020-02-08T02:47:17.112178: step 2562, loss 0.0323127, acc 1
2020-02-08T02:47:17.227999: step 2563, loss 0.0470253, acc 0.984375
2020-02-08T02:47:17.347548: step 2564, loss 0.0128909, acc 1
2020-02-08T02:47:17.463500: step 2565, loss 0.0571885, acc 0.96875
2020-02-08T02:47:17.578669: step 2566, loss 0.00930846, acc 1
2020-02-08T02:47:17.694025: step 2567, loss 0.0197596, acc 0.984375
2020-02-08T02:47:17.810396: step 2568, loss 0.0377859, acc 0.984375
2020-02-08T02:47:17.925537: step 2569, loss 0.0437745, acc 0.984375
2020-02-08T02:47:18.043654: step 2570, loss 0.0111348, acc 1
2020-02-08T02:47:18.158709: step 2571, loss 0.0171226, acc 1
2020-02-08T02:47:18.273916: step 2572, loss 0.0519071, acc 0.984375
2020-02-08T02:47:18.392438: step 2573, loss 0.0125022, acc 1
2020-02-08T02:47:18.507780: step 2574, loss 0.0349319, acc 0.984375
2020-02-08T02:47:18.624402: step 2575, loss 0.0109018, acc 1
2020-02-08T02:47:18.740164: step 2576, loss 0.0288673, acc 0.984375
2020-02-08T02:47:18.853568: step 2577, loss 0.0237212, acc 0.984375
2020-02-08T02:47:18.966791: step 2578, loss 0.0185787, acc 1
2020-02-08T02:47:19.082782: step 2579, loss 0.0156034, acc 1
2020-02-08T02:47:19.198195: step 2580, loss 0.0194944, acc 1
2020-02-08T02:47:19.318651: step 2581, loss 0.0139153, acc 1
2020-02-08T02:47:19.435144: step 2582, loss 0.00766757, acc 1
2020-02-08T02:47:19.549339: step 2583, loss 0.0555957, acc 0.984375
2020-02-08T02:47:19.667311: step 2584, loss 0.0161781, acc 1
2020-02-08T02:47:19.785497: step 2585, loss 0.107346, acc 0.96875
2020-02-08T02:47:19.899358: step 2586, loss 0.0220085, acc 1
2020-02-08T02:47:20.016835: step 2587, loss 0.0174537, acc 1
2020-02-08T02:47:20.132612: step 2588, loss 0.0380552, acc 0.984375
2020-02-08T02:47:20.248076: step 2589, loss 0.0130743, acc 1
2020-02-08T02:47:20.364168: step 2590, loss 0.0390898, acc 1
2020-02-08T02:47:20.482780: step 2591, loss 0.0597229, acc 1
2020-02-08T02:47:20.598506: step 2592, loss 0.0321241, acc 0.984375
2020-02-08T02:47:20.714070: step 2593, loss 0.0387084, acc 0.984375
2020-02-08T02:47:20.831571: step 2594, loss 0.0162648, acc 1
2020-02-08T02:47:20.948455: step 2595, loss 0.0261617, acc 0.984375
2020-02-08T02:47:21.070945: step 2596, loss 0.0538849, acc 0.984375
2020-02-08T02:47:21.188980: step 2597, loss 0.0148915, acc 1
2020-02-08T02:47:21.535646: step 2598, loss 0.0337074, acc 0.984375
2020-02-08T02:47:21.653111: step 2599, loss 0.017648, acc 1
2020-02-08T02:47:21.769600: step 2600, loss 0.0399724, acc 0.96875

Evaluation:
2020-02-08T02:47:21.957732: step 2600, loss 0.873662, acc 0.754221

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2600

2020-02-08T02:47:23.480485: step 2601, loss 0.00455734, acc 1
2020-02-08T02:47:23.599114: step 2602, loss 0.0159384, acc 1
2020-02-08T02:47:23.714723: step 2603, loss 0.0586809, acc 0.984375
2020-02-08T02:47:23.834077: step 2604, loss 0.0168628, acc 1
2020-02-08T02:47:23.954393: step 2605, loss 0.0697254, acc 0.96875
2020-02-08T02:47:24.071554: step 2606, loss 0.0360996, acc 0.984375
2020-02-08T02:47:24.189301: step 2607, loss 0.0183862, acc 1
2020-02-08T02:47:24.303881: step 2608, loss 0.00311688, acc 1
2020-02-08T02:47:24.422716: step 2609, loss 0.00695479, acc 1
2020-02-08T02:47:24.541137: step 2610, loss 0.0072479, acc 1
2020-02-08T02:47:24.656192: step 2611, loss 0.00995285, acc 1
2020-02-08T02:47:24.779623: step 2612, loss 0.0360106, acc 0.984375
2020-02-08T02:47:24.897957: step 2613, loss 0.0140121, acc 1
2020-02-08T02:47:25.017272: step 2614, loss 0.00937115, acc 1
2020-02-08T02:47:25.135301: step 2615, loss 0.0222165, acc 0.984375
2020-02-08T02:47:25.254625: step 2616, loss 0.0328526, acc 0.984375
2020-02-08T02:47:25.373380: step 2617, loss 0.042068, acc 1
2020-02-08T02:47:25.489907: step 2618, loss 0.0114675, acc 1
2020-02-08T02:47:25.608005: step 2619, loss 0.0231234, acc 1
2020-02-08T02:47:25.723595: step 2620, loss 0.058393, acc 0.984375
2020-02-08T02:47:25.844082: step 2621, loss 0.0186152, acc 1
2020-02-08T02:47:25.959739: step 2622, loss 0.0278349, acc 0.984375
2020-02-08T02:47:26.076347: step 2623, loss 0.0059936, acc 1
2020-02-08T02:47:26.193387: step 2624, loss 0.0160688, acc 1
2020-02-08T02:47:26.309225: step 2625, loss 0.0573755, acc 0.984375
2020-02-08T02:47:26.425695: step 2626, loss 0.0130592, acc 1
2020-02-08T02:47:26.544759: step 2627, loss 0.0217804, acc 0.984375
2020-02-08T02:47:26.659199: step 2628, loss 0.00718106, acc 1
2020-02-08T02:47:26.777736: step 2629, loss 0.0240438, acc 1
2020-02-08T02:47:26.893771: step 2630, loss 0.0182924, acc 1
2020-02-08T02:47:27.012442: step 2631, loss 0.0242001, acc 0.984375
2020-02-08T02:47:27.129381: step 2632, loss 0.0107102, acc 1
2020-02-08T02:47:27.245033: step 2633, loss 0.0215106, acc 1
2020-02-08T02:47:27.359016: step 2634, loss 0.0251725, acc 0.984375
2020-02-08T02:47:27.475907: step 2635, loss 0.0210569, acc 1
2020-02-08T02:47:27.593503: step 2636, loss 0.0227581, acc 0.984375
2020-02-08T02:47:27.704958: step 2637, loss 0.0559673, acc 0.96875
2020-02-08T02:47:27.820884: step 2638, loss 0.029764, acc 0.984375
2020-02-08T02:47:27.936376: step 2639, loss 0.00776495, acc 1
2020-02-08T02:47:28.052957: step 2640, loss 0.0537259, acc 0.96875
2020-02-08T02:47:28.169576: step 2641, loss 0.0378811, acc 0.984375
2020-02-08T02:47:28.285878: step 2642, loss 0.00895393, acc 1
2020-02-08T02:47:28.403317: step 2643, loss 0.0397759, acc 0.984375
2020-02-08T02:47:28.518838: step 2644, loss 0.0082929, acc 1
2020-02-08T02:47:28.636013: step 2645, loss 0.0343909, acc 1
2020-02-08T02:47:28.750387: step 2646, loss 0.0358345, acc 0.984375
2020-02-08T02:47:28.868113: step 2647, loss 0.0270893, acc 1
2020-02-08T02:47:28.985238: step 2648, loss 0.00888585, acc 1
2020-02-08T02:47:29.101168: step 2649, loss 0.01528, acc 1
2020-02-08T02:47:29.222990: step 2650, loss 0.0339496, acc 1
2020-02-08T02:47:29.341581: step 2651, loss 0.0322637, acc 0.984375
2020-02-08T02:47:29.456553: step 2652, loss 0.0232779, acc 1
2020-02-08T02:47:29.573545: step 2653, loss 0.0076346, acc 1
2020-02-08T02:47:29.691648: step 2654, loss 0.0158272, acc 1
2020-02-08T02:47:29.811238: step 2655, loss 0.0256769, acc 0.984375
2020-02-08T02:47:29.927603: step 2656, loss 0.0351772, acc 0.984375
2020-02-08T02:47:30.043830: step 2657, loss 0.0283881, acc 0.984375
2020-02-08T02:47:30.156243: step 2658, loss 0.0158005, acc 1
2020-02-08T02:47:30.272992: step 2659, loss 0.0202972, acc 0.984375
2020-02-08T02:47:30.389522: step 2660, loss 0.00743365, acc 1
2020-02-08T02:47:30.503396: step 2661, loss 0.00753046, acc 1
2020-02-08T02:47:30.620205: step 2662, loss 0.0164054, acc 1
2020-02-08T02:47:30.736550: step 2663, loss 0.00768473, acc 1
2020-02-08T02:47:30.851063: step 2664, loss 0.0123369, acc 1
2020-02-08T02:47:30.969312: step 2665, loss 0.0333847, acc 0.96875
2020-02-08T02:47:31.089558: step 2666, loss 0.0124623, acc 1
2020-02-08T02:47:31.204040: step 2667, loss 0.0198353, acc 0.984375
2020-02-08T02:47:31.320434: step 2668, loss 0.0363214, acc 0.96875
2020-02-08T02:47:31.437552: step 2669, loss 0.0414327, acc 0.984375
2020-02-08T02:47:31.552339: step 2670, loss 0.0244978, acc 0.984375
2020-02-08T02:47:31.665746: step 2671, loss 0.0254094, acc 1
2020-02-08T02:47:31.781315: step 2672, loss 0.0197764, acc 0.984375
2020-02-08T02:47:31.896755: step 2673, loss 0.0586119, acc 0.96875
2020-02-08T02:47:32.010323: step 2674, loss 0.0331928, acc 1
2020-02-08T02:47:32.128797: step 2675, loss 0.00811324, acc 1
2020-02-08T02:47:32.244995: step 2676, loss 0.0100585, acc 1
2020-02-08T02:47:32.361808: step 2677, loss 0.023118, acc 0.984375
2020-02-08T02:47:32.480891: step 2678, loss 0.00574562, acc 1
2020-02-08T02:47:32.597091: step 2679, loss 0.0706603, acc 0.96875
2020-02-08T02:47:32.714280: step 2680, loss 0.0216561, acc 0.984375
2020-02-08T02:47:32.831113: step 2681, loss 0.0524934, acc 0.984375
2020-02-08T02:47:32.947717: step 2682, loss 0.115579, acc 0.953125
2020-02-08T02:47:33.063170: step 2683, loss 0.00978843, acc 1
2020-02-08T02:47:33.182118: step 2684, loss 0.0110815, acc 1
2020-02-08T02:47:33.301854: step 2685, loss 0.056656, acc 0.96875
2020-02-08T02:47:33.417799: step 2686, loss 0.0189312, acc 1
2020-02-08T02:47:33.536667: step 2687, loss 0.00599075, acc 1
2020-02-08T02:47:33.652797: step 2688, loss 0.00401617, acc 1
2020-02-08T02:47:33.769843: step 2689, loss 0.0468133, acc 0.984375
2020-02-08T02:47:33.889453: step 2690, loss 0.0124605, acc 1
2020-02-08T02:47:34.002390: step 2691, loss 0.074652, acc 0.953125
2020-02-08T02:47:34.119388: step 2692, loss 0.0320954, acc 1
2020-02-08T02:47:34.236523: step 2693, loss 0.00533024, acc 1
2020-02-08T02:47:34.352779: step 2694, loss 0.0555003, acc 0.96875
2020-02-08T02:47:34.467239: step 2695, loss 0.0465222, acc 0.96875
2020-02-08T02:47:34.584373: step 2696, loss 0.019896, acc 1
2020-02-08T02:47:34.699339: step 2697, loss 0.0280612, acc 1
2020-02-08T02:47:34.815334: step 2698, loss 0.01846, acc 1
2020-02-08T02:47:34.933393: step 2699, loss 0.0296652, acc 0.984375
2020-02-08T02:47:35.047398: step 2700, loss 0.0119194, acc 1

Evaluation:
2020-02-08T02:47:35.233487: step 2700, loss 0.913729, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2700

2020-02-08T02:47:36.736472: step 2701, loss 0.0106742, acc 1
2020-02-08T02:47:36.851963: step 2702, loss 0.0148328, acc 1
2020-02-08T02:47:36.968012: step 2703, loss 0.00596171, acc 1
2020-02-08T02:47:37.082462: step 2704, loss 0.0290525, acc 0.984375
2020-02-08T02:47:37.197814: step 2705, loss 0.00558527, acc 1
2020-02-08T02:47:37.312811: step 2706, loss 0.0114916, acc 1
2020-02-08T02:47:37.431514: step 2707, loss 0.014497, acc 1
2020-02-08T02:47:37.546146: step 2708, loss 0.00440644, acc 1
2020-02-08T02:47:37.662102: step 2709, loss 0.0140759, acc 1
2020-02-08T02:47:37.779464: step 2710, loss 0.0286626, acc 0.984375
2020-02-08T02:47:37.894544: step 2711, loss 0.00547221, acc 1
2020-02-08T02:47:38.011408: step 2712, loss 0.00595391, acc 1
2020-02-08T02:47:38.128677: step 2713, loss 0.00972819, acc 1
2020-02-08T02:47:38.247542: step 2714, loss 0.00857426, acc 1
2020-02-08T02:47:38.362978: step 2715, loss 0.0332364, acc 1
2020-02-08T02:47:38.480938: step 2716, loss 0.0158401, acc 1
2020-02-08T02:47:38.598304: step 2717, loss 0.0655167, acc 0.984375
2020-02-08T02:47:38.713739: step 2718, loss 0.0188092, acc 1
2020-02-08T02:47:38.831898: step 2719, loss 0.0128265, acc 1
2020-02-08T02:47:38.949061: step 2720, loss 0.012874, acc 1
2020-02-08T02:47:39.065014: step 2721, loss 0.00436952, acc 1
2020-02-08T02:47:39.181987: step 2722, loss 0.0223934, acc 1
2020-02-08T02:47:39.297261: step 2723, loss 0.0160087, acc 0.984375
2020-02-08T02:47:39.412588: step 2724, loss 0.016947, acc 1
2020-02-08T02:47:39.531950: step 2725, loss 0.0209855, acc 0.984375
2020-02-08T02:47:39.648078: step 2726, loss 0.032936, acc 0.984375
2020-02-08T02:47:39.768188: step 2727, loss 0.00736083, acc 1
2020-02-08T02:47:39.887961: step 2728, loss 0.00587656, acc 1
2020-02-08T02:47:40.003620: step 2729, loss 0.0448221, acc 0.984375
2020-02-08T02:47:40.119710: step 2730, loss 0.0102939, acc 1
2020-02-08T02:47:40.235722: step 2731, loss 0.0229379, acc 0.984375
2020-02-08T02:47:40.350964: step 2732, loss 0.0159082, acc 1
2020-02-08T02:47:40.468145: step 2733, loss 0.0109302, acc 1
2020-02-08T02:47:40.586899: step 2734, loss 0.0105638, acc 1
2020-02-08T02:47:40.701003: step 2735, loss 0.0181601, acc 1
2020-02-08T02:47:40.816913: step 2736, loss 0.0379442, acc 0.984375
2020-02-08T02:47:40.932750: step 2737, loss 0.0192455, acc 0.984375
2020-02-08T02:47:41.048507: step 2738, loss 0.0299879, acc 0.984375
2020-02-08T02:47:41.164442: step 2739, loss 0.0611009, acc 0.96875
2020-02-08T02:47:41.281038: step 2740, loss 0.00529986, acc 1
2020-02-08T02:47:41.399131: step 2741, loss 0.00516485, acc 1
2020-02-08T02:47:41.516141: step 2742, loss 0.0282104, acc 1
2020-02-08T02:47:41.632919: step 2743, loss 0.0243804, acc 0.984375
2020-02-08T02:47:41.749010: step 2744, loss 0.0346672, acc 0.984375
2020-02-08T02:47:41.864729: step 2745, loss 0.0306526, acc 1
2020-02-08T02:47:41.982231: step 2746, loss 0.0205177, acc 1
2020-02-08T02:47:42.099308: step 2747, loss 0.00501192, acc 1
2020-02-08T02:47:42.213795: step 2748, loss 0.0297233, acc 1
2020-02-08T02:47:42.329853: step 2749, loss 0.00591254, acc 1
2020-02-08T02:47:42.445650: step 2750, loss 0.0155355, acc 1
2020-02-08T02:47:42.560598: step 2751, loss 0.0118334, acc 1
2020-02-08T02:47:42.679121: step 2752, loss 0.0253845, acc 0.984375
2020-02-08T02:47:42.798042: step 2753, loss 0.00807946, acc 1
2020-02-08T02:47:42.911630: step 2754, loss 0.0182929, acc 1
2020-02-08T02:47:43.026520: step 2755, loss 0.0111179, acc 1
2020-02-08T02:47:43.143307: step 2756, loss 0.0362718, acc 0.984375
2020-02-08T02:47:43.259312: step 2757, loss 0.0322597, acc 0.984375
2020-02-08T02:47:43.378150: step 2758, loss 0.00907164, acc 1
2020-02-08T02:47:43.492491: step 2759, loss 0.0265676, acc 0.984375
2020-02-08T02:47:43.610420: step 2760, loss 0.0207607, acc 0.984375
2020-02-08T02:47:43.731192: step 2761, loss 0.0122822, acc 1
2020-02-08T02:47:43.846743: step 2762, loss 0.0150791, acc 1
2020-02-08T02:47:43.962438: step 2763, loss 0.0360625, acc 1
2020-02-08T02:47:44.078652: step 2764, loss 0.0145504, acc 1
2020-02-08T02:47:44.194999: step 2765, loss 0.047619, acc 0.984375
2020-02-08T02:47:44.312421: step 2766, loss 0.100538, acc 0.984375
2020-02-08T02:47:44.430334: step 2767, loss 0.0120826, acc 1
2020-02-08T02:47:44.545970: step 2768, loss 0.0101858, acc 1
2020-02-08T02:47:44.660761: step 2769, loss 0.0256325, acc 0.984375
2020-02-08T02:47:44.775412: step 2770, loss 0.00897997, acc 1
2020-02-08T02:47:44.892650: step 2771, loss 0.0909, acc 0.96875
2020-02-08T02:47:45.006486: step 2772, loss 0.0120042, acc 1
2020-02-08T02:47:45.122794: step 2773, loss 0.0178428, acc 1
2020-02-08T02:47:45.237405: step 2774, loss 0.0265709, acc 0.984375
2020-02-08T02:47:45.353421: step 2775, loss 0.0200995, acc 1
2020-02-08T02:47:45.471527: step 2776, loss 0.0068869, acc 1
2020-02-08T02:47:45.592081: step 2777, loss 0.0121458, acc 1
2020-02-08T02:47:45.706446: step 2778, loss 0.0206873, acc 1
2020-02-08T02:47:45.824866: step 2779, loss 0.0222687, acc 1
2020-02-08T02:47:45.944828: step 2780, loss 0.0128332, acc 1
2020-02-08T02:47:46.059348: step 2781, loss 0.0118672, acc 1
2020-02-08T02:47:46.172505: step 2782, loss 0.0076037, acc 1
2020-02-08T02:47:46.292024: step 2783, loss 0.0102489, acc 1
2020-02-08T02:47:46.409267: step 2784, loss 0.00946469, acc 1
2020-02-08T02:47:46.524647: step 2785, loss 0.00795449, acc 1
2020-02-08T02:47:46.639622: step 2786, loss 0.00906865, acc 1
2020-02-08T02:47:46.756364: step 2787, loss 0.017435, acc 0.984375
2020-02-08T02:47:46.873526: step 2788, loss 0.0162011, acc 1
2020-02-08T02:47:46.990549: step 2789, loss 0.0175598, acc 1
2020-02-08T02:47:47.104493: step 2790, loss 0.0522831, acc 0.984375
2020-02-08T02:47:47.220501: step 2791, loss 0.0190794, acc 0.984375
2020-02-08T02:47:47.338401: step 2792, loss 0.0334594, acc 0.984375
2020-02-08T02:47:47.454889: step 2793, loss 0.029909, acc 0.984375
2020-02-08T02:47:47.569582: step 2794, loss 0.00685726, acc 1
2020-02-08T02:47:47.687685: step 2795, loss 0.0268491, acc 0.984375
2020-02-08T02:47:47.804257: step 2796, loss 0.0250054, acc 0.984375
2020-02-08T02:47:47.922291: step 2797, loss 0.00752132, acc 1
2020-02-08T02:47:48.038514: step 2798, loss 0.0404204, acc 0.984375
2020-02-08T02:47:48.154400: step 2799, loss 0.0934913, acc 0.953125
2020-02-08T02:47:48.272642: step 2800, loss 0.0307812, acc 1

Evaluation:
2020-02-08T02:47:48.465692: step 2800, loss 0.928251, acc 0.757974

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2800

2020-02-08T02:47:49.947780: step 2801, loss 0.0330999, acc 0.984375
2020-02-08T02:47:50.064570: step 2802, loss 0.0107995, acc 1
2020-02-08T02:47:50.178777: step 2803, loss 0.00793987, acc 1
2020-02-08T02:47:50.293408: step 2804, loss 0.00652406, acc 1
2020-02-08T02:47:50.408067: step 2805, loss 0.0384219, acc 0.984375
2020-02-08T02:47:50.523781: step 2806, loss 0.0184587, acc 1
2020-02-08T02:47:50.638629: step 2807, loss 0.0153183, acc 1
2020-02-08T02:47:50.753931: step 2808, loss 0.0230796, acc 1
2020-02-08T02:47:50.870396: step 2809, loss 0.0122891, acc 1
2020-02-08T02:47:50.985054: step 2810, loss 0.0312746, acc 0.984375
2020-02-08T02:47:51.102233: step 2811, loss 0.0194267, acc 0.984375
2020-02-08T02:47:51.220205: step 2812, loss 0.0235067, acc 0.984375
2020-02-08T02:47:51.334939: step 2813, loss 0.0387329, acc 0.984375
2020-02-08T02:47:51.598300: step 2814, loss 0.00946392, acc 1
2020-02-08T02:47:51.723885: step 2815, loss 0.0231918, acc 1
2020-02-08T02:47:51.845098: step 2816, loss 0.0140122, acc 1
2020-02-08T02:47:51.961013: step 2817, loss 0.0610483, acc 0.984375
2020-02-08T02:47:52.082220: step 2818, loss 0.0193424, acc 1
2020-02-08T02:47:52.199013: step 2819, loss 0.0153545, acc 1
2020-02-08T02:47:52.315991: step 2820, loss 0.00578246, acc 1
2020-02-08T02:47:52.433166: step 2821, loss 0.0239269, acc 1
2020-02-08T02:47:52.550484: step 2822, loss 0.00836633, acc 1
2020-02-08T02:47:52.666842: step 2823, loss 0.0120014, acc 1
2020-02-08T02:47:52.781775: step 2824, loss 0.0149323, acc 1
2020-02-08T02:47:52.897163: step 2825, loss 0.00775062, acc 1
2020-02-08T02:47:53.012666: step 2826, loss 0.0249715, acc 0.984375
2020-02-08T02:47:53.130086: step 2827, loss 0.0310895, acc 0.984375
2020-02-08T02:47:53.247705: step 2828, loss 0.0174947, acc 1
2020-02-08T02:47:53.363285: step 2829, loss 0.0232474, acc 1
2020-02-08T02:47:53.480568: step 2830, loss 0.0201099, acc 1
2020-02-08T02:47:53.597973: step 2831, loss 0.0259073, acc 1
2020-02-08T02:47:53.714133: step 2832, loss 0.0117487, acc 1
2020-02-08T02:47:53.833414: step 2833, loss 0.00805925, acc 1
2020-02-08T02:47:53.949499: step 2834, loss 0.0151577, acc 1
2020-02-08T02:47:54.067579: step 2835, loss 0.00529362, acc 1
2020-02-08T02:47:54.184739: step 2836, loss 0.0042472, acc 1
2020-02-08T02:47:54.303421: step 2837, loss 0.0324482, acc 0.984375
2020-02-08T02:47:54.423768: step 2838, loss 0.0118898, acc 1
2020-02-08T02:47:54.540910: step 2839, loss 0.0161033, acc 1
2020-02-08T02:47:54.655742: step 2840, loss 0.039018, acc 0.984375
2020-02-08T02:47:54.771633: step 2841, loss 0.0245927, acc 1
2020-02-08T02:47:54.888955: step 2842, loss 0.0428626, acc 0.984375
2020-02-08T02:47:55.006042: step 2843, loss 0.00367193, acc 1
2020-02-08T02:47:55.122014: step 2844, loss 0.0723753, acc 0.984375
2020-02-08T02:47:55.238250: step 2845, loss 0.0302863, acc 0.984375
2020-02-08T02:47:55.354940: step 2846, loss 0.0109864, acc 1
2020-02-08T02:47:55.471504: step 2847, loss 0.0153479, acc 1
2020-02-08T02:47:55.590150: step 2848, loss 0.0216094, acc 0.984375
2020-02-08T02:47:55.708684: step 2849, loss 0.0236337, acc 1
2020-02-08T02:47:55.823093: step 2850, loss 0.00910475, acc 1
2020-02-08T02:47:55.942499: step 2851, loss 0.0610335, acc 0.96875
2020-02-08T02:47:56.060605: step 2852, loss 0.0145828, acc 1
2020-02-08T02:47:56.176269: step 2853, loss 0.00812161, acc 1
2020-02-08T02:47:56.293186: step 2854, loss 0.00476355, acc 1
2020-02-08T02:47:56.409840: step 2855, loss 0.0398762, acc 0.984375
2020-02-08T02:47:56.527118: step 2856, loss 0.00510719, acc 1
2020-02-08T02:47:56.642914: step 2857, loss 0.0272881, acc 0.984375
2020-02-08T02:47:56.759855: step 2858, loss 0.111592, acc 0.96875
2020-02-08T02:47:56.875616: step 2859, loss 0.0217909, acc 0.984375
2020-02-08T02:47:56.994518: step 2860, loss 0.0091765, acc 1
2020-02-08T02:47:57.115126: step 2861, loss 0.0128611, acc 1
2020-02-08T02:47:57.233191: step 2862, loss 0.0371458, acc 0.984375
2020-02-08T02:47:57.350688: step 2863, loss 0.0110916, acc 1
2020-02-08T02:47:57.467452: step 2864, loss 0.0202418, acc 1
2020-02-08T02:47:57.584745: step 2865, loss 0.0346278, acc 0.984375
2020-02-08T02:47:57.699311: step 2866, loss 0.0685161, acc 0.984375
2020-02-08T02:47:57.818318: step 2867, loss 0.0168134, acc 1
2020-02-08T02:47:57.936586: step 2868, loss 0.0104507, acc 1
2020-02-08T02:47:58.054262: step 2869, loss 0.00618894, acc 1
2020-02-08T02:47:58.172882: step 2870, loss 0.00399562, acc 1
2020-02-08T02:47:58.289576: step 2871, loss 0.0190389, acc 0.984375
2020-02-08T02:47:58.404796: step 2872, loss 0.0196148, acc 1
2020-02-08T02:47:58.521998: step 2873, loss 0.00861831, acc 1
2020-02-08T02:47:58.639272: step 2874, loss 0.00854413, acc 1
2020-02-08T02:47:58.753942: step 2875, loss 0.00337059, acc 1
2020-02-08T02:47:58.868433: step 2876, loss 0.00758264, acc 1
2020-02-08T02:47:58.983762: step 2877, loss 0.006007, acc 1
2020-02-08T02:47:59.099541: step 2878, loss 0.00909916, acc 1
2020-02-08T02:47:59.216437: step 2879, loss 0.0420096, acc 0.984375
2020-02-08T02:47:59.335529: step 2880, loss 0.025196, acc 0.984375
2020-02-08T02:47:59.451261: step 2881, loss 0.0285843, acc 0.984375
2020-02-08T02:47:59.566437: step 2882, loss 0.0104115, acc 1
2020-02-08T02:47:59.686495: step 2883, loss 0.00588284, acc 1
2020-02-08T02:47:59.800109: step 2884, loss 0.00759559, acc 1
2020-02-08T02:47:59.918809: step 2885, loss 0.00666905, acc 1
2020-02-08T02:48:00.035500: step 2886, loss 0.0375026, acc 0.984375
2020-02-08T02:48:00.151721: step 2887, loss 0.0369276, acc 0.984375
2020-02-08T02:48:00.269661: step 2888, loss 0.0186679, acc 1
2020-02-08T02:48:00.388484: step 2889, loss 0.0436731, acc 0.96875
2020-02-08T02:48:00.504478: step 2890, loss 0.0182963, acc 1
2020-02-08T02:48:00.623007: step 2891, loss 0.00410396, acc 1
2020-02-08T02:48:00.740888: step 2892, loss 0.00933064, acc 1
2020-02-08T02:48:00.856484: step 2893, loss 0.0353104, acc 0.984375
2020-02-08T02:48:00.973695: step 2894, loss 0.0112806, acc 1
2020-02-08T02:48:01.092035: step 2895, loss 0.0228776, acc 0.984375
2020-02-08T02:48:01.207338: step 2896, loss 0.0260266, acc 0.984375
2020-02-08T02:48:01.324481: step 2897, loss 0.0406191, acc 0.984375
2020-02-08T02:48:01.440804: step 2898, loss 0.0188204, acc 1
2020-02-08T02:48:01.554408: step 2899, loss 0.0187788, acc 0.984375
2020-02-08T02:48:01.670191: step 2900, loss 0.00823626, acc 1

Evaluation:
2020-02-08T02:48:01.858904: step 2900, loss 0.963957, acc 0.745779

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-2900

2020-02-08T02:48:03.411166: step 2901, loss 0.00796398, acc 1
2020-02-08T02:48:03.529723: step 2902, loss 0.0109147, acc 1
2020-02-08T02:48:03.646188: step 2903, loss 0.00654455, acc 1
2020-02-08T02:48:03.763780: step 2904, loss 0.0445874, acc 0.96875
2020-02-08T02:48:03.882044: step 2905, loss 0.00638232, acc 1
2020-02-08T02:48:03.997712: step 2906, loss 0.00926763, acc 1
2020-02-08T02:48:04.113765: step 2907, loss 0.0436043, acc 0.984375
2020-02-08T02:48:04.232376: step 2908, loss 0.0479179, acc 0.984375
2020-02-08T02:48:04.350402: step 2909, loss 0.0226852, acc 1
2020-02-08T02:48:04.467875: step 2910, loss 0.0313159, acc 0.96875
2020-02-08T02:48:04.587719: step 2911, loss 0.0258614, acc 1
2020-02-08T02:48:04.704500: step 2912, loss 0.00897329, acc 1
2020-02-08T02:48:04.821923: step 2913, loss 0.00849702, acc 1
2020-02-08T02:48:04.938285: step 2914, loss 0.0218024, acc 1
2020-02-08T02:48:05.056084: step 2915, loss 0.0390451, acc 0.96875
2020-02-08T02:48:05.174685: step 2916, loss 0.0233508, acc 0.984375
2020-02-08T02:48:05.290602: step 2917, loss 0.00184283, acc 1
2020-02-08T02:48:05.405897: step 2918, loss 0.00413621, acc 1
2020-02-08T02:48:05.521185: step 2919, loss 0.00966873, acc 1
2020-02-08T02:48:05.639470: step 2920, loss 0.0106828, acc 1
2020-02-08T02:48:05.753425: step 2921, loss 0.00698099, acc 1
2020-02-08T02:48:05.873845: step 2922, loss 0.0302598, acc 1
2020-02-08T02:48:05.993126: step 2923, loss 0.0117551, acc 1
2020-02-08T02:48:06.110174: step 2924, loss 0.0130484, acc 1
2020-02-08T02:48:06.227733: step 2925, loss 0.0117037, acc 1
2020-02-08T02:48:06.345624: step 2926, loss 0.01192, acc 1
2020-02-08T02:48:06.461231: step 2927, loss 0.028121, acc 0.984375
2020-02-08T02:48:06.576137: step 2928, loss 0.0300059, acc 0.984375
2020-02-08T02:48:06.692927: step 2929, loss 0.00458867, acc 1
2020-02-08T02:48:06.808080: step 2930, loss 0.0345319, acc 0.96875
2020-02-08T02:48:06.924067: step 2931, loss 0.0212895, acc 1
2020-02-08T02:48:07.041700: step 2932, loss 0.00501978, acc 1
2020-02-08T02:48:07.155667: step 2933, loss 0.0175667, acc 1
2020-02-08T02:48:07.273197: step 2934, loss 0.0083611, acc 1
2020-02-08T02:48:07.389852: step 2935, loss 0.016726, acc 1
2020-02-08T02:48:07.506545: step 2936, loss 0.0228686, acc 1
2020-02-08T02:48:07.622336: step 2937, loss 0.0413678, acc 0.984375
2020-02-08T02:48:07.739066: step 2938, loss 0.0189621, acc 1
2020-02-08T02:48:07.854992: step 2939, loss 0.00487007, acc 1
2020-02-08T02:48:07.971178: step 2940, loss 0.0164155, acc 1
2020-02-08T02:48:08.088752: step 2941, loss 0.0353552, acc 0.984375
2020-02-08T02:48:08.206494: step 2942, loss 0.00996417, acc 1
2020-02-08T02:48:08.327649: step 2943, loss 0.01418, acc 1
2020-02-08T02:48:08.443443: step 2944, loss 0.0347371, acc 0.984375
2020-02-08T02:48:08.560270: step 2945, loss 0.0187693, acc 1
2020-02-08T02:48:08.676036: step 2946, loss 0.0101458, acc 1
2020-02-08T02:48:08.796161: step 2947, loss 0.104225, acc 0.96875
2020-02-08T02:48:08.913430: step 2948, loss 0.0259067, acc 0.984375
2020-02-08T02:48:09.033545: step 2949, loss 0.0331903, acc 0.984375
2020-02-08T02:48:09.152764: step 2950, loss 0.00713318, acc 1
2020-02-08T02:48:09.268415: step 2951, loss 0.0079042, acc 1
2020-02-08T02:48:09.385848: step 2952, loss 0.0100553, acc 1
2020-02-08T02:48:09.502961: step 2953, loss 0.028214, acc 0.984375
2020-02-08T02:48:09.619919: step 2954, loss 0.0318417, acc 0.984375
2020-02-08T02:48:09.737028: step 2955, loss 0.0200386, acc 1
2020-02-08T02:48:09.854424: step 2956, loss 0.00578759, acc 1
2020-02-08T02:48:09.971833: step 2957, loss 0.0230539, acc 0.984375
2020-02-08T02:48:10.090818: step 2958, loss 0.018662, acc 0.984375
2020-02-08T02:48:10.211272: step 2959, loss 0.014739, acc 1
2020-02-08T02:48:10.329729: step 2960, loss 0.0498775, acc 0.96875
2020-02-08T02:48:10.449261: step 2961, loss 0.0170764, acc 0.984375
2020-02-08T02:48:10.565594: step 2962, loss 0.00690496, acc 1
2020-02-08T02:48:10.680820: step 2963, loss 0.0267925, acc 1
2020-02-08T02:48:10.797453: step 2964, loss 0.00446257, acc 1
2020-02-08T02:48:10.918572: step 2965, loss 0.0116567, acc 1
2020-02-08T02:48:11.036780: step 2966, loss 0.013938, acc 1
2020-02-08T02:48:11.155508: step 2967, loss 0.00616011, acc 1
2020-02-08T02:48:11.273460: step 2968, loss 0.00534152, acc 1
2020-02-08T02:48:11.390487: step 2969, loss 0.032329, acc 0.984375
2020-02-08T02:48:11.508726: step 2970, loss 0.0586026, acc 0.96875
2020-02-08T02:48:11.626177: step 2971, loss 0.0231327, acc 1
2020-02-08T02:48:11.743106: step 2972, loss 0.00727748, acc 1
2020-02-08T02:48:11.858699: step 2973, loss 0.0152778, acc 1
2020-02-08T02:48:11.976974: step 2974, loss 0.0181503, acc 1
2020-02-08T02:48:12.095448: step 2975, loss 0.0361981, acc 0.984375
2020-02-08T02:48:12.213187: step 2976, loss 0.0127133, acc 1
2020-02-08T02:48:12.328265: step 2977, loss 0.00356334, acc 1
2020-02-08T02:48:12.443783: step 2978, loss 0.0101122, acc 1
2020-02-08T02:48:12.559072: step 2979, loss 0.00331988, acc 1
2020-02-08T02:48:12.675850: step 2980, loss 0.0220485, acc 0.984375
2020-02-08T02:48:12.793793: step 2981, loss 0.00896361, acc 1
2020-02-08T02:48:12.910535: step 2982, loss 0.0228259, acc 1
2020-02-08T02:48:13.026248: step 2983, loss 0.0175772, acc 0.984375
2020-02-08T02:48:13.139669: step 2984, loss 0.0300399, acc 0.984375
2020-02-08T02:48:13.253711: step 2985, loss 0.0112065, acc 1
2020-02-08T02:48:13.369371: step 2986, loss 0.0191112, acc 0.984375
2020-02-08T02:48:13.487932: step 2987, loss 0.0349097, acc 0.984375
2020-02-08T02:48:13.605644: step 2988, loss 0.0250738, acc 0.984375
2020-02-08T02:48:13.725918: step 2989, loss 0.00855583, acc 1
2020-02-08T02:48:13.844434: step 2990, loss 0.0207648, acc 0.984375
2020-02-08T02:48:13.963539: step 2991, loss 0.0250457, acc 0.984375
2020-02-08T02:48:14.081508: step 2992, loss 0.00739698, acc 1
2020-02-08T02:48:14.198845: step 2993, loss 0.0148875, acc 1
2020-02-08T02:48:14.318515: step 2994, loss 0.00245544, acc 1
2020-02-08T02:48:14.436010: step 2995, loss 0.00315544, acc 1
2020-02-08T02:48:14.550508: step 2996, loss 0.0030213, acc 1
2020-02-08T02:48:14.666626: step 2997, loss 0.0193538, acc 0.984375
2020-02-08T02:48:14.785879: step 2998, loss 0.0159881, acc 1
2020-02-08T02:48:14.902728: step 2999, loss 0.00666046, acc 1
2020-02-08T02:48:15.016584: step 3000, loss 0.00791328, acc 1

Evaluation:
2020-02-08T02:48:15.207111: step 3000, loss 1.01178, acc 0.737336

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100882/checkpoints/model-3000

