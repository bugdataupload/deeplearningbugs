WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 15:34:59.107802 4504624576 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 15:34:59.108017 4504624576 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 15:34:59.108122 4504624576 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0216 15:34:59.640707 4504624576 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0216 15:34:59.640944 4504624576 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-16 15:34:59.641152: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-16 15:34:59.656220: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffe08090170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-16 15:34:59.656288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0216 15:34:59.657139 4504624576 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0216 15:34:59.661845 4504624576 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0216 15:34:59.680289 4504624576 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0216 15:34:59.690543 4504624576 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0216 15:34:59.714327 4504624576 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0216 15:34:59.726711 4504624576 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0216 15:34:59.726971 4504624576 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0216 15:34:59.740002 4504624576 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0216 15:34:59.742384 4504624576 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0216 15:34:59.768266 4504624576 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0216 15:35:00.012987 4504624576 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0216 15:35:00.013212 4504624576 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0216 15:35:00.021106 4504624576 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0216 15:35:00.043061 4504624576 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0216 15:35:00.044144 4504624576 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0216 15:35:00.059121 4504624576 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0216 15:35:00.060352 4504624576 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0216 15:35:00.081254 4504624576 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0216 15:35:00.082864 4504624576 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0216 15:35:00.097898 4504624576 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0216 15:35:00.098994 4504624576 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0216 15:35:00.113041 4504624576 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0216 15:35:00.114087 4504624576 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0216 15:35:00.134104 4504624576 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0216 15:35:00.135173 4504624576 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0216 15:35:00.149356 4504624576 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0216 15:35:00.150552 4504624576 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0216 15:35:00.164937 4504624576 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0216 15:35:00.166018 4504624576 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0216 15:35:00.187061 4504624576 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0216 15:35:00.188138 4504624576 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0216 15:35:00.191534 4504624576 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0216 15:35:00.507374 4504624576 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0216 15:35:00.507642 4504624576 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0216 15:35:01.091063 4504624576 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0216 15:35:01.683167 4504624576 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0216 15:36:33.306926 4504624576 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500

2020-02-16T15:35:01.682752: step 1, loss 2.00667, acc 0.578125
2020-02-16T15:35:01.823886: step 2, loss 1.93424, acc 0.5625
2020-02-16T15:35:01.949833: step 3, loss 1.92332, acc 0.453125
2020-02-16T15:35:02.074961: step 4, loss 2.38696, acc 0.4375
2020-02-16T15:35:02.195355: step 5, loss 2.45908, acc 0.4375
2020-02-16T15:35:02.316022: step 6, loss 1.76084, acc 0.546875
2020-02-16T15:35:02.440145: step 7, loss 2.24021, acc 0.484375
2020-02-16T15:35:02.560787: step 8, loss 1.67672, acc 0.53125
2020-02-16T15:35:02.686756: step 9, loss 1.99326, acc 0.46875
2020-02-16T15:35:02.809289: step 10, loss 1.69169, acc 0.484375
2020-02-16T15:35:02.932575: step 11, loss 1.7922, acc 0.515625
2020-02-16T15:35:03.052178: step 12, loss 1.51793, acc 0.546875
2020-02-16T15:35:03.174472: step 13, loss 1.87847, acc 0.5625
2020-02-16T15:35:03.290155: step 14, loss 2.14374, acc 0.390625
2020-02-16T15:35:03.409007: step 15, loss 1.7895, acc 0.515625
2020-02-16T15:35:03.528554: step 16, loss 2.05698, acc 0.421875
2020-02-16T15:35:03.649789: step 17, loss 1.61737, acc 0.5
2020-02-16T15:35:03.774772: step 18, loss 1.86623, acc 0.546875
2020-02-16T15:35:03.898862: step 19, loss 1.99037, acc 0.53125
2020-02-16T15:35:04.028682: step 20, loss 2.36368, acc 0.46875
2020-02-16T15:35:04.158531: step 21, loss 1.7889, acc 0.4375
2020-02-16T15:35:04.282691: step 22, loss 1.76787, acc 0.53125
2020-02-16T15:35:04.406483: step 23, loss 2.12959, acc 0.453125
2020-02-16T15:35:04.532432: step 24, loss 1.39117, acc 0.625
2020-02-16T15:35:04.661334: step 25, loss 1.60667, acc 0.4375
2020-02-16T15:35:04.789674: step 26, loss 1.45356, acc 0.546875
2020-02-16T15:35:04.925169: step 27, loss 1.90016, acc 0.53125
2020-02-16T15:35:05.050591: step 28, loss 1.29915, acc 0.6875
2020-02-16T15:35:05.195930: step 29, loss 1.92762, acc 0.5
2020-02-16T15:35:05.317776: step 30, loss 2.01678, acc 0.53125
2020-02-16T15:35:05.449710: step 31, loss 1.74794, acc 0.53125
2020-02-16T15:35:05.581427: step 32, loss 1.6485, acc 0.5
2020-02-16T15:35:05.705106: step 33, loss 1.45353, acc 0.53125
2020-02-16T15:35:05.834800: step 34, loss 1.77923, acc 0.5625
2020-02-16T15:35:05.957343: step 35, loss 1.3291, acc 0.609375
2020-02-16T15:35:06.082090: step 36, loss 1.89415, acc 0.484375
2020-02-16T15:35:06.210021: step 37, loss 1.97229, acc 0.484375
2020-02-16T15:35:06.333202: step 38, loss 1.71574, acc 0.53125
2020-02-16T15:35:06.457582: step 39, loss 2.037, acc 0.484375
2020-02-16T15:35:06.574896: step 40, loss 1.58478, acc 0.546875
2020-02-16T15:35:06.697190: step 41, loss 1.61215, acc 0.53125
2020-02-16T15:35:06.817074: step 42, loss 1.91384, acc 0.46875
2020-02-16T15:35:06.940459: step 43, loss 1.28067, acc 0.65625
2020-02-16T15:35:07.058446: step 44, loss 1.50567, acc 0.515625
2020-02-16T15:35:07.179971: step 45, loss 1.70245, acc 0.59375
2020-02-16T15:35:07.327758: step 46, loss 1.95136, acc 0.5
2020-02-16T15:35:07.452670: step 47, loss 1.22007, acc 0.578125
2020-02-16T15:35:07.568759: step 48, loss 1.37113, acc 0.515625
2020-02-16T15:35:07.699811: step 49, loss 1.76872, acc 0.453125
2020-02-16T15:35:07.825856: step 50, loss 1.83114, acc 0.5
2020-02-16T15:35:07.955542: step 51, loss 1.93203, acc 0.46875
2020-02-16T15:35:08.164488: step 52, loss 1.5295, acc 0.53125
2020-02-16T15:35:08.295242: step 53, loss 1.87433, acc 0.46875
2020-02-16T15:35:08.426022: step 54, loss 1.68071, acc 0.46875
2020-02-16T15:35:08.574810: step 55, loss 1.76882, acc 0.484375
2020-02-16T15:35:08.731875: step 56, loss 1.3928, acc 0.578125
2020-02-16T15:35:08.856047: step 57, loss 1.22793, acc 0.609375
2020-02-16T15:35:08.979658: step 58, loss 1.46256, acc 0.546875
2020-02-16T15:35:09.099900: step 59, loss 1.18999, acc 0.6875
2020-02-16T15:35:09.217909: step 60, loss 1.74152, acc 0.484375
2020-02-16T15:35:09.337726: step 61, loss 1.30456, acc 0.53125
2020-02-16T15:35:09.458721: step 62, loss 1.64204, acc 0.4375
2020-02-16T15:35:09.579375: step 63, loss 1.48581, acc 0.59375
2020-02-16T15:35:09.703638: step 64, loss 1.25777, acc 0.578125
2020-02-16T15:35:09.824729: step 65, loss 1.78158, acc 0.4375
2020-02-16T15:35:09.949498: step 66, loss 1.32151, acc 0.53125
2020-02-16T15:35:10.069634: step 67, loss 1.14585, acc 0.59375
2020-02-16T15:35:10.189989: step 68, loss 1.31212, acc 0.578125
2020-02-16T15:35:10.313690: step 69, loss 1.73239, acc 0.46875
2020-02-16T15:35:10.434269: step 70, loss 1.48141, acc 0.59375
2020-02-16T15:35:10.556514: step 71, loss 1.79752, acc 0.390625
2020-02-16T15:35:10.679065: step 72, loss 1.08175, acc 0.53125
2020-02-16T15:35:10.802036: step 73, loss 1.09788, acc 0.59375
2020-02-16T15:35:10.920015: step 74, loss 1.09321, acc 0.640625
2020-02-16T15:35:11.042909: step 75, loss 1.37046, acc 0.546875
2020-02-16T15:35:11.161244: step 76, loss 1.45087, acc 0.484375
2020-02-16T15:35:11.278924: step 77, loss 1.39723, acc 0.578125
2020-02-16T15:35:11.400985: step 78, loss 1.58971, acc 0.484375
2020-02-16T15:35:11.524762: step 79, loss 1.44214, acc 0.5
2020-02-16T15:35:11.647105: step 80, loss 1.25036, acc 0.546875
2020-02-16T15:35:11.774092: step 81, loss 1.96226, acc 0.5
2020-02-16T15:35:11.894088: step 82, loss 1.3785, acc 0.515625
2020-02-16T15:35:12.019307: step 83, loss 1.73687, acc 0.515625
2020-02-16T15:35:12.151144: step 84, loss 1.56714, acc 0.53125
2020-02-16T15:35:12.283473: step 85, loss 1.39803, acc 0.5625
2020-02-16T15:35:12.403982: step 86, loss 1.59458, acc 0.46875
2020-02-16T15:35:12.527727: step 87, loss 1.14715, acc 0.578125
2020-02-16T15:35:12.650067: step 88, loss 1.12303, acc 0.53125
2020-02-16T15:35:12.776935: step 89, loss 1.21554, acc 0.578125
2020-02-16T15:35:12.898692: step 90, loss 1.87567, acc 0.484375
2020-02-16T15:35:13.019739: step 91, loss 1.73053, acc 0.46875
2020-02-16T15:35:13.142318: step 92, loss 1.32734, acc 0.515625
2020-02-16T15:35:13.261044: step 93, loss 1.36437, acc 0.515625
2020-02-16T15:35:13.381332: step 94, loss 1.33711, acc 0.484375
2020-02-16T15:35:13.503811: step 95, loss 1.22913, acc 0.5
2020-02-16T15:35:13.626944: step 96, loss 1.2117, acc 0.5
2020-02-16T15:35:13.753022: step 97, loss 1.17132, acc 0.5
2020-02-16T15:35:13.876191: step 98, loss 1.54756, acc 0.5625
2020-02-16T15:35:13.999412: step 99, loss 1.05018, acc 0.625
2020-02-16T15:35:14.118857: step 100, loss 1.60673, acc 0.4375

Evaluation:
2020-02-16T15:35:14.372997: step 100, loss 0.887574, acc 0.550657

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-100

2020-02-16T15:35:16.018024: step 101, loss 1.38268, acc 0.46875
2020-02-16T15:35:16.138184: step 102, loss 1.45185, acc 0.59375
2020-02-16T15:35:16.258923: step 103, loss 1.10248, acc 0.546875
2020-02-16T15:35:16.379410: step 104, loss 1.26914, acc 0.59375
2020-02-16T15:35:16.499797: step 105, loss 1.43061, acc 0.53125
2020-02-16T15:35:16.621484: step 106, loss 1.28885, acc 0.5625
2020-02-16T15:35:16.746452: step 107, loss 1.05313, acc 0.59375
2020-02-16T15:35:16.867077: step 108, loss 1.10524, acc 0.53125
2020-02-16T15:35:16.986294: step 109, loss 1.21871, acc 0.5625
2020-02-16T15:35:17.108133: step 110, loss 1.32963, acc 0.484375
2020-02-16T15:35:17.228882: step 111, loss 1.17062, acc 0.5
2020-02-16T15:35:17.347951: step 112, loss 1.34658, acc 0.546875
2020-02-16T15:35:17.467838: step 113, loss 1.21134, acc 0.578125
2020-02-16T15:35:17.590537: step 114, loss 1.31769, acc 0.5
2020-02-16T15:35:17.713344: step 115, loss 0.972204, acc 0.671875
2020-02-16T15:35:17.835585: step 116, loss 1.3078, acc 0.5625
2020-02-16T15:35:17.955712: step 117, loss 1.40604, acc 0.453125
2020-02-16T15:35:18.080786: step 118, loss 1.10809, acc 0.578125
2020-02-16T15:35:18.204029: step 119, loss 1.12901, acc 0.578125
2020-02-16T15:35:18.320081: step 120, loss 1.12757, acc 0.609375
2020-02-16T15:35:18.439924: step 121, loss 1.50698, acc 0.484375
2020-02-16T15:35:18.558809: step 122, loss 1.24003, acc 0.53125
2020-02-16T15:35:18.680301: step 123, loss 1.08733, acc 0.546875
2020-02-16T15:35:18.802614: step 124, loss 0.879012, acc 0.578125
2020-02-16T15:35:18.920228: step 125, loss 1.24263, acc 0.578125
2020-02-16T15:35:19.049740: step 126, loss 1.31508, acc 0.5625
2020-02-16T15:35:19.179761: step 127, loss 1.20585, acc 0.578125
2020-02-16T15:35:19.303972: step 128, loss 1.00459, acc 0.609375
2020-02-16T15:35:19.432710: step 129, loss 1.12281, acc 0.53125
2020-02-16T15:35:19.558066: step 130, loss 1.0206, acc 0.671875
2020-02-16T15:35:19.689781: step 131, loss 0.972052, acc 0.625
2020-02-16T15:35:19.811870: step 132, loss 1.18433, acc 0.578125
2020-02-16T15:35:19.933123: step 133, loss 1.05108, acc 0.625
2020-02-16T15:35:20.056621: step 134, loss 1.21439, acc 0.453125
2020-02-16T15:35:20.181836: step 135, loss 1.06033, acc 0.59375
2020-02-16T15:35:20.304845: step 136, loss 1.28454, acc 0.5
2020-02-16T15:35:20.433412: step 137, loss 1.19733, acc 0.484375
2020-02-16T15:35:20.558705: step 138, loss 1.00835, acc 0.546875
2020-02-16T15:35:20.689954: step 139, loss 1.09553, acc 0.609375
2020-02-16T15:35:20.812869: step 140, loss 1.24247, acc 0.515625
2020-02-16T15:35:20.935780: step 141, loss 1.26181, acc 0.484375
2020-02-16T15:35:21.063893: step 142, loss 1.31508, acc 0.453125
2020-02-16T15:35:21.265225: step 143, loss 0.79313, acc 0.6875
2020-02-16T15:35:21.453760: step 144, loss 0.813702, acc 0.609375
2020-02-16T15:35:21.606356: step 145, loss 1.1352, acc 0.53125
2020-02-16T15:35:21.764810: step 146, loss 1.07705, acc 0.59375
2020-02-16T15:35:21.906415: step 147, loss 1.09456, acc 0.578125
2020-02-16T15:35:22.060806: step 148, loss 1.37929, acc 0.53125
2020-02-16T15:35:22.205758: step 149, loss 1.17994, acc 0.578125
2020-02-16T15:35:22.340893: step 150, loss 1.08601, acc 0.5
2020-02-16T15:35:22.483525: step 151, loss 0.911393, acc 0.609375
2020-02-16T15:35:22.619792: step 152, loss 0.973039, acc 0.640625
2020-02-16T15:35:22.772226: step 153, loss 0.975312, acc 0.53125
2020-02-16T15:35:22.926243: step 154, loss 1.2892, acc 0.578125
2020-02-16T15:35:23.068101: step 155, loss 0.901726, acc 0.59375
2020-02-16T15:35:23.207561: step 156, loss 0.875203, acc 0.609375
2020-02-16T15:35:23.347446: step 157, loss 1.00451, acc 0.5625
2020-02-16T15:35:23.478311: step 158, loss 1.05752, acc 0.625
2020-02-16T15:35:23.615414: step 159, loss 0.565574, acc 0.75
2020-02-16T15:35:23.747749: step 160, loss 1.19486, acc 0.484375
2020-02-16T15:35:23.874914: step 161, loss 0.85129, acc 0.625
2020-02-16T15:35:24.012488: step 162, loss 0.681764, acc 0.703125
2020-02-16T15:35:24.155317: step 163, loss 1.03105, acc 0.65625
2020-02-16T15:35:24.288219: step 164, loss 1.03629, acc 0.53125
2020-02-16T15:35:24.415531: step 165, loss 0.809, acc 0.671875
2020-02-16T15:35:24.566894: step 166, loss 0.933192, acc 0.5625
2020-02-16T15:35:24.720415: step 167, loss 0.948215, acc 0.609375
2020-02-16T15:35:24.860995: step 168, loss 0.84091, acc 0.609375
2020-02-16T15:35:24.991012: step 169, loss 0.9662, acc 0.609375
2020-02-16T15:35:25.119785: step 170, loss 1.20897, acc 0.5625
2020-02-16T15:35:25.246568: step 171, loss 0.784116, acc 0.65625
2020-02-16T15:35:25.370894: step 172, loss 0.863656, acc 0.609375
2020-02-16T15:35:25.495331: step 173, loss 0.906938, acc 0.625
2020-02-16T15:35:25.622166: step 174, loss 0.896764, acc 0.578125
2020-02-16T15:35:25.760135: step 175, loss 0.997276, acc 0.578125
2020-02-16T15:35:25.893782: step 176, loss 1.03519, acc 0.515625
2020-02-16T15:35:26.034131: step 177, loss 0.899384, acc 0.609375
2020-02-16T15:35:26.171731: step 178, loss 0.999989, acc 0.53125
2020-02-16T15:35:26.307715: step 179, loss 0.82006, acc 0.671875
2020-02-16T15:35:26.440810: step 180, loss 0.885246, acc 0.671875
2020-02-16T15:35:26.582406: step 181, loss 0.768106, acc 0.671875
2020-02-16T15:35:26.719842: step 182, loss 0.857304, acc 0.640625
2020-02-16T15:35:26.850274: step 183, loss 1.09356, acc 0.453125
2020-02-16T15:35:26.987829: step 184, loss 1.33194, acc 0.40625
2020-02-16T15:35:27.126292: step 185, loss 0.658159, acc 0.703125
2020-02-16T15:35:27.256594: step 186, loss 0.867712, acc 0.640625
2020-02-16T15:35:27.391265: step 187, loss 0.784871, acc 0.59375
2020-02-16T15:35:27.525483: step 188, loss 0.821898, acc 0.640625
2020-02-16T15:35:27.669825: step 189, loss 1.11386, acc 0.484375
2020-02-16T15:35:27.808757: step 190, loss 0.989576, acc 0.578125
2020-02-16T15:35:27.946008: step 191, loss 0.854012, acc 0.6875
2020-02-16T15:35:28.086824: step 192, loss 0.918442, acc 0.546875
2020-02-16T15:35:28.227530: step 193, loss 0.764322, acc 0.625
2020-02-16T15:35:28.350450: step 194, loss 0.801605, acc 0.640625
2020-02-16T15:35:28.480785: step 195, loss 0.720668, acc 0.625
2020-02-16T15:35:28.607588: step 196, loss 0.720826, acc 0.671875
2020-02-16T15:35:28.745499: step 197, loss 0.981137, acc 0.53125
2020-02-16T15:35:28.873936: step 198, loss 1.09979, acc 0.59375
2020-02-16T15:35:28.997341: step 199, loss 1.07638, acc 0.5625
2020-02-16T15:35:29.129635: step 200, loss 0.957101, acc 0.578125

Evaluation:
2020-02-16T15:35:29.334040: step 200, loss 0.650973, acc 0.615385

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-200

2020-02-16T15:35:30.973746: step 201, loss 0.737956, acc 0.640625
2020-02-16T15:35:31.118894: step 202, loss 0.883013, acc 0.609375
2020-02-16T15:35:31.261081: step 203, loss 0.822271, acc 0.625
2020-02-16T15:35:31.399907: step 204, loss 0.948392, acc 0.625
2020-02-16T15:35:31.532296: step 205, loss 1.05382, acc 0.5
2020-02-16T15:35:31.682614: step 206, loss 1.02687, acc 0.53125
2020-02-16T15:35:31.867930: step 207, loss 0.895084, acc 0.65625
2020-02-16T15:35:32.002090: step 208, loss 0.97344, acc 0.53125
2020-02-16T15:35:32.138249: step 209, loss 0.613741, acc 0.703125
2020-02-16T15:35:32.272815: step 210, loss 0.926159, acc 0.609375
2020-02-16T15:35:32.410953: step 211, loss 1.17318, acc 0.59375
2020-02-16T15:35:32.572300: step 212, loss 0.954855, acc 0.546875
2020-02-16T15:35:32.746358: step 213, loss 0.74173, acc 0.53125
2020-02-16T15:35:32.884642: step 214, loss 0.83696, acc 0.625
2020-02-16T15:35:33.018985: step 215, loss 0.740702, acc 0.65625
2020-02-16T15:35:33.156605: step 216, loss 0.746657, acc 0.671875
2020-02-16T15:35:33.295842: step 217, loss 0.859295, acc 0.625
2020-02-16T15:35:33.434971: step 218, loss 0.915303, acc 0.609375
2020-02-16T15:35:33.578625: step 219, loss 1.18386, acc 0.46875
2020-02-16T15:35:33.720335: step 220, loss 0.622806, acc 0.65625
2020-02-16T15:35:33.862628: step 221, loss 0.796627, acc 0.609375
2020-02-16T15:35:34.004350: step 222, loss 0.646981, acc 0.734375
2020-02-16T15:35:34.141042: step 223, loss 0.862472, acc 0.515625
2020-02-16T15:35:34.274109: step 224, loss 0.899727, acc 0.546875
2020-02-16T15:35:34.409966: step 225, loss 0.802835, acc 0.578125
2020-02-16T15:35:34.544863: step 226, loss 0.79398, acc 0.640625
2020-02-16T15:35:34.691822: step 227, loss 0.795808, acc 0.625
2020-02-16T15:35:34.834255: step 228, loss 0.777081, acc 0.5625
2020-02-16T15:35:34.974543: step 229, loss 0.909042, acc 0.671875
2020-02-16T15:35:35.114440: step 230, loss 0.901688, acc 0.59375
2020-02-16T15:35:35.264343: step 231, loss 0.880008, acc 0.515625
2020-02-16T15:35:35.408465: step 232, loss 0.731378, acc 0.703125
2020-02-16T15:35:35.552076: step 233, loss 0.861859, acc 0.609375
2020-02-16T15:35:35.700077: step 234, loss 0.583909, acc 0.78125
2020-02-16T15:35:35.837171: step 235, loss 0.826969, acc 0.578125
2020-02-16T15:35:35.984144: step 236, loss 0.876083, acc 0.546875
2020-02-16T15:35:36.125792: step 237, loss 1.02175, acc 0.5625
2020-02-16T15:35:36.261374: step 238, loss 0.74343, acc 0.6875
2020-02-16T15:35:36.403537: step 239, loss 0.818374, acc 0.578125
2020-02-16T15:35:36.541421: step 240, loss 1.05145, acc 0.453125
2020-02-16T15:35:36.693848: step 241, loss 0.785935, acc 0.6875
2020-02-16T15:35:36.838120: step 242, loss 0.958834, acc 0.46875
2020-02-16T15:35:36.984267: step 243, loss 0.825443, acc 0.625
2020-02-16T15:35:37.214498: step 244, loss 0.791576, acc 0.65625
2020-02-16T15:35:37.405136: step 245, loss 0.872401, acc 0.609375
2020-02-16T15:35:37.574135: step 246, loss 0.705553, acc 0.5625
2020-02-16T15:35:37.743550: step 247, loss 0.681872, acc 0.65625
2020-02-16T15:35:37.888056: step 248, loss 0.940781, acc 0.5
2020-02-16T15:35:38.031935: step 249, loss 0.800626, acc 0.625
2020-02-16T15:35:38.197304: step 250, loss 0.685613, acc 0.703125
2020-02-16T15:35:38.350130: step 251, loss 0.655474, acc 0.640625
2020-02-16T15:35:38.506781: step 252, loss 0.758941, acc 0.671875
2020-02-16T15:35:38.671293: step 253, loss 0.863909, acc 0.59375
2020-02-16T15:35:38.810422: step 254, loss 0.709017, acc 0.609375
2020-02-16T15:35:38.949697: step 255, loss 0.77813, acc 0.578125
2020-02-16T15:35:39.097516: step 256, loss 0.837678, acc 0.640625
2020-02-16T15:35:39.273141: step 257, loss 0.787621, acc 0.53125
2020-02-16T15:35:39.419839: step 258, loss 0.7523, acc 0.609375
2020-02-16T15:35:39.578109: step 259, loss 0.855844, acc 0.546875
2020-02-16T15:35:39.744354: step 260, loss 1.03685, acc 0.546875
2020-02-16T15:35:39.886382: step 261, loss 0.72445, acc 0.65625
2020-02-16T15:35:40.022841: step 262, loss 0.668249, acc 0.6875
2020-02-16T15:35:40.183183: step 263, loss 0.75819, acc 0.640625
2020-02-16T15:35:40.329521: step 264, loss 0.73048, acc 0.71875
2020-02-16T15:35:40.484305: step 265, loss 0.638422, acc 0.703125
2020-02-16T15:35:40.648511: step 266, loss 0.591075, acc 0.734375
2020-02-16T15:35:40.784830: step 267, loss 0.851139, acc 0.59375
2020-02-16T15:35:40.914495: step 268, loss 0.649284, acc 0.625
2020-02-16T15:35:41.047220: step 269, loss 0.662443, acc 0.703125
2020-02-16T15:35:41.200877: step 270, loss 0.783806, acc 0.546875
2020-02-16T15:35:41.352191: step 271, loss 0.629771, acc 0.640625
2020-02-16T15:35:41.509437: step 272, loss 0.806335, acc 0.625
2020-02-16T15:35:41.673457: step 273, loss 0.760611, acc 0.65625
2020-02-16T15:35:41.805435: step 274, loss 0.648551, acc 0.609375
2020-02-16T15:35:41.947829: step 275, loss 0.773597, acc 0.59375
2020-02-16T15:35:42.100441: step 276, loss 0.617499, acc 0.671875
2020-02-16T15:35:42.266445: step 277, loss 0.698434, acc 0.609375
2020-02-16T15:35:42.418408: step 278, loss 0.814599, acc 0.640625
2020-02-16T15:35:42.561109: step 279, loss 0.69158, acc 0.65625
2020-02-16T15:35:42.715895: step 280, loss 0.877127, acc 0.546875
2020-02-16T15:35:42.855470: step 281, loss 0.675717, acc 0.703125
2020-02-16T15:35:42.992179: step 282, loss 0.798319, acc 0.625
2020-02-16T15:35:43.150884: step 283, loss 0.749336, acc 0.640625
2020-02-16T15:35:43.296985: step 284, loss 0.886846, acc 0.609375
2020-02-16T15:35:43.443183: step 285, loss 0.662359, acc 0.703125
2020-02-16T15:35:43.586082: step 286, loss 0.830887, acc 0.546875
2020-02-16T15:35:43.744112: step 287, loss 0.806999, acc 0.59375
2020-02-16T15:35:43.886400: step 288, loss 0.610924, acc 0.671875
2020-02-16T15:35:44.025342: step 289, loss 0.633772, acc 0.625
2020-02-16T15:35:44.184839: step 290, loss 0.70505, acc 0.609375
2020-02-16T15:35:44.322892: step 291, loss 0.701314, acc 0.640625
2020-02-16T15:35:44.467511: step 292, loss 0.783646, acc 0.640625
2020-02-16T15:35:44.623651: step 293, loss 0.814728, acc 0.5625
2020-02-16T15:35:44.779217: step 294, loss 0.772696, acc 0.609375
2020-02-16T15:35:44.918493: step 295, loss 0.557206, acc 0.734375
2020-02-16T15:35:45.052462: step 296, loss 0.63672, acc 0.703125
2020-02-16T15:35:45.219254: step 297, loss 0.805403, acc 0.5625
2020-02-16T15:35:45.362105: step 298, loss 0.827323, acc 0.578125
2020-02-16T15:35:45.522680: step 299, loss 0.793819, acc 0.671875
2020-02-16T15:35:45.683785: step 300, loss 0.719131, acc 0.6

Evaluation:
2020-02-16T15:35:45.900677: step 300, loss 0.62805, acc 0.628518

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-300

2020-02-16T15:35:47.536932: step 301, loss 0.594676, acc 0.671875
2020-02-16T15:35:47.711538: step 302, loss 0.607, acc 0.640625
2020-02-16T15:35:47.853783: step 303, loss 0.598697, acc 0.703125
2020-02-16T15:35:47.990941: step 304, loss 0.618849, acc 0.6875
2020-02-16T15:35:48.155989: step 305, loss 0.83336, acc 0.578125
2020-02-16T15:35:48.323048: step 306, loss 0.553368, acc 0.6875
2020-02-16T15:35:48.466937: step 307, loss 0.679167, acc 0.640625
2020-02-16T15:35:48.621293: step 308, loss 0.675471, acc 0.65625
2020-02-16T15:35:48.773094: step 309, loss 0.623878, acc 0.6875
2020-02-16T15:35:48.912706: step 310, loss 0.713189, acc 0.546875
2020-02-16T15:35:49.052669: step 311, loss 0.711767, acc 0.625
2020-02-16T15:35:49.254844: step 312, loss 0.597056, acc 0.703125
2020-02-16T15:35:49.390244: step 313, loss 0.620484, acc 0.671875
2020-02-16T15:35:49.526020: step 314, loss 0.665628, acc 0.65625
2020-02-16T15:35:49.665541: step 315, loss 0.633071, acc 0.640625
2020-02-16T15:35:49.802804: step 316, loss 0.608102, acc 0.640625
2020-02-16T15:35:49.923054: step 317, loss 0.59641, acc 0.71875
2020-02-16T15:35:50.057157: step 318, loss 0.508232, acc 0.796875
2020-02-16T15:35:50.197994: step 319, loss 0.695927, acc 0.625
2020-02-16T15:35:50.324072: step 320, loss 0.727816, acc 0.671875
2020-02-16T15:35:50.453560: step 321, loss 0.582374, acc 0.765625
2020-02-16T15:35:50.596565: step 322, loss 0.637576, acc 0.6875
2020-02-16T15:35:50.740056: step 323, loss 0.448476, acc 0.796875
2020-02-16T15:35:50.859960: step 324, loss 0.581611, acc 0.765625
2020-02-16T15:35:50.983865: step 325, loss 0.76912, acc 0.578125
2020-02-16T15:35:51.116756: step 326, loss 0.570242, acc 0.671875
2020-02-16T15:35:51.257442: step 327, loss 0.414907, acc 0.8125
2020-02-16T15:35:51.390122: step 328, loss 0.544263, acc 0.6875
2020-02-16T15:35:51.521902: step 329, loss 0.706201, acc 0.609375
2020-02-16T15:35:51.669881: step 330, loss 0.564118, acc 0.6875
2020-02-16T15:35:51.794851: step 331, loss 0.727905, acc 0.578125
2020-02-16T15:35:51.914015: step 332, loss 0.775058, acc 0.578125
2020-02-16T15:35:52.039873: step 333, loss 0.710787, acc 0.625
2020-02-16T15:35:52.183886: step 334, loss 0.621846, acc 0.6875
2020-02-16T15:35:52.315457: step 335, loss 0.730788, acc 0.625
2020-02-16T15:35:52.461849: step 336, loss 0.678278, acc 0.671875
2020-02-16T15:35:52.618519: step 337, loss 0.681081, acc 0.53125
2020-02-16T15:35:52.764845: step 338, loss 0.721385, acc 0.515625
2020-02-16T15:35:52.889949: step 339, loss 0.528072, acc 0.765625
2020-02-16T15:35:53.010230: step 340, loss 0.560806, acc 0.703125
2020-02-16T15:35:53.147233: step 341, loss 0.497011, acc 0.765625
2020-02-16T15:35:53.279876: step 342, loss 0.683064, acc 0.65625
2020-02-16T15:35:53.411656: step 343, loss 0.54279, acc 0.75
2020-02-16T15:35:53.543789: step 344, loss 0.670315, acc 0.65625
2020-02-16T15:35:53.684720: step 345, loss 0.614285, acc 0.734375
2020-02-16T15:35:53.803948: step 346, loss 0.70353, acc 0.59375
2020-02-16T15:35:53.921850: step 347, loss 0.732191, acc 0.578125
2020-02-16T15:35:54.046368: step 348, loss 0.610192, acc 0.59375
2020-02-16T15:35:54.184834: step 349, loss 0.609782, acc 0.65625
2020-02-16T15:35:54.326812: step 350, loss 0.632896, acc 0.6875
2020-02-16T15:35:54.460919: step 351, loss 0.56706, acc 0.703125
2020-02-16T15:35:54.602425: step 352, loss 0.601458, acc 0.65625
2020-02-16T15:35:54.749164: step 353, loss 0.584394, acc 0.71875
2020-02-16T15:35:54.873977: step 354, loss 0.535706, acc 0.71875
2020-02-16T15:35:54.991857: step 355, loss 0.625626, acc 0.703125
2020-02-16T15:35:55.121436: step 356, loss 0.730055, acc 0.5625
2020-02-16T15:35:55.260234: step 357, loss 0.705265, acc 0.625
2020-02-16T15:35:55.388029: step 358, loss 0.531646, acc 0.734375
2020-02-16T15:35:55.527031: step 359, loss 0.676431, acc 0.5625
2020-02-16T15:35:55.669705: step 360, loss 0.586378, acc 0.6875
2020-02-16T15:35:55.795413: step 361, loss 0.68911, acc 0.65625
2020-02-16T15:35:55.915509: step 362, loss 0.547753, acc 0.71875
2020-02-16T15:35:56.041048: step 363, loss 0.680941, acc 0.6875
2020-02-16T15:35:56.180702: step 364, loss 0.781999, acc 0.546875
2020-02-16T15:35:56.315257: step 365, loss 0.606778, acc 0.71875
2020-02-16T15:35:56.447509: step 366, loss 0.552711, acc 0.71875
2020-02-16T15:35:56.579971: step 367, loss 0.686174, acc 0.609375
2020-02-16T15:35:56.718822: step 368, loss 0.780903, acc 0.46875
2020-02-16T15:35:56.850850: step 369, loss 0.643143, acc 0.671875
2020-02-16T15:35:56.983960: step 370, loss 0.689602, acc 0.640625
2020-02-16T15:35:57.141087: step 371, loss 0.599096, acc 0.734375
2020-02-16T15:35:57.275451: step 372, loss 0.621117, acc 0.65625
2020-02-16T15:35:57.410532: step 373, loss 0.671958, acc 0.6875
2020-02-16T15:35:57.552698: step 374, loss 0.670291, acc 0.640625
2020-02-16T15:35:57.701231: step 375, loss 0.59407, acc 0.640625
2020-02-16T15:35:57.818986: step 376, loss 0.516475, acc 0.734375
2020-02-16T15:35:57.937912: step 377, loss 0.627557, acc 0.71875
2020-02-16T15:35:58.070104: step 378, loss 0.615707, acc 0.75
2020-02-16T15:35:58.209143: step 379, loss 0.571426, acc 0.703125
2020-02-16T15:35:58.334827: step 380, loss 0.480168, acc 0.734375
2020-02-16T15:35:58.470727: step 381, loss 0.731662, acc 0.578125
2020-02-16T15:35:58.613831: step 382, loss 0.680415, acc 0.625
2020-02-16T15:35:58.748472: step 383, loss 0.745616, acc 0.640625
2020-02-16T15:35:58.865066: step 384, loss 0.610878, acc 0.6875
2020-02-16T15:35:58.983751: step 385, loss 0.762896, acc 0.484375
2020-02-16T15:35:59.119484: step 386, loss 0.744255, acc 0.59375
2020-02-16T15:35:59.259841: step 387, loss 0.562582, acc 0.671875
2020-02-16T15:35:59.391119: step 388, loss 0.63685, acc 0.625
2020-02-16T15:35:59.520462: step 389, loss 0.606861, acc 0.65625
2020-02-16T15:35:59.669748: step 390, loss 0.578721, acc 0.640625
2020-02-16T15:35:59.792856: step 391, loss 0.674456, acc 0.640625
2020-02-16T15:35:59.909537: step 392, loss 0.608144, acc 0.640625
2020-02-16T15:36:00.029936: step 393, loss 0.659023, acc 0.609375
2020-02-16T15:36:00.176308: step 394, loss 0.641585, acc 0.59375
2020-02-16T15:36:00.308996: step 395, loss 0.717743, acc 0.65625
2020-02-16T15:36:00.442835: step 396, loss 0.597549, acc 0.71875
2020-02-16T15:36:00.814000: step 397, loss 0.627911, acc 0.6875
2020-02-16T15:36:00.935345: step 398, loss 0.638564, acc 0.625
2020-02-16T15:36:01.060453: step 399, loss 0.490409, acc 0.75
2020-02-16T15:36:01.207479: step 400, loss 0.652527, acc 0.65625

Evaluation:
2020-02-16T15:36:01.425944: step 400, loss 0.632887, acc 0.62758

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-400

2020-02-16T15:36:02.992497: step 401, loss 0.596123, acc 0.703125
2020-02-16T15:36:03.115460: step 402, loss 0.620273, acc 0.640625
2020-02-16T15:36:03.260240: step 403, loss 0.624907, acc 0.640625
2020-02-16T15:36:03.397443: step 404, loss 0.60791, acc 0.6875
2020-02-16T15:36:03.528034: step 405, loss 0.682755, acc 0.703125
2020-02-16T15:36:03.669911: step 406, loss 0.578636, acc 0.6875
2020-02-16T15:36:03.793356: step 407, loss 0.563559, acc 0.734375
2020-02-16T15:36:03.916688: step 408, loss 0.624104, acc 0.75
2020-02-16T15:36:04.041605: step 409, loss 0.661715, acc 0.6875
2020-02-16T15:36:04.184267: step 410, loss 0.813305, acc 0.5625
2020-02-16T15:36:04.323253: step 411, loss 0.610626, acc 0.671875
2020-02-16T15:36:04.462483: step 412, loss 0.59329, acc 0.671875
2020-02-16T15:36:04.619447: step 413, loss 0.605421, acc 0.703125
2020-02-16T15:36:04.758327: step 414, loss 0.731306, acc 0.640625
2020-02-16T15:36:04.896247: step 415, loss 0.666154, acc 0.65625
2020-02-16T15:36:05.023203: step 416, loss 0.598754, acc 0.65625
2020-02-16T15:36:05.179855: step 417, loss 0.687275, acc 0.65625
2020-02-16T15:36:05.326637: step 418, loss 0.522367, acc 0.703125
2020-02-16T15:36:05.470201: step 419, loss 0.68223, acc 0.65625
2020-02-16T15:36:05.633675: step 420, loss 0.547592, acc 0.71875
2020-02-16T15:36:05.783433: step 421, loss 0.654674, acc 0.71875
2020-02-16T15:36:05.908195: step 422, loss 0.543886, acc 0.703125
2020-02-16T15:36:06.050539: step 423, loss 0.822116, acc 0.5625
2020-02-16T15:36:06.205938: step 424, loss 0.722409, acc 0.625
2020-02-16T15:36:06.345930: step 425, loss 0.652378, acc 0.625
2020-02-16T15:36:06.554055: step 426, loss 0.682109, acc 0.640625
2020-02-16T15:36:06.683725: step 427, loss 0.629481, acc 0.65625
2020-02-16T15:36:06.817437: step 428, loss 0.610448, acc 0.75
2020-02-16T15:36:06.946332: step 429, loss 0.569836, acc 0.640625
2020-02-16T15:36:07.074608: step 430, loss 0.681056, acc 0.59375
2020-02-16T15:36:07.200600: step 431, loss 0.602536, acc 0.703125
2020-02-16T15:36:07.326691: step 432, loss 0.620688, acc 0.671875
2020-02-16T15:36:07.448140: step 433, loss 0.495446, acc 0.75
2020-02-16T15:36:07.567341: step 434, loss 0.593098, acc 0.71875
2020-02-16T15:36:07.691437: step 435, loss 0.586198, acc 0.703125
2020-02-16T15:36:07.817636: step 436, loss 0.610999, acc 0.6875
2020-02-16T15:36:07.943545: step 437, loss 0.56363, acc 0.71875
2020-02-16T15:36:08.061403: step 438, loss 0.668382, acc 0.65625
2020-02-16T15:36:08.184718: step 439, loss 0.627748, acc 0.640625
2020-02-16T15:36:08.313251: step 440, loss 0.634222, acc 0.65625
2020-02-16T15:36:08.439008: step 441, loss 0.571088, acc 0.6875
2020-02-16T15:36:08.565288: step 442, loss 0.607817, acc 0.640625
2020-02-16T15:36:08.698478: step 443, loss 0.684834, acc 0.5625
2020-02-16T15:36:08.907788: step 444, loss 0.659229, acc 0.65625
2020-02-16T15:36:09.040172: step 445, loss 0.588735, acc 0.703125
2020-02-16T15:36:09.192658: step 446, loss 0.598768, acc 0.65625
2020-02-16T15:36:09.439693: step 447, loss 0.691781, acc 0.578125
2020-02-16T15:36:09.602002: step 448, loss 0.682609, acc 0.640625
2020-02-16T15:36:09.805387: step 449, loss 0.640094, acc 0.6875
2020-02-16T15:36:09.939319: step 450, loss 0.792491, acc 0.55
2020-02-16T15:36:10.084152: step 451, loss 0.574473, acc 0.765625
2020-02-16T15:36:10.214953: step 452, loss 0.574899, acc 0.671875
2020-02-16T15:36:10.345120: step 453, loss 0.617796, acc 0.703125
2020-02-16T15:36:10.472326: step 454, loss 0.565682, acc 0.734375
2020-02-16T15:36:10.590536: step 455, loss 0.585739, acc 0.71875
2020-02-16T15:36:10.748272: step 456, loss 0.537086, acc 0.6875
2020-02-16T15:36:10.901148: step 457, loss 0.563787, acc 0.65625
2020-02-16T15:36:11.043263: step 458, loss 0.538912, acc 0.703125
2020-02-16T15:36:11.189156: step 459, loss 0.484386, acc 0.78125
2020-02-16T15:36:11.332085: step 460, loss 0.574, acc 0.75
2020-02-16T15:36:11.455190: step 461, loss 0.56274, acc 0.71875
2020-02-16T15:36:11.572380: step 462, loss 0.624683, acc 0.65625
2020-02-16T15:36:11.694568: step 463, loss 0.47906, acc 0.78125
2020-02-16T15:36:11.813753: step 464, loss 0.633757, acc 0.671875
2020-02-16T15:36:11.939937: step 465, loss 0.563671, acc 0.71875
2020-02-16T15:36:12.064640: step 466, loss 0.570904, acc 0.75
2020-02-16T15:36:12.186269: step 467, loss 0.663206, acc 0.59375
2020-02-16T15:36:12.307469: step 468, loss 0.587224, acc 0.671875
2020-02-16T15:36:12.426549: step 469, loss 0.572625, acc 0.671875
2020-02-16T15:36:12.545304: step 470, loss 0.573187, acc 0.703125
2020-02-16T15:36:12.664128: step 471, loss 0.635736, acc 0.703125
2020-02-16T15:36:12.786544: step 472, loss 0.565275, acc 0.71875
2020-02-16T15:36:12.910396: step 473, loss 0.551317, acc 0.703125
2020-02-16T15:36:13.056689: step 474, loss 0.570399, acc 0.671875
2020-02-16T15:36:13.202120: step 475, loss 0.443121, acc 0.828125
2020-02-16T15:36:13.344770: step 476, loss 0.633469, acc 0.671875
2020-02-16T15:36:13.491172: step 477, loss 0.500805, acc 0.78125
2020-02-16T15:36:13.634142: step 478, loss 0.51534, acc 0.734375
2020-02-16T15:36:13.762871: step 479, loss 0.50906, acc 0.75
2020-02-16T15:36:13.892876: step 480, loss 0.590935, acc 0.625
2020-02-16T15:36:14.029310: step 481, loss 0.606032, acc 0.6875
2020-02-16T15:36:14.200252: step 482, loss 0.546696, acc 0.6875
2020-02-16T15:36:14.350267: step 483, loss 0.487735, acc 0.75
2020-02-16T15:36:14.487253: step 484, loss 0.568073, acc 0.703125
2020-02-16T15:36:14.608479: step 485, loss 0.566805, acc 0.6875
2020-02-16T15:36:14.743751: step 486, loss 0.580251, acc 0.640625
2020-02-16T15:36:14.872094: step 487, loss 0.507687, acc 0.765625
2020-02-16T15:36:15.052332: step 488, loss 0.622512, acc 0.71875
2020-02-16T15:36:15.193462: step 489, loss 0.58427, acc 0.734375
2020-02-16T15:36:15.329603: step 490, loss 0.603228, acc 0.640625
2020-02-16T15:36:15.509392: step 491, loss 0.598607, acc 0.671875
2020-02-16T15:36:15.648597: step 492, loss 0.528732, acc 0.765625
2020-02-16T15:36:15.785659: step 493, loss 0.43903, acc 0.828125
2020-02-16T15:36:15.925242: step 494, loss 0.527956, acc 0.6875
2020-02-16T15:36:16.083814: step 495, loss 0.567227, acc 0.71875
2020-02-16T15:36:16.213705: step 496, loss 0.653379, acc 0.59375
2020-02-16T15:36:16.334425: step 497, loss 0.563901, acc 0.734375
2020-02-16T15:36:16.457607: step 498, loss 0.648062, acc 0.625
2020-02-16T15:36:16.577948: step 499, loss 0.530638, acc 0.765625
2020-02-16T15:36:16.704715: step 500, loss 0.571906, acc 0.71875

Evaluation:
2020-02-16T15:36:16.911733: step 500, loss 0.611567, acc 0.657598

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-500

2020-02-16T15:36:18.550712: step 501, loss 0.622051, acc 0.71875
2020-02-16T15:36:18.707419: step 502, loss 0.598762, acc 0.6875
2020-02-16T15:36:18.855595: step 503, loss 0.558181, acc 0.65625
2020-02-16T15:36:18.999527: step 504, loss 0.577002, acc 0.71875
2020-02-16T15:36:19.133882: step 505, loss 0.526426, acc 0.75
2020-02-16T15:36:19.270788: step 506, loss 0.579095, acc 0.671875
2020-02-16T15:36:19.398472: step 507, loss 0.57767, acc 0.703125
2020-02-16T15:36:19.526088: step 508, loss 0.64898, acc 0.65625
2020-02-16T15:36:19.651580: step 509, loss 0.505205, acc 0.71875
2020-02-16T15:36:19.787987: step 510, loss 0.582701, acc 0.703125
2020-02-16T15:36:19.914088: step 511, loss 0.593326, acc 0.609375
2020-02-16T15:36:20.037060: step 512, loss 0.572527, acc 0.71875
2020-02-16T15:36:20.159897: step 513, loss 0.570309, acc 0.78125
2020-02-16T15:36:20.289003: step 514, loss 0.658125, acc 0.625
2020-02-16T15:36:20.449762: step 515, loss 0.571681, acc 0.734375
2020-02-16T15:36:20.615588: step 516, loss 0.516836, acc 0.78125
2020-02-16T15:36:20.757760: step 517, loss 0.570921, acc 0.75
2020-02-16T15:36:20.889229: step 518, loss 0.494991, acc 0.71875
2020-02-16T15:36:21.026992: step 519, loss 0.592751, acc 0.640625
2020-02-16T15:36:21.185139: step 520, loss 0.553366, acc 0.65625
2020-02-16T15:36:21.341132: step 521, loss 0.592672, acc 0.65625
2020-02-16T15:36:21.494376: step 522, loss 0.522963, acc 0.71875
2020-02-16T15:36:21.639166: step 523, loss 0.491529, acc 0.75
2020-02-16T15:36:21.789790: step 524, loss 0.626652, acc 0.640625
2020-02-16T15:36:21.924011: step 525, loss 0.527732, acc 0.78125
2020-02-16T15:36:22.042798: step 526, loss 0.590647, acc 0.65625
2020-02-16T15:36:22.161001: step 527, loss 0.561137, acc 0.75
2020-02-16T15:36:22.280760: step 528, loss 0.669847, acc 0.671875
2020-02-16T15:36:22.407153: step 529, loss 0.637878, acc 0.609375
2020-02-16T15:36:22.532196: step 530, loss 0.620687, acc 0.6875
2020-02-16T15:36:22.652696: step 531, loss 0.581375, acc 0.671875
2020-02-16T15:36:22.778975: step 532, loss 0.525521, acc 0.734375
2020-02-16T15:36:22.900578: step 533, loss 0.51447, acc 0.734375
2020-02-16T15:36:23.044668: step 534, loss 0.533628, acc 0.75
2020-02-16T15:36:23.189744: step 535, loss 0.5162, acc 0.75
2020-02-16T15:36:23.310548: step 536, loss 0.583967, acc 0.640625
2020-02-16T15:36:23.442490: step 537, loss 0.510317, acc 0.75
2020-02-16T15:36:23.563070: step 538, loss 0.578595, acc 0.703125
2020-02-16T15:36:23.683621: step 539, loss 0.667575, acc 0.59375
2020-02-16T15:36:23.804686: step 540, loss 0.607463, acc 0.65625
2020-02-16T15:36:23.930350: step 541, loss 0.63319, acc 0.625
2020-02-16T15:36:24.057494: step 542, loss 0.498837, acc 0.71875
2020-02-16T15:36:24.186786: step 543, loss 0.581687, acc 0.703125
2020-02-16T15:36:24.307685: step 544, loss 0.571669, acc 0.703125
2020-02-16T15:36:24.428397: step 545, loss 0.631425, acc 0.6875
2020-02-16T15:36:24.545130: step 546, loss 0.645737, acc 0.65625
2020-02-16T15:36:24.663750: step 547, loss 0.611774, acc 0.671875
2020-02-16T15:36:24.783930: step 548, loss 0.519018, acc 0.765625
2020-02-16T15:36:24.906716: step 549, loss 0.643784, acc 0.6875
2020-02-16T15:36:25.035497: step 550, loss 0.543054, acc 0.796875
2020-02-16T15:36:25.163715: step 551, loss 0.541266, acc 0.703125
2020-02-16T15:36:25.290058: step 552, loss 0.608236, acc 0.71875
2020-02-16T15:36:25.410381: step 553, loss 0.521207, acc 0.765625
2020-02-16T15:36:25.532188: step 554, loss 0.516817, acc 0.75
2020-02-16T15:36:25.650018: step 555, loss 0.533545, acc 0.71875
2020-02-16T15:36:25.779940: step 556, loss 0.548465, acc 0.765625
2020-02-16T15:36:25.901541: step 557, loss 0.522294, acc 0.765625
2020-02-16T15:36:26.025590: step 558, loss 0.537089, acc 0.734375
2020-02-16T15:36:26.142838: step 559, loss 0.55862, acc 0.71875
2020-02-16T15:36:26.263025: step 560, loss 0.729516, acc 0.578125
2020-02-16T15:36:26.381950: step 561, loss 0.453997, acc 0.78125
2020-02-16T15:36:26.501013: step 562, loss 0.541316, acc 0.765625
2020-02-16T15:36:26.619798: step 563, loss 0.551548, acc 0.671875
2020-02-16T15:36:26.744550: step 564, loss 0.580737, acc 0.6875
2020-02-16T15:36:26.866897: step 565, loss 0.65744, acc 0.65625
2020-02-16T15:36:26.985675: step 566, loss 0.636849, acc 0.65625
2020-02-16T15:36:27.104384: step 567, loss 0.697586, acc 0.59375
2020-02-16T15:36:27.224457: step 568, loss 0.521206, acc 0.734375
2020-02-16T15:36:27.344654: step 569, loss 0.491433, acc 0.75
2020-02-16T15:36:27.463143: step 570, loss 0.500445, acc 0.796875
2020-02-16T15:36:27.584385: step 571, loss 0.473958, acc 0.765625
2020-02-16T15:36:27.711155: step 572, loss 0.623676, acc 0.6875
2020-02-16T15:36:27.942326: step 573, loss 0.658015, acc 0.609375
2020-02-16T15:36:28.061931: step 574, loss 0.571699, acc 0.734375
2020-02-16T15:36:28.194952: step 575, loss 0.542545, acc 0.75
2020-02-16T15:36:28.353096: step 576, loss 0.535011, acc 0.6875
2020-02-16T15:36:28.480045: step 577, loss 0.563122, acc 0.71875
2020-02-16T15:36:28.599791: step 578, loss 0.621026, acc 0.625
2020-02-16T15:36:28.726899: step 579, loss 0.528021, acc 0.71875
2020-02-16T15:36:28.875456: step 580, loss 0.63148, acc 0.671875
2020-02-16T15:36:29.030318: step 581, loss 0.583124, acc 0.671875
2020-02-16T15:36:29.172167: step 582, loss 0.576499, acc 0.65625
2020-02-16T15:36:29.337781: step 583, loss 0.503551, acc 0.796875
2020-02-16T15:36:29.467768: step 584, loss 0.516466, acc 0.71875
2020-02-16T15:36:29.588618: step 585, loss 0.50506, acc 0.734375
2020-02-16T15:36:29.712281: step 586, loss 0.463812, acc 0.8125
2020-02-16T15:36:29.856625: step 587, loss 0.464967, acc 0.796875
2020-02-16T15:36:29.989339: step 588, loss 0.471068, acc 0.75
2020-02-16T15:36:30.113506: step 589, loss 0.527569, acc 0.71875
2020-02-16T15:36:30.235531: step 590, loss 0.626344, acc 0.703125
2020-02-16T15:36:30.380881: step 591, loss 0.596561, acc 0.71875
2020-02-16T15:36:30.695381: step 592, loss 0.56817, acc 0.71875
2020-02-16T15:36:30.852083: step 593, loss 0.549041, acc 0.671875
2020-02-16T15:36:30.992222: step 594, loss 0.462127, acc 0.78125
2020-02-16T15:36:31.128263: step 595, loss 0.539033, acc 0.75
2020-02-16T15:36:31.268776: step 596, loss 0.554881, acc 0.671875
2020-02-16T15:36:31.410826: step 597, loss 0.560554, acc 0.75
2020-02-16T15:36:31.531531: step 598, loss 0.484026, acc 0.734375
2020-02-16T15:36:31.647932: step 599, loss 0.611824, acc 0.71875
2020-02-16T15:36:31.780076: step 600, loss 0.575086, acc 0.666667

Evaluation:
2020-02-16T15:36:32.009915: step 600, loss 0.671828, acc 0.608818

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-600

2020-02-16T15:36:33.550725: step 601, loss 0.414611, acc 0.875
2020-02-16T15:36:33.670365: step 602, loss 0.551587, acc 0.71875
2020-02-16T15:36:33.798405: step 603, loss 0.562462, acc 0.6875
2020-02-16T15:36:33.948918: step 604, loss 0.441628, acc 0.8125
2020-02-16T15:36:34.083359: step 605, loss 0.576886, acc 0.671875
2020-02-16T15:36:34.208908: step 606, loss 0.588737, acc 0.703125
2020-02-16T15:36:34.355033: step 607, loss 0.58517, acc 0.75
2020-02-16T15:36:34.474144: step 608, loss 0.62021, acc 0.71875
2020-02-16T15:36:34.594587: step 609, loss 0.649048, acc 0.703125
2020-02-16T15:36:34.717439: step 610, loss 0.488104, acc 0.765625
2020-02-16T15:36:34.865783: step 611, loss 0.52695, acc 0.6875
2020-02-16T15:36:35.005262: step 612, loss 0.445928, acc 0.796875
2020-02-16T15:36:35.137745: step 613, loss 0.620048, acc 0.640625
2020-02-16T15:36:35.269076: step 614, loss 0.614923, acc 0.65625
2020-02-16T15:36:35.410321: step 615, loss 0.529091, acc 0.734375
2020-02-16T15:36:35.529419: step 616, loss 0.45793, acc 0.78125
2020-02-16T15:36:35.650734: step 617, loss 0.63297, acc 0.703125
2020-02-16T15:36:35.782702: step 618, loss 0.465072, acc 0.734375
2020-02-16T15:36:35.924409: step 619, loss 0.484016, acc 0.71875
2020-02-16T15:36:36.054029: step 620, loss 0.487365, acc 0.71875
2020-02-16T15:36:36.189892: step 621, loss 0.634051, acc 0.71875
2020-02-16T15:36:36.333822: step 622, loss 0.529234, acc 0.671875
2020-02-16T15:36:36.462469: step 623, loss 0.437882, acc 0.828125
2020-02-16T15:36:36.582942: step 624, loss 0.554546, acc 0.71875
2020-02-16T15:36:36.705394: step 625, loss 0.419189, acc 0.828125
2020-02-16T15:36:36.846221: step 626, loss 0.456549, acc 0.75
2020-02-16T15:36:36.985615: step 627, loss 0.524604, acc 0.75
2020-02-16T15:36:37.110287: step 628, loss 0.520887, acc 0.734375
2020-02-16T15:36:37.244352: step 629, loss 0.574367, acc 0.671875
2020-02-16T15:36:37.386313: step 630, loss 0.562419, acc 0.6875
2020-02-16T15:36:37.509809: step 631, loss 0.543637, acc 0.6875
2020-02-16T15:36:37.632503: step 632, loss 0.50581, acc 0.75
2020-02-16T15:36:37.760735: step 633, loss 0.600689, acc 0.734375
2020-02-16T15:36:37.905609: step 634, loss 0.595691, acc 0.71875
2020-02-16T15:36:38.034080: step 635, loss 0.562987, acc 0.71875
2020-02-16T15:36:38.161826: step 636, loss 0.482479, acc 0.78125
2020-02-16T15:36:38.302145: step 637, loss 0.618659, acc 0.6875
2020-02-16T15:36:38.436583: step 638, loss 0.445882, acc 0.78125
2020-02-16T15:36:38.558115: step 639, loss 0.482542, acc 0.765625
2020-02-16T15:36:38.677612: step 640, loss 0.48661, acc 0.75
2020-02-16T15:36:38.809828: step 641, loss 0.435398, acc 0.8125
2020-02-16T15:36:38.947147: step 642, loss 0.610459, acc 0.671875
2020-02-16T15:36:39.080520: step 643, loss 0.506916, acc 0.8125
2020-02-16T15:36:39.209229: step 644, loss 0.663853, acc 0.6875
2020-02-16T15:36:39.347413: step 645, loss 0.536032, acc 0.71875
2020-02-16T15:36:39.466245: step 646, loss 0.520798, acc 0.75
2020-02-16T15:36:39.584279: step 647, loss 0.521503, acc 0.734375
2020-02-16T15:36:39.709339: step 648, loss 0.555223, acc 0.734375
2020-02-16T15:36:39.850060: step 649, loss 0.464448, acc 0.703125
2020-02-16T15:36:39.987136: step 650, loss 0.434466, acc 0.796875
2020-02-16T15:36:40.116798: step 651, loss 0.46479, acc 0.734375
2020-02-16T15:36:40.249999: step 652, loss 0.50085, acc 0.75
2020-02-16T15:36:40.389154: step 653, loss 0.480659, acc 0.75
2020-02-16T15:36:40.510524: step 654, loss 0.434744, acc 0.828125
2020-02-16T15:36:40.626714: step 655, loss 0.440164, acc 0.8125
2020-02-16T15:36:40.752474: step 656, loss 0.61346, acc 0.703125
2020-02-16T15:36:40.898544: step 657, loss 0.483332, acc 0.78125
2020-02-16T15:36:41.027574: step 658, loss 0.450342, acc 0.78125
2020-02-16T15:36:41.155017: step 659, loss 0.445172, acc 0.734375
2020-02-16T15:36:41.293148: step 660, loss 0.548718, acc 0.71875
2020-02-16T15:36:41.431524: step 661, loss 0.57323, acc 0.671875
2020-02-16T15:36:41.554056: step 662, loss 0.411562, acc 0.84375
2020-02-16T15:36:41.679035: step 663, loss 0.454507, acc 0.84375
2020-02-16T15:36:41.808313: step 664, loss 0.422774, acc 0.828125
2020-02-16T15:36:41.949639: step 665, loss 0.477529, acc 0.75
2020-02-16T15:36:42.079143: step 666, loss 0.542694, acc 0.65625
2020-02-16T15:36:42.210479: step 667, loss 0.569697, acc 0.671875
2020-02-16T15:36:42.348520: step 668, loss 0.47988, acc 0.8125
2020-02-16T15:36:42.477424: step 669, loss 0.534642, acc 0.6875
2020-02-16T15:36:42.597233: step 670, loss 0.541781, acc 0.6875
2020-02-16T15:36:42.720519: step 671, loss 0.502687, acc 0.6875
2020-02-16T15:36:42.855563: step 672, loss 0.525593, acc 0.6875
2020-02-16T15:36:42.992455: step 673, loss 0.465835, acc 0.8125
2020-02-16T15:36:43.117808: step 674, loss 0.431179, acc 0.796875
2020-02-16T15:36:43.268755: step 675, loss 0.547123, acc 0.75
2020-02-16T15:36:43.410796: step 676, loss 0.510268, acc 0.78125
2020-02-16T15:36:43.532562: step 677, loss 0.425484, acc 0.828125
2020-02-16T15:36:43.651749: step 678, loss 0.484482, acc 0.765625
2020-02-16T15:36:43.782125: step 679, loss 0.442539, acc 0.8125
2020-02-16T15:36:43.930001: step 680, loss 0.634426, acc 0.640625
2020-02-16T15:36:44.060261: step 681, loss 0.563395, acc 0.71875
2020-02-16T15:36:44.188905: step 682, loss 0.465812, acc 0.734375
2020-02-16T15:36:44.326230: step 683, loss 0.501012, acc 0.78125
2020-02-16T15:36:44.460989: step 684, loss 0.398823, acc 0.84375
2020-02-16T15:36:44.583339: step 685, loss 0.512155, acc 0.703125
2020-02-16T15:36:44.706255: step 686, loss 0.589727, acc 0.71875
2020-02-16T15:36:44.844903: step 687, loss 0.515171, acc 0.75
2020-02-16T15:36:44.992198: step 688, loss 0.471772, acc 0.765625
2020-02-16T15:36:45.120369: step 689, loss 0.470303, acc 0.765625
2020-02-16T15:36:45.256099: step 690, loss 0.500765, acc 0.8125
2020-02-16T15:36:45.400302: step 691, loss 0.38895, acc 0.828125
2020-02-16T15:36:45.519747: step 692, loss 0.554137, acc 0.765625
2020-02-16T15:36:45.639152: step 693, loss 0.600313, acc 0.6875
2020-02-16T15:36:45.767543: step 694, loss 0.358224, acc 0.828125
2020-02-16T15:36:45.906052: step 695, loss 0.462201, acc 0.8125
2020-02-16T15:36:46.047214: step 696, loss 0.487216, acc 0.796875
2020-02-16T15:36:46.175976: step 697, loss 0.473246, acc 0.75
2020-02-16T15:36:46.358180: step 698, loss 0.544566, acc 0.71875
2020-02-16T15:36:46.548353: step 699, loss 0.494983, acc 0.734375
2020-02-16T15:36:46.671769: step 700, loss 0.414296, acc 0.859375

Evaluation:
2020-02-16T15:36:46.908352: step 700, loss 0.593742, acc 0.666041

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-700

2020-02-16T15:36:48.542491: step 701, loss 0.664299, acc 0.65625
2020-02-16T15:36:48.662323: step 702, loss 0.560905, acc 0.703125
2020-02-16T15:36:48.795728: step 703, loss 0.470201, acc 0.75
2020-02-16T15:36:48.935882: step 704, loss 0.47553, acc 0.796875
2020-02-16T15:36:49.063484: step 705, loss 0.559861, acc 0.6875
2020-02-16T15:36:49.193946: step 706, loss 0.512136, acc 0.765625
2020-02-16T15:36:49.346083: step 707, loss 0.556412, acc 0.765625
2020-02-16T15:36:49.469297: step 708, loss 0.401838, acc 0.8125
2020-02-16T15:36:49.589562: step 709, loss 0.542172, acc 0.734375
2020-02-16T15:36:49.714948: step 710, loss 0.504205, acc 0.71875
2020-02-16T15:36:49.857300: step 711, loss 0.516537, acc 0.734375
2020-02-16T15:36:49.991249: step 712, loss 0.489625, acc 0.71875
2020-02-16T15:36:50.117990: step 713, loss 0.48349, acc 0.828125
2020-02-16T15:36:50.246484: step 714, loss 0.47056, acc 0.765625
2020-02-16T15:36:50.392938: step 715, loss 0.417764, acc 0.8125
2020-02-16T15:36:50.510415: step 716, loss 0.465222, acc 0.765625
2020-02-16T15:36:50.629155: step 717, loss 0.455639, acc 0.796875
2020-02-16T15:36:50.760146: step 718, loss 0.421764, acc 0.8125
2020-02-16T15:36:50.907289: step 719, loss 0.43151, acc 0.828125
2020-02-16T15:36:51.036371: step 720, loss 0.546729, acc 0.703125
2020-02-16T15:36:51.163763: step 721, loss 0.470609, acc 0.796875
2020-02-16T15:36:51.309706: step 722, loss 0.455173, acc 0.78125
2020-02-16T15:36:51.448723: step 723, loss 0.478135, acc 0.75
2020-02-16T15:36:51.565113: step 724, loss 0.568912, acc 0.796875
2020-02-16T15:36:51.687817: step 725, loss 0.76181, acc 0.59375
2020-02-16T15:36:51.817731: step 726, loss 0.583917, acc 0.75
2020-02-16T15:36:51.954694: step 727, loss 0.528735, acc 0.703125
2020-02-16T15:36:52.087474: step 728, loss 0.407148, acc 0.765625
2020-02-16T15:36:52.212635: step 729, loss 0.554356, acc 0.734375
2020-02-16T15:36:52.360172: step 730, loss 0.601575, acc 0.734375
2020-02-16T15:36:52.482827: step 731, loss 0.391642, acc 0.859375
2020-02-16T15:36:52.605420: step 732, loss 0.478217, acc 0.78125
2020-02-16T15:36:52.733910: step 733, loss 0.376705, acc 0.875
2020-02-16T15:36:52.881979: step 734, loss 0.429983, acc 0.765625
2020-02-16T15:36:53.011559: step 735, loss 0.543099, acc 0.75
2020-02-16T15:36:53.142122: step 736, loss 0.519566, acc 0.75
2020-02-16T15:36:53.282674: step 737, loss 0.484503, acc 0.71875
2020-02-16T15:36:53.422921: step 738, loss 0.659941, acc 0.640625
2020-02-16T15:36:53.543864: step 739, loss 0.46247, acc 0.78125
2020-02-16T15:36:53.662583: step 740, loss 0.457453, acc 0.78125
2020-02-16T15:36:53.797768: step 741, loss 0.620704, acc 0.703125
2020-02-16T15:36:53.938038: step 742, loss 0.558635, acc 0.6875
2020-02-16T15:36:54.079350: step 743, loss 0.59684, acc 0.71875
2020-02-16T15:36:54.203387: step 744, loss 0.54978, acc 0.703125
2020-02-16T15:36:54.350316: step 745, loss 0.520201, acc 0.765625
2020-02-16T15:36:54.466466: step 746, loss 0.494065, acc 0.8125
2020-02-16T15:36:54.582587: step 747, loss 0.399041, acc 0.875
2020-02-16T15:36:54.703319: step 748, loss 0.455794, acc 0.828125
2020-02-16T15:36:54.845090: step 749, loss 0.478642, acc 0.703125
2020-02-16T15:36:54.979897: step 750, loss 0.509438, acc 0.783333
2020-02-16T15:36:55.111624: step 751, loss 0.274087, acc 0.953125
2020-02-16T15:36:55.249162: step 752, loss 0.514991, acc 0.734375
2020-02-16T15:36:55.397309: step 753, loss 0.584997, acc 0.703125
2020-02-16T15:36:55.516179: step 754, loss 0.496685, acc 0.75
2020-02-16T15:36:55.632636: step 755, loss 0.511116, acc 0.734375
2020-02-16T15:36:55.758875: step 756, loss 0.463285, acc 0.765625
2020-02-16T15:36:55.906725: step 757, loss 0.445408, acc 0.796875
2020-02-16T15:36:56.039502: step 758, loss 0.449506, acc 0.796875
2020-02-16T15:36:56.164458: step 759, loss 0.537844, acc 0.71875
2020-02-16T15:36:56.313299: step 760, loss 0.46334, acc 0.796875
2020-02-16T15:36:56.439414: step 761, loss 0.408317, acc 0.859375
2020-02-16T15:36:56.557882: step 762, loss 0.334663, acc 0.875
2020-02-16T15:36:56.680936: step 763, loss 0.388331, acc 0.796875
2020-02-16T15:36:56.811229: step 764, loss 0.444395, acc 0.78125
2020-02-16T15:36:56.952848: step 765, loss 0.437978, acc 0.8125
2020-02-16T15:36:57.086299: step 766, loss 0.286583, acc 0.90625
2020-02-16T15:36:57.214293: step 767, loss 0.38907, acc 0.84375
2020-02-16T15:36:57.356207: step 768, loss 0.540726, acc 0.75
2020-02-16T15:36:57.476321: step 769, loss 0.368277, acc 0.8125
2020-02-16T15:36:57.594211: step 770, loss 0.569769, acc 0.75
2020-02-16T15:36:57.715083: step 771, loss 0.303055, acc 0.875
2020-02-16T15:36:57.854817: step 772, loss 0.448474, acc 0.8125
2020-02-16T15:36:57.988592: step 773, loss 0.361559, acc 0.828125
2020-02-16T15:36:58.115350: step 774, loss 0.434654, acc 0.78125
2020-02-16T15:36:58.241155: step 775, loss 0.46674, acc 0.75
2020-02-16T15:36:58.397362: step 776, loss 0.375929, acc 0.890625
2020-02-16T15:36:58.514934: step 777, loss 0.409765, acc 0.859375
2020-02-16T15:36:58.634585: step 778, loss 0.352414, acc 0.828125
2020-02-16T15:36:58.761058: step 779, loss 0.46318, acc 0.765625
2020-02-16T15:36:58.918915: step 780, loss 0.548481, acc 0.703125
2020-02-16T15:36:59.048058: step 781, loss 0.622034, acc 0.71875
2020-02-16T15:36:59.172416: step 782, loss 0.424341, acc 0.8125
2020-02-16T15:36:59.310296: step 783, loss 0.385939, acc 0.84375
2020-02-16T15:36:59.448608: step 784, loss 0.475303, acc 0.828125
2020-02-16T15:36:59.565497: step 785, loss 0.410742, acc 0.828125
2020-02-16T15:36:59.690097: step 786, loss 0.413713, acc 0.8125
2020-02-16T15:36:59.813974: step 787, loss 0.354972, acc 0.8125
2020-02-16T15:36:59.957669: step 788, loss 0.440238, acc 0.78125
2020-02-16T15:37:00.090759: step 789, loss 0.437848, acc 0.765625
2020-02-16T15:37:00.216455: step 790, loss 0.423652, acc 0.8125
2020-02-16T15:37:00.358001: step 791, loss 0.387208, acc 0.84375
2020-02-16T15:37:00.475219: step 792, loss 0.418858, acc 0.8125
2020-02-16T15:37:00.593607: step 793, loss 0.431776, acc 0.796875
2020-02-16T15:37:00.720065: step 794, loss 0.456051, acc 0.8125
2020-02-16T15:37:00.879304: step 795, loss 0.345952, acc 0.875
2020-02-16T15:37:01.012884: step 796, loss 0.403111, acc 0.796875
2020-02-16T15:37:01.141469: step 797, loss 0.475543, acc 0.8125
2020-02-16T15:37:01.283735: step 798, loss 0.497898, acc 0.734375
2020-02-16T15:37:01.419474: step 799, loss 0.420587, acc 0.828125
2020-02-16T15:37:01.538328: step 800, loss 0.299478, acc 0.890625

Evaluation:
2020-02-16T15:37:01.751168: step 800, loss 0.592393, acc 0.673546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-800

2020-02-16T15:37:03.962344: step 801, loss 0.514309, acc 0.796875
2020-02-16T15:37:04.092514: step 802, loss 0.415441, acc 0.78125
2020-02-16T15:37:04.213916: step 803, loss 0.442763, acc 0.78125
2020-02-16T15:37:04.363762: step 804, loss 0.344744, acc 0.84375
2020-02-16T15:37:04.484921: step 805, loss 0.464219, acc 0.796875
2020-02-16T15:37:04.605017: step 806, loss 0.420924, acc 0.765625
2020-02-16T15:37:04.734259: step 807, loss 0.492584, acc 0.796875
2020-02-16T15:37:04.892346: step 808, loss 0.509206, acc 0.734375
2020-02-16T15:37:05.024821: step 809, loss 0.423921, acc 0.8125
2020-02-16T15:37:05.153072: step 810, loss 0.364561, acc 0.875
2020-02-16T15:37:05.298273: step 811, loss 0.520548, acc 0.765625
2020-02-16T15:37:05.439066: step 812, loss 0.452935, acc 0.8125
2020-02-16T15:37:05.555605: step 813, loss 0.356413, acc 0.875
2020-02-16T15:37:05.676349: step 814, loss 0.508106, acc 0.71875
2020-02-16T15:37:05.802809: step 815, loss 0.518459, acc 0.796875
2020-02-16T15:37:05.949212: step 816, loss 0.368408, acc 0.84375
2020-02-16T15:37:06.080488: step 817, loss 0.267236, acc 0.921875
2020-02-16T15:37:06.212911: step 818, loss 0.425842, acc 0.796875
2020-02-16T15:37:06.355427: step 819, loss 0.463453, acc 0.765625
2020-02-16T15:37:06.478068: step 820, loss 0.38263, acc 0.828125
2020-02-16T15:37:06.599360: step 821, loss 0.466174, acc 0.765625
2020-02-16T15:37:06.723716: step 822, loss 0.34804, acc 0.828125
2020-02-16T15:37:06.866968: step 823, loss 0.382998, acc 0.8125
2020-02-16T15:37:06.998634: step 824, loss 0.457859, acc 0.796875
2020-02-16T15:37:07.127584: step 825, loss 0.3294, acc 0.859375
2020-02-16T15:37:07.257122: step 826, loss 0.395627, acc 0.84375
2020-02-16T15:37:07.404011: step 827, loss 0.507482, acc 0.71875
2020-02-16T15:37:07.521106: step 828, loss 0.386511, acc 0.8125
2020-02-16T15:37:07.641998: step 829, loss 0.384496, acc 0.828125
2020-02-16T15:37:07.767082: step 830, loss 0.381527, acc 0.859375
2020-02-16T15:37:07.907486: step 831, loss 0.376985, acc 0.796875
2020-02-16T15:37:08.037720: step 832, loss 0.447, acc 0.828125
2020-02-16T15:37:08.162894: step 833, loss 0.381628, acc 0.828125
2020-02-16T15:37:08.304378: step 834, loss 0.338907, acc 0.828125
2020-02-16T15:37:08.434798: step 835, loss 0.509032, acc 0.703125
2020-02-16T15:37:08.553099: step 836, loss 0.58016, acc 0.71875
2020-02-16T15:37:08.674537: step 837, loss 0.449846, acc 0.765625
2020-02-16T15:37:08.810856: step 838, loss 0.449377, acc 0.765625
2020-02-16T15:37:08.949354: step 839, loss 0.366502, acc 0.828125
2020-02-16T15:37:09.083113: step 840, loss 0.482085, acc 0.75
2020-02-16T15:37:09.208931: step 841, loss 0.469617, acc 0.75
2020-02-16T15:37:09.352555: step 842, loss 0.554115, acc 0.703125
2020-02-16T15:37:09.471160: step 843, loss 0.479469, acc 0.796875
2020-02-16T15:37:09.591069: step 844, loss 0.285612, acc 0.890625
2020-02-16T15:37:09.712970: step 845, loss 0.439763, acc 0.765625
2020-02-16T15:37:09.857032: step 846, loss 0.457893, acc 0.78125
2020-02-16T15:37:10.002308: step 847, loss 0.39858, acc 0.859375
2020-02-16T15:37:10.131330: step 848, loss 0.335666, acc 0.90625
2020-02-16T15:37:10.269964: step 849, loss 0.377732, acc 0.796875
2020-02-16T15:37:10.404906: step 850, loss 0.446165, acc 0.765625
2020-02-16T15:37:10.525016: step 851, loss 0.396125, acc 0.8125
2020-02-16T15:37:10.645436: step 852, loss 0.438706, acc 0.796875
2020-02-16T15:37:10.785820: step 853, loss 0.490732, acc 0.796875
2020-02-16T15:37:10.926311: step 854, loss 0.514139, acc 0.703125
2020-02-16T15:37:11.065325: step 855, loss 0.462862, acc 0.765625
2020-02-16T15:37:11.187105: step 856, loss 0.594289, acc 0.734375
2020-02-16T15:37:11.325632: step 857, loss 0.305063, acc 0.890625
2020-02-16T15:37:11.455787: step 858, loss 0.520756, acc 0.765625
2020-02-16T15:37:11.573533: step 859, loss 0.415847, acc 0.828125
2020-02-16T15:37:11.696412: step 860, loss 0.400594, acc 0.796875
2020-02-16T15:37:11.827374: step 861, loss 0.589463, acc 0.765625
2020-02-16T15:37:11.962336: step 862, loss 0.443544, acc 0.796875
2020-02-16T15:37:12.093401: step 863, loss 0.388867, acc 0.84375
2020-02-16T15:37:12.225967: step 864, loss 0.634689, acc 0.640625
2020-02-16T15:37:12.364822: step 865, loss 0.450189, acc 0.78125
2020-02-16T15:37:12.488009: step 866, loss 0.421514, acc 0.796875
2020-02-16T15:37:12.605597: step 867, loss 0.537719, acc 0.71875
2020-02-16T15:37:12.731036: step 868, loss 0.461601, acc 0.75
2020-02-16T15:37:12.876417: step 869, loss 0.254366, acc 0.921875
2020-02-16T15:37:13.012057: step 870, loss 0.417343, acc 0.8125
2020-02-16T15:37:13.145244: step 871, loss 0.507903, acc 0.703125
2020-02-16T15:37:13.279803: step 872, loss 0.348381, acc 0.84375
2020-02-16T15:37:13.417484: step 873, loss 0.370236, acc 0.828125
2020-02-16T15:37:13.541844: step 874, loss 0.405894, acc 0.8125
2020-02-16T15:37:13.663282: step 875, loss 0.355912, acc 0.859375
2020-02-16T15:37:13.796688: step 876, loss 0.461364, acc 0.734375
2020-02-16T15:37:13.935391: step 877, loss 0.455005, acc 0.796875
2020-02-16T15:37:14.074816: step 878, loss 0.471357, acc 0.765625
2020-02-16T15:37:14.204558: step 879, loss 0.50272, acc 0.765625
2020-02-16T15:37:14.348170: step 880, loss 0.456529, acc 0.765625
2020-02-16T15:37:14.471381: step 881, loss 0.559758, acc 0.765625
2020-02-16T15:37:14.588407: step 882, loss 0.471798, acc 0.75
2020-02-16T15:37:14.710368: step 883, loss 0.515445, acc 0.75
2020-02-16T15:37:14.849786: step 884, loss 0.418356, acc 0.78125
2020-02-16T15:37:14.999272: step 885, loss 0.406457, acc 0.859375
2020-02-16T15:37:15.135547: step 886, loss 0.439932, acc 0.78125
2020-02-16T15:37:15.265850: step 887, loss 0.607992, acc 0.734375
2020-02-16T15:37:15.409374: step 888, loss 0.554697, acc 0.75
2020-02-16T15:37:15.528029: step 889, loss 0.394783, acc 0.828125
2020-02-16T15:37:15.646433: step 890, loss 0.337177, acc 0.84375
2020-02-16T15:37:15.772493: step 891, loss 0.617631, acc 0.671875
2020-02-16T15:37:15.915941: step 892, loss 0.539122, acc 0.734375
2020-02-16T15:37:16.046607: step 893, loss 0.418929, acc 0.828125
2020-02-16T15:37:16.171866: step 894, loss 0.447729, acc 0.78125
2020-02-16T15:37:16.316207: step 895, loss 0.407827, acc 0.84375
2020-02-16T15:37:16.455105: step 896, loss 0.27628, acc 0.90625
2020-02-16T15:37:16.574176: step 897, loss 0.448939, acc 0.796875
2020-02-16T15:37:16.695674: step 898, loss 0.309461, acc 0.90625
2020-02-16T15:37:16.831473: step 899, loss 0.458439, acc 0.796875
2020-02-16T15:37:16.958314: step 900, loss 0.355212, acc 0.833333

Evaluation:
2020-02-16T15:37:17.173921: step 900, loss 0.562982, acc 0.699812

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-900

2020-02-16T15:37:18.755487: step 901, loss 0.432455, acc 0.8125
2020-02-16T15:37:18.904244: step 902, loss 0.30084, acc 0.90625
2020-02-16T15:37:19.031910: step 903, loss 0.274827, acc 0.90625
2020-02-16T15:37:19.159508: step 904, loss 0.3508, acc 0.8125
2020-02-16T15:37:19.300796: step 905, loss 0.295761, acc 0.828125
2020-02-16T15:37:19.436776: step 906, loss 0.369543, acc 0.828125
2020-02-16T15:37:19.556056: step 907, loss 0.471237, acc 0.78125
2020-02-16T15:37:19.675971: step 908, loss 0.430496, acc 0.796875
2020-02-16T15:37:19.810476: step 909, loss 0.357507, acc 0.8125
2020-02-16T15:37:19.951034: step 910, loss 0.378168, acc 0.8125
2020-02-16T15:37:20.083919: step 911, loss 0.32549, acc 0.828125
2020-02-16T15:37:20.310774: step 912, loss 0.506072, acc 0.78125
2020-02-16T15:37:20.508714: step 913, loss 0.427325, acc 0.796875
2020-02-16T15:37:20.678423: step 914, loss 0.459101, acc 0.796875
2020-02-16T15:37:20.817739: step 915, loss 0.316243, acc 0.859375
2020-02-16T15:37:21.041763: step 916, loss 0.260145, acc 0.921875
2020-02-16T15:37:21.171350: step 917, loss 0.371037, acc 0.796875
2020-02-16T15:37:21.314167: step 918, loss 0.399075, acc 0.828125
2020-02-16T15:37:21.441373: step 919, loss 0.347196, acc 0.859375
2020-02-16T15:37:21.575726: step 920, loss 0.265756, acc 0.875
2020-02-16T15:37:21.729431: step 921, loss 0.300804, acc 0.890625
2020-02-16T15:37:21.866371: step 922, loss 0.3131, acc 0.890625
2020-02-16T15:37:21.998921: step 923, loss 0.389701, acc 0.828125
2020-02-16T15:37:22.128126: step 924, loss 0.333816, acc 0.828125
2020-02-16T15:37:22.264081: step 925, loss 0.386946, acc 0.84375
2020-02-16T15:37:22.407189: step 926, loss 0.331342, acc 0.859375
2020-02-16T15:37:22.542912: step 927, loss 0.445881, acc 0.8125
2020-02-16T15:37:22.763281: step 928, loss 0.293569, acc 0.828125
2020-02-16T15:37:22.957602: step 929, loss 0.360165, acc 0.8125
2020-02-16T15:37:23.159624: step 930, loss 0.331432, acc 0.859375
2020-02-16T15:37:23.344536: step 931, loss 0.287104, acc 0.875
2020-02-16T15:37:23.541764: step 932, loss 0.476285, acc 0.765625
2020-02-16T15:37:23.662320: step 933, loss 0.346023, acc 0.890625
2020-02-16T15:37:23.814042: step 934, loss 0.347163, acc 0.84375
2020-02-16T15:37:23.957663: step 935, loss 0.352341, acc 0.84375
2020-02-16T15:37:24.139344: step 936, loss 0.436823, acc 0.8125
2020-02-16T15:37:24.298511: step 937, loss 0.33392, acc 0.859375
2020-02-16T15:37:24.424835: step 938, loss 0.373086, acc 0.859375
2020-02-16T15:37:24.543733: step 939, loss 0.295699, acc 0.90625
2020-02-16T15:37:24.661916: step 940, loss 0.413739, acc 0.796875
2020-02-16T15:37:24.800642: step 941, loss 0.315557, acc 0.859375
2020-02-16T15:37:24.946491: step 942, loss 0.30407, acc 0.875
2020-02-16T15:37:25.073373: step 943, loss 0.277122, acc 0.921875
2020-02-16T15:37:25.199417: step 944, loss 0.369971, acc 0.84375
2020-02-16T15:37:25.349974: step 945, loss 0.399325, acc 0.78125
2020-02-16T15:37:25.467825: step 946, loss 0.401922, acc 0.8125
2020-02-16T15:37:25.585578: step 947, loss 0.330096, acc 0.84375
2020-02-16T15:37:25.707686: step 948, loss 0.395754, acc 0.828125
2020-02-16T15:37:25.853333: step 949, loss 0.372422, acc 0.84375
2020-02-16T15:37:25.984689: step 950, loss 0.330022, acc 0.84375
2020-02-16T15:37:26.117929: step 951, loss 0.365334, acc 0.796875
2020-02-16T15:37:26.253250: step 952, loss 0.463199, acc 0.78125
2020-02-16T15:37:26.398432: step 953, loss 0.374157, acc 0.828125
2020-02-16T15:37:26.516965: step 954, loss 0.328672, acc 0.875
2020-02-16T15:37:26.634245: step 955, loss 0.459506, acc 0.734375
2020-02-16T15:37:26.761243: step 956, loss 0.289017, acc 0.890625
2020-02-16T15:37:26.906040: step 957, loss 0.438496, acc 0.765625
2020-02-16T15:37:27.031086: step 958, loss 0.366291, acc 0.828125
2020-02-16T15:37:27.159204: step 959, loss 0.432105, acc 0.8125
2020-02-16T15:37:27.304842: step 960, loss 0.427189, acc 0.84375
2020-02-16T15:37:27.434617: step 961, loss 0.383887, acc 0.859375
2020-02-16T15:37:27.552885: step 962, loss 0.231446, acc 0.90625
2020-02-16T15:37:27.670991: step 963, loss 0.330209, acc 0.828125
2020-02-16T15:37:27.809674: step 964, loss 0.361567, acc 0.859375
2020-02-16T15:37:27.944543: step 965, loss 0.471547, acc 0.8125
2020-02-16T15:37:28.067972: step 966, loss 0.333462, acc 0.859375
2020-02-16T15:37:28.197551: step 967, loss 0.402008, acc 0.796875
2020-02-16T15:37:28.343409: step 968, loss 0.325506, acc 0.859375
2020-02-16T15:37:28.464239: step 969, loss 0.429558, acc 0.8125
2020-02-16T15:37:28.581636: step 970, loss 0.388736, acc 0.796875
2020-02-16T15:37:28.705100: step 971, loss 0.341736, acc 0.859375
2020-02-16T15:37:28.849257: step 972, loss 0.353256, acc 0.859375
2020-02-16T15:37:28.975446: step 973, loss 0.216672, acc 0.9375
2020-02-16T15:37:29.105537: step 974, loss 0.399235, acc 0.796875
2020-02-16T15:37:29.232547: step 975, loss 0.389071, acc 0.859375
2020-02-16T15:37:29.376117: step 976, loss 0.341495, acc 0.84375
2020-02-16T15:37:29.493035: step 977, loss 0.342058, acc 0.859375
2020-02-16T15:37:29.609933: step 978, loss 0.402913, acc 0.828125
2020-02-16T15:37:29.744854: step 979, loss 0.331728, acc 0.828125
2020-02-16T15:37:29.888619: step 980, loss 0.326691, acc 0.84375
2020-02-16T15:37:30.024056: step 981, loss 0.328914, acc 0.8125
2020-02-16T15:37:30.163845: step 982, loss 0.307368, acc 0.84375
2020-02-16T15:37:30.306007: step 983, loss 0.283507, acc 0.90625
2020-02-16T15:37:30.443268: step 984, loss 0.279844, acc 0.890625
2020-02-16T15:37:30.560312: step 985, loss 0.353434, acc 0.84375
2020-02-16T15:37:30.882844: step 986, loss 0.383631, acc 0.84375
2020-02-16T15:37:31.033820: step 987, loss 0.354881, acc 0.8125
2020-02-16T15:37:31.162330: step 988, loss 0.377783, acc 0.859375
2020-02-16T15:37:31.301175: step 989, loss 0.279879, acc 0.90625
2020-02-16T15:37:31.438587: step 990, loss 0.451406, acc 0.8125
2020-02-16T15:37:31.556066: step 991, loss 0.391639, acc 0.84375
2020-02-16T15:37:31.679692: step 992, loss 0.355018, acc 0.796875
2020-02-16T15:37:31.816498: step 993, loss 0.36177, acc 0.890625
2020-02-16T15:37:31.958062: step 994, loss 0.296148, acc 0.90625
2020-02-16T15:37:32.092990: step 995, loss 0.373148, acc 0.8125
2020-02-16T15:37:32.216812: step 996, loss 0.472806, acc 0.75
2020-02-16T15:37:32.363181: step 997, loss 0.429267, acc 0.8125
2020-02-16T15:37:32.484173: step 998, loss 0.302554, acc 0.875
2020-02-16T15:37:32.641408: step 999, loss 0.428195, acc 0.859375
2020-02-16T15:37:32.771727: step 1000, loss 0.367311, acc 0.84375

Evaluation:
2020-02-16T15:37:33.005716: step 1000, loss 0.570099, acc 0.712946

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1000

2020-02-16T15:37:34.598543: step 1001, loss 0.343076, acc 0.875
2020-02-16T15:37:34.727578: step 1002, loss 0.426304, acc 0.84375
2020-02-16T15:37:34.879990: step 1003, loss 0.387321, acc 0.796875
2020-02-16T15:37:35.014889: step 1004, loss 0.393355, acc 0.796875
2020-02-16T15:37:35.147752: step 1005, loss 0.395439, acc 0.828125
2020-02-16T15:37:35.281031: step 1006, loss 0.443873, acc 0.765625
2020-02-16T15:37:35.417233: step 1007, loss 0.311927, acc 0.859375
2020-02-16T15:37:35.536126: step 1008, loss 0.403576, acc 0.796875
2020-02-16T15:37:35.657480: step 1009, loss 0.344372, acc 0.84375
2020-02-16T15:37:35.790411: step 1010, loss 0.371315, acc 0.859375
2020-02-16T15:37:35.933149: step 1011, loss 0.259366, acc 0.890625
2020-02-16T15:37:36.067094: step 1012, loss 0.386041, acc 0.84375
2020-02-16T15:37:36.193012: step 1013, loss 0.517331, acc 0.765625
2020-02-16T15:37:36.339818: step 1014, loss 0.327844, acc 0.84375
2020-02-16T15:37:36.463151: step 1015, loss 0.428686, acc 0.75
2020-02-16T15:37:36.585287: step 1016, loss 0.267385, acc 0.859375
2020-02-16T15:37:36.707874: step 1017, loss 0.428114, acc 0.796875
2020-02-16T15:37:36.842007: step 1018, loss 0.239196, acc 0.890625
2020-02-16T15:37:36.975196: step 1019, loss 0.431585, acc 0.75
2020-02-16T15:37:37.103291: step 1020, loss 0.249581, acc 0.90625
2020-02-16T15:37:37.229241: step 1021, loss 0.275415, acc 0.90625
2020-02-16T15:37:37.367123: step 1022, loss 0.314202, acc 0.84375
2020-02-16T15:37:37.487575: step 1023, loss 0.449837, acc 0.796875
2020-02-16T15:37:37.606939: step 1024, loss 0.48002, acc 0.796875
2020-02-16T15:37:37.734285: step 1025, loss 0.451268, acc 0.765625
2020-02-16T15:37:37.877064: step 1026, loss 0.433164, acc 0.796875
2020-02-16T15:37:38.012743: step 1027, loss 0.327428, acc 0.84375
2020-02-16T15:37:38.148439: step 1028, loss 0.447632, acc 0.78125
2020-02-16T15:37:38.281041: step 1029, loss 0.295685, acc 0.859375
2020-02-16T15:37:38.416483: step 1030, loss 0.452104, acc 0.703125
2020-02-16T15:37:38.539496: step 1031, loss 0.407856, acc 0.828125
2020-02-16T15:37:38.655608: step 1032, loss 0.376727, acc 0.828125
2020-02-16T15:37:38.783579: step 1033, loss 0.333491, acc 0.859375
2020-02-16T15:37:38.917121: step 1034, loss 0.338615, acc 0.8125
2020-02-16T15:37:39.053063: step 1035, loss 0.554548, acc 0.78125
2020-02-16T15:37:39.182696: step 1036, loss 0.421346, acc 0.828125
2020-02-16T15:37:39.323241: step 1037, loss 0.524413, acc 0.78125
2020-02-16T15:37:39.453634: step 1038, loss 0.306949, acc 0.921875
2020-02-16T15:37:39.570709: step 1039, loss 0.329748, acc 0.859375
2020-02-16T15:37:39.694237: step 1040, loss 0.492878, acc 0.796875
2020-02-16T15:37:39.834629: step 1041, loss 0.425338, acc 0.796875
2020-02-16T15:37:39.966558: step 1042, loss 0.235129, acc 0.875
2020-02-16T15:37:40.093973: step 1043, loss 0.290064, acc 0.90625
2020-02-16T15:37:40.219399: step 1044, loss 0.513304, acc 0.765625
2020-02-16T15:37:40.362646: step 1045, loss 0.277427, acc 0.875
2020-02-16T15:37:40.482937: step 1046, loss 0.269273, acc 0.875
2020-02-16T15:37:40.602723: step 1047, loss 0.350486, acc 0.796875
2020-02-16T15:37:40.727592: step 1048, loss 0.290956, acc 0.875
2020-02-16T15:37:40.876758: step 1049, loss 0.247317, acc 0.921875
2020-02-16T15:37:41.007402: step 1050, loss 0.305646, acc 0.883333
2020-02-16T15:37:41.146808: step 1051, loss 0.203161, acc 0.953125
2020-02-16T15:37:41.301004: step 1052, loss 0.222247, acc 0.9375
2020-02-16T15:37:41.429989: step 1053, loss 0.312586, acc 0.90625
2020-02-16T15:37:41.551879: step 1054, loss 0.312091, acc 0.859375
2020-02-16T15:37:41.668160: step 1055, loss 0.281524, acc 0.921875
2020-02-16T15:37:41.801867: step 1056, loss 0.278863, acc 0.90625
2020-02-16T15:37:41.939964: step 1057, loss 0.339045, acc 0.765625
2020-02-16T15:37:42.073527: step 1058, loss 0.393237, acc 0.84375
2020-02-16T15:37:42.204387: step 1059, loss 0.224605, acc 0.921875
2020-02-16T15:37:42.346239: step 1060, loss 0.378407, acc 0.875
2020-02-16T15:37:42.472325: step 1061, loss 0.278511, acc 0.921875
2020-02-16T15:37:42.591990: step 1062, loss 0.314504, acc 0.828125
2020-02-16T15:37:42.713707: step 1063, loss 0.273077, acc 0.890625
2020-02-16T15:37:42.860238: step 1064, loss 0.228284, acc 0.921875
2020-02-16T15:37:43.013033: step 1065, loss 0.322604, acc 0.875
2020-02-16T15:37:43.155255: step 1066, loss 0.313953, acc 0.859375
2020-02-16T15:37:43.343496: step 1067, loss 0.356592, acc 0.828125
2020-02-16T15:37:43.491347: step 1068, loss 0.222782, acc 0.953125
2020-02-16T15:37:43.627975: step 1069, loss 0.317528, acc 0.875
2020-02-16T15:37:43.812332: step 1070, loss 0.256234, acc 0.859375
2020-02-16T15:37:43.964511: step 1071, loss 0.29252, acc 0.859375
2020-02-16T15:37:44.095563: step 1072, loss 0.345188, acc 0.890625
2020-02-16T15:37:44.221253: step 1073, loss 0.413268, acc 0.84375
2020-02-16T15:37:44.360267: step 1074, loss 0.386572, acc 0.8125
2020-02-16T15:37:44.485266: step 1075, loss 0.24105, acc 0.890625
2020-02-16T15:37:44.606173: step 1076, loss 0.322526, acc 0.890625
2020-02-16T15:37:44.733702: step 1077, loss 0.272815, acc 0.90625
2020-02-16T15:37:44.881736: step 1078, loss 0.338903, acc 0.875
2020-02-16T15:37:45.020489: step 1079, loss 0.278108, acc 0.90625
2020-02-16T15:37:45.152146: step 1080, loss 0.302786, acc 0.84375
2020-02-16T15:37:45.295391: step 1081, loss 0.349146, acc 0.875
2020-02-16T15:37:45.430392: step 1082, loss 0.333518, acc 0.84375
2020-02-16T15:37:45.553064: step 1083, loss 0.309132, acc 0.875
2020-02-16T15:37:45.673366: step 1084, loss 0.247812, acc 0.90625
2020-02-16T15:37:45.799657: step 1085, loss 0.395341, acc 0.84375
2020-02-16T15:37:45.940157: step 1086, loss 0.294063, acc 0.890625
2020-02-16T15:37:46.074503: step 1087, loss 0.301634, acc 0.859375
2020-02-16T15:37:46.203703: step 1088, loss 0.307112, acc 0.859375
2020-02-16T15:37:46.348370: step 1089, loss 0.23802, acc 0.9375
2020-02-16T15:37:46.469134: step 1090, loss 0.248416, acc 0.875
2020-02-16T15:37:46.590750: step 1091, loss 0.264928, acc 0.921875
2020-02-16T15:37:46.712487: step 1092, loss 0.248027, acc 0.9375
2020-02-16T15:37:46.847496: step 1093, loss 0.271372, acc 0.890625
2020-02-16T15:37:47.014191: step 1094, loss 0.271901, acc 0.890625
2020-02-16T15:37:47.174647: step 1095, loss 0.338439, acc 0.828125
2020-02-16T15:37:47.329230: step 1096, loss 0.261651, acc 0.890625
2020-02-16T15:37:47.469950: step 1097, loss 0.223719, acc 0.921875
2020-02-16T15:37:47.605112: step 1098, loss 0.331208, acc 0.828125
2020-02-16T15:37:47.761779: step 1099, loss 0.193546, acc 0.9375
2020-02-16T15:37:47.922289: step 1100, loss 0.225896, acc 0.9375

Evaluation:
2020-02-16T15:37:48.208184: step 1100, loss 0.555315, acc 0.712008

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1100

2020-02-16T15:37:49.822701: step 1101, loss 0.378357, acc 0.8125
2020-02-16T15:37:49.959382: step 1102, loss 0.303968, acc 0.859375
2020-02-16T15:37:50.092805: step 1103, loss 0.243351, acc 0.90625
2020-02-16T15:37:50.219865: step 1104, loss 0.333226, acc 0.859375
2020-02-16T15:37:50.377694: step 1105, loss 0.21452, acc 0.9375
2020-02-16T15:37:50.501988: step 1106, loss 0.240471, acc 0.921875
2020-02-16T15:37:50.618681: step 1107, loss 0.315089, acc 0.875
2020-02-16T15:37:50.751698: step 1108, loss 0.332922, acc 0.859375
2020-02-16T15:37:50.891171: step 1109, loss 0.26129, acc 0.875
2020-02-16T15:37:51.027510: step 1110, loss 0.306305, acc 0.890625
2020-02-16T15:37:51.158428: step 1111, loss 0.241044, acc 0.90625
2020-02-16T15:37:51.303898: step 1112, loss 0.408015, acc 0.875
2020-02-16T15:37:51.441500: step 1113, loss 0.343894, acc 0.890625
2020-02-16T15:37:51.562013: step 1114, loss 0.28797, acc 0.875
2020-02-16T15:37:51.684903: step 1115, loss 0.300397, acc 0.9375
2020-02-16T15:37:51.818093: step 1116, loss 0.236875, acc 0.890625
2020-02-16T15:37:51.960721: step 1117, loss 0.39481, acc 0.78125
2020-02-16T15:37:52.096027: step 1118, loss 0.307921, acc 0.875
2020-02-16T15:37:52.224895: step 1119, loss 0.162505, acc 0.921875
2020-02-16T15:37:52.370024: step 1120, loss 0.340474, acc 0.8125
2020-02-16T15:37:52.491476: step 1121, loss 0.209941, acc 0.9375
2020-02-16T15:37:52.613418: step 1122, loss 0.282341, acc 0.875
2020-02-16T15:37:52.740301: step 1123, loss 0.313104, acc 0.875
2020-02-16T15:37:52.876039: step 1124, loss 0.211428, acc 0.921875
2020-02-16T15:37:53.012357: step 1125, loss 0.257463, acc 0.921875
2020-02-16T15:37:53.150416: step 1126, loss 0.272724, acc 0.921875
2020-02-16T15:37:53.286243: step 1127, loss 0.311791, acc 0.875
2020-02-16T15:37:53.421022: step 1128, loss 0.402676, acc 0.765625
2020-02-16T15:37:53.541930: step 1129, loss 0.329835, acc 0.875
2020-02-16T15:37:53.660094: step 1130, loss 0.336621, acc 0.8125
2020-02-16T15:37:53.790955: step 1131, loss 0.2444, acc 0.890625
2020-02-16T15:37:53.934836: step 1132, loss 0.386928, acc 0.828125
2020-02-16T15:37:54.112960: step 1133, loss 0.212239, acc 0.921875
2020-02-16T15:37:54.243535: step 1134, loss 0.267562, acc 0.921875
2020-02-16T15:37:54.390064: step 1135, loss 0.352517, acc 0.859375
2020-02-16T15:37:54.514543: step 1136, loss 0.254354, acc 0.875
2020-02-16T15:37:54.631914: step 1137, loss 0.253469, acc 0.90625
2020-02-16T15:37:54.758063: step 1138, loss 0.305185, acc 0.890625
2020-02-16T15:37:54.911149: step 1139, loss 0.337221, acc 0.859375
2020-02-16T15:37:55.053470: step 1140, loss 0.228497, acc 0.9375
2020-02-16T15:37:55.213300: step 1141, loss 0.31936, acc 0.875
2020-02-16T15:37:55.372288: step 1142, loss 0.373463, acc 0.859375
2020-02-16T15:37:55.515337: step 1143, loss 0.268712, acc 0.890625
2020-02-16T15:37:55.657156: step 1144, loss 0.323161, acc 0.859375
2020-02-16T15:37:55.809504: step 1145, loss 0.21065, acc 0.921875
2020-02-16T15:37:55.961379: step 1146, loss 0.231786, acc 0.875
2020-02-16T15:37:56.118048: step 1147, loss 0.219325, acc 0.90625
2020-02-16T15:37:56.277872: step 1148, loss 0.288081, acc 0.890625
2020-02-16T15:37:56.433067: step 1149, loss 0.204992, acc 0.90625
2020-02-16T15:37:56.570325: step 1150, loss 0.207686, acc 0.921875
2020-02-16T15:37:56.716984: step 1151, loss 0.184725, acc 0.953125
2020-02-16T15:37:56.876485: step 1152, loss 0.316346, acc 0.859375
2020-02-16T15:37:57.029998: step 1153, loss 0.327311, acc 0.875
2020-02-16T15:37:57.178015: step 1154, loss 0.292846, acc 0.84375
2020-02-16T15:37:57.331062: step 1155, loss 0.421714, acc 0.84375
2020-02-16T15:37:57.477209: step 1156, loss 0.273097, acc 0.90625
2020-02-16T15:37:57.597577: step 1157, loss 0.366572, acc 0.8125
2020-02-16T15:37:57.727522: step 1158, loss 0.320759, acc 0.84375
2020-02-16T15:37:57.872982: step 1159, loss 0.253931, acc 0.875
2020-02-16T15:37:58.000986: step 1160, loss 0.36811, acc 0.796875
2020-02-16T15:37:58.139523: step 1161, loss 0.303151, acc 0.90625
2020-02-16T15:37:58.277187: step 1162, loss 0.185892, acc 0.953125
2020-02-16T15:37:58.416258: step 1163, loss 0.242979, acc 0.90625
2020-02-16T15:37:58.537678: step 1164, loss 0.263334, acc 0.890625
2020-02-16T15:37:58.657631: step 1165, loss 0.367808, acc 0.828125
2020-02-16T15:37:58.794339: step 1166, loss 0.343777, acc 0.84375
2020-02-16T15:37:58.933261: step 1167, loss 0.325794, acc 0.859375
2020-02-16T15:37:59.086858: step 1168, loss 0.294429, acc 0.8125
2020-02-16T15:37:59.230753: step 1169, loss 0.213523, acc 0.9375
2020-02-16T15:37:59.380654: step 1170, loss 0.283511, acc 0.875
2020-02-16T15:37:59.501549: step 1171, loss 0.257078, acc 0.9375
2020-02-16T15:37:59.624804: step 1172, loss 0.37149, acc 0.8125
2020-02-16T15:37:59.756388: step 1173, loss 0.380288, acc 0.828125
2020-02-16T15:37:59.897401: step 1174, loss 0.243638, acc 0.90625
2020-02-16T15:38:00.033515: step 1175, loss 0.334095, acc 0.8125
2020-02-16T15:38:00.164114: step 1176, loss 0.353927, acc 0.796875
2020-02-16T15:38:00.304070: step 1177, loss 0.265517, acc 0.90625
2020-02-16T15:38:00.443419: step 1178, loss 0.301438, acc 0.875
2020-02-16T15:38:00.566700: step 1179, loss 0.271168, acc 0.875
2020-02-16T15:38:00.935219: step 1180, loss 0.311294, acc 0.890625
2020-02-16T15:38:01.093972: step 1181, loss 0.315521, acc 0.859375
2020-02-16T15:38:01.219873: step 1182, loss 0.315394, acc 0.875
2020-02-16T15:38:01.365087: step 1183, loss 0.36856, acc 0.8125
2020-02-16T15:38:01.485640: step 1184, loss 0.229655, acc 0.921875
2020-02-16T15:38:01.611496: step 1185, loss 0.278517, acc 0.90625
2020-02-16T15:38:01.741918: step 1186, loss 0.334209, acc 0.84375
2020-02-16T15:38:01.886931: step 1187, loss 0.275802, acc 0.90625
2020-02-16T15:38:02.025729: step 1188, loss 0.391962, acc 0.8125
2020-02-16T15:38:02.159264: step 1189, loss 0.349614, acc 0.828125
2020-02-16T15:38:02.302714: step 1190, loss 0.281765, acc 0.875
2020-02-16T15:38:02.435087: step 1191, loss 0.247357, acc 0.90625
2020-02-16T15:38:02.555903: step 1192, loss 0.388213, acc 0.859375
2020-02-16T15:38:02.678082: step 1193, loss 0.263962, acc 0.90625
2020-02-16T15:38:02.810338: step 1194, loss 0.266476, acc 0.84375
2020-02-16T15:38:02.955856: step 1195, loss 0.319726, acc 0.875
2020-02-16T15:38:03.093025: step 1196, loss 0.324828, acc 0.890625
2020-02-16T15:38:03.225975: step 1197, loss 0.222737, acc 0.90625
2020-02-16T15:38:03.373713: step 1198, loss 0.303389, acc 0.90625
2020-02-16T15:38:03.497248: step 1199, loss 0.237663, acc 0.90625
2020-02-16T15:38:03.614575: step 1200, loss 0.353678, acc 0.866667

Evaluation:
2020-02-16T15:38:03.842540: step 1200, loss 0.55203, acc 0.709193

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1200

2020-02-16T15:38:05.448647: step 1201, loss 0.189149, acc 0.953125
2020-02-16T15:38:05.565138: step 1202, loss 0.17737, acc 0.96875
2020-02-16T15:38:05.689489: step 1203, loss 0.311167, acc 0.875
2020-02-16T15:38:05.827839: step 1204, loss 0.185527, acc 0.90625
2020-02-16T15:38:05.964561: step 1205, loss 0.184411, acc 0.96875
2020-02-16T15:38:06.092444: step 1206, loss 0.289107, acc 0.875
2020-02-16T15:38:06.225519: step 1207, loss 0.236189, acc 0.921875
2020-02-16T15:38:06.373701: step 1208, loss 0.295129, acc 0.90625
2020-02-16T15:38:06.495184: step 1209, loss 0.321077, acc 0.828125
2020-02-16T15:38:06.617870: step 1210, loss 0.304406, acc 0.890625
2020-02-16T15:38:06.755090: step 1211, loss 0.242891, acc 0.921875
2020-02-16T15:38:06.908250: step 1212, loss 0.234217, acc 0.921875
2020-02-16T15:38:07.040271: step 1213, loss 0.19303, acc 0.921875
2020-02-16T15:38:07.170860: step 1214, loss 0.21638, acc 0.9375
2020-02-16T15:38:07.314316: step 1215, loss 0.27812, acc 0.84375
2020-02-16T15:38:07.444966: step 1216, loss 0.223463, acc 0.9375
2020-02-16T15:38:07.565711: step 1217, loss 0.129534, acc 0.96875
2020-02-16T15:38:07.693096: step 1218, loss 0.231655, acc 0.921875
2020-02-16T15:38:07.838052: step 1219, loss 0.214079, acc 0.9375
2020-02-16T15:38:07.976347: step 1220, loss 0.332941, acc 0.859375
2020-02-16T15:38:08.108750: step 1221, loss 0.237606, acc 0.890625
2020-02-16T15:38:08.250607: step 1222, loss 0.12541, acc 1
2020-02-16T15:38:08.395186: step 1223, loss 0.149773, acc 0.9375
2020-02-16T15:38:08.514442: step 1224, loss 0.259363, acc 0.90625
2020-02-16T15:38:08.631818: step 1225, loss 0.162383, acc 0.90625
2020-02-16T15:38:08.760226: step 1226, loss 0.190109, acc 0.9375
2020-02-16T15:38:08.909322: step 1227, loss 0.230152, acc 0.921875
2020-02-16T15:38:09.036607: step 1228, loss 0.197757, acc 0.890625
2020-02-16T15:38:09.166496: step 1229, loss 0.161057, acc 0.953125
2020-02-16T15:38:09.314126: step 1230, loss 0.208633, acc 0.953125
2020-02-16T15:38:09.446623: step 1231, loss 0.222059, acc 0.890625
2020-02-16T15:38:09.562651: step 1232, loss 0.277616, acc 0.90625
2020-02-16T15:38:09.688915: step 1233, loss 0.238545, acc 0.890625
2020-02-16T15:38:09.833113: step 1234, loss 0.244283, acc 0.890625
2020-02-16T15:38:09.975232: step 1235, loss 0.175117, acc 0.921875
2020-02-16T15:38:10.106085: step 1236, loss 0.2182, acc 0.921875
2020-02-16T15:38:10.238677: step 1237, loss 0.167079, acc 0.96875
2020-02-16T15:38:10.385450: step 1238, loss 0.201844, acc 0.921875
2020-02-16T15:38:10.516755: step 1239, loss 0.300482, acc 0.90625
2020-02-16T15:38:10.636022: step 1240, loss 0.183376, acc 0.921875
2020-02-16T15:38:10.764552: step 1241, loss 0.278545, acc 0.875
2020-02-16T15:38:10.911362: step 1242, loss 0.131595, acc 0.96875
2020-02-16T15:38:11.044462: step 1243, loss 0.326848, acc 0.875
2020-02-16T15:38:11.170512: step 1244, loss 0.26535, acc 0.890625
2020-02-16T15:38:11.316598: step 1245, loss 0.245054, acc 0.921875
2020-02-16T15:38:11.445608: step 1246, loss 0.30209, acc 0.84375
2020-02-16T15:38:11.583048: step 1247, loss 0.203521, acc 0.921875
2020-02-16T15:38:11.737506: step 1248, loss 0.200375, acc 0.90625
2020-02-16T15:38:11.892212: step 1249, loss 0.152823, acc 0.953125
2020-02-16T15:38:12.049516: step 1250, loss 0.217811, acc 0.90625
2020-02-16T15:38:12.192028: step 1251, loss 0.208085, acc 0.921875
2020-02-16T15:38:12.365275: step 1252, loss 0.182238, acc 0.890625
2020-02-16T15:38:12.505774: step 1253, loss 0.267704, acc 0.890625
2020-02-16T15:38:12.643163: step 1254, loss 0.26233, acc 0.890625
2020-02-16T15:38:12.800707: step 1255, loss 0.265162, acc 0.90625
2020-02-16T15:38:12.946194: step 1256, loss 0.184376, acc 0.921875
2020-02-16T15:38:13.099405: step 1257, loss 0.163709, acc 0.9375
2020-02-16T15:38:13.254465: step 1258, loss 0.31652, acc 0.859375
2020-02-16T15:38:13.404431: step 1259, loss 0.163384, acc 0.9375
2020-02-16T15:38:13.545135: step 1260, loss 0.234275, acc 0.859375
2020-02-16T15:38:13.669755: step 1261, loss 0.229424, acc 0.90625
2020-02-16T15:38:13.815906: step 1262, loss 0.222349, acc 0.90625
2020-02-16T15:38:13.980908: step 1263, loss 0.332967, acc 0.84375
2020-02-16T15:38:14.114711: step 1264, loss 0.330465, acc 0.859375
2020-02-16T15:38:14.251321: step 1265, loss 0.211285, acc 0.90625
2020-02-16T15:38:14.422262: step 1266, loss 0.208522, acc 0.90625
2020-02-16T15:38:14.546281: step 1267, loss 0.204436, acc 0.953125
2020-02-16T15:38:14.664601: step 1268, loss 0.265476, acc 0.875
2020-02-16T15:38:14.803787: step 1269, loss 0.193352, acc 0.9375
2020-02-16T15:38:14.958118: step 1270, loss 0.272202, acc 0.875
2020-02-16T15:38:15.093116: step 1271, loss 0.279677, acc 0.921875
2020-02-16T15:38:15.223843: step 1272, loss 0.22047, acc 0.90625
2020-02-16T15:38:15.370330: step 1273, loss 0.250935, acc 0.90625
2020-02-16T15:38:15.491584: step 1274, loss 0.281357, acc 0.859375
2020-02-16T15:38:15.609713: step 1275, loss 0.17524, acc 0.9375
2020-02-16T15:38:15.740319: step 1276, loss 0.308893, acc 0.84375
2020-02-16T15:38:15.875666: step 1277, loss 0.266416, acc 0.890625
2020-02-16T15:38:16.016314: step 1278, loss 0.27457, acc 0.84375
2020-02-16T15:38:16.142560: step 1279, loss 0.252073, acc 0.890625
2020-02-16T15:38:16.283272: step 1280, loss 0.156823, acc 0.9375
2020-02-16T15:38:16.417116: step 1281, loss 0.330138, acc 0.875
2020-02-16T15:38:16.536277: step 1282, loss 0.345309, acc 0.859375
2020-02-16T15:38:16.655320: step 1283, loss 0.131657, acc 0.96875
2020-02-16T15:38:16.791013: step 1284, loss 0.264794, acc 0.90625
2020-02-16T15:38:16.939900: step 1285, loss 0.327832, acc 0.890625
2020-02-16T15:38:17.077159: step 1286, loss 0.161985, acc 0.953125
2020-02-16T15:38:17.207687: step 1287, loss 0.257753, acc 0.921875
2020-02-16T15:38:17.359592: step 1288, loss 0.222584, acc 0.890625
2020-02-16T15:38:17.479138: step 1289, loss 0.269353, acc 0.890625
2020-02-16T15:38:17.599934: step 1290, loss 0.174352, acc 0.90625
2020-02-16T15:38:17.722672: step 1291, loss 0.301818, acc 0.859375
2020-02-16T15:38:17.865292: step 1292, loss 0.256313, acc 0.859375
2020-02-16T15:38:17.998616: step 1293, loss 0.204978, acc 0.953125
2020-02-16T15:38:18.134306: step 1294, loss 0.175006, acc 0.9375
2020-02-16T15:38:18.274289: step 1295, loss 0.20437, acc 0.921875
2020-02-16T15:38:18.412490: step 1296, loss 0.261099, acc 0.859375
2020-02-16T15:38:18.528150: step 1297, loss 0.245959, acc 0.90625
2020-02-16T15:38:18.646413: step 1298, loss 0.182427, acc 0.9375
2020-02-16T15:38:18.776372: step 1299, loss 0.230237, acc 0.921875
2020-02-16T15:38:18.924750: step 1300, loss 0.32873, acc 0.828125

Evaluation:
2020-02-16T15:38:19.144692: step 1300, loss 0.569569, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1300

2020-02-16T15:38:20.890777: step 1301, loss 0.279268, acc 0.890625
2020-02-16T15:38:21.025215: step 1302, loss 0.219053, acc 0.921875
2020-02-16T15:38:21.156221: step 1303, loss 0.1918, acc 0.9375
2020-02-16T15:38:21.300628: step 1304, loss 0.240365, acc 0.90625
2020-02-16T15:38:21.436197: step 1305, loss 0.272918, acc 0.90625
2020-02-16T15:38:21.554439: step 1306, loss 0.139673, acc 0.953125
2020-02-16T15:38:21.675431: step 1307, loss 0.243411, acc 0.859375
2020-02-16T15:38:21.810001: step 1308, loss 0.20502, acc 0.921875
2020-02-16T15:38:21.950134: step 1309, loss 0.242683, acc 0.90625
2020-02-16T15:38:22.085773: step 1310, loss 0.159542, acc 0.953125
2020-02-16T15:38:22.221744: step 1311, loss 0.326724, acc 0.875
2020-02-16T15:38:22.368070: step 1312, loss 0.292354, acc 0.890625
2020-02-16T15:38:22.489243: step 1313, loss 0.308914, acc 0.84375
2020-02-16T15:38:22.606416: step 1314, loss 0.180421, acc 0.90625
2020-02-16T15:38:22.739819: step 1315, loss 0.289624, acc 0.828125
2020-02-16T15:38:22.885522: step 1316, loss 0.372282, acc 0.859375
2020-02-16T15:38:23.018391: step 1317, loss 0.203727, acc 0.90625
2020-02-16T15:38:23.147754: step 1318, loss 0.275864, acc 0.859375
2020-02-16T15:38:23.288033: step 1319, loss 0.227634, acc 0.90625
2020-02-16T15:38:23.423336: step 1320, loss 0.278954, acc 0.890625
2020-02-16T15:38:23.541583: step 1321, loss 0.309279, acc 0.890625
2020-02-16T15:38:23.660239: step 1322, loss 0.213506, acc 0.921875
2020-02-16T15:38:23.803448: step 1323, loss 0.255301, acc 0.90625
2020-02-16T15:38:23.943838: step 1324, loss 0.302152, acc 0.859375
2020-02-16T15:38:24.094657: step 1325, loss 0.25354, acc 0.859375
2020-02-16T15:38:24.281398: step 1326, loss 0.271978, acc 0.90625
2020-02-16T15:38:24.414964: step 1327, loss 0.263341, acc 0.921875
2020-02-16T15:38:24.534579: step 1328, loss 0.21309, acc 0.9375
2020-02-16T15:38:24.653808: step 1329, loss 0.286138, acc 0.90625
2020-02-16T15:38:24.795990: step 1330, loss 0.227449, acc 0.890625
2020-02-16T15:38:24.947360: step 1331, loss 0.223074, acc 0.921875
2020-02-16T15:38:25.081301: step 1332, loss 0.321536, acc 0.890625
2020-02-16T15:38:25.217353: step 1333, loss 0.253382, acc 0.9375
2020-02-16T15:38:25.366142: step 1334, loss 0.305871, acc 0.875
2020-02-16T15:38:25.485545: step 1335, loss 0.284533, acc 0.859375
2020-02-16T15:38:25.606216: step 1336, loss 0.177124, acc 0.9375
2020-02-16T15:38:25.737363: step 1337, loss 0.300704, acc 0.875
2020-02-16T15:38:25.887172: step 1338, loss 0.222394, acc 0.921875
2020-02-16T15:38:26.019100: step 1339, loss 0.214781, acc 0.953125
2020-02-16T15:38:26.151560: step 1340, loss 0.182485, acc 0.921875
2020-02-16T15:38:26.292267: step 1341, loss 0.214636, acc 0.953125
2020-02-16T15:38:26.430588: step 1342, loss 0.406437, acc 0.828125
2020-02-16T15:38:26.550519: step 1343, loss 0.294385, acc 0.921875
2020-02-16T15:38:26.671989: step 1344, loss 0.289093, acc 0.859375
2020-02-16T15:38:26.802647: step 1345, loss 0.372868, acc 0.828125
2020-02-16T15:38:26.946264: step 1346, loss 0.274015, acc 0.890625
2020-02-16T15:38:27.080839: step 1347, loss 0.173244, acc 0.921875
2020-02-16T15:38:27.222271: step 1348, loss 0.366151, acc 0.828125
2020-02-16T15:38:27.372889: step 1349, loss 0.21972, acc 0.90625
2020-02-16T15:38:27.489115: step 1350, loss 0.205435, acc 0.95
2020-02-16T15:38:27.614193: step 1351, loss 0.126413, acc 0.953125
2020-02-16T15:38:27.745502: step 1352, loss 0.181322, acc 0.921875
2020-02-16T15:38:27.893260: step 1353, loss 0.187544, acc 0.9375
2020-02-16T15:38:28.026413: step 1354, loss 0.248374, acc 0.875
2020-02-16T15:38:28.158844: step 1355, loss 0.221696, acc 0.890625
2020-02-16T15:38:28.298872: step 1356, loss 0.139613, acc 0.984375
2020-02-16T15:38:28.440085: step 1357, loss 0.180109, acc 0.921875
2020-02-16T15:38:28.561837: step 1358, loss 0.237631, acc 0.859375
2020-02-16T15:38:28.685847: step 1359, loss 0.154602, acc 0.9375
2020-02-16T15:38:28.813850: step 1360, loss 0.251898, acc 0.859375
2020-02-16T15:38:28.960425: step 1361, loss 0.160162, acc 0.921875
2020-02-16T15:38:29.097365: step 1362, loss 0.154514, acc 0.9375
2020-02-16T15:38:29.254904: step 1363, loss 0.135054, acc 0.9375
2020-02-16T15:38:29.398347: step 1364, loss 0.176441, acc 0.9375
2020-02-16T15:38:29.516559: step 1365, loss 0.170299, acc 0.9375
2020-02-16T15:38:29.637628: step 1366, loss 0.185483, acc 0.90625
2020-02-16T15:38:29.770759: step 1367, loss 0.102032, acc 1
2020-02-16T15:38:29.907127: step 1368, loss 0.225443, acc 0.890625
2020-02-16T15:38:30.151816: step 1369, loss 0.124609, acc 0.984375
2020-02-16T15:38:30.301693: step 1370, loss 0.213574, acc 0.875
2020-02-16T15:38:30.508471: step 1371, loss 0.246945, acc 0.890625
2020-02-16T15:38:30.637189: step 1372, loss 0.14234, acc 0.9375
2020-02-16T15:38:30.773724: step 1373, loss 0.21065, acc 0.90625
2020-02-16T15:38:30.991770: step 1374, loss 0.266188, acc 0.890625
2020-02-16T15:38:31.208325: step 1375, loss 0.180333, acc 0.9375
2020-02-16T15:38:31.362949: step 1376, loss 0.28389, acc 0.890625
2020-02-16T15:38:31.499700: step 1377, loss 0.142812, acc 0.984375
2020-02-16T15:38:31.652146: step 1378, loss 0.189408, acc 0.921875
2020-02-16T15:38:31.797593: step 1379, loss 0.16729, acc 0.953125
2020-02-16T15:38:31.939917: step 1380, loss 0.147318, acc 0.9375
2020-02-16T15:38:32.075205: step 1381, loss 0.244811, acc 0.921875
2020-02-16T15:38:32.203542: step 1382, loss 0.137201, acc 0.9375
2020-02-16T15:38:32.352234: step 1383, loss 0.202095, acc 0.90625
2020-02-16T15:38:32.471506: step 1384, loss 0.170486, acc 0.90625
2020-02-16T15:38:32.615290: step 1385, loss 0.222987, acc 0.890625
2020-02-16T15:38:32.763659: step 1386, loss 0.124443, acc 0.9375
2020-02-16T15:38:32.900943: step 1387, loss 0.161323, acc 0.953125
2020-02-16T15:38:33.024928: step 1388, loss 0.193479, acc 0.921875
2020-02-16T15:38:33.158976: step 1389, loss 0.116607, acc 0.96875
2020-02-16T15:38:33.312770: step 1390, loss 0.149073, acc 0.9375
2020-02-16T15:38:33.437753: step 1391, loss 0.188342, acc 0.9375
2020-02-16T15:38:33.559008: step 1392, loss 0.13672, acc 0.9375
2020-02-16T15:38:33.681855: step 1393, loss 0.139715, acc 0.953125
2020-02-16T15:38:33.814946: step 1394, loss 0.086721, acc 0.984375
2020-02-16T15:38:33.951480: step 1395, loss 0.187076, acc 0.90625
2020-02-16T15:38:34.083225: step 1396, loss 0.124007, acc 0.953125
2020-02-16T15:38:34.213546: step 1397, loss 0.18026, acc 0.953125
2020-02-16T15:38:34.365606: step 1398, loss 0.17277, acc 0.921875
2020-02-16T15:38:34.509237: step 1399, loss 0.216758, acc 0.9375
2020-02-16T15:38:34.655359: step 1400, loss 0.232827, acc 0.90625

Evaluation:
2020-02-16T15:38:34.979887: step 1400, loss 0.580031, acc 0.726079

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1400

2020-02-16T15:38:37.705094: step 1401, loss 0.141663, acc 0.953125
2020-02-16T15:38:37.861780: step 1402, loss 0.214779, acc 0.90625
2020-02-16T15:38:37.999446: step 1403, loss 0.286454, acc 0.890625
2020-02-16T15:38:38.141842: step 1404, loss 0.203443, acc 0.921875
2020-02-16T15:38:38.364516: step 1405, loss 0.112991, acc 0.953125
2020-02-16T15:38:38.488755: step 1406, loss 0.331939, acc 0.890625
2020-02-16T15:38:38.608615: step 1407, loss 0.136722, acc 0.9375
2020-02-16T15:38:38.740398: step 1408, loss 0.12038, acc 0.953125
2020-02-16T15:38:38.906177: step 1409, loss 0.162071, acc 0.9375
2020-02-16T15:38:39.061672: step 1410, loss 0.111293, acc 0.984375
2020-02-16T15:38:39.202340: step 1411, loss 0.138742, acc 0.953125
2020-02-16T15:38:39.344727: step 1412, loss 0.219981, acc 0.921875
2020-02-16T15:38:39.470125: step 1413, loss 0.207893, acc 0.90625
2020-02-16T15:38:39.590296: step 1414, loss 0.196808, acc 0.921875
2020-02-16T15:38:39.719233: step 1415, loss 0.261067, acc 0.90625
2020-02-16T15:38:39.861304: step 1416, loss 0.0860107, acc 0.984375
2020-02-16T15:38:39.997239: step 1417, loss 0.171614, acc 0.953125
2020-02-16T15:38:40.135885: step 1418, loss 0.19285, acc 0.953125
2020-02-16T15:38:40.274882: step 1419, loss 0.152887, acc 0.9375
2020-02-16T15:38:40.418194: step 1420, loss 0.186499, acc 0.90625
2020-02-16T15:38:40.537243: step 1421, loss 0.230678, acc 0.890625
2020-02-16T15:38:40.658567: step 1422, loss 0.164247, acc 0.9375
2020-02-16T15:38:40.794072: step 1423, loss 0.100076, acc 0.96875
2020-02-16T15:38:40.939088: step 1424, loss 0.207391, acc 0.90625
2020-02-16T15:38:41.070119: step 1425, loss 0.178729, acc 0.921875
2020-02-16T15:38:41.199356: step 1426, loss 0.110568, acc 0.953125
2020-02-16T15:38:41.344893: step 1427, loss 0.127359, acc 0.96875
2020-02-16T15:38:41.474117: step 1428, loss 0.115984, acc 0.9375
2020-02-16T15:38:41.594736: step 1429, loss 0.20304, acc 0.90625
2020-02-16T15:38:41.721905: step 1430, loss 0.168935, acc 0.90625
2020-02-16T15:38:41.858537: step 1431, loss 0.241937, acc 0.9375
2020-02-16T15:38:41.994822: step 1432, loss 0.148555, acc 0.9375
2020-02-16T15:38:42.123054: step 1433, loss 0.175874, acc 0.9375
2020-02-16T15:38:42.263357: step 1434, loss 0.170344, acc 0.90625
2020-02-16T15:38:42.397384: step 1435, loss 0.147022, acc 0.953125
2020-02-16T15:38:42.518573: step 1436, loss 0.143204, acc 0.90625
2020-02-16T15:38:42.640240: step 1437, loss 0.144265, acc 0.984375
2020-02-16T15:38:42.765386: step 1438, loss 0.231108, acc 0.828125
2020-02-16T15:38:42.902592: step 1439, loss 0.220024, acc 0.890625
2020-02-16T15:38:43.026529: step 1440, loss 0.143769, acc 0.953125
2020-02-16T15:38:43.162010: step 1441, loss 0.192704, acc 0.90625
2020-02-16T15:38:43.299687: step 1442, loss 0.245715, acc 0.890625
2020-02-16T15:38:43.439141: step 1443, loss 0.221019, acc 0.921875
2020-02-16T15:38:43.561191: step 1444, loss 0.240729, acc 0.921875
2020-02-16T15:38:43.683726: step 1445, loss 0.13066, acc 0.953125
2020-02-16T15:38:43.811623: step 1446, loss 0.212569, acc 0.890625
2020-02-16T15:38:43.948983: step 1447, loss 0.160617, acc 0.96875
2020-02-16T15:38:44.084877: step 1448, loss 0.106001, acc 0.96875
2020-02-16T15:38:44.216802: step 1449, loss 0.267504, acc 0.890625
2020-02-16T15:38:44.362800: step 1450, loss 0.173344, acc 0.953125
2020-02-16T15:38:44.481600: step 1451, loss 0.149114, acc 0.9375
2020-02-16T15:38:44.605061: step 1452, loss 0.136448, acc 0.921875
2020-02-16T15:38:44.732216: step 1453, loss 0.258636, acc 0.90625
2020-02-16T15:38:44.870114: step 1454, loss 0.233353, acc 0.921875
2020-02-16T15:38:45.009598: step 1455, loss 0.244208, acc 0.890625
2020-02-16T15:38:45.141358: step 1456, loss 0.176018, acc 0.890625
2020-02-16T15:38:45.278912: step 1457, loss 0.110658, acc 0.96875
2020-02-16T15:38:45.412105: step 1458, loss 0.302705, acc 0.875
2020-02-16T15:38:45.529506: step 1459, loss 0.207825, acc 0.90625
2020-02-16T15:38:45.650430: step 1460, loss 0.185488, acc 0.953125
2020-02-16T15:38:45.787562: step 1461, loss 0.233639, acc 0.9375
2020-02-16T15:38:45.932709: step 1462, loss 0.161336, acc 0.90625
2020-02-16T15:38:46.065908: step 1463, loss 0.13941, acc 0.953125
2020-02-16T15:38:46.199260: step 1464, loss 0.140456, acc 0.96875
2020-02-16T15:38:46.337549: step 1465, loss 0.159147, acc 0.921875
2020-02-16T15:38:46.462547: step 1466, loss 0.0975148, acc 0.96875
2020-02-16T15:38:46.581691: step 1467, loss 0.19988, acc 0.9375
2020-02-16T15:38:46.707422: step 1468, loss 0.201583, acc 0.9375
2020-02-16T15:38:46.848252: step 1469, loss 0.327997, acc 0.890625
2020-02-16T15:38:46.974755: step 1470, loss 0.102809, acc 0.9375
2020-02-16T15:38:47.106199: step 1471, loss 0.218123, acc 0.875
2020-02-16T15:38:47.242769: step 1472, loss 0.222122, acc 0.90625
2020-02-16T15:38:47.394795: step 1473, loss 0.214308, acc 0.890625
2020-02-16T15:38:47.513022: step 1474, loss 0.171877, acc 0.9375
2020-02-16T15:38:47.647527: step 1475, loss 0.222507, acc 0.890625
2020-02-16T15:38:47.777262: step 1476, loss 0.24304, acc 0.90625
2020-02-16T15:38:47.922251: step 1477, loss 0.105164, acc 0.96875
2020-02-16T15:38:48.067663: step 1478, loss 0.261665, acc 0.859375
2020-02-16T15:38:48.206803: step 1479, loss 0.357646, acc 0.828125
2020-02-16T15:38:48.353332: step 1480, loss 0.141931, acc 0.9375
2020-02-16T15:38:48.469520: step 1481, loss 0.12341, acc 0.9375
2020-02-16T15:38:48.590535: step 1482, loss 0.205183, acc 0.90625
2020-02-16T15:38:48.716071: step 1483, loss 0.222713, acc 0.890625
2020-02-16T15:38:48.870583: step 1484, loss 0.171504, acc 0.953125
2020-02-16T15:38:49.022527: step 1485, loss 0.187441, acc 0.890625
2020-02-16T15:38:49.181019: step 1486, loss 0.219191, acc 0.9375
2020-02-16T15:38:49.345767: step 1487, loss 0.320165, acc 0.875
2020-02-16T15:38:49.488366: step 1488, loss 0.134586, acc 0.9375
2020-02-16T15:38:49.626303: step 1489, loss 0.237766, acc 0.890625
2020-02-16T15:38:49.771621: step 1490, loss 0.160442, acc 0.921875
2020-02-16T15:38:49.945681: step 1491, loss 0.132254, acc 0.953125
2020-02-16T15:38:50.102522: step 1492, loss 0.386908, acc 0.8125
2020-02-16T15:38:50.263022: step 1493, loss 0.230963, acc 0.90625
2020-02-16T15:38:50.420841: step 1494, loss 0.237971, acc 0.921875
2020-02-16T15:38:50.566893: step 1495, loss 0.189216, acc 0.9375
2020-02-16T15:38:50.705734: step 1496, loss 0.154385, acc 0.921875
2020-02-16T15:38:50.858115: step 1497, loss 0.224608, acc 0.90625
2020-02-16T15:38:51.011789: step 1498, loss 0.182995, acc 0.890625
2020-02-16T15:38:51.168240: step 1499, loss 0.253082, acc 0.890625
2020-02-16T15:38:51.327638: step 1500, loss 0.136268, acc 0.95

Evaluation:
2020-02-16T15:38:51.532297: step 1500, loss 0.590028, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1500

2020-02-16T15:38:53.124523: step 1501, loss 0.12196, acc 0.953125
2020-02-16T15:38:53.275845: step 1502, loss 0.15938, acc 0.921875
2020-02-16T15:38:53.485452: step 1503, loss 0.100043, acc 0.96875
2020-02-16T15:38:53.609552: step 1504, loss 0.0702096, acc 0.96875
2020-02-16T15:38:53.743946: step 1505, loss 0.0814376, acc 0.984375
2020-02-16T15:38:53.886873: step 1506, loss 0.155115, acc 0.9375
2020-02-16T15:38:54.017154: step 1507, loss 0.110108, acc 0.96875
2020-02-16T15:38:54.157529: step 1508, loss 0.144579, acc 0.953125
2020-02-16T15:38:54.276755: step 1509, loss 0.136841, acc 0.953125
2020-02-16T15:38:54.422263: step 1510, loss 0.140539, acc 0.921875
2020-02-16T15:38:54.571228: step 1511, loss 0.172684, acc 0.9375
2020-02-16T15:38:54.721645: step 1512, loss 0.200985, acc 0.90625
2020-02-16T15:38:54.866430: step 1513, loss 0.12253, acc 0.953125
2020-02-16T15:38:55.019681: step 1514, loss 0.128157, acc 0.96875
2020-02-16T15:38:55.143189: step 1515, loss 0.104324, acc 0.96875
2020-02-16T15:38:55.266275: step 1516, loss 0.163742, acc 0.921875
2020-02-16T15:38:55.397011: step 1517, loss 0.155332, acc 0.953125
2020-02-16T15:38:55.521598: step 1518, loss 0.173142, acc 0.984375
2020-02-16T15:38:55.645052: step 1519, loss 0.214559, acc 0.90625
2020-02-16T15:38:55.779090: step 1520, loss 0.184505, acc 0.921875
2020-02-16T15:38:55.910624: step 1521, loss 0.100355, acc 0.984375
2020-02-16T15:38:56.096176: step 1522, loss 0.156158, acc 0.921875
2020-02-16T15:38:56.219578: step 1523, loss 0.121269, acc 0.9375
2020-02-16T15:38:56.342519: step 1524, loss 0.121967, acc 0.984375
2020-02-16T15:38:56.468348: step 1525, loss 0.134479, acc 0.9375
2020-02-16T15:38:56.652229: step 1526, loss 0.0724033, acc 0.96875
2020-02-16T15:38:56.846141: step 1527, loss 0.112012, acc 0.9375
2020-02-16T15:38:56.966070: step 1528, loss 0.339951, acc 0.875
2020-02-16T15:38:57.176755: step 1529, loss 0.17636, acc 0.921875
2020-02-16T15:38:57.385981: step 1530, loss 0.0910944, acc 0.953125
2020-02-16T15:38:57.540266: step 1531, loss 0.147003, acc 0.953125
2020-02-16T15:38:57.675775: step 1532, loss 0.179266, acc 0.921875
2020-02-16T15:38:57.811038: step 1533, loss 0.174145, acc 0.9375
2020-02-16T15:38:58.015536: step 1534, loss 0.126815, acc 0.9375
2020-02-16T15:38:58.176256: step 1535, loss 0.0912537, acc 0.96875
2020-02-16T15:38:58.319543: step 1536, loss 0.087458, acc 0.984375
2020-02-16T15:38:58.515176: step 1537, loss 0.160219, acc 0.96875
2020-02-16T15:38:58.651171: step 1538, loss 0.0687727, acc 0.984375
2020-02-16T15:38:58.789619: step 1539, loss 0.0577732, acc 1
2020-02-16T15:38:58.914557: step 1540, loss 0.193357, acc 0.921875
2020-02-16T15:38:59.047936: step 1541, loss 0.0790005, acc 0.96875
2020-02-16T15:38:59.206565: step 1542, loss 0.0984368, acc 0.953125
2020-02-16T15:38:59.394525: step 1543, loss 0.140927, acc 0.984375
2020-02-16T15:38:59.534200: step 1544, loss 0.153001, acc 0.9375
2020-02-16T15:38:59.667184: step 1545, loss 0.215247, acc 0.90625
2020-02-16T15:38:59.792354: step 1546, loss 0.119109, acc 0.953125
2020-02-16T15:38:59.913231: step 1547, loss 0.118992, acc 0.953125
2020-02-16T15:39:00.049136: step 1548, loss 0.120819, acc 0.984375
2020-02-16T15:39:00.197328: step 1549, loss 0.126046, acc 0.953125
2020-02-16T15:39:00.327383: step 1550, loss 0.136601, acc 0.953125
2020-02-16T15:39:00.449539: step 1551, loss 0.109403, acc 0.953125
2020-02-16T15:39:00.728546: step 1552, loss 0.134903, acc 0.921875
2020-02-16T15:39:00.862718: step 1553, loss 0.0951686, acc 0.96875
2020-02-16T15:39:00.984153: step 1554, loss 0.13301, acc 0.953125
2020-02-16T15:39:01.130158: step 1555, loss 0.111452, acc 0.96875
2020-02-16T15:39:01.265540: step 1556, loss 0.181106, acc 0.9375
2020-02-16T15:39:01.399144: step 1557, loss 0.101944, acc 0.96875
2020-02-16T15:39:01.544929: step 1558, loss 0.142892, acc 0.9375
2020-02-16T15:39:01.681930: step 1559, loss 0.176384, acc 0.953125
2020-02-16T15:39:01.801985: step 1560, loss 0.191505, acc 0.921875
2020-02-16T15:39:01.919662: step 1561, loss 0.127808, acc 0.96875
2020-02-16T15:39:02.050893: step 1562, loss 0.169676, acc 0.921875
2020-02-16T15:39:02.196359: step 1563, loss 0.137541, acc 0.96875
2020-02-16T15:39:02.321683: step 1564, loss 0.238915, acc 0.890625
2020-02-16T15:39:02.449799: step 1565, loss 0.148146, acc 0.96875
2020-02-16T15:39:02.587529: step 1566, loss 0.086913, acc 0.96875
2020-02-16T15:39:02.716349: step 1567, loss 0.195929, acc 0.921875
2020-02-16T15:39:02.836132: step 1568, loss 0.203482, acc 0.9375
2020-02-16T15:39:02.957388: step 1569, loss 0.0870039, acc 0.96875
2020-02-16T15:39:03.098160: step 1570, loss 0.0886219, acc 0.96875
2020-02-16T15:39:03.240330: step 1571, loss 0.154887, acc 0.953125
2020-02-16T15:39:03.377053: step 1572, loss 0.113692, acc 0.921875
2020-02-16T15:39:03.515435: step 1573, loss 0.152779, acc 0.953125
2020-02-16T15:39:03.658035: step 1574, loss 0.15862, acc 0.953125
2020-02-16T15:39:03.786807: step 1575, loss 0.15576, acc 0.953125
2020-02-16T15:39:03.903664: step 1576, loss 0.187743, acc 0.921875
2020-02-16T15:39:04.039182: step 1577, loss 0.139471, acc 0.96875
2020-02-16T15:39:04.261438: step 1578, loss 0.134373, acc 0.9375
2020-02-16T15:39:04.399194: step 1579, loss 0.122151, acc 0.953125
2020-02-16T15:39:04.541949: step 1580, loss 0.14875, acc 0.953125
2020-02-16T15:39:04.668757: step 1581, loss 0.0467447, acc 1
2020-02-16T15:39:04.793808: step 1582, loss 0.0912654, acc 0.953125
2020-02-16T15:39:04.914905: step 1583, loss 0.234207, acc 0.890625
2020-02-16T15:39:05.050724: step 1584, loss 0.118915, acc 0.953125
2020-02-16T15:39:05.199281: step 1585, loss 0.166065, acc 0.90625
2020-02-16T15:39:05.332081: step 1586, loss 0.21268, acc 0.921875
2020-02-16T15:39:05.460474: step 1587, loss 0.0686868, acc 0.984375
2020-02-16T15:39:05.600908: step 1588, loss 0.183193, acc 0.90625
2020-02-16T15:39:05.740107: step 1589, loss 0.233222, acc 0.921875
2020-02-16T15:39:05.859587: step 1590, loss 0.217166, acc 0.9375
2020-02-16T15:39:05.981740: step 1591, loss 0.119634, acc 0.984375
2020-02-16T15:39:06.120422: step 1592, loss 0.0816339, acc 0.96875
2020-02-16T15:39:06.262885: step 1593, loss 0.11531, acc 0.984375
2020-02-16T15:39:06.399030: step 1594, loss 0.154162, acc 0.921875
2020-02-16T15:39:06.553646: step 1595, loss 0.189145, acc 0.9375
2020-02-16T15:39:06.687898: step 1596, loss 0.0878394, acc 0.953125
2020-02-16T15:39:06.811549: step 1597, loss 0.107889, acc 0.96875
2020-02-16T15:39:06.928591: step 1598, loss 0.132946, acc 0.9375
2020-02-16T15:39:07.064951: step 1599, loss 0.0878703, acc 0.984375
2020-02-16T15:39:07.207419: step 1600, loss 0.155067, acc 0.9375

Evaluation:
2020-02-16T15:39:07.424753: step 1600, loss 0.628554, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1600

2020-02-16T15:39:09.006151: step 1601, loss 0.191141, acc 0.90625
2020-02-16T15:39:09.157149: step 1602, loss 0.109187, acc 0.96875
2020-02-16T15:39:09.325591: step 1603, loss 0.175514, acc 0.9375
2020-02-16T15:39:09.472031: step 1604, loss 0.138859, acc 0.953125
2020-02-16T15:39:09.610041: step 1605, loss 0.16774, acc 0.921875
2020-02-16T15:39:09.746186: step 1606, loss 0.100874, acc 0.953125
2020-02-16T15:39:09.865686: step 1607, loss 0.0832032, acc 0.984375
2020-02-16T15:39:09.986283: step 1608, loss 0.112311, acc 0.96875
2020-02-16T15:39:10.128494: step 1609, loss 0.0658912, acc 0.984375
2020-02-16T15:39:10.264887: step 1610, loss 0.178161, acc 0.921875
2020-02-16T15:39:10.399503: step 1611, loss 0.14988, acc 0.921875
2020-02-16T15:39:10.543951: step 1612, loss 0.212004, acc 0.875
2020-02-16T15:39:10.672503: step 1613, loss 0.183308, acc 0.9375
2020-02-16T15:39:10.796809: step 1614, loss 0.226939, acc 0.921875
2020-02-16T15:39:10.915963: step 1615, loss 0.148407, acc 0.9375
2020-02-16T15:39:11.046597: step 1616, loss 0.100815, acc 0.953125
2020-02-16T15:39:11.193096: step 1617, loss 0.0991643, acc 0.96875
2020-02-16T15:39:11.318481: step 1618, loss 0.122893, acc 0.953125
2020-02-16T15:39:11.444259: step 1619, loss 0.109044, acc 0.953125
2020-02-16T15:39:11.584289: step 1620, loss 0.247659, acc 0.90625
2020-02-16T15:39:11.710648: step 1621, loss 0.233499, acc 0.921875
2020-02-16T15:39:11.830670: step 1622, loss 0.155171, acc 0.9375
2020-02-16T15:39:11.951816: step 1623, loss 0.111418, acc 0.953125
2020-02-16T15:39:12.086832: step 1624, loss 0.175926, acc 0.9375
2020-02-16T15:39:12.226369: step 1625, loss 0.105473, acc 0.953125
2020-02-16T15:39:12.358201: step 1626, loss 0.137903, acc 0.9375
2020-02-16T15:39:12.486536: step 1627, loss 0.0938747, acc 0.96875
2020-02-16T15:39:12.626962: step 1628, loss 0.165336, acc 0.9375
2020-02-16T15:39:12.759063: step 1629, loss 0.0999904, acc 0.96875
2020-02-16T15:39:12.879021: step 1630, loss 0.142875, acc 0.96875
2020-02-16T15:39:13.002983: step 1631, loss 0.138468, acc 0.953125
2020-02-16T15:39:13.144132: step 1632, loss 0.162599, acc 0.90625
2020-02-16T15:39:13.275327: step 1633, loss 0.120496, acc 0.953125
2020-02-16T15:39:13.417727: step 1634, loss 0.15348, acc 0.890625
2020-02-16T15:39:13.557799: step 1635, loss 0.287356, acc 0.90625
2020-02-16T15:39:13.685532: step 1636, loss 0.170495, acc 0.953125
2020-02-16T15:39:13.805744: step 1637, loss 0.341558, acc 0.859375
2020-02-16T15:39:13.926902: step 1638, loss 0.129079, acc 0.953125
2020-02-16T15:39:14.062785: step 1639, loss 0.187118, acc 0.9375
2020-02-16T15:39:14.204615: step 1640, loss 0.164864, acc 0.9375
2020-02-16T15:39:14.331942: step 1641, loss 0.0748483, acc 0.984375
2020-02-16T15:39:14.462198: step 1642, loss 0.0787704, acc 0.984375
2020-02-16T15:39:14.603956: step 1643, loss 0.240073, acc 0.890625
2020-02-16T15:39:14.741855: step 1644, loss 0.109006, acc 0.953125
2020-02-16T15:39:14.865970: step 1645, loss 0.0856812, acc 0.96875
2020-02-16T15:39:14.993621: step 1646, loss 0.210549, acc 0.9375
2020-02-16T15:39:15.141093: step 1647, loss 0.131321, acc 0.953125
2020-02-16T15:39:15.271979: step 1648, loss 0.117192, acc 0.96875
2020-02-16T15:39:15.410002: step 1649, loss 0.161931, acc 0.9375
2020-02-16T15:39:15.553761: step 1650, loss 0.26426, acc 0.9
2020-02-16T15:39:15.684886: step 1651, loss 0.142974, acc 0.9375
2020-02-16T15:39:15.804753: step 1652, loss 0.218166, acc 0.921875
2020-02-16T15:39:15.923930: step 1653, loss 0.0574071, acc 0.984375
2020-02-16T15:39:16.066059: step 1654, loss 0.0962242, acc 0.96875
2020-02-16T15:39:16.208992: step 1655, loss 0.0953824, acc 0.96875
2020-02-16T15:39:16.338061: step 1656, loss 0.0765118, acc 0.953125
2020-02-16T15:39:16.462904: step 1657, loss 0.101929, acc 0.96875
2020-02-16T15:39:16.607414: step 1658, loss 0.0542094, acc 0.984375
2020-02-16T15:39:16.743897: step 1659, loss 0.0416284, acc 0.984375
2020-02-16T15:39:16.862379: step 1660, loss 0.102849, acc 0.96875
2020-02-16T15:39:16.985977: step 1661, loss 0.0719157, acc 1
2020-02-16T15:39:17.129696: step 1662, loss 0.156399, acc 0.953125
2020-02-16T15:39:17.268925: step 1663, loss 0.0613744, acc 0.984375
2020-02-16T15:39:17.401551: step 1664, loss 0.138228, acc 0.953125
2020-02-16T15:39:17.544981: step 1665, loss 0.0680398, acc 0.984375
2020-02-16T15:39:17.686329: step 1666, loss 0.103558, acc 0.953125
2020-02-16T15:39:17.802454: step 1667, loss 0.0941664, acc 0.96875
2020-02-16T15:39:17.921137: step 1668, loss 0.102599, acc 0.953125
2020-02-16T15:39:18.059734: step 1669, loss 0.062446, acc 0.984375
2020-02-16T15:39:18.203854: step 1670, loss 0.062939, acc 0.984375
2020-02-16T15:39:18.330837: step 1671, loss 0.0926558, acc 0.96875
2020-02-16T15:39:18.463788: step 1672, loss 0.119993, acc 0.9375
2020-02-16T15:39:18.608527: step 1673, loss 0.145227, acc 0.953125
2020-02-16T15:39:18.742010: step 1674, loss 0.121295, acc 0.9375
2020-02-16T15:39:18.862563: step 1675, loss 0.183367, acc 0.90625
2020-02-16T15:39:18.984388: step 1676, loss 0.0701916, acc 0.984375
2020-02-16T15:39:19.126716: step 1677, loss 0.0918524, acc 0.96875
2020-02-16T15:39:19.265170: step 1678, loss 0.124763, acc 0.9375
2020-02-16T15:39:19.396337: step 1679, loss 0.0827489, acc 0.984375
2020-02-16T15:39:19.543775: step 1680, loss 0.0984154, acc 0.96875
2020-02-16T15:39:19.672027: step 1681, loss 0.176507, acc 0.9375
2020-02-16T15:39:19.792676: step 1682, loss 0.118973, acc 0.953125
2020-02-16T15:39:19.912462: step 1683, loss 0.122864, acc 0.9375
2020-02-16T15:39:20.052755: step 1684, loss 0.108017, acc 0.96875
2020-02-16T15:39:20.197781: step 1685, loss 0.153609, acc 0.953125
2020-02-16T15:39:20.321765: step 1686, loss 0.0947381, acc 0.953125
2020-02-16T15:39:20.447003: step 1687, loss 0.122847, acc 0.9375
2020-02-16T15:39:20.594070: step 1688, loss 0.124892, acc 0.9375
2020-02-16T15:39:20.724856: step 1689, loss 0.0689309, acc 0.984375
2020-02-16T15:39:20.843541: step 1690, loss 0.0743865, acc 0.96875
2020-02-16T15:39:20.965935: step 1691, loss 0.0519437, acc 0.984375
2020-02-16T15:39:21.113739: step 1692, loss 0.0788744, acc 0.96875
2020-02-16T15:39:21.253175: step 1693, loss 0.0701968, acc 0.984375
2020-02-16T15:39:21.392951: step 1694, loss 0.096894, acc 0.96875
2020-02-16T15:39:21.535525: step 1695, loss 0.0651649, acc 0.984375
2020-02-16T15:39:21.670692: step 1696, loss 0.0767062, acc 0.984375
2020-02-16T15:39:21.797994: step 1697, loss 0.11432, acc 0.984375
2020-02-16T15:39:21.916018: step 1698, loss 0.0574934, acc 0.984375
2020-02-16T15:39:22.052248: step 1699, loss 0.133767, acc 0.921875
2020-02-16T15:39:22.200871: step 1700, loss 0.0733097, acc 1

Evaluation:
2020-02-16T15:39:22.419113: step 1700, loss 0.627646, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1700

2020-02-16T15:39:24.030463: step 1701, loss 0.176364, acc 0.96875
2020-02-16T15:39:24.172859: step 1702, loss 0.12437, acc 0.953125
2020-02-16T15:39:24.302514: step 1703, loss 0.0951209, acc 0.96875
2020-02-16T15:39:24.433494: step 1704, loss 0.102704, acc 0.96875
2020-02-16T15:39:24.580754: step 1705, loss 0.0580378, acc 0.984375
2020-02-16T15:39:24.709343: step 1706, loss 0.176129, acc 0.921875
2020-02-16T15:39:24.830702: step 1707, loss 0.157066, acc 0.921875
2020-02-16T15:39:24.960913: step 1708, loss 0.100866, acc 0.953125
2020-02-16T15:39:25.105623: step 1709, loss 0.143704, acc 0.9375
2020-02-16T15:39:25.245980: step 1710, loss 0.215596, acc 0.875
2020-02-16T15:39:25.378043: step 1711, loss 0.119352, acc 0.953125
2020-02-16T15:39:25.517980: step 1712, loss 0.191147, acc 0.90625
2020-02-16T15:39:25.646831: step 1713, loss 0.0846077, acc 0.96875
2020-02-16T15:39:25.770032: step 1714, loss 0.179252, acc 0.9375
2020-02-16T15:39:25.888962: step 1715, loss 0.0761232, acc 0.984375
2020-02-16T15:39:26.015975: step 1716, loss 0.12159, acc 0.984375
2020-02-16T15:39:26.158128: step 1717, loss 0.0660617, acc 1
2020-02-16T15:39:26.290837: step 1718, loss 0.111128, acc 0.921875
2020-02-16T15:39:26.421581: step 1719, loss 0.111405, acc 0.96875
2020-02-16T15:39:26.566388: step 1720, loss 0.0961018, acc 0.96875
2020-02-16T15:39:26.693321: step 1721, loss 0.207746, acc 0.921875
2020-02-16T15:39:26.811634: step 1722, loss 0.0620458, acc 1
2020-02-16T15:39:26.931623: step 1723, loss 0.212039, acc 0.9375
2020-02-16T15:39:27.072394: step 1724, loss 0.124811, acc 0.9375
2020-02-16T15:39:27.208319: step 1725, loss 0.037612, acc 1
2020-02-16T15:39:27.334761: step 1726, loss 0.273843, acc 0.921875
2020-02-16T15:39:27.464778: step 1727, loss 0.0789382, acc 0.984375
2020-02-16T15:39:27.604456: step 1728, loss 0.152414, acc 0.90625
2020-02-16T15:39:27.738259: step 1729, loss 0.143482, acc 0.96875
2020-02-16T15:39:27.855355: step 1730, loss 0.0957602, acc 0.96875
2020-02-16T15:39:27.971692: step 1731, loss 0.167801, acc 0.9375
2020-02-16T15:39:28.114074: step 1732, loss 0.225566, acc 0.9375
2020-02-16T15:39:28.252246: step 1733, loss 0.0861745, acc 0.96875
2020-02-16T15:39:28.386277: step 1734, loss 0.143701, acc 0.96875
2020-02-16T15:39:28.525958: step 1735, loss 0.0739603, acc 0.984375
2020-02-16T15:39:28.660681: step 1736, loss 0.228901, acc 0.890625
2020-02-16T15:39:28.788659: step 1737, loss 0.0877918, acc 0.96875
2020-02-16T15:39:28.912954: step 1738, loss 0.0931608, acc 0.953125
2020-02-16T15:39:29.045220: step 1739, loss 0.128247, acc 0.953125
2020-02-16T15:39:29.187755: step 1740, loss 0.117846, acc 0.953125
2020-02-16T15:39:29.311580: step 1741, loss 0.174702, acc 0.96875
2020-02-16T15:39:29.444198: step 1742, loss 0.14127, acc 0.9375
2020-02-16T15:39:29.579720: step 1743, loss 0.104807, acc 0.96875
2020-02-16T15:39:29.705754: step 1744, loss 0.0752338, acc 0.96875
2020-02-16T15:39:29.823229: step 1745, loss 0.126229, acc 0.953125
2020-02-16T15:39:29.943465: step 1746, loss 0.0917915, acc 0.984375
2020-02-16T15:39:30.089630: step 1747, loss 0.136824, acc 0.9375
2020-02-16T15:39:30.227496: step 1748, loss 0.0489129, acc 0.984375
2020-02-16T15:39:30.356530: step 1749, loss 0.10005, acc 0.96875
2020-02-16T15:39:30.492513: step 1750, loss 0.116916, acc 0.9375
2020-02-16T15:39:30.625580: step 1751, loss 0.10835, acc 0.984375
2020-02-16T15:39:30.830419: step 1752, loss 0.161606, acc 0.90625
2020-02-16T15:39:30.951578: step 1753, loss 0.031132, acc 1
2020-02-16T15:39:31.084551: step 1754, loss 0.116867, acc 0.96875
2020-02-16T15:39:31.220719: step 1755, loss 0.118684, acc 0.96875
2020-02-16T15:39:31.346452: step 1756, loss 0.115726, acc 0.96875
2020-02-16T15:39:31.474266: step 1757, loss 0.0783876, acc 0.984375
2020-02-16T15:39:31.611502: step 1758, loss 0.0879248, acc 0.984375
2020-02-16T15:39:31.749437: step 1759, loss 0.155712, acc 0.921875
2020-02-16T15:39:31.869091: step 1760, loss 0.0640303, acc 0.984375
2020-02-16T15:39:31.988518: step 1761, loss 0.148663, acc 0.953125
2020-02-16T15:39:32.133113: step 1762, loss 0.080799, acc 0.96875
2020-02-16T15:39:32.267561: step 1763, loss 0.109522, acc 0.96875
2020-02-16T15:39:32.403357: step 1764, loss 0.112422, acc 0.953125
2020-02-16T15:39:32.549629: step 1765, loss 0.15242, acc 0.921875
2020-02-16T15:39:32.743442: step 1766, loss 0.0620609, acc 0.984375
2020-02-16T15:39:32.863297: step 1767, loss 0.0562764, acc 0.984375
2020-02-16T15:39:32.987558: step 1768, loss 0.180213, acc 0.90625
2020-02-16T15:39:33.131758: step 1769, loss 0.106705, acc 0.953125
2020-02-16T15:39:33.273084: step 1770, loss 0.095491, acc 0.96875
2020-02-16T15:39:33.411697: step 1771, loss 0.106803, acc 0.953125
2020-02-16T15:39:33.551941: step 1772, loss 0.0372824, acc 1
2020-02-16T15:39:33.688697: step 1773, loss 0.0766527, acc 0.984375
2020-02-16T15:39:33.808885: step 1774, loss 0.146003, acc 0.921875
2020-02-16T15:39:33.928256: step 1775, loss 0.0787716, acc 0.953125
2020-02-16T15:39:34.064925: step 1776, loss 0.0629758, acc 1
2020-02-16T15:39:34.208980: step 1777, loss 0.139627, acc 0.953125
2020-02-16T15:39:34.339896: step 1778, loss 0.145454, acc 0.9375
2020-02-16T15:39:34.472916: step 1779, loss 0.144641, acc 0.953125
2020-02-16T15:39:34.612673: step 1780, loss 0.0819968, acc 0.953125
2020-02-16T15:39:34.739755: step 1781, loss 0.0332271, acc 1
2020-02-16T15:39:34.859183: step 1782, loss 0.0435971, acc 1
2020-02-16T15:39:34.987662: step 1783, loss 0.108252, acc 0.96875
2020-02-16T15:39:35.131495: step 1784, loss 0.0668054, acc 0.96875
2020-02-16T15:39:35.264560: step 1785, loss 0.148165, acc 0.96875
2020-02-16T15:39:35.400183: step 1786, loss 0.0351995, acc 1
2020-02-16T15:39:35.549431: step 1787, loss 0.142289, acc 0.953125
2020-02-16T15:39:35.682021: step 1788, loss 0.100841, acc 0.984375
2020-02-16T15:39:35.802961: step 1789, loss 0.135372, acc 0.90625
2020-02-16T15:39:35.922365: step 1790, loss 0.0750781, acc 0.96875
2020-02-16T15:39:36.055459: step 1791, loss 0.0752344, acc 0.96875
2020-02-16T15:39:36.203781: step 1792, loss 0.0978494, acc 0.984375
2020-02-16T15:39:36.333057: step 1793, loss 0.116448, acc 0.953125
2020-02-16T15:39:36.464016: step 1794, loss 0.284328, acc 0.890625
2020-02-16T15:39:36.601824: step 1795, loss 0.0619548, acc 0.96875
2020-02-16T15:39:36.741577: step 1796, loss 0.0929578, acc 0.96875
2020-02-16T15:39:36.860750: step 1797, loss 0.100829, acc 0.984375
2020-02-16T15:39:36.986185: step 1798, loss 0.264933, acc 0.890625
2020-02-16T15:39:37.128248: step 1799, loss 0.179101, acc 0.953125
2020-02-16T15:39:37.260673: step 1800, loss 0.144639, acc 0.933333

Evaluation:
2020-02-16T15:39:37.496386: step 1800, loss 0.657442, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1800

2020-02-16T15:39:39.111314: step 1801, loss 0.0939862, acc 0.96875
2020-02-16T15:39:39.252172: step 1802, loss 0.0493865, acc 1
2020-02-16T15:39:39.389039: step 1803, loss 0.0712938, acc 0.984375
2020-02-16T15:39:39.540257: step 1804, loss 0.0713283, acc 0.984375
2020-02-16T15:39:39.672192: step 1805, loss 0.16164, acc 0.953125
2020-02-16T15:39:39.794529: step 1806, loss 0.12408, acc 0.96875
2020-02-16T15:39:39.915048: step 1807, loss 0.053402, acc 0.96875
2020-02-16T15:39:40.043229: step 1808, loss 0.109436, acc 0.96875
2020-02-16T15:39:40.191000: step 1809, loss 0.0833772, acc 0.96875
2020-02-16T15:39:40.320117: step 1810, loss 0.122181, acc 0.953125
2020-02-16T15:39:40.443828: step 1811, loss 0.0401973, acc 1
2020-02-16T15:39:40.588238: step 1812, loss 0.0875002, acc 0.96875
2020-02-16T15:39:40.718085: step 1813, loss 0.120219, acc 0.9375
2020-02-16T15:39:40.839593: step 1814, loss 0.0973161, acc 0.96875
2020-02-16T15:39:40.960367: step 1815, loss 0.0460911, acc 0.96875
2020-02-16T15:39:41.107682: step 1816, loss 0.0678122, acc 0.984375
2020-02-16T15:39:41.253816: step 1817, loss 0.0944077, acc 0.96875
2020-02-16T15:39:41.387186: step 1818, loss 0.126363, acc 0.953125
2020-02-16T15:39:41.523710: step 1819, loss 0.0896257, acc 0.96875
2020-02-16T15:39:41.654370: step 1820, loss 0.0444659, acc 1
2020-02-16T15:39:41.781461: step 1821, loss 0.0908454, acc 0.953125
2020-02-16T15:39:41.901304: step 1822, loss 0.0769869, acc 0.96875
2020-02-16T15:39:42.023830: step 1823, loss 0.0790642, acc 0.984375
2020-02-16T15:39:42.167160: step 1824, loss 0.0774323, acc 0.96875
2020-02-16T15:39:42.299902: step 1825, loss 0.0532176, acc 0.96875
2020-02-16T15:39:42.438921: step 1826, loss 0.0432174, acc 0.984375
2020-02-16T15:39:42.578750: step 1827, loss 0.0691223, acc 0.953125
2020-02-16T15:39:42.707795: step 1828, loss 0.0540231, acc 0.984375
2020-02-16T15:39:42.830586: step 1829, loss 0.120929, acc 0.9375
2020-02-16T15:39:42.952265: step 1830, loss 0.0545454, acc 0.984375
2020-02-16T15:39:43.097460: step 1831, loss 0.106429, acc 0.96875
2020-02-16T15:39:43.244737: step 1832, loss 0.0471179, acc 1
2020-02-16T15:39:43.378335: step 1833, loss 0.0982267, acc 0.953125
2020-02-16T15:39:43.518974: step 1834, loss 0.0310384, acc 1
2020-02-16T15:39:43.657507: step 1835, loss 0.044954, acc 0.984375
2020-02-16T15:39:43.790683: step 1836, loss 0.0497997, acc 0.984375
2020-02-16T15:39:43.945172: step 1837, loss 0.114382, acc 0.9375
2020-02-16T15:39:44.150985: step 1838, loss 0.0975062, acc 0.96875
2020-02-16T15:39:44.327533: step 1839, loss 0.0471444, acc 1
2020-02-16T15:39:44.511498: step 1840, loss 0.0849729, acc 0.984375
2020-02-16T15:39:44.669501: step 1841, loss 0.0480523, acc 1
2020-02-16T15:39:44.818907: step 1842, loss 0.202262, acc 0.921875
2020-02-16T15:39:44.969880: step 1843, loss 0.056339, acc 0.984375
2020-02-16T15:39:45.148722: step 1844, loss 0.102207, acc 0.96875
2020-02-16T15:39:45.299025: step 1845, loss 0.092896, acc 0.96875
2020-02-16T15:39:45.442462: step 1846, loss 0.06744, acc 0.984375
2020-02-16T15:39:45.603457: step 1847, loss 0.0691859, acc 0.953125
2020-02-16T15:39:45.757648: step 1848, loss 0.107265, acc 0.953125
2020-02-16T15:39:45.894210: step 1849, loss 0.157956, acc 0.9375
2020-02-16T15:39:46.043869: step 1850, loss 0.106295, acc 0.953125
2020-02-16T15:39:46.207603: step 1851, loss 0.0871346, acc 0.984375
2020-02-16T15:39:46.356435: step 1852, loss 0.036891, acc 1
2020-02-16T15:39:46.515080: step 1853, loss 0.0833685, acc 0.96875
2020-02-16T15:39:46.672372: step 1854, loss 0.128582, acc 0.9375
2020-02-16T15:39:46.809094: step 1855, loss 0.099407, acc 0.96875
2020-02-16T15:39:46.942945: step 1856, loss 0.0983555, acc 0.953125
2020-02-16T15:39:47.103696: step 1857, loss 0.0947385, acc 0.953125
2020-02-16T15:39:47.262739: step 1858, loss 0.0931408, acc 0.953125
2020-02-16T15:39:47.418161: step 1859, loss 0.051014, acc 0.984375
2020-02-16T15:39:47.570330: step 1860, loss 0.065778, acc 0.984375
2020-02-16T15:39:47.731606: step 1861, loss 0.0744538, acc 0.96875
2020-02-16T15:39:47.873841: step 1862, loss 0.0903063, acc 0.953125
2020-02-16T15:39:48.022766: step 1863, loss 0.0661575, acc 0.96875
2020-02-16T15:39:48.189391: step 1864, loss 0.0851247, acc 0.96875
2020-02-16T15:39:48.316929: step 1865, loss 0.0430025, acc 0.984375
2020-02-16T15:39:48.450185: step 1866, loss 0.0653472, acc 1
2020-02-16T15:39:48.614787: step 1867, loss 0.0498627, acc 0.96875
2020-02-16T15:39:48.760288: step 1868, loss 0.114407, acc 0.9375
2020-02-16T15:39:48.895743: step 1869, loss 0.0293706, acc 1
2020-02-16T15:39:49.050529: step 1870, loss 0.0806891, acc 0.984375
2020-02-16T15:39:49.198884: step 1871, loss 0.134422, acc 0.953125
2020-02-16T15:39:49.344338: step 1872, loss 0.0415642, acc 0.984375
2020-02-16T15:39:49.500108: step 1873, loss 0.110374, acc 0.9375
2020-02-16T15:39:49.658994: step 1874, loss 0.104141, acc 0.953125
2020-02-16T15:39:49.797104: step 1875, loss 0.036708, acc 1
2020-02-16T15:39:49.923163: step 1876, loss 0.117918, acc 0.953125
2020-02-16T15:39:50.073746: step 1877, loss 0.110504, acc 0.96875
2020-02-16T15:39:50.236715: step 1878, loss 0.0496447, acc 1
2020-02-16T15:39:50.390533: step 1879, loss 0.0479604, acc 0.984375
2020-02-16T15:39:50.552326: step 1880, loss 0.0657254, acc 0.96875
2020-02-16T15:39:50.696416: step 1881, loss 0.0650837, acc 0.984375
2020-02-16T15:39:50.830566: step 1882, loss 0.0870978, acc 0.953125
2020-02-16T15:39:50.969235: step 1883, loss 0.0589385, acc 0.96875
2020-02-16T15:39:51.151494: step 1884, loss 0.209709, acc 0.953125
2020-02-16T15:39:51.295334: step 1885, loss 0.0682463, acc 0.984375
2020-02-16T15:39:51.429114: step 1886, loss 0.06234, acc 0.953125
2020-02-16T15:39:51.582736: step 1887, loss 0.0484539, acc 0.96875
2020-02-16T15:39:51.730420: step 1888, loss 0.100008, acc 0.96875
2020-02-16T15:39:51.864164: step 1889, loss 0.13404, acc 0.9375
2020-02-16T15:39:52.007622: step 1890, loss 0.0624573, acc 0.984375
2020-02-16T15:39:52.176824: step 1891, loss 0.153755, acc 0.9375
2020-02-16T15:39:52.311096: step 1892, loss 0.082711, acc 0.984375
2020-02-16T15:39:52.445148: step 1893, loss 0.044227, acc 0.984375
2020-02-16T15:39:52.614752: step 1894, loss 0.0439167, acc 1
2020-02-16T15:39:52.765937: step 1895, loss 0.0486184, acc 1
2020-02-16T15:39:52.900023: step 1896, loss 0.0721097, acc 1
2020-02-16T15:39:53.045294: step 1897, loss 0.101862, acc 0.953125
2020-02-16T15:39:53.190929: step 1898, loss 0.0804286, acc 0.953125
2020-02-16T15:39:53.340742: step 1899, loss 0.0451762, acc 1
2020-02-16T15:39:53.479581: step 1900, loss 0.0708296, acc 0.984375

Evaluation:
2020-02-16T15:39:53.735046: step 1900, loss 0.669997, acc 0.74015

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-1900

2020-02-16T15:39:55.420469: step 1901, loss 0.027345, acc 1
2020-02-16T15:39:55.588356: step 1902, loss 0.0752508, acc 0.984375
2020-02-16T15:39:55.746128: step 1903, loss 0.0917903, acc 0.96875
2020-02-16T15:39:55.882041: step 1904, loss 0.05258, acc 0.984375
2020-02-16T15:39:56.025187: step 1905, loss 0.202592, acc 0.90625
2020-02-16T15:39:56.197476: step 1906, loss 0.0513929, acc 0.984375
2020-02-16T15:39:56.348637: step 1907, loss 0.0644668, acc 0.984375
2020-02-16T15:39:56.491403: step 1908, loss 0.0445696, acc 0.984375
2020-02-16T15:39:56.651379: step 1909, loss 0.081048, acc 0.96875
2020-02-16T15:39:56.802468: step 1910, loss 0.0844769, acc 0.953125
2020-02-16T15:39:56.937292: step 1911, loss 0.0218336, acc 1
2020-02-16T15:39:57.101334: step 1912, loss 0.0636428, acc 0.984375
2020-02-16T15:39:57.269886: step 1913, loss 0.0536816, acc 1
2020-02-16T15:39:57.423698: step 1914, loss 0.0616758, acc 0.96875
2020-02-16T15:39:57.591744: step 1915, loss 0.0344082, acc 1
2020-02-16T15:39:57.735545: step 1916, loss 0.0416531, acc 0.984375
2020-02-16T15:39:57.870933: step 1917, loss 0.0583765, acc 0.984375
2020-02-16T15:39:58.006923: step 1918, loss 0.0641102, acc 0.984375
2020-02-16T15:39:58.180403: step 1919, loss 0.0477813, acc 0.96875
2020-02-16T15:39:58.335223: step 1920, loss 0.0849041, acc 0.984375
2020-02-16T15:39:58.498318: step 1921, loss 0.132611, acc 0.921875
2020-02-16T15:39:58.649043: step 1922, loss 0.0539403, acc 0.984375
2020-02-16T15:39:58.804466: step 1923, loss 0.114882, acc 0.96875
2020-02-16T15:39:58.934390: step 1924, loss 0.110134, acc 0.96875
2020-02-16T15:39:59.098882: step 1925, loss 0.100588, acc 0.953125
2020-02-16T15:39:59.265265: step 1926, loss 0.0889928, acc 0.96875
2020-02-16T15:39:59.416148: step 1927, loss 0.119675, acc 0.96875
2020-02-16T15:39:59.574074: step 1928, loss 0.119579, acc 0.9375
2020-02-16T15:39:59.740457: step 1929, loss 0.118274, acc 0.96875
2020-02-16T15:39:59.890208: step 1930, loss 0.1172, acc 0.9375
2020-02-16T15:40:00.050943: step 1931, loss 0.0966849, acc 0.9375
2020-02-16T15:40:00.215574: step 1932, loss 0.073932, acc 0.96875
2020-02-16T15:40:00.367007: step 1933, loss 0.0624717, acc 0.96875
2020-02-16T15:40:00.534733: step 1934, loss 0.0704221, acc 0.953125
2020-02-16T15:40:00.788358: step 1935, loss 0.101848, acc 0.9375
2020-02-16T15:40:00.921625: step 1936, loss 0.166248, acc 0.9375
2020-02-16T15:40:01.082001: step 1937, loss 0.0747211, acc 0.96875
2020-02-16T15:40:01.247229: step 1938, loss 0.20261, acc 0.921875
2020-02-16T15:40:01.397962: step 1939, loss 0.0677216, acc 0.96875
2020-02-16T15:40:01.567755: step 1940, loss 0.193729, acc 0.9375
2020-02-16T15:40:01.726164: step 1941, loss 0.0512687, acc 0.984375
2020-02-16T15:40:01.866559: step 1942, loss 0.107645, acc 0.9375
2020-02-16T15:40:02.012384: step 1943, loss 0.0791136, acc 0.953125
2020-02-16T15:40:02.185651: step 1944, loss 0.13282, acc 0.953125
2020-02-16T15:40:02.337681: step 1945, loss 0.0477849, acc 1
2020-02-16T15:40:02.480615: step 1946, loss 0.0993192, acc 0.953125
2020-02-16T15:40:02.630715: step 1947, loss 0.0542903, acc 1
2020-02-16T15:40:02.781510: step 1948, loss 0.142088, acc 0.96875
2020-02-16T15:40:02.922305: step 1949, loss 0.132337, acc 0.953125
2020-02-16T15:40:03.078447: step 1950, loss 0.0522224, acc 1
2020-02-16T15:40:03.230648: step 1951, loss 0.128624, acc 0.96875
2020-02-16T15:40:03.378854: step 1952, loss 0.0792511, acc 0.984375
2020-02-16T15:40:03.532234: step 1953, loss 0.0711598, acc 0.96875
2020-02-16T15:40:03.686841: step 1954, loss 0.0444036, acc 1
2020-02-16T15:40:03.828249: step 1955, loss 0.0523098, acc 1
2020-02-16T15:40:03.969984: step 1956, loss 0.0570598, acc 0.984375
2020-02-16T15:40:04.149444: step 1957, loss 0.0376181, acc 0.984375
2020-02-16T15:40:04.313073: step 1958, loss 0.0792929, acc 0.953125
2020-02-16T15:40:04.463235: step 1959, loss 0.0655261, acc 0.96875
2020-02-16T15:40:04.630993: step 1960, loss 0.0581548, acc 0.984375
2020-02-16T15:40:04.783002: step 1961, loss 0.0358204, acc 0.984375
2020-02-16T15:40:04.942991: step 1962, loss 0.0692905, acc 0.984375
2020-02-16T15:40:05.108580: step 1963, loss 0.0922599, acc 0.96875
2020-02-16T15:40:05.270134: step 1964, loss 0.0869358, acc 0.96875
2020-02-16T15:40:05.430700: step 1965, loss 0.0728844, acc 0.96875
2020-02-16T15:40:05.615051: step 1966, loss 0.0434118, acc 1
2020-02-16T15:40:05.766163: step 1967, loss 0.0617209, acc 0.984375
2020-02-16T15:40:05.908367: step 1968, loss 0.0201405, acc 1
2020-02-16T15:40:06.067005: step 1969, loss 0.0407569, acc 1
2020-02-16T15:40:06.233915: step 1970, loss 0.0773595, acc 0.96875
2020-02-16T15:40:06.381306: step 1971, loss 0.0408853, acc 1
2020-02-16T15:40:06.530354: step 1972, loss 0.033388, acc 0.984375
2020-02-16T15:40:06.686924: step 1973, loss 0.0228151, acc 1
2020-02-16T15:40:06.837976: step 1974, loss 0.055065, acc 0.984375
2020-02-16T15:40:06.976825: step 1975, loss 0.0781111, acc 0.96875
2020-02-16T15:40:07.136822: step 1976, loss 0.0578835, acc 0.953125
2020-02-16T15:40:07.300927: step 1977, loss 0.0698119, acc 0.96875
2020-02-16T15:40:07.453480: step 1978, loss 0.0726988, acc 0.984375
2020-02-16T15:40:07.626413: step 1979, loss 0.0967899, acc 0.953125
2020-02-16T15:40:07.770793: step 1980, loss 0.0864854, acc 0.953125
2020-02-16T15:40:07.913328: step 1981, loss 0.0640523, acc 0.96875
2020-02-16T15:40:08.066816: step 1982, loss 0.10047, acc 0.953125
2020-02-16T15:40:08.243021: step 1983, loss 0.0647903, acc 0.984375
2020-02-16T15:40:08.385009: step 1984, loss 0.0426861, acc 0.984375
2020-02-16T15:40:08.532018: step 1985, loss 0.0497194, acc 0.984375
2020-02-16T15:40:08.693106: step 1986, loss 0.0817581, acc 0.96875
2020-02-16T15:40:08.833445: step 1987, loss 0.103401, acc 0.96875
2020-02-16T15:40:08.972642: step 1988, loss 0.038237, acc 0.984375
2020-02-16T15:40:09.124524: step 1989, loss 0.0563669, acc 0.984375
2020-02-16T15:40:09.271340: step 1990, loss 0.0711308, acc 0.96875
2020-02-16T15:40:09.431113: step 1991, loss 0.0783553, acc 0.953125
2020-02-16T15:40:09.600247: step 1992, loss 0.0533768, acc 0.96875
2020-02-16T15:40:09.750466: step 1993, loss 0.0850256, acc 0.953125
2020-02-16T15:40:09.893584: step 1994, loss 0.0768586, acc 0.96875
2020-02-16T15:40:10.040933: step 1995, loss 0.049767, acc 0.984375
2020-02-16T15:40:10.202177: step 1996, loss 0.151492, acc 0.9375
2020-02-16T15:40:10.356153: step 1997, loss 0.0164237, acc 1
2020-02-16T15:40:10.497955: step 1998, loss 0.039843, acc 0.984375
2020-02-16T15:40:10.647454: step 1999, loss 0.0637902, acc 0.984375
2020-02-16T15:40:10.802372: step 2000, loss 0.0366371, acc 1

Evaluation:
2020-02-16T15:40:11.064661: step 2000, loss 0.708024, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2000

2020-02-16T15:40:12.772396: step 2001, loss 0.0660038, acc 0.96875
2020-02-16T15:40:12.902094: step 2002, loss 0.0717582, acc 0.984375
2020-02-16T15:40:13.056084: step 2003, loss 0.0318837, acc 0.984375
2020-02-16T15:40:13.229482: step 2004, loss 0.0575128, acc 0.96875
2020-02-16T15:40:13.389835: step 2005, loss 0.0568448, acc 0.984375
2020-02-16T15:40:13.548932: step 2006, loss 0.0553738, acc 0.984375
2020-02-16T15:40:13.722104: step 2007, loss 0.0324594, acc 1
2020-02-16T15:40:13.841911: step 2008, loss 0.0726783, acc 0.96875
2020-02-16T15:40:13.964675: step 2009, loss 0.0197108, acc 1
2020-02-16T15:40:14.106870: step 2010, loss 0.0380868, acc 0.984375
2020-02-16T15:40:14.249007: step 2011, loss 0.0279625, acc 1
2020-02-16T15:40:14.395127: step 2012, loss 0.123303, acc 0.9375
2020-02-16T15:40:14.557376: step 2013, loss 0.0477757, acc 1
2020-02-16T15:40:14.688774: step 2014, loss 0.14484, acc 0.921875
2020-02-16T15:40:14.809998: step 2015, loss 0.150672, acc 0.96875
2020-02-16T15:40:14.930076: step 2016, loss 0.0841942, acc 0.96875
2020-02-16T15:40:15.071632: step 2017, loss 0.0400264, acc 1
2020-02-16T15:40:15.211245: step 2018, loss 0.0289757, acc 1
2020-02-16T15:40:15.340062: step 2019, loss 0.0533016, acc 0.984375
2020-02-16T15:40:15.476037: step 2020, loss 0.211038, acc 0.9375
2020-02-16T15:40:15.616690: step 2021, loss 0.0595725, acc 0.984375
2020-02-16T15:40:15.749919: step 2022, loss 0.028287, acc 1
2020-02-16T15:40:15.870314: step 2023, loss 0.0443256, acc 0.984375
2020-02-16T15:40:15.991375: step 2024, loss 0.0370015, acc 0.984375
2020-02-16T15:40:16.134747: step 2025, loss 0.0516972, acc 0.984375
2020-02-16T15:40:16.269230: step 2026, loss 0.0569516, acc 0.984375
2020-02-16T15:40:16.405231: step 2027, loss 0.0176587, acc 1
2020-02-16T15:40:16.550503: step 2028, loss 0.0542318, acc 0.984375
2020-02-16T15:40:16.678078: step 2029, loss 0.0991895, acc 0.96875
2020-02-16T15:40:16.802163: step 2030, loss 0.0854224, acc 0.9375
2020-02-16T15:40:16.920254: step 2031, loss 0.0170545, acc 1
2020-02-16T15:40:17.053556: step 2032, loss 0.0756073, acc 0.96875
2020-02-16T15:40:17.199346: step 2033, loss 0.0288712, acc 1
2020-02-16T15:40:17.325450: step 2034, loss 0.0396758, acc 1
2020-02-16T15:40:17.451884: step 2035, loss 0.0704041, acc 0.984375
2020-02-16T15:40:17.592039: step 2036, loss 0.0982094, acc 0.953125
2020-02-16T15:40:17.721384: step 2037, loss 0.130519, acc 0.921875
2020-02-16T15:40:17.843411: step 2038, loss 0.0407604, acc 1
2020-02-16T15:40:17.962144: step 2039, loss 0.0848783, acc 0.953125
2020-02-16T15:40:18.114499: step 2040, loss 0.0834423, acc 0.984375
2020-02-16T15:40:18.253858: step 2041, loss 0.018864, acc 1
2020-02-16T15:40:18.387455: step 2042, loss 0.0762229, acc 0.96875
2020-02-16T15:40:18.523412: step 2043, loss 0.0552557, acc 0.96875
2020-02-16T15:40:18.657757: step 2044, loss 0.0913758, acc 0.9375
2020-02-16T15:40:18.805063: step 2045, loss 0.0170893, acc 1
2020-02-16T15:40:18.945333: step 2046, loss 0.106256, acc 0.9375
2020-02-16T15:40:19.110157: step 2047, loss 0.117103, acc 0.96875
2020-02-16T15:40:19.272483: step 2048, loss 0.0439655, acc 0.984375
2020-02-16T15:40:19.424961: step 2049, loss 0.0537639, acc 1
2020-02-16T15:40:19.576662: step 2050, loss 0.077282, acc 0.984375
2020-02-16T15:40:19.730502: step 2051, loss 0.104278, acc 0.953125
2020-02-16T15:40:19.870912: step 2052, loss 0.078735, acc 0.96875
2020-02-16T15:40:20.018283: step 2053, loss 0.047797, acc 0.984375
2020-02-16T15:40:20.193625: step 2054, loss 0.0253879, acc 0.984375
2020-02-16T15:40:20.347030: step 2055, loss 0.0425413, acc 0.984375
2020-02-16T15:40:20.501202: step 2056, loss 0.0668703, acc 0.984375
2020-02-16T15:40:20.658516: step 2057, loss 0.107303, acc 0.9375
2020-02-16T15:40:20.808027: step 2058, loss 0.0896827, acc 0.96875
2020-02-16T15:40:20.944672: step 2059, loss 0.0370866, acc 1
2020-02-16T15:40:21.106145: step 2060, loss 0.102637, acc 0.96875
2020-02-16T15:40:21.257222: step 2061, loss 0.0289003, acc 1
2020-02-16T15:40:21.391550: step 2062, loss 0.0563819, acc 0.984375
2020-02-16T15:40:21.546218: step 2063, loss 0.0370848, acc 0.984375
2020-02-16T15:40:21.696096: step 2064, loss 0.127246, acc 0.9375
2020-02-16T15:40:21.820157: step 2065, loss 0.121424, acc 0.953125
2020-02-16T15:40:21.950253: step 2066, loss 0.0352345, acc 1
2020-02-16T15:40:22.112581: step 2067, loss 0.0602068, acc 0.984375
2020-02-16T15:40:22.264992: step 2068, loss 0.0724832, acc 0.96875
2020-02-16T15:40:22.402237: step 2069, loss 0.130322, acc 0.96875
2020-02-16T15:40:22.553563: step 2070, loss 0.0519262, acc 1
2020-02-16T15:40:22.698768: step 2071, loss 0.127235, acc 0.9375
2020-02-16T15:40:22.821187: step 2072, loss 0.0360485, acc 1
2020-02-16T15:40:22.941374: step 2073, loss 0.0776964, acc 0.984375
2020-02-16T15:40:23.078820: step 2074, loss 0.0406477, acc 0.984375
2020-02-16T15:40:23.236190: step 2075, loss 0.0457861, acc 0.984375
2020-02-16T15:40:23.374356: step 2076, loss 0.0501564, acc 0.984375
2020-02-16T15:40:23.507228: step 2077, loss 0.0287593, acc 1
2020-02-16T15:40:23.646502: step 2078, loss 0.0596418, acc 0.984375
2020-02-16T15:40:23.774967: step 2079, loss 0.139291, acc 0.953125
2020-02-16T15:40:23.900550: step 2080, loss 0.0751029, acc 0.96875
2020-02-16T15:40:24.025983: step 2081, loss 0.0358492, acc 1
2020-02-16T15:40:24.199652: step 2082, loss 0.0671281, acc 0.984375
2020-02-16T15:40:24.364339: step 2083, loss 0.0423353, acc 0.984375
2020-02-16T15:40:24.505384: step 2084, loss 0.0448345, acc 0.984375
2020-02-16T15:40:24.649432: step 2085, loss 0.0590775, acc 0.984375
2020-02-16T15:40:24.781189: step 2086, loss 0.052148, acc 0.96875
2020-02-16T15:40:24.918270: step 2087, loss 0.0216899, acc 1
2020-02-16T15:40:25.050089: step 2088, loss 0.0533182, acc 0.96875
2020-02-16T15:40:25.220695: step 2089, loss 0.08046, acc 0.96875
2020-02-16T15:40:25.407610: step 2090, loss 0.0604003, acc 0.984375
2020-02-16T15:40:25.564181: step 2091, loss 0.0633318, acc 0.984375
2020-02-16T15:40:25.714870: step 2092, loss 0.0368733, acc 1
2020-02-16T15:40:25.840676: step 2093, loss 0.033454, acc 0.984375
2020-02-16T15:40:26.014229: step 2094, loss 0.142339, acc 0.921875
2020-02-16T15:40:26.147169: step 2095, loss 0.0958826, acc 0.96875
2020-02-16T15:40:26.296549: step 2096, loss 0.132718, acc 0.953125
2020-02-16T15:40:26.427750: step 2097, loss 0.0967179, acc 0.96875
2020-02-16T15:40:26.555267: step 2098, loss 0.0351161, acc 1
2020-02-16T15:40:26.678424: step 2099, loss 0.04201, acc 0.984375
2020-02-16T15:40:26.797035: step 2100, loss 0.0324054, acc 1

Evaluation:
2020-02-16T15:40:27.010190: step 2100, loss 0.7198, acc 0.741088

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2100

2020-02-16T15:40:28.674989: step 2101, loss 0.0263691, acc 1
2020-02-16T15:40:28.797534: step 2102, loss 0.0351676, acc 1
2020-02-16T15:40:28.916372: step 2103, loss 0.0477232, acc 0.984375
2020-02-16T15:40:29.036682: step 2104, loss 0.032375, acc 1
2020-02-16T15:40:29.159329: step 2105, loss 0.0448925, acc 0.984375
2020-02-16T15:40:29.299140: step 2106, loss 0.0389617, acc 0.984375
2020-02-16T15:40:29.417984: step 2107, loss 0.0339999, acc 0.984375
2020-02-16T15:40:29.540846: step 2108, loss 0.0435901, acc 0.984375
2020-02-16T15:40:29.662314: step 2109, loss 0.0543791, acc 0.984375
2020-02-16T15:40:29.793251: step 2110, loss 0.0158944, acc 1
2020-02-16T15:40:29.913426: step 2111, loss 0.0505609, acc 0.96875
2020-02-16T15:40:30.034877: step 2112, loss 0.0324314, acc 1
2020-02-16T15:40:30.157029: step 2113, loss 0.0144143, acc 1
2020-02-16T15:40:30.274617: step 2114, loss 0.0388733, acc 1
2020-02-16T15:40:30.398836: step 2115, loss 0.0645444, acc 0.984375
2020-02-16T15:40:30.531787: step 2116, loss 0.0414922, acc 1
2020-02-16T15:40:30.667497: step 2117, loss 0.0501009, acc 0.984375
2020-02-16T15:40:30.794403: step 2118, loss 0.0453415, acc 0.984375
2020-02-16T15:40:30.914711: step 2119, loss 0.0309454, acc 1
2020-02-16T15:40:31.035748: step 2120, loss 0.029544, acc 1
2020-02-16T15:40:31.157863: step 2121, loss 0.0408247, acc 0.984375
2020-02-16T15:40:31.276226: step 2122, loss 0.0157533, acc 1
2020-02-16T15:40:31.398094: step 2123, loss 0.0478956, acc 1
2020-02-16T15:40:31.518411: step 2124, loss 0.0801096, acc 0.953125
2020-02-16T15:40:31.636490: step 2125, loss 0.0745193, acc 0.984375
2020-02-16T15:40:31.803305: step 2126, loss 0.0475818, acc 0.984375
2020-02-16T15:40:31.949529: step 2127, loss 0.0242797, acc 1
2020-02-16T15:40:32.080132: step 2128, loss 0.0302433, acc 1
2020-02-16T15:40:32.203966: step 2129, loss 0.124213, acc 0.9375
2020-02-16T15:40:32.328066: step 2130, loss 0.0750968, acc 0.953125
2020-02-16T15:40:32.452475: step 2131, loss 0.0267351, acc 1
2020-02-16T15:40:32.607782: step 2132, loss 0.0400706, acc 0.984375
2020-02-16T15:40:32.766336: step 2133, loss 0.0370936, acc 0.984375
2020-02-16T15:40:32.887193: step 2134, loss 0.0495302, acc 0.984375
2020-02-16T15:40:33.011315: step 2135, loss 0.0206183, acc 1
2020-02-16T15:40:33.150483: step 2136, loss 0.112476, acc 0.9375
2020-02-16T15:40:33.281065: step 2137, loss 0.0287647, acc 1
2020-02-16T15:40:33.407669: step 2138, loss 0.117061, acc 0.96875
2020-02-16T15:40:33.525934: step 2139, loss 0.0772169, acc 0.96875
2020-02-16T15:40:33.648270: step 2140, loss 0.0179289, acc 1
2020-02-16T15:40:33.772037: step 2141, loss 0.0875209, acc 0.96875
2020-02-16T15:40:33.891150: step 2142, loss 0.0189452, acc 1
2020-02-16T15:40:34.010315: step 2143, loss 0.024084, acc 1
2020-02-16T15:40:34.129963: step 2144, loss 0.0140717, acc 1
2020-02-16T15:40:34.255614: step 2145, loss 0.0832632, acc 0.96875
2020-02-16T15:40:34.372910: step 2146, loss 0.0234879, acc 1
2020-02-16T15:40:34.494069: step 2147, loss 0.11693, acc 0.921875
2020-02-16T15:40:34.614824: step 2148, loss 0.0252922, acc 1
2020-02-16T15:40:34.741039: step 2149, loss 0.0451645, acc 0.96875
2020-02-16T15:40:34.862928: step 2150, loss 0.103817, acc 0.9375
2020-02-16T15:40:34.990427: step 2151, loss 0.0615807, acc 0.96875
2020-02-16T15:40:35.116620: step 2152, loss 0.100132, acc 0.9375
2020-02-16T15:40:35.237371: step 2153, loss 0.0467766, acc 0.984375
2020-02-16T15:40:35.357559: step 2154, loss 0.0386016, acc 0.984375
2020-02-16T15:40:35.474287: step 2155, loss 0.0667337, acc 0.96875
2020-02-16T15:40:35.596858: step 2156, loss 0.117099, acc 0.953125
2020-02-16T15:40:35.719099: step 2157, loss 0.0702232, acc 0.96875
2020-02-16T15:40:35.844351: step 2158, loss 0.0464708, acc 0.984375
2020-02-16T15:40:35.966253: step 2159, loss 0.0430906, acc 0.984375
2020-02-16T15:40:36.089880: step 2160, loss 0.0495504, acc 0.984375
2020-02-16T15:40:36.212447: step 2161, loss 0.0334834, acc 1
2020-02-16T15:40:36.335409: step 2162, loss 0.0188421, acc 1
2020-02-16T15:40:36.461342: step 2163, loss 0.116652, acc 0.96875
2020-02-16T15:40:36.592036: step 2164, loss 0.0338631, acc 1
2020-02-16T15:40:36.713963: step 2165, loss 0.0347504, acc 1
2020-02-16T15:40:36.837510: step 2166, loss 0.0336304, acc 1
2020-02-16T15:40:36.956346: step 2167, loss 0.0266002, acc 1
2020-02-16T15:40:37.084582: step 2168, loss 0.0336212, acc 0.984375
2020-02-16T15:40:37.206532: step 2169, loss 0.0315573, acc 0.984375
2020-02-16T15:40:37.324196: step 2170, loss 0.056081, acc 0.96875
2020-02-16T15:40:37.447823: step 2171, loss 0.0190958, acc 1
2020-02-16T15:40:37.663070: step 2172, loss 0.105997, acc 0.9375
2020-02-16T15:40:37.802592: step 2173, loss 0.0725873, acc 0.96875
2020-02-16T15:40:38.024994: step 2174, loss 0.0495181, acc 0.984375
2020-02-16T15:40:38.163810: step 2175, loss 0.0266164, acc 1
2020-02-16T15:40:38.312739: step 2176, loss 0.0197484, acc 1
2020-02-16T15:40:38.475386: step 2177, loss 0.0320076, acc 1
2020-02-16T15:40:38.611197: step 2178, loss 0.0448753, acc 0.984375
2020-02-16T15:40:38.797450: step 2179, loss 0.0229023, acc 1
2020-02-16T15:40:38.938614: step 2180, loss 0.0670495, acc 0.984375
2020-02-16T15:40:39.117878: step 2181, loss 0.0541853, acc 0.96875
2020-02-16T15:40:39.323193: step 2182, loss 0.0433384, acc 0.984375
2020-02-16T15:40:39.501826: step 2183, loss 0.0809465, acc 0.96875
2020-02-16T15:40:39.629207: step 2184, loss 0.0323324, acc 0.984375
2020-02-16T15:40:39.776049: step 2185, loss 0.0222901, acc 1
2020-02-16T15:40:39.964549: step 2186, loss 0.0460813, acc 0.984375
2020-02-16T15:40:40.107446: step 2187, loss 0.0254591, acc 1
2020-02-16T15:40:40.285021: step 2188, loss 0.0374205, acc 1
2020-02-16T15:40:40.443091: step 2189, loss 0.0299775, acc 1
2020-02-16T15:40:40.574470: step 2190, loss 0.0370941, acc 1
2020-02-16T15:40:40.705118: step 2191, loss 0.103284, acc 0.96875
2020-02-16T15:40:40.825518: step 2192, loss 0.0672698, acc 0.96875
2020-02-16T15:40:40.956584: step 2193, loss 0.02878, acc 0.984375
2020-02-16T15:40:41.079873: step 2194, loss 0.130802, acc 0.984375
2020-02-16T15:40:41.257734: step 2195, loss 0.0798501, acc 0.96875
2020-02-16T15:40:41.450097: step 2196, loss 0.0888225, acc 0.96875
2020-02-16T15:40:41.594681: step 2197, loss 0.0761829, acc 0.953125
2020-02-16T15:40:41.735622: step 2198, loss 0.0579152, acc 0.96875
2020-02-16T15:40:41.855234: step 2199, loss 0.0741732, acc 0.96875
2020-02-16T15:40:41.972793: step 2200, loss 0.0723334, acc 0.984375

Evaluation:
2020-02-16T15:40:42.194373: step 2200, loss 0.748392, acc 0.73546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2200

2020-02-16T15:40:44.390699: step 2201, loss 0.0106679, acc 1
2020-02-16T15:40:44.533372: step 2202, loss 0.0159315, acc 1
2020-02-16T15:40:44.664123: step 2203, loss 0.0264418, acc 0.984375
2020-02-16T15:40:44.800133: step 2204, loss 0.0201026, acc 1
2020-02-16T15:40:44.927640: step 2205, loss 0.0574595, acc 0.984375
2020-02-16T15:40:45.055461: step 2206, loss 0.123338, acc 0.953125
2020-02-16T15:40:45.179963: step 2207, loss 0.0511592, acc 0.96875
2020-02-16T15:40:45.310771: step 2208, loss 0.027123, acc 1
2020-02-16T15:40:45.432851: step 2209, loss 0.0577485, acc 1
2020-02-16T15:40:45.553442: step 2210, loss 0.0748311, acc 0.96875
2020-02-16T15:40:45.677191: step 2211, loss 0.0440219, acc 0.984375
2020-02-16T15:40:45.801191: step 2212, loss 0.0745061, acc 0.953125
2020-02-16T15:40:45.921435: step 2213, loss 0.016773, acc 1
2020-02-16T15:40:46.039985: step 2214, loss 0.0836325, acc 0.96875
2020-02-16T15:40:46.158740: step 2215, loss 0.129154, acc 0.96875
2020-02-16T15:40:46.280869: step 2216, loss 0.0228897, acc 1
2020-02-16T15:40:46.406420: step 2217, loss 0.0615893, acc 0.96875
2020-02-16T15:40:46.531367: step 2218, loss 0.0462723, acc 0.984375
2020-02-16T15:40:46.680965: step 2219, loss 0.0119682, acc 1
2020-02-16T15:40:46.810808: step 2220, loss 0.0658564, acc 0.984375
2020-02-16T15:40:47.084769: step 2221, loss 0.0520219, acc 1
2020-02-16T15:40:47.328688: step 2222, loss 0.100982, acc 0.9375
2020-02-16T15:40:47.534817: step 2223, loss 0.0142088, acc 1
2020-02-16T15:40:47.728687: step 2224, loss 0.0486153, acc 0.984375
2020-02-16T15:40:47.916599: step 2225, loss 0.0282393, acc 1
2020-02-16T15:40:48.117941: step 2226, loss 0.044742, acc 1
2020-02-16T15:40:48.269340: step 2227, loss 0.0339951, acc 0.984375
2020-02-16T15:40:48.418416: step 2228, loss 0.0637272, acc 0.984375
2020-02-16T15:40:48.654254: step 2229, loss 0.0395344, acc 0.984375
2020-02-16T15:40:48.796171: step 2230, loss 0.0537606, acc 0.984375
2020-02-16T15:40:48.952402: step 2231, loss 0.100951, acc 0.9375
2020-02-16T15:40:49.111646: step 2232, loss 0.0179338, acc 1
2020-02-16T15:40:49.342521: step 2233, loss 0.0363735, acc 1
2020-02-16T15:40:49.501857: step 2234, loss 0.0288535, acc 1
2020-02-16T15:40:49.710533: step 2235, loss 0.0581431, acc 0.984375
2020-02-16T15:40:49.856766: step 2236, loss 0.0241961, acc 0.984375
2020-02-16T15:40:50.066108: step 2237, loss 0.147822, acc 0.9375
2020-02-16T15:40:50.212386: step 2238, loss 0.0285927, acc 1
2020-02-16T15:40:50.423773: step 2239, loss 0.049814, acc 0.984375
2020-02-16T15:40:50.686086: step 2240, loss 0.0639076, acc 0.96875
2020-02-16T15:40:50.890015: step 2241, loss 0.0570339, acc 0.984375
2020-02-16T15:40:51.138107: step 2242, loss 0.0298682, acc 1
2020-02-16T15:40:51.363567: step 2243, loss 0.0483167, acc 0.96875
2020-02-16T15:40:51.535861: step 2244, loss 0.0458136, acc 0.96875
2020-02-16T15:40:51.696651: step 2245, loss 0.0348858, acc 0.984375
2020-02-16T15:40:51.889414: step 2246, loss 0.0184262, acc 1
2020-02-16T15:40:52.106289: step 2247, loss 0.0273742, acc 0.984375
2020-02-16T15:40:52.277479: step 2248, loss 0.0193331, acc 1
2020-02-16T15:40:52.457446: step 2249, loss 0.0465214, acc 0.96875
2020-02-16T15:40:52.602348: step 2250, loss 0.0454489, acc 0.983333
2020-02-16T15:40:52.745949: step 2251, loss 0.0445713, acc 0.984375
2020-02-16T15:40:52.876371: step 2252, loss 0.0570948, acc 0.953125
2020-02-16T15:40:53.001757: step 2253, loss 0.0202123, acc 1
2020-02-16T15:40:53.138791: step 2254, loss 0.0142331, acc 1
2020-02-16T15:40:53.404468: step 2255, loss 0.0181963, acc 1
2020-02-16T15:40:53.583763: step 2256, loss 0.0316027, acc 1
2020-02-16T15:40:53.735564: step 2257, loss 0.0402274, acc 1
2020-02-16T15:40:53.861306: step 2258, loss 0.0276898, acc 1
2020-02-16T15:40:53.990811: step 2259, loss 0.0255012, acc 0.984375
2020-02-16T15:40:54.126992: step 2260, loss 0.0361241, acc 0.96875
2020-02-16T15:40:54.262719: step 2261, loss 0.0541637, acc 0.96875
2020-02-16T15:40:54.393180: step 2262, loss 0.0247776, acc 0.984375
2020-02-16T15:40:54.517728: step 2263, loss 0.0703621, acc 0.96875
2020-02-16T15:40:54.642029: step 2264, loss 0.0492252, acc 0.96875
2020-02-16T15:40:54.777428: step 2265, loss 0.0349761, acc 0.984375
2020-02-16T15:40:54.906801: step 2266, loss 0.036012, acc 0.984375
2020-02-16T15:40:55.038866: step 2267, loss 0.0123754, acc 1
2020-02-16T15:40:55.169197: step 2268, loss 0.0191436, acc 1
2020-02-16T15:40:55.303943: step 2269, loss 0.0371469, acc 0.984375
2020-02-16T15:40:55.431924: step 2270, loss 0.0340647, acc 0.984375
2020-02-16T15:40:55.562058: step 2271, loss 0.0175204, acc 1
2020-02-16T15:40:55.691409: step 2272, loss 0.0179587, acc 1
2020-02-16T15:40:55.822736: step 2273, loss 0.0468447, acc 0.984375
2020-02-16T15:40:55.948944: step 2274, loss 0.107501, acc 0.96875
2020-02-16T15:40:56.079698: step 2275, loss 0.099256, acc 0.96875
2020-02-16T15:40:56.205732: step 2276, loss 0.0206401, acc 1
2020-02-16T15:40:56.338160: step 2277, loss 0.0441128, acc 0.984375
2020-02-16T15:40:56.463413: step 2278, loss 0.0343677, acc 0.984375
2020-02-16T15:40:56.596101: step 2279, loss 0.0117101, acc 1
2020-02-16T15:40:56.733104: step 2280, loss 0.0159858, acc 1
2020-02-16T15:40:56.863707: step 2281, loss 0.0336761, acc 1
2020-02-16T15:40:56.992551: step 2282, loss 0.0314794, acc 1
2020-02-16T15:40:57.123292: step 2283, loss 0.0441975, acc 0.984375
2020-02-16T15:40:57.259608: step 2284, loss 0.0232323, acc 1
2020-02-16T15:40:57.389230: step 2285, loss 0.0695833, acc 0.984375
2020-02-16T15:40:57.521207: step 2286, loss 0.0279563, acc 1
2020-02-16T15:40:57.650131: step 2287, loss 0.0255369, acc 0.984375
2020-02-16T15:40:57.787703: step 2288, loss 0.0361939, acc 0.984375
2020-02-16T15:40:57.915652: step 2289, loss 0.0437381, acc 1
2020-02-16T15:40:58.043461: step 2290, loss 0.0233223, acc 1
2020-02-16T15:40:58.170588: step 2291, loss 0.11965, acc 0.96875
2020-02-16T15:40:58.306312: step 2292, loss 0.0269507, acc 1
2020-02-16T15:40:58.437406: step 2293, loss 0.0266831, acc 0.984375
2020-02-16T15:40:58.567474: step 2294, loss 0.0713121, acc 0.96875
2020-02-16T15:40:58.699168: step 2295, loss 0.095818, acc 0.96875
2020-02-16T15:40:58.834736: step 2296, loss 0.0142429, acc 1
2020-02-16T15:40:58.965564: step 2297, loss 0.0299623, acc 1
2020-02-16T15:40:59.106541: step 2298, loss 0.0295676, acc 1
2020-02-16T15:40:59.232671: step 2299, loss 0.0333143, acc 1
2020-02-16T15:40:59.362110: step 2300, loss 0.0280986, acc 1

Evaluation:
2020-02-16T15:40:59.572510: step 2300, loss 0.78071, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2300

2020-02-16T15:41:02.376670: step 2301, loss 0.0227893, acc 1
2020-02-16T15:41:02.711894: step 2302, loss 0.0355253, acc 0.984375
2020-02-16T15:41:02.854540: step 2303, loss 0.0181159, acc 1
2020-02-16T15:41:02.982525: step 2304, loss 0.0434346, acc 0.984375
2020-02-16T15:41:03.113125: step 2305, loss 0.0543735, acc 0.96875
2020-02-16T15:41:03.243925: step 2306, loss 0.0367234, acc 0.984375
2020-02-16T15:41:03.373087: step 2307, loss 0.0212875, acc 1
2020-02-16T15:41:03.497796: step 2308, loss 0.00910141, acc 1
2020-02-16T15:41:03.622177: step 2309, loss 0.0769833, acc 0.984375
2020-02-16T15:41:03.770300: step 2310, loss 0.0909381, acc 0.984375
2020-02-16T15:41:03.898768: step 2311, loss 0.0280629, acc 0.984375
2020-02-16T15:41:04.031844: step 2312, loss 0.0340814, acc 0.96875
2020-02-16T15:41:04.157339: step 2313, loss 0.0152128, acc 1
2020-02-16T15:41:04.292785: step 2314, loss 0.0462479, acc 0.984375
2020-02-16T15:41:04.421474: step 2315, loss 0.0369435, acc 1
2020-02-16T15:41:04.548306: step 2316, loss 0.05248, acc 0.984375
2020-02-16T15:41:04.678260: step 2317, loss 0.00941933, acc 1
2020-02-16T15:41:04.811263: step 2318, loss 0.0483509, acc 0.984375
2020-02-16T15:41:04.946605: step 2319, loss 0.0344185, acc 0.984375
2020-02-16T15:41:05.072605: step 2320, loss 0.0388786, acc 0.984375
2020-02-16T15:41:05.201117: step 2321, loss 0.0610108, acc 0.984375
2020-02-16T15:41:05.328308: step 2322, loss 0.0784057, acc 0.96875
2020-02-16T15:41:05.457691: step 2323, loss 0.127385, acc 0.984375
2020-02-16T15:41:05.588917: step 2324, loss 0.0333887, acc 0.984375
2020-02-16T15:41:05.724778: step 2325, loss 0.00999358, acc 1
2020-02-16T15:41:05.856309: step 2326, loss 0.0313978, acc 1
2020-02-16T15:41:05.985592: step 2327, loss 0.0938433, acc 0.953125
2020-02-16T15:41:06.110798: step 2328, loss 0.019749, acc 1
2020-02-16T15:41:06.244706: step 2329, loss 0.0350954, acc 1
2020-02-16T15:41:06.372751: step 2330, loss 0.0210114, acc 1
2020-02-16T15:41:06.501272: step 2331, loss 0.0192139, acc 1
2020-02-16T15:41:06.628926: step 2332, loss 0.0339821, acc 1
2020-02-16T15:41:06.768677: step 2333, loss 0.00992487, acc 1
2020-02-16T15:41:06.902192: step 2334, loss 0.0472115, acc 0.984375
2020-02-16T15:41:07.027021: step 2335, loss 0.0160463, acc 1
2020-02-16T15:41:07.158308: step 2336, loss 0.0205977, acc 1
2020-02-16T15:41:07.289602: step 2337, loss 0.0320209, acc 1
2020-02-16T15:41:07.416987: step 2338, loss 0.0146556, acc 1
2020-02-16T15:41:07.543900: step 2339, loss 0.014069, acc 1
2020-02-16T15:41:07.675991: step 2340, loss 0.0700565, acc 0.96875
2020-02-16T15:41:07.809418: step 2341, loss 0.0202472, acc 1
2020-02-16T15:41:07.938819: step 2342, loss 0.0217667, acc 1
2020-02-16T15:41:08.067628: step 2343, loss 0.0158503, acc 1
2020-02-16T15:41:08.193742: step 2344, loss 0.0151496, acc 1
2020-02-16T15:41:08.325029: step 2345, loss 0.0394553, acc 0.984375
2020-02-16T15:41:08.453681: step 2346, loss 0.0348094, acc 1
2020-02-16T15:41:08.585446: step 2347, loss 0.00622394, acc 1
2020-02-16T15:41:08.718060: step 2348, loss 0.0536035, acc 0.96875
2020-02-16T15:41:08.842910: step 2349, loss 0.0144658, acc 1
2020-02-16T15:41:08.969319: step 2350, loss 0.0426311, acc 0.96875
2020-02-16T15:41:09.099774: step 2351, loss 0.127535, acc 0.9375
2020-02-16T15:41:09.229603: step 2352, loss 0.0339199, acc 0.984375
2020-02-16T15:41:09.358983: step 2353, loss 0.0120698, acc 1
2020-02-16T15:41:09.487174: step 2354, loss 0.0130822, acc 1
2020-02-16T15:41:09.611888: step 2355, loss 0.0541043, acc 0.984375
2020-02-16T15:41:09.748402: step 2356, loss 0.0218734, acc 0.984375
2020-02-16T15:41:09.872122: step 2357, loss 0.0506607, acc 0.984375
2020-02-16T15:41:09.997015: step 2358, loss 0.0198815, acc 1
2020-02-16T15:41:10.125560: step 2359, loss 0.0254447, acc 1
2020-02-16T15:41:10.256485: step 2360, loss 0.0191681, acc 1
2020-02-16T15:41:10.385040: step 2361, loss 0.0870158, acc 0.96875
2020-02-16T15:41:10.509502: step 2362, loss 0.0801813, acc 0.984375
2020-02-16T15:41:10.639002: step 2363, loss 0.0500315, acc 0.984375
2020-02-16T15:41:10.775811: step 2364, loss 0.035499, acc 0.984375
2020-02-16T15:41:10.906129: step 2365, loss 0.0430523, acc 0.984375
2020-02-16T15:41:11.031129: step 2366, loss 0.0246569, acc 0.984375
2020-02-16T15:41:11.158671: step 2367, loss 0.0306379, acc 1
2020-02-16T15:41:11.292750: step 2368, loss 0.0184974, acc 1
2020-02-16T15:41:11.420476: step 2369, loss 0.0769891, acc 0.984375
2020-02-16T15:41:11.549594: step 2370, loss 0.0230594, acc 0.984375
2020-02-16T15:41:11.681337: step 2371, loss 0.0367501, acc 0.984375
2020-02-16T15:41:11.814978: step 2372, loss 0.0430076, acc 0.984375
2020-02-16T15:41:11.943477: step 2373, loss 0.0199382, acc 1
2020-02-16T15:41:12.070721: step 2374, loss 0.026051, acc 1
2020-02-16T15:41:12.198151: step 2375, loss 0.0759264, acc 0.96875
2020-02-16T15:41:12.322613: step 2376, loss 0.0290561, acc 1
2020-02-16T15:41:12.450574: step 2377, loss 0.00428593, acc 1
2020-02-16T15:41:12.574567: step 2378, loss 0.0338457, acc 0.984375
2020-02-16T15:41:12.712356: step 2379, loss 0.0219544, acc 1
2020-02-16T15:41:12.843904: step 2380, loss 0.0620515, acc 0.96875
2020-02-16T15:41:12.975833: step 2381, loss 0.0447609, acc 0.984375
2020-02-16T15:41:13.102120: step 2382, loss 0.0442993, acc 0.984375
2020-02-16T15:41:13.225593: step 2383, loss 0.0348569, acc 0.984375
2020-02-16T15:41:13.355912: step 2384, loss 0.0462159, acc 0.984375
2020-02-16T15:41:13.483150: step 2385, loss 0.0658822, acc 0.96875
2020-02-16T15:41:13.607825: step 2386, loss 0.0182416, acc 1
2020-02-16T15:41:13.743751: step 2387, loss 0.0768532, acc 0.984375
2020-02-16T15:41:13.872425: step 2388, loss 0.124479, acc 0.953125
2020-02-16T15:41:13.999477: step 2389, loss 0.0382819, acc 0.984375
2020-02-16T15:41:14.124200: step 2390, loss 0.0322909, acc 0.984375
2020-02-16T15:41:14.257109: step 2391, loss 0.0824244, acc 0.984375
2020-02-16T15:41:14.384090: step 2392, loss 0.0158278, acc 1
2020-02-16T15:41:14.514154: step 2393, loss 0.0608681, acc 0.96875
2020-02-16T15:41:14.643781: step 2394, loss 0.0250226, acc 1
2020-02-16T15:41:14.778623: step 2395, loss 0.0685902, acc 0.984375
2020-02-16T15:41:14.918616: step 2396, loss 0.014021, acc 1
2020-02-16T15:41:15.052176: step 2397, loss 0.0192345, acc 1
2020-02-16T15:41:15.178471: step 2398, loss 0.0461902, acc 0.984375
2020-02-16T15:41:15.314266: step 2399, loss 0.0233822, acc 1
2020-02-16T15:41:15.438892: step 2400, loss 0.10026, acc 0.933333

Evaluation:
2020-02-16T15:41:15.643957: step 2400, loss 0.807921, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2400

2020-02-16T15:41:17.510700: step 2401, loss 0.0318144, acc 0.984375
2020-02-16T15:41:17.642868: step 2402, loss 0.0112728, acc 1
2020-02-16T15:41:17.775195: step 2403, loss 0.0210285, acc 1
2020-02-16T15:41:17.904291: step 2404, loss 0.0102826, acc 1
2020-02-16T15:41:18.029551: step 2405, loss 0.0121365, acc 1
2020-02-16T15:41:18.156159: step 2406, loss 0.0220046, acc 1
2020-02-16T15:41:18.283442: step 2407, loss 0.028141, acc 0.984375
2020-02-16T15:41:18.412367: step 2408, loss 0.0169445, acc 1
2020-02-16T15:41:18.541486: step 2409, loss 0.00361306, acc 1
2020-02-16T15:41:18.674605: step 2410, loss 0.0400076, acc 0.984375
2020-02-16T15:41:18.805483: step 2411, loss 0.0771912, acc 0.96875
2020-02-16T15:41:18.933054: step 2412, loss 0.0306524, acc 0.984375
2020-02-16T15:41:19.063490: step 2413, loss 0.0638464, acc 0.96875
2020-02-16T15:41:19.192824: step 2414, loss 0.0306835, acc 0.984375
2020-02-16T15:41:19.322442: step 2415, loss 0.0593927, acc 0.984375
2020-02-16T15:41:19.451729: step 2416, loss 0.0202162, acc 1
2020-02-16T15:41:19.579173: step 2417, loss 0.0132535, acc 1
2020-02-16T15:41:19.712497: step 2418, loss 0.112356, acc 0.953125
2020-02-16T15:41:19.845458: step 2419, loss 0.0154124, acc 1
2020-02-16T15:41:19.976475: step 2420, loss 0.0207983, acc 0.984375
2020-02-16T15:41:20.103034: step 2421, loss 0.00980759, acc 1
2020-02-16T15:41:20.231859: step 2422, loss 0.00677073, acc 1
2020-02-16T15:41:20.363139: step 2423, loss 0.0282241, acc 1
2020-02-16T15:41:20.493693: step 2424, loss 0.029851, acc 1
2020-02-16T15:41:20.617104: step 2425, loss 0.028321, acc 1
2020-02-16T15:41:20.752006: step 2426, loss 0.0276069, acc 1
2020-02-16T15:41:20.882783: step 2427, loss 0.0211905, acc 0.984375
2020-02-16T15:41:21.012109: step 2428, loss 0.044349, acc 0.96875
2020-02-16T15:41:21.139512: step 2429, loss 0.100649, acc 0.953125
2020-02-16T15:41:21.264848: step 2430, loss 0.0204566, acc 1
2020-02-16T15:41:21.395238: step 2431, loss 0.0383983, acc 0.96875
2020-02-16T15:41:21.522027: step 2432, loss 0.0164488, acc 1
2020-02-16T15:41:21.649038: step 2433, loss 0.028924, acc 1
2020-02-16T15:41:21.783780: step 2434, loss 0.0431216, acc 0.984375
2020-02-16T15:41:21.912828: step 2435, loss 0.0100518, acc 1
2020-02-16T15:41:22.038973: step 2436, loss 0.00682258, acc 1
2020-02-16T15:41:22.167006: step 2437, loss 0.0202153, acc 1
2020-02-16T15:41:22.322348: step 2438, loss 0.0155601, acc 1
2020-02-16T15:41:22.511020: step 2439, loss 0.00956594, acc 1
2020-02-16T15:41:22.688051: step 2440, loss 0.0338356, acc 1
2020-02-16T15:41:22.853369: step 2441, loss 0.0297603, acc 1
2020-02-16T15:41:23.006447: step 2442, loss 0.0419187, acc 0.984375
2020-02-16T15:41:23.164452: step 2443, loss 0.0114591, acc 1
2020-02-16T15:41:23.313924: step 2444, loss 0.0201058, acc 1
2020-02-16T15:41:23.493954: step 2445, loss 0.0556312, acc 0.96875
2020-02-16T15:41:23.823773: step 2446, loss 0.0519881, acc 0.96875
2020-02-16T15:41:23.966481: step 2447, loss 0.0642235, acc 0.984375
2020-02-16T15:41:24.230110: step 2448, loss 0.0251486, acc 1
2020-02-16T15:41:24.519310: step 2449, loss 0.0449273, acc 0.984375
2020-02-16T15:41:24.791735: step 2450, loss 0.0132366, acc 1
2020-02-16T15:41:25.053023: step 2451, loss 0.035025, acc 0.984375
2020-02-16T15:41:25.304818: step 2452, loss 0.0734575, acc 0.953125
2020-02-16T15:41:25.551025: step 2453, loss 0.0239802, acc 0.984375
2020-02-16T15:41:25.753265: step 2454, loss 0.0114165, acc 1
2020-02-16T15:41:25.949868: step 2455, loss 0.0229008, acc 1
2020-02-16T15:41:26.146138: step 2456, loss 0.00948546, acc 1
2020-02-16T15:41:26.319736: step 2457, loss 0.0308477, acc 1
2020-02-16T15:41:26.562854: step 2458, loss 0.0347551, acc 0.984375
2020-02-16T15:41:26.715535: step 2459, loss 0.0199661, acc 1
2020-02-16T15:41:26.863168: step 2460, loss 0.0579872, acc 0.984375
2020-02-16T15:41:27.014534: step 2461, loss 0.0483435, acc 0.984375
2020-02-16T15:41:27.167245: step 2462, loss 0.032606, acc 0.984375
2020-02-16T15:41:27.414054: step 2463, loss 0.0153573, acc 1
2020-02-16T15:41:27.587377: step 2464, loss 0.0187306, acc 1
2020-02-16T15:41:27.741674: step 2465, loss 0.016079, acc 1
2020-02-16T15:41:27.897401: step 2466, loss 0.109896, acc 0.96875
2020-02-16T15:41:28.098398: step 2467, loss 0.0224806, acc 0.984375
2020-02-16T15:41:28.273205: step 2468, loss 0.0432677, acc 0.96875
2020-02-16T15:41:28.440098: step 2469, loss 0.0156056, acc 1
2020-02-16T15:41:28.605458: step 2470, loss 0.0284403, acc 1
2020-02-16T15:41:28.815014: step 2471, loss 0.0266637, acc 1
2020-02-16T15:41:28.967784: step 2472, loss 0.0331905, acc 0.984375
2020-02-16T15:41:29.182330: step 2473, loss 0.0315966, acc 1
2020-02-16T15:41:29.339266: step 2474, loss 0.0590437, acc 0.984375
2020-02-16T15:41:29.490927: step 2475, loss 0.0274897, acc 0.984375
2020-02-16T15:41:29.739927: step 2476, loss 0.0498562, acc 0.96875
2020-02-16T15:41:29.945164: step 2477, loss 0.0372804, acc 0.984375
2020-02-16T15:41:30.095431: step 2478, loss 0.0384034, acc 0.984375
2020-02-16T15:41:30.290362: step 2479, loss 0.0361637, acc 0.984375
2020-02-16T15:41:30.500378: step 2480, loss 0.0332419, acc 0.984375
2020-02-16T15:41:31.039882: step 2481, loss 0.0260047, acc 0.984375
2020-02-16T15:41:31.286812: step 2482, loss 0.0153135, acc 1
2020-02-16T15:41:31.525317: step 2483, loss 0.0153064, acc 1
2020-02-16T15:41:31.705537: step 2484, loss 0.0643887, acc 0.953125
2020-02-16T15:41:31.887473: step 2485, loss 0.0371845, acc 1
2020-02-16T15:41:32.168212: step 2486, loss 0.0365292, acc 0.984375
2020-02-16T15:41:32.354453: step 2487, loss 0.0461589, acc 0.96875
2020-02-16T15:41:32.507522: step 2488, loss 0.0234253, acc 1
2020-02-16T15:41:32.742652: step 2489, loss 0.0277358, acc 1
2020-02-16T15:41:32.936284: step 2490, loss 0.0309603, acc 0.984375
2020-02-16T15:41:33.183816: step 2491, loss 0.00981454, acc 1
2020-02-16T15:41:33.324277: step 2492, loss 0.065915, acc 0.96875
2020-02-16T15:41:33.475801: step 2493, loss 0.0133859, acc 1
2020-02-16T15:41:33.687804: step 2494, loss 0.0213524, acc 0.984375
2020-02-16T15:41:33.842864: step 2495, loss 0.0258503, acc 1
2020-02-16T15:41:33.997862: step 2496, loss 0.0403067, acc 0.984375
2020-02-16T15:41:34.145705: step 2497, loss 0.0344285, acc 0.984375
2020-02-16T15:41:34.273511: step 2498, loss 0.177779, acc 0.96875
2020-02-16T15:41:34.456110: step 2499, loss 0.00465372, acc 1
2020-02-16T15:41:34.688804: step 2500, loss 0.0254923, acc 1

Evaluation:
2020-02-16T15:41:35.094536: step 2500, loss 0.840861, acc 0.738274

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2500

2020-02-16T15:41:37.003839: step 2501, loss 0.0703316, acc 0.953125
2020-02-16T15:41:37.177134: step 2502, loss 0.0143054, acc 1
2020-02-16T15:41:37.415764: step 2503, loss 0.0352856, acc 0.984375
2020-02-16T15:41:37.607038: step 2504, loss 0.0131314, acc 1
2020-02-16T15:41:37.825821: step 2505, loss 0.017012, acc 1
2020-02-16T15:41:38.022054: step 2506, loss 0.030317, acc 0.984375
2020-02-16T15:41:38.219716: step 2507, loss 0.0327767, acc 1
2020-02-16T15:41:38.414399: step 2508, loss 0.0273299, acc 0.984375
2020-02-16T15:41:38.613767: step 2509, loss 0.0577543, acc 0.96875
2020-02-16T15:41:38.923498: step 2510, loss 0.137518, acc 0.96875
2020-02-16T15:41:39.091947: step 2511, loss 0.0100483, acc 1
2020-02-16T15:41:39.342951: step 2512, loss 0.0424261, acc 1
2020-02-16T15:41:39.499406: step 2513, loss 0.0238096, acc 1
2020-02-16T15:41:39.639625: step 2514, loss 0.0952727, acc 0.9375
2020-02-16T15:41:39.790411: step 2515, loss 0.0356952, acc 1
2020-02-16T15:41:39.938166: step 2516, loss 0.023859, acc 1
2020-02-16T15:41:40.082065: step 2517, loss 0.0469006, acc 0.984375
2020-02-16T15:41:40.287059: step 2518, loss 0.0197148, acc 0.984375
2020-02-16T15:41:40.485314: step 2519, loss 0.0359673, acc 1
2020-02-16T15:41:40.658890: step 2520, loss 0.042504, acc 0.984375
2020-02-16T15:41:40.830270: step 2521, loss 0.0121291, acc 1
2020-02-16T15:41:40.971112: step 2522, loss 0.017263, acc 1
2020-02-16T15:41:41.110063: step 2523, loss 0.0154218, acc 1
2020-02-16T15:41:41.255242: step 2524, loss 0.0277842, acc 0.984375
2020-02-16T15:41:41.405449: step 2525, loss 0.0311359, acc 0.984375
2020-02-16T15:41:41.550989: step 2526, loss 0.0434595, acc 0.96875
2020-02-16T15:41:41.698749: step 2527, loss 0.026024, acc 0.984375
2020-02-16T15:41:41.847621: step 2528, loss 0.0325799, acc 0.984375
2020-02-16T15:41:42.021883: step 2529, loss 0.111079, acc 0.953125
2020-02-16T15:41:42.222086: step 2530, loss 0.0262894, acc 1
2020-02-16T15:41:42.373857: step 2531, loss 0.0264937, acc 1
2020-02-16T15:41:42.518035: step 2532, loss 0.0496382, acc 0.984375
2020-02-16T15:41:42.663533: step 2533, loss 0.0235192, acc 1
2020-02-16T15:41:42.815719: step 2534, loss 0.0300768, acc 0.984375
2020-02-16T15:41:42.963216: step 2535, loss 0.0107659, acc 1
2020-02-16T15:41:43.105660: step 2536, loss 0.0631853, acc 0.953125
2020-02-16T15:41:43.247568: step 2537, loss 0.0195308, acc 1
2020-02-16T15:41:43.403177: step 2538, loss 0.0387336, acc 0.984375
2020-02-16T15:41:43.606111: step 2539, loss 0.0214075, acc 1
2020-02-16T15:41:43.817049: step 2540, loss 0.00995146, acc 1
2020-02-16T15:41:43.976630: step 2541, loss 0.0214065, acc 1
2020-02-16T15:41:44.143000: step 2542, loss 0.022277, acc 1
2020-02-16T15:41:44.346965: step 2543, loss 0.0138684, acc 1
2020-02-16T15:41:44.518066: step 2544, loss 0.027101, acc 1
2020-02-16T15:41:44.806211: step 2545, loss 0.0210637, acc 1
2020-02-16T15:41:44.998078: step 2546, loss 0.0427426, acc 0.984375
2020-02-16T15:41:45.149066: step 2547, loss 0.0475181, acc 0.984375
2020-02-16T15:41:45.389500: step 2548, loss 0.020508, acc 1
2020-02-16T15:41:45.630522: step 2549, loss 0.0219928, acc 1
2020-02-16T15:41:45.870695: step 2550, loss 0.0434569, acc 0.983333
2020-02-16T15:41:46.116667: step 2551, loss 0.0139071, acc 1
2020-02-16T15:41:46.265297: step 2552, loss 0.0476698, acc 0.984375
2020-02-16T15:41:46.419435: step 2553, loss 0.0358299, acc 0.984375
2020-02-16T15:41:46.566897: step 2554, loss 0.010845, acc 1
2020-02-16T15:41:46.720258: step 2555, loss 0.0793949, acc 0.984375
2020-02-16T15:41:46.868154: step 2556, loss 0.0631995, acc 0.96875
2020-02-16T15:41:47.010314: step 2557, loss 0.0189787, acc 1
2020-02-16T15:41:47.151026: step 2558, loss 0.012474, acc 1
2020-02-16T15:41:47.296464: step 2559, loss 0.00802426, acc 1
2020-02-16T15:41:47.445133: step 2560, loss 0.0151477, acc 1
2020-02-16T15:41:47.594597: step 2561, loss 0.0243463, acc 1
2020-02-16T15:41:47.750591: step 2562, loss 0.0255573, acc 1
2020-02-16T15:41:47.923128: step 2563, loss 0.0298679, acc 0.984375
2020-02-16T15:41:48.073500: step 2564, loss 0.0526607, acc 0.984375
2020-02-16T15:41:48.224793: step 2565, loss 0.0234104, acc 1
2020-02-16T15:41:48.378175: step 2566, loss 0.0607227, acc 0.984375
2020-02-16T15:41:48.524343: step 2567, loss 0.00694036, acc 1
2020-02-16T15:41:48.676381: step 2568, loss 0.0206005, acc 1
2020-02-16T15:41:48.832630: step 2569, loss 0.0121349, acc 1
2020-02-16T15:41:48.992541: step 2570, loss 0.0169213, acc 1
2020-02-16T15:41:49.140318: step 2571, loss 0.0222426, acc 1
2020-02-16T15:41:49.283152: step 2572, loss 0.0196707, acc 1
2020-02-16T15:41:49.434549: step 2573, loss 0.0186445, acc 1
2020-02-16T15:41:49.581201: step 2574, loss 0.0205727, acc 1
2020-02-16T15:41:49.736304: step 2575, loss 0.0191744, acc 1
2020-02-16T15:41:49.882905: step 2576, loss 0.00402003, acc 1
2020-02-16T15:41:50.029518: step 2577, loss 0.0221391, acc 1
2020-02-16T15:41:50.175457: step 2578, loss 0.027643, acc 1
2020-02-16T15:41:50.323829: step 2579, loss 0.0230182, acc 1
2020-02-16T15:41:50.474906: step 2580, loss 0.0248842, acc 1
2020-02-16T15:41:50.618597: step 2581, loss 0.00903604, acc 1
2020-02-16T15:41:50.882058: step 2582, loss 0.0268275, acc 0.984375
2020-02-16T15:41:51.089994: step 2583, loss 0.0104251, acc 1
2020-02-16T15:41:51.276504: step 2584, loss 0.0153469, acc 1
2020-02-16T15:41:51.505481: step 2585, loss 0.0144553, acc 1
2020-02-16T15:41:51.793635: step 2586, loss 0.0252726, acc 0.984375
2020-02-16T15:41:51.978349: step 2587, loss 0.0136602, acc 1
2020-02-16T15:41:52.125479: step 2588, loss 0.0136913, acc 1
2020-02-16T15:41:52.271869: step 2589, loss 0.00793396, acc 1
2020-02-16T15:41:52.435447: step 2590, loss 0.0149875, acc 1
2020-02-16T15:41:52.700571: step 2591, loss 0.0185063, acc 1
2020-02-16T15:41:52.909716: step 2592, loss 0.00812616, acc 1
2020-02-16T15:41:53.183230: step 2593, loss 0.0396614, acc 0.984375
2020-02-16T15:41:53.342087: step 2594, loss 0.0109421, acc 1
2020-02-16T15:41:53.485047: step 2595, loss 0.0062718, acc 1
2020-02-16T15:41:53.732175: step 2596, loss 0.045624, acc 0.984375
2020-02-16T15:41:53.944669: step 2597, loss 0.0300231, acc 0.984375
2020-02-16T15:41:54.162861: step 2598, loss 0.0352661, acc 0.984375
2020-02-16T15:41:54.312951: step 2599, loss 0.0233207, acc 0.984375
2020-02-16T15:41:54.533438: step 2600, loss 0.00780098, acc 1

Evaluation:
2020-02-16T15:41:54.870976: step 2600, loss 0.875616, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2600

2020-02-16T15:41:56.809231: step 2601, loss 0.0137107, acc 1
2020-02-16T15:41:56.960084: step 2602, loss 0.0783843, acc 0.984375
2020-02-16T15:41:57.129964: step 2603, loss 0.0289312, acc 0.984375
2020-02-16T15:41:57.295920: step 2604, loss 0.042093, acc 0.984375
2020-02-16T15:41:57.445386: step 2605, loss 0.0158299, acc 1
2020-02-16T15:41:57.604896: step 2606, loss 0.0107811, acc 1
2020-02-16T15:41:57.764787: step 2607, loss 0.0179379, acc 1
2020-02-16T15:41:57.912214: step 2608, loss 0.023992, acc 0.984375
2020-02-16T15:41:58.066414: step 2609, loss 0.0354796, acc 0.984375
2020-02-16T15:41:58.215573: step 2610, loss 0.0201607, acc 0.984375
2020-02-16T15:41:58.360137: step 2611, loss 0.0159275, acc 1
2020-02-16T15:41:58.511338: step 2612, loss 0.0675894, acc 0.984375
2020-02-16T15:41:58.680416: step 2613, loss 0.0436536, acc 0.984375
2020-02-16T15:41:58.836027: step 2614, loss 0.0188783, acc 1
2020-02-16T15:41:58.980416: step 2615, loss 0.00636029, acc 1
2020-02-16T15:41:59.140270: step 2616, loss 0.0357525, acc 0.96875
2020-02-16T15:41:59.294531: step 2617, loss 0.0212304, acc 0.984375
2020-02-16T15:41:59.444959: step 2618, loss 0.0288384, acc 0.984375
2020-02-16T15:41:59.600870: step 2619, loss 0.00468943, acc 1
2020-02-16T15:41:59.758901: step 2620, loss 0.0839457, acc 0.96875
2020-02-16T15:41:59.919357: step 2621, loss 0.0281019, acc 0.984375
2020-02-16T15:42:00.072076: step 2622, loss 0.0505076, acc 0.96875
2020-02-16T15:42:00.224408: step 2623, loss 0.00756881, acc 1
2020-02-16T15:42:00.375471: step 2624, loss 0.0161443, acc 1
2020-02-16T15:42:00.529145: step 2625, loss 0.0172833, acc 1
2020-02-16T15:42:00.935102: step 2626, loss 0.0185528, acc 1
2020-02-16T15:42:01.116873: step 2627, loss 0.0361621, acc 0.984375
2020-02-16T15:42:01.270353: step 2628, loss 0.0561511, acc 0.984375
2020-02-16T15:42:01.419326: step 2629, loss 0.0405838, acc 0.984375
2020-02-16T15:42:01.615819: step 2630, loss 0.0460699, acc 0.984375
2020-02-16T15:42:01.842697: step 2631, loss 0.0728961, acc 0.984375
2020-02-16T15:42:01.999446: step 2632, loss 0.0445392, acc 0.96875
2020-02-16T15:42:02.171500: step 2633, loss 0.0250359, acc 1
2020-02-16T15:42:02.327787: step 2634, loss 0.024512, acc 1
2020-02-16T15:42:02.477899: step 2635, loss 0.0149625, acc 1
2020-02-16T15:42:02.645976: step 2636, loss 0.0178578, acc 1
2020-02-16T15:42:02.810008: step 2637, loss 0.0214949, acc 1
2020-02-16T15:42:02.962696: step 2638, loss 0.0110588, acc 1
2020-02-16T15:42:03.147824: step 2639, loss 0.0114341, acc 1
2020-02-16T15:42:03.318975: step 2640, loss 0.0086834, acc 1
2020-02-16T15:42:03.473108: step 2641, loss 0.0485327, acc 0.984375
2020-02-16T15:42:03.762951: step 2642, loss 0.0383456, acc 0.984375
2020-02-16T15:42:04.006765: step 2643, loss 0.018572, acc 1
2020-02-16T15:42:04.183115: step 2644, loss 0.0208908, acc 1
2020-02-16T15:42:04.352614: step 2645, loss 0.0113587, acc 1
2020-02-16T15:42:04.953063: step 2646, loss 0.0316755, acc 0.984375
2020-02-16T15:42:05.357419: step 2647, loss 0.0595277, acc 0.984375
2020-02-16T15:42:05.584505: step 2648, loss 0.0371038, acc 0.984375
2020-02-16T15:42:05.900707: step 2649, loss 0.0283378, acc 1
2020-02-16T15:42:06.048604: step 2650, loss 0.0068077, acc 1
2020-02-16T15:42:06.271015: step 2651, loss 0.0164118, acc 1
2020-02-16T15:42:06.444969: step 2652, loss 0.0130786, acc 1
2020-02-16T15:42:06.649269: step 2653, loss 0.0207361, acc 0.984375
2020-02-16T15:42:06.802014: step 2654, loss 0.0129016, acc 1
2020-02-16T15:42:06.954970: step 2655, loss 0.00964095, acc 1
2020-02-16T15:42:07.103878: step 2656, loss 0.0514204, acc 0.984375
2020-02-16T15:42:07.257211: step 2657, loss 0.0152953, acc 1
2020-02-16T15:42:07.404152: step 2658, loss 0.0593093, acc 0.984375
2020-02-16T15:42:07.561773: step 2659, loss 0.0774796, acc 0.96875
2020-02-16T15:42:07.730309: step 2660, loss 0.0110607, acc 1
2020-02-16T15:42:07.874966: step 2661, loss 0.00971553, acc 1
2020-02-16T15:42:08.020228: step 2662, loss 0.014229, acc 1
2020-02-16T15:42:08.170760: step 2663, loss 0.0204544, acc 1
2020-02-16T15:42:08.318876: step 2664, loss 0.00368704, acc 1
2020-02-16T15:42:08.466985: step 2665, loss 0.0128667, acc 1
2020-02-16T15:42:08.616373: step 2666, loss 0.0297511, acc 0.984375
2020-02-16T15:42:08.774143: step 2667, loss 0.0147341, acc 1
2020-02-16T15:42:08.917786: step 2668, loss 0.112533, acc 0.984375
2020-02-16T15:42:09.060554: step 2669, loss 0.0142521, acc 1
2020-02-16T15:42:09.202196: step 2670, loss 0.0348498, acc 0.96875
2020-02-16T15:42:09.343853: step 2671, loss 0.0254799, acc 0.984375
2020-02-16T15:42:09.485591: step 2672, loss 0.0148498, acc 1
2020-02-16T15:42:09.631374: step 2673, loss 0.0282354, acc 0.984375
2020-02-16T15:42:09.790027: step 2674, loss 0.046025, acc 0.984375
2020-02-16T15:42:09.967372: step 2675, loss 0.0108487, acc 1
2020-02-16T15:42:10.108873: step 2676, loss 0.00818343, acc 1
2020-02-16T15:42:10.254431: step 2677, loss 0.0195693, acc 1
2020-02-16T15:42:10.393747: step 2678, loss 0.0127901, acc 1
2020-02-16T15:42:10.535296: step 2679, loss 0.0198334, acc 1
2020-02-16T15:42:10.684609: step 2680, loss 0.0695662, acc 0.984375
2020-02-16T15:42:10.827848: step 2681, loss 0.00998579, acc 1
2020-02-16T15:42:10.968778: step 2682, loss 0.0093596, acc 1
2020-02-16T15:42:11.111144: step 2683, loss 0.00863034, acc 1
2020-02-16T15:42:11.257877: step 2684, loss 0.0166599, acc 1
2020-02-16T15:42:11.401054: step 2685, loss 0.0174389, acc 1
2020-02-16T15:42:11.543547: step 2686, loss 0.0128497, acc 1
2020-02-16T15:42:11.690287: step 2687, loss 0.0343748, acc 0.984375
2020-02-16T15:42:11.840849: step 2688, loss 0.00777651, acc 1
2020-02-16T15:42:11.984156: step 2689, loss 0.0224052, acc 0.984375
2020-02-16T15:42:12.132828: step 2690, loss 0.0183668, acc 1
2020-02-16T15:42:12.274486: step 2691, loss 0.0339477, acc 0.984375
2020-02-16T15:42:12.414458: step 2692, loss 0.0419585, acc 0.984375
2020-02-16T15:42:12.559628: step 2693, loss 0.0169458, acc 1
2020-02-16T15:42:12.710863: step 2694, loss 0.106506, acc 0.953125
2020-02-16T15:42:12.859816: step 2695, loss 0.0370004, acc 0.96875
2020-02-16T15:42:13.008181: step 2696, loss 0.025729, acc 0.984375
2020-02-16T15:42:13.156187: step 2697, loss 0.0322188, acc 1
2020-02-16T15:42:13.302008: step 2698, loss 0.016069, acc 1
2020-02-16T15:42:13.443773: step 2699, loss 0.00924682, acc 1
2020-02-16T15:42:13.579717: step 2700, loss 0.0147613, acc 1

Evaluation:
2020-02-16T15:42:13.943602: step 2700, loss 0.895169, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2700

2020-02-16T15:42:15.726249: step 2701, loss 0.0137833, acc 1
2020-02-16T15:42:15.866847: step 2702, loss 0.00475399, acc 1
2020-02-16T15:42:16.072694: step 2703, loss 0.0166442, acc 1
2020-02-16T15:42:16.252190: step 2704, loss 0.0515403, acc 0.984375
2020-02-16T15:42:16.430095: step 2705, loss 0.00548905, acc 1
2020-02-16T15:42:16.600133: step 2706, loss 0.0196126, acc 0.984375
2020-02-16T15:42:16.762121: step 2707, loss 0.0262278, acc 0.984375
2020-02-16T15:42:16.969576: step 2708, loss 0.00518584, acc 1
2020-02-16T15:42:17.127081: step 2709, loss 0.0119307, acc 1
2020-02-16T15:42:17.292474: step 2710, loss 0.0123837, acc 1
2020-02-16T15:42:17.428951: step 2711, loss 0.0194042, acc 1
2020-02-16T15:42:17.617849: step 2712, loss 0.0293639, acc 0.984375
2020-02-16T15:42:17.817929: step 2713, loss 0.0152874, acc 1
2020-02-16T15:42:18.033701: step 2714, loss 0.010791, acc 1
2020-02-16T15:42:18.210031: step 2715, loss 0.0110412, acc 1
2020-02-16T15:42:18.402746: step 2716, loss 0.0512436, acc 0.984375
2020-02-16T15:42:18.551697: step 2717, loss 0.0191771, acc 1
2020-02-16T15:42:18.709173: step 2718, loss 0.0353262, acc 1
2020-02-16T15:42:18.914811: step 2719, loss 0.0146037, acc 1
2020-02-16T15:42:19.147841: step 2720, loss 0.0216475, acc 0.984375
2020-02-16T15:42:19.326003: step 2721, loss 0.00929216, acc 1
2020-02-16T15:42:19.477177: step 2722, loss 0.0144811, acc 1
2020-02-16T15:42:19.623772: step 2723, loss 0.00378006, acc 1
2020-02-16T15:42:19.842744: step 2724, loss 0.0354159, acc 1
2020-02-16T15:42:20.009513: step 2725, loss 0.01185, acc 1
2020-02-16T15:42:20.197317: step 2726, loss 0.0329442, acc 0.984375
2020-02-16T15:42:20.347615: step 2727, loss 0.00725636, acc 1
2020-02-16T15:42:20.560144: step 2728, loss 0.0124931, acc 1
2020-02-16T15:42:20.726926: step 2729, loss 0.0155438, acc 1
2020-02-16T15:42:20.898172: step 2730, loss 0.0247713, acc 0.984375
2020-02-16T15:42:21.079920: step 2731, loss 0.0178096, acc 1
2020-02-16T15:42:21.225514: step 2732, loss 0.0277736, acc 0.984375
2020-02-16T15:42:21.380196: step 2733, loss 0.0487347, acc 0.96875
2020-02-16T15:42:21.610565: step 2734, loss 0.0250118, acc 0.984375
2020-02-16T15:42:21.763983: step 2735, loss 0.0635671, acc 0.984375
2020-02-16T15:42:21.937729: step 2736, loss 0.00477418, acc 1
2020-02-16T15:42:22.289463: step 2737, loss 0.0112388, acc 1
2020-02-16T15:42:22.493978: step 2738, loss 0.0109991, acc 1
2020-02-16T15:42:22.696190: step 2739, loss 0.027823, acc 0.984375
2020-02-16T15:42:22.885316: step 2740, loss 0.00553806, acc 1
2020-02-16T15:42:23.050496: step 2741, loss 0.00987736, acc 1
2020-02-16T15:42:23.378270: step 2742, loss 0.00529381, acc 1
2020-02-16T15:42:23.717187: step 2743, loss 0.0118948, acc 1
2020-02-16T15:42:23.924058: step 2744, loss 0.0119388, acc 1
2020-02-16T15:42:24.111764: step 2745, loss 0.0246875, acc 0.984375
2020-02-16T15:42:24.312381: step 2746, loss 0.0169164, acc 1
2020-02-16T15:42:24.490493: step 2747, loss 0.0286827, acc 0.984375
2020-02-16T15:42:24.688239: step 2748, loss 0.00853126, acc 1
2020-02-16T15:42:24.876280: step 2749, loss 0.0033288, acc 1
2020-02-16T15:42:25.072984: step 2750, loss 0.0393015, acc 0.984375
2020-02-16T15:42:25.262694: step 2751, loss 0.0235523, acc 0.984375
2020-02-16T15:42:25.428366: step 2752, loss 0.00830709, acc 1
2020-02-16T15:42:25.627402: step 2753, loss 0.0135967, acc 1
2020-02-16T15:42:25.820354: step 2754, loss 0.0096352, acc 1
2020-02-16T15:42:26.047483: step 2755, loss 0.00498903, acc 1
2020-02-16T15:42:26.203250: step 2756, loss 0.0239429, acc 0.984375
2020-02-16T15:42:26.372352: step 2757, loss 0.0158395, acc 1
2020-02-16T15:42:26.753424: step 2758, loss 0.0143509, acc 1
2020-02-16T15:42:27.053067: step 2759, loss 0.0122216, acc 1
2020-02-16T15:42:27.320025: step 2760, loss 0.0174662, acc 0.984375
2020-02-16T15:42:27.503289: step 2761, loss 0.0255122, acc 0.984375
2020-02-16T15:42:27.808443: step 2762, loss 0.00803357, acc 1
2020-02-16T15:42:27.976086: step 2763, loss 0.00634324, acc 1
2020-02-16T15:42:28.132394: step 2764, loss 0.00497211, acc 1
2020-02-16T15:42:28.298867: step 2765, loss 0.0754913, acc 0.96875
2020-02-16T15:42:28.516880: step 2766, loss 0.00415885, acc 1
2020-02-16T15:42:28.684884: step 2767, loss 0.0119899, acc 1
2020-02-16T15:42:28.834642: step 2768, loss 0.0159034, acc 1
2020-02-16T15:42:28.981665: step 2769, loss 0.0101615, acc 1
2020-02-16T15:42:29.147203: step 2770, loss 0.0152782, acc 1
2020-02-16T15:42:29.309404: step 2771, loss 0.0247666, acc 0.984375
2020-02-16T15:42:29.469743: step 2772, loss 0.0130647, acc 1
2020-02-16T15:42:29.620579: step 2773, loss 0.0234139, acc 0.984375
2020-02-16T15:42:29.772549: step 2774, loss 0.00455304, acc 1
2020-02-16T15:42:29.916560: step 2775, loss 0.00236097, acc 1
2020-02-16T15:42:30.067284: step 2776, loss 0.0051996, acc 1
2020-02-16T15:42:30.217949: step 2777, loss 0.012189, acc 1
2020-02-16T15:42:30.437188: step 2778, loss 0.0084948, acc 1
2020-02-16T15:42:30.605995: step 2779, loss 0.0226845, acc 0.984375
2020-02-16T15:42:30.849959: step 2780, loss 0.0114171, acc 1
2020-02-16T15:42:31.048750: step 2781, loss 0.0353197, acc 1
2020-02-16T15:42:31.204022: step 2782, loss 0.0598486, acc 0.96875
2020-02-16T15:42:31.403578: step 2783, loss 0.0083747, acc 1
2020-02-16T15:42:31.582955: step 2784, loss 0.0160602, acc 1
2020-02-16T15:42:31.774805: step 2785, loss 0.0159035, acc 1
2020-02-16T15:42:31.937286: step 2786, loss 0.00525732, acc 1
2020-02-16T15:42:32.153405: step 2787, loss 0.00400248, acc 1
2020-02-16T15:42:32.302751: step 2788, loss 0.00388866, acc 1
2020-02-16T15:42:32.506375: step 2789, loss 0.0642095, acc 0.96875
2020-02-16T15:42:32.724504: step 2790, loss 0.0230727, acc 1
2020-02-16T15:42:32.866189: step 2791, loss 0.00607906, acc 1
2020-02-16T15:42:33.003029: step 2792, loss 0.0232986, acc 0.984375
2020-02-16T15:42:33.152872: step 2793, loss 0.010652, acc 1
2020-02-16T15:42:33.332302: step 2794, loss 0.0345356, acc 0.984375
2020-02-16T15:42:33.513207: step 2795, loss 0.0146956, acc 0.984375
2020-02-16T15:42:33.732265: step 2796, loss 0.0301567, acc 0.984375
2020-02-16T15:42:34.037751: step 2797, loss 0.040708, acc 0.96875
2020-02-16T15:42:34.288484: step 2798, loss 0.0128275, acc 1
2020-02-16T15:42:34.541812: step 2799, loss 0.0381839, acc 0.984375
2020-02-16T15:42:34.753535: step 2800, loss 0.00794602, acc 1

Evaluation:
2020-02-16T15:42:35.157237: step 2800, loss 0.933864, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2800

2020-02-16T15:42:37.635793: step 2801, loss 0.03157, acc 0.984375
2020-02-16T15:42:37.803434: step 2802, loss 0.0512391, acc 0.984375
2020-02-16T15:42:37.957362: step 2803, loss 0.0146369, acc 1
2020-02-16T15:42:38.122183: step 2804, loss 0.0114308, acc 1
2020-02-16T15:42:38.303187: step 2805, loss 0.0251551, acc 1
2020-02-16T15:42:38.471892: step 2806, loss 0.0102605, acc 1
2020-02-16T15:42:38.730027: step 2807, loss 0.0149128, acc 1
2020-02-16T15:42:38.891648: step 2808, loss 0.00281355, acc 1
2020-02-16T15:42:39.051710: step 2809, loss 0.00403381, acc 1
2020-02-16T15:42:39.220354: step 2810, loss 0.0149025, acc 1
2020-02-16T15:42:39.439597: step 2811, loss 0.0080315, acc 1
2020-02-16T15:42:39.592647: step 2812, loss 0.0196075, acc 1
2020-02-16T15:42:39.895008: step 2813, loss 0.0133039, acc 1
2020-02-16T15:42:40.059597: step 2814, loss 0.00765079, acc 1
2020-02-16T15:42:40.422030: step 2815, loss 0.0616293, acc 0.96875
2020-02-16T15:42:40.609910: step 2816, loss 0.0280568, acc 0.984375
2020-02-16T15:42:40.809104: step 2817, loss 0.0107566, acc 1
2020-02-16T15:42:41.101296: step 2818, loss 0.0262876, acc 1
2020-02-16T15:42:41.409905: step 2819, loss 0.0146918, acc 1
2020-02-16T15:42:41.570490: step 2820, loss 0.0102292, acc 1
2020-02-16T15:42:41.777177: step 2821, loss 0.0930819, acc 0.953125
2020-02-16T15:42:41.910163: step 2822, loss 0.00404286, acc 1
2020-02-16T15:42:42.139754: step 2823, loss 0.013293, acc 1
2020-02-16T15:42:42.407721: step 2824, loss 0.0676444, acc 0.984375
2020-02-16T15:42:42.612645: step 2825, loss 0.015043, acc 1
2020-02-16T15:42:42.765003: step 2826, loss 0.00611182, acc 1
2020-02-16T15:42:42.930427: step 2827, loss 0.00831511, acc 1
2020-02-16T15:42:43.076167: step 2828, loss 0.0199598, acc 1
2020-02-16T15:42:43.325983: step 2829, loss 0.014366, acc 1
2020-02-16T15:42:43.531448: step 2830, loss 0.0187789, acc 0.984375
2020-02-16T15:42:43.727654: step 2831, loss 0.014976, acc 1
2020-02-16T15:42:43.953410: step 2832, loss 0.00735452, acc 1
2020-02-16T15:42:44.144904: step 2833, loss 0.0626478, acc 0.96875
2020-02-16T15:42:44.458190: step 2834, loss 0.00689831, acc 1
2020-02-16T15:42:44.760433: step 2835, loss 0.0137397, acc 1
2020-02-16T15:42:44.976873: step 2836, loss 0.015275, acc 1
2020-02-16T15:42:45.120515: step 2837, loss 0.0149809, acc 1
2020-02-16T15:42:45.347387: step 2838, loss 0.0405358, acc 0.984375
2020-02-16T15:42:45.492303: step 2839, loss 0.0156642, acc 1
2020-02-16T15:42:45.669097: step 2840, loss 0.108776, acc 0.96875
2020-02-16T15:42:45.824929: step 2841, loss 0.00986312, acc 1
2020-02-16T15:42:45.961840: step 2842, loss 0.0143636, acc 1
2020-02-16T15:42:46.093267: step 2843, loss 0.00717382, acc 1
2020-02-16T15:42:46.220233: step 2844, loss 0.00594867, acc 1
2020-02-16T15:42:46.347790: step 2845, loss 0.0242898, acc 1
2020-02-16T15:42:46.478647: step 2846, loss 0.00673259, acc 1
2020-02-16T15:42:46.606726: step 2847, loss 0.0192232, acc 1
2020-02-16T15:42:46.739276: step 2848, loss 0.0549567, acc 0.984375
2020-02-16T15:42:46.867963: step 2849, loss 0.0158562, acc 1
2020-02-16T15:42:46.992030: step 2850, loss 0.0125894, acc 1
2020-02-16T15:42:47.123007: step 2851, loss 0.0114817, acc 1
2020-02-16T15:42:47.251275: step 2852, loss 0.0238029, acc 1
2020-02-16T15:42:47.377211: step 2853, loss 0.0191387, acc 1
2020-02-16T15:42:47.506121: step 2854, loss 0.009089, acc 1
2020-02-16T15:42:47.630785: step 2855, loss 0.0122666, acc 1
2020-02-16T15:42:47.766184: step 2856, loss 0.01201, acc 1
2020-02-16T15:42:47.904777: step 2857, loss 0.00938553, acc 1
2020-02-16T15:42:48.029737: step 2858, loss 0.0168949, acc 1
2020-02-16T15:42:48.160448: step 2859, loss 0.012143, acc 1
2020-02-16T15:42:48.287922: step 2860, loss 0.0396812, acc 0.984375
2020-02-16T15:42:48.419879: step 2861, loss 0.0682149, acc 0.96875
2020-02-16T15:42:48.550256: step 2862, loss 0.0108252, acc 1
2020-02-16T15:42:48.678426: step 2863, loss 0.0199816, acc 0.984375
2020-02-16T15:42:48.806756: step 2864, loss 0.00884293, acc 1
2020-02-16T15:42:48.935806: step 2865, loss 0.015656, acc 1
2020-02-16T15:42:49.062820: step 2866, loss 0.00983663, acc 1
2020-02-16T15:42:49.193811: step 2867, loss 0.0142883, acc 1
2020-02-16T15:42:49.391411: step 2868, loss 0.00674338, acc 1
2020-02-16T15:42:49.539914: step 2869, loss 0.00622908, acc 1
2020-02-16T15:42:49.675103: step 2870, loss 0.00602012, acc 1
2020-02-16T15:42:49.820563: step 2871, loss 0.0189272, acc 0.984375
2020-02-16T15:42:49.959263: step 2872, loss 0.0183143, acc 0.984375
2020-02-16T15:42:50.100190: step 2873, loss 0.0748606, acc 0.96875
2020-02-16T15:42:50.236553: step 2874, loss 0.0670029, acc 0.953125
2020-02-16T15:42:50.366622: step 2875, loss 0.00676423, acc 1
2020-02-16T15:42:50.503061: step 2876, loss 0.018935, acc 1
2020-02-16T15:42:50.666336: step 2877, loss 0.010882, acc 1
2020-02-16T15:42:50.822707: step 2878, loss 0.00836558, acc 1
2020-02-16T15:42:50.954892: step 2879, loss 0.0116113, acc 1
2020-02-16T15:42:51.078389: step 2880, loss 0.0351097, acc 0.984375
2020-02-16T15:42:51.204474: step 2881, loss 0.0092614, acc 1
2020-02-16T15:42:51.330456: step 2882, loss 0.00661129, acc 1
2020-02-16T15:42:51.461270: step 2883, loss 0.00919559, acc 1
2020-02-16T15:42:51.591418: step 2884, loss 0.00890121, acc 1
2020-02-16T15:42:51.720727: step 2885, loss 0.0087064, acc 1
2020-02-16T15:42:51.863536: step 2886, loss 0.00699292, acc 1
2020-02-16T15:42:52.022571: step 2887, loss 0.00742292, acc 1
2020-02-16T15:42:52.146524: step 2888, loss 0.0371556, acc 0.96875
2020-02-16T15:42:52.271393: step 2889, loss 0.00179676, acc 1
2020-02-16T15:42:52.400485: step 2890, loss 0.0186393, acc 1
2020-02-16T15:42:52.527606: step 2891, loss 0.00666384, acc 1
2020-02-16T15:42:52.656200: step 2892, loss 0.00957595, acc 1
2020-02-16T15:42:52.790087: step 2893, loss 0.00911428, acc 1
2020-02-16T15:42:52.924810: step 2894, loss 0.00735241, acc 1
2020-02-16T15:42:53.118874: step 2895, loss 0.0152563, acc 1
2020-02-16T15:42:53.259046: step 2896, loss 0.00511368, acc 1
2020-02-16T15:42:53.408197: step 2897, loss 0.0132802, acc 1
2020-02-16T15:42:53.540446: step 2898, loss 0.0146245, acc 1
2020-02-16T15:42:53.679545: step 2899, loss 0.0187431, acc 0.984375
2020-02-16T15:42:53.841831: step 2900, loss 0.00780698, acc 1

Evaluation:
2020-02-16T15:42:54.078171: step 2900, loss 0.954964, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-2900

2020-02-16T15:42:56.466220: step 2901, loss 0.00656187, acc 1
2020-02-16T15:42:56.706696: step 2902, loss 0.00165865, acc 1
2020-02-16T15:42:56.912727: step 2903, loss 0.0136863, acc 1
2020-02-16T15:42:57.161149: step 2904, loss 0.0384761, acc 0.984375
2020-02-16T15:42:57.393376: step 2905, loss 0.00796266, acc 1
2020-02-16T15:42:57.615119: step 2906, loss 0.00877343, acc 1
2020-02-16T15:42:57.860160: step 2907, loss 0.0850519, acc 0.984375
2020-02-16T15:42:58.036328: step 2908, loss 0.00914507, acc 1
2020-02-16T15:42:58.196523: step 2909, loss 0.0203334, acc 0.984375
2020-02-16T15:42:58.359309: step 2910, loss 0.00489252, acc 1
2020-02-16T15:42:58.552870: step 2911, loss 0.0151197, acc 1
2020-02-16T15:42:58.714669: step 2912, loss 0.0161008, acc 1
2020-02-16T15:42:58.860716: step 2913, loss 0.0158778, acc 1
2020-02-16T15:42:59.004501: step 2914, loss 0.0361853, acc 0.984375
2020-02-16T15:42:59.145197: step 2915, loss 0.00835095, acc 1
2020-02-16T15:42:59.295802: step 2916, loss 0.0467354, acc 0.984375
2020-02-16T15:42:59.459250: step 2917, loss 0.00414342, acc 1
2020-02-16T15:42:59.683680: step 2918, loss 0.0120017, acc 1
2020-02-16T15:42:59.933888: step 2919, loss 0.0306205, acc 0.984375
2020-02-16T15:43:00.139710: step 2920, loss 0.0184248, acc 0.984375
2020-02-16T15:43:00.306133: step 2921, loss 0.00296298, acc 1
2020-02-16T15:43:00.483994: step 2922, loss 0.00632821, acc 1
2020-02-16T15:43:00.641361: step 2923, loss 0.00526079, acc 1
2020-02-16T15:43:00.798694: step 2924, loss 0.0185301, acc 0.984375
2020-02-16T15:43:01.125510: step 2925, loss 0.0303744, acc 0.984375
2020-02-16T15:43:01.422394: step 2926, loss 0.0140641, acc 1
2020-02-16T15:43:01.762484: step 2927, loss 0.00631316, acc 1
2020-02-16T15:43:02.055152: step 2928, loss 0.0141901, acc 1
2020-02-16T15:43:02.277044: step 2929, loss 0.0276491, acc 0.984375
2020-02-16T15:43:02.448086: step 2930, loss 0.0472992, acc 0.984375
2020-02-16T15:43:02.654496: step 2931, loss 0.00955873, acc 1
2020-02-16T15:43:02.901316: step 2932, loss 0.00876235, acc 1
2020-02-16T15:43:03.072982: step 2933, loss 0.00734301, acc 1
2020-02-16T15:43:03.257421: step 2934, loss 0.0310497, acc 0.984375
2020-02-16T15:43:03.438872: step 2935, loss 0.00651658, acc 1
2020-02-16T15:43:03.645029: step 2936, loss 0.0101451, acc 1
2020-02-16T15:43:03.847648: step 2937, loss 0.00700641, acc 1
2020-02-16T15:43:04.005462: step 2938, loss 0.0147728, acc 1
2020-02-16T15:43:04.207396: step 2939, loss 0.00345239, acc 1
2020-02-16T15:43:04.411188: step 2940, loss 0.0129625, acc 1
2020-02-16T15:43:04.572766: step 2941, loss 0.00931506, acc 1
2020-02-16T15:43:04.758553: step 2942, loss 0.00382756, acc 1
2020-02-16T15:43:05.041540: step 2943, loss 0.0336315, acc 0.984375
2020-02-16T15:43:05.230541: step 2944, loss 0.00875294, acc 1
2020-02-16T15:43:05.458285: step 2945, loss 0.0104485, acc 1
2020-02-16T15:43:05.687191: step 2946, loss 0.0140409, acc 1
2020-02-16T15:43:05.888731: step 2947, loss 0.0808548, acc 0.984375
2020-02-16T15:43:06.062267: step 2948, loss 0.0351077, acc 0.984375
2020-02-16T15:43:06.232463: step 2949, loss 0.00724585, acc 1
2020-02-16T15:43:06.403998: step 2950, loss 0.00840483, acc 1
2020-02-16T15:43:06.571175: step 2951, loss 0.0243865, acc 1
2020-02-16T15:43:06.734346: step 2952, loss 0.00952135, acc 1
2020-02-16T15:43:06.911754: step 2953, loss 0.031186, acc 0.96875
2020-02-16T15:43:07.081649: step 2954, loss 0.0668728, acc 0.96875
2020-02-16T15:43:07.248174: step 2955, loss 0.0372798, acc 0.984375
2020-02-16T15:43:07.418870: step 2956, loss 0.00959591, acc 1
2020-02-16T15:43:07.649046: step 2957, loss 0.00535783, acc 1
2020-02-16T15:43:07.912926: step 2958, loss 0.0205019, acc 1
2020-02-16T15:43:08.138333: step 2959, loss 0.0219833, acc 0.984375
2020-02-16T15:43:08.313310: step 2960, loss 0.0174414, acc 1
2020-02-16T15:43:08.483067: step 2961, loss 0.0304652, acc 0.984375
2020-02-16T15:43:08.655123: step 2962, loss 0.00612866, acc 1
2020-02-16T15:43:08.833720: step 2963, loss 0.0151763, acc 1
2020-02-16T15:43:08.994446: step 2964, loss 0.0154443, acc 1
2020-02-16T15:43:09.164613: step 2965, loss 0.0179784, acc 1
2020-02-16T15:43:09.337592: step 2966, loss 0.0395972, acc 0.96875
2020-02-16T15:43:09.508952: step 2967, loss 0.00501697, acc 1
2020-02-16T15:43:09.685784: step 2968, loss 0.00577681, acc 1
2020-02-16T15:43:09.857962: step 2969, loss 0.0128398, acc 1
2020-02-16T15:43:10.023668: step 2970, loss 0.00901939, acc 1
2020-02-16T15:43:10.191268: step 2971, loss 0.0672299, acc 0.984375
2020-02-16T15:43:10.376199: step 2972, loss 0.00367326, acc 1
2020-02-16T15:43:10.541330: step 2973, loss 0.103104, acc 0.953125
2020-02-16T15:43:10.726328: step 2974, loss 0.104161, acc 0.96875
2020-02-16T15:43:10.919303: step 2975, loss 0.0629859, acc 0.96875
2020-02-16T15:43:11.093054: step 2976, loss 0.0322949, acc 1
2020-02-16T15:43:11.258540: step 2977, loss 0.0146142, acc 1
2020-02-16T15:43:11.438757: step 2978, loss 0.0112434, acc 1
2020-02-16T15:43:11.613213: step 2979, loss 0.0298588, acc 0.984375
2020-02-16T15:43:11.794723: step 2980, loss 0.0271082, acc 0.984375
2020-02-16T15:43:11.974811: step 2981, loss 0.00734707, acc 1
2020-02-16T15:43:12.147522: step 2982, loss 0.032618, acc 0.984375
2020-02-16T15:43:12.319036: step 2983, loss 0.0033401, acc 1
2020-02-16T15:43:12.485534: step 2984, loss 0.00387243, acc 1
2020-02-16T15:43:12.700133: step 2985, loss 0.00425199, acc 1
2020-02-16T15:43:12.936689: step 2986, loss 0.0458557, acc 0.96875
2020-02-16T15:43:13.140336: step 2987, loss 0.020367, acc 1
2020-02-16T15:43:13.316253: step 2988, loss 0.0209095, acc 1
2020-02-16T15:43:13.487139: step 2989, loss 0.00279166, acc 1
2020-02-16T15:43:13.657856: step 2990, loss 0.00489597, acc 1
2020-02-16T15:43:13.842178: step 2991, loss 0.0140439, acc 1
2020-02-16T15:43:14.008318: step 2992, loss 0.0119611, acc 1
2020-02-16T15:43:14.180566: step 2993, loss 0.0016434, acc 1
2020-02-16T15:43:14.356323: step 2994, loss 0.0462993, acc 0.984375
2020-02-16T15:43:14.521982: step 2995, loss 0.00782092, acc 1
2020-02-16T15:43:14.695588: step 2996, loss 0.0223265, acc 0.984375
2020-02-16T15:43:14.880838: step 2997, loss 0.0190217, acc 1
2020-02-16T15:43:15.058701: step 2998, loss 0.030358, acc 0.984375
2020-02-16T15:43:15.226193: step 2999, loss 0.0108708, acc 1
2020-02-16T15:43:15.402176: step 3000, loss 0.0032856, acc 1

Evaluation:
2020-02-16T15:43:15.744100: step 3000, loss 0.976026, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581838500/checkpoints/model-3000

