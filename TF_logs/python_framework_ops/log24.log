WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:30:19.289191 4554300864 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:30:19.289407 4554300864 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:30:19.289509 4554300864 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 03:30:19.789793 4554300864 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 03:30:19.790081 4554300864 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 03:30:19.790333: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 03:30:19.806440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd255306160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 03:30:19.806462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 03:30:19.806818 4554300864 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 03:30:19.810442 4554300864 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 03:30:19.823015 4554300864 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 03:30:19.833767 4554300864 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 03:30:19.861261 4554300864 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 03:30:19.870540 4554300864 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 03:30:19.870763 4554300864 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 03:30:19.883364 4554300864 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 03:30:19.886341 4554300864 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 03:30:19.915478 4554300864 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 03:30:20.154846 4554300864 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 03:30:20.155087 4554300864 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 03:30:20.161164 4554300864 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 03:30:20.179296 4554300864 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 03:30:20.180387 4554300864 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 03:30:20.195768 4554300864 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 03:30:20.196849 4554300864 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 03:30:20.213835 4554300864 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 03:30:20.215168 4554300864 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 03:30:20.231781 4554300864 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 03:30:20.232872 4554300864 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 03:30:20.249804 4554300864 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 03:30:20.251035 4554300864 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 03:30:20.267862 4554300864 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 03:30:20.269001 4554300864 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 03:30:20.285490 4554300864 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 03:30:20.286918 4554300864 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 03:30:20.303676 4554300864 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 03:30:20.305092 4554300864 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 03:30:20.321748 4554300864 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 03:30:20.322896 4554300864 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 03:30:20.326951 4554300864 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 03:30:20.627624 4554300864 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 03:30:20.627809 4554300864 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 03:30:20.751073 4554300864 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 03:30:21.306858 4554300864 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 03:31:43.890618 4554300864 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820

2020-02-08T03:30:21.306418: step 1, loss 1.8975, acc 0.546875
2020-02-08T03:30:21.461394: step 2, loss 2.51223, acc 0.421875
2020-02-08T03:30:21.581701: step 3, loss 2.03561, acc 0.46875
2020-02-08T03:30:21.700678: step 4, loss 1.95473, acc 0.5
2020-02-08T03:30:21.817128: step 5, loss 2.0062, acc 0.5625
2020-02-08T03:30:21.934510: step 6, loss 2.35594, acc 0.46875
2020-02-08T03:30:22.055841: step 7, loss 1.53953, acc 0.59375
2020-02-08T03:30:22.174089: step 8, loss 2.45081, acc 0.390625
2020-02-08T03:30:22.290855: step 9, loss 1.48387, acc 0.5625
2020-02-08T03:30:22.407796: step 10, loss 2.14677, acc 0.4375
2020-02-08T03:30:22.526128: step 11, loss 2.06979, acc 0.515625
2020-02-08T03:30:22.642100: step 12, loss 1.93125, acc 0.359375
2020-02-08T03:30:22.757714: step 13, loss 1.79137, acc 0.515625
2020-02-08T03:30:22.883029: step 14, loss 1.73345, acc 0.5
2020-02-08T03:30:22.999720: step 15, loss 1.87951, acc 0.484375
2020-02-08T03:30:23.117027: step 16, loss 1.68596, acc 0.546875
2020-02-08T03:30:23.236469: step 17, loss 1.80557, acc 0.421875
2020-02-08T03:30:23.353126: step 18, loss 1.79233, acc 0.5625
2020-02-08T03:30:23.471278: step 19, loss 1.87749, acc 0.46875
2020-02-08T03:30:23.585815: step 20, loss 2.10809, acc 0.46875
2020-02-08T03:30:23.704095: step 21, loss 1.57838, acc 0.53125
2020-02-08T03:30:23.826127: step 22, loss 1.78401, acc 0.453125
2020-02-08T03:30:23.942817: step 23, loss 1.50701, acc 0.5625
2020-02-08T03:30:24.061682: step 24, loss 1.72927, acc 0.5
2020-02-08T03:30:24.178892: step 25, loss 1.53678, acc 0.5
2020-02-08T03:30:24.300081: step 26, loss 1.8153, acc 0.53125
2020-02-08T03:30:24.417997: step 27, loss 1.51854, acc 0.546875
2020-02-08T03:30:24.536010: step 28, loss 1.29087, acc 0.5625
2020-02-08T03:30:24.654161: step 29, loss 1.67845, acc 0.5
2020-02-08T03:30:24.773907: step 30, loss 1.46969, acc 0.53125
2020-02-08T03:30:24.894442: step 31, loss 1.8583, acc 0.421875
2020-02-08T03:30:25.013847: step 32, loss 2.02605, acc 0.46875
2020-02-08T03:30:25.132872: step 33, loss 1.56655, acc 0.515625
2020-02-08T03:30:25.247654: step 34, loss 1.60403, acc 0.484375
2020-02-08T03:30:25.369774: step 35, loss 1.71695, acc 0.484375
2020-02-08T03:30:25.488166: step 36, loss 1.63566, acc 0.5625
2020-02-08T03:30:25.610360: step 37, loss 1.72082, acc 0.484375
2020-02-08T03:30:25.729671: step 38, loss 1.59466, acc 0.484375
2020-02-08T03:30:25.848073: step 39, loss 1.16034, acc 0.671875
2020-02-08T03:30:25.966787: step 40, loss 1.69476, acc 0.5
2020-02-08T03:30:26.088060: step 41, loss 1.64123, acc 0.546875
2020-02-08T03:30:26.205944: step 42, loss 1.43868, acc 0.515625
2020-02-08T03:30:26.323000: step 43, loss 1.51869, acc 0.5625
2020-02-08T03:30:26.444769: step 44, loss 1.4796, acc 0.5
2020-02-08T03:30:26.560866: step 45, loss 1.48617, acc 0.53125
2020-02-08T03:30:26.676133: step 46, loss 1.4584, acc 0.53125
2020-02-08T03:30:26.792488: step 47, loss 1.49424, acc 0.53125
2020-02-08T03:30:26.912552: step 48, loss 1.69715, acc 0.515625
2020-02-08T03:30:27.031425: step 49, loss 1.52424, acc 0.5
2020-02-08T03:30:27.145756: step 50, loss 1.43126, acc 0.515625
2020-02-08T03:30:27.264991: step 51, loss 1.49712, acc 0.546875
2020-02-08T03:30:27.382308: step 52, loss 1.44033, acc 0.609375
2020-02-08T03:30:27.495673: step 53, loss 1.61703, acc 0.46875
2020-02-08T03:30:27.612713: step 54, loss 1.43457, acc 0.5
2020-02-08T03:30:27.730694: step 55, loss 1.37042, acc 0.5
2020-02-08T03:30:27.850254: step 56, loss 1.76244, acc 0.453125
2020-02-08T03:30:27.969566: step 57, loss 1.54796, acc 0.53125
2020-02-08T03:30:28.085230: step 58, loss 1.25242, acc 0.546875
2020-02-08T03:30:28.201319: step 59, loss 1.6711, acc 0.484375
2020-02-08T03:30:28.319846: step 60, loss 1.81167, acc 0.40625
2020-02-08T03:30:28.435530: step 61, loss 1.90675, acc 0.453125
2020-02-08T03:30:28.553876: step 62, loss 1.54948, acc 0.484375
2020-02-08T03:30:28.673770: step 63, loss 1.83381, acc 0.4375
2020-02-08T03:30:28.791188: step 64, loss 1.00445, acc 0.65625
2020-02-08T03:30:28.913662: step 65, loss 1.44942, acc 0.5
2020-02-08T03:30:29.032060: step 66, loss 1.36836, acc 0.609375
2020-02-08T03:30:29.150151: step 67, loss 1.45616, acc 0.46875
2020-02-08T03:30:29.273384: step 68, loss 1.9681, acc 0.40625
2020-02-08T03:30:29.391126: step 69, loss 1.51025, acc 0.578125
2020-02-08T03:30:29.507504: step 70, loss 1.49052, acc 0.453125
2020-02-08T03:30:29.623888: step 71, loss 1.56828, acc 0.46875
2020-02-08T03:30:29.739136: step 72, loss 1.58553, acc 0.578125
2020-02-08T03:30:29.861687: step 73, loss 1.68423, acc 0.46875
2020-02-08T03:30:29.980226: step 74, loss 1.49374, acc 0.46875
2020-02-08T03:30:30.093636: step 75, loss 1.39176, acc 0.515625
2020-02-08T03:30:30.211362: step 76, loss 1.36269, acc 0.5
2020-02-08T03:30:30.331356: step 77, loss 1.27753, acc 0.5
2020-02-08T03:30:30.449284: step 78, loss 1.29415, acc 0.5
2020-02-08T03:30:30.567441: step 79, loss 1.35845, acc 0.53125
2020-02-08T03:30:30.683932: step 80, loss 1.30639, acc 0.546875
2020-02-08T03:30:30.801667: step 81, loss 1.74337, acc 0.515625
2020-02-08T03:30:30.920370: step 82, loss 1.48268, acc 0.546875
2020-02-08T03:30:31.036355: step 83, loss 1.35113, acc 0.546875
2020-02-08T03:30:31.152904: step 84, loss 1.16227, acc 0.625
2020-02-08T03:30:31.271087: step 85, loss 1.75502, acc 0.5
2020-02-08T03:30:31.387157: step 86, loss 1.53372, acc 0.5625
2020-02-08T03:30:31.506434: step 87, loss 1.15541, acc 0.578125
2020-02-08T03:30:31.621549: step 88, loss 1.57179, acc 0.53125
2020-02-08T03:30:31.736359: step 89, loss 1.22518, acc 0.546875
2020-02-08T03:30:31.858863: step 90, loss 1.29355, acc 0.5625
2020-02-08T03:30:31.977052: step 91, loss 1.30197, acc 0.546875
2020-02-08T03:30:32.093638: step 92, loss 1.42519, acc 0.546875
2020-02-08T03:30:32.209039: step 93, loss 1.05039, acc 0.53125
2020-02-08T03:30:32.326882: step 94, loss 1.55046, acc 0.515625
2020-02-08T03:30:32.442825: step 95, loss 1.48688, acc 0.515625
2020-02-08T03:30:32.559943: step 96, loss 1.59938, acc 0.484375
2020-02-08T03:30:32.679625: step 97, loss 1.22542, acc 0.5
2020-02-08T03:30:32.796005: step 98, loss 1.4263, acc 0.5
2020-02-08T03:30:32.918490: step 99, loss 1.44098, acc 0.53125
2020-02-08T03:30:33.034149: step 100, loss 1.08778, acc 0.5

Evaluation:
2020-02-08T03:30:33.268370: step 100, loss 0.968999, acc 0.536585

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-100

2020-02-08T03:30:35.350313: step 101, loss 1.23107, acc 0.546875
2020-02-08T03:30:35.466076: step 102, loss 1.30145, acc 0.578125
2020-02-08T03:30:35.581514: step 103, loss 1.20752, acc 0.515625
2020-02-08T03:30:35.695896: step 104, loss 1.20036, acc 0.53125
2020-02-08T03:30:35.814098: step 105, loss 1.32528, acc 0.5
2020-02-08T03:30:35.932430: step 106, loss 1.3738, acc 0.46875
2020-02-08T03:30:36.050552: step 107, loss 1.19731, acc 0.59375
2020-02-08T03:30:36.168696: step 108, loss 1.41885, acc 0.5
2020-02-08T03:30:36.285957: step 109, loss 1.3008, acc 0.515625
2020-02-08T03:30:36.402118: step 110, loss 1.12224, acc 0.59375
2020-02-08T03:30:36.518134: step 111, loss 0.996585, acc 0.640625
2020-02-08T03:30:36.635970: step 112, loss 1.23753, acc 0.53125
2020-02-08T03:30:36.753421: step 113, loss 1.39563, acc 0.46875
2020-02-08T03:30:36.874784: step 114, loss 1.59392, acc 0.484375
2020-02-08T03:30:36.992403: step 115, loss 1.5668, acc 0.421875
2020-02-08T03:30:37.108008: step 116, loss 1.35225, acc 0.578125
2020-02-08T03:30:37.223783: step 117, loss 1.05519, acc 0.578125
2020-02-08T03:30:37.339721: step 118, loss 1.19386, acc 0.546875
2020-02-08T03:30:37.455564: step 119, loss 1.63952, acc 0.40625
2020-02-08T03:30:37.573394: step 120, loss 1.31446, acc 0.515625
2020-02-08T03:30:37.689126: step 121, loss 0.914378, acc 0.65625
2020-02-08T03:30:37.810949: step 122, loss 1.11894, acc 0.625
2020-02-08T03:30:37.931556: step 123, loss 1.01679, acc 0.5
2020-02-08T03:30:38.048189: step 124, loss 1.47956, acc 0.53125
2020-02-08T03:30:38.166015: step 125, loss 1.206, acc 0.59375
2020-02-08T03:30:38.291116: step 126, loss 1.16856, acc 0.5625
2020-02-08T03:30:38.405807: step 127, loss 1.28232, acc 0.53125
2020-02-08T03:30:38.525512: step 128, loss 1.22734, acc 0.5625
2020-02-08T03:30:38.642625: step 129, loss 1.26052, acc 0.609375
2020-02-08T03:30:38.760432: step 130, loss 1.49627, acc 0.453125
2020-02-08T03:30:38.887758: step 131, loss 1.21177, acc 0.484375
2020-02-08T03:30:39.004737: step 132, loss 1.23722, acc 0.5
2020-02-08T03:30:39.125122: step 133, loss 1.379, acc 0.421875
2020-02-08T03:30:39.243760: step 134, loss 1.26124, acc 0.53125
2020-02-08T03:30:39.361531: step 135, loss 1.21928, acc 0.5625
2020-02-08T03:30:39.480447: step 136, loss 1.34219, acc 0.5
2020-02-08T03:30:39.595617: step 137, loss 1.25465, acc 0.46875
2020-02-08T03:30:39.713226: step 138, loss 1.21344, acc 0.515625
2020-02-08T03:30:39.833168: step 139, loss 0.85624, acc 0.65625
2020-02-08T03:30:39.950789: step 140, loss 1.20451, acc 0.515625
2020-02-08T03:30:40.068345: step 141, loss 1.36919, acc 0.5
2020-02-08T03:30:40.187508: step 142, loss 1.13674, acc 0.546875
2020-02-08T03:30:40.304319: step 143, loss 0.954016, acc 0.578125
2020-02-08T03:30:40.422963: step 144, loss 1.22181, acc 0.46875
2020-02-08T03:30:40.541193: step 145, loss 0.977051, acc 0.546875
2020-02-08T03:30:40.657519: step 146, loss 1.02578, acc 0.515625
2020-02-08T03:30:40.778324: step 147, loss 1.10509, acc 0.53125
2020-02-08T03:30:40.897202: step 148, loss 1.36227, acc 0.484375
2020-02-08T03:30:41.014484: step 149, loss 1.27496, acc 0.5625
2020-02-08T03:30:41.133317: step 150, loss 0.988073, acc 0.583333
2020-02-08T03:30:41.251570: step 151, loss 0.801672, acc 0.640625
2020-02-08T03:30:41.371600: step 152, loss 1.309, acc 0.5
2020-02-08T03:30:41.488602: step 153, loss 1.07442, acc 0.5
2020-02-08T03:30:41.608120: step 154, loss 1.20211, acc 0.46875
2020-02-08T03:30:41.726562: step 155, loss 0.99391, acc 0.609375
2020-02-08T03:30:41.846722: step 156, loss 0.809884, acc 0.65625
2020-02-08T03:30:41.963426: step 157, loss 0.888517, acc 0.625
2020-02-08T03:30:42.082372: step 158, loss 0.865955, acc 0.59375
2020-02-08T03:30:42.197350: step 159, loss 0.985808, acc 0.59375
2020-02-08T03:30:42.314717: step 160, loss 0.916914, acc 0.640625
2020-02-08T03:30:42.433337: step 161, loss 0.712172, acc 0.625
2020-02-08T03:30:42.549662: step 162, loss 1.07764, acc 0.625
2020-02-08T03:30:42.668102: step 163, loss 1.0779, acc 0.5625
2020-02-08T03:30:42.786546: step 164, loss 0.693547, acc 0.65625
2020-02-08T03:30:42.907954: step 165, loss 0.757658, acc 0.6875
2020-02-08T03:30:43.031199: step 166, loss 1.16039, acc 0.484375
2020-02-08T03:30:43.145567: step 167, loss 0.86963, acc 0.578125
2020-02-08T03:30:43.263009: step 168, loss 1.08248, acc 0.5625
2020-02-08T03:30:43.381857: step 169, loss 0.917558, acc 0.609375
2020-02-08T03:30:43.499614: step 170, loss 0.833823, acc 0.65625
2020-02-08T03:30:43.619113: step 171, loss 0.977966, acc 0.546875
2020-02-08T03:30:43.734961: step 172, loss 0.769166, acc 0.671875
2020-02-08T03:30:43.857326: step 173, loss 0.786757, acc 0.609375
2020-02-08T03:30:43.979105: step 174, loss 1.01465, acc 0.578125
2020-02-08T03:30:44.096712: step 175, loss 0.83627, acc 0.640625
2020-02-08T03:30:44.217201: step 176, loss 0.852326, acc 0.65625
2020-02-08T03:30:44.334680: step 177, loss 1.11582, acc 0.53125
2020-02-08T03:30:44.453034: step 178, loss 1.12289, acc 0.546875
2020-02-08T03:30:44.569197: step 179, loss 0.915333, acc 0.59375
2020-02-08T03:30:44.684718: step 180, loss 1.07489, acc 0.5625
2020-02-08T03:30:44.799043: step 181, loss 1.05276, acc 0.546875
2020-02-08T03:30:44.923381: step 182, loss 1.14952, acc 0.546875
2020-02-08T03:30:45.040663: step 183, loss 0.856884, acc 0.640625
2020-02-08T03:30:45.157246: step 184, loss 0.674086, acc 0.59375
2020-02-08T03:30:45.275210: step 185, loss 1.01412, acc 0.5
2020-02-08T03:30:45.390945: step 186, loss 0.788585, acc 0.53125
2020-02-08T03:30:45.508915: step 187, loss 0.766584, acc 0.671875
2020-02-08T03:30:45.625783: step 188, loss 1.12968, acc 0.484375
2020-02-08T03:30:45.740913: step 189, loss 0.846791, acc 0.640625
2020-02-08T03:30:45.861915: step 190, loss 1.01778, acc 0.546875
2020-02-08T03:30:45.986439: step 191, loss 0.797618, acc 0.625
2020-02-08T03:30:46.106582: step 192, loss 1.05525, acc 0.46875
2020-02-08T03:30:46.223960: step 193, loss 0.76636, acc 0.65625
2020-02-08T03:30:46.342275: step 194, loss 1.02234, acc 0.546875
2020-02-08T03:30:46.463093: step 195, loss 0.959303, acc 0.53125
2020-02-08T03:30:46.581345: step 196, loss 0.643843, acc 0.6875
2020-02-08T03:30:46.694787: step 197, loss 0.976016, acc 0.578125
2020-02-08T03:30:46.812589: step 198, loss 0.984921, acc 0.59375
2020-02-08T03:30:46.930497: step 199, loss 0.856456, acc 0.59375
2020-02-08T03:30:47.047066: step 200, loss 0.832696, acc 0.5625

Evaluation:
2020-02-08T03:30:47.232008: step 200, loss 0.766214, acc 0.543152

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-200

2020-02-08T03:30:48.736186: step 201, loss 0.848562, acc 0.59375
2020-02-08T03:30:48.860702: step 202, loss 0.913246, acc 0.625
2020-02-08T03:30:48.977945: step 203, loss 0.855284, acc 0.6875
2020-02-08T03:30:49.093729: step 204, loss 0.719739, acc 0.671875
2020-02-08T03:30:49.212342: step 205, loss 0.896877, acc 0.5625
2020-02-08T03:30:49.331864: step 206, loss 0.839446, acc 0.625
2020-02-08T03:30:49.449617: step 207, loss 0.712774, acc 0.65625
2020-02-08T03:30:49.568837: step 208, loss 0.86582, acc 0.671875
2020-02-08T03:30:49.683618: step 209, loss 0.762014, acc 0.609375
2020-02-08T03:30:49.804147: step 210, loss 0.783362, acc 0.65625
2020-02-08T03:30:49.925610: step 211, loss 0.654843, acc 0.734375
2020-02-08T03:30:50.041430: step 212, loss 0.916574, acc 0.546875
2020-02-08T03:30:50.157237: step 213, loss 0.517882, acc 0.75
2020-02-08T03:30:50.272284: step 214, loss 0.75575, acc 0.5625
2020-02-08T03:30:50.387710: step 215, loss 0.83978, acc 0.59375
2020-02-08T03:30:50.505764: step 216, loss 0.727676, acc 0.609375
2020-02-08T03:30:50.624092: step 217, loss 0.901879, acc 0.5625
2020-02-08T03:30:50.739505: step 218, loss 0.980153, acc 0.546875
2020-02-08T03:30:50.860397: step 219, loss 0.70269, acc 0.671875
2020-02-08T03:30:50.980007: step 220, loss 0.690482, acc 0.734375
2020-02-08T03:30:51.097468: step 221, loss 0.873137, acc 0.59375
2020-02-08T03:30:51.217493: step 222, loss 0.969568, acc 0.59375
2020-02-08T03:30:51.333094: step 223, loss 0.805902, acc 0.65625
2020-02-08T03:30:51.617929: step 224, loss 0.740192, acc 0.640625
2020-02-08T03:30:51.744754: step 225, loss 0.941345, acc 0.5
2020-02-08T03:30:51.868479: step 226, loss 0.878679, acc 0.5625
2020-02-08T03:30:51.984988: step 227, loss 0.814959, acc 0.59375
2020-02-08T03:30:52.101511: step 228, loss 0.771147, acc 0.546875
2020-02-08T03:30:52.222106: step 229, loss 0.885057, acc 0.59375
2020-02-08T03:30:52.339389: step 230, loss 0.628533, acc 0.703125
2020-02-08T03:30:52.460381: step 231, loss 0.894546, acc 0.59375
2020-02-08T03:30:52.579102: step 232, loss 0.943639, acc 0.484375
2020-02-08T03:30:52.695765: step 233, loss 0.919693, acc 0.546875
2020-02-08T03:30:52.814603: step 234, loss 0.780446, acc 0.671875
2020-02-08T03:30:52.931440: step 235, loss 0.992462, acc 0.546875
2020-02-08T03:30:53.048146: step 236, loss 0.775832, acc 0.578125
2020-02-08T03:30:53.167350: step 237, loss 0.791456, acc 0.65625
2020-02-08T03:30:53.284776: step 238, loss 0.774378, acc 0.59375
2020-02-08T03:30:53.400446: step 239, loss 0.822561, acc 0.578125
2020-02-08T03:30:53.518423: step 240, loss 0.815267, acc 0.5
2020-02-08T03:30:53.635559: step 241, loss 1.04037, acc 0.53125
2020-02-08T03:30:53.754916: step 242, loss 0.718785, acc 0.640625
2020-02-08T03:30:53.880560: step 243, loss 0.788853, acc 0.5625
2020-02-08T03:30:53.996128: step 244, loss 0.820453, acc 0.59375
2020-02-08T03:30:54.114624: step 245, loss 0.776669, acc 0.640625
2020-02-08T03:30:54.230663: step 246, loss 1.03443, acc 0.515625
2020-02-08T03:30:54.346226: step 247, loss 0.716281, acc 0.59375
2020-02-08T03:30:54.462917: step 248, loss 0.976279, acc 0.5625
2020-02-08T03:30:54.581447: step 249, loss 0.873292, acc 0.578125
2020-02-08T03:30:54.699489: step 250, loss 0.799893, acc 0.609375
2020-02-08T03:30:54.819524: step 251, loss 0.925475, acc 0.53125
2020-02-08T03:30:54.937624: step 252, loss 0.731516, acc 0.640625
2020-02-08T03:30:55.061170: step 253, loss 0.86715, acc 0.546875
2020-02-08T03:30:55.178593: step 254, loss 0.935769, acc 0.5625
2020-02-08T03:30:55.296346: step 255, loss 0.880004, acc 0.625
2020-02-08T03:30:55.416939: step 256, loss 0.684252, acc 0.71875
2020-02-08T03:30:55.534400: step 257, loss 0.772651, acc 0.609375
2020-02-08T03:30:55.653097: step 258, loss 0.875361, acc 0.5625
2020-02-08T03:30:55.774740: step 259, loss 0.784884, acc 0.625
2020-02-08T03:30:55.895503: step 260, loss 0.815914, acc 0.625
2020-02-08T03:30:56.013957: step 261, loss 0.742834, acc 0.578125
2020-02-08T03:30:56.135267: step 262, loss 0.916007, acc 0.5625
2020-02-08T03:30:56.252438: step 263, loss 0.814161, acc 0.6875
2020-02-08T03:30:56.369580: step 264, loss 0.680714, acc 0.734375
2020-02-08T03:30:56.488348: step 265, loss 0.751714, acc 0.578125
2020-02-08T03:30:56.603607: step 266, loss 0.952404, acc 0.515625
2020-02-08T03:30:56.721385: step 267, loss 0.777669, acc 0.625
2020-02-08T03:30:56.838849: step 268, loss 0.8023, acc 0.5625
2020-02-08T03:30:56.957304: step 269, loss 0.814099, acc 0.625
2020-02-08T03:30:57.080019: step 270, loss 0.773235, acc 0.546875
2020-02-08T03:30:57.195360: step 271, loss 0.789399, acc 0.65625
2020-02-08T03:30:57.310051: step 272, loss 0.764677, acc 0.640625
2020-02-08T03:30:57.429296: step 273, loss 0.695952, acc 0.625
2020-02-08T03:30:57.548641: step 274, loss 0.627515, acc 0.6875
2020-02-08T03:30:57.667386: step 275, loss 0.803734, acc 0.546875
2020-02-08T03:30:57.784700: step 276, loss 0.847625, acc 0.578125
2020-02-08T03:30:57.905796: step 277, loss 0.722809, acc 0.640625
2020-02-08T03:30:58.028358: step 278, loss 0.789923, acc 0.578125
2020-02-08T03:30:58.146284: step 279, loss 0.638749, acc 0.59375
2020-02-08T03:30:58.262164: step 280, loss 0.845571, acc 0.578125
2020-02-08T03:30:58.378968: step 281, loss 0.831018, acc 0.609375
2020-02-08T03:30:58.496854: step 282, loss 0.72779, acc 0.625
2020-02-08T03:30:58.615324: step 283, loss 0.841632, acc 0.578125
2020-02-08T03:30:58.734002: step 284, loss 0.692624, acc 0.640625
2020-02-08T03:30:58.855238: step 285, loss 0.629383, acc 0.671875
2020-02-08T03:30:58.972799: step 286, loss 0.757613, acc 0.59375
2020-02-08T03:30:59.089296: step 287, loss 0.730761, acc 0.59375
2020-02-08T03:30:59.207031: step 288, loss 0.832576, acc 0.640625
2020-02-08T03:30:59.326519: step 289, loss 0.606322, acc 0.734375
2020-02-08T03:30:59.448410: step 290, loss 0.63493, acc 0.609375
2020-02-08T03:30:59.566981: step 291, loss 0.872358, acc 0.546875
2020-02-08T03:30:59.684421: step 292, loss 0.881725, acc 0.546875
2020-02-08T03:30:59.797627: step 293, loss 0.692321, acc 0.6875
2020-02-08T03:30:59.922579: step 294, loss 0.694677, acc 0.609375
2020-02-08T03:31:00.042596: step 295, loss 0.745824, acc 0.578125
2020-02-08T03:31:00.160564: step 296, loss 0.886104, acc 0.515625
2020-02-08T03:31:00.277987: step 297, loss 0.713802, acc 0.671875
2020-02-08T03:31:00.395197: step 298, loss 0.632563, acc 0.671875
2020-02-08T03:31:00.514933: step 299, loss 0.69502, acc 0.59375
2020-02-08T03:31:00.630341: step 300, loss 0.785273, acc 0.6

Evaluation:
2020-02-08T03:31:00.821871: step 300, loss 0.652705, acc 0.619137

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-300

2020-02-08T03:31:02.344569: step 301, loss 0.692529, acc 0.640625
2020-02-08T03:31:02.464976: step 302, loss 0.739079, acc 0.65625
2020-02-08T03:31:02.584753: step 303, loss 0.673296, acc 0.609375
2020-02-08T03:31:02.701938: step 304, loss 0.529077, acc 0.75
2020-02-08T03:31:02.821330: step 305, loss 0.70906, acc 0.53125
2020-02-08T03:31:02.939375: step 306, loss 0.766464, acc 0.53125
2020-02-08T03:31:03.055678: step 307, loss 0.587313, acc 0.6875
2020-02-08T03:31:03.176024: step 308, loss 0.743495, acc 0.609375
2020-02-08T03:31:03.292731: step 309, loss 0.602166, acc 0.71875
2020-02-08T03:31:03.412844: step 310, loss 0.63865, acc 0.609375
2020-02-08T03:31:03.528599: step 311, loss 0.622628, acc 0.703125
2020-02-08T03:31:03.644822: step 312, loss 0.57277, acc 0.6875
2020-02-08T03:31:03.762822: step 313, loss 0.758982, acc 0.65625
2020-02-08T03:31:03.884865: step 314, loss 0.73767, acc 0.59375
2020-02-08T03:31:04.002495: step 315, loss 0.61742, acc 0.734375
2020-02-08T03:31:04.121271: step 316, loss 0.65811, acc 0.609375
2020-02-08T03:31:04.239187: step 317, loss 0.56141, acc 0.78125
2020-02-08T03:31:04.357523: step 318, loss 0.78087, acc 0.5625
2020-02-08T03:31:04.480088: step 319, loss 0.810605, acc 0.609375
2020-02-08T03:31:04.594635: step 320, loss 0.711338, acc 0.578125
2020-02-08T03:31:04.713625: step 321, loss 0.691114, acc 0.609375
2020-02-08T03:31:04.833699: step 322, loss 0.720283, acc 0.609375
2020-02-08T03:31:04.951946: step 323, loss 0.364147, acc 0.890625
2020-02-08T03:31:05.068939: step 324, loss 0.656589, acc 0.65625
2020-02-08T03:31:05.186649: step 325, loss 0.670254, acc 0.65625
2020-02-08T03:31:05.301025: step 326, loss 0.688508, acc 0.65625
2020-02-08T03:31:05.421277: step 327, loss 0.508184, acc 0.75
2020-02-08T03:31:05.540064: step 328, loss 0.583778, acc 0.640625
2020-02-08T03:31:05.658227: step 329, loss 0.604841, acc 0.65625
2020-02-08T03:31:05.778806: step 330, loss 0.504053, acc 0.71875
2020-02-08T03:31:05.898812: step 331, loss 0.550797, acc 0.765625
2020-02-08T03:31:06.020308: step 332, loss 0.818319, acc 0.609375
2020-02-08T03:31:06.139721: step 333, loss 0.772149, acc 0.609375
2020-02-08T03:31:06.257629: step 334, loss 0.580573, acc 0.65625
2020-02-08T03:31:06.375423: step 335, loss 0.650434, acc 0.671875
2020-02-08T03:31:06.491280: step 336, loss 0.714576, acc 0.6875
2020-02-08T03:31:06.613176: step 337, loss 0.739994, acc 0.578125
2020-02-08T03:31:06.733275: step 338, loss 0.744949, acc 0.625
2020-02-08T03:31:06.852297: step 339, loss 0.726519, acc 0.65625
2020-02-08T03:31:06.970674: step 340, loss 0.685445, acc 0.625
2020-02-08T03:31:07.089342: step 341, loss 0.64135, acc 0.609375
2020-02-08T03:31:07.206885: step 342, loss 0.612302, acc 0.71875
2020-02-08T03:31:07.325702: step 343, loss 0.652174, acc 0.65625
2020-02-08T03:31:07.444169: step 344, loss 0.706331, acc 0.59375
2020-02-08T03:31:07.558180: step 345, loss 0.523346, acc 0.71875
2020-02-08T03:31:07.675950: step 346, loss 0.687831, acc 0.59375
2020-02-08T03:31:07.794568: step 347, loss 0.616644, acc 0.75
2020-02-08T03:31:07.917860: step 348, loss 0.68534, acc 0.6875
2020-02-08T03:31:08.033038: step 349, loss 0.555263, acc 0.734375
2020-02-08T03:31:08.149297: step 350, loss 0.620997, acc 0.6875
2020-02-08T03:31:08.264456: step 351, loss 0.590816, acc 0.703125
2020-02-08T03:31:08.381949: step 352, loss 0.624104, acc 0.6875
2020-02-08T03:31:08.502943: step 353, loss 0.504044, acc 0.734375
2020-02-08T03:31:08.624448: step 354, loss 0.62752, acc 0.640625
2020-02-08T03:31:08.742986: step 355, loss 0.540531, acc 0.734375
2020-02-08T03:31:08.864299: step 356, loss 0.655039, acc 0.625
2020-02-08T03:31:08.982023: step 357, loss 0.698107, acc 0.640625
2020-02-08T03:31:09.099691: step 358, loss 0.617775, acc 0.75
2020-02-08T03:31:09.218824: step 359, loss 0.72904, acc 0.59375
2020-02-08T03:31:09.335999: step 360, loss 0.551696, acc 0.6875
2020-02-08T03:31:09.454471: step 361, loss 0.533284, acc 0.734375
2020-02-08T03:31:09.572317: step 362, loss 0.613932, acc 0.6875
2020-02-08T03:31:09.688028: step 363, loss 0.736437, acc 0.59375
2020-02-08T03:31:09.807833: step 364, loss 0.612319, acc 0.78125
2020-02-08T03:31:09.925098: step 365, loss 0.645548, acc 0.640625
2020-02-08T03:31:10.043151: step 366, loss 0.610327, acc 0.703125
2020-02-08T03:31:10.161388: step 367, loss 0.751389, acc 0.578125
2020-02-08T03:31:10.277588: step 368, loss 0.658217, acc 0.65625
2020-02-08T03:31:10.394652: step 369, loss 0.585668, acc 0.703125
2020-02-08T03:31:10.513284: step 370, loss 0.641844, acc 0.671875
2020-02-08T03:31:10.633621: step 371, loss 0.628374, acc 0.71875
2020-02-08T03:31:10.751253: step 372, loss 0.606539, acc 0.703125
2020-02-08T03:31:10.873034: step 373, loss 0.586566, acc 0.703125
2020-02-08T03:31:10.988049: step 374, loss 0.772539, acc 0.5625
2020-02-08T03:31:11.102710: step 375, loss 0.627239, acc 0.65625
2020-02-08T03:31:11.218398: step 376, loss 0.750015, acc 0.625
2020-02-08T03:31:11.338164: step 377, loss 0.877637, acc 0.5
2020-02-08T03:31:11.456329: step 378, loss 0.57964, acc 0.703125
2020-02-08T03:31:11.573952: step 379, loss 0.659997, acc 0.671875
2020-02-08T03:31:11.694991: step 380, loss 0.586169, acc 0.703125
2020-02-08T03:31:11.814787: step 381, loss 0.66704, acc 0.65625
2020-02-08T03:31:11.930568: step 382, loss 0.617841, acc 0.640625
2020-02-08T03:31:12.045570: step 383, loss 0.635396, acc 0.671875
2020-02-08T03:31:12.165851: step 384, loss 0.720138, acc 0.609375
2020-02-08T03:31:12.282874: step 385, loss 0.640157, acc 0.625
2020-02-08T03:31:12.400581: step 386, loss 0.710226, acc 0.59375
2020-02-08T03:31:12.522654: step 387, loss 0.602076, acc 0.703125
2020-02-08T03:31:12.641308: step 388, loss 0.659153, acc 0.640625
2020-02-08T03:31:12.759449: step 389, loss 0.695595, acc 0.609375
2020-02-08T03:31:12.880193: step 390, loss 0.669245, acc 0.609375
2020-02-08T03:31:12.999244: step 391, loss 0.552457, acc 0.734375
2020-02-08T03:31:13.118524: step 392, loss 0.716985, acc 0.65625
2020-02-08T03:31:13.238133: step 393, loss 0.606684, acc 0.71875
2020-02-08T03:31:13.359891: step 394, loss 0.658635, acc 0.625
2020-02-08T03:31:13.479977: step 395, loss 0.604513, acc 0.703125
2020-02-08T03:31:13.596992: step 396, loss 0.756846, acc 0.640625
2020-02-08T03:31:13.715263: step 397, loss 0.740146, acc 0.609375
2020-02-08T03:31:13.837779: step 398, loss 0.683479, acc 0.609375
2020-02-08T03:31:13.956669: step 399, loss 0.521945, acc 0.75
2020-02-08T03:31:14.075219: step 400, loss 0.656538, acc 0.65625

Evaluation:
2020-02-08T03:31:14.266187: step 400, loss 0.668094, acc 0.593809

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-400

2020-02-08T03:31:15.770167: step 401, loss 0.47601, acc 0.765625
2020-02-08T03:31:15.890996: step 402, loss 0.623095, acc 0.703125
2020-02-08T03:31:16.006977: step 403, loss 0.525002, acc 0.78125
2020-02-08T03:31:16.126531: step 404, loss 0.620487, acc 0.625
2020-02-08T03:31:16.242073: step 405, loss 0.588639, acc 0.75
2020-02-08T03:31:16.363321: step 406, loss 0.616075, acc 0.6875
2020-02-08T03:31:16.482304: step 407, loss 0.581694, acc 0.65625
2020-02-08T03:31:16.602113: step 408, loss 0.790509, acc 0.546875
2020-02-08T03:31:16.723413: step 409, loss 0.675302, acc 0.65625
2020-02-08T03:31:16.845686: step 410, loss 0.653457, acc 0.640625
2020-02-08T03:31:16.965475: step 411, loss 0.671288, acc 0.59375
2020-02-08T03:31:17.083901: step 412, loss 0.53148, acc 0.734375
2020-02-08T03:31:17.196548: step 413, loss 0.684646, acc 0.625
2020-02-08T03:31:17.316602: step 414, loss 0.587333, acc 0.625
2020-02-08T03:31:17.434877: step 415, loss 0.591913, acc 0.734375
2020-02-08T03:31:17.553372: step 416, loss 0.777468, acc 0.484375
2020-02-08T03:31:17.671656: step 417, loss 0.573233, acc 0.71875
2020-02-08T03:31:17.790527: step 418, loss 0.583136, acc 0.734375
2020-02-08T03:31:17.910866: step 419, loss 0.791935, acc 0.578125
2020-02-08T03:31:18.029471: step 420, loss 0.62922, acc 0.65625
2020-02-08T03:31:18.146174: step 421, loss 0.489783, acc 0.765625
2020-02-08T03:31:18.263556: step 422, loss 0.593872, acc 0.671875
2020-02-08T03:31:18.380968: step 423, loss 0.58116, acc 0.796875
2020-02-08T03:31:18.496065: step 424, loss 0.645579, acc 0.640625
2020-02-08T03:31:18.614274: step 425, loss 0.697216, acc 0.5625
2020-02-08T03:31:18.736562: step 426, loss 0.657951, acc 0.703125
2020-02-08T03:31:18.857189: step 427, loss 0.60937, acc 0.6875
2020-02-08T03:31:19.020035: step 428, loss 0.615316, acc 0.625
2020-02-08T03:31:19.180387: step 429, loss 0.546717, acc 0.6875
2020-02-08T03:31:19.307907: step 430, loss 0.645527, acc 0.6875
2020-02-08T03:31:19.433355: step 431, loss 0.627783, acc 0.640625
2020-02-08T03:31:19.569237: step 432, loss 0.579226, acc 0.703125
2020-02-08T03:31:19.714692: step 433, loss 0.613427, acc 0.6875
2020-02-08T03:31:19.857521: step 434, loss 0.674087, acc 0.640625
2020-02-08T03:31:19.993710: step 435, loss 0.653213, acc 0.65625
2020-02-08T03:31:20.127698: step 436, loss 0.617148, acc 0.671875
2020-02-08T03:31:20.260549: step 437, loss 0.687578, acc 0.640625
2020-02-08T03:31:20.394625: step 438, loss 0.509665, acc 0.703125
2020-02-08T03:31:20.531222: step 439, loss 0.661103, acc 0.71875
2020-02-08T03:31:20.660589: step 440, loss 0.648591, acc 0.59375
2020-02-08T03:31:20.792523: step 441, loss 0.704876, acc 0.5625
2020-02-08T03:31:20.924406: step 442, loss 0.609653, acc 0.703125
2020-02-08T03:31:21.055481: step 443, loss 0.611709, acc 0.65625
2020-02-08T03:31:21.187503: step 444, loss 0.669556, acc 0.625
2020-02-08T03:31:21.313406: step 445, loss 0.630477, acc 0.609375
2020-02-08T03:31:21.432242: step 446, loss 0.559465, acc 0.71875
2020-02-08T03:31:21.622134: step 447, loss 0.667372, acc 0.671875
2020-02-08T03:31:21.782438: step 448, loss 0.698647, acc 0.625
2020-02-08T03:31:21.923877: step 449, loss 0.666979, acc 0.65625
2020-02-08T03:31:22.054454: step 450, loss 0.686454, acc 0.6
2020-02-08T03:31:22.190712: step 451, loss 0.652485, acc 0.65625
2020-02-08T03:31:22.327179: step 452, loss 0.55901, acc 0.703125
2020-02-08T03:31:22.472494: step 453, loss 0.695951, acc 0.578125
2020-02-08T03:31:22.623604: step 454, loss 0.503699, acc 0.71875
2020-02-08T03:31:22.759790: step 455, loss 0.612535, acc 0.625
2020-02-08T03:31:22.907414: step 456, loss 0.639476, acc 0.671875
2020-02-08T03:31:23.047246: step 457, loss 0.541571, acc 0.71875
2020-02-08T03:31:23.174115: step 458, loss 0.667265, acc 0.625
2020-02-08T03:31:23.317304: step 459, loss 0.595407, acc 0.6875
2020-02-08T03:31:23.459082: step 460, loss 0.561124, acc 0.640625
2020-02-08T03:31:23.597592: step 461, loss 0.546716, acc 0.671875
2020-02-08T03:31:23.737601: step 462, loss 0.599191, acc 0.71875
2020-02-08T03:31:23.883652: step 463, loss 0.546053, acc 0.703125
2020-02-08T03:31:24.023918: step 464, loss 0.606246, acc 0.640625
2020-02-08T03:31:24.167532: step 465, loss 0.624632, acc 0.703125
2020-02-08T03:31:24.313582: step 466, loss 0.581014, acc 0.65625
2020-02-08T03:31:24.457049: step 467, loss 0.549175, acc 0.71875
2020-02-08T03:31:24.598065: step 468, loss 0.53357, acc 0.703125
2020-02-08T03:31:24.736905: step 469, loss 0.682315, acc 0.65625
2020-02-08T03:31:24.881660: step 470, loss 0.582838, acc 0.75
2020-02-08T03:31:25.026278: step 471, loss 0.660714, acc 0.640625
2020-02-08T03:31:25.169074: step 472, loss 0.693364, acc 0.6875
2020-02-08T03:31:25.309668: step 473, loss 0.589257, acc 0.703125
2020-02-08T03:31:25.450832: step 474, loss 0.533673, acc 0.75
2020-02-08T03:31:25.593800: step 475, loss 0.525666, acc 0.78125
2020-02-08T03:31:25.738756: step 476, loss 0.53053, acc 0.671875
2020-02-08T03:31:25.885707: step 477, loss 0.644984, acc 0.640625
2020-02-08T03:31:26.021965: step 478, loss 0.61459, acc 0.71875
2020-02-08T03:31:26.146930: step 479, loss 0.597038, acc 0.703125
2020-02-08T03:31:26.270629: step 480, loss 0.605221, acc 0.671875
2020-02-08T03:31:26.413142: step 481, loss 0.662014, acc 0.65625
2020-02-08T03:31:26.568329: step 482, loss 0.517564, acc 0.78125
2020-02-08T03:31:26.702378: step 483, loss 0.553027, acc 0.734375
2020-02-08T03:31:26.847206: step 484, loss 0.671433, acc 0.625
2020-02-08T03:31:26.991060: step 485, loss 0.79743, acc 0.671875
2020-02-08T03:31:27.132727: step 486, loss 0.628882, acc 0.6875
2020-02-08T03:31:27.264270: step 487, loss 0.608312, acc 0.65625
2020-02-08T03:31:27.402640: step 488, loss 0.578039, acc 0.734375
2020-02-08T03:31:27.545477: step 489, loss 0.512896, acc 0.796875
2020-02-08T03:31:27.694338: step 490, loss 0.570142, acc 0.703125
2020-02-08T03:31:27.853596: step 491, loss 0.530338, acc 0.796875
2020-02-08T03:31:27.972247: step 492, loss 0.557448, acc 0.6875
2020-02-08T03:31:28.091029: step 493, loss 0.568747, acc 0.6875
2020-02-08T03:31:28.214045: step 494, loss 0.595806, acc 0.6875
2020-02-08T03:31:28.344019: step 495, loss 0.57791, acc 0.71875
2020-02-08T03:31:28.470605: step 496, loss 0.567559, acc 0.671875
2020-02-08T03:31:28.590295: step 497, loss 0.468169, acc 0.828125
2020-02-08T03:31:28.716940: step 498, loss 0.506645, acc 0.734375
2020-02-08T03:31:28.843144: step 499, loss 0.630225, acc 0.625
2020-02-08T03:31:28.964886: step 500, loss 0.496991, acc 0.765625

Evaluation:
2020-02-08T03:31:29.160880: step 500, loss 0.629764, acc 0.65197

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-500

2020-02-08T03:31:30.726367: step 501, loss 0.593009, acc 0.6875
2020-02-08T03:31:30.848324: step 502, loss 0.681652, acc 0.578125
2020-02-08T03:31:30.971987: step 503, loss 0.535307, acc 0.828125
2020-02-08T03:31:31.089509: step 504, loss 0.636218, acc 0.640625
2020-02-08T03:31:31.204651: step 505, loss 0.387689, acc 0.84375
2020-02-08T03:31:31.320215: step 506, loss 0.511387, acc 0.765625
2020-02-08T03:31:31.437827: step 507, loss 0.618716, acc 0.6875
2020-02-08T03:31:31.555155: step 508, loss 0.548188, acc 0.78125
2020-02-08T03:31:31.672497: step 509, loss 0.523613, acc 0.765625
2020-02-08T03:31:31.789254: step 510, loss 0.525389, acc 0.765625
2020-02-08T03:31:31.909513: step 511, loss 0.476624, acc 0.734375
2020-02-08T03:31:32.028212: step 512, loss 0.609711, acc 0.65625
2020-02-08T03:31:32.145151: step 513, loss 0.61494, acc 0.640625
2020-02-08T03:31:32.265365: step 514, loss 0.801562, acc 0.609375
2020-02-08T03:31:32.384051: step 515, loss 0.536022, acc 0.734375
2020-02-08T03:31:32.502227: step 516, loss 0.534291, acc 0.75
2020-02-08T03:31:32.619385: step 517, loss 0.396678, acc 0.84375
2020-02-08T03:31:32.735228: step 518, loss 0.533295, acc 0.75
2020-02-08T03:31:32.853443: step 519, loss 0.620571, acc 0.671875
2020-02-08T03:31:32.971928: step 520, loss 0.554504, acc 0.6875
2020-02-08T03:31:33.088134: step 521, loss 0.510392, acc 0.734375
2020-02-08T03:31:33.207732: step 522, loss 0.646379, acc 0.65625
2020-02-08T03:31:33.334863: step 523, loss 0.600031, acc 0.703125
2020-02-08T03:31:33.460346: step 524, loss 0.63619, acc 0.625
2020-02-08T03:31:33.574049: step 525, loss 0.736027, acc 0.640625
2020-02-08T03:31:33.691028: step 526, loss 0.511477, acc 0.75
2020-02-08T03:31:33.808648: step 527, loss 0.556123, acc 0.6875
2020-02-08T03:31:33.925001: step 528, loss 0.597587, acc 0.671875
2020-02-08T03:31:34.045481: step 529, loss 0.57856, acc 0.734375
2020-02-08T03:31:34.162410: step 530, loss 0.484998, acc 0.765625
2020-02-08T03:31:34.285854: step 531, loss 0.574169, acc 0.671875
2020-02-08T03:31:34.402517: step 532, loss 0.665536, acc 0.671875
2020-02-08T03:31:34.520902: step 533, loss 0.543361, acc 0.765625
2020-02-08T03:31:34.636957: step 534, loss 0.509992, acc 0.75
2020-02-08T03:31:34.752508: step 535, loss 0.582609, acc 0.6875
2020-02-08T03:31:34.876440: step 536, loss 0.606818, acc 0.6875
2020-02-08T03:31:34.994051: step 537, loss 0.480986, acc 0.78125
2020-02-08T03:31:35.113360: step 538, loss 0.547391, acc 0.796875
2020-02-08T03:31:35.233553: step 539, loss 0.617082, acc 0.75
2020-02-08T03:31:35.351813: step 540, loss 0.616389, acc 0.65625
2020-02-08T03:31:35.473149: step 541, loss 0.575818, acc 0.671875
2020-02-08T03:31:35.590005: step 542, loss 0.564991, acc 0.734375
2020-02-08T03:31:35.704197: step 543, loss 0.525753, acc 0.71875
2020-02-08T03:31:35.824037: step 544, loss 0.56866, acc 0.6875
2020-02-08T03:31:35.938647: step 545, loss 0.675599, acc 0.65625
2020-02-08T03:31:36.056105: step 546, loss 0.645803, acc 0.640625
2020-02-08T03:31:36.173475: step 547, loss 0.687118, acc 0.609375
2020-02-08T03:31:36.288803: step 548, loss 0.442808, acc 0.90625
2020-02-08T03:31:36.406766: step 549, loss 0.635474, acc 0.5625
2020-02-08T03:31:36.528290: step 550, loss 0.501219, acc 0.796875
2020-02-08T03:31:36.642275: step 551, loss 0.571986, acc 0.796875
2020-02-08T03:31:36.762051: step 552, loss 0.638745, acc 0.609375
2020-02-08T03:31:36.884372: step 553, loss 0.51847, acc 0.8125
2020-02-08T03:31:36.999469: step 554, loss 0.473746, acc 0.78125
2020-02-08T03:31:37.118353: step 555, loss 0.619688, acc 0.6875
2020-02-08T03:31:37.233857: step 556, loss 0.630674, acc 0.6875
2020-02-08T03:31:37.348942: step 557, loss 0.614496, acc 0.640625
2020-02-08T03:31:37.467377: step 558, loss 0.656276, acc 0.5625
2020-02-08T03:31:37.584930: step 559, loss 0.561666, acc 0.671875
2020-02-08T03:31:37.703392: step 560, loss 0.634564, acc 0.65625
2020-02-08T03:31:37.823798: step 561, loss 0.488436, acc 0.796875
2020-02-08T03:31:37.940138: step 562, loss 0.502112, acc 0.796875
2020-02-08T03:31:38.057993: step 563, loss 0.481252, acc 0.75
2020-02-08T03:31:38.174390: step 564, loss 0.523039, acc 0.734375
2020-02-08T03:31:38.291132: step 565, loss 0.511164, acc 0.75
2020-02-08T03:31:38.410715: step 566, loss 0.53467, acc 0.796875
2020-02-08T03:31:38.531617: step 567, loss 0.56377, acc 0.6875
2020-02-08T03:31:38.648613: step 568, loss 0.551174, acc 0.765625
2020-02-08T03:31:38.767825: step 569, loss 0.560479, acc 0.75
2020-02-08T03:31:38.891747: step 570, loss 0.59416, acc 0.625
2020-02-08T03:31:39.009505: step 571, loss 0.568983, acc 0.71875
2020-02-08T03:31:39.127102: step 572, loss 0.602895, acc 0.671875
2020-02-08T03:31:39.244083: step 573, loss 0.645035, acc 0.703125
2020-02-08T03:31:39.369037: step 574, loss 0.612763, acc 0.703125
2020-02-08T03:31:39.486653: step 575, loss 0.513956, acc 0.734375
2020-02-08T03:31:39.605571: step 576, loss 0.567384, acc 0.71875
2020-02-08T03:31:39.723497: step 577, loss 0.668615, acc 0.6875
2020-02-08T03:31:39.841821: step 578, loss 0.602152, acc 0.671875
2020-02-08T03:31:39.955455: step 579, loss 0.598074, acc 0.6875
2020-02-08T03:31:40.073428: step 580, loss 0.607106, acc 0.671875
2020-02-08T03:31:40.190676: step 581, loss 0.604267, acc 0.65625
2020-02-08T03:31:40.307244: step 582, loss 0.701318, acc 0.640625
2020-02-08T03:31:40.425541: step 583, loss 0.607917, acc 0.734375
2020-02-08T03:31:40.542756: step 584, loss 0.583471, acc 0.703125
2020-02-08T03:31:40.660165: step 585, loss 0.526681, acc 0.71875
2020-02-08T03:31:40.782379: step 586, loss 0.474381, acc 0.75
2020-02-08T03:31:40.902723: step 587, loss 0.643641, acc 0.625
2020-02-08T03:31:41.019602: step 588, loss 0.543491, acc 0.71875
2020-02-08T03:31:41.137205: step 589, loss 0.479739, acc 0.75
2020-02-08T03:31:41.252789: step 590, loss 0.681386, acc 0.640625
2020-02-08T03:31:41.369524: step 591, loss 0.522802, acc 0.71875
2020-02-08T03:31:41.487369: step 592, loss 0.495532, acc 0.71875
2020-02-08T03:31:41.602806: step 593, loss 0.498625, acc 0.75
2020-02-08T03:31:41.721234: step 594, loss 0.604778, acc 0.671875
2020-02-08T03:31:41.841518: step 595, loss 0.521643, acc 0.734375
2020-02-08T03:31:41.954974: step 596, loss 0.583145, acc 0.703125
2020-02-08T03:31:42.071654: step 597, loss 0.496791, acc 0.765625
2020-02-08T03:31:42.188586: step 598, loss 0.55236, acc 0.75
2020-02-08T03:31:42.303074: step 599, loss 0.535222, acc 0.6875
2020-02-08T03:31:42.422352: step 600, loss 0.573787, acc 0.683333

Evaluation:
2020-02-08T03:31:42.614548: step 600, loss 0.649059, acc 0.610694

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-600

2020-02-08T03:31:44.082185: step 601, loss 0.469369, acc 0.78125
2020-02-08T03:31:44.195805: step 602, loss 0.517212, acc 0.71875
2020-02-08T03:31:44.313127: step 603, loss 0.537985, acc 0.828125
2020-02-08T03:31:44.430176: step 604, loss 0.538247, acc 0.71875
2020-02-08T03:31:44.549458: step 605, loss 0.518202, acc 0.75
2020-02-08T03:31:44.668336: step 606, loss 0.557431, acc 0.6875
2020-02-08T03:31:44.789319: step 607, loss 0.46641, acc 0.78125
2020-02-08T03:31:44.913125: step 608, loss 0.63325, acc 0.640625
2020-02-08T03:31:45.033319: step 609, loss 0.544439, acc 0.703125
2020-02-08T03:31:45.152745: step 610, loss 0.519479, acc 0.765625
2020-02-08T03:31:45.270827: step 611, loss 0.504265, acc 0.703125
2020-02-08T03:31:45.389004: step 612, loss 0.568798, acc 0.703125
2020-02-08T03:31:45.506966: step 613, loss 0.501511, acc 0.765625
2020-02-08T03:31:45.629137: step 614, loss 0.566895, acc 0.796875
2020-02-08T03:31:45.742816: step 615, loss 0.461089, acc 0.75
2020-02-08T03:31:45.863060: step 616, loss 0.499073, acc 0.78125
2020-02-08T03:31:45.978719: step 617, loss 0.555978, acc 0.65625
2020-02-08T03:31:46.095526: step 618, loss 0.508004, acc 0.75
2020-02-08T03:31:46.210366: step 619, loss 0.497527, acc 0.703125
2020-02-08T03:31:46.327842: step 620, loss 0.597539, acc 0.6875
2020-02-08T03:31:46.445011: step 621, loss 0.511606, acc 0.796875
2020-02-08T03:31:46.559542: step 622, loss 0.464461, acc 0.8125
2020-02-08T03:31:46.675373: step 623, loss 0.503994, acc 0.734375
2020-02-08T03:31:46.794404: step 624, loss 0.535791, acc 0.6875
2020-02-08T03:31:46.916631: step 625, loss 0.498936, acc 0.703125
2020-02-08T03:31:47.035790: step 626, loss 0.530124, acc 0.703125
2020-02-08T03:31:47.153624: step 627, loss 0.416897, acc 0.84375
2020-02-08T03:31:47.275904: step 628, loss 0.409971, acc 0.828125
2020-02-08T03:31:47.390872: step 629, loss 0.481423, acc 0.765625
2020-02-08T03:31:47.511674: step 630, loss 0.531412, acc 0.75
2020-02-08T03:31:47.629576: step 631, loss 0.504939, acc 0.765625
2020-02-08T03:31:47.744961: step 632, loss 0.606778, acc 0.640625
2020-02-08T03:31:47.869027: step 633, loss 0.49569, acc 0.75
2020-02-08T03:31:47.987556: step 634, loss 0.467619, acc 0.828125
2020-02-08T03:31:48.104304: step 635, loss 0.549861, acc 0.765625
2020-02-08T03:31:48.222433: step 636, loss 0.467138, acc 0.78125
2020-02-08T03:31:48.340009: step 637, loss 0.483134, acc 0.796875
2020-02-08T03:31:48.455502: step 638, loss 0.438242, acc 0.796875
2020-02-08T03:31:48.574104: step 639, loss 0.454282, acc 0.828125
2020-02-08T03:31:48.691580: step 640, loss 0.421128, acc 0.8125
2020-02-08T03:31:48.812239: step 641, loss 0.467811, acc 0.78125
2020-02-08T03:31:48.929520: step 642, loss 0.645028, acc 0.609375
2020-02-08T03:31:49.046130: step 643, loss 0.375873, acc 0.859375
2020-02-08T03:31:49.166388: step 644, loss 0.573132, acc 0.703125
2020-02-08T03:31:49.285692: step 645, loss 0.541429, acc 0.703125
2020-02-08T03:31:49.401635: step 646, loss 0.444284, acc 0.75
2020-02-08T03:31:49.521925: step 647, loss 0.625574, acc 0.6875
2020-02-08T03:31:49.638139: step 648, loss 0.411776, acc 0.828125
2020-02-08T03:31:49.752288: step 649, loss 0.574014, acc 0.734375
2020-02-08T03:31:49.875134: step 650, loss 0.529514, acc 0.71875
2020-02-08T03:31:49.992372: step 651, loss 0.407387, acc 0.796875
2020-02-08T03:31:50.109106: step 652, loss 0.448947, acc 0.8125
2020-02-08T03:31:50.226809: step 653, loss 0.38446, acc 0.796875
2020-02-08T03:31:50.343784: step 654, loss 0.405775, acc 0.84375
2020-02-08T03:31:50.459113: step 655, loss 0.564497, acc 0.703125
2020-02-08T03:31:50.574809: step 656, loss 0.512506, acc 0.71875
2020-02-08T03:31:50.690358: step 657, loss 0.518747, acc 0.734375
2020-02-08T03:31:50.806019: step 658, loss 0.481742, acc 0.78125
2020-02-08T03:31:50.925162: step 659, loss 0.481158, acc 0.796875
2020-02-08T03:31:51.043560: step 660, loss 0.54872, acc 0.703125
2020-02-08T03:31:51.158831: step 661, loss 0.628411, acc 0.703125
2020-02-08T03:31:51.276265: step 662, loss 0.431024, acc 0.84375
2020-02-08T03:31:51.392351: step 663, loss 0.62408, acc 0.65625
2020-02-08T03:31:51.506796: step 664, loss 0.52647, acc 0.765625
2020-02-08T03:31:51.710530: step 665, loss 0.54158, acc 0.71875
2020-02-08T03:31:51.844457: step 666, loss 0.44179, acc 0.8125
2020-02-08T03:31:51.962007: step 667, loss 0.610844, acc 0.65625
2020-02-08T03:31:52.082391: step 668, loss 0.475429, acc 0.71875
2020-02-08T03:31:52.199285: step 669, loss 0.529367, acc 0.734375
2020-02-08T03:31:52.317459: step 670, loss 0.569506, acc 0.65625
2020-02-08T03:31:52.433270: step 671, loss 0.475596, acc 0.8125
2020-02-08T03:31:52.550509: step 672, loss 0.535029, acc 0.703125
2020-02-08T03:31:52.669342: step 673, loss 0.458896, acc 0.8125
2020-02-08T03:31:52.783290: step 674, loss 0.537908, acc 0.703125
2020-02-08T03:31:52.902601: step 675, loss 0.522605, acc 0.78125
2020-02-08T03:31:53.020656: step 676, loss 0.566987, acc 0.71875
2020-02-08T03:31:53.138200: step 677, loss 0.444067, acc 0.796875
2020-02-08T03:31:53.253324: step 678, loss 0.468755, acc 0.765625
2020-02-08T03:31:53.370098: step 679, loss 0.52856, acc 0.71875
2020-02-08T03:31:53.486718: step 680, loss 0.69917, acc 0.703125
2020-02-08T03:31:53.603543: step 681, loss 0.444372, acc 0.796875
2020-02-08T03:31:53.722714: step 682, loss 0.492878, acc 0.75
2020-02-08T03:31:53.841913: step 683, loss 0.628147, acc 0.65625
2020-02-08T03:31:53.960917: step 684, loss 0.470445, acc 0.78125
2020-02-08T03:31:54.080336: step 685, loss 0.527554, acc 0.734375
2020-02-08T03:31:54.199317: step 686, loss 0.56924, acc 0.734375
2020-02-08T03:31:54.316932: step 687, loss 0.627657, acc 0.75
2020-02-08T03:31:54.434813: step 688, loss 0.536284, acc 0.765625
2020-02-08T03:31:54.551864: step 689, loss 0.464231, acc 0.78125
2020-02-08T03:31:54.669010: step 690, loss 0.510082, acc 0.71875
2020-02-08T03:31:54.784193: step 691, loss 0.439858, acc 0.796875
2020-02-08T03:31:54.905143: step 692, loss 0.47305, acc 0.765625
2020-02-08T03:31:55.024091: step 693, loss 0.504483, acc 0.78125
2020-02-08T03:31:55.139905: step 694, loss 0.433426, acc 0.78125
2020-02-08T03:31:55.258849: step 695, loss 0.478639, acc 0.765625
2020-02-08T03:31:55.375992: step 696, loss 0.552297, acc 0.71875
2020-02-08T03:31:55.493739: step 697, loss 0.567312, acc 0.734375
2020-02-08T03:31:55.614388: step 698, loss 0.42859, acc 0.796875
2020-02-08T03:31:55.734643: step 699, loss 0.510373, acc 0.71875
2020-02-08T03:31:55.857209: step 700, loss 0.54585, acc 0.765625

Evaluation:
2020-02-08T03:31:56.046565: step 700, loss 0.606033, acc 0.67167

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-700

2020-02-08T03:31:57.626851: step 701, loss 0.575133, acc 0.71875
2020-02-08T03:31:57.742468: step 702, loss 0.595816, acc 0.6875
2020-02-08T03:31:57.859989: step 703, loss 0.526539, acc 0.65625
2020-02-08T03:31:57.974354: step 704, loss 0.494365, acc 0.796875
2020-02-08T03:31:58.090709: step 705, loss 0.40374, acc 0.78125
2020-02-08T03:31:58.206947: step 706, loss 0.498352, acc 0.734375
2020-02-08T03:31:58.324810: step 707, loss 0.478951, acc 0.765625
2020-02-08T03:31:58.442824: step 708, loss 0.486084, acc 0.765625
2020-02-08T03:31:58.557008: step 709, loss 0.527054, acc 0.78125
2020-02-08T03:31:58.676936: step 710, loss 0.41405, acc 0.84375
2020-02-08T03:31:58.791426: step 711, loss 0.400188, acc 0.875
2020-02-08T03:31:58.911612: step 712, loss 0.53291, acc 0.796875
2020-02-08T03:31:59.027876: step 713, loss 0.464351, acc 0.75
2020-02-08T03:31:59.143798: step 714, loss 0.499496, acc 0.6875
2020-02-08T03:31:59.260501: step 715, loss 0.601859, acc 0.625
2020-02-08T03:31:59.375658: step 716, loss 0.520245, acc 0.75
2020-02-08T03:31:59.496074: step 717, loss 0.517715, acc 0.71875
2020-02-08T03:31:59.612893: step 718, loss 0.48564, acc 0.828125
2020-02-08T03:31:59.730633: step 719, loss 0.534693, acc 0.765625
2020-02-08T03:31:59.850270: step 720, loss 0.424407, acc 0.765625
2020-02-08T03:31:59.966873: step 721, loss 0.442262, acc 0.78125
2020-02-08T03:32:00.084187: step 722, loss 0.4007, acc 0.78125
2020-02-08T03:32:00.198384: step 723, loss 0.508892, acc 0.6875
2020-02-08T03:32:00.314493: step 724, loss 0.494224, acc 0.765625
2020-02-08T03:32:00.432846: step 725, loss 0.605281, acc 0.65625
2020-02-08T03:32:00.547416: step 726, loss 0.545708, acc 0.734375
2020-02-08T03:32:00.665411: step 727, loss 0.564904, acc 0.65625
2020-02-08T03:32:00.780582: step 728, loss 0.427107, acc 0.796875
2020-02-08T03:32:00.901433: step 729, loss 0.518954, acc 0.71875
2020-02-08T03:32:01.022340: step 730, loss 0.470653, acc 0.84375
2020-02-08T03:32:01.138186: step 731, loss 0.582151, acc 0.71875
2020-02-08T03:32:01.255284: step 732, loss 0.481011, acc 0.703125
2020-02-08T03:32:01.374112: step 733, loss 0.506818, acc 0.734375
2020-02-08T03:32:01.493783: step 734, loss 0.617094, acc 0.71875
2020-02-08T03:32:01.611463: step 735, loss 0.47594, acc 0.78125
2020-02-08T03:32:01.726763: step 736, loss 0.574862, acc 0.65625
2020-02-08T03:32:01.846403: step 737, loss 0.585411, acc 0.71875
2020-02-08T03:32:01.962899: step 738, loss 0.467869, acc 0.765625
2020-02-08T03:32:02.080091: step 739, loss 0.489495, acc 0.765625
2020-02-08T03:32:02.197527: step 740, loss 0.375905, acc 0.890625
2020-02-08T03:32:02.314875: step 741, loss 0.566391, acc 0.703125
2020-02-08T03:32:02.431254: step 742, loss 0.557468, acc 0.765625
2020-02-08T03:32:02.549762: step 743, loss 0.571749, acc 0.703125
2020-02-08T03:32:02.667831: step 744, loss 0.62938, acc 0.65625
2020-02-08T03:32:02.786359: step 745, loss 0.528238, acc 0.734375
2020-02-08T03:32:02.907847: step 746, loss 0.412341, acc 0.8125
2020-02-08T03:32:03.021700: step 747, loss 0.437553, acc 0.78125
2020-02-08T03:32:03.138946: step 748, loss 0.567245, acc 0.71875
2020-02-08T03:32:03.255826: step 749, loss 0.475446, acc 0.78125
2020-02-08T03:32:03.368807: step 750, loss 0.46558, acc 0.866667
2020-02-08T03:32:03.486785: step 751, loss 0.427066, acc 0.796875
2020-02-08T03:32:03.603685: step 752, loss 0.561184, acc 0.734375
2020-02-08T03:32:03.719396: step 753, loss 0.490783, acc 0.78125
2020-02-08T03:32:03.840199: step 754, loss 0.327809, acc 0.859375
2020-02-08T03:32:03.957520: step 755, loss 0.499034, acc 0.828125
2020-02-08T03:32:04.072163: step 756, loss 0.515203, acc 0.75
2020-02-08T03:32:04.186106: step 757, loss 0.450155, acc 0.796875
2020-02-08T03:32:04.302210: step 758, loss 0.355836, acc 0.890625
2020-02-08T03:32:04.419917: step 759, loss 0.442882, acc 0.8125
2020-02-08T03:32:04.540542: step 760, loss 0.548519, acc 0.671875
2020-02-08T03:32:04.656140: step 761, loss 0.569206, acc 0.734375
2020-02-08T03:32:04.774688: step 762, loss 0.489205, acc 0.78125
2020-02-08T03:32:04.896574: step 763, loss 0.444422, acc 0.75
2020-02-08T03:32:05.013968: step 764, loss 0.454408, acc 0.796875
2020-02-08T03:32:05.131957: step 765, loss 0.409666, acc 0.8125
2020-02-08T03:32:05.246549: step 766, loss 0.466093, acc 0.75
2020-02-08T03:32:05.360988: step 767, loss 0.493966, acc 0.796875
2020-02-08T03:32:05.476736: step 768, loss 0.580521, acc 0.6875
2020-02-08T03:32:05.591529: step 769, loss 0.40471, acc 0.765625
2020-02-08T03:32:05.707286: step 770, loss 0.516137, acc 0.78125
2020-02-08T03:32:05.828529: step 771, loss 0.362218, acc 0.875
2020-02-08T03:32:05.943053: step 772, loss 0.374584, acc 0.859375
2020-02-08T03:32:06.059735: step 773, loss 0.425428, acc 0.78125
2020-02-08T03:32:06.178889: step 774, loss 0.36735, acc 0.828125
2020-02-08T03:32:06.295596: step 775, loss 0.538878, acc 0.78125
2020-02-08T03:32:06.410590: step 776, loss 0.41863, acc 0.8125
2020-02-08T03:32:06.527863: step 777, loss 0.426701, acc 0.78125
2020-02-08T03:32:06.645698: step 778, loss 0.479309, acc 0.78125
2020-02-08T03:32:06.762886: step 779, loss 0.450151, acc 0.78125
2020-02-08T03:32:06.885180: step 780, loss 0.437655, acc 0.859375
2020-02-08T03:32:07.001952: step 781, loss 0.50557, acc 0.765625
2020-02-08T03:32:07.121962: step 782, loss 0.479895, acc 0.765625
2020-02-08T03:32:07.238537: step 783, loss 0.451603, acc 0.796875
2020-02-08T03:32:07.354161: step 784, loss 0.471908, acc 0.78125
2020-02-08T03:32:07.470225: step 785, loss 0.369644, acc 0.890625
2020-02-08T03:32:07.589050: step 786, loss 0.33897, acc 0.84375
2020-02-08T03:32:07.705175: step 787, loss 0.474974, acc 0.75
2020-02-08T03:32:07.823834: step 788, loss 0.397694, acc 0.828125
2020-02-08T03:32:07.941755: step 789, loss 0.451989, acc 0.765625
2020-02-08T03:32:08.056144: step 790, loss 0.393917, acc 0.765625
2020-02-08T03:32:08.174541: step 791, loss 0.443349, acc 0.828125
2020-02-08T03:32:08.291036: step 792, loss 0.403831, acc 0.8125
2020-02-08T03:32:08.405917: step 793, loss 0.48162, acc 0.78125
2020-02-08T03:32:08.525997: step 794, loss 0.497714, acc 0.765625
2020-02-08T03:32:08.642045: step 795, loss 0.377078, acc 0.84375
2020-02-08T03:32:08.759155: step 796, loss 0.471055, acc 0.78125
2020-02-08T03:32:08.884092: step 797, loss 0.431617, acc 0.8125
2020-02-08T03:32:09.000953: step 798, loss 0.465276, acc 0.84375
2020-02-08T03:32:09.118084: step 799, loss 0.459862, acc 0.796875
2020-02-08T03:32:09.234656: step 800, loss 0.527415, acc 0.75

Evaluation:
2020-02-08T03:32:09.427818: step 800, loss 0.623673, acc 0.660413

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-800

2020-02-08T03:32:10.938836: step 801, loss 0.460134, acc 0.78125
2020-02-08T03:32:11.054285: step 802, loss 0.457227, acc 0.8125
2020-02-08T03:32:11.172290: step 803, loss 0.369126, acc 0.796875
2020-02-08T03:32:11.289565: step 804, loss 0.389681, acc 0.859375
2020-02-08T03:32:11.402941: step 805, loss 0.3709, acc 0.828125
2020-02-08T03:32:11.521747: step 806, loss 0.427711, acc 0.8125
2020-02-08T03:32:11.638866: step 807, loss 0.429943, acc 0.84375
2020-02-08T03:32:11.755099: step 808, loss 0.445133, acc 0.75
2020-02-08T03:32:11.878961: step 809, loss 0.517454, acc 0.75
2020-02-08T03:32:11.994118: step 810, loss 0.439592, acc 0.78125
2020-02-08T03:32:12.112376: step 811, loss 0.435088, acc 0.796875
2020-02-08T03:32:12.229414: step 812, loss 0.451972, acc 0.796875
2020-02-08T03:32:12.348950: step 813, loss 0.354203, acc 0.828125
2020-02-08T03:32:12.466646: step 814, loss 0.519556, acc 0.734375
2020-02-08T03:32:12.583429: step 815, loss 0.575666, acc 0.703125
2020-02-08T03:32:12.698720: step 816, loss 0.555681, acc 0.765625
2020-02-08T03:32:12.818972: step 817, loss 0.486336, acc 0.703125
2020-02-08T03:32:12.937292: step 818, loss 0.425823, acc 0.796875
2020-02-08T03:32:13.054742: step 819, loss 0.467911, acc 0.78125
2020-02-08T03:32:13.172642: step 820, loss 0.523172, acc 0.765625
2020-02-08T03:32:13.291256: step 821, loss 0.473513, acc 0.78125
2020-02-08T03:32:13.408990: step 822, loss 0.424335, acc 0.796875
2020-02-08T03:32:13.525042: step 823, loss 0.376751, acc 0.828125
2020-02-08T03:32:13.641350: step 824, loss 0.358075, acc 0.859375
2020-02-08T03:32:13.754021: step 825, loss 0.409458, acc 0.78125
2020-02-08T03:32:13.878075: step 826, loss 0.352918, acc 0.84375
2020-02-08T03:32:13.991957: step 827, loss 0.474207, acc 0.8125
2020-02-08T03:32:14.106291: step 828, loss 0.417123, acc 0.765625
2020-02-08T03:32:14.225289: step 829, loss 0.492659, acc 0.765625
2020-02-08T03:32:14.340980: step 830, loss 0.407565, acc 0.828125
2020-02-08T03:32:14.459216: step 831, loss 0.36361, acc 0.828125
2020-02-08T03:32:14.576664: step 832, loss 0.390351, acc 0.859375
2020-02-08T03:32:14.692971: step 833, loss 0.440937, acc 0.796875
2020-02-08T03:32:14.808639: step 834, loss 0.523061, acc 0.75
2020-02-08T03:32:14.927630: step 835, loss 0.442255, acc 0.8125
2020-02-08T03:32:15.044486: step 836, loss 0.486007, acc 0.765625
2020-02-08T03:32:15.160039: step 837, loss 0.466023, acc 0.8125
2020-02-08T03:32:15.277564: step 838, loss 0.451377, acc 0.796875
2020-02-08T03:32:15.394492: step 839, loss 0.310569, acc 0.859375
2020-02-08T03:32:15.511558: step 840, loss 0.404981, acc 0.796875
2020-02-08T03:32:15.628838: step 841, loss 0.55553, acc 0.796875
2020-02-08T03:32:15.744544: step 842, loss 0.479093, acc 0.796875
2020-02-08T03:32:15.865378: step 843, loss 0.360824, acc 0.84375
2020-02-08T03:32:15.982772: step 844, loss 0.482715, acc 0.765625
2020-02-08T03:32:16.099403: step 845, loss 0.51607, acc 0.75
2020-02-08T03:32:16.215662: step 846, loss 0.486177, acc 0.78125
2020-02-08T03:32:16.335908: step 847, loss 0.359715, acc 0.875
2020-02-08T03:32:16.449904: step 848, loss 0.33786, acc 0.859375
2020-02-08T03:32:16.569375: step 849, loss 0.452784, acc 0.75
2020-02-08T03:32:16.686916: step 850, loss 0.563497, acc 0.734375
2020-02-08T03:32:16.801550: step 851, loss 0.478392, acc 0.78125
2020-02-08T03:32:16.923900: step 852, loss 0.44898, acc 0.8125
2020-02-08T03:32:17.040756: step 853, loss 0.343732, acc 0.859375
2020-02-08T03:32:17.157433: step 854, loss 0.469989, acc 0.8125
2020-02-08T03:32:17.273550: step 855, loss 0.406726, acc 0.8125
2020-02-08T03:32:17.391079: step 856, loss 0.534327, acc 0.734375
2020-02-08T03:32:17.508161: step 857, loss 0.394827, acc 0.828125
2020-02-08T03:32:17.624445: step 858, loss 0.399058, acc 0.796875
2020-02-08T03:32:17.741986: step 859, loss 0.550948, acc 0.703125
2020-02-08T03:32:17.864376: step 860, loss 0.32458, acc 0.84375
2020-02-08T03:32:17.980436: step 861, loss 0.51643, acc 0.71875
2020-02-08T03:32:18.096817: step 862, loss 0.482395, acc 0.703125
2020-02-08T03:32:18.212087: step 863, loss 0.492036, acc 0.78125
2020-02-08T03:32:18.329739: step 864, loss 0.586491, acc 0.6875
2020-02-08T03:32:18.448103: step 865, loss 0.44356, acc 0.765625
2020-02-08T03:32:18.565879: step 866, loss 0.436102, acc 0.796875
2020-02-08T03:32:18.683095: step 867, loss 0.433464, acc 0.8125
2020-02-08T03:32:18.796234: step 868, loss 0.6301, acc 0.71875
2020-02-08T03:32:18.915745: step 869, loss 0.376369, acc 0.8125
2020-02-08T03:32:19.033370: step 870, loss 0.354838, acc 0.84375
2020-02-08T03:32:19.149664: step 871, loss 0.477547, acc 0.78125
2020-02-08T03:32:19.268568: step 872, loss 0.352786, acc 0.84375
2020-02-08T03:32:19.388242: step 873, loss 0.462181, acc 0.78125
2020-02-08T03:32:19.502677: step 874, loss 0.413612, acc 0.828125
2020-02-08T03:32:19.624996: step 875, loss 0.45591, acc 0.828125
2020-02-08T03:32:19.740568: step 876, loss 0.414416, acc 0.84375
2020-02-08T03:32:19.863224: step 877, loss 0.469302, acc 0.78125
2020-02-08T03:32:19.981027: step 878, loss 0.427679, acc 0.765625
2020-02-08T03:32:20.098173: step 879, loss 0.725016, acc 0.671875
2020-02-08T03:32:20.213996: step 880, loss 0.42694, acc 0.796875
2020-02-08T03:32:20.332756: step 881, loss 0.402417, acc 0.8125
2020-02-08T03:32:20.449846: step 882, loss 0.458693, acc 0.78125
2020-02-08T03:32:20.569094: step 883, loss 0.484194, acc 0.796875
2020-02-08T03:32:20.686176: step 884, loss 0.531133, acc 0.8125
2020-02-08T03:32:20.802752: step 885, loss 0.394275, acc 0.8125
2020-02-08T03:32:20.926135: step 886, loss 0.388929, acc 0.765625
2020-02-08T03:32:21.041791: step 887, loss 0.522564, acc 0.71875
2020-02-08T03:32:21.154259: step 888, loss 0.420387, acc 0.78125
2020-02-08T03:32:21.272438: step 889, loss 0.429568, acc 0.796875
2020-02-08T03:32:21.387265: step 890, loss 0.322833, acc 0.921875
2020-02-08T03:32:21.501694: step 891, loss 0.435576, acc 0.75
2020-02-08T03:32:21.621180: step 892, loss 0.460234, acc 0.765625
2020-02-08T03:32:21.750066: step 893, loss 0.466685, acc 0.78125
2020-02-08T03:32:21.873469: step 894, loss 0.590149, acc 0.640625
2020-02-08T03:32:21.992559: step 895, loss 0.434803, acc 0.734375
2020-02-08T03:32:22.110853: step 896, loss 0.353276, acc 0.828125
2020-02-08T03:32:22.229008: step 897, loss 0.374283, acc 0.859375
2020-02-08T03:32:22.350988: step 898, loss 0.364648, acc 0.828125
2020-02-08T03:32:22.466799: step 899, loss 0.413515, acc 0.84375
2020-02-08T03:32:22.582470: step 900, loss 0.526307, acc 0.783333

Evaluation:
2020-02-08T03:32:22.778943: step 900, loss 0.586474, acc 0.692308

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-900

2020-02-08T03:32:24.291626: step 901, loss 0.366106, acc 0.859375
2020-02-08T03:32:24.407963: step 902, loss 0.359895, acc 0.796875
2020-02-08T03:32:24.529011: step 903, loss 0.303554, acc 0.875
2020-02-08T03:32:24.645751: step 904, loss 0.312528, acc 0.828125
2020-02-08T03:32:24.762700: step 905, loss 0.313911, acc 0.8125
2020-02-08T03:32:24.890978: step 906, loss 0.357884, acc 0.859375
2020-02-08T03:32:25.010292: step 907, loss 0.35273, acc 0.828125
2020-02-08T03:32:25.128509: step 908, loss 0.306735, acc 0.890625
2020-02-08T03:32:25.245117: step 909, loss 0.39854, acc 0.796875
2020-02-08T03:32:25.362925: step 910, loss 0.370697, acc 0.875
2020-02-08T03:32:25.481825: step 911, loss 0.248433, acc 0.921875
2020-02-08T03:32:25.598942: step 912, loss 0.424826, acc 0.796875
2020-02-08T03:32:25.717453: step 913, loss 0.388166, acc 0.875
2020-02-08T03:32:25.838573: step 914, loss 0.260324, acc 0.890625
2020-02-08T03:32:25.953427: step 915, loss 0.383054, acc 0.828125
2020-02-08T03:32:26.071079: step 916, loss 0.3168, acc 0.84375
2020-02-08T03:32:26.186917: step 917, loss 0.316388, acc 0.90625
2020-02-08T03:32:26.301016: step 918, loss 0.41996, acc 0.8125
2020-02-08T03:32:26.419450: step 919, loss 0.381909, acc 0.796875
2020-02-08T03:32:26.537447: step 920, loss 0.411512, acc 0.84375
2020-02-08T03:32:26.657128: step 921, loss 0.403984, acc 0.8125
2020-02-08T03:32:26.774145: step 922, loss 0.279301, acc 0.890625
2020-02-08T03:32:26.896606: step 923, loss 0.385551, acc 0.875
2020-02-08T03:32:27.011607: step 924, loss 0.368971, acc 0.859375
2020-02-08T03:32:27.131383: step 925, loss 0.345939, acc 0.859375
2020-02-08T03:32:27.247633: step 926, loss 0.319329, acc 0.859375
2020-02-08T03:32:27.361376: step 927, loss 0.423023, acc 0.765625
2020-02-08T03:32:27.479322: step 928, loss 0.251246, acc 0.875
2020-02-08T03:32:27.597045: step 929, loss 0.259095, acc 0.875
2020-02-08T03:32:27.714816: step 930, loss 0.544455, acc 0.71875
2020-02-08T03:32:27.833295: step 931, loss 0.45321, acc 0.796875
2020-02-08T03:32:27.950654: step 932, loss 0.3741, acc 0.8125
2020-02-08T03:32:28.064993: step 933, loss 0.334343, acc 0.890625
2020-02-08T03:32:28.182797: step 934, loss 0.407427, acc 0.859375
2020-02-08T03:32:28.297370: step 935, loss 0.258535, acc 0.875
2020-02-08T03:32:28.414873: step 936, loss 0.427926, acc 0.828125
2020-02-08T03:32:28.532213: step 937, loss 0.417604, acc 0.84375
2020-02-08T03:32:28.650750: step 938, loss 0.406196, acc 0.84375
2020-02-08T03:32:28.768737: step 939, loss 0.479083, acc 0.75
2020-02-08T03:32:28.889681: step 940, loss 0.439372, acc 0.765625
2020-02-08T03:32:29.004699: step 941, loss 0.309959, acc 0.8125
2020-02-08T03:32:29.124628: step 942, loss 0.338989, acc 0.828125
2020-02-08T03:32:29.242668: step 943, loss 0.355757, acc 0.84375
2020-02-08T03:32:29.358231: step 944, loss 0.373354, acc 0.796875
2020-02-08T03:32:29.476084: step 945, loss 0.484544, acc 0.765625
2020-02-08T03:32:29.591994: step 946, loss 0.30981, acc 0.875
2020-02-08T03:32:29.711211: step 947, loss 0.232576, acc 0.890625
2020-02-08T03:32:29.826847: step 948, loss 0.349587, acc 0.875
2020-02-08T03:32:29.942945: step 949, loss 0.356458, acc 0.84375
2020-02-08T03:32:30.059542: step 950, loss 0.404699, acc 0.828125
2020-02-08T03:32:30.176405: step 951, loss 0.404, acc 0.84375
2020-02-08T03:32:30.291904: step 952, loss 0.354355, acc 0.828125
2020-02-08T03:32:30.410422: step 953, loss 0.332959, acc 0.84375
2020-02-08T03:32:30.527647: step 954, loss 0.430358, acc 0.796875
2020-02-08T03:32:30.646388: step 955, loss 0.482661, acc 0.828125
2020-02-08T03:32:30.763728: step 956, loss 0.37292, acc 0.859375
2020-02-08T03:32:30.887644: step 957, loss 0.453202, acc 0.828125
2020-02-08T03:32:31.006689: step 958, loss 0.328839, acc 0.859375
2020-02-08T03:32:31.124269: step 959, loss 0.335838, acc 0.8125
2020-02-08T03:32:31.239544: step 960, loss 0.41585, acc 0.828125
2020-02-08T03:32:31.354973: step 961, loss 0.283681, acc 0.90625
2020-02-08T03:32:31.473263: step 962, loss 0.273148, acc 0.859375
2020-02-08T03:32:31.591669: step 963, loss 0.298328, acc 0.890625
2020-02-08T03:32:31.705724: step 964, loss 0.434521, acc 0.8125
2020-02-08T03:32:31.826393: step 965, loss 0.401932, acc 0.8125
2020-02-08T03:32:31.947001: step 966, loss 0.388253, acc 0.828125
2020-02-08T03:32:32.064132: step 967, loss 0.329221, acc 0.859375
2020-02-08T03:32:32.182699: step 968, loss 0.402206, acc 0.78125
2020-02-08T03:32:32.297985: step 969, loss 0.463334, acc 0.8125
2020-02-08T03:32:32.413065: step 970, loss 0.286626, acc 0.90625
2020-02-08T03:32:32.529826: step 971, loss 0.299998, acc 0.859375
2020-02-08T03:32:32.646745: step 972, loss 0.336551, acc 0.828125
2020-02-08T03:32:32.764357: step 973, loss 0.284887, acc 0.875
2020-02-08T03:32:32.886444: step 974, loss 0.473751, acc 0.796875
2020-02-08T03:32:33.000735: step 975, loss 0.315021, acc 0.875
2020-02-08T03:32:33.118005: step 976, loss 0.31584, acc 0.84375
2020-02-08T03:32:33.235187: step 977, loss 0.326314, acc 0.859375
2020-02-08T03:32:33.350871: step 978, loss 0.365538, acc 0.828125
2020-02-08T03:32:33.467167: step 979, loss 0.318266, acc 0.90625
2020-02-08T03:32:33.586334: step 980, loss 0.302353, acc 0.890625
2020-02-08T03:32:33.703856: step 981, loss 0.41562, acc 0.796875
2020-02-08T03:32:33.818295: step 982, loss 0.36496, acc 0.796875
2020-02-08T03:32:33.937020: step 983, loss 0.339939, acc 0.890625
2020-02-08T03:32:34.052530: step 984, loss 0.409926, acc 0.8125
2020-02-08T03:32:34.172072: step 985, loss 0.369148, acc 0.828125
2020-02-08T03:32:34.287872: step 986, loss 0.364466, acc 0.875
2020-02-08T03:32:34.403957: step 987, loss 0.313831, acc 0.875
2020-02-08T03:32:34.522237: step 988, loss 0.341669, acc 0.828125
2020-02-08T03:32:34.641268: step 989, loss 0.302811, acc 0.890625
2020-02-08T03:32:34.757108: step 990, loss 0.291081, acc 0.859375
2020-02-08T03:32:34.879657: step 991, loss 0.279401, acc 0.90625
2020-02-08T03:32:34.994768: step 992, loss 0.438734, acc 0.8125
2020-02-08T03:32:35.109765: step 993, loss 0.358743, acc 0.875
2020-02-08T03:32:35.228823: step 994, loss 0.360995, acc 0.84375
2020-02-08T03:32:35.344299: step 995, loss 0.388378, acc 0.8125
2020-02-08T03:32:35.462380: step 996, loss 0.404182, acc 0.8125
2020-02-08T03:32:35.579672: step 997, loss 0.309463, acc 0.828125
2020-02-08T03:32:35.695894: step 998, loss 0.319389, acc 0.875
2020-02-08T03:32:35.813663: step 999, loss 0.425086, acc 0.859375
2020-02-08T03:32:35.932690: step 1000, loss 0.36176, acc 0.859375

Evaluation:
2020-02-08T03:32:36.126159: step 1000, loss 0.596286, acc 0.701689

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1000

2020-02-08T03:32:37.624655: step 1001, loss 0.303676, acc 0.859375
2020-02-08T03:32:37.742465: step 1002, loss 0.264876, acc 0.921875
2020-02-08T03:32:37.861193: step 1003, loss 0.505033, acc 0.75
2020-02-08T03:32:37.983204: step 1004, loss 0.315362, acc 0.859375
2020-02-08T03:32:38.100901: step 1005, loss 0.364125, acc 0.859375
2020-02-08T03:32:38.218844: step 1006, loss 0.382154, acc 0.796875
2020-02-08T03:32:38.340235: step 1007, loss 0.346397, acc 0.828125
2020-02-08T03:32:38.457536: step 1008, loss 0.345797, acc 0.890625
2020-02-08T03:32:38.573475: step 1009, loss 0.386211, acc 0.859375
2020-02-08T03:32:38.690789: step 1010, loss 0.373394, acc 0.828125
2020-02-08T03:32:38.805178: step 1011, loss 0.506244, acc 0.765625
2020-02-08T03:32:38.927788: step 1012, loss 0.378126, acc 0.765625
2020-02-08T03:32:39.044731: step 1013, loss 0.45458, acc 0.765625
2020-02-08T03:32:39.162775: step 1014, loss 0.35025, acc 0.859375
2020-02-08T03:32:39.277869: step 1015, loss 0.359377, acc 0.859375
2020-02-08T03:32:39.394541: step 1016, loss 0.355404, acc 0.875
2020-02-08T03:32:39.516659: step 1017, loss 0.309752, acc 0.84375
2020-02-08T03:32:39.635729: step 1018, loss 0.348399, acc 0.890625
2020-02-08T03:32:39.751147: step 1019, loss 0.301513, acc 0.828125
2020-02-08T03:32:39.870918: step 1020, loss 0.37043, acc 0.796875
2020-02-08T03:32:39.985988: step 1021, loss 0.341413, acc 0.84375
2020-02-08T03:32:40.101332: step 1022, loss 0.45986, acc 0.75
2020-02-08T03:32:40.216552: step 1023, loss 0.382504, acc 0.828125
2020-02-08T03:32:40.333515: step 1024, loss 0.401112, acc 0.859375
2020-02-08T03:32:40.448346: step 1025, loss 0.392534, acc 0.796875
2020-02-08T03:32:40.564502: step 1026, loss 0.40529, acc 0.84375
2020-02-08T03:32:40.679899: step 1027, loss 0.319734, acc 0.859375
2020-02-08T03:32:40.796186: step 1028, loss 0.376375, acc 0.828125
2020-02-08T03:32:40.919424: step 1029, loss 0.460561, acc 0.75
2020-02-08T03:32:41.037571: step 1030, loss 0.372354, acc 0.78125
2020-02-08T03:32:41.155469: step 1031, loss 0.391557, acc 0.796875
2020-02-08T03:32:41.269555: step 1032, loss 0.353682, acc 0.78125
2020-02-08T03:32:41.388503: step 1033, loss 0.400093, acc 0.84375
2020-02-08T03:32:41.503652: step 1034, loss 0.305648, acc 0.84375
2020-02-08T03:32:41.622048: step 1035, loss 0.455442, acc 0.828125
2020-02-08T03:32:41.743474: step 1036, loss 0.336924, acc 0.90625
2020-02-08T03:32:41.865160: step 1037, loss 0.36377, acc 0.796875
2020-02-08T03:32:41.985206: step 1038, loss 0.315472, acc 0.84375
2020-02-08T03:32:42.102107: step 1039, loss 0.319892, acc 0.875
2020-02-08T03:32:42.222137: step 1040, loss 0.338641, acc 0.828125
2020-02-08T03:32:42.336176: step 1041, loss 0.351263, acc 0.90625
2020-02-08T03:32:42.453360: step 1042, loss 0.310518, acc 0.90625
2020-02-08T03:32:42.568850: step 1043, loss 0.310467, acc 0.890625
2020-02-08T03:32:42.685722: step 1044, loss 0.364025, acc 0.8125
2020-02-08T03:32:42.802536: step 1045, loss 0.453744, acc 0.8125
2020-02-08T03:32:42.921818: step 1046, loss 0.373005, acc 0.75
2020-02-08T03:32:43.038498: step 1047, loss 0.540644, acc 0.734375
2020-02-08T03:32:43.154546: step 1048, loss 0.320976, acc 0.875
2020-02-08T03:32:43.272935: step 1049, loss 0.416874, acc 0.859375
2020-02-08T03:32:43.383342: step 1050, loss 0.495066, acc 0.75
2020-02-08T03:32:43.499684: step 1051, loss 0.26195, acc 0.875
2020-02-08T03:32:43.621448: step 1052, loss 0.317727, acc 0.859375
2020-02-08T03:32:43.739845: step 1053, loss 0.226193, acc 0.921875
2020-02-08T03:32:43.863859: step 1054, loss 0.285999, acc 0.875
2020-02-08T03:32:43.983042: step 1055, loss 0.271439, acc 0.859375
2020-02-08T03:32:44.099657: step 1056, loss 0.361391, acc 0.875
2020-02-08T03:32:44.215556: step 1057, loss 0.203582, acc 0.9375
2020-02-08T03:32:44.334122: step 1058, loss 0.322367, acc 0.90625
2020-02-08T03:32:44.451152: step 1059, loss 0.243497, acc 0.890625
2020-02-08T03:32:44.568524: step 1060, loss 0.30355, acc 0.828125
2020-02-08T03:32:44.687094: step 1061, loss 0.254546, acc 0.9375
2020-02-08T03:32:44.803847: step 1062, loss 0.37042, acc 0.828125
2020-02-08T03:32:44.923621: step 1063, loss 0.362609, acc 0.84375
2020-02-08T03:32:45.043866: step 1064, loss 0.268183, acc 0.890625
2020-02-08T03:32:45.160195: step 1065, loss 0.336685, acc 0.890625
2020-02-08T03:32:45.281085: step 1066, loss 0.333995, acc 0.859375
2020-02-08T03:32:45.398946: step 1067, loss 0.310503, acc 0.828125
2020-02-08T03:32:45.519588: step 1068, loss 0.275538, acc 0.859375
2020-02-08T03:32:45.637561: step 1069, loss 0.326893, acc 0.859375
2020-02-08T03:32:45.751948: step 1070, loss 0.38257, acc 0.875
2020-02-08T03:32:45.870675: step 1071, loss 0.242804, acc 0.890625
2020-02-08T03:32:45.987378: step 1072, loss 0.359348, acc 0.859375
2020-02-08T03:32:46.103524: step 1073, loss 0.422725, acc 0.828125
2020-02-08T03:32:46.221910: step 1074, loss 0.270985, acc 0.890625
2020-02-08T03:32:46.339788: step 1075, loss 0.240807, acc 0.890625
2020-02-08T03:32:46.458164: step 1076, loss 0.430279, acc 0.796875
2020-02-08T03:32:46.574694: step 1077, loss 0.319049, acc 0.828125
2020-02-08T03:32:46.690736: step 1078, loss 0.281552, acc 0.890625
2020-02-08T03:32:46.808467: step 1079, loss 0.26707, acc 0.859375
2020-02-08T03:32:46.924405: step 1080, loss 0.326692, acc 0.828125
2020-02-08T03:32:47.040551: step 1081, loss 0.408763, acc 0.78125
2020-02-08T03:32:47.158195: step 1082, loss 0.314612, acc 0.890625
2020-02-08T03:32:47.278125: step 1083, loss 0.352997, acc 0.859375
2020-02-08T03:32:47.395445: step 1084, loss 0.259877, acc 0.921875
2020-02-08T03:32:47.513071: step 1085, loss 0.464116, acc 0.75
2020-02-08T03:32:47.631405: step 1086, loss 0.295916, acc 0.84375
2020-02-08T03:32:47.746460: step 1087, loss 0.368715, acc 0.8125
2020-02-08T03:32:47.866716: step 1088, loss 0.177425, acc 0.9375
2020-02-08T03:32:47.984621: step 1089, loss 0.214696, acc 0.9375
2020-02-08T03:32:48.102970: step 1090, loss 0.179801, acc 0.9375
2020-02-08T03:32:48.219254: step 1091, loss 0.355001, acc 0.8125
2020-02-08T03:32:48.334165: step 1092, loss 0.381034, acc 0.84375
2020-02-08T03:32:48.450457: step 1093, loss 0.196194, acc 0.9375
2020-02-08T03:32:48.568450: step 1094, loss 0.318694, acc 0.859375
2020-02-08T03:32:48.689933: step 1095, loss 0.304834, acc 0.84375
2020-02-08T03:32:48.808395: step 1096, loss 0.34388, acc 0.875
2020-02-08T03:32:48.928542: step 1097, loss 0.244519, acc 0.890625
2020-02-08T03:32:49.046583: step 1098, loss 0.294054, acc 0.8125
2020-02-08T03:32:49.161147: step 1099, loss 0.294646, acc 0.875
2020-02-08T03:32:49.277718: step 1100, loss 0.289593, acc 0.890625

Evaluation:
2020-02-08T03:32:49.471942: step 1100, loss 0.587605, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1100

2020-02-08T03:32:51.218065: step 1101, loss 0.249378, acc 0.875
2020-02-08T03:32:51.334770: step 1102, loss 0.227086, acc 0.953125
2020-02-08T03:32:51.596698: step 1103, loss 0.341035, acc 0.890625
2020-02-08T03:32:51.721129: step 1104, loss 0.253909, acc 0.890625
2020-02-08T03:32:51.840707: step 1105, loss 0.288607, acc 0.875
2020-02-08T03:32:51.955890: step 1106, loss 0.227591, acc 0.921875
2020-02-08T03:32:52.075467: step 1107, loss 0.351351, acc 0.875
2020-02-08T03:32:52.193394: step 1108, loss 0.319911, acc 0.859375
2020-02-08T03:32:52.309817: step 1109, loss 0.278633, acc 0.859375
2020-02-08T03:32:52.431442: step 1110, loss 0.338166, acc 0.875
2020-02-08T03:32:52.547271: step 1111, loss 0.293923, acc 0.859375
2020-02-08T03:32:52.662615: step 1112, loss 0.235796, acc 0.921875
2020-02-08T03:32:52.780581: step 1113, loss 0.41756, acc 0.765625
2020-02-08T03:32:52.897839: step 1114, loss 0.198654, acc 0.953125
2020-02-08T03:32:53.013249: step 1115, loss 0.286466, acc 0.875
2020-02-08T03:32:53.130872: step 1116, loss 0.251331, acc 0.890625
2020-02-08T03:32:53.246371: step 1117, loss 0.283893, acc 0.859375
2020-02-08T03:32:53.363155: step 1118, loss 0.208788, acc 0.90625
2020-02-08T03:32:53.477814: step 1119, loss 0.212194, acc 0.9375
2020-02-08T03:32:53.597762: step 1120, loss 0.275879, acc 0.875
2020-02-08T03:32:53.713365: step 1121, loss 0.274079, acc 0.875
2020-02-08T03:32:53.834524: step 1122, loss 0.401458, acc 0.859375
2020-02-08T03:32:53.949700: step 1123, loss 0.320482, acc 0.84375
2020-02-08T03:32:54.065477: step 1124, loss 0.293333, acc 0.859375
2020-02-08T03:32:54.183307: step 1125, loss 0.276773, acc 0.921875
2020-02-08T03:32:54.299072: step 1126, loss 0.292565, acc 0.921875
2020-02-08T03:32:54.416540: step 1127, loss 0.308845, acc 0.859375
2020-02-08T03:32:54.532683: step 1128, loss 0.362694, acc 0.859375
2020-02-08T03:32:54.649599: step 1129, loss 0.343883, acc 0.84375
2020-02-08T03:32:54.765979: step 1130, loss 0.308543, acc 0.875
2020-02-08T03:32:54.888688: step 1131, loss 0.28196, acc 0.875
2020-02-08T03:32:55.003243: step 1132, loss 0.335771, acc 0.90625
2020-02-08T03:32:55.122605: step 1133, loss 0.232068, acc 0.890625
2020-02-08T03:32:55.238567: step 1134, loss 0.171224, acc 0.953125
2020-02-08T03:32:55.354592: step 1135, loss 0.260258, acc 0.890625
2020-02-08T03:32:55.472454: step 1136, loss 0.285081, acc 0.90625
2020-02-08T03:32:55.589847: step 1137, loss 0.242543, acc 0.90625
2020-02-08T03:32:55.707719: step 1138, loss 0.318756, acc 0.859375
2020-02-08T03:32:55.825592: step 1139, loss 0.289097, acc 0.8125
2020-02-08T03:32:55.943061: step 1140, loss 0.25945, acc 0.875
2020-02-08T03:32:56.057077: step 1141, loss 0.372777, acc 0.84375
2020-02-08T03:32:56.175767: step 1142, loss 0.290327, acc 0.921875
2020-02-08T03:32:56.292755: step 1143, loss 0.209817, acc 0.9375
2020-02-08T03:32:56.410852: step 1144, loss 0.330171, acc 0.875
2020-02-08T03:32:56.529968: step 1145, loss 0.272953, acc 0.890625
2020-02-08T03:32:56.645522: step 1146, loss 0.194004, acc 0.953125
2020-02-08T03:32:56.760670: step 1147, loss 0.20041, acc 0.953125
2020-02-08T03:32:56.880852: step 1148, loss 0.37144, acc 0.796875
2020-02-08T03:32:56.995840: step 1149, loss 0.302713, acc 0.859375
2020-02-08T03:32:57.111101: step 1150, loss 0.464209, acc 0.84375
2020-02-08T03:32:57.228456: step 1151, loss 0.372126, acc 0.875
2020-02-08T03:32:57.344478: step 1152, loss 0.424344, acc 0.828125
2020-02-08T03:32:57.459079: step 1153, loss 0.362087, acc 0.84375
2020-02-08T03:32:57.575571: step 1154, loss 0.267929, acc 0.875
2020-02-08T03:32:57.691665: step 1155, loss 0.378705, acc 0.84375
2020-02-08T03:32:57.807023: step 1156, loss 0.248193, acc 0.890625
2020-02-08T03:32:57.927463: step 1157, loss 0.276342, acc 0.859375
2020-02-08T03:32:58.044971: step 1158, loss 0.347489, acc 0.796875
2020-02-08T03:32:58.163506: step 1159, loss 0.280342, acc 0.859375
2020-02-08T03:32:58.282836: step 1160, loss 0.413138, acc 0.765625
2020-02-08T03:32:58.400621: step 1161, loss 0.309557, acc 0.859375
2020-02-08T03:32:58.522483: step 1162, loss 0.277211, acc 0.890625
2020-02-08T03:32:58.639386: step 1163, loss 0.292332, acc 0.890625
2020-02-08T03:32:58.755136: step 1164, loss 0.323575, acc 0.875
2020-02-08T03:32:58.872640: step 1165, loss 0.319867, acc 0.859375
2020-02-08T03:32:58.989028: step 1166, loss 0.355155, acc 0.828125
2020-02-08T03:32:59.104778: step 1167, loss 0.353366, acc 0.828125
2020-02-08T03:32:59.223607: step 1168, loss 0.189989, acc 0.9375
2020-02-08T03:32:59.341430: step 1169, loss 0.374386, acc 0.84375
2020-02-08T03:32:59.455024: step 1170, loss 0.266684, acc 0.921875
2020-02-08T03:32:59.572005: step 1171, loss 0.394774, acc 0.78125
2020-02-08T03:32:59.691288: step 1172, loss 0.253007, acc 0.890625
2020-02-08T03:32:59.808786: step 1173, loss 0.432256, acc 0.796875
2020-02-08T03:32:59.929543: step 1174, loss 0.367506, acc 0.78125
2020-02-08T03:33:00.046767: step 1175, loss 0.371454, acc 0.828125
2020-02-08T03:33:00.162633: step 1176, loss 0.330426, acc 0.84375
2020-02-08T03:33:00.279916: step 1177, loss 0.287664, acc 0.890625
2020-02-08T03:33:00.396024: step 1178, loss 0.403711, acc 0.78125
2020-02-08T03:33:00.511234: step 1179, loss 0.269827, acc 0.875
2020-02-08T03:33:00.628551: step 1180, loss 0.34479, acc 0.796875
2020-02-08T03:33:00.743423: step 1181, loss 0.300133, acc 0.90625
2020-02-08T03:33:00.860453: step 1182, loss 0.305207, acc 0.84375
2020-02-08T03:33:00.978103: step 1183, loss 0.247692, acc 0.90625
2020-02-08T03:33:01.093365: step 1184, loss 0.405745, acc 0.8125
2020-02-08T03:33:01.209333: step 1185, loss 0.256768, acc 0.890625
2020-02-08T03:33:01.328468: step 1186, loss 0.327414, acc 0.859375
2020-02-08T03:33:01.443867: step 1187, loss 0.323231, acc 0.90625
2020-02-08T03:33:01.560569: step 1188, loss 0.181782, acc 0.96875
2020-02-08T03:33:01.678489: step 1189, loss 0.276126, acc 0.84375
2020-02-08T03:33:01.795836: step 1190, loss 0.358014, acc 0.84375
2020-02-08T03:33:01.918346: step 1191, loss 0.278192, acc 0.875
2020-02-08T03:33:02.035927: step 1192, loss 0.375444, acc 0.8125
2020-02-08T03:33:02.150767: step 1193, loss 0.225136, acc 0.9375
2020-02-08T03:33:02.266430: step 1194, loss 0.264569, acc 0.890625
2020-02-08T03:33:02.381669: step 1195, loss 0.216957, acc 0.90625
2020-02-08T03:33:02.497810: step 1196, loss 0.410755, acc 0.828125
2020-02-08T03:33:02.613925: step 1197, loss 0.312762, acc 0.84375
2020-02-08T03:33:02.729009: step 1198, loss 0.282157, acc 0.859375
2020-02-08T03:33:02.847628: step 1199, loss 0.369038, acc 0.78125
2020-02-08T03:33:02.959163: step 1200, loss 0.327452, acc 0.85

Evaluation:
2020-02-08T03:33:03.151178: step 1200, loss 0.60317, acc 0.709193

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1200

2020-02-08T03:33:04.625865: step 1201, loss 0.330717, acc 0.859375
2020-02-08T03:33:04.741925: step 1202, loss 0.220407, acc 0.921875
2020-02-08T03:33:04.859418: step 1203, loss 0.239743, acc 0.875
2020-02-08T03:33:04.978985: step 1204, loss 0.326515, acc 0.890625
2020-02-08T03:33:05.095238: step 1205, loss 0.223058, acc 0.875
2020-02-08T03:33:05.208205: step 1206, loss 0.285434, acc 0.84375
2020-02-08T03:33:05.327767: step 1207, loss 0.228351, acc 0.90625
2020-02-08T03:33:05.445426: step 1208, loss 0.251531, acc 0.890625
2020-02-08T03:33:05.562988: step 1209, loss 0.176546, acc 0.953125
2020-02-08T03:33:05.681111: step 1210, loss 0.301179, acc 0.890625
2020-02-08T03:33:05.799645: step 1211, loss 0.274559, acc 0.90625
2020-02-08T03:33:05.921942: step 1212, loss 0.175476, acc 0.90625
2020-02-08T03:33:06.039605: step 1213, loss 0.191649, acc 0.921875
2020-02-08T03:33:06.156994: step 1214, loss 0.159019, acc 0.9375
2020-02-08T03:33:06.274803: step 1215, loss 0.255923, acc 0.875
2020-02-08T03:33:06.390302: step 1216, loss 0.23282, acc 0.875
2020-02-08T03:33:06.508818: step 1217, loss 0.198814, acc 0.921875
2020-02-08T03:33:06.625345: step 1218, loss 0.219167, acc 0.859375
2020-02-08T03:33:06.741152: step 1219, loss 0.22126, acc 0.921875
2020-02-08T03:33:06.861975: step 1220, loss 0.178806, acc 0.9375
2020-02-08T03:33:06.979153: step 1221, loss 0.351958, acc 0.90625
2020-02-08T03:33:07.096744: step 1222, loss 0.295173, acc 0.84375
2020-02-08T03:33:07.213831: step 1223, loss 0.243502, acc 0.890625
2020-02-08T03:33:07.330950: step 1224, loss 0.219485, acc 0.921875
2020-02-08T03:33:07.448847: step 1225, loss 0.206128, acc 0.9375
2020-02-08T03:33:07.567822: step 1226, loss 0.287236, acc 0.890625
2020-02-08T03:33:07.683402: step 1227, loss 0.146113, acc 0.96875
2020-02-08T03:33:07.798790: step 1228, loss 0.13298, acc 0.96875
2020-02-08T03:33:07.919498: step 1229, loss 0.294389, acc 0.828125
2020-02-08T03:33:08.036377: step 1230, loss 0.279006, acc 0.875
2020-02-08T03:33:08.150104: step 1231, loss 0.166982, acc 0.96875
2020-02-08T03:33:08.268895: step 1232, loss 0.27904, acc 0.890625
2020-02-08T03:33:08.384842: step 1233, loss 0.20699, acc 0.9375
2020-02-08T03:33:08.500192: step 1234, loss 0.155672, acc 0.953125
2020-02-08T03:33:08.617418: step 1235, loss 0.234605, acc 0.890625
2020-02-08T03:33:08.735760: step 1236, loss 0.321294, acc 0.859375
2020-02-08T03:33:08.855674: step 1237, loss 0.214097, acc 0.9375
2020-02-08T03:33:08.974313: step 1238, loss 0.249676, acc 0.90625
2020-02-08T03:33:09.092799: step 1239, loss 0.347534, acc 0.84375
2020-02-08T03:33:09.208395: step 1240, loss 0.243125, acc 0.90625
2020-02-08T03:33:09.325126: step 1241, loss 0.2342, acc 0.875
2020-02-08T03:33:09.441056: step 1242, loss 0.212459, acc 0.921875
2020-02-08T03:33:09.555687: step 1243, loss 0.224191, acc 0.921875
2020-02-08T03:33:09.672079: step 1244, loss 0.244469, acc 0.890625
2020-02-08T03:33:09.787185: step 1245, loss 0.143662, acc 0.96875
2020-02-08T03:33:09.903723: step 1246, loss 0.364621, acc 0.84375
2020-02-08T03:33:10.017099: step 1247, loss 0.207507, acc 0.921875
2020-02-08T03:33:10.134976: step 1248, loss 0.199163, acc 0.921875
2020-02-08T03:33:10.250055: step 1249, loss 0.232397, acc 0.90625
2020-02-08T03:33:10.371780: step 1250, loss 0.143018, acc 0.921875
2020-02-08T03:33:10.489140: step 1251, loss 0.217303, acc 0.90625
2020-02-08T03:33:10.605564: step 1252, loss 0.27876, acc 0.84375
2020-02-08T03:33:10.721129: step 1253, loss 0.210334, acc 0.921875
2020-02-08T03:33:10.836568: step 1254, loss 0.348432, acc 0.84375
2020-02-08T03:33:10.953352: step 1255, loss 0.145863, acc 0.953125
2020-02-08T03:33:11.068083: step 1256, loss 0.245276, acc 0.875
2020-02-08T03:33:11.184505: step 1257, loss 0.199113, acc 0.90625
2020-02-08T03:33:11.301327: step 1258, loss 0.255181, acc 0.921875
2020-02-08T03:33:11.417013: step 1259, loss 0.172577, acc 0.921875
2020-02-08T03:33:11.535730: step 1260, loss 0.160084, acc 0.953125
2020-02-08T03:33:11.653553: step 1261, loss 0.133357, acc 0.96875
2020-02-08T03:33:11.773490: step 1262, loss 0.208245, acc 0.90625
2020-02-08T03:33:11.891756: step 1263, loss 0.220578, acc 0.9375
2020-02-08T03:33:12.007627: step 1264, loss 0.182536, acc 0.921875
2020-02-08T03:33:12.125018: step 1265, loss 0.205801, acc 0.921875
2020-02-08T03:33:12.243486: step 1266, loss 0.247887, acc 0.921875
2020-02-08T03:33:12.360092: step 1267, loss 0.327618, acc 0.828125
2020-02-08T03:33:12.477165: step 1268, loss 0.427463, acc 0.84375
2020-02-08T03:33:12.594011: step 1269, loss 0.266435, acc 0.890625
2020-02-08T03:33:12.710725: step 1270, loss 0.234186, acc 0.90625
2020-02-08T03:33:12.826767: step 1271, loss 0.217997, acc 0.90625
2020-02-08T03:33:12.940793: step 1272, loss 0.165817, acc 0.890625
2020-02-08T03:33:13.060163: step 1273, loss 0.442751, acc 0.828125
2020-02-08T03:33:13.179379: step 1274, loss 0.113275, acc 0.984375
2020-02-08T03:33:13.298529: step 1275, loss 0.146367, acc 0.953125
2020-02-08T03:33:13.418122: step 1276, loss 0.319817, acc 0.828125
2020-02-08T03:33:13.533846: step 1277, loss 0.311205, acc 0.859375
2020-02-08T03:33:13.652154: step 1278, loss 0.331832, acc 0.84375
2020-02-08T03:33:13.767177: step 1279, loss 0.243824, acc 0.90625
2020-02-08T03:33:13.888695: step 1280, loss 0.128226, acc 0.96875
2020-02-08T03:33:14.006370: step 1281, loss 0.245816, acc 0.890625
2020-02-08T03:33:14.122884: step 1282, loss 0.221513, acc 0.921875
2020-02-08T03:33:14.241356: step 1283, loss 0.248587, acc 0.875
2020-02-08T03:33:14.356351: step 1284, loss 0.237701, acc 0.90625
2020-02-08T03:33:14.475969: step 1285, loss 0.243255, acc 0.90625
2020-02-08T03:33:14.594025: step 1286, loss 0.214904, acc 0.90625
2020-02-08T03:33:14.711092: step 1287, loss 0.174848, acc 0.921875
2020-02-08T03:33:14.828199: step 1288, loss 0.192996, acc 0.953125
2020-02-08T03:33:14.945591: step 1289, loss 0.237632, acc 0.890625
2020-02-08T03:33:15.061015: step 1290, loss 0.156785, acc 0.9375
2020-02-08T03:33:15.179654: step 1291, loss 0.248465, acc 0.859375
2020-02-08T03:33:15.297814: step 1292, loss 0.232981, acc 0.9375
2020-02-08T03:33:15.417326: step 1293, loss 0.283917, acc 0.890625
2020-02-08T03:33:15.535681: step 1294, loss 0.125991, acc 0.984375
2020-02-08T03:33:15.652000: step 1295, loss 0.294958, acc 0.84375
2020-02-08T03:33:15.770333: step 1296, loss 0.2719, acc 0.90625
2020-02-08T03:33:15.888693: step 1297, loss 0.231416, acc 0.90625
2020-02-08T03:33:16.006139: step 1298, loss 0.190946, acc 0.90625
2020-02-08T03:33:16.124352: step 1299, loss 0.246272, acc 0.90625
2020-02-08T03:33:16.240685: step 1300, loss 0.286374, acc 0.875

Evaluation:
2020-02-08T03:33:16.432505: step 1300, loss 0.597858, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1300

2020-02-08T03:33:17.986183: step 1301, loss 0.27817, acc 0.90625
2020-02-08T03:33:18.102346: step 1302, loss 0.281226, acc 0.84375
2020-02-08T03:33:18.221091: step 1303, loss 0.162475, acc 0.9375
2020-02-08T03:33:18.338603: step 1304, loss 0.229715, acc 0.90625
2020-02-08T03:33:18.456307: step 1305, loss 0.200835, acc 0.953125
2020-02-08T03:33:18.575310: step 1306, loss 0.151, acc 0.9375
2020-02-08T03:33:18.690030: step 1307, loss 0.322565, acc 0.828125
2020-02-08T03:33:18.805510: step 1308, loss 0.230484, acc 0.875
2020-02-08T03:33:18.921940: step 1309, loss 0.23099, acc 0.890625
2020-02-08T03:33:19.040885: step 1310, loss 0.120905, acc 0.984375
2020-02-08T03:33:19.157684: step 1311, loss 0.207113, acc 0.96875
2020-02-08T03:33:19.275361: step 1312, loss 0.266368, acc 0.875
2020-02-08T03:33:19.391352: step 1313, loss 0.269503, acc 0.921875
2020-02-08T03:33:19.508852: step 1314, loss 0.289702, acc 0.90625
2020-02-08T03:33:19.623263: step 1315, loss 0.355536, acc 0.84375
2020-02-08T03:33:19.739887: step 1316, loss 0.220103, acc 0.890625
2020-02-08T03:33:19.857269: step 1317, loss 0.250614, acc 0.921875
2020-02-08T03:33:19.974562: step 1318, loss 0.220719, acc 0.875
2020-02-08T03:33:20.091608: step 1319, loss 0.264997, acc 0.90625
2020-02-08T03:33:20.208470: step 1320, loss 0.311696, acc 0.828125
2020-02-08T03:33:20.325567: step 1321, loss 0.210206, acc 0.90625
2020-02-08T03:33:20.443323: step 1322, loss 0.338681, acc 0.84375
2020-02-08T03:33:20.560142: step 1323, loss 0.162706, acc 0.953125
2020-02-08T03:33:20.679659: step 1324, loss 0.259761, acc 0.90625
2020-02-08T03:33:20.795860: step 1325, loss 0.311328, acc 0.875
2020-02-08T03:33:20.910360: step 1326, loss 0.229825, acc 0.9375
2020-02-08T03:33:21.027730: step 1327, loss 0.182809, acc 0.921875
2020-02-08T03:33:21.143160: step 1328, loss 0.167233, acc 0.9375
2020-02-08T03:33:21.257366: step 1329, loss 0.298461, acc 0.875
2020-02-08T03:33:21.372034: step 1330, loss 0.220454, acc 0.921875
2020-02-08T03:33:21.484876: step 1331, loss 0.399406, acc 0.8125
2020-02-08T03:33:21.600084: step 1332, loss 0.269624, acc 0.875
2020-02-08T03:33:21.733437: step 1333, loss 0.206459, acc 0.859375
2020-02-08T03:33:21.852496: step 1334, loss 0.26457, acc 0.921875
2020-02-08T03:33:21.969231: step 1335, loss 0.244139, acc 0.875
2020-02-08T03:33:22.085951: step 1336, loss 0.322955, acc 0.890625
2020-02-08T03:33:22.203931: step 1337, loss 0.199985, acc 0.921875
2020-02-08T03:33:22.320939: step 1338, loss 0.169264, acc 0.953125
2020-02-08T03:33:22.437884: step 1339, loss 0.262537, acc 0.890625
2020-02-08T03:33:22.554198: step 1340, loss 0.194843, acc 0.921875
2020-02-08T03:33:22.672113: step 1341, loss 0.279278, acc 0.90625
2020-02-08T03:33:22.789830: step 1342, loss 0.228401, acc 0.890625
2020-02-08T03:33:22.906083: step 1343, loss 0.176308, acc 0.921875
2020-02-08T03:33:23.023369: step 1344, loss 0.211072, acc 0.921875
2020-02-08T03:33:23.143601: step 1345, loss 0.291878, acc 0.859375
2020-02-08T03:33:23.258517: step 1346, loss 0.193437, acc 0.921875
2020-02-08T03:33:23.375004: step 1347, loss 0.166823, acc 0.9375
2020-02-08T03:33:23.494733: step 1348, loss 0.210871, acc 0.890625
2020-02-08T03:33:23.612553: step 1349, loss 0.232726, acc 0.90625
2020-02-08T03:33:23.725858: step 1350, loss 0.137259, acc 0.933333
2020-02-08T03:33:23.844014: step 1351, loss 0.175721, acc 0.9375
2020-02-08T03:33:23.957655: step 1352, loss 0.142582, acc 0.953125
2020-02-08T03:33:24.073312: step 1353, loss 0.121255, acc 0.96875
2020-02-08T03:33:24.190072: step 1354, loss 0.21552, acc 0.890625
2020-02-08T03:33:24.305179: step 1355, loss 0.196023, acc 0.9375
2020-02-08T03:33:24.420639: step 1356, loss 0.113153, acc 0.96875
2020-02-08T03:33:24.537638: step 1357, loss 0.167247, acc 0.9375
2020-02-08T03:33:24.656802: step 1358, loss 0.206121, acc 0.9375
2020-02-08T03:33:24.775757: step 1359, loss 0.098209, acc 0.953125
2020-02-08T03:33:24.894608: step 1360, loss 0.1256, acc 0.953125
2020-02-08T03:33:25.013420: step 1361, loss 0.139637, acc 0.96875
2020-02-08T03:33:25.131243: step 1362, loss 0.20091, acc 0.921875
2020-02-08T03:33:25.247049: step 1363, loss 0.182241, acc 0.90625
2020-02-08T03:33:25.362343: step 1364, loss 0.133215, acc 0.953125
2020-02-08T03:33:25.481265: step 1365, loss 0.153469, acc 0.953125
2020-02-08T03:33:25.596384: step 1366, loss 0.23298, acc 0.921875
2020-02-08T03:33:25.711212: step 1367, loss 0.178884, acc 0.90625
2020-02-08T03:33:25.829791: step 1368, loss 0.205202, acc 0.921875
2020-02-08T03:33:25.946462: step 1369, loss 0.124609, acc 0.953125
2020-02-08T03:33:26.065489: step 1370, loss 0.124735, acc 0.953125
2020-02-08T03:33:26.181833: step 1371, loss 0.10695, acc 0.984375
2020-02-08T03:33:26.295964: step 1372, loss 0.078491, acc 1
2020-02-08T03:33:26.417790: step 1373, loss 0.102667, acc 0.96875
2020-02-08T03:33:26.533389: step 1374, loss 0.21565, acc 0.90625
2020-02-08T03:33:26.648909: step 1375, loss 0.16367, acc 0.9375
2020-02-08T03:33:26.764769: step 1376, loss 0.159399, acc 0.9375
2020-02-08T03:33:26.882025: step 1377, loss 0.134616, acc 0.96875
2020-02-08T03:33:26.996684: step 1378, loss 0.178985, acc 0.9375
2020-02-08T03:33:27.115635: step 1379, loss 0.247689, acc 0.921875
2020-02-08T03:33:27.234434: step 1380, loss 0.205294, acc 0.953125
2020-02-08T03:33:27.350386: step 1381, loss 0.204859, acc 0.875
2020-02-08T03:33:27.467452: step 1382, loss 0.175052, acc 0.90625
2020-02-08T03:33:27.582761: step 1383, loss 0.153736, acc 0.953125
2020-02-08T03:33:27.698773: step 1384, loss 0.189549, acc 0.9375
2020-02-08T03:33:27.816528: step 1385, loss 0.248245, acc 0.890625
2020-02-08T03:33:27.932459: step 1386, loss 0.147736, acc 0.9375
2020-02-08T03:33:28.045186: step 1387, loss 0.108199, acc 0.96875
2020-02-08T03:33:28.160439: step 1388, loss 0.142104, acc 0.9375
2020-02-08T03:33:28.278119: step 1389, loss 0.123845, acc 0.953125
2020-02-08T03:33:28.393519: step 1390, loss 0.153409, acc 0.984375
2020-02-08T03:33:28.508628: step 1391, loss 0.224689, acc 0.9375
2020-02-08T03:33:28.623969: step 1392, loss 0.183044, acc 0.9375
2020-02-08T03:33:28.737968: step 1393, loss 0.121309, acc 0.96875
2020-02-08T03:33:28.854235: step 1394, loss 0.195188, acc 0.921875
2020-02-08T03:33:28.972307: step 1395, loss 0.178457, acc 0.921875
2020-02-08T03:33:29.089197: step 1396, loss 0.178379, acc 0.9375
2020-02-08T03:33:29.203618: step 1397, loss 0.220241, acc 0.921875
2020-02-08T03:33:29.319173: step 1398, loss 0.207018, acc 0.921875
2020-02-08T03:33:29.436503: step 1399, loss 0.165217, acc 0.90625
2020-02-08T03:33:29.552669: step 1400, loss 0.213648, acc 0.921875

Evaluation:
2020-02-08T03:33:29.747713: step 1400, loss 0.617484, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1400

2020-02-08T03:33:31.325725: step 1401, loss 0.28169, acc 0.859375
2020-02-08T03:33:31.441257: step 1402, loss 0.307292, acc 0.859375
2020-02-08T03:33:31.556925: step 1403, loss 0.120953, acc 0.953125
2020-02-08T03:33:31.672403: step 1404, loss 0.131149, acc 0.9375
2020-02-08T03:33:31.786852: step 1405, loss 0.0919564, acc 0.96875
2020-02-08T03:33:31.903504: step 1406, loss 0.152197, acc 0.9375
2020-02-08T03:33:32.020883: step 1407, loss 0.232503, acc 0.921875
2020-02-08T03:33:32.136255: step 1408, loss 0.120056, acc 0.9375
2020-02-08T03:33:32.252661: step 1409, loss 0.297448, acc 0.875
2020-02-08T03:33:32.367859: step 1410, loss 0.2168, acc 0.921875
2020-02-08T03:33:32.485227: step 1411, loss 0.235901, acc 0.90625
2020-02-08T03:33:32.601299: step 1412, loss 0.155252, acc 0.921875
2020-02-08T03:33:32.719034: step 1413, loss 0.150673, acc 0.9375
2020-02-08T03:33:32.835618: step 1414, loss 0.104818, acc 0.984375
2020-02-08T03:33:32.951230: step 1415, loss 0.14907, acc 0.9375
2020-02-08T03:33:33.068777: step 1416, loss 0.223974, acc 0.875
2020-02-08T03:33:33.189488: step 1417, loss 0.137685, acc 0.9375
2020-02-08T03:33:33.306509: step 1418, loss 0.242768, acc 0.90625
2020-02-08T03:33:33.424231: step 1419, loss 0.239199, acc 0.890625
2020-02-08T03:33:33.542061: step 1420, loss 0.203278, acc 0.890625
2020-02-08T03:33:33.655966: step 1421, loss 0.191353, acc 0.921875
2020-02-08T03:33:33.770504: step 1422, loss 0.123634, acc 0.96875
2020-02-08T03:33:33.886180: step 1423, loss 0.171026, acc 0.9375
2020-02-08T03:33:34.001103: step 1424, loss 0.121093, acc 0.953125
2020-02-08T03:33:34.118603: step 1425, loss 0.230701, acc 0.90625
2020-02-08T03:33:34.236423: step 1426, loss 0.214618, acc 0.921875
2020-02-08T03:33:34.353769: step 1427, loss 0.162855, acc 0.921875
2020-02-08T03:33:34.472936: step 1428, loss 0.182434, acc 0.90625
2020-02-08T03:33:34.591219: step 1429, loss 0.17805, acc 0.9375
2020-02-08T03:33:34.709372: step 1430, loss 0.133598, acc 0.96875
2020-02-08T03:33:34.825392: step 1431, loss 0.131985, acc 0.9375
2020-02-08T03:33:34.942924: step 1432, loss 0.175673, acc 0.90625
2020-02-08T03:33:35.062406: step 1433, loss 0.0901177, acc 0.984375
2020-02-08T03:33:35.179721: step 1434, loss 0.14333, acc 0.921875
2020-02-08T03:33:35.297109: step 1435, loss 0.125504, acc 0.953125
2020-02-08T03:33:35.413269: step 1436, loss 0.133609, acc 0.921875
2020-02-08T03:33:35.528032: step 1437, loss 0.2596, acc 0.890625
2020-02-08T03:33:35.641600: step 1438, loss 0.139214, acc 0.9375
2020-02-08T03:33:35.756404: step 1439, loss 0.1248, acc 0.953125
2020-02-08T03:33:35.872228: step 1440, loss 0.218917, acc 0.890625
2020-02-08T03:33:35.990304: step 1441, loss 0.176361, acc 0.90625
2020-02-08T03:33:36.105272: step 1442, loss 0.133086, acc 0.953125
2020-02-08T03:33:36.223854: step 1443, loss 0.353998, acc 0.859375
2020-02-08T03:33:36.342708: step 1444, loss 0.191907, acc 0.90625
2020-02-08T03:33:36.458985: step 1445, loss 0.131155, acc 0.984375
2020-02-08T03:33:36.582053: step 1446, loss 0.128591, acc 0.953125
2020-02-08T03:33:36.700695: step 1447, loss 0.30692, acc 0.875
2020-02-08T03:33:36.820041: step 1448, loss 0.0995032, acc 0.96875
2020-02-08T03:33:36.938668: step 1449, loss 0.225593, acc 0.9375
2020-02-08T03:33:37.054820: step 1450, loss 0.196475, acc 0.9375
2020-02-08T03:33:37.169929: step 1451, loss 0.236616, acc 0.90625
2020-02-08T03:33:37.290331: step 1452, loss 0.190162, acc 0.921875
2020-02-08T03:33:37.404885: step 1453, loss 0.19381, acc 0.9375
2020-02-08T03:33:37.521247: step 1454, loss 0.0754983, acc 0.984375
2020-02-08T03:33:37.640617: step 1455, loss 0.162814, acc 0.921875
2020-02-08T03:33:37.756531: step 1456, loss 0.181451, acc 0.9375
2020-02-08T03:33:37.875987: step 1457, loss 0.0904884, acc 0.984375
2020-02-08T03:33:37.992832: step 1458, loss 0.267066, acc 0.875
2020-02-08T03:33:38.108047: step 1459, loss 0.111826, acc 0.984375
2020-02-08T03:33:38.231770: step 1460, loss 0.14125, acc 0.953125
2020-02-08T03:33:38.347796: step 1461, loss 0.162926, acc 0.890625
2020-02-08T03:33:38.470327: step 1462, loss 0.190056, acc 0.96875
2020-02-08T03:33:38.587388: step 1463, loss 0.171715, acc 0.9375
2020-02-08T03:33:38.706248: step 1464, loss 0.169676, acc 0.921875
2020-02-08T03:33:38.825624: step 1465, loss 0.20813, acc 0.90625
2020-02-08T03:33:38.943086: step 1466, loss 0.12868, acc 0.9375
2020-02-08T03:33:39.059932: step 1467, loss 0.322698, acc 0.90625
2020-02-08T03:33:39.179925: step 1468, loss 0.18404, acc 0.9375
2020-02-08T03:33:39.297028: step 1469, loss 0.163243, acc 0.9375
2020-02-08T03:33:39.414380: step 1470, loss 0.249614, acc 0.890625
2020-02-08T03:33:39.532858: step 1471, loss 0.19661, acc 0.9375
2020-02-08T03:33:39.650624: step 1472, loss 0.146099, acc 0.9375
2020-02-08T03:33:39.767050: step 1473, loss 0.180387, acc 0.953125
2020-02-08T03:33:39.886630: step 1474, loss 0.197304, acc 0.90625
2020-02-08T03:33:40.001680: step 1475, loss 0.159341, acc 0.953125
2020-02-08T03:33:40.119580: step 1476, loss 0.229939, acc 0.90625
2020-02-08T03:33:40.237807: step 1477, loss 0.143021, acc 0.96875
2020-02-08T03:33:40.353494: step 1478, loss 0.196572, acc 0.9375
2020-02-08T03:33:40.470038: step 1479, loss 0.158034, acc 0.921875
2020-02-08T03:33:40.589163: step 1480, loss 0.173113, acc 0.9375
2020-02-08T03:33:40.706487: step 1481, loss 0.143625, acc 0.9375
2020-02-08T03:33:40.822627: step 1482, loss 0.123768, acc 0.953125
2020-02-08T03:33:40.939644: step 1483, loss 0.209019, acc 0.9375
2020-02-08T03:33:41.057130: step 1484, loss 0.154431, acc 0.9375
2020-02-08T03:33:41.174919: step 1485, loss 0.114359, acc 1
2020-02-08T03:33:41.293314: step 1486, loss 0.157429, acc 0.953125
2020-02-08T03:33:41.409444: step 1487, loss 0.198626, acc 0.921875
2020-02-08T03:33:41.526940: step 1488, loss 0.12225, acc 0.953125
2020-02-08T03:33:41.647285: step 1489, loss 0.141201, acc 0.90625
2020-02-08T03:33:41.765691: step 1490, loss 0.147708, acc 0.953125
2020-02-08T03:33:41.882196: step 1491, loss 0.122041, acc 0.984375
2020-02-08T03:33:41.998909: step 1492, loss 0.131679, acc 0.953125
2020-02-08T03:33:42.114160: step 1493, loss 0.221169, acc 0.921875
2020-02-08T03:33:42.232253: step 1494, loss 0.178646, acc 0.90625
2020-02-08T03:33:42.346905: step 1495, loss 0.157871, acc 0.9375
2020-02-08T03:33:42.463804: step 1496, loss 0.217135, acc 0.90625
2020-02-08T03:33:42.581448: step 1497, loss 0.186675, acc 0.9375
2020-02-08T03:33:42.697557: step 1498, loss 0.163818, acc 0.921875
2020-02-08T03:33:42.816812: step 1499, loss 0.234367, acc 0.890625
2020-02-08T03:33:42.932842: step 1500, loss 0.125882, acc 0.95

Evaluation:
2020-02-08T03:33:43.121057: step 1500, loss 0.628813, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1500

2020-02-08T03:33:44.579369: step 1501, loss 0.0814325, acc 0.96875
2020-02-08T03:33:44.696686: step 1502, loss 0.167853, acc 0.921875
2020-02-08T03:33:44.814085: step 1503, loss 0.0893877, acc 0.984375
2020-02-08T03:33:44.931254: step 1504, loss 0.231409, acc 0.90625
2020-02-08T03:33:45.047175: step 1505, loss 0.0717549, acc 0.984375
2020-02-08T03:33:45.162801: step 1506, loss 0.133348, acc 0.96875
2020-02-08T03:33:45.279452: step 1507, loss 0.0646502, acc 1
2020-02-08T03:33:45.394440: step 1508, loss 0.19606, acc 0.921875
2020-02-08T03:33:45.510908: step 1509, loss 0.176393, acc 0.921875
2020-02-08T03:33:45.627450: step 1510, loss 0.122324, acc 0.9375
2020-02-08T03:33:45.744055: step 1511, loss 0.138684, acc 0.9375
2020-02-08T03:33:45.863032: step 1512, loss 0.112372, acc 0.984375
2020-02-08T03:33:45.979782: step 1513, loss 0.10977, acc 0.984375
2020-02-08T03:33:46.095982: step 1514, loss 0.119512, acc 0.9375
2020-02-08T03:33:46.211355: step 1515, loss 0.150956, acc 0.921875
2020-02-08T03:33:46.326707: step 1516, loss 0.11224, acc 0.953125
2020-02-08T03:33:46.446341: step 1517, loss 0.131073, acc 0.9375
2020-02-08T03:33:46.565501: step 1518, loss 0.142882, acc 0.9375
2020-02-08T03:33:46.680351: step 1519, loss 0.229941, acc 0.90625
2020-02-08T03:33:46.796129: step 1520, loss 0.184479, acc 0.890625
2020-02-08T03:33:46.913323: step 1521, loss 0.0930274, acc 0.96875
2020-02-08T03:33:47.032202: step 1522, loss 0.0878659, acc 0.96875
2020-02-08T03:33:47.148458: step 1523, loss 0.214336, acc 0.9375
2020-02-08T03:33:47.261698: step 1524, loss 0.142143, acc 0.953125
2020-02-08T03:33:47.378678: step 1525, loss 0.0694737, acc 1
2020-02-08T03:33:47.494465: step 1526, loss 0.131813, acc 0.953125
2020-02-08T03:33:47.608084: step 1527, loss 0.165342, acc 0.9375
2020-02-08T03:33:47.728499: step 1528, loss 0.161381, acc 0.9375
2020-02-08T03:33:47.845837: step 1529, loss 0.102625, acc 0.96875
2020-02-08T03:33:47.962754: step 1530, loss 0.165895, acc 0.921875
2020-02-08T03:33:48.081629: step 1531, loss 0.238379, acc 0.890625
2020-02-08T03:33:48.198959: step 1532, loss 0.0884093, acc 0.96875
2020-02-08T03:33:48.315979: step 1533, loss 0.14432, acc 0.953125
2020-02-08T03:33:48.434801: step 1534, loss 0.177978, acc 0.921875
2020-02-08T03:33:48.548712: step 1535, loss 0.133174, acc 0.921875
2020-02-08T03:33:48.663288: step 1536, loss 0.0939482, acc 0.984375
2020-02-08T03:33:48.782712: step 1537, loss 0.148956, acc 0.9375
2020-02-08T03:33:48.900172: step 1538, loss 0.162016, acc 0.953125
2020-02-08T03:33:49.014274: step 1539, loss 0.0892693, acc 1
2020-02-08T03:33:49.133293: step 1540, loss 0.10479, acc 0.96875
2020-02-08T03:33:49.249385: step 1541, loss 0.10481, acc 0.96875
2020-02-08T03:33:49.366017: step 1542, loss 0.149066, acc 0.984375
2020-02-08T03:33:49.484993: step 1543, loss 0.0871769, acc 1
2020-02-08T03:33:49.603240: step 1544, loss 0.0765651, acc 0.96875
2020-02-08T03:33:49.720268: step 1545, loss 0.0942059, acc 0.953125
2020-02-08T03:33:49.842901: step 1546, loss 0.171693, acc 0.921875
2020-02-08T03:33:49.964989: step 1547, loss 0.214223, acc 0.90625
2020-02-08T03:33:50.083804: step 1548, loss 0.188156, acc 0.9375
2020-02-08T03:33:50.200684: step 1549, loss 0.103002, acc 0.984375
2020-02-08T03:33:50.317906: step 1550, loss 0.105687, acc 0.96875
2020-02-08T03:33:50.436794: step 1551, loss 0.161319, acc 0.9375
2020-02-08T03:33:50.553457: step 1552, loss 0.171106, acc 0.953125
2020-02-08T03:33:50.671583: step 1553, loss 0.0985225, acc 0.953125
2020-02-08T03:33:50.788801: step 1554, loss 0.141957, acc 0.9375
2020-02-08T03:33:50.903393: step 1555, loss 0.13885, acc 0.9375
2020-02-08T03:33:51.020682: step 1556, loss 0.227192, acc 0.890625
2020-02-08T03:33:51.139113: step 1557, loss 0.113279, acc 0.953125
2020-02-08T03:33:51.255544: step 1558, loss 0.20686, acc 0.890625
2020-02-08T03:33:51.612382: step 1559, loss 0.0898982, acc 0.984375
2020-02-08T03:33:51.747124: step 1560, loss 0.127556, acc 0.9375
2020-02-08T03:33:51.864431: step 1561, loss 0.164193, acc 0.90625
2020-02-08T03:33:51.982580: step 1562, loss 0.104275, acc 0.953125
2020-02-08T03:33:52.099973: step 1563, loss 0.218801, acc 0.9375
2020-02-08T03:33:52.218734: step 1564, loss 0.120202, acc 0.96875
2020-02-08T03:33:52.337927: step 1565, loss 0.18897, acc 0.921875
2020-02-08T03:33:52.453159: step 1566, loss 0.171215, acc 0.9375
2020-02-08T03:33:52.569682: step 1567, loss 0.076251, acc 0.96875
2020-02-08T03:33:52.687737: step 1568, loss 0.0730999, acc 0.984375
2020-02-08T03:33:52.804660: step 1569, loss 0.239661, acc 0.9375
2020-02-08T03:33:52.920011: step 1570, loss 0.102135, acc 0.953125
2020-02-08T03:33:53.037738: step 1571, loss 0.215597, acc 0.921875
2020-02-08T03:33:53.152588: step 1572, loss 0.209415, acc 0.921875
2020-02-08T03:33:53.271904: step 1573, loss 0.170211, acc 0.90625
2020-02-08T03:33:53.391656: step 1574, loss 0.100909, acc 0.953125
2020-02-08T03:33:53.507614: step 1575, loss 0.0941037, acc 0.953125
2020-02-08T03:33:53.629275: step 1576, loss 0.211578, acc 0.921875
2020-02-08T03:33:53.746677: step 1577, loss 0.107447, acc 0.953125
2020-02-08T03:33:53.862337: step 1578, loss 0.172096, acc 0.9375
2020-02-08T03:33:53.979146: step 1579, loss 0.124725, acc 0.953125
2020-02-08T03:33:54.096433: step 1580, loss 0.133731, acc 0.953125
2020-02-08T03:33:54.210761: step 1581, loss 0.0842681, acc 0.96875
2020-02-08T03:33:54.327147: step 1582, loss 0.128424, acc 0.96875
2020-02-08T03:33:54.443502: step 1583, loss 0.144449, acc 0.9375
2020-02-08T03:33:54.558975: step 1584, loss 0.153791, acc 0.9375
2020-02-08T03:33:54.674399: step 1585, loss 0.158768, acc 0.953125
2020-02-08T03:33:54.795667: step 1586, loss 0.21939, acc 0.921875
2020-02-08T03:33:54.912519: step 1587, loss 0.0883095, acc 0.96875
2020-02-08T03:33:55.031817: step 1588, loss 0.106583, acc 0.96875
2020-02-08T03:33:55.147607: step 1589, loss 0.144037, acc 0.9375
2020-02-08T03:33:55.264758: step 1590, loss 0.0783714, acc 0.96875
2020-02-08T03:33:55.380232: step 1591, loss 0.220409, acc 0.90625
2020-02-08T03:33:55.497024: step 1592, loss 0.29412, acc 0.84375
2020-02-08T03:33:55.613137: step 1593, loss 0.135195, acc 0.953125
2020-02-08T03:33:55.731370: step 1594, loss 0.124679, acc 0.9375
2020-02-08T03:33:55.848184: step 1595, loss 0.127035, acc 0.96875
2020-02-08T03:33:55.968211: step 1596, loss 0.166537, acc 0.96875
2020-02-08T03:33:56.086634: step 1597, loss 0.142118, acc 0.96875
2020-02-08T03:33:56.201162: step 1598, loss 0.199565, acc 0.9375
2020-02-08T03:33:56.319163: step 1599, loss 0.101268, acc 0.953125
2020-02-08T03:33:56.437576: step 1600, loss 0.0659366, acc 1

Evaluation:
2020-02-08T03:33:56.627803: step 1600, loss 0.683594, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1600

2020-02-08T03:33:58.123164: step 1601, loss 0.219009, acc 0.921875
2020-02-08T03:33:58.240850: step 1602, loss 0.0863906, acc 0.96875
2020-02-08T03:33:58.360471: step 1603, loss 0.132631, acc 0.953125
2020-02-08T03:33:58.477953: step 1604, loss 0.156178, acc 0.921875
2020-02-08T03:33:58.595612: step 1605, loss 0.0725278, acc 0.984375
2020-02-08T03:33:58.713425: step 1606, loss 0.21702, acc 0.90625
2020-02-08T03:33:58.835711: step 1607, loss 0.143415, acc 0.90625
2020-02-08T03:33:58.951920: step 1608, loss 0.227594, acc 0.890625
2020-02-08T03:33:59.073368: step 1609, loss 0.217542, acc 0.921875
2020-02-08T03:33:59.191961: step 1610, loss 0.157075, acc 0.9375
2020-02-08T03:33:59.306314: step 1611, loss 0.220212, acc 0.921875
2020-02-08T03:33:59.423955: step 1612, loss 0.181742, acc 0.953125
2020-02-08T03:33:59.538928: step 1613, loss 0.116811, acc 0.9375
2020-02-08T03:33:59.652885: step 1614, loss 0.163382, acc 0.921875
2020-02-08T03:33:59.770474: step 1615, loss 0.199961, acc 0.90625
2020-02-08T03:33:59.887996: step 1616, loss 0.217096, acc 0.90625
2020-02-08T03:34:00.008086: step 1617, loss 0.200918, acc 0.921875
2020-02-08T03:34:00.131963: step 1618, loss 0.172877, acc 0.921875
2020-02-08T03:34:00.247672: step 1619, loss 0.121499, acc 0.96875
2020-02-08T03:34:00.363590: step 1620, loss 0.143489, acc 0.96875
2020-02-08T03:34:00.484283: step 1621, loss 0.10752, acc 0.96875
2020-02-08T03:34:00.600323: step 1622, loss 0.229867, acc 0.921875
2020-02-08T03:34:00.717446: step 1623, loss 0.155419, acc 0.953125
2020-02-08T03:34:00.834639: step 1624, loss 0.129998, acc 0.921875
2020-02-08T03:34:00.950070: step 1625, loss 0.146106, acc 0.9375
2020-02-08T03:34:01.067328: step 1626, loss 0.0702469, acc 1
2020-02-08T03:34:01.187912: step 1627, loss 0.105725, acc 0.96875
2020-02-08T03:34:01.305080: step 1628, loss 0.214989, acc 0.921875
2020-02-08T03:34:01.423251: step 1629, loss 0.168514, acc 0.921875
2020-02-08T03:34:01.539287: step 1630, loss 0.0930173, acc 0.96875
2020-02-08T03:34:01.656157: step 1631, loss 0.185871, acc 0.953125
2020-02-08T03:34:01.775706: step 1632, loss 0.168204, acc 0.921875
2020-02-08T03:34:01.892378: step 1633, loss 0.138307, acc 0.90625
2020-02-08T03:34:02.005784: step 1634, loss 0.154653, acc 0.953125
2020-02-08T03:34:02.121158: step 1635, loss 0.0783431, acc 0.984375
2020-02-08T03:34:02.238910: step 1636, loss 0.186703, acc 0.90625
2020-02-08T03:34:02.353198: step 1637, loss 0.275393, acc 0.875
2020-02-08T03:34:02.471205: step 1638, loss 0.107265, acc 0.953125
2020-02-08T03:34:02.586330: step 1639, loss 0.177367, acc 0.921875
2020-02-08T03:34:02.701811: step 1640, loss 0.202505, acc 0.921875
2020-02-08T03:34:02.822098: step 1641, loss 0.142234, acc 0.9375
2020-02-08T03:34:02.941928: step 1642, loss 0.133669, acc 0.953125
2020-02-08T03:34:03.056883: step 1643, loss 0.131087, acc 0.953125
2020-02-08T03:34:03.175481: step 1644, loss 0.102309, acc 0.953125
2020-02-08T03:34:03.292835: step 1645, loss 0.107396, acc 0.96875
2020-02-08T03:34:03.410183: step 1646, loss 0.200423, acc 0.921875
2020-02-08T03:34:03.531544: step 1647, loss 0.0629037, acc 0.96875
2020-02-08T03:34:03.646075: step 1648, loss 0.155204, acc 0.9375
2020-02-08T03:34:03.768046: step 1649, loss 0.144683, acc 0.953125
2020-02-08T03:34:03.880923: step 1650, loss 0.162485, acc 0.933333
2020-02-08T03:34:03.998519: step 1651, loss 0.102321, acc 0.953125
2020-02-08T03:34:04.119110: step 1652, loss 0.115513, acc 0.96875
2020-02-08T03:34:04.237438: step 1653, loss 0.119699, acc 0.96875
2020-02-08T03:34:04.350596: step 1654, loss 0.14126, acc 0.953125
2020-02-08T03:34:04.464851: step 1655, loss 0.135856, acc 0.9375
2020-02-08T03:34:04.582480: step 1656, loss 0.169977, acc 0.921875
2020-02-08T03:34:04.701234: step 1657, loss 0.138594, acc 0.953125
2020-02-08T03:34:04.818017: step 1658, loss 0.0592137, acc 1
2020-02-08T03:34:04.935271: step 1659, loss 0.150351, acc 0.9375
2020-02-08T03:34:05.051773: step 1660, loss 0.070959, acc 0.984375
2020-02-08T03:34:05.169671: step 1661, loss 0.109945, acc 0.953125
2020-02-08T03:34:05.289510: step 1662, loss 0.089987, acc 0.984375
2020-02-08T03:34:05.406924: step 1663, loss 0.0820023, acc 0.96875
2020-02-08T03:34:05.523478: step 1664, loss 0.0938813, acc 0.953125
2020-02-08T03:34:05.642888: step 1665, loss 0.0993146, acc 0.96875
2020-02-08T03:34:05.758716: step 1666, loss 0.153845, acc 0.921875
2020-02-08T03:34:05.873117: step 1667, loss 0.0899226, acc 0.984375
2020-02-08T03:34:05.989115: step 1668, loss 0.0482086, acc 0.984375
2020-02-08T03:34:06.106108: step 1669, loss 0.107062, acc 0.953125
2020-02-08T03:34:06.226468: step 1670, loss 0.100037, acc 0.96875
2020-02-08T03:34:06.342669: step 1671, loss 0.104305, acc 0.96875
2020-02-08T03:34:06.461467: step 1672, loss 0.0379002, acc 0.984375
2020-02-08T03:34:06.580065: step 1673, loss 0.0695957, acc 0.984375
2020-02-08T03:34:06.699395: step 1674, loss 0.0851029, acc 0.96875
2020-02-08T03:34:06.816066: step 1675, loss 0.0893747, acc 0.96875
2020-02-08T03:34:06.933766: step 1676, loss 0.128236, acc 0.953125
2020-02-08T03:34:07.050942: step 1677, loss 0.146268, acc 0.9375
2020-02-08T03:34:07.164565: step 1678, loss 0.120673, acc 0.9375
2020-02-08T03:34:07.278521: step 1679, loss 0.0821588, acc 0.96875
2020-02-08T03:34:07.396765: step 1680, loss 0.175359, acc 0.875
2020-02-08T03:34:07.511760: step 1681, loss 0.0746759, acc 0.984375
2020-02-08T03:34:07.629457: step 1682, loss 0.161858, acc 0.921875
2020-02-08T03:34:07.747368: step 1683, loss 0.102167, acc 0.96875
2020-02-08T03:34:07.863179: step 1684, loss 0.0809508, acc 0.984375
2020-02-08T03:34:07.983102: step 1685, loss 0.202546, acc 0.90625
2020-02-08T03:34:08.099761: step 1686, loss 0.0735678, acc 0.984375
2020-02-08T03:34:08.218415: step 1687, loss 0.048657, acc 0.984375
2020-02-08T03:34:08.341069: step 1688, loss 0.0679457, acc 0.984375
2020-02-08T03:34:08.455592: step 1689, loss 0.136504, acc 0.9375
2020-02-08T03:34:08.573502: step 1690, loss 0.0714206, acc 0.984375
2020-02-08T03:34:08.688993: step 1691, loss 0.105682, acc 0.96875
2020-02-08T03:34:08.802965: step 1692, loss 0.0805658, acc 0.984375
2020-02-08T03:34:08.919988: step 1693, loss 0.0802978, acc 0.953125
2020-02-08T03:34:09.037576: step 1694, loss 0.102891, acc 0.9375
2020-02-08T03:34:09.152057: step 1695, loss 0.0735639, acc 0.984375
2020-02-08T03:34:09.270953: step 1696, loss 0.0678385, acc 1
2020-02-08T03:34:09.391327: step 1697, loss 0.0717839, acc 0.96875
2020-02-08T03:34:09.506845: step 1698, loss 0.0763395, acc 0.984375
2020-02-08T03:34:09.626058: step 1699, loss 0.0667485, acc 0.984375
2020-02-08T03:34:09.743790: step 1700, loss 0.123118, acc 0.96875

Evaluation:
2020-02-08T03:34:09.927448: step 1700, loss 0.669493, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1700

2020-02-08T03:34:11.481205: step 1701, loss 0.190475, acc 0.9375
2020-02-08T03:34:11.602527: step 1702, loss 0.109859, acc 0.953125
2020-02-08T03:34:11.720817: step 1703, loss 0.0731582, acc 0.96875
2020-02-08T03:34:11.841156: step 1704, loss 0.180991, acc 0.921875
2020-02-08T03:34:11.956522: step 1705, loss 0.122794, acc 0.953125
2020-02-08T03:34:12.074238: step 1706, loss 0.0459076, acc 1
2020-02-08T03:34:12.192229: step 1707, loss 0.10739, acc 0.96875
2020-02-08T03:34:12.308710: step 1708, loss 0.0632586, acc 0.96875
2020-02-08T03:34:12.424564: step 1709, loss 0.106546, acc 0.96875
2020-02-08T03:34:12.540012: step 1710, loss 0.122008, acc 0.9375
2020-02-08T03:34:12.654906: step 1711, loss 0.131219, acc 0.9375
2020-02-08T03:34:12.772460: step 1712, loss 0.113413, acc 0.96875
2020-02-08T03:34:12.891183: step 1713, loss 0.103974, acc 0.953125
2020-02-08T03:34:13.005655: step 1714, loss 0.206425, acc 0.9375
2020-02-08T03:34:13.130118: step 1715, loss 0.0809917, acc 0.984375
2020-02-08T03:34:13.246707: step 1716, loss 0.152976, acc 0.890625
2020-02-08T03:34:13.361438: step 1717, loss 0.210152, acc 0.953125
2020-02-08T03:34:13.479647: step 1718, loss 0.140933, acc 0.921875
2020-02-08T03:34:13.596139: step 1719, loss 0.064231, acc 1
2020-02-08T03:34:13.710569: step 1720, loss 0.0384569, acc 1
2020-02-08T03:34:13.829515: step 1721, loss 0.0815195, acc 0.96875
2020-02-08T03:34:13.944536: step 1722, loss 0.129014, acc 0.9375
2020-02-08T03:34:14.062150: step 1723, loss 0.0584381, acc 0.984375
2020-02-08T03:34:14.179995: step 1724, loss 0.0698808, acc 0.96875
2020-02-08T03:34:14.295895: step 1725, loss 0.123137, acc 0.953125
2020-02-08T03:34:14.416599: step 1726, loss 0.0800856, acc 0.96875
2020-02-08T03:34:14.536748: step 1727, loss 0.0460924, acc 1
2020-02-08T03:34:14.655381: step 1728, loss 0.0704482, acc 0.96875
2020-02-08T03:34:14.772669: step 1729, loss 0.0838672, acc 0.984375
2020-02-08T03:34:14.888878: step 1730, loss 0.114924, acc 0.96875
2020-02-08T03:34:15.002658: step 1731, loss 0.100281, acc 0.96875
2020-02-08T03:34:15.121238: step 1732, loss 0.0940359, acc 0.96875
2020-02-08T03:34:15.238651: step 1733, loss 0.129551, acc 0.9375
2020-02-08T03:34:15.352566: step 1734, loss 0.108331, acc 0.953125
2020-02-08T03:34:15.469514: step 1735, loss 0.0930781, acc 0.953125
2020-02-08T03:34:15.587385: step 1736, loss 0.0830698, acc 0.953125
2020-02-08T03:34:15.704596: step 1737, loss 0.152955, acc 0.921875
2020-02-08T03:34:15.819511: step 1738, loss 0.11769, acc 0.96875
2020-02-08T03:34:15.940184: step 1739, loss 0.120285, acc 0.953125
2020-02-08T03:34:16.053960: step 1740, loss 0.0945113, acc 0.9375
2020-02-08T03:34:16.169529: step 1741, loss 0.202407, acc 0.953125
2020-02-08T03:34:16.286495: step 1742, loss 0.0924271, acc 0.953125
2020-02-08T03:34:16.399369: step 1743, loss 0.105239, acc 0.9375
2020-02-08T03:34:16.518683: step 1744, loss 0.0679268, acc 0.984375
2020-02-08T03:34:16.637488: step 1745, loss 0.0826197, acc 0.96875
2020-02-08T03:34:16.755626: step 1746, loss 0.156502, acc 0.9375
2020-02-08T03:34:16.874279: step 1747, loss 0.0714446, acc 0.984375
2020-02-08T03:34:16.990728: step 1748, loss 0.0680528, acc 0.984375
2020-02-08T03:34:17.107230: step 1749, loss 0.0951976, acc 0.96875
2020-02-08T03:34:17.225363: step 1750, loss 0.111356, acc 0.953125
2020-02-08T03:34:17.341043: step 1751, loss 0.133561, acc 0.9375
2020-02-08T03:34:17.459098: step 1752, loss 0.122495, acc 0.96875
2020-02-08T03:34:17.576201: step 1753, loss 0.0749857, acc 0.96875
2020-02-08T03:34:17.694348: step 1754, loss 0.0585914, acc 0.984375
2020-02-08T03:34:17.811765: step 1755, loss 0.0907713, acc 0.984375
2020-02-08T03:34:17.931771: step 1756, loss 0.120409, acc 0.96875
2020-02-08T03:34:18.049747: step 1757, loss 0.102592, acc 0.953125
2020-02-08T03:34:18.169032: step 1758, loss 0.0604265, acc 0.96875
2020-02-08T03:34:18.288145: step 1759, loss 0.13363, acc 0.953125
2020-02-08T03:34:18.403805: step 1760, loss 0.0783445, acc 0.984375
2020-02-08T03:34:18.522297: step 1761, loss 0.04695, acc 1
2020-02-08T03:34:18.637591: step 1762, loss 0.134647, acc 0.96875
2020-02-08T03:34:18.754225: step 1763, loss 0.0639532, acc 1
2020-02-08T03:34:18.869918: step 1764, loss 0.0577419, acc 1
2020-02-08T03:34:18.989360: step 1765, loss 0.170269, acc 0.90625
2020-02-08T03:34:19.103582: step 1766, loss 0.10655, acc 0.9375
2020-02-08T03:34:19.220964: step 1767, loss 0.0804414, acc 0.96875
2020-02-08T03:34:19.337166: step 1768, loss 0.0586362, acc 1
2020-02-08T03:34:19.451148: step 1769, loss 0.0818866, acc 0.953125
2020-02-08T03:34:19.569765: step 1770, loss 0.125881, acc 0.953125
2020-02-08T03:34:19.687302: step 1771, loss 0.19456, acc 0.9375
2020-02-08T03:34:19.805138: step 1772, loss 0.053565, acc 0.984375
2020-02-08T03:34:19.923763: step 1773, loss 0.132974, acc 0.9375
2020-02-08T03:34:20.041459: step 1774, loss 0.155168, acc 0.90625
2020-02-08T03:34:20.157953: step 1775, loss 0.168417, acc 0.9375
2020-02-08T03:34:20.274854: step 1776, loss 0.0750453, acc 0.984375
2020-02-08T03:34:20.394092: step 1777, loss 0.131115, acc 0.953125
2020-02-08T03:34:20.512689: step 1778, loss 0.0918382, acc 0.984375
2020-02-08T03:34:20.627564: step 1779, loss 0.0639038, acc 0.984375
2020-02-08T03:34:20.746284: step 1780, loss 0.136571, acc 0.921875
2020-02-08T03:34:20.863775: step 1781, loss 0.114864, acc 0.953125
2020-02-08T03:34:20.982307: step 1782, loss 0.13353, acc 0.9375
2020-02-08T03:34:21.101135: step 1783, loss 0.203777, acc 0.90625
2020-02-08T03:34:21.219364: step 1784, loss 0.0847211, acc 0.953125
2020-02-08T03:34:21.337648: step 1785, loss 0.081125, acc 0.96875
2020-02-08T03:34:21.454489: step 1786, loss 0.0803043, acc 0.953125
2020-02-08T03:34:21.568546: step 1787, loss 0.145346, acc 0.96875
2020-02-08T03:34:21.788685: step 1788, loss 0.0809914, acc 0.953125
2020-02-08T03:34:21.911726: step 1789, loss 0.164663, acc 0.9375
2020-02-08T03:34:22.027405: step 1790, loss 0.0765996, acc 0.953125
2020-02-08T03:34:22.143627: step 1791, loss 0.0467587, acc 0.984375
2020-02-08T03:34:22.259292: step 1792, loss 0.0713183, acc 0.96875
2020-02-08T03:34:22.377487: step 1793, loss 0.156062, acc 0.890625
2020-02-08T03:34:22.494880: step 1794, loss 0.111554, acc 0.96875
2020-02-08T03:34:22.609855: step 1795, loss 0.0609762, acc 1
2020-02-08T03:34:22.728037: step 1796, loss 0.0847239, acc 0.953125
2020-02-08T03:34:22.848301: step 1797, loss 0.0564514, acc 0.984375
2020-02-08T03:34:22.963284: step 1798, loss 0.0667417, acc 0.984375
2020-02-08T03:34:23.079441: step 1799, loss 0.0933471, acc 0.953125
2020-02-08T03:34:23.193014: step 1800, loss 0.0686372, acc 0.966667

Evaluation:
2020-02-08T03:34:23.385050: step 1800, loss 0.702295, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1800

2020-02-08T03:34:25.199056: step 1801, loss 0.110109, acc 0.953125
2020-02-08T03:34:25.315508: step 1802, loss 0.0903078, acc 0.984375
2020-02-08T03:34:25.434449: step 1803, loss 0.0478493, acc 0.984375
2020-02-08T03:34:25.549601: step 1804, loss 0.0566535, acc 0.984375
2020-02-08T03:34:25.666233: step 1805, loss 0.0604325, acc 0.96875
2020-02-08T03:34:25.782307: step 1806, loss 0.0717471, acc 0.984375
2020-02-08T03:34:25.899671: step 1807, loss 0.0960043, acc 0.96875
2020-02-08T03:34:26.018084: step 1808, loss 0.174165, acc 0.9375
2020-02-08T03:34:26.138896: step 1809, loss 0.0729282, acc 0.96875
2020-02-08T03:34:26.258996: step 1810, loss 0.088016, acc 0.9375
2020-02-08T03:34:26.378980: step 1811, loss 0.0613701, acc 0.984375
2020-02-08T03:34:26.496632: step 1812, loss 0.146201, acc 0.953125
2020-02-08T03:34:26.615643: step 1813, loss 0.0630431, acc 0.984375
2020-02-08T03:34:26.733893: step 1814, loss 0.0359662, acc 1
2020-02-08T03:34:26.848582: step 1815, loss 0.0471581, acc 0.984375
2020-02-08T03:34:26.967129: step 1816, loss 0.0635844, acc 0.984375
2020-02-08T03:34:27.084060: step 1817, loss 0.0865575, acc 0.953125
2020-02-08T03:34:27.199531: step 1818, loss 0.0537137, acc 0.984375
2020-02-08T03:34:27.315645: step 1819, loss 0.0905606, acc 0.96875
2020-02-08T03:34:27.432461: step 1820, loss 0.057609, acc 0.984375
2020-02-08T03:34:27.549438: step 1821, loss 0.047557, acc 1
2020-02-08T03:34:27.667167: step 1822, loss 0.0496953, acc 0.984375
2020-02-08T03:34:27.785123: step 1823, loss 0.0412116, acc 1
2020-02-08T03:34:27.905588: step 1824, loss 0.150751, acc 0.9375
2020-02-08T03:34:28.024926: step 1825, loss 0.062656, acc 0.96875
2020-02-08T03:34:28.140110: step 1826, loss 0.0919276, acc 0.984375
2020-02-08T03:34:28.258157: step 1827, loss 0.040914, acc 0.984375
2020-02-08T03:34:28.374921: step 1828, loss 0.074717, acc 0.96875
2020-02-08T03:34:28.496483: step 1829, loss 0.0604568, acc 1
2020-02-08T03:34:28.616305: step 1830, loss 0.0458012, acc 0.984375
2020-02-08T03:34:28.731614: step 1831, loss 0.0665365, acc 0.984375
2020-02-08T03:34:28.848648: step 1832, loss 0.0748828, acc 0.953125
2020-02-08T03:34:28.965416: step 1833, loss 0.0453579, acc 0.984375
2020-02-08T03:34:29.082315: step 1834, loss 0.0706554, acc 0.96875
2020-02-08T03:34:29.199680: step 1835, loss 0.116498, acc 0.96875
2020-02-08T03:34:29.315625: step 1836, loss 0.0658761, acc 0.96875
2020-02-08T03:34:29.435725: step 1837, loss 0.109887, acc 0.96875
2020-02-08T03:34:29.553971: step 1838, loss 0.083575, acc 0.96875
2020-02-08T03:34:29.672043: step 1839, loss 0.0559918, acc 0.984375
2020-02-08T03:34:29.791682: step 1840, loss 0.0337976, acc 1
2020-02-08T03:34:29.911243: step 1841, loss 0.0984336, acc 0.96875
2020-02-08T03:34:30.028818: step 1842, loss 0.10648, acc 0.96875
2020-02-08T03:34:30.148992: step 1843, loss 0.0892127, acc 0.984375
2020-02-08T03:34:30.266369: step 1844, loss 0.101511, acc 0.953125
2020-02-08T03:34:30.385249: step 1845, loss 0.0358146, acc 0.984375
2020-02-08T03:34:30.501294: step 1846, loss 0.118214, acc 0.953125
2020-02-08T03:34:30.621636: step 1847, loss 0.058176, acc 0.96875
2020-02-08T03:34:30.740295: step 1848, loss 0.149822, acc 0.953125
2020-02-08T03:34:30.854363: step 1849, loss 0.116682, acc 0.953125
2020-02-08T03:34:30.976036: step 1850, loss 0.038641, acc 0.984375
2020-02-08T03:34:31.101840: step 1851, loss 0.0918156, acc 0.96875
2020-02-08T03:34:31.217644: step 1852, loss 0.0397037, acc 0.96875
2020-02-08T03:34:31.380677: step 1853, loss 0.0803646, acc 0.984375
2020-02-08T03:34:31.551234: step 1854, loss 0.0454749, acc 1
2020-02-08T03:34:31.686825: step 1855, loss 0.11984, acc 0.9375
2020-02-08T03:34:31.808500: step 1856, loss 0.17067, acc 0.921875
2020-02-08T03:34:31.960300: step 1857, loss 0.124264, acc 0.953125
2020-02-08T03:34:32.103465: step 1858, loss 0.0778534, acc 0.96875
2020-02-08T03:34:32.238598: step 1859, loss 0.0656748, acc 0.984375
2020-02-08T03:34:32.376273: step 1860, loss 0.0674385, acc 1
2020-02-08T03:34:32.512859: step 1861, loss 0.0899574, acc 0.953125
2020-02-08T03:34:32.645288: step 1862, loss 0.0344136, acc 1
2020-02-08T03:34:32.779071: step 1863, loss 0.099691, acc 0.984375
2020-02-08T03:34:32.906854: step 1864, loss 0.120143, acc 0.9375
2020-02-08T03:34:33.038119: step 1865, loss 0.0508217, acc 1
2020-02-08T03:34:33.171687: step 1866, loss 0.142042, acc 0.890625
2020-02-08T03:34:33.305772: step 1867, loss 0.0935543, acc 0.953125
2020-02-08T03:34:33.439509: step 1868, loss 0.0586108, acc 0.953125
2020-02-08T03:34:33.578318: step 1869, loss 0.065515, acc 0.96875
2020-02-08T03:34:33.709021: step 1870, loss 0.0331201, acc 1
2020-02-08T03:34:33.845629: step 1871, loss 0.10993, acc 0.9375
2020-02-08T03:34:33.977033: step 1872, loss 0.165015, acc 0.96875
2020-02-08T03:34:34.109819: step 1873, loss 0.0922587, acc 0.953125
2020-02-08T03:34:34.239824: step 1874, loss 0.117922, acc 0.9375
2020-02-08T03:34:34.382026: step 1875, loss 0.170447, acc 0.90625
2020-02-08T03:34:34.532480: step 1876, loss 0.125641, acc 0.9375
2020-02-08T03:34:34.684183: step 1877, loss 0.0566988, acc 0.984375
2020-02-08T03:34:34.826840: step 1878, loss 0.0929817, acc 0.984375
2020-02-08T03:34:34.971057: step 1879, loss 0.149741, acc 0.90625
2020-02-08T03:34:35.111402: step 1880, loss 0.0577628, acc 0.984375
2020-02-08T03:34:35.237455: step 1881, loss 0.124072, acc 0.96875
2020-02-08T03:34:35.377089: step 1882, loss 0.15178, acc 0.96875
2020-02-08T03:34:35.519731: step 1883, loss 0.0812784, acc 0.984375
2020-02-08T03:34:35.658297: step 1884, loss 0.0660456, acc 0.96875
2020-02-08T03:34:35.798507: step 1885, loss 0.0443363, acc 0.984375
2020-02-08T03:34:35.935717: step 1886, loss 0.106296, acc 0.9375
2020-02-08T03:34:36.074264: step 1887, loss 0.0432224, acc 0.984375
2020-02-08T03:34:36.213758: step 1888, loss 0.0262821, acc 1
2020-02-08T03:34:36.353425: step 1889, loss 0.0496429, acc 1
2020-02-08T03:34:36.486338: step 1890, loss 0.0794852, acc 0.984375
2020-02-08T03:34:36.630952: step 1891, loss 0.0822342, acc 0.96875
2020-02-08T03:34:36.774133: step 1892, loss 0.109002, acc 0.953125
2020-02-08T03:34:36.916702: step 1893, loss 0.0409894, acc 0.984375
2020-02-08T03:34:37.057897: step 1894, loss 0.107635, acc 0.953125
2020-02-08T03:34:37.200093: step 1895, loss 0.0977436, acc 0.96875
2020-02-08T03:34:37.339653: step 1896, loss 0.0593365, acc 0.984375
2020-02-08T03:34:37.480465: step 1897, loss 0.077572, acc 0.984375
2020-02-08T03:34:37.627569: step 1898, loss 0.0494258, acc 0.96875
2020-02-08T03:34:37.762383: step 1899, loss 0.119476, acc 0.953125
2020-02-08T03:34:37.895728: step 1900, loss 0.102083, acc 0.96875

Evaluation:
2020-02-08T03:34:38.100196: step 1900, loss 0.73504, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-1900

2020-02-08T03:34:39.722717: step 1901, loss 0.109573, acc 0.953125
2020-02-08T03:34:39.862334: step 1902, loss 0.0724545, acc 0.984375
2020-02-08T03:34:40.001179: step 1903, loss 0.0588536, acc 0.984375
2020-02-08T03:34:40.144663: step 1904, loss 0.0923821, acc 0.96875
2020-02-08T03:34:40.281101: step 1905, loss 0.121572, acc 0.9375
2020-02-08T03:34:40.411543: step 1906, loss 0.0842741, acc 0.953125
2020-02-08T03:34:40.549263: step 1907, loss 0.110691, acc 0.953125
2020-02-08T03:34:40.678737: step 1908, loss 0.0511476, acc 0.984375
2020-02-08T03:34:40.809989: step 1909, loss 0.0503819, acc 0.984375
2020-02-08T03:34:40.940315: step 1910, loss 0.101809, acc 0.953125
2020-02-08T03:34:41.070770: step 1911, loss 0.035602, acc 1
2020-02-08T03:34:41.212452: step 1912, loss 0.0827789, acc 0.96875
2020-02-08T03:34:41.350225: step 1913, loss 0.0360758, acc 1
2020-02-08T03:34:41.493175: step 1914, loss 0.0612694, acc 0.984375
2020-02-08T03:34:41.617687: step 1915, loss 0.0567478, acc 0.96875
2020-02-08T03:34:41.738300: step 1916, loss 0.0403034, acc 0.984375
2020-02-08T03:34:41.875269: step 1917, loss 0.181926, acc 0.953125
2020-02-08T03:34:41.997052: step 1918, loss 0.0843528, acc 0.9375
2020-02-08T03:34:42.119925: step 1919, loss 0.0942671, acc 0.96875
2020-02-08T03:34:42.241707: step 1920, loss 0.137166, acc 0.96875
2020-02-08T03:34:42.363642: step 1921, loss 0.0704708, acc 0.953125
2020-02-08T03:34:42.482053: step 1922, loss 0.060602, acc 0.96875
2020-02-08T03:34:42.604901: step 1923, loss 0.0457111, acc 0.984375
2020-02-08T03:34:42.723375: step 1924, loss 0.101935, acc 0.96875
2020-02-08T03:34:42.843648: step 1925, loss 0.0985057, acc 0.953125
2020-02-08T03:34:42.963252: step 1926, loss 0.0883068, acc 0.96875
2020-02-08T03:34:43.083124: step 1927, loss 0.0818568, acc 0.984375
2020-02-08T03:34:43.202861: step 1928, loss 0.129709, acc 0.96875
2020-02-08T03:34:43.317636: step 1929, loss 0.0520765, acc 0.984375
2020-02-08T03:34:43.437542: step 1930, loss 0.111725, acc 0.953125
2020-02-08T03:34:43.553001: step 1931, loss 0.058451, acc 0.984375
2020-02-08T03:34:43.669299: step 1932, loss 0.0274221, acc 1
2020-02-08T03:34:43.789629: step 1933, loss 0.115639, acc 0.953125
2020-02-08T03:34:43.904426: step 1934, loss 0.0538454, acc 0.96875
2020-02-08T03:34:44.024360: step 1935, loss 0.129214, acc 0.953125
2020-02-08T03:34:44.141278: step 1936, loss 0.0648186, acc 0.984375
2020-02-08T03:34:44.257084: step 1937, loss 0.121302, acc 0.953125
2020-02-08T03:34:44.376147: step 1938, loss 0.046114, acc 0.984375
2020-02-08T03:34:44.494285: step 1939, loss 0.0393335, acc 0.984375
2020-02-08T03:34:44.611001: step 1940, loss 0.0774752, acc 0.953125
2020-02-08T03:34:44.728701: step 1941, loss 0.174661, acc 0.90625
2020-02-08T03:34:44.846276: step 1942, loss 0.0532937, acc 0.96875
2020-02-08T03:34:44.961753: step 1943, loss 0.11459, acc 0.9375
2020-02-08T03:34:45.079314: step 1944, loss 0.0546623, acc 0.984375
2020-02-08T03:34:45.196414: step 1945, loss 0.0855183, acc 0.96875
2020-02-08T03:34:45.311546: step 1946, loss 0.083836, acc 0.984375
2020-02-08T03:34:45.429791: step 1947, loss 0.0538296, acc 1
2020-02-08T03:34:45.546016: step 1948, loss 0.0400263, acc 1
2020-02-08T03:34:45.667050: step 1949, loss 0.0513966, acc 0.984375
2020-02-08T03:34:45.782558: step 1950, loss 0.0728186, acc 0.983333
2020-02-08T03:34:45.901282: step 1951, loss 0.0334022, acc 1
2020-02-08T03:34:46.018975: step 1952, loss 0.0230665, acc 1
2020-02-08T03:34:46.140772: step 1953, loss 0.0521778, acc 0.984375
2020-02-08T03:34:46.256608: step 1954, loss 0.0472376, acc 0.984375
2020-02-08T03:34:46.377504: step 1955, loss 0.0321356, acc 1
2020-02-08T03:34:46.494814: step 1956, loss 0.0261024, acc 1
2020-02-08T03:34:46.608776: step 1957, loss 0.0431562, acc 0.984375
2020-02-08T03:34:46.723656: step 1958, loss 0.0442366, acc 0.984375
2020-02-08T03:34:46.839906: step 1959, loss 0.0260234, acc 1
2020-02-08T03:34:46.956217: step 1960, loss 0.0420115, acc 0.984375
2020-02-08T03:34:47.072652: step 1961, loss 0.0759353, acc 0.953125
2020-02-08T03:34:47.192056: step 1962, loss 0.0616101, acc 0.96875
2020-02-08T03:34:47.307431: step 1963, loss 0.0491668, acc 0.96875
2020-02-08T03:34:47.431883: step 1964, loss 0.0316167, acc 1
2020-02-08T03:34:47.546119: step 1965, loss 0.0852005, acc 0.96875
2020-02-08T03:34:47.665909: step 1966, loss 0.0232888, acc 1
2020-02-08T03:34:47.785177: step 1967, loss 0.10736, acc 0.953125
2020-02-08T03:34:47.899901: step 1968, loss 0.0576849, acc 0.984375
2020-02-08T03:34:48.017319: step 1969, loss 0.0604741, acc 0.984375
2020-02-08T03:34:48.132200: step 1970, loss 0.0686951, acc 0.96875
2020-02-08T03:34:48.247318: step 1971, loss 0.0822933, acc 0.96875
2020-02-08T03:34:48.365755: step 1972, loss 0.108365, acc 0.9375
2020-02-08T03:34:48.484903: step 1973, loss 0.0565192, acc 0.984375
2020-02-08T03:34:48.601118: step 1974, loss 0.0261421, acc 1
2020-02-08T03:34:48.715810: step 1975, loss 0.0275123, acc 1
2020-02-08T03:34:48.834412: step 1976, loss 0.0104263, acc 1
2020-02-08T03:34:48.952637: step 1977, loss 0.0561985, acc 0.984375
2020-02-08T03:34:49.070946: step 1978, loss 0.0875337, acc 0.953125
2020-02-08T03:34:49.186910: step 1979, loss 0.0478582, acc 1
2020-02-08T03:34:49.304894: step 1980, loss 0.103585, acc 0.96875
2020-02-08T03:34:49.424023: step 1981, loss 0.0607119, acc 0.96875
2020-02-08T03:34:49.543318: step 1982, loss 0.0691857, acc 0.96875
2020-02-08T03:34:49.660249: step 1983, loss 0.02636, acc 1
2020-02-08T03:34:49.776836: step 1984, loss 0.0765165, acc 0.96875
2020-02-08T03:34:49.895109: step 1985, loss 0.042165, acc 0.984375
2020-02-08T03:34:50.011335: step 1986, loss 0.067551, acc 0.984375
2020-02-08T03:34:50.131889: step 1987, loss 0.0774606, acc 0.96875
2020-02-08T03:34:50.249122: step 1988, loss 0.0396792, acc 0.984375
2020-02-08T03:34:50.364942: step 1989, loss 0.0369209, acc 1
2020-02-08T03:34:50.483757: step 1990, loss 0.135321, acc 0.96875
2020-02-08T03:34:50.601755: step 1991, loss 0.0417467, acc 0.96875
2020-02-08T03:34:50.718291: step 1992, loss 0.0627537, acc 0.96875
2020-02-08T03:34:50.837704: step 1993, loss 0.0392042, acc 1
2020-02-08T03:34:50.954731: step 1994, loss 0.0200369, acc 1
2020-02-08T03:34:51.073773: step 1995, loss 0.0428825, acc 0.984375
2020-02-08T03:34:51.189686: step 1996, loss 0.054091, acc 0.96875
2020-02-08T03:34:51.303942: step 1997, loss 0.07456, acc 0.96875
2020-02-08T03:34:51.619112: step 1998, loss 0.11216, acc 0.953125
2020-02-08T03:34:51.744100: step 1999, loss 0.0329775, acc 1
2020-02-08T03:34:51.859511: step 2000, loss 0.0676718, acc 0.96875

Evaluation:
2020-02-08T03:34:52.046707: step 2000, loss 0.765626, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2000

2020-02-08T03:34:53.570783: step 2001, loss 0.0276493, acc 1
2020-02-08T03:34:53.687344: step 2002, loss 0.061532, acc 0.96875
2020-02-08T03:34:53.803187: step 2003, loss 0.0474381, acc 0.984375
2020-02-08T03:34:53.925323: step 2004, loss 0.0981813, acc 0.984375
2020-02-08T03:34:54.041942: step 2005, loss 0.0573866, acc 0.984375
2020-02-08T03:34:54.156699: step 2006, loss 0.0658604, acc 0.984375
2020-02-08T03:34:54.273890: step 2007, loss 0.0431891, acc 1
2020-02-08T03:34:54.392304: step 2008, loss 0.0870486, acc 0.984375
2020-02-08T03:34:54.505962: step 2009, loss 0.075289, acc 0.953125
2020-02-08T03:34:54.622376: step 2010, loss 0.0693807, acc 0.96875
2020-02-08T03:34:54.742469: step 2011, loss 0.0137351, acc 1
2020-02-08T03:34:54.859593: step 2012, loss 0.0673023, acc 0.96875
2020-02-08T03:34:54.975266: step 2013, loss 0.148757, acc 0.921875
2020-02-08T03:34:55.092835: step 2014, loss 0.0465396, acc 0.984375
2020-02-08T03:34:55.209641: step 2015, loss 0.044226, acc 0.984375
2020-02-08T03:34:55.329648: step 2016, loss 0.0350914, acc 1
2020-02-08T03:34:55.447408: step 2017, loss 0.0427768, acc 0.984375
2020-02-08T03:34:55.567790: step 2018, loss 0.0866717, acc 0.96875
2020-02-08T03:34:55.685520: step 2019, loss 0.0648661, acc 0.96875
2020-02-08T03:34:55.802531: step 2020, loss 0.0965606, acc 0.96875
2020-02-08T03:34:55.919111: step 2021, loss 0.0420625, acc 0.984375
2020-02-08T03:34:56.037768: step 2022, loss 0.0408035, acc 1
2020-02-08T03:34:56.152116: step 2023, loss 0.0630862, acc 0.96875
2020-02-08T03:34:56.270116: step 2024, loss 0.0622354, acc 0.96875
2020-02-08T03:34:56.388182: step 2025, loss 0.053082, acc 0.96875
2020-02-08T03:34:56.505540: step 2026, loss 0.0993181, acc 0.96875
2020-02-08T03:34:56.625585: step 2027, loss 0.0969233, acc 0.984375
2020-02-08T03:34:56.742113: step 2028, loss 0.0697755, acc 0.984375
2020-02-08T03:34:56.856180: step 2029, loss 0.0387023, acc 1
2020-02-08T03:34:56.976944: step 2030, loss 0.0620321, acc 0.953125
2020-02-08T03:34:57.098350: step 2031, loss 0.0389863, acc 1
2020-02-08T03:34:57.221025: step 2032, loss 0.0437676, acc 1
2020-02-08T03:34:57.340776: step 2033, loss 0.0331306, acc 0.984375
2020-02-08T03:34:57.456103: step 2034, loss 0.0838911, acc 0.96875
2020-02-08T03:34:57.575552: step 2035, loss 0.17543, acc 0.953125
2020-02-08T03:34:57.693024: step 2036, loss 0.0551572, acc 0.984375
2020-02-08T03:34:57.813852: step 2037, loss 0.0932037, acc 0.96875
2020-02-08T03:34:57.932491: step 2038, loss 0.0686655, acc 0.984375
2020-02-08T03:34:58.048736: step 2039, loss 0.066209, acc 0.96875
2020-02-08T03:34:58.166090: step 2040, loss 0.0838175, acc 0.984375
2020-02-08T03:34:58.283741: step 2041, loss 0.0843423, acc 0.953125
2020-02-08T03:34:58.397764: step 2042, loss 0.0919528, acc 0.953125
2020-02-08T03:34:58.516937: step 2043, loss 0.0621624, acc 0.96875
2020-02-08T03:34:58.633722: step 2044, loss 0.0599654, acc 0.96875
2020-02-08T03:34:58.750020: step 2045, loss 0.0418382, acc 1
2020-02-08T03:34:58.866995: step 2046, loss 0.0944107, acc 0.96875
2020-02-08T03:34:58.989768: step 2047, loss 0.0593853, acc 0.984375
2020-02-08T03:34:59.121607: step 2048, loss 0.0905406, acc 0.984375
2020-02-08T03:34:59.260092: step 2049, loss 0.0586575, acc 0.96875
2020-02-08T03:34:59.396751: step 2050, loss 0.0351404, acc 1
2020-02-08T03:34:59.540927: step 2051, loss 0.0449185, acc 0.984375
2020-02-08T03:34:59.681779: step 2052, loss 0.0924134, acc 0.96875
2020-02-08T03:34:59.846468: step 2053, loss 0.110011, acc 0.96875
2020-02-08T03:35:00.002762: step 2054, loss 0.0173312, acc 1
2020-02-08T03:35:00.117883: step 2055, loss 0.0622623, acc 0.984375
2020-02-08T03:35:00.238954: step 2056, loss 0.0892443, acc 0.96875
2020-02-08T03:35:00.356043: step 2057, loss 0.0279306, acc 1
2020-02-08T03:35:00.478531: step 2058, loss 0.0679404, acc 0.984375
2020-02-08T03:35:00.598366: step 2059, loss 0.115067, acc 0.953125
2020-02-08T03:35:00.715663: step 2060, loss 0.0524705, acc 0.96875
2020-02-08T03:35:00.836947: step 2061, loss 0.0812548, acc 0.953125
2020-02-08T03:35:00.954556: step 2062, loss 0.0737306, acc 0.96875
2020-02-08T03:35:01.073062: step 2063, loss 0.0519457, acc 0.96875
2020-02-08T03:35:01.193186: step 2064, loss 0.0389894, acc 1
2020-02-08T03:35:01.307923: step 2065, loss 0.0970926, acc 0.96875
2020-02-08T03:35:01.425927: step 2066, loss 0.136791, acc 0.9375
2020-02-08T03:35:01.541257: step 2067, loss 0.113941, acc 0.953125
2020-02-08T03:35:01.655991: step 2068, loss 0.0468812, acc 0.984375
2020-02-08T03:35:01.773408: step 2069, loss 0.0897485, acc 0.984375
2020-02-08T03:35:01.895264: step 2070, loss 0.0726802, acc 0.96875
2020-02-08T03:35:02.013433: step 2071, loss 0.118358, acc 0.953125
2020-02-08T03:35:02.133010: step 2072, loss 0.167624, acc 0.953125
2020-02-08T03:35:02.249830: step 2073, loss 0.0572587, acc 0.984375
2020-02-08T03:35:02.369006: step 2074, loss 0.0430056, acc 0.984375
2020-02-08T03:35:02.486294: step 2075, loss 0.0872275, acc 0.96875
2020-02-08T03:35:02.604377: step 2076, loss 0.0307197, acc 0.984375
2020-02-08T03:35:02.721616: step 2077, loss 0.0107471, acc 1
2020-02-08T03:35:02.838801: step 2078, loss 0.0839339, acc 0.953125
2020-02-08T03:35:02.953941: step 2079, loss 0.0815944, acc 0.96875
2020-02-08T03:35:03.074831: step 2080, loss 0.0610638, acc 0.96875
2020-02-08T03:35:03.189042: step 2081, loss 0.100379, acc 0.9375
2020-02-08T03:35:03.305779: step 2082, loss 0.0723602, acc 0.984375
2020-02-08T03:35:03.422734: step 2083, loss 0.055993, acc 0.96875
2020-02-08T03:35:03.540699: step 2084, loss 0.0456899, acc 0.984375
2020-02-08T03:35:03.657223: step 2085, loss 0.0301679, acc 0.984375
2020-02-08T03:35:03.777046: step 2086, loss 0.0663778, acc 0.96875
2020-02-08T03:35:03.893571: step 2087, loss 0.0367509, acc 1
2020-02-08T03:35:04.016193: step 2088, loss 0.0763933, acc 0.953125
2020-02-08T03:35:04.132922: step 2089, loss 0.0800181, acc 0.984375
2020-02-08T03:35:04.251659: step 2090, loss 0.0368182, acc 1
2020-02-08T03:35:04.366203: step 2091, loss 0.0622944, acc 0.96875
2020-02-08T03:35:04.485742: step 2092, loss 0.0408309, acc 1
2020-02-08T03:35:04.602377: step 2093, loss 0.0538639, acc 0.984375
2020-02-08T03:35:04.719747: step 2094, loss 0.0681257, acc 0.984375
2020-02-08T03:35:04.838265: step 2095, loss 0.162253, acc 0.90625
2020-02-08T03:35:04.955392: step 2096, loss 0.125357, acc 0.953125
2020-02-08T03:35:05.073582: step 2097, loss 0.0462967, acc 0.984375
2020-02-08T03:35:05.194331: step 2098, loss 0.0864857, acc 0.96875
2020-02-08T03:35:05.309906: step 2099, loss 0.151416, acc 0.9375
2020-02-08T03:35:05.426196: step 2100, loss 0.0417938, acc 0.983333

Evaluation:
2020-02-08T03:35:05.614043: step 2100, loss 0.798468, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2100

2020-02-08T03:35:07.116356: step 2101, loss 0.0493401, acc 0.984375
2020-02-08T03:35:07.237327: step 2102, loss 0.0457781, acc 0.984375
2020-02-08T03:35:07.353131: step 2103, loss 0.06729, acc 0.984375
2020-02-08T03:35:07.471475: step 2104, loss 0.0239971, acc 1
2020-02-08T03:35:07.591169: step 2105, loss 0.0331149, acc 0.984375
2020-02-08T03:35:07.711187: step 2106, loss 0.0353942, acc 1
2020-02-08T03:35:07.829957: step 2107, loss 0.0546798, acc 1
2020-02-08T03:35:07.948551: step 2108, loss 0.0761511, acc 0.96875
2020-02-08T03:35:08.066998: step 2109, loss 0.0341467, acc 0.984375
2020-02-08T03:35:08.185801: step 2110, loss 0.0353403, acc 0.984375
2020-02-08T03:35:08.302023: step 2111, loss 0.0819244, acc 0.96875
2020-02-08T03:35:08.417563: step 2112, loss 0.058574, acc 0.96875
2020-02-08T03:35:08.534618: step 2113, loss 0.0350068, acc 1
2020-02-08T03:35:08.651061: step 2114, loss 0.024936, acc 1
2020-02-08T03:35:08.765077: step 2115, loss 0.0511201, acc 0.984375
2020-02-08T03:35:08.883451: step 2116, loss 0.0311337, acc 1
2020-02-08T03:35:08.998712: step 2117, loss 0.013853, acc 1
2020-02-08T03:35:09.116025: step 2118, loss 0.0259284, acc 1
2020-02-08T03:35:09.231204: step 2119, loss 0.0302816, acc 1
2020-02-08T03:35:09.347025: step 2120, loss 0.0779938, acc 0.96875
2020-02-08T03:35:09.462265: step 2121, loss 0.0320492, acc 1
2020-02-08T03:35:09.577372: step 2122, loss 0.0560958, acc 0.984375
2020-02-08T03:35:09.694387: step 2123, loss 0.0381046, acc 0.984375
2020-02-08T03:35:09.810077: step 2124, loss 0.0391111, acc 0.984375
2020-02-08T03:35:09.928007: step 2125, loss 0.0271517, acc 1
2020-02-08T03:35:10.044266: step 2126, loss 0.0121837, acc 1
2020-02-08T03:35:10.160847: step 2127, loss 0.0657904, acc 0.984375
2020-02-08T03:35:10.276921: step 2128, loss 0.00968393, acc 1
2020-02-08T03:35:10.392534: step 2129, loss 0.0598706, acc 0.96875
2020-02-08T03:35:10.511003: step 2130, loss 0.0362003, acc 1
2020-02-08T03:35:10.628463: step 2131, loss 0.0283045, acc 1
2020-02-08T03:35:10.743575: step 2132, loss 0.0368078, acc 0.984375
2020-02-08T03:35:10.860759: step 2133, loss 0.0223375, acc 1
2020-02-08T03:35:10.976999: step 2134, loss 0.0327311, acc 0.984375
2020-02-08T03:35:11.095734: step 2135, loss 0.0127404, acc 1
2020-02-08T03:35:11.212382: step 2136, loss 0.0396533, acc 0.984375
2020-02-08T03:35:11.331293: step 2137, loss 0.0812228, acc 0.96875
2020-02-08T03:35:11.447368: step 2138, loss 0.0404989, acc 1
2020-02-08T03:35:11.566455: step 2139, loss 0.0507504, acc 1
2020-02-08T03:35:11.686918: step 2140, loss 0.030468, acc 0.984375
2020-02-08T03:35:11.806672: step 2141, loss 0.0486756, acc 0.984375
2020-02-08T03:35:11.925007: step 2142, loss 0.0323114, acc 0.984375
2020-02-08T03:35:12.043163: step 2143, loss 0.0554564, acc 0.984375
2020-02-08T03:35:12.161825: step 2144, loss 0.0191133, acc 1
2020-02-08T03:35:12.278881: step 2145, loss 0.0282922, acc 0.984375
2020-02-08T03:35:12.395942: step 2146, loss 0.0395102, acc 1
2020-02-08T03:35:12.513988: step 2147, loss 0.0878053, acc 0.96875
2020-02-08T03:35:12.629120: step 2148, loss 0.0328618, acc 0.984375
2020-02-08T03:35:12.744518: step 2149, loss 0.0488042, acc 0.96875
2020-02-08T03:35:12.860226: step 2150, loss 0.0193575, acc 0.984375
2020-02-08T03:35:12.976630: step 2151, loss 0.118967, acc 0.984375
2020-02-08T03:35:13.092410: step 2152, loss 0.0456361, acc 0.984375
2020-02-08T03:35:13.211811: step 2153, loss 0.0268262, acc 1
2020-02-08T03:35:13.327472: step 2154, loss 0.0370251, acc 0.984375
2020-02-08T03:35:13.447527: step 2155, loss 0.0798491, acc 0.96875
2020-02-08T03:35:13.566223: step 2156, loss 0.0831073, acc 0.96875
2020-02-08T03:35:13.681022: step 2157, loss 0.0372629, acc 0.984375
2020-02-08T03:35:13.799324: step 2158, loss 0.0234062, acc 1
2020-02-08T03:35:13.917350: step 2159, loss 0.0665929, acc 0.96875
2020-02-08T03:35:14.032846: step 2160, loss 0.0232264, acc 1
2020-02-08T03:35:14.149703: step 2161, loss 0.0371793, acc 0.984375
2020-02-08T03:35:14.269884: step 2162, loss 0.0225107, acc 0.984375
2020-02-08T03:35:14.387028: step 2163, loss 0.173813, acc 0.921875
2020-02-08T03:35:14.506597: step 2164, loss 0.0174319, acc 1
2020-02-08T03:35:14.624671: step 2165, loss 0.0323702, acc 1
2020-02-08T03:35:14.744721: step 2166, loss 0.0980548, acc 0.984375
2020-02-08T03:35:14.860813: step 2167, loss 0.0149936, acc 1
2020-02-08T03:35:14.978611: step 2168, loss 0.0634285, acc 0.984375
2020-02-08T03:35:15.097207: step 2169, loss 0.0330534, acc 0.984375
2020-02-08T03:35:15.214552: step 2170, loss 0.040296, acc 0.984375
2020-02-08T03:35:15.330784: step 2171, loss 0.043661, acc 0.984375
2020-02-08T03:35:15.448826: step 2172, loss 0.0451894, acc 0.984375
2020-02-08T03:35:15.566942: step 2173, loss 0.0216672, acc 1
2020-02-08T03:35:15.683490: step 2174, loss 0.0125904, acc 1
2020-02-08T03:35:15.803272: step 2175, loss 0.0803373, acc 0.984375
2020-02-08T03:35:15.921991: step 2176, loss 0.0254461, acc 1
2020-02-08T03:35:16.038355: step 2177, loss 0.0206496, acc 1
2020-02-08T03:35:16.158213: step 2178, loss 0.0258109, acc 1
2020-02-08T03:35:16.275434: step 2179, loss 0.0333987, acc 1
2020-02-08T03:35:16.392115: step 2180, loss 0.0260545, acc 1
2020-02-08T03:35:16.510399: step 2181, loss 0.0160646, acc 1
2020-02-08T03:35:16.629401: step 2182, loss 0.0520359, acc 0.984375
2020-02-08T03:35:16.747666: step 2183, loss 0.0347779, acc 1
2020-02-08T03:35:16.864300: step 2184, loss 0.0370511, acc 0.984375
2020-02-08T03:35:16.983765: step 2185, loss 0.0425673, acc 0.984375
2020-02-08T03:35:17.101566: step 2186, loss 0.0253753, acc 1
2020-02-08T03:35:17.224000: step 2187, loss 0.0306031, acc 1
2020-02-08T03:35:17.342478: step 2188, loss 0.0166537, acc 1
2020-02-08T03:35:17.458450: step 2189, loss 0.0188888, acc 1
2020-02-08T03:35:17.576783: step 2190, loss 0.0573047, acc 0.96875
2020-02-08T03:35:17.696790: step 2191, loss 0.0476647, acc 0.984375
2020-02-08T03:35:17.811882: step 2192, loss 0.0322374, acc 0.984375
2020-02-08T03:35:17.930303: step 2193, loss 0.0350105, acc 1
2020-02-08T03:35:18.046835: step 2194, loss 0.0472954, acc 0.984375
2020-02-08T03:35:18.162881: step 2195, loss 0.018229, acc 1
2020-02-08T03:35:18.276231: step 2196, loss 0.0801491, acc 0.953125
2020-02-08T03:35:18.395720: step 2197, loss 0.0628688, acc 0.984375
2020-02-08T03:35:18.512956: step 2198, loss 0.023767, acc 1
2020-02-08T03:35:18.629888: step 2199, loss 0.0154699, acc 1
2020-02-08T03:35:18.745420: step 2200, loss 0.0279004, acc 1

Evaluation:
2020-02-08T03:35:18.936391: step 2200, loss 0.834941, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2200

2020-02-08T03:35:20.435648: step 2201, loss 0.013947, acc 1
2020-02-08T03:35:20.552977: step 2202, loss 0.0824938, acc 0.96875
2020-02-08T03:35:20.671378: step 2203, loss 0.0354075, acc 0.96875
2020-02-08T03:35:20.797451: step 2204, loss 0.0458745, acc 0.984375
2020-02-08T03:35:20.916528: step 2205, loss 0.0108281, acc 1
2020-02-08T03:35:21.036396: step 2206, loss 0.0402564, acc 0.984375
2020-02-08T03:35:21.154499: step 2207, loss 0.00986804, acc 1
2020-02-08T03:35:21.274657: step 2208, loss 0.0143237, acc 1
2020-02-08T03:35:21.391632: step 2209, loss 0.0359358, acc 1
2020-02-08T03:35:21.686360: step 2210, loss 0.045353, acc 0.96875
2020-02-08T03:35:21.810814: step 2211, loss 0.0237781, acc 0.984375
2020-02-08T03:35:21.927235: step 2212, loss 0.0834415, acc 0.953125
2020-02-08T03:35:22.045923: step 2213, loss 0.0214829, acc 1
2020-02-08T03:35:22.160348: step 2214, loss 0.0253032, acc 1
2020-02-08T03:35:22.278205: step 2215, loss 0.026924, acc 1
2020-02-08T03:35:22.398590: step 2216, loss 0.0605903, acc 0.984375
2020-02-08T03:35:22.520867: step 2217, loss 0.0433883, acc 0.984375
2020-02-08T03:35:22.639612: step 2218, loss 0.0707391, acc 0.96875
2020-02-08T03:35:22.755456: step 2219, loss 0.0742051, acc 0.953125
2020-02-08T03:35:22.874210: step 2220, loss 0.0602245, acc 0.96875
2020-02-08T03:35:22.992299: step 2221, loss 0.0642792, acc 0.96875
2020-02-08T03:35:23.107731: step 2222, loss 0.0123782, acc 1
2020-02-08T03:35:23.226561: step 2223, loss 0.0388445, acc 0.984375
2020-02-08T03:35:23.345250: step 2224, loss 0.0310206, acc 1
2020-02-08T03:35:23.460781: step 2225, loss 0.0337313, acc 1
2020-02-08T03:35:23.578770: step 2226, loss 0.113465, acc 0.96875
2020-02-08T03:35:23.695166: step 2227, loss 0.0205128, acc 1
2020-02-08T03:35:23.812220: step 2228, loss 0.0336432, acc 1
2020-02-08T03:35:23.930735: step 2229, loss 0.0498522, acc 0.984375
2020-02-08T03:35:24.048546: step 2230, loss 0.110295, acc 0.96875
2020-02-08T03:35:24.168428: step 2231, loss 0.0624688, acc 0.96875
2020-02-08T03:35:24.291950: step 2232, loss 0.0221105, acc 1
2020-02-08T03:35:24.406398: step 2233, loss 0.0278523, acc 1
2020-02-08T03:35:24.525224: step 2234, loss 0.0486161, acc 0.96875
2020-02-08T03:35:24.643269: step 2235, loss 0.0209647, acc 1
2020-02-08T03:35:24.788228: step 2236, loss 0.053192, acc 0.96875
2020-02-08T03:35:24.905423: step 2237, loss 0.0518451, acc 0.96875
2020-02-08T03:35:25.024413: step 2238, loss 0.0899393, acc 0.96875
2020-02-08T03:35:25.144932: step 2239, loss 0.0354268, acc 0.984375
2020-02-08T03:35:25.263016: step 2240, loss 0.108011, acc 0.96875
2020-02-08T03:35:25.382323: step 2241, loss 0.0287308, acc 0.984375
2020-02-08T03:35:25.501303: step 2242, loss 0.0927799, acc 0.96875
2020-02-08T03:35:25.617024: step 2243, loss 0.0123223, acc 1
2020-02-08T03:35:25.735246: step 2244, loss 0.0379698, acc 0.984375
2020-02-08T03:35:25.853700: step 2245, loss 0.0541709, acc 0.96875
2020-02-08T03:35:25.972353: step 2246, loss 0.02181, acc 1
2020-02-08T03:35:26.090420: step 2247, loss 0.0110498, acc 1
2020-02-08T03:35:26.207244: step 2248, loss 0.0125187, acc 1
2020-02-08T03:35:26.325825: step 2249, loss 0.0350947, acc 0.984375
2020-02-08T03:35:26.438634: step 2250, loss 0.0310512, acc 1
2020-02-08T03:35:26.555856: step 2251, loss 0.0237135, acc 0.984375
2020-02-08T03:35:26.674952: step 2252, loss 0.0395303, acc 0.984375
2020-02-08T03:35:26.791059: step 2253, loss 0.0129334, acc 1
2020-02-08T03:35:26.905022: step 2254, loss 0.0271958, acc 1
2020-02-08T03:35:27.021237: step 2255, loss 0.0386211, acc 0.984375
2020-02-08T03:35:27.142098: step 2256, loss 0.0255135, acc 0.984375
2020-02-08T03:35:27.257524: step 2257, loss 0.0314, acc 0.984375
2020-02-08T03:35:27.374984: step 2258, loss 0.0158126, acc 1
2020-02-08T03:35:27.495175: step 2259, loss 0.0128143, acc 1
2020-02-08T03:35:27.609142: step 2260, loss 0.0668414, acc 0.984375
2020-02-08T03:35:27.727216: step 2261, loss 0.0262724, acc 0.984375
2020-02-08T03:35:27.845841: step 2262, loss 0.0145915, acc 1
2020-02-08T03:35:27.962752: step 2263, loss 0.0137302, acc 1
2020-02-08T03:35:28.081760: step 2264, loss 0.0330685, acc 1
2020-02-08T03:35:28.198548: step 2265, loss 0.0295234, acc 1
2020-02-08T03:35:28.315916: step 2266, loss 0.0189528, acc 1
2020-02-08T03:35:28.434081: step 2267, loss 0.0219941, acc 1
2020-02-08T03:35:28.551326: step 2268, loss 0.0266232, acc 1
2020-02-08T03:35:28.668095: step 2269, loss 0.0640323, acc 0.984375
2020-02-08T03:35:28.788327: step 2270, loss 0.0798719, acc 0.96875
2020-02-08T03:35:28.902909: step 2271, loss 0.0313872, acc 1
2020-02-08T03:35:29.022798: step 2272, loss 0.0168454, acc 0.984375
2020-02-08T03:35:29.142022: step 2273, loss 0.0212242, acc 1
2020-02-08T03:35:29.258696: step 2274, loss 0.0449933, acc 0.96875
2020-02-08T03:35:29.377329: step 2275, loss 0.101909, acc 0.96875
2020-02-08T03:35:29.496479: step 2276, loss 0.0454082, acc 1
2020-02-08T03:35:29.619453: step 2277, loss 0.0133018, acc 1
2020-02-08T03:35:29.737784: step 2278, loss 0.0182827, acc 1
2020-02-08T03:35:29.854896: step 2279, loss 0.027248, acc 1
2020-02-08T03:35:29.973465: step 2280, loss 0.0544411, acc 0.96875
2020-02-08T03:35:30.092898: step 2281, loss 0.0357416, acc 0.984375
2020-02-08T03:35:30.207746: step 2282, loss 0.0147356, acc 1
2020-02-08T03:35:30.327830: step 2283, loss 0.0114815, acc 1
2020-02-08T03:35:30.444838: step 2284, loss 0.0121815, acc 1
2020-02-08T03:35:30.559375: step 2285, loss 0.0270591, acc 1
2020-02-08T03:35:30.680524: step 2286, loss 0.150773, acc 0.953125
2020-02-08T03:35:30.799641: step 2287, loss 0.0160946, acc 1
2020-02-08T03:35:30.919397: step 2288, loss 0.0471573, acc 0.984375
2020-02-08T03:35:31.039448: step 2289, loss 0.0250879, acc 0.984375
2020-02-08T03:35:31.155111: step 2290, loss 0.0356359, acc 0.984375
2020-02-08T03:35:31.278293: step 2291, loss 0.0115354, acc 1
2020-02-08T03:35:31.399492: step 2292, loss 0.0145096, acc 1
2020-02-08T03:35:31.519063: step 2293, loss 0.00801721, acc 1
2020-02-08T03:35:31.639522: step 2294, loss 0.0182634, acc 1
2020-02-08T03:35:31.753421: step 2295, loss 0.0160519, acc 1
2020-02-08T03:35:31.872806: step 2296, loss 0.0586257, acc 0.96875
2020-02-08T03:35:31.992824: step 2297, loss 0.0334546, acc 0.984375
2020-02-08T03:35:32.108847: step 2298, loss 0.0663688, acc 0.984375
2020-02-08T03:35:32.226555: step 2299, loss 0.0364312, acc 0.984375
2020-02-08T03:35:32.346892: step 2300, loss 0.0835586, acc 0.984375

Evaluation:
2020-02-08T03:35:32.538831: step 2300, loss 0.875304, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2300

2020-02-08T03:35:34.058663: step 2301, loss 0.03216, acc 0.984375
2020-02-08T03:35:34.179172: step 2302, loss 0.0143271, acc 1
2020-02-08T03:35:34.298386: step 2303, loss 0.0622566, acc 0.96875
2020-02-08T03:35:34.416690: step 2304, loss 0.0294513, acc 0.984375
2020-02-08T03:35:34.535178: step 2305, loss 0.0387437, acc 0.96875
2020-02-08T03:35:34.650610: step 2306, loss 0.0290782, acc 0.984375
2020-02-08T03:35:34.766878: step 2307, loss 0.0717033, acc 0.96875
2020-02-08T03:35:34.884415: step 2308, loss 0.0171655, acc 1
2020-02-08T03:35:35.001684: step 2309, loss 0.0407302, acc 0.96875
2020-02-08T03:35:35.121523: step 2310, loss 0.0264452, acc 1
2020-02-08T03:35:35.239337: step 2311, loss 0.0345195, acc 0.96875
2020-02-08T03:35:35.354205: step 2312, loss 0.0511176, acc 0.96875
2020-02-08T03:35:35.474984: step 2313, loss 0.0158431, acc 1
2020-02-08T03:35:35.597017: step 2314, loss 0.0584275, acc 0.96875
2020-02-08T03:35:35.714002: step 2315, loss 0.0550862, acc 0.984375
2020-02-08T03:35:35.831657: step 2316, loss 0.00920687, acc 1
2020-02-08T03:35:35.949374: step 2317, loss 0.086723, acc 0.96875
2020-02-08T03:35:36.066312: step 2318, loss 0.029757, acc 1
2020-02-08T03:35:36.183873: step 2319, loss 0.0188843, acc 1
2020-02-08T03:35:36.299108: step 2320, loss 0.0112789, acc 1
2020-02-08T03:35:36.412577: step 2321, loss 0.0484608, acc 1
2020-02-08T03:35:36.531534: step 2322, loss 0.0203861, acc 1
2020-02-08T03:35:36.649599: step 2323, loss 0.0467768, acc 0.984375
2020-02-08T03:35:36.767484: step 2324, loss 0.0393143, acc 0.984375
2020-02-08T03:35:36.887652: step 2325, loss 0.0587163, acc 0.984375
2020-02-08T03:35:37.004488: step 2326, loss 0.0196747, acc 1
2020-02-08T03:35:37.122180: step 2327, loss 0.0385435, acc 0.984375
2020-02-08T03:35:37.243310: step 2328, loss 0.0126756, acc 1
2020-02-08T03:35:37.361484: step 2329, loss 0.0482685, acc 0.984375
2020-02-08T03:35:37.480007: step 2330, loss 0.0191244, acc 1
2020-02-08T03:35:37.596289: step 2331, loss 0.0416923, acc 0.984375
2020-02-08T03:35:37.713059: step 2332, loss 0.0344394, acc 1
2020-02-08T03:35:37.829701: step 2333, loss 0.0107478, acc 1
2020-02-08T03:35:37.946663: step 2334, loss 0.0204624, acc 0.984375
2020-02-08T03:35:38.063160: step 2335, loss 0.00835088, acc 1
2020-02-08T03:35:38.180046: step 2336, loss 0.049462, acc 0.984375
2020-02-08T03:35:38.296150: step 2337, loss 0.0310666, acc 0.984375
2020-02-08T03:35:38.414345: step 2338, loss 0.00590212, acc 1
2020-02-08T03:35:38.531864: step 2339, loss 0.0343528, acc 0.984375
2020-02-08T03:35:38.648772: step 2340, loss 0.0258304, acc 1
2020-02-08T03:35:38.766186: step 2341, loss 0.03352, acc 0.984375
2020-02-08T03:35:38.884077: step 2342, loss 0.0294001, acc 1
2020-02-08T03:35:39.001632: step 2343, loss 0.00755541, acc 1
2020-02-08T03:35:39.123252: step 2344, loss 0.0172944, acc 0.984375
2020-02-08T03:35:39.240165: step 2345, loss 0.0343222, acc 1
2020-02-08T03:35:39.355336: step 2346, loss 0.0131727, acc 1
2020-02-08T03:35:39.472831: step 2347, loss 0.02574, acc 1
2020-02-08T03:35:39.591382: step 2348, loss 0.0419731, acc 0.984375
2020-02-08T03:35:39.703901: step 2349, loss 0.0563253, acc 0.984375
2020-02-08T03:35:39.818898: step 2350, loss 0.0115236, acc 1
2020-02-08T03:35:39.940563: step 2351, loss 0.0492862, acc 0.984375
2020-02-08T03:35:40.057427: step 2352, loss 0.0235907, acc 1
2020-02-08T03:35:40.176548: step 2353, loss 0.0233839, acc 0.984375
2020-02-08T03:35:40.290780: step 2354, loss 0.0580285, acc 0.96875
2020-02-08T03:35:40.406536: step 2355, loss 0.0160248, acc 1
2020-02-08T03:35:40.529093: step 2356, loss 0.0556595, acc 0.984375
2020-02-08T03:35:40.645480: step 2357, loss 0.0400015, acc 0.984375
2020-02-08T03:35:40.761566: step 2358, loss 0.0326149, acc 0.984375
2020-02-08T03:35:40.879492: step 2359, loss 0.021969, acc 1
2020-02-08T03:35:40.997440: step 2360, loss 0.104145, acc 0.984375
2020-02-08T03:35:41.114161: step 2361, loss 0.0336516, acc 0.984375
2020-02-08T03:35:41.231928: step 2362, loss 0.0523238, acc 0.96875
2020-02-08T03:35:41.349705: step 2363, loss 0.00672668, acc 1
2020-02-08T03:35:41.463930: step 2364, loss 0.062637, acc 0.96875
2020-02-08T03:35:41.581862: step 2365, loss 0.0226455, acc 0.984375
2020-02-08T03:35:41.696078: step 2366, loss 0.022422, acc 1
2020-02-08T03:35:41.812940: step 2367, loss 0.0168812, acc 1
2020-02-08T03:35:41.930234: step 2368, loss 0.0155588, acc 1
2020-02-08T03:35:42.048248: step 2369, loss 0.0637755, acc 0.984375
2020-02-08T03:35:42.163981: step 2370, loss 0.0507521, acc 0.984375
2020-02-08T03:35:42.278566: step 2371, loss 0.0396477, acc 1
2020-02-08T03:35:42.398570: step 2372, loss 0.0236737, acc 1
2020-02-08T03:35:42.513571: step 2373, loss 0.0549876, acc 0.953125
2020-02-08T03:35:42.630257: step 2374, loss 0.0210687, acc 1
2020-02-08T03:35:42.746791: step 2375, loss 0.0446501, acc 1
2020-02-08T03:35:42.863860: step 2376, loss 0.0305728, acc 1
2020-02-08T03:35:42.981788: step 2377, loss 0.012761, acc 1
2020-02-08T03:35:43.099680: step 2378, loss 0.0470578, acc 0.984375
2020-02-08T03:35:43.217189: step 2379, loss 0.011611, acc 1
2020-02-08T03:35:43.336847: step 2380, loss 0.00753586, acc 1
2020-02-08T03:35:43.452913: step 2381, loss 0.022414, acc 1
2020-02-08T03:35:43.572381: step 2382, loss 0.0101564, acc 1
2020-02-08T03:35:43.690959: step 2383, loss 0.0155268, acc 1
2020-02-08T03:35:43.807875: step 2384, loss 0.0234844, acc 1
2020-02-08T03:35:43.924676: step 2385, loss 0.0272473, acc 1
2020-02-08T03:35:44.040979: step 2386, loss 0.0183848, acc 1
2020-02-08T03:35:44.158612: step 2387, loss 0.0589593, acc 0.984375
2020-02-08T03:35:44.276715: step 2388, loss 0.0385692, acc 0.984375
2020-02-08T03:35:44.391301: step 2389, loss 0.0358241, acc 0.984375
2020-02-08T03:35:44.506785: step 2390, loss 0.0406513, acc 0.984375
2020-02-08T03:35:44.626272: step 2391, loss 0.0473252, acc 0.984375
2020-02-08T03:35:44.744593: step 2392, loss 0.0170312, acc 1
2020-02-08T03:35:44.865504: step 2393, loss 0.0489335, acc 1
2020-02-08T03:35:44.983074: step 2394, loss 0.0413381, acc 0.984375
2020-02-08T03:35:45.099136: step 2395, loss 0.0447999, acc 0.984375
2020-02-08T03:35:45.213987: step 2396, loss 0.0577664, acc 0.96875
2020-02-08T03:35:45.333458: step 2397, loss 0.0226758, acc 1
2020-02-08T03:35:45.450488: step 2398, loss 0.0165897, acc 1
2020-02-08T03:35:45.566358: step 2399, loss 0.0286611, acc 1
2020-02-08T03:35:45.678168: step 2400, loss 0.0663054, acc 0.983333

Evaluation:
2020-02-08T03:35:45.864894: step 2400, loss 0.894781, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2400

2020-02-08T03:35:47.378000: step 2401, loss 0.0222081, acc 0.984375
2020-02-08T03:35:47.495876: step 2402, loss 0.0192203, acc 1
2020-02-08T03:35:47.611838: step 2403, loss 0.033172, acc 0.984375
2020-02-08T03:35:47.731200: step 2404, loss 0.0371288, acc 0.984375
2020-02-08T03:35:47.848950: step 2405, loss 0.0475895, acc 0.984375
2020-02-08T03:35:47.964205: step 2406, loss 0.019687, acc 0.984375
2020-02-08T03:35:48.082746: step 2407, loss 0.0443336, acc 0.984375
2020-02-08T03:35:48.202003: step 2408, loss 0.0186694, acc 1
2020-02-08T03:35:48.320891: step 2409, loss 0.0261833, acc 1
2020-02-08T03:35:48.437785: step 2410, loss 0.0483046, acc 0.984375
2020-02-08T03:35:48.552429: step 2411, loss 0.021155, acc 1
2020-02-08T03:35:48.669160: step 2412, loss 0.0567444, acc 0.984375
2020-02-08T03:35:48.785099: step 2413, loss 0.0653759, acc 0.984375
2020-02-08T03:35:48.900995: step 2414, loss 0.0109474, acc 1
2020-02-08T03:35:49.021020: step 2415, loss 0.00787449, acc 1
2020-02-08T03:35:49.137852: step 2416, loss 0.020099, acc 1
2020-02-08T03:35:49.257695: step 2417, loss 0.0184353, acc 1
2020-02-08T03:35:49.376556: step 2418, loss 0.0427408, acc 1
2020-02-08T03:35:49.494542: step 2419, loss 0.0238619, acc 1
2020-02-08T03:35:49.614100: step 2420, loss 0.0296495, acc 1
2020-02-08T03:35:49.733506: step 2421, loss 0.0137381, acc 1
2020-02-08T03:35:49.851250: step 2422, loss 0.0584724, acc 0.984375
2020-02-08T03:35:49.971136: step 2423, loss 0.0170356, acc 1
2020-02-08T03:35:50.087903: step 2424, loss 0.0145603, acc 1
2020-02-08T03:35:50.203243: step 2425, loss 0.0685011, acc 0.96875
2020-02-08T03:35:50.322065: step 2426, loss 0.00612308, acc 1
2020-02-08T03:35:50.437917: step 2427, loss 0.0104395, acc 1
2020-02-08T03:35:50.552989: step 2428, loss 0.111306, acc 0.96875
2020-02-08T03:35:50.667353: step 2429, loss 0.00794403, acc 1
2020-02-08T03:35:50.786043: step 2430, loss 0.0313253, acc 0.984375
2020-02-08T03:35:50.901973: step 2431, loss 0.0335895, acc 1
2020-02-08T03:35:51.015947: step 2432, loss 0.0341885, acc 0.984375
2020-02-08T03:35:51.137067: step 2433, loss 0.0159479, acc 1
2020-02-08T03:35:51.251423: step 2434, loss 0.0296384, acc 0.984375
2020-02-08T03:35:51.608826: step 2435, loss 0.0122373, acc 1
2020-02-08T03:35:51.730334: step 2436, loss 0.0107062, acc 1
2020-02-08T03:35:51.851341: step 2437, loss 0.0369194, acc 0.984375
2020-02-08T03:35:51.971331: step 2438, loss 0.0193476, acc 1
2020-02-08T03:35:52.088409: step 2439, loss 0.0515167, acc 0.96875
2020-02-08T03:35:52.205358: step 2440, loss 0.00465251, acc 1
2020-02-08T03:35:52.322895: step 2441, loss 0.0298689, acc 0.984375
2020-02-08T03:35:52.438079: step 2442, loss 0.115567, acc 0.953125
2020-02-08T03:35:52.554878: step 2443, loss 0.031923, acc 0.984375
2020-02-08T03:35:52.671594: step 2444, loss 0.00460804, acc 1
2020-02-08T03:35:52.788042: step 2445, loss 0.00767669, acc 1
2020-02-08T03:35:52.904434: step 2446, loss 0.00704833, acc 1
2020-02-08T03:35:53.025504: step 2447, loss 0.04227, acc 0.96875
2020-02-08T03:35:53.143268: step 2448, loss 0.0262178, acc 0.984375
2020-02-08T03:35:53.263650: step 2449, loss 0.0393525, acc 0.984375
2020-02-08T03:35:53.379100: step 2450, loss 0.0207661, acc 1
2020-02-08T03:35:53.497259: step 2451, loss 0.0188118, acc 1
2020-02-08T03:35:53.615934: step 2452, loss 0.014688, acc 1
2020-02-08T03:35:53.736892: step 2453, loss 0.00365205, acc 1
2020-02-08T03:35:53.854760: step 2454, loss 0.0097528, acc 1
2020-02-08T03:35:53.972902: step 2455, loss 0.0105707, acc 1
2020-02-08T03:35:54.090469: step 2456, loss 0.0104572, acc 1
2020-02-08T03:35:54.207126: step 2457, loss 0.0086011, acc 1
2020-02-08T03:35:54.323158: step 2458, loss 0.0275115, acc 0.984375
2020-02-08T03:35:54.444416: step 2459, loss 0.0160737, acc 1
2020-02-08T03:35:54.561201: step 2460, loss 0.0340549, acc 1
2020-02-08T03:35:54.679121: step 2461, loss 0.0440268, acc 0.984375
2020-02-08T03:35:54.796378: step 2462, loss 0.0127273, acc 1
2020-02-08T03:35:54.914467: step 2463, loss 0.0322483, acc 1
2020-02-08T03:35:55.032567: step 2464, loss 0.0563921, acc 0.984375
2020-02-08T03:35:55.150941: step 2465, loss 0.033153, acc 1
2020-02-08T03:35:55.266785: step 2466, loss 0.0256981, acc 1
2020-02-08T03:35:55.383117: step 2467, loss 0.0368982, acc 0.984375
2020-02-08T03:35:55.500763: step 2468, loss 0.0200944, acc 1
2020-02-08T03:35:55.619541: step 2469, loss 0.0129835, acc 1
2020-02-08T03:35:55.735736: step 2470, loss 0.0159301, acc 1
2020-02-08T03:35:55.852456: step 2471, loss 0.0395125, acc 0.984375
2020-02-08T03:35:55.971134: step 2472, loss 0.0420044, acc 0.984375
2020-02-08T03:35:56.088144: step 2473, loss 0.00565485, acc 1
2020-02-08T03:35:56.205550: step 2474, loss 0.0130686, acc 1
2020-02-08T03:35:56.324607: step 2475, loss 0.0109289, acc 1
2020-02-08T03:35:56.448643: step 2476, loss 0.0563607, acc 0.96875
2020-02-08T03:35:56.565382: step 2477, loss 0.0705203, acc 0.953125
2020-02-08T03:35:56.685087: step 2478, loss 0.0118307, acc 1
2020-02-08T03:35:56.804958: step 2479, loss 0.0519701, acc 0.984375
2020-02-08T03:35:56.920560: step 2480, loss 0.0375698, acc 0.984375
2020-02-08T03:35:57.038008: step 2481, loss 0.0420459, acc 0.984375
2020-02-08T03:35:57.153345: step 2482, loss 0.0402041, acc 0.984375
2020-02-08T03:35:57.272509: step 2483, loss 0.012112, acc 1
2020-02-08T03:35:57.389364: step 2484, loss 0.0607508, acc 0.984375
2020-02-08T03:35:57.505086: step 2485, loss 0.0102474, acc 1
2020-02-08T03:35:57.621330: step 2486, loss 0.0179712, acc 1
2020-02-08T03:35:57.736963: step 2487, loss 0.0153286, acc 1
2020-02-08T03:35:57.855011: step 2488, loss 0.0150802, acc 1
2020-02-08T03:35:57.972353: step 2489, loss 0.0095475, acc 1
2020-02-08T03:35:58.091910: step 2490, loss 0.0457899, acc 0.984375
2020-02-08T03:35:58.209988: step 2491, loss 0.0074308, acc 1
2020-02-08T03:35:58.330153: step 2492, loss 0.0222948, acc 0.984375
2020-02-08T03:35:58.447673: step 2493, loss 0.0309541, acc 0.984375
2020-02-08T03:35:58.566222: step 2494, loss 0.0580281, acc 0.96875
2020-02-08T03:35:58.687409: step 2495, loss 0.0206891, acc 1
2020-02-08T03:35:58.804892: step 2496, loss 0.0597956, acc 0.984375
2020-02-08T03:35:58.925485: step 2497, loss 0.0318722, acc 0.984375
2020-02-08T03:35:59.046757: step 2498, loss 0.0334887, acc 1
2020-02-08T03:35:59.164573: step 2499, loss 0.00926751, acc 1
2020-02-08T03:35:59.282163: step 2500, loss 0.0456931, acc 0.984375

Evaluation:
2020-02-08T03:35:59.474715: step 2500, loss 0.956393, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2500

2020-02-08T03:36:01.033568: step 2501, loss 0.0103428, acc 1
2020-02-08T03:36:01.151154: step 2502, loss 0.0464077, acc 0.984375
2020-02-08T03:36:01.269950: step 2503, loss 0.0114549, acc 1
2020-02-08T03:36:01.385571: step 2504, loss 0.0223398, acc 0.984375
2020-02-08T03:36:01.500454: step 2505, loss 0.0294454, acc 0.984375
2020-02-08T03:36:01.617395: step 2506, loss 0.00916942, acc 1
2020-02-08T03:36:01.735891: step 2507, loss 0.0178365, acc 1
2020-02-08T03:36:01.854573: step 2508, loss 0.00562669, acc 1
2020-02-08T03:36:01.974712: step 2509, loss 0.0229604, acc 0.984375
2020-02-08T03:36:02.091321: step 2510, loss 0.0246619, acc 1
2020-02-08T03:36:02.204782: step 2511, loss 0.0485894, acc 0.984375
2020-02-08T03:36:02.320861: step 2512, loss 0.0141837, acc 1
2020-02-08T03:36:02.439347: step 2513, loss 0.0148996, acc 1
2020-02-08T03:36:02.555605: step 2514, loss 0.0626481, acc 0.984375
2020-02-08T03:36:02.674891: step 2515, loss 0.0129267, acc 1
2020-02-08T03:36:02.791293: step 2516, loss 0.0669243, acc 0.953125
2020-02-08T03:36:02.908803: step 2517, loss 0.025301, acc 1
2020-02-08T03:36:03.026888: step 2518, loss 0.0235255, acc 1
2020-02-08T03:36:03.142982: step 2519, loss 0.0115657, acc 1
2020-02-08T03:36:03.257795: step 2520, loss 0.0806099, acc 0.96875
2020-02-08T03:36:03.376472: step 2521, loss 0.0233792, acc 1
2020-02-08T03:36:03.493489: step 2522, loss 0.0133314, acc 1
2020-02-08T03:36:03.610161: step 2523, loss 0.0483509, acc 0.984375
2020-02-08T03:36:03.733646: step 2524, loss 0.0607889, acc 0.96875
2020-02-08T03:36:03.851377: step 2525, loss 0.0137784, acc 1
2020-02-08T03:36:03.969135: step 2526, loss 0.0137549, acc 1
2020-02-08T03:36:04.087173: step 2527, loss 0.0270877, acc 0.984375
2020-02-08T03:36:04.205387: step 2528, loss 0.0154293, acc 1
2020-02-08T03:36:04.326499: step 2529, loss 0.0329644, acc 0.984375
2020-02-08T03:36:04.448671: step 2530, loss 0.0126099, acc 1
2020-02-08T03:36:04.567618: step 2531, loss 0.0103183, acc 1
2020-02-08T03:36:04.685668: step 2532, loss 0.0150405, acc 1
2020-02-08T03:36:04.802387: step 2533, loss 0.0161466, acc 1
2020-02-08T03:36:04.918263: step 2534, loss 0.0119811, acc 1
2020-02-08T03:36:05.034778: step 2535, loss 0.00812648, acc 1
2020-02-08T03:36:05.149580: step 2536, loss 0.032878, acc 1
2020-02-08T03:36:05.264645: step 2537, loss 0.0173922, acc 1
2020-02-08T03:36:05.382343: step 2538, loss 0.0388897, acc 0.96875
2020-02-08T03:36:05.499435: step 2539, loss 0.0288622, acc 1
2020-02-08T03:36:05.616742: step 2540, loss 0.00928207, acc 1
2020-02-08T03:36:05.733172: step 2541, loss 0.0431732, acc 0.984375
2020-02-08T03:36:05.849411: step 2542, loss 0.0102628, acc 1
2020-02-08T03:36:05.964873: step 2543, loss 0.0497341, acc 0.984375
2020-02-08T03:36:06.082757: step 2544, loss 0.0165504, acc 1
2020-02-08T03:36:06.200697: step 2545, loss 0.0348763, acc 0.984375
2020-02-08T03:36:06.316376: step 2546, loss 0.063068, acc 0.96875
2020-02-08T03:36:06.435232: step 2547, loss 0.064165, acc 0.984375
2020-02-08T03:36:06.554725: step 2548, loss 0.0126037, acc 1
2020-02-08T03:36:06.671446: step 2549, loss 0.00693937, acc 1
2020-02-08T03:36:06.788312: step 2550, loss 0.0288083, acc 1
2020-02-08T03:36:06.907329: step 2551, loss 0.00439736, acc 1
2020-02-08T03:36:07.026196: step 2552, loss 0.0347163, acc 0.984375
2020-02-08T03:36:07.144563: step 2553, loss 0.00830896, acc 1
2020-02-08T03:36:07.259727: step 2554, loss 0.0119805, acc 1
2020-02-08T03:36:07.377593: step 2555, loss 0.01215, acc 1
2020-02-08T03:36:07.496332: step 2556, loss 0.0916528, acc 0.984375
2020-02-08T03:36:07.611555: step 2557, loss 0.077174, acc 0.953125
2020-02-08T03:36:07.731014: step 2558, loss 0.0181415, acc 1
2020-02-08T03:36:07.849021: step 2559, loss 0.0290508, acc 0.984375
2020-02-08T03:36:07.968128: step 2560, loss 0.00759396, acc 1
2020-02-08T03:36:08.086269: step 2561, loss 0.0643544, acc 0.953125
2020-02-08T03:36:08.201957: step 2562, loss 0.0124809, acc 1
2020-02-08T03:36:08.319592: step 2563, loss 0.0111557, acc 1
2020-02-08T03:36:08.436659: step 2564, loss 0.00628691, acc 1
2020-02-08T03:36:08.554113: step 2565, loss 0.0196914, acc 1
2020-02-08T03:36:08.671986: step 2566, loss 0.0335416, acc 0.984375
2020-02-08T03:36:08.789799: step 2567, loss 0.0220428, acc 0.984375
2020-02-08T03:36:08.909757: step 2568, loss 0.00807819, acc 1
2020-02-08T03:36:09.030484: step 2569, loss 0.0130461, acc 1
2020-02-08T03:36:09.148673: step 2570, loss 0.0106971, acc 1
2020-02-08T03:36:09.270957: step 2571, loss 0.0234719, acc 1
2020-02-08T03:36:09.388911: step 2572, loss 0.0197598, acc 1
2020-02-08T03:36:09.505407: step 2573, loss 0.0246859, acc 0.984375
2020-02-08T03:36:09.624419: step 2574, loss 0.00557433, acc 1
2020-02-08T03:36:09.745537: step 2575, loss 0.0212796, acc 0.984375
2020-02-08T03:36:09.860052: step 2576, loss 0.00439599, acc 1
2020-02-08T03:36:09.976996: step 2577, loss 0.0145655, acc 1
2020-02-08T03:36:10.094984: step 2578, loss 0.0183889, acc 1
2020-02-08T03:36:10.208458: step 2579, loss 0.0508127, acc 0.96875
2020-02-08T03:36:10.326432: step 2580, loss 0.0293325, acc 0.984375
2020-02-08T03:36:10.446005: step 2581, loss 0.0381856, acc 0.984375
2020-02-08T03:36:10.564297: step 2582, loss 0.00433923, acc 1
2020-02-08T03:36:10.680398: step 2583, loss 0.0138113, acc 1
2020-02-08T03:36:10.796308: step 2584, loss 0.00506116, acc 1
2020-02-08T03:36:10.913276: step 2585, loss 0.0334075, acc 0.984375
2020-02-08T03:36:11.029901: step 2586, loss 0.0126884, acc 1
2020-02-08T03:36:11.146600: step 2587, loss 0.020678, acc 1
2020-02-08T03:36:11.264979: step 2588, loss 0.0726487, acc 0.984375
2020-02-08T03:36:11.383791: step 2589, loss 0.0112873, acc 1
2020-02-08T03:36:11.500013: step 2590, loss 0.022802, acc 0.984375
2020-02-08T03:36:11.613716: step 2591, loss 0.0115892, acc 1
2020-02-08T03:36:11.730398: step 2592, loss 0.0225205, acc 0.984375
2020-02-08T03:36:11.845561: step 2593, loss 0.0168666, acc 1
2020-02-08T03:36:11.961403: step 2594, loss 0.0358229, acc 0.984375
2020-02-08T03:36:12.083628: step 2595, loss 0.0334182, acc 1
2020-02-08T03:36:12.202356: step 2596, loss 0.0106642, acc 1
2020-02-08T03:36:12.324862: step 2597, loss 0.0315926, acc 0.984375
2020-02-08T03:36:12.443458: step 2598, loss 0.0187805, acc 1
2020-02-08T03:36:12.559173: step 2599, loss 0.0211195, acc 1
2020-02-08T03:36:12.675741: step 2600, loss 0.00718271, acc 1

Evaluation:
2020-02-08T03:36:12.864797: step 2600, loss 0.958558, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2600

2020-02-08T03:36:14.406881: step 2601, loss 0.00923784, acc 1
2020-02-08T03:36:14.526749: step 2602, loss 0.00643386, acc 1
2020-02-08T03:36:14.642852: step 2603, loss 0.0111328, acc 1
2020-02-08T03:36:14.756449: step 2604, loss 0.0181624, acc 0.984375
2020-02-08T03:36:14.871182: step 2605, loss 0.0115735, acc 1
2020-02-08T03:36:14.986579: step 2606, loss 0.0275766, acc 0.984375
2020-02-08T03:36:15.104557: step 2607, loss 0.0200645, acc 0.984375
2020-02-08T03:36:15.226581: step 2608, loss 0.0108491, acc 1
2020-02-08T03:36:15.345404: step 2609, loss 0.0197817, acc 1
2020-02-08T03:36:15.460643: step 2610, loss 0.0071106, acc 1
2020-02-08T03:36:15.578878: step 2611, loss 0.102133, acc 0.96875
2020-02-08T03:36:15.702795: step 2612, loss 0.026382, acc 1
2020-02-08T03:36:15.819588: step 2613, loss 0.027986, acc 0.984375
2020-02-08T03:36:15.938118: step 2614, loss 0.0415282, acc 0.984375
2020-02-08T03:36:16.054427: step 2615, loss 0.0353613, acc 0.984375
2020-02-08T03:36:16.169428: step 2616, loss 0.0329362, acc 0.984375
2020-02-08T03:36:16.287262: step 2617, loss 0.0858307, acc 0.984375
2020-02-08T03:36:16.401511: step 2618, loss 0.0374978, acc 0.984375
2020-02-08T03:36:16.516939: step 2619, loss 0.0542962, acc 0.96875
2020-02-08T03:36:16.636938: step 2620, loss 0.0214109, acc 1
2020-02-08T03:36:16.753880: step 2621, loss 0.00933559, acc 1
2020-02-08T03:36:16.872426: step 2622, loss 0.0148869, acc 1
2020-02-08T03:36:16.993227: step 2623, loss 0.0343065, acc 0.984375
2020-02-08T03:36:17.111516: step 2624, loss 0.117727, acc 0.96875
2020-02-08T03:36:17.230487: step 2625, loss 0.00859266, acc 1
2020-02-08T03:36:17.348038: step 2626, loss 0.0122032, acc 1
2020-02-08T03:36:17.463607: step 2627, loss 0.0209475, acc 1
2020-02-08T03:36:17.582118: step 2628, loss 0.0788533, acc 0.984375
2020-02-08T03:36:17.700014: step 2629, loss 0.0218959, acc 1
2020-02-08T03:36:17.818080: step 2630, loss 0.0100849, acc 1
2020-02-08T03:36:17.936028: step 2631, loss 0.0152483, acc 1
2020-02-08T03:36:18.052928: step 2632, loss 0.0619191, acc 0.96875
2020-02-08T03:36:18.167802: step 2633, loss 0.0200962, acc 1
2020-02-08T03:36:18.287616: step 2634, loss 0.0227367, acc 1
2020-02-08T03:36:18.404288: step 2635, loss 0.0358763, acc 0.984375
2020-02-08T03:36:18.523043: step 2636, loss 0.0191433, acc 1
2020-02-08T03:36:18.639934: step 2637, loss 0.0613558, acc 0.96875
2020-02-08T03:36:18.756215: step 2638, loss 0.0377511, acc 0.984375
2020-02-08T03:36:18.875014: step 2639, loss 0.012333, acc 1
2020-02-08T03:36:18.994139: step 2640, loss 0.0191341, acc 1
2020-02-08T03:36:19.108499: step 2641, loss 0.0134854, acc 1
2020-02-08T03:36:19.226135: step 2642, loss 0.0104548, acc 1
2020-02-08T03:36:19.342835: step 2643, loss 0.0191383, acc 0.984375
2020-02-08T03:36:19.457072: step 2644, loss 0.0351785, acc 0.96875
2020-02-08T03:36:19.571482: step 2645, loss 0.0110877, acc 1
2020-02-08T03:36:19.690668: step 2646, loss 0.0274462, acc 1
2020-02-08T03:36:19.806734: step 2647, loss 0.0194061, acc 1
2020-02-08T03:36:19.922620: step 2648, loss 0.0308937, acc 0.984375
2020-02-08T03:36:20.044687: step 2649, loss 0.015625, acc 1
2020-02-08T03:36:20.159454: step 2650, loss 0.0459585, acc 0.984375
2020-02-08T03:36:20.276132: step 2651, loss 0.0154784, acc 1
2020-02-08T03:36:20.398887: step 2652, loss 0.0409179, acc 1
2020-02-08T03:36:20.513683: step 2653, loss 0.0624384, acc 0.96875
2020-02-08T03:36:20.634562: step 2654, loss 0.0109263, acc 1
2020-02-08T03:36:20.753084: step 2655, loss 0.116713, acc 0.96875
2020-02-08T03:36:20.871197: step 2656, loss 0.0202549, acc 1
2020-02-08T03:36:20.990252: step 2657, loss 0.0120229, acc 1
2020-02-08T03:36:21.107545: step 2658, loss 0.041381, acc 1
2020-02-08T03:36:21.225560: step 2659, loss 0.0322211, acc 1
2020-02-08T03:36:21.344961: step 2660, loss 0.0109965, acc 1
2020-02-08T03:36:21.458680: step 2661, loss 0.0214562, acc 0.984375
2020-02-08T03:36:21.574307: step 2662, loss 0.0472903, acc 0.984375
2020-02-08T03:36:21.727420: step 2663, loss 0.0120638, acc 1
2020-02-08T03:36:21.851170: step 2664, loss 0.0450061, acc 0.96875
2020-02-08T03:36:21.968658: step 2665, loss 0.0389433, acc 0.984375
2020-02-08T03:36:22.088439: step 2666, loss 0.0562241, acc 0.96875
2020-02-08T03:36:22.205850: step 2667, loss 0.0361624, acc 0.984375
2020-02-08T03:36:22.323203: step 2668, loss 0.00718312, acc 1
2020-02-08T03:36:22.440908: step 2669, loss 0.0290325, acc 0.984375
2020-02-08T03:36:22.559295: step 2670, loss 0.0383887, acc 0.984375
2020-02-08T03:36:22.680324: step 2671, loss 0.0175972, acc 0.984375
2020-02-08T03:36:22.797235: step 2672, loss 0.0043008, acc 1
2020-02-08T03:36:22.919083: step 2673, loss 0.0903376, acc 0.984375
2020-02-08T03:36:23.038636: step 2674, loss 0.0183883, acc 1
2020-02-08T03:36:23.152310: step 2675, loss 0.0180493, acc 1
2020-02-08T03:36:23.270881: step 2676, loss 0.0118534, acc 1
2020-02-08T03:36:23.387605: step 2677, loss 0.0165283, acc 1
2020-02-08T03:36:23.505052: step 2678, loss 0.015622, acc 1
2020-02-08T03:36:23.620719: step 2679, loss 0.00772826, acc 1
2020-02-08T03:36:23.739777: step 2680, loss 0.0211167, acc 0.984375
2020-02-08T03:36:23.858959: step 2681, loss 0.0200504, acc 1
2020-02-08T03:36:23.973469: step 2682, loss 0.00844513, acc 1
2020-02-08T03:36:24.094396: step 2683, loss 0.0220627, acc 0.984375
2020-02-08T03:36:24.211812: step 2684, loss 0.0186359, acc 1
2020-02-08T03:36:24.326972: step 2685, loss 0.0210734, acc 0.984375
2020-02-08T03:36:24.444859: step 2686, loss 0.0182493, acc 1
2020-02-08T03:36:24.561965: step 2687, loss 0.00448583, acc 1
2020-02-08T03:36:24.680272: step 2688, loss 0.0134258, acc 1
2020-02-08T03:36:24.797770: step 2689, loss 0.0143416, acc 1
2020-02-08T03:36:24.917741: step 2690, loss 0.008461, acc 1
2020-02-08T03:36:25.036446: step 2691, loss 0.0451616, acc 1
2020-02-08T03:36:25.155661: step 2692, loss 0.0396186, acc 1
2020-02-08T03:36:25.273811: step 2693, loss 0.0414813, acc 0.984375
2020-02-08T03:36:25.392161: step 2694, loss 0.036942, acc 0.984375
2020-02-08T03:36:25.506987: step 2695, loss 0.0921135, acc 0.953125
2020-02-08T03:36:25.623881: step 2696, loss 0.0311868, acc 1
2020-02-08T03:36:25.743272: step 2697, loss 0.03851, acc 0.984375
2020-02-08T03:36:25.859195: step 2698, loss 0.0245186, acc 1
2020-02-08T03:36:25.974161: step 2699, loss 0.0384416, acc 0.984375
2020-02-08T03:36:26.087956: step 2700, loss 0.0157592, acc 1

Evaluation:
2020-02-08T03:36:26.280094: step 2700, loss 0.984202, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2700

2020-02-08T03:36:27.831664: step 2701, loss 0.0154835, acc 1
2020-02-08T03:36:27.948315: step 2702, loss 0.0478858, acc 0.984375
2020-02-08T03:36:28.063421: step 2703, loss 0.006011, acc 1
2020-02-08T03:36:28.180566: step 2704, loss 0.0112331, acc 1
2020-02-08T03:36:28.300578: step 2705, loss 0.0149459, acc 1
2020-02-08T03:36:28.418916: step 2706, loss 0.0355115, acc 0.984375
2020-02-08T03:36:28.535974: step 2707, loss 0.0119275, acc 1
2020-02-08T03:36:28.652304: step 2708, loss 0.00381524, acc 1
2020-02-08T03:36:28.770614: step 2709, loss 0.0119039, acc 1
2020-02-08T03:36:28.888931: step 2710, loss 0.00969424, acc 1
2020-02-08T03:36:29.006815: step 2711, loss 0.00803136, acc 1
2020-02-08T03:36:29.123268: step 2712, loss 0.0128949, acc 1
2020-02-08T03:36:29.242609: step 2713, loss 0.00611753, acc 1
2020-02-08T03:36:29.359529: step 2714, loss 0.00899469, acc 1
2020-02-08T03:36:29.476383: step 2715, loss 0.0318255, acc 1
2020-02-08T03:36:29.593796: step 2716, loss 0.00646931, acc 1
2020-02-08T03:36:29.710550: step 2717, loss 0.0513461, acc 0.984375
2020-02-08T03:36:29.829084: step 2718, loss 0.00867544, acc 1
2020-02-08T03:36:29.948569: step 2719, loss 0.0070334, acc 1
2020-02-08T03:36:30.064475: step 2720, loss 0.046634, acc 0.984375
2020-02-08T03:36:30.182191: step 2721, loss 0.0110614, acc 1
2020-02-08T03:36:30.299205: step 2722, loss 0.0130137, acc 1
2020-02-08T03:36:30.417135: step 2723, loss 0.0113382, acc 1
2020-02-08T03:36:30.535803: step 2724, loss 0.0639708, acc 0.96875
2020-02-08T03:36:30.653735: step 2725, loss 0.0517666, acc 0.984375
2020-02-08T03:36:30.773448: step 2726, loss 0.00777878, acc 1
2020-02-08T03:36:30.892081: step 2727, loss 0.0215882, acc 0.984375
2020-02-08T03:36:31.010690: step 2728, loss 0.00884294, acc 1
2020-02-08T03:36:31.131024: step 2729, loss 0.00842283, acc 1
2020-02-08T03:36:31.247176: step 2730, loss 0.00954448, acc 1
2020-02-08T03:36:31.365384: step 2731, loss 0.00880919, acc 1
2020-02-08T03:36:31.482517: step 2732, loss 0.0158868, acc 1
2020-02-08T03:36:31.600792: step 2733, loss 0.0139641, acc 1
2020-02-08T03:36:31.720297: step 2734, loss 0.0328933, acc 0.984375
2020-02-08T03:36:31.841015: step 2735, loss 0.00568316, acc 1
2020-02-08T03:36:31.958072: step 2736, loss 0.0043504, acc 1
2020-02-08T03:36:32.079871: step 2737, loss 0.011916, acc 1
2020-02-08T03:36:32.197746: step 2738, loss 0.00920727, acc 1
2020-02-08T03:36:32.316582: step 2739, loss 0.0204065, acc 0.984375
2020-02-08T03:36:32.437598: step 2740, loss 0.0154177, acc 0.984375
2020-02-08T03:36:32.553569: step 2741, loss 0.0100689, acc 1
2020-02-08T03:36:32.676061: step 2742, loss 0.0104799, acc 1
2020-02-08T03:36:32.794005: step 2743, loss 0.0292985, acc 1
2020-02-08T03:36:32.911989: step 2744, loss 0.069641, acc 0.96875
2020-02-08T03:36:33.033028: step 2745, loss 0.00714034, acc 1
2020-02-08T03:36:33.151310: step 2746, loss 0.00930329, acc 1
2020-02-08T03:36:33.272209: step 2747, loss 0.0147123, acc 1
2020-02-08T03:36:33.389911: step 2748, loss 0.0253443, acc 0.984375
2020-02-08T03:36:33.506128: step 2749, loss 0.0193145, acc 1
2020-02-08T03:36:33.632370: step 2750, loss 0.015306, acc 1
2020-02-08T03:36:33.750477: step 2751, loss 0.0114416, acc 1
2020-02-08T03:36:33.866564: step 2752, loss 0.0103806, acc 1
2020-02-08T03:36:33.986262: step 2753, loss 0.0683747, acc 0.96875
2020-02-08T03:36:34.103221: step 2754, loss 0.0286211, acc 1
2020-02-08T03:36:34.222306: step 2755, loss 0.0140359, acc 1
2020-02-08T03:36:34.340172: step 2756, loss 0.0239492, acc 1
2020-02-08T03:36:34.457785: step 2757, loss 0.00513325, acc 1
2020-02-08T03:36:34.575485: step 2758, loss 0.0109063, acc 1
2020-02-08T03:36:34.695405: step 2759, loss 0.0256053, acc 0.984375
2020-02-08T03:36:34.810168: step 2760, loss 0.00961295, acc 1
2020-02-08T03:36:34.927771: step 2761, loss 0.0198244, acc 1
2020-02-08T03:36:35.045017: step 2762, loss 0.0171867, acc 1
2020-02-08T03:36:35.161983: step 2763, loss 0.0226657, acc 0.984375
2020-02-08T03:36:35.281492: step 2764, loss 0.00681505, acc 1
2020-02-08T03:36:35.399415: step 2765, loss 0.00690531, acc 1
2020-02-08T03:36:35.521819: step 2766, loss 0.0407505, acc 0.984375
2020-02-08T03:36:35.639397: step 2767, loss 0.0232627, acc 1
2020-02-08T03:36:35.757809: step 2768, loss 0.0136006, acc 1
2020-02-08T03:36:35.876986: step 2769, loss 0.0066287, acc 1
2020-02-08T03:36:35.995340: step 2770, loss 0.0080115, acc 1
2020-02-08T03:36:36.110723: step 2771, loss 0.0087056, acc 1
2020-02-08T03:36:36.228862: step 2772, loss 0.0266058, acc 1
2020-02-08T03:36:36.348962: step 2773, loss 0.0157111, acc 1
2020-02-08T03:36:36.462519: step 2774, loss 0.00566234, acc 1
2020-02-08T03:36:36.583646: step 2775, loss 0.00834162, acc 1
2020-02-08T03:36:36.703315: step 2776, loss 0.0294677, acc 0.984375
2020-02-08T03:36:36.822768: step 2777, loss 0.0172772, acc 1
2020-02-08T03:36:36.941995: step 2778, loss 0.0180618, acc 1
2020-02-08T03:36:37.058716: step 2779, loss 0.0288385, acc 0.984375
2020-02-08T03:36:37.177470: step 2780, loss 0.021976, acc 1
2020-02-08T03:36:37.296386: step 2781, loss 0.0188112, acc 1
2020-02-08T03:36:37.415540: step 2782, loss 0.0159646, acc 1
2020-02-08T03:36:37.533807: step 2783, loss 0.0275377, acc 0.984375
2020-02-08T03:36:37.651760: step 2784, loss 0.0565528, acc 0.984375
2020-02-08T03:36:37.770432: step 2785, loss 0.00857098, acc 1
2020-02-08T03:36:37.888430: step 2786, loss 0.0253805, acc 0.984375
2020-02-08T03:36:38.004808: step 2787, loss 0.0084719, acc 1
2020-02-08T03:36:38.122660: step 2788, loss 0.013947, acc 0.984375
2020-02-08T03:36:38.241935: step 2789, loss 0.0206134, acc 1
2020-02-08T03:36:38.357364: step 2790, loss 0.0164548, acc 1
2020-02-08T03:36:38.474518: step 2791, loss 0.0497847, acc 0.96875
2020-02-08T03:36:38.593747: step 2792, loss 0.0347093, acc 0.984375
2020-02-08T03:36:38.713814: step 2793, loss 0.0196857, acc 1
2020-02-08T03:36:38.832184: step 2794, loss 0.0100433, acc 1
2020-02-08T03:36:38.949589: step 2795, loss 0.0193475, acc 1
2020-02-08T03:36:39.071355: step 2796, loss 0.0397969, acc 0.96875
2020-02-08T03:36:39.191690: step 2797, loss 0.0204914, acc 1
2020-02-08T03:36:39.308500: step 2798, loss 0.0141341, acc 1
2020-02-08T03:36:39.426739: step 2799, loss 0.0251548, acc 1
2020-02-08T03:36:39.544409: step 2800, loss 0.0231684, acc 1

Evaluation:
2020-02-08T03:36:39.734477: step 2800, loss 1.02167, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2800

2020-02-08T03:36:41.252861: step 2801, loss 0.0307327, acc 0.984375
2020-02-08T03:36:41.376310: step 2802, loss 0.0408199, acc 0.984375
2020-02-08T03:36:41.491682: step 2803, loss 0.121666, acc 0.984375
2020-02-08T03:36:41.610165: step 2804, loss 0.0371203, acc 0.984375
2020-02-08T03:36:41.729444: step 2805, loss 0.0377926, acc 0.984375
2020-02-08T03:36:41.848276: step 2806, loss 0.0417627, acc 0.984375
2020-02-08T03:36:41.968680: step 2807, loss 0.0103155, acc 1
2020-02-08T03:36:42.088809: step 2808, loss 0.0166172, acc 1
2020-02-08T03:36:42.206234: step 2809, loss 0.0126999, acc 1
2020-02-08T03:36:42.325353: step 2810, loss 0.0646725, acc 0.984375
2020-02-08T03:36:42.444487: step 2811, loss 0.0239562, acc 0.984375
2020-02-08T03:36:42.565554: step 2812, loss 0.028782, acc 1
2020-02-08T03:36:42.681757: step 2813, loss 0.0208876, acc 1
2020-02-08T03:36:42.800697: step 2814, loss 0.0168467, acc 0.984375
2020-02-08T03:36:42.922922: step 2815, loss 0.00367377, acc 1
2020-02-08T03:36:43.042698: step 2816, loss 0.0214934, acc 1
2020-02-08T03:36:43.163156: step 2817, loss 0.0193355, acc 1
2020-02-08T03:36:43.281823: step 2818, loss 0.0105838, acc 1
2020-02-08T03:36:43.400297: step 2819, loss 0.0243124, acc 1
2020-02-08T03:36:43.519871: step 2820, loss 0.017041, acc 1
2020-02-08T03:36:43.636247: step 2821, loss 0.0284032, acc 0.984375
2020-02-08T03:36:43.751876: step 2822, loss 0.0153143, acc 1
2020-02-08T03:36:43.873229: step 2823, loss 0.0373584, acc 0.984375
2020-02-08T03:36:43.988045: step 2824, loss 0.0236343, acc 1
2020-02-08T03:36:44.109310: step 2825, loss 0.0221125, acc 1
2020-02-08T03:36:44.226314: step 2826, loss 0.00573544, acc 1
2020-02-08T03:36:44.345611: step 2827, loss 0.0776209, acc 0.984375
2020-02-08T03:36:44.461991: step 2828, loss 0.00632776, acc 1
2020-02-08T03:36:44.578582: step 2829, loss 0.0156218, acc 1
2020-02-08T03:36:44.694699: step 2830, loss 0.0141654, acc 1
2020-02-08T03:36:44.811086: step 2831, loss 0.0217242, acc 0.984375
2020-02-08T03:36:44.930402: step 2832, loss 0.0219893, acc 0.984375
2020-02-08T03:36:45.048985: step 2833, loss 0.039902, acc 0.984375
2020-02-08T03:36:45.168103: step 2834, loss 0.0115148, acc 1
2020-02-08T03:36:45.285523: step 2835, loss 0.0148523, acc 1
2020-02-08T03:36:45.402379: step 2836, loss 0.00247801, acc 1
2020-02-08T03:36:45.520787: step 2837, loss 0.0344333, acc 0.984375
2020-02-08T03:36:45.638032: step 2838, loss 0.00250979, acc 1
2020-02-08T03:36:45.756377: step 2839, loss 0.0364687, acc 0.984375
2020-02-08T03:36:45.873122: step 2840, loss 0.00972194, acc 1
2020-02-08T03:36:45.990408: step 2841, loss 0.0350136, acc 0.984375
2020-02-08T03:36:46.108148: step 2842, loss 0.0152618, acc 1
2020-02-08T03:36:46.226189: step 2843, loss 0.0105377, acc 1
2020-02-08T03:36:46.343224: step 2844, loss 0.0139655, acc 1
2020-02-08T03:36:46.461891: step 2845, loss 0.0125486, acc 1
2020-02-08T03:36:46.579553: step 2846, loss 0.0125238, acc 1
2020-02-08T03:36:46.698015: step 2847, loss 0.0222069, acc 0.984375
2020-02-08T03:36:46.818238: step 2848, loss 0.00832032, acc 1
2020-02-08T03:36:46.939247: step 2849, loss 0.0381523, acc 0.984375
2020-02-08T03:36:47.053256: step 2850, loss 0.012907, acc 1
2020-02-08T03:36:47.173896: step 2851, loss 0.00869938, acc 1
2020-02-08T03:36:47.292757: step 2852, loss 0.0100977, acc 1
2020-02-08T03:36:47.412342: step 2853, loss 0.00538773, acc 1
2020-02-08T03:36:47.530648: step 2854, loss 0.00792942, acc 1
2020-02-08T03:36:47.649443: step 2855, loss 0.015125, acc 1
2020-02-08T03:36:47.768289: step 2856, loss 0.0115647, acc 1
2020-02-08T03:36:47.884775: step 2857, loss 0.00213333, acc 1
2020-02-08T03:36:48.002193: step 2858, loss 0.0204262, acc 0.984375
2020-02-08T03:36:48.122399: step 2859, loss 0.00795186, acc 1
2020-02-08T03:36:48.241133: step 2860, loss 0.0118825, acc 1
2020-02-08T03:36:48.357227: step 2861, loss 0.0290168, acc 0.984375
2020-02-08T03:36:48.474034: step 2862, loss 0.0236054, acc 1
2020-02-08T03:36:48.592014: step 2863, loss 0.00791929, acc 1
2020-02-08T03:36:48.712182: step 2864, loss 0.00120904, acc 1
2020-02-08T03:36:48.831650: step 2865, loss 0.0573658, acc 0.96875
2020-02-08T03:36:48.950522: step 2866, loss 0.00572168, acc 1
2020-02-08T03:36:49.064586: step 2867, loss 0.00357319, acc 1
2020-02-08T03:36:49.180978: step 2868, loss 0.00720886, acc 1
2020-02-08T03:36:49.299542: step 2869, loss 0.00659465, acc 1
2020-02-08T03:36:49.415137: step 2870, loss 0.00901604, acc 1
2020-02-08T03:36:49.535775: step 2871, loss 0.0269764, acc 0.984375
2020-02-08T03:36:49.659431: step 2872, loss 0.012098, acc 1
2020-02-08T03:36:49.776932: step 2873, loss 0.010393, acc 1
2020-02-08T03:36:49.892947: step 2874, loss 0.0150851, acc 1
2020-02-08T03:36:50.008348: step 2875, loss 0.0160763, acc 1
2020-02-08T03:36:50.128334: step 2876, loss 0.00512792, acc 1
2020-02-08T03:36:50.248612: step 2877, loss 0.0327436, acc 0.984375
2020-02-08T03:36:50.366155: step 2878, loss 0.0117888, acc 1
2020-02-08T03:36:50.488783: step 2879, loss 0.0319309, acc 0.984375
2020-02-08T03:36:50.604829: step 2880, loss 0.00819676, acc 1
2020-02-08T03:36:50.719900: step 2881, loss 0.0152064, acc 1
2020-02-08T03:36:50.840754: step 2882, loss 0.0178113, acc 0.984375
2020-02-08T03:36:50.956183: step 2883, loss 0.00608233, acc 1
2020-02-08T03:36:51.073534: step 2884, loss 0.0104278, acc 1
2020-02-08T03:36:51.193273: step 2885, loss 0.0261593, acc 0.984375
2020-02-08T03:36:51.309576: step 2886, loss 0.0529898, acc 0.984375
2020-02-08T03:36:51.426500: step 2887, loss 0.00757108, acc 1
2020-02-08T03:36:51.680366: step 2888, loss 0.00866145, acc 1
2020-02-08T03:36:51.805487: step 2889, loss 0.0102415, acc 1
2020-02-08T03:36:51.923812: step 2890, loss 0.003009, acc 1
2020-02-08T03:36:52.044635: step 2891, loss 0.00668262, acc 1
2020-02-08T03:36:52.164963: step 2892, loss 0.00171215, acc 1
2020-02-08T03:36:52.284560: step 2893, loss 0.0157682, acc 1
2020-02-08T03:36:52.406281: step 2894, loss 0.0108064, acc 1
2020-02-08T03:36:52.523452: step 2895, loss 0.00518065, acc 1
2020-02-08T03:36:52.642297: step 2896, loss 0.00713256, acc 1
2020-02-08T03:36:52.758821: step 2897, loss 0.00886527, acc 1
2020-02-08T03:36:52.880734: step 2898, loss 0.0118591, acc 1
2020-02-08T03:36:52.998058: step 2899, loss 0.0149589, acc 1
2020-02-08T03:36:53.116944: step 2900, loss 0.0145301, acc 1

Evaluation:
2020-02-08T03:36:53.306882: step 2900, loss 1.04326, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-2900

2020-02-08T03:36:54.815859: step 2901, loss 0.00769712, acc 1
2020-02-08T03:36:54.931381: step 2902, loss 0.00242814, acc 1
2020-02-08T03:36:55.045407: step 2903, loss 0.00919511, acc 1
2020-02-08T03:36:55.160464: step 2904, loss 0.0601464, acc 0.984375
2020-02-08T03:36:55.278918: step 2905, loss 0.0105891, acc 1
2020-02-08T03:36:55.397020: step 2906, loss 0.0335047, acc 0.96875
2020-02-08T03:36:55.515923: step 2907, loss 0.00550012, acc 1
2020-02-08T03:36:55.633876: step 2908, loss 0.00642791, acc 1
2020-02-08T03:36:55.751530: step 2909, loss 0.00739414, acc 1
2020-02-08T03:36:55.867854: step 2910, loss 0.00770981, acc 1
2020-02-08T03:36:55.987811: step 2911, loss 0.0147987, acc 1
2020-02-08T03:36:56.106025: step 2912, loss 0.0390893, acc 0.96875
2020-02-08T03:36:56.223426: step 2913, loss 0.00937635, acc 1
2020-02-08T03:36:56.341889: step 2914, loss 0.00919781, acc 1
2020-02-08T03:36:56.455448: step 2915, loss 0.0170454, acc 1
2020-02-08T03:36:56.569997: step 2916, loss 0.0100052, acc 1
2020-02-08T03:36:56.690214: step 2917, loss 0.00918543, acc 1
2020-02-08T03:36:56.804199: step 2918, loss 0.00986209, acc 1
2020-02-08T03:36:56.927678: step 2919, loss 0.00667443, acc 1
2020-02-08T03:36:57.044354: step 2920, loss 0.00471102, acc 1
2020-02-08T03:36:57.168196: step 2921, loss 0.00604024, acc 1
2020-02-08T03:36:57.286284: step 2922, loss 0.0165849, acc 1
2020-02-08T03:36:57.403072: step 2923, loss 0.00371873, acc 1
2020-02-08T03:36:57.518971: step 2924, loss 0.00302594, acc 1
2020-02-08T03:36:57.636184: step 2925, loss 0.0141506, acc 1
2020-02-08T03:36:57.751870: step 2926, loss 0.00626039, acc 1
2020-02-08T03:36:57.868461: step 2927, loss 0.0226868, acc 0.984375
2020-02-08T03:36:57.985758: step 2928, loss 0.0155781, acc 1
2020-02-08T03:36:58.105189: step 2929, loss 0.0160212, acc 1
2020-02-08T03:36:58.221807: step 2930, loss 0.0221748, acc 0.984375
2020-02-08T03:36:58.342454: step 2931, loss 0.0183102, acc 1
2020-02-08T03:36:58.461533: step 2932, loss 0.00940872, acc 1
2020-02-08T03:36:58.578926: step 2933, loss 0.0110418, acc 1
2020-02-08T03:36:58.699085: step 2934, loss 0.00398573, acc 1
2020-02-08T03:36:58.818217: step 2935, loss 0.00375513, acc 1
2020-02-08T03:36:58.936452: step 2936, loss 0.0232942, acc 1
2020-02-08T03:36:59.051337: step 2937, loss 0.0177595, acc 1
2020-02-08T03:36:59.167221: step 2938, loss 0.00861179, acc 1
2020-02-08T03:36:59.286467: step 2939, loss 0.0398026, acc 0.984375
2020-02-08T03:36:59.404080: step 2940, loss 0.00689684, acc 1
2020-02-08T03:36:59.525670: step 2941, loss 0.0211531, acc 0.984375
2020-02-08T03:36:59.643269: step 2942, loss 0.0186118, acc 1
2020-02-08T03:36:59.759574: step 2943, loss 0.0248749, acc 0.984375
2020-02-08T03:36:59.877487: step 2944, loss 0.0159435, acc 0.984375
2020-02-08T03:36:59.997239: step 2945, loss 0.0167923, acc 1
2020-02-08T03:37:00.116719: step 2946, loss 0.00423657, acc 1
2020-02-08T03:37:00.235495: step 2947, loss 0.0170476, acc 1
2020-02-08T03:37:00.350980: step 2948, loss 0.0313823, acc 0.984375
2020-02-08T03:37:00.465673: step 2949, loss 0.0146596, acc 1
2020-02-08T03:37:00.584296: step 2950, loss 0.00898794, acc 1
2020-02-08T03:37:00.700546: step 2951, loss 0.0283353, acc 0.984375
2020-02-08T03:37:00.816531: step 2952, loss 0.00294238, acc 1
2020-02-08T03:37:00.934981: step 2953, loss 0.0183072, acc 0.984375
2020-02-08T03:37:01.052003: step 2954, loss 0.015701, acc 1
2020-02-08T03:37:01.169691: step 2955, loss 0.0167435, acc 1
2020-02-08T03:37:01.289330: step 2956, loss 0.0904022, acc 0.984375
2020-02-08T03:37:01.406856: step 2957, loss 0.0344518, acc 0.984375
2020-02-08T03:37:01.523262: step 2958, loss 0.00992647, acc 1
2020-02-08T03:37:01.643500: step 2959, loss 0.0172575, acc 1
2020-02-08T03:37:01.761367: step 2960, loss 0.0149769, acc 1
2020-02-08T03:37:01.879385: step 2961, loss 0.0299084, acc 0.984375
2020-02-08T03:37:01.997568: step 2962, loss 0.0028489, acc 1
2020-02-08T03:37:02.117436: step 2963, loss 0.0110327, acc 1
2020-02-08T03:37:02.236103: step 2964, loss 0.00965785, acc 1
2020-02-08T03:37:02.352425: step 2965, loss 0.0103425, acc 1
2020-02-08T03:37:02.475690: step 2966, loss 0.0238103, acc 0.984375
2020-02-08T03:37:02.595160: step 2967, loss 0.00408226, acc 1
2020-02-08T03:37:02.715234: step 2968, loss 0.0182451, acc 0.984375
2020-02-08T03:37:02.833681: step 2969, loss 0.0111116, acc 1
2020-02-08T03:37:02.958217: step 2970, loss 0.0114865, acc 1
2020-02-08T03:37:03.075657: step 2971, loss 0.0207952, acc 1
2020-02-08T03:37:03.194351: step 2972, loss 0.0240683, acc 0.984375
2020-02-08T03:37:03.308223: step 2973, loss 0.0363929, acc 0.984375
2020-02-08T03:37:03.425150: step 2974, loss 0.00435988, acc 1
2020-02-08T03:37:03.546662: step 2975, loss 0.0373765, acc 0.984375
2020-02-08T03:37:03.661630: step 2976, loss 0.0156499, acc 1
2020-02-08T03:37:03.778358: step 2977, loss 0.00265652, acc 1
2020-02-08T03:37:03.896343: step 2978, loss 0.014622, acc 1
2020-02-08T03:37:04.011237: step 2979, loss 0.00833548, acc 1
2020-02-08T03:37:04.131896: step 2980, loss 0.0357642, acc 0.984375
2020-02-08T03:37:04.250673: step 2981, loss 0.0486983, acc 0.984375
2020-02-08T03:37:04.363374: step 2982, loss 0.00926535, acc 1
2020-02-08T03:37:04.484627: step 2983, loss 0.00867, acc 1
2020-02-08T03:37:04.603449: step 2984, loss 0.0365244, acc 0.984375
2020-02-08T03:37:04.723404: step 2985, loss 0.00866014, acc 1
2020-02-08T03:37:04.842382: step 2986, loss 0.0150935, acc 1
2020-02-08T03:37:04.960221: step 2987, loss 0.0219578, acc 1
2020-02-08T03:37:05.080263: step 2988, loss 0.00808053, acc 1
2020-02-08T03:37:05.198326: step 2989, loss 0.0114839, acc 1
2020-02-08T03:37:05.314296: step 2990, loss 0.00972921, acc 1
2020-02-08T03:37:05.431719: step 2991, loss 0.0257559, acc 0.984375
2020-02-08T03:37:05.551354: step 2992, loss 0.0238465, acc 0.984375
2020-02-08T03:37:05.671426: step 2993, loss 0.00562198, acc 1
2020-02-08T03:37:05.789135: step 2994, loss 0.0226312, acc 0.984375
2020-02-08T03:37:05.903867: step 2995, loss 0.0132758, acc 1
2020-02-08T03:37:06.029207: step 2996, loss 0.0050537, acc 1
2020-02-08T03:37:06.145908: step 2997, loss 0.00374565, acc 1
2020-02-08T03:37:06.261197: step 2998, loss 0.0247729, acc 1
2020-02-08T03:37:06.380512: step 2999, loss 0.00892088, acc 1
2020-02-08T03:37:06.495840: step 3000, loss 0.0125104, acc 1

Evaluation:
2020-02-08T03:37:06.685557: step 3000, loss 1.08836, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103820/checkpoints/model-3000

