WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 01:37:53.770416 4702916032 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 01:37:53.770664 4702916032 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 01:37:53.770772 4702916032 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 01:37:54.542659 4702916032 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 01:37:54.543376 4702916032 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 01:37:54.544206: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 01:37:54.571887: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe121826840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 01:37:54.571920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 01:37:54.572615 4702916032 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 01:37:54.580919 4702916032 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 01:37:54.599637 4702916032 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 01:37:54.615791 4702916032 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 01:37:54.659980 4702916032 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 01:37:54.678684 4702916032 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 01:37:54.678970 4702916032 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 01:37:54.704490 4702916032 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 01:37:54.714643 4702916032 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 01:37:54.768834 4702916032 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 01:37:55.268404 4702916032 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 01:37:55.268752 4702916032 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 01:37:55.284317 4702916032 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 01:37:55.327989 4702916032 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 01:37:55.330249 4702916032 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 01:37:55.369237 4702916032 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 01:37:55.370676 4702916032 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 01:37:55.401149 4702916032 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 01:37:55.402997 4702916032 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 01:37:55.440583 4702916032 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 01:37:55.443068 4702916032 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 01:37:55.477670 4702916032 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 01:37:55.480709 4702916032 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 01:37:55.520413 4702916032 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 01:37:55.522415 4702916032 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 01:37:55.559034 4702916032 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 01:37:55.563148 4702916032 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 01:37:55.597872 4702916032 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 01:37:55.599522 4702916032 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 01:37:55.632814 4702916032 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 01:37:55.634959 4702916032 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 01:37:55.640100 4702916032 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 01:37:56.138367 4702916032 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 01:37:56.138858 4702916032 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 01:37:56.975717 4702916032 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 01:37:57.835377 4702916032 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 01:40:04.596814 4702916032 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075

2020-02-08T01:37:57.834931: step 1, loss 1.83446, acc 0.546875
2020-02-08T01:37:58.056764: step 2, loss 1.9974, acc 0.484375
2020-02-08T01:37:58.266408: step 3, loss 2.1402, acc 0.46875
2020-02-08T01:37:58.471581: step 4, loss 1.87096, acc 0.453125
2020-02-08T01:37:58.694981: step 5, loss 1.78257, acc 0.484375
2020-02-08T01:37:59.002013: step 6, loss 1.96242, acc 0.53125
2020-02-08T01:37:59.329218: step 7, loss 1.50904, acc 0.5
2020-02-08T01:37:59.515319: step 8, loss 2.11237, acc 0.421875
2020-02-08T01:37:59.738159: step 9, loss 2.07856, acc 0.5
2020-02-08T01:37:59.959054: step 10, loss 1.70097, acc 0.484375
2020-02-08T01:38:00.147687: step 11, loss 1.89753, acc 0.5
2020-02-08T01:38:00.334036: step 12, loss 1.74942, acc 0.53125
2020-02-08T01:38:00.522231: step 13, loss 2.63879, acc 0.453125
2020-02-08T01:38:00.728295: step 14, loss 1.47873, acc 0.59375
2020-02-08T01:38:00.922136: step 15, loss 1.38501, acc 0.546875
2020-02-08T01:38:01.121720: step 16, loss 2.25007, acc 0.40625
2020-02-08T01:38:01.327955: step 17, loss 1.55168, acc 0.5625
2020-02-08T01:38:01.521688: step 18, loss 1.74433, acc 0.5
2020-02-08T01:38:01.736035: step 19, loss 1.63402, acc 0.515625
2020-02-08T01:38:01.935610: step 20, loss 1.81298, acc 0.546875
2020-02-08T01:38:02.126988: step 21, loss 1.994, acc 0.5
2020-02-08T01:38:02.336548: step 22, loss 1.62929, acc 0.53125
2020-02-08T01:38:02.533809: step 23, loss 2.16638, acc 0.421875
2020-02-08T01:38:02.737233: step 24, loss 1.5635, acc 0.46875
2020-02-08T01:38:02.940569: step 25, loss 1.44122, acc 0.515625
2020-02-08T01:38:03.141867: step 26, loss 1.14755, acc 0.65625
2020-02-08T01:38:03.361048: step 27, loss 1.65275, acc 0.5
2020-02-08T01:38:03.554270: step 28, loss 1.77413, acc 0.5
2020-02-08T01:38:03.757353: step 29, loss 1.515, acc 0.53125
2020-02-08T01:38:03.966830: step 30, loss 1.89431, acc 0.359375
2020-02-08T01:38:04.157966: step 31, loss 1.91698, acc 0.390625
2020-02-08T01:38:04.372183: step 32, loss 1.70326, acc 0.484375
2020-02-08T01:38:04.571231: step 33, loss 1.30267, acc 0.453125
2020-02-08T01:38:04.751443: step 34, loss 2.07784, acc 0.4375
2020-02-08T01:38:04.952806: step 35, loss 1.61374, acc 0.53125
2020-02-08T01:38:05.152312: step 36, loss 1.5019, acc 0.546875
2020-02-08T01:38:05.337010: step 37, loss 1.63025, acc 0.5
2020-02-08T01:38:05.531433: step 38, loss 1.76653, acc 0.4375
2020-02-08T01:38:05.734124: step 39, loss 1.4224, acc 0.5625
2020-02-08T01:38:05.928179: step 40, loss 1.71036, acc 0.5
2020-02-08T01:38:06.127324: step 41, loss 1.24887, acc 0.5625
2020-02-08T01:38:06.331110: step 42, loss 2.04991, acc 0.46875
2020-02-08T01:38:06.526662: step 43, loss 1.79498, acc 0.484375
2020-02-08T01:38:06.725484: step 44, loss 1.85058, acc 0.5
2020-02-08T01:38:06.931047: step 45, loss 1.72213, acc 0.484375
2020-02-08T01:38:07.132260: step 46, loss 1.70404, acc 0.546875
2020-02-08T01:38:07.330538: step 47, loss 1.48012, acc 0.59375
2020-02-08T01:38:07.592892: step 48, loss 1.76815, acc 0.46875
2020-02-08T01:38:07.810224: step 49, loss 2.11208, acc 0.4375
2020-02-08T01:38:08.005931: step 50, loss 1.665, acc 0.46875
2020-02-08T01:38:08.205034: step 51, loss 1.2456, acc 0.640625
2020-02-08T01:38:08.401840: step 52, loss 1.38806, acc 0.546875
2020-02-08T01:38:08.600236: step 53, loss 2.28476, acc 0.46875
2020-02-08T01:38:08.798871: step 54, loss 1.78479, acc 0.46875
2020-02-08T01:38:08.985551: step 55, loss 1.83282, acc 0.4375
2020-02-08T01:38:09.192457: step 56, loss 1.78408, acc 0.46875
2020-02-08T01:38:09.388225: step 57, loss 1.52814, acc 0.546875
2020-02-08T01:38:09.601900: step 58, loss 1.23724, acc 0.515625
2020-02-08T01:38:09.786346: step 59, loss 1.56617, acc 0.515625
2020-02-08T01:38:09.984531: step 60, loss 1.58705, acc 0.578125
2020-02-08T01:38:10.181758: step 61, loss 1.58073, acc 0.5625
2020-02-08T01:38:10.376365: step 62, loss 1.58908, acc 0.484375
2020-02-08T01:38:10.577987: step 63, loss 1.51046, acc 0.578125
2020-02-08T01:38:10.774033: step 64, loss 1.51726, acc 0.578125
2020-02-08T01:38:10.975532: step 65, loss 1.43914, acc 0.515625
2020-02-08T01:38:11.170958: step 66, loss 1.20715, acc 0.578125
2020-02-08T01:38:11.355839: step 67, loss 1.29269, acc 0.515625
2020-02-08T01:38:11.554181: step 68, loss 1.00445, acc 0.578125
2020-02-08T01:38:11.771076: step 69, loss 1.57942, acc 0.515625
2020-02-08T01:38:11.973580: step 70, loss 2.02848, acc 0.359375
2020-02-08T01:38:12.159706: step 71, loss 1.43746, acc 0.484375
2020-02-08T01:38:12.363419: step 72, loss 1.29399, acc 0.515625
2020-02-08T01:38:12.553285: step 73, loss 1.52878, acc 0.4375
2020-02-08T01:38:12.740896: step 74, loss 1.21942, acc 0.625
2020-02-08T01:38:12.921717: step 75, loss 1.25786, acc 0.578125
2020-02-08T01:38:13.123281: step 76, loss 1.88163, acc 0.4375
2020-02-08T01:38:13.308975: step 77, loss 1.3011, acc 0.5
2020-02-08T01:38:13.507205: step 78, loss 0.967412, acc 0.6875
2020-02-08T01:38:13.709652: step 79, loss 0.87939, acc 0.671875
2020-02-08T01:38:13.888721: step 80, loss 1.38593, acc 0.515625
2020-02-08T01:38:14.064823: step 81, loss 1.39622, acc 0.578125
2020-02-08T01:38:14.261757: step 82, loss 1.21543, acc 0.53125
2020-02-08T01:38:14.444962: step 83, loss 1.65816, acc 0.453125
2020-02-08T01:38:14.636834: step 84, loss 1.17994, acc 0.59375
2020-02-08T01:38:14.827558: step 85, loss 1.62489, acc 0.53125
2020-02-08T01:38:15.016604: step 86, loss 1.29246, acc 0.578125
2020-02-08T01:38:15.222339: step 87, loss 1.87997, acc 0.46875
2020-02-08T01:38:15.405334: step 88, loss 1.21205, acc 0.578125
2020-02-08T01:38:15.603454: step 89, loss 1.35107, acc 0.484375
2020-02-08T01:38:15.780714: step 90, loss 1.3051, acc 0.46875
2020-02-08T01:38:15.975145: step 91, loss 1.54863, acc 0.515625
2020-02-08T01:38:16.173292: step 92, loss 1.01492, acc 0.65625
2020-02-08T01:38:16.377614: step 93, loss 1.20009, acc 0.46875
2020-02-08T01:38:16.572091: step 94, loss 1.16107, acc 0.546875
2020-02-08T01:38:16.759351: step 95, loss 1.75546, acc 0.46875
2020-02-08T01:38:16.938897: step 96, loss 1.03009, acc 0.640625
2020-02-08T01:38:17.123193: step 97, loss 1.6289, acc 0.515625
2020-02-08T01:38:17.296315: step 98, loss 1.73305, acc 0.453125
2020-02-08T01:38:17.482891: step 99, loss 1.32769, acc 0.4375
2020-02-08T01:38:17.686106: step 100, loss 1.28338, acc 0.546875

Evaluation:
2020-02-08T01:38:18.094230: step 100, loss 0.879643, acc 0.540338

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-100

2020-02-08T01:38:20.318829: step 101, loss 1.39278, acc 0.515625
2020-02-08T01:38:20.527535: step 102, loss 1.71005, acc 0.609375
2020-02-08T01:38:20.723393: step 103, loss 1.22516, acc 0.5625
2020-02-08T01:38:20.903913: step 104, loss 1.43277, acc 0.40625
2020-02-08T01:38:21.099115: step 105, loss 1.52755, acc 0.4375
2020-02-08T01:38:21.300713: step 106, loss 1.24918, acc 0.53125
2020-02-08T01:38:21.531917: step 107, loss 1.40213, acc 0.484375
2020-02-08T01:38:21.719675: step 108, loss 1.28416, acc 0.4375
2020-02-08T01:38:21.895978: step 109, loss 1.0331, acc 0.59375
2020-02-08T01:38:22.076026: step 110, loss 1.41736, acc 0.453125
2020-02-08T01:38:22.257566: step 111, loss 1.10493, acc 0.578125
2020-02-08T01:38:22.442539: step 112, loss 1.44037, acc 0.484375
2020-02-08T01:38:22.633722: step 113, loss 1.50475, acc 0.4375
2020-02-08T01:38:22.815814: step 114, loss 1.39546, acc 0.5
2020-02-08T01:38:23.000501: step 115, loss 1.31814, acc 0.53125
2020-02-08T01:38:23.195996: step 116, loss 1.66066, acc 0.515625
2020-02-08T01:38:23.393477: step 117, loss 1.3067, acc 0.546875
2020-02-08T01:38:23.707755: step 118, loss 1.14877, acc 0.546875
2020-02-08T01:38:23.996357: step 119, loss 1.14663, acc 0.609375
2020-02-08T01:38:24.196565: step 120, loss 1.08767, acc 0.65625
2020-02-08T01:38:24.385283: step 121, loss 1.22238, acc 0.5
2020-02-08T01:38:24.584822: step 122, loss 1.12815, acc 0.609375
2020-02-08T01:38:24.780170: step 123, loss 0.967369, acc 0.59375
2020-02-08T01:38:24.985724: step 124, loss 1.3564, acc 0.484375
2020-02-08T01:38:25.170350: step 125, loss 1.08829, acc 0.515625
2020-02-08T01:38:25.359951: step 126, loss 0.991204, acc 0.59375
2020-02-08T01:38:25.532125: step 127, loss 1.19809, acc 0.5625
2020-02-08T01:38:25.713097: step 128, loss 1.26778, acc 0.5
2020-02-08T01:38:25.894783: step 129, loss 1.24184, acc 0.421875
2020-02-08T01:38:26.090513: step 130, loss 1.25102, acc 0.578125
2020-02-08T01:38:26.280531: step 131, loss 1.20683, acc 0.578125
2020-02-08T01:38:26.482029: step 132, loss 1.41596, acc 0.484375
2020-02-08T01:38:26.663379: step 133, loss 1.19052, acc 0.53125
2020-02-08T01:38:26.847272: step 134, loss 1.13297, acc 0.578125
2020-02-08T01:38:27.019226: step 135, loss 0.993379, acc 0.53125
2020-02-08T01:38:27.210741: step 136, loss 1.32373, acc 0.578125
2020-02-08T01:38:27.395595: step 137, loss 1.43209, acc 0.453125
2020-02-08T01:38:27.585553: step 138, loss 1.02873, acc 0.640625
2020-02-08T01:38:27.785419: step 139, loss 1.00154, acc 0.5625
2020-02-08T01:38:27.977245: step 140, loss 1.07292, acc 0.546875
2020-02-08T01:38:28.171380: step 141, loss 1.3467, acc 0.484375
2020-02-08T01:38:28.363229: step 142, loss 1.34689, acc 0.53125
2020-02-08T01:38:28.548712: step 143, loss 1.25123, acc 0.46875
2020-02-08T01:38:28.741983: step 144, loss 1.34255, acc 0.53125
2020-02-08T01:38:28.921276: step 145, loss 1.0029, acc 0.59375
2020-02-08T01:38:29.097176: step 146, loss 1.06676, acc 0.46875
2020-02-08T01:38:29.282089: step 147, loss 1.08755, acc 0.578125
2020-02-08T01:38:29.461977: step 148, loss 1.23886, acc 0.546875
2020-02-08T01:38:29.643546: step 149, loss 0.905884, acc 0.65625
2020-02-08T01:38:29.820556: step 150, loss 1.50815, acc 0.433333
2020-02-08T01:38:30.017577: step 151, loss 0.792211, acc 0.65625
2020-02-08T01:38:30.192630: step 152, loss 0.892856, acc 0.5625
2020-02-08T01:38:30.383424: step 153, loss 0.861484, acc 0.65625
2020-02-08T01:38:30.564829: step 154, loss 1.23964, acc 0.515625
2020-02-08T01:38:30.747227: step 155, loss 0.833616, acc 0.640625
2020-02-08T01:38:30.928862: step 156, loss 0.785402, acc 0.6875
2020-02-08T01:38:31.137230: step 157, loss 1.00565, acc 0.609375
2020-02-08T01:38:31.323116: step 158, loss 1.03978, acc 0.59375
2020-02-08T01:38:31.503321: step 159, loss 1.10235, acc 0.515625
2020-02-08T01:38:31.690316: step 160, loss 0.928739, acc 0.609375
2020-02-08T01:38:31.876940: step 161, loss 0.763451, acc 0.65625
2020-02-08T01:38:32.061850: step 162, loss 1.19439, acc 0.46875
2020-02-08T01:38:32.240401: step 163, loss 0.929865, acc 0.609375
2020-02-08T01:38:32.433290: step 164, loss 1.02277, acc 0.5625
2020-02-08T01:38:32.632759: step 165, loss 1.12936, acc 0.609375
2020-02-08T01:38:32.821158: step 166, loss 0.826193, acc 0.703125
2020-02-08T01:38:33.002051: step 167, loss 0.955191, acc 0.53125
2020-02-08T01:38:33.183263: step 168, loss 0.975783, acc 0.5625
2020-02-08T01:38:33.381600: step 169, loss 0.844082, acc 0.609375
2020-02-08T01:38:33.591299: step 170, loss 0.79682, acc 0.59375
2020-02-08T01:38:33.799594: step 171, loss 1.0387, acc 0.59375
2020-02-08T01:38:34.007175: step 172, loss 0.911085, acc 0.671875
2020-02-08T01:38:34.258168: step 173, loss 0.939627, acc 0.484375
2020-02-08T01:38:34.576139: step 174, loss 0.990129, acc 0.59375
2020-02-08T01:38:34.852365: step 175, loss 0.91093, acc 0.546875
2020-02-08T01:38:35.097760: step 176, loss 0.59083, acc 0.671875
2020-02-08T01:38:35.308179: step 177, loss 1.17149, acc 0.484375
2020-02-08T01:38:35.483607: step 178, loss 0.999557, acc 0.53125
2020-02-08T01:38:35.673421: step 179, loss 1.03522, acc 0.484375
2020-02-08T01:38:35.861695: step 180, loss 0.81038, acc 0.515625
2020-02-08T01:38:36.045257: step 181, loss 1.14403, acc 0.546875
2020-02-08T01:38:36.238407: step 182, loss 0.902238, acc 0.59375
2020-02-08T01:38:36.419159: step 183, loss 0.793773, acc 0.65625
2020-02-08T01:38:36.601115: step 184, loss 0.68033, acc 0.640625
2020-02-08T01:38:36.783597: step 185, loss 1.0171, acc 0.578125
2020-02-08T01:38:36.975753: step 186, loss 0.906382, acc 0.5625
2020-02-08T01:38:37.160704: step 187, loss 0.854622, acc 0.609375
2020-02-08T01:38:37.355020: step 188, loss 0.978864, acc 0.578125
2020-02-08T01:38:37.559989: step 189, loss 0.739411, acc 0.625
2020-02-08T01:38:37.758247: step 190, loss 0.724587, acc 0.609375
2020-02-08T01:38:37.939197: step 191, loss 0.833892, acc 0.609375
2020-02-08T01:38:38.140093: step 192, loss 0.865613, acc 0.625
2020-02-08T01:38:38.324339: step 193, loss 1.01054, acc 0.671875
2020-02-08T01:38:38.517650: step 194, loss 0.852389, acc 0.59375
2020-02-08T01:38:38.712299: step 195, loss 0.970377, acc 0.609375
2020-02-08T01:38:38.904904: step 196, loss 0.946524, acc 0.5625
2020-02-08T01:38:39.092667: step 197, loss 0.903973, acc 0.578125
2020-02-08T01:38:39.276158: step 198, loss 0.982847, acc 0.546875
2020-02-08T01:38:39.462741: step 199, loss 0.977869, acc 0.59375
2020-02-08T01:38:39.660966: step 200, loss 1.05783, acc 0.578125

Evaluation:
2020-02-08T01:38:40.008223: step 200, loss 0.662765, acc 0.609756

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-200

2020-02-08T01:38:41.635704: step 201, loss 0.895382, acc 0.640625
2020-02-08T01:38:41.819500: step 202, loss 0.827708, acc 0.609375
2020-02-08T01:38:42.000335: step 203, loss 0.840674, acc 0.671875
2020-02-08T01:38:42.176377: step 204, loss 0.917506, acc 0.578125
2020-02-08T01:38:42.357933: step 205, loss 0.668131, acc 0.703125
2020-02-08T01:38:42.539147: step 206, loss 0.819219, acc 0.609375
2020-02-08T01:38:42.730470: step 207, loss 0.627224, acc 0.765625
2020-02-08T01:38:42.909062: step 208, loss 0.856792, acc 0.609375
2020-02-08T01:38:43.086241: step 209, loss 0.687196, acc 0.609375
2020-02-08T01:38:43.259917: step 210, loss 0.792295, acc 0.640625
2020-02-08T01:38:43.459023: step 211, loss 1.07342, acc 0.515625
2020-02-08T01:38:43.661169: step 212, loss 0.774158, acc 0.546875
2020-02-08T01:38:43.863852: step 213, loss 0.886986, acc 0.578125
2020-02-08T01:38:44.046295: step 214, loss 0.525029, acc 0.75
2020-02-08T01:38:44.234209: step 215, loss 0.782565, acc 0.640625
2020-02-08T01:38:44.421406: step 216, loss 0.982103, acc 0.609375
2020-02-08T01:38:44.612773: step 217, loss 0.7301, acc 0.671875
2020-02-08T01:38:44.795777: step 218, loss 0.737667, acc 0.703125
2020-02-08T01:38:44.989455: step 219, loss 1.04829, acc 0.53125
2020-02-08T01:38:45.172400: step 220, loss 0.954959, acc 0.578125
2020-02-08T01:38:45.345354: step 221, loss 0.959798, acc 0.578125
2020-02-08T01:38:45.535898: step 222, loss 0.940505, acc 0.59375
2020-02-08T01:38:45.720266: step 223, loss 0.896839, acc 0.5
2020-02-08T01:38:45.906225: step 224, loss 0.728989, acc 0.65625
2020-02-08T01:38:46.090126: step 225, loss 1.08138, acc 0.5625
2020-02-08T01:38:46.275993: step 226, loss 1.1684, acc 0.578125
2020-02-08T01:38:46.472140: step 227, loss 0.593786, acc 0.734375
2020-02-08T01:38:46.659478: step 228, loss 0.812534, acc 0.609375
2020-02-08T01:38:46.847797: step 229, loss 0.760084, acc 0.625
2020-02-08T01:38:47.077819: step 230, loss 0.758838, acc 0.546875
2020-02-08T01:38:47.275445: step 231, loss 0.704146, acc 0.671875
2020-02-08T01:38:47.493573: step 232, loss 0.613256, acc 0.65625
2020-02-08T01:38:47.707039: step 233, loss 0.817338, acc 0.625
2020-02-08T01:38:47.892645: step 234, loss 0.697121, acc 0.640625
2020-02-08T01:38:48.077098: step 235, loss 0.828613, acc 0.609375
2020-02-08T01:38:48.265419: step 236, loss 0.854234, acc 0.53125
2020-02-08T01:38:48.459135: step 237, loss 0.780191, acc 0.6875
2020-02-08T01:38:48.661573: step 238, loss 1.07052, acc 0.546875
2020-02-08T01:38:48.857635: step 239, loss 0.761711, acc 0.609375
2020-02-08T01:38:49.065785: step 240, loss 0.861711, acc 0.578125
2020-02-08T01:38:49.277312: step 241, loss 0.774421, acc 0.640625
2020-02-08T01:38:49.465271: step 242, loss 0.958627, acc 0.578125
2020-02-08T01:38:49.666843: step 243, loss 0.791061, acc 0.578125
2020-02-08T01:38:49.849174: step 244, loss 0.807975, acc 0.5625
2020-02-08T01:38:50.044650: step 245, loss 0.891638, acc 0.578125
2020-02-08T01:38:50.231072: step 246, loss 0.875509, acc 0.515625
2020-02-08T01:38:50.417641: step 247, loss 0.75371, acc 0.65625
2020-02-08T01:38:50.624262: step 248, loss 0.777973, acc 0.609375
2020-02-08T01:38:50.800929: step 249, loss 0.846659, acc 0.5
2020-02-08T01:38:50.987606: step 250, loss 0.843461, acc 0.515625
2020-02-08T01:38:51.172665: step 251, loss 0.636513, acc 0.65625
2020-02-08T01:38:51.348331: step 252, loss 0.975141, acc 0.46875
2020-02-08T01:38:51.538346: step 253, loss 0.836738, acc 0.609375
2020-02-08T01:38:51.740009: step 254, loss 0.845029, acc 0.5625
2020-02-08T01:38:51.922651: step 255, loss 0.892048, acc 0.59375
2020-02-08T01:38:52.098184: step 256, loss 0.841648, acc 0.640625
2020-02-08T01:38:52.279899: step 257, loss 0.909273, acc 0.515625
2020-02-08T01:38:52.458779: step 258, loss 0.737487, acc 0.65625
2020-02-08T01:38:52.673815: step 259, loss 0.72786, acc 0.546875
2020-02-08T01:38:52.865313: step 260, loss 0.971706, acc 0.5625
2020-02-08T01:38:53.062028: step 261, loss 0.761036, acc 0.65625
2020-02-08T01:38:53.255066: step 262, loss 0.659785, acc 0.640625
2020-02-08T01:38:53.440699: step 263, loss 0.810944, acc 0.671875
2020-02-08T01:38:53.635005: step 264, loss 0.707532, acc 0.640625
2020-02-08T01:38:53.820782: step 265, loss 0.682807, acc 0.703125
2020-02-08T01:38:54.000410: step 266, loss 0.738723, acc 0.5625
2020-02-08T01:38:54.182467: step 267, loss 0.60687, acc 0.671875
2020-02-08T01:38:54.356812: step 268, loss 0.871291, acc 0.578125
2020-02-08T01:38:54.536467: step 269, loss 0.730432, acc 0.65625
2020-02-08T01:38:54.741026: step 270, loss 0.630006, acc 0.6875
2020-02-08T01:38:54.912862: step 271, loss 0.899204, acc 0.65625
2020-02-08T01:38:55.095034: step 272, loss 0.897675, acc 0.5625
2020-02-08T01:38:55.278097: step 273, loss 0.950058, acc 0.515625
2020-02-08T01:38:55.467355: step 274, loss 0.662965, acc 0.59375
2020-02-08T01:38:55.709716: step 275, loss 0.738085, acc 0.625
2020-02-08T01:38:55.931175: step 276, loss 0.842041, acc 0.59375
2020-02-08T01:38:56.115634: step 277, loss 1.06362, acc 0.453125
2020-02-08T01:38:56.296383: step 278, loss 0.637891, acc 0.671875
2020-02-08T01:38:56.560848: step 279, loss 1.04816, acc 0.515625
2020-02-08T01:38:56.761764: step 280, loss 0.677447, acc 0.71875
2020-02-08T01:38:56.935148: step 281, loss 0.658796, acc 0.6875
2020-02-08T01:38:57.124586: step 282, loss 0.779811, acc 0.609375
2020-02-08T01:38:57.296657: step 283, loss 0.902212, acc 0.515625
2020-02-08T01:38:57.460827: step 284, loss 0.766048, acc 0.59375
2020-02-08T01:38:57.650423: step 285, loss 0.733565, acc 0.625
2020-02-08T01:38:57.832953: step 286, loss 0.915628, acc 0.59375
2020-02-08T01:38:58.021259: step 287, loss 0.737296, acc 0.59375
2020-02-08T01:38:58.205710: step 288, loss 0.779053, acc 0.5625
2020-02-08T01:38:58.417071: step 289, loss 0.772209, acc 0.609375
2020-02-08T01:38:58.738441: step 290, loss 0.919781, acc 0.546875
2020-02-08T01:38:58.942920: step 291, loss 0.790411, acc 0.546875
2020-02-08T01:38:59.133101: step 292, loss 0.864069, acc 0.5625
2020-02-08T01:38:59.314830: step 293, loss 0.859113, acc 0.609375
2020-02-08T01:38:59.497033: step 294, loss 0.63348, acc 0.640625
2020-02-08T01:38:59.682742: step 295, loss 0.633402, acc 0.640625
2020-02-08T01:38:59.862935: step 296, loss 0.820433, acc 0.625
2020-02-08T01:39:00.042911: step 297, loss 0.697797, acc 0.640625
2020-02-08T01:39:00.224992: step 298, loss 0.754412, acc 0.625
2020-02-08T01:39:00.414980: step 299, loss 0.710197, acc 0.609375
2020-02-08T01:39:00.592234: step 300, loss 0.484638, acc 0.7

Evaluation:
2020-02-08T01:39:00.904692: step 300, loss 0.627055, acc 0.650094

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-300

2020-02-08T01:39:02.515845: step 301, loss 0.5637, acc 0.703125
2020-02-08T01:39:02.693781: step 302, loss 0.600357, acc 0.75
2020-02-08T01:39:02.866939: step 303, loss 0.703236, acc 0.625
2020-02-08T01:39:03.053778: step 304, loss 0.620732, acc 0.6875
2020-02-08T01:39:03.237523: step 305, loss 0.686194, acc 0.609375
2020-02-08T01:39:03.417945: step 306, loss 0.658617, acc 0.65625
2020-02-08T01:39:03.613057: step 307, loss 0.558415, acc 0.703125
2020-02-08T01:39:03.787786: step 308, loss 0.682599, acc 0.578125
2020-02-08T01:39:03.963691: step 309, loss 0.558239, acc 0.6875
2020-02-08T01:39:04.133536: step 310, loss 0.719403, acc 0.59375
2020-02-08T01:39:04.315466: step 311, loss 0.568771, acc 0.75
2020-02-08T01:39:04.485845: step 312, loss 0.637819, acc 0.71875
2020-02-08T01:39:04.667176: step 313, loss 0.574237, acc 0.703125
2020-02-08T01:39:04.843157: step 314, loss 0.607861, acc 0.71875
2020-02-08T01:39:05.017157: step 315, loss 0.6064, acc 0.671875
2020-02-08T01:39:05.205924: step 316, loss 0.631231, acc 0.671875
2020-02-08T01:39:05.433893: step 317, loss 0.600327, acc 0.703125
2020-02-08T01:39:05.624778: step 318, loss 0.770804, acc 0.59375
2020-02-08T01:39:05.837290: step 319, loss 0.662845, acc 0.671875
2020-02-08T01:39:06.013879: step 320, loss 0.689956, acc 0.609375
2020-02-08T01:39:06.198417: step 321, loss 0.707018, acc 0.59375
2020-02-08T01:39:06.370407: step 322, loss 0.634893, acc 0.625
2020-02-08T01:39:06.535605: step 323, loss 0.526248, acc 0.75
2020-02-08T01:39:06.715841: step 324, loss 0.69128, acc 0.609375
2020-02-08T01:39:06.889026: step 325, loss 0.704876, acc 0.65625
2020-02-08T01:39:07.062988: step 326, loss 0.721764, acc 0.640625
2020-02-08T01:39:07.241618: step 327, loss 0.702894, acc 0.65625
2020-02-08T01:39:07.412280: step 328, loss 0.613448, acc 0.75
2020-02-08T01:39:07.591615: step 329, loss 0.73516, acc 0.578125
2020-02-08T01:39:07.778420: step 330, loss 0.85444, acc 0.59375
2020-02-08T01:39:07.946818: step 331, loss 0.71546, acc 0.625
2020-02-08T01:39:08.119730: step 332, loss 0.723375, acc 0.625
2020-02-08T01:39:08.294761: step 333, loss 0.646433, acc 0.640625
2020-02-08T01:39:08.472983: step 334, loss 0.52296, acc 0.78125
2020-02-08T01:39:08.659573: step 335, loss 0.758697, acc 0.609375
2020-02-08T01:39:08.864400: step 336, loss 0.626598, acc 0.640625
2020-02-08T01:39:09.107168: step 337, loss 0.768402, acc 0.5625
2020-02-08T01:39:09.386878: step 338, loss 0.611584, acc 0.734375
2020-02-08T01:39:09.561427: step 339, loss 0.715618, acc 0.640625
2020-02-08T01:39:09.739301: step 340, loss 0.677504, acc 0.6875
2020-02-08T01:39:09.922040: step 341, loss 0.541643, acc 0.75
2020-02-08T01:39:10.118076: step 342, loss 0.438167, acc 0.796875
2020-02-08T01:39:10.291129: step 343, loss 0.554995, acc 0.765625
2020-02-08T01:39:10.467651: step 344, loss 0.668006, acc 0.703125
2020-02-08T01:39:10.649816: step 345, loss 0.592663, acc 0.75
2020-02-08T01:39:10.821368: step 346, loss 0.588356, acc 0.6875
2020-02-08T01:39:11.001921: step 347, loss 0.672676, acc 0.609375
2020-02-08T01:39:11.193098: step 348, loss 0.622268, acc 0.65625
2020-02-08T01:39:11.381538: step 349, loss 0.45611, acc 0.78125
2020-02-08T01:39:11.569088: step 350, loss 0.729691, acc 0.609375
2020-02-08T01:39:11.748484: step 351, loss 0.56397, acc 0.65625
2020-02-08T01:39:11.917011: step 352, loss 0.669235, acc 0.609375
2020-02-08T01:39:12.090075: step 353, loss 0.570107, acc 0.71875
2020-02-08T01:39:12.276358: step 354, loss 0.632332, acc 0.65625
2020-02-08T01:39:12.462912: step 355, loss 0.446529, acc 0.765625
2020-02-08T01:39:12.652631: step 356, loss 0.813933, acc 0.515625
2020-02-08T01:39:12.840266: step 357, loss 0.754892, acc 0.609375
2020-02-08T01:39:13.020395: step 358, loss 0.449028, acc 0.765625
2020-02-08T01:39:13.204819: step 359, loss 0.756442, acc 0.59375
2020-02-08T01:39:13.389224: step 360, loss 0.584883, acc 0.65625
2020-02-08T01:39:13.581660: step 361, loss 0.752487, acc 0.515625
2020-02-08T01:39:13.767760: step 362, loss 0.610729, acc 0.671875
2020-02-08T01:39:13.942548: step 363, loss 0.685898, acc 0.625
2020-02-08T01:39:14.125784: step 364, loss 0.720301, acc 0.640625
2020-02-08T01:39:14.338781: step 365, loss 0.572971, acc 0.65625
2020-02-08T01:39:14.537911: step 366, loss 0.647684, acc 0.703125
2020-02-08T01:39:14.778434: step 367, loss 0.462326, acc 0.828125
2020-02-08T01:39:14.939224: step 368, loss 0.65105, acc 0.671875
2020-02-08T01:39:15.100895: step 369, loss 0.726789, acc 0.625
2020-02-08T01:39:15.274827: step 370, loss 0.604799, acc 0.703125
2020-02-08T01:39:15.450918: step 371, loss 0.786281, acc 0.65625
2020-02-08T01:39:15.622214: step 372, loss 0.779336, acc 0.59375
2020-02-08T01:39:15.803809: step 373, loss 0.619411, acc 0.625
2020-02-08T01:39:15.984073: step 374, loss 0.679482, acc 0.609375
2020-02-08T01:39:16.151914: step 375, loss 0.606524, acc 0.734375
2020-02-08T01:39:16.330933: step 376, loss 0.546212, acc 0.734375
2020-02-08T01:39:16.519065: step 377, loss 0.650494, acc 0.703125
2020-02-08T01:39:16.697054: step 378, loss 0.612723, acc 0.6875
2020-02-08T01:39:16.881515: step 379, loss 0.743793, acc 0.578125
2020-02-08T01:39:17.076224: step 380, loss 0.600616, acc 0.703125
2020-02-08T01:39:17.244763: step 381, loss 0.673426, acc 0.640625
2020-02-08T01:39:17.420299: step 382, loss 0.564337, acc 0.75
2020-02-08T01:39:17.595428: step 383, loss 0.632373, acc 0.640625
2020-02-08T01:39:17.771060: step 384, loss 0.682489, acc 0.5625
2020-02-08T01:39:17.953744: step 385, loss 0.732945, acc 0.578125
2020-02-08T01:39:18.140945: step 386, loss 0.665183, acc 0.703125
2020-02-08T01:39:18.324775: step 387, loss 0.571847, acc 0.671875
2020-02-08T01:39:18.546780: step 388, loss 0.714346, acc 0.625
2020-02-08T01:39:18.768329: step 389, loss 0.739633, acc 0.625
2020-02-08T01:39:18.968472: step 390, loss 0.636455, acc 0.609375
2020-02-08T01:39:19.159680: step 391, loss 0.891029, acc 0.5625
2020-02-08T01:39:19.364175: step 392, loss 0.61917, acc 0.734375
2020-02-08T01:39:19.556252: step 393, loss 0.594649, acc 0.625
2020-02-08T01:39:19.746534: step 394, loss 0.627118, acc 0.703125
2020-02-08T01:39:19.932034: step 395, loss 0.803003, acc 0.578125
2020-02-08T01:39:20.144749: step 396, loss 0.648602, acc 0.546875
2020-02-08T01:39:20.337810: step 397, loss 0.59108, acc 0.65625
2020-02-08T01:39:20.516393: step 398, loss 0.799966, acc 0.5625
2020-02-08T01:39:20.708517: step 399, loss 0.675774, acc 0.59375
2020-02-08T01:39:20.903784: step 400, loss 0.766935, acc 0.6875

Evaluation:
2020-02-08T01:39:21.237057: step 400, loss 0.665228, acc 0.60788

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-400

2020-02-08T01:39:22.846982: step 401, loss 0.537607, acc 0.765625
2020-02-08T01:39:23.078923: step 402, loss 0.586604, acc 0.703125
2020-02-08T01:39:23.262989: step 403, loss 0.749587, acc 0.640625
2020-02-08T01:39:23.478384: step 404, loss 0.46914, acc 0.765625
2020-02-08T01:39:23.687112: step 405, loss 0.551638, acc 0.765625
2020-02-08T01:39:23.874976: step 406, loss 0.653237, acc 0.625
2020-02-08T01:39:24.063428: step 407, loss 0.672734, acc 0.671875
2020-02-08T01:39:24.248269: step 408, loss 0.783326, acc 0.5625
2020-02-08T01:39:24.459625: step 409, loss 0.67919, acc 0.640625
2020-02-08T01:39:24.700017: step 410, loss 0.582958, acc 0.75
2020-02-08T01:39:24.892807: step 411, loss 0.605179, acc 0.703125
2020-02-08T01:39:25.082397: step 412, loss 0.643718, acc 0.703125
2020-02-08T01:39:25.267949: step 413, loss 0.767158, acc 0.609375
2020-02-08T01:39:25.455614: step 414, loss 0.778782, acc 0.578125
2020-02-08T01:39:25.647383: step 415, loss 0.624219, acc 0.6875
2020-02-08T01:39:25.829555: step 416, loss 0.617486, acc 0.6875
2020-02-08T01:39:26.009449: step 417, loss 0.639214, acc 0.59375
2020-02-08T01:39:26.205240: step 418, loss 0.532415, acc 0.78125
2020-02-08T01:39:26.387314: step 419, loss 0.608862, acc 0.734375
2020-02-08T01:39:26.576725: step 420, loss 0.715393, acc 0.65625
2020-02-08T01:39:26.748652: step 421, loss 0.668498, acc 0.65625
2020-02-08T01:39:26.912415: step 422, loss 0.656979, acc 0.71875
2020-02-08T01:39:27.090846: step 423, loss 0.730401, acc 0.53125
2020-02-08T01:39:27.272982: step 424, loss 0.639875, acc 0.671875
2020-02-08T01:39:27.446927: step 425, loss 0.630164, acc 0.671875
2020-02-08T01:39:27.638336: step 426, loss 0.569434, acc 0.71875
2020-02-08T01:39:27.824428: step 427, loss 0.573576, acc 0.734375
2020-02-08T01:39:28.001944: step 428, loss 0.746379, acc 0.640625
2020-02-08T01:39:28.195377: step 429, loss 0.626511, acc 0.640625
2020-02-08T01:39:28.383235: step 430, loss 0.521139, acc 0.6875
2020-02-08T01:39:28.580031: step 431, loss 0.614583, acc 0.671875
2020-02-08T01:39:28.762014: step 432, loss 0.672856, acc 0.59375
2020-02-08T01:39:28.942901: step 433, loss 0.560299, acc 0.6875
2020-02-08T01:39:29.143986: step 434, loss 0.689061, acc 0.578125
2020-02-08T01:39:29.332847: step 435, loss 0.595211, acc 0.671875
2020-02-08T01:39:29.513343: step 436, loss 0.617406, acc 0.71875
2020-02-08T01:39:29.697193: step 437, loss 0.659285, acc 0.625
2020-02-08T01:39:29.881388: step 438, loss 0.599326, acc 0.65625
2020-02-08T01:39:30.076272: step 439, loss 0.552802, acc 0.703125
2020-02-08T01:39:30.258406: step 440, loss 0.614387, acc 0.671875
2020-02-08T01:39:30.438505: step 441, loss 0.574705, acc 0.6875
2020-02-08T01:39:30.644816: step 442, loss 0.651455, acc 0.640625
2020-02-08T01:39:30.833828: step 443, loss 0.67338, acc 0.609375
2020-02-08T01:39:31.024788: step 444, loss 0.543645, acc 0.765625
2020-02-08T01:39:31.204044: step 445, loss 0.634572, acc 0.59375
2020-02-08T01:39:31.392688: step 446, loss 0.572596, acc 0.71875
2020-02-08T01:39:31.583963: step 447, loss 0.586024, acc 0.640625
2020-02-08T01:39:31.789272: step 448, loss 0.696698, acc 0.671875
2020-02-08T01:39:31.970759: step 449, loss 0.637355, acc 0.640625
2020-02-08T01:39:32.146660: step 450, loss 0.664626, acc 0.6
2020-02-08T01:39:32.332414: step 451, loss 0.591379, acc 0.625
2020-02-08T01:39:32.514745: step 452, loss 0.608056, acc 0.71875
2020-02-08T01:39:32.709387: step 453, loss 0.663887, acc 0.703125
2020-02-08T01:39:32.896561: step 454, loss 0.600867, acc 0.71875
2020-02-08T01:39:33.090430: step 455, loss 0.565814, acc 0.6875
2020-02-08T01:39:33.278647: step 456, loss 0.487764, acc 0.734375
2020-02-08T01:39:33.462248: step 457, loss 0.481989, acc 0.78125
2020-02-08T01:39:33.677162: step 458, loss 0.631391, acc 0.703125
2020-02-08T01:39:33.970298: step 459, loss 0.581838, acc 0.65625
2020-02-08T01:39:34.195951: step 460, loss 0.556469, acc 0.671875
2020-02-08T01:39:34.364669: step 461, loss 0.546351, acc 0.703125
2020-02-08T01:39:34.586878: step 462, loss 0.587535, acc 0.625
2020-02-08T01:39:34.779661: step 463, loss 0.607199, acc 0.6875
2020-02-08T01:39:34.958861: step 464, loss 0.662364, acc 0.640625
2020-02-08T01:39:35.145901: step 465, loss 0.535796, acc 0.71875
2020-02-08T01:39:35.329839: step 466, loss 0.61097, acc 0.625
2020-02-08T01:39:35.505409: step 467, loss 0.640745, acc 0.640625
2020-02-08T01:39:35.698619: step 468, loss 0.666048, acc 0.671875
2020-02-08T01:39:35.870087: step 469, loss 0.486796, acc 0.78125
2020-02-08T01:39:36.054542: step 470, loss 0.616769, acc 0.6875
2020-02-08T01:39:36.236940: step 471, loss 0.614562, acc 0.609375
2020-02-08T01:39:36.419138: step 472, loss 0.545937, acc 0.734375
2020-02-08T01:39:36.597129: step 473, loss 0.493828, acc 0.828125
2020-02-08T01:39:36.774244: step 474, loss 0.565966, acc 0.640625
2020-02-08T01:39:36.963828: step 475, loss 0.588171, acc 0.71875
2020-02-08T01:39:37.140122: step 476, loss 0.58413, acc 0.6875
2020-02-08T01:39:37.312073: step 477, loss 0.529346, acc 0.703125
2020-02-08T01:39:37.494567: step 478, loss 0.445877, acc 0.84375
2020-02-08T01:39:37.683070: step 479, loss 0.548899, acc 0.703125
2020-02-08T01:39:37.865133: step 480, loss 0.544891, acc 0.6875
2020-02-08T01:39:38.052464: step 481, loss 0.597033, acc 0.703125
2020-02-08T01:39:38.231504: step 482, loss 0.552482, acc 0.734375
2020-02-08T01:39:38.426526: step 483, loss 0.521988, acc 0.765625
2020-02-08T01:39:38.616328: step 484, loss 0.647686, acc 0.671875
2020-02-08T01:39:38.800646: step 485, loss 0.53218, acc 0.8125
2020-02-08T01:39:38.989009: step 486, loss 0.58085, acc 0.65625
2020-02-08T01:39:39.294825: step 487, loss 0.477353, acc 0.75
2020-02-08T01:39:39.558466: step 488, loss 0.56364, acc 0.65625
2020-02-08T01:39:39.756520: step 489, loss 0.468457, acc 0.75
2020-02-08T01:39:39.950941: step 490, loss 0.504724, acc 0.765625
2020-02-08T01:39:40.134286: step 491, loss 0.54879, acc 0.765625
2020-02-08T01:39:40.317943: step 492, loss 0.540623, acc 0.734375
2020-02-08T01:39:40.488271: step 493, loss 0.61583, acc 0.671875
2020-02-08T01:39:40.682227: step 494, loss 0.472122, acc 0.8125
2020-02-08T01:39:40.856437: step 495, loss 0.558668, acc 0.71875
2020-02-08T01:39:41.033329: step 496, loss 0.597223, acc 0.71875
2020-02-08T01:39:41.204741: step 497, loss 0.500813, acc 0.78125
2020-02-08T01:39:41.384904: step 498, loss 0.451665, acc 0.828125
2020-02-08T01:39:41.568756: step 499, loss 0.626316, acc 0.6875
2020-02-08T01:39:41.742946: step 500, loss 0.598343, acc 0.6875

Evaluation:
2020-02-08T01:39:42.056571: step 500, loss 0.612061, acc 0.651032

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-500

2020-02-08T01:39:43.654824: step 501, loss 0.581068, acc 0.65625
2020-02-08T01:39:43.850362: step 502, loss 0.683632, acc 0.640625
2020-02-08T01:39:44.042486: step 503, loss 0.60325, acc 0.65625
2020-02-08T01:39:44.230308: step 504, loss 0.583829, acc 0.6875
2020-02-08T01:39:44.413500: step 505, loss 0.466409, acc 0.8125
2020-02-08T01:39:44.606464: step 506, loss 0.624531, acc 0.671875
2020-02-08T01:39:44.795039: step 507, loss 0.645286, acc 0.59375
2020-02-08T01:39:44.987140: step 508, loss 0.447382, acc 0.828125
2020-02-08T01:39:45.184467: step 509, loss 0.708201, acc 0.640625
2020-02-08T01:39:45.376715: step 510, loss 0.671673, acc 0.640625
2020-02-08T01:39:45.584042: step 511, loss 0.627252, acc 0.703125
2020-02-08T01:39:45.778410: step 512, loss 0.672042, acc 0.59375
2020-02-08T01:39:45.984220: step 513, loss 0.632945, acc 0.671875
2020-02-08T01:39:46.189991: step 514, loss 0.626351, acc 0.671875
2020-02-08T01:39:46.392192: step 515, loss 0.70065, acc 0.671875
2020-02-08T01:39:46.589151: step 516, loss 0.558068, acc 0.71875
2020-02-08T01:39:46.778138: step 517, loss 0.569539, acc 0.71875
2020-02-08T01:39:46.963214: step 518, loss 0.43321, acc 0.8125
2020-02-08T01:39:47.143793: step 519, loss 0.531083, acc 0.78125
2020-02-08T01:39:47.324275: step 520, loss 0.623567, acc 0.65625
2020-02-08T01:39:47.527448: step 521, loss 0.505004, acc 0.8125
2020-02-08T01:39:47.740590: step 522, loss 0.581653, acc 0.6875
2020-02-08T01:39:47.936682: step 523, loss 0.509301, acc 0.734375
2020-02-08T01:39:48.128581: step 524, loss 0.546847, acc 0.671875
2020-02-08T01:39:48.320300: step 525, loss 0.603948, acc 0.671875
2020-02-08T01:39:48.519374: step 526, loss 0.528889, acc 0.8125
2020-02-08T01:39:48.727397: step 527, loss 0.462029, acc 0.75
2020-02-08T01:39:48.934992: step 528, loss 0.644579, acc 0.640625
2020-02-08T01:39:49.154795: step 529, loss 0.53762, acc 0.6875
2020-02-08T01:39:49.355145: step 530, loss 0.491555, acc 0.71875
2020-02-08T01:39:49.539041: step 531, loss 0.787644, acc 0.59375
2020-02-08T01:39:49.736851: step 532, loss 0.579683, acc 0.71875
2020-02-08T01:39:49.934702: step 533, loss 0.567624, acc 0.75
2020-02-08T01:39:50.125010: step 534, loss 0.459207, acc 0.796875
2020-02-08T01:39:50.313309: step 535, loss 0.529971, acc 0.78125
2020-02-08T01:39:50.498617: step 536, loss 0.655495, acc 0.65625
2020-02-08T01:39:50.717021: step 537, loss 0.552441, acc 0.734375
2020-02-08T01:39:50.919180: step 538, loss 0.65381, acc 0.65625
2020-02-08T01:39:51.104796: step 539, loss 0.622962, acc 0.671875
2020-02-08T01:39:51.299435: step 540, loss 0.544334, acc 0.71875
2020-02-08T01:39:51.487384: step 541, loss 0.540027, acc 0.765625
2020-02-08T01:39:51.776617: step 542, loss 0.581822, acc 0.640625
2020-02-08T01:39:51.989718: step 543, loss 0.447374, acc 0.75
2020-02-08T01:39:52.187168: step 544, loss 0.566188, acc 0.734375
2020-02-08T01:39:52.378738: step 545, loss 0.479859, acc 0.71875
2020-02-08T01:39:52.585203: step 546, loss 0.582105, acc 0.703125
2020-02-08T01:39:52.764259: step 547, loss 0.548907, acc 0.703125
2020-02-08T01:39:52.960056: step 548, loss 0.585873, acc 0.703125
2020-02-08T01:39:53.158362: step 549, loss 0.614338, acc 0.6875
2020-02-08T01:39:53.363831: step 550, loss 0.515313, acc 0.734375
2020-02-08T01:39:53.557545: step 551, loss 0.479793, acc 0.75
2020-02-08T01:39:53.747637: step 552, loss 0.575975, acc 0.703125
2020-02-08T01:39:53.937850: step 553, loss 0.579856, acc 0.765625
2020-02-08T01:39:54.127022: step 554, loss 0.530709, acc 0.75
2020-02-08T01:39:54.323056: step 555, loss 0.512687, acc 0.734375
2020-02-08T01:39:54.505004: step 556, loss 0.737561, acc 0.5625
2020-02-08T01:39:54.696037: step 557, loss 0.519717, acc 0.75
2020-02-08T01:39:54.887738: step 558, loss 0.580771, acc 0.703125
2020-02-08T01:39:55.073992: step 559, loss 0.632569, acc 0.625
2020-02-08T01:39:55.276139: step 560, loss 0.773078, acc 0.59375
2020-02-08T01:39:55.462727: step 561, loss 0.47715, acc 0.78125
2020-02-08T01:39:55.659784: step 562, loss 0.482372, acc 0.8125
2020-02-08T01:39:55.857378: step 563, loss 0.531394, acc 0.734375
2020-02-08T01:39:56.058634: step 564, loss 0.495383, acc 0.765625
2020-02-08T01:39:56.249570: step 565, loss 0.618636, acc 0.625
2020-02-08T01:39:56.447800: step 566, loss 0.468481, acc 0.78125
2020-02-08T01:39:56.648588: step 567, loss 0.655262, acc 0.546875
2020-02-08T01:39:56.836419: step 568, loss 0.497608, acc 0.78125
2020-02-08T01:39:57.028744: step 569, loss 0.622013, acc 0.625
2020-02-08T01:39:57.212659: step 570, loss 0.579909, acc 0.671875
2020-02-08T01:39:57.430849: step 571, loss 0.540519, acc 0.734375
2020-02-08T01:39:57.631098: step 572, loss 0.514235, acc 0.765625
2020-02-08T01:39:57.813409: step 573, loss 0.616452, acc 0.640625
2020-02-08T01:39:57.992898: step 574, loss 0.511159, acc 0.703125
2020-02-08T01:39:58.176550: step 575, loss 0.542875, acc 0.671875
2020-02-08T01:39:58.357577: step 576, loss 0.491388, acc 0.734375
2020-02-08T01:39:58.546071: step 577, loss 0.520328, acc 0.828125
2020-02-08T01:39:58.739589: step 578, loss 0.647833, acc 0.65625
2020-02-08T01:39:58.924338: step 579, loss 0.488274, acc 0.75
2020-02-08T01:39:59.126407: step 580, loss 0.569611, acc 0.71875
2020-02-08T01:39:59.304637: step 581, loss 0.45469, acc 0.78125
2020-02-08T01:39:59.489630: step 582, loss 0.524623, acc 0.6875
2020-02-08T01:39:59.679693: step 583, loss 0.510511, acc 0.75
2020-02-08T01:39:59.861345: step 584, loss 0.634151, acc 0.65625
2020-02-08T01:40:00.052254: step 585, loss 0.484568, acc 0.78125
2020-02-08T01:40:00.243820: step 586, loss 0.514295, acc 0.765625
2020-02-08T01:40:00.436175: step 587, loss 0.518663, acc 0.71875
2020-02-08T01:40:00.644493: step 588, loss 0.582185, acc 0.703125
2020-02-08T01:40:00.834997: step 589, loss 0.495297, acc 0.71875
2020-02-08T01:40:01.038167: step 590, loss 0.621958, acc 0.65625
2020-02-08T01:40:01.231943: step 591, loss 0.643961, acc 0.609375
2020-02-08T01:40:01.418798: step 592, loss 0.597919, acc 0.6875
2020-02-08T01:40:01.626330: step 593, loss 0.436764, acc 0.828125
2020-02-08T01:40:01.813999: step 594, loss 0.503222, acc 0.734375
2020-02-08T01:40:02.007935: step 595, loss 0.558218, acc 0.65625
2020-02-08T01:40:02.206657: step 596, loss 0.670022, acc 0.65625
2020-02-08T01:40:02.393391: step 597, loss 0.564798, acc 0.734375
2020-02-08T01:40:02.596507: step 598, loss 0.586507, acc 0.6875
2020-02-08T01:40:02.793478: step 599, loss 0.581288, acc 0.671875
2020-02-08T01:40:02.976693: step 600, loss 0.51005, acc 0.75

Evaluation:
2020-02-08T01:40:03.287495: step 600, loss 0.679631, acc 0.602251

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-600

2020-02-08T01:40:04.881122: step 601, loss 0.567244, acc 0.71875
2020-02-08T01:40:05.076004: step 602, loss 0.562033, acc 0.6875
2020-02-08T01:40:05.260098: step 603, loss 0.509054, acc 0.75
2020-02-08T01:40:05.439211: step 604, loss 0.554079, acc 0.765625
2020-02-08T01:40:05.636807: step 605, loss 0.494516, acc 0.75
2020-02-08T01:40:05.828892: step 606, loss 0.500285, acc 0.71875
2020-02-08T01:40:06.020129: step 607, loss 0.529764, acc 0.75
2020-02-08T01:40:06.217458: step 608, loss 0.56211, acc 0.6875
2020-02-08T01:40:06.407981: step 609, loss 0.574346, acc 0.703125
2020-02-08T01:40:06.606628: step 610, loss 0.470115, acc 0.796875
2020-02-08T01:40:06.802385: step 611, loss 0.509121, acc 0.78125
2020-02-08T01:40:07.001052: step 612, loss 0.389141, acc 0.828125
2020-02-08T01:40:07.192542: step 613, loss 0.488268, acc 0.765625
2020-02-08T01:40:07.384241: step 614, loss 0.611055, acc 0.6875
2020-02-08T01:40:07.584350: step 615, loss 0.608082, acc 0.65625
2020-02-08T01:40:07.778748: step 616, loss 0.44373, acc 0.796875
2020-02-08T01:40:07.984986: step 617, loss 0.5806, acc 0.609375
2020-02-08T01:40:08.187016: step 618, loss 0.558628, acc 0.71875
2020-02-08T01:40:08.390809: step 619, loss 0.505842, acc 0.734375
2020-02-08T01:40:08.600060: step 620, loss 0.565405, acc 0.734375
2020-02-08T01:40:08.796827: step 621, loss 0.463128, acc 0.78125
2020-02-08T01:40:08.998043: step 622, loss 0.482081, acc 0.78125
2020-02-08T01:40:09.188057: step 623, loss 0.433628, acc 0.828125
2020-02-08T01:40:09.376539: step 624, loss 0.514268, acc 0.796875
2020-02-08T01:40:09.570502: step 625, loss 0.422053, acc 0.796875
2020-02-08T01:40:09.760455: step 626, loss 0.493047, acc 0.8125
2020-02-08T01:40:09.939727: step 627, loss 0.397698, acc 0.828125
2020-02-08T01:40:10.288693: step 628, loss 0.583635, acc 0.734375
2020-02-08T01:40:10.781564: step 629, loss 0.666431, acc 0.671875
2020-02-08T01:40:11.005885: step 630, loss 0.472658, acc 0.765625
2020-02-08T01:40:11.301685: step 631, loss 0.469281, acc 0.78125
2020-02-08T01:40:11.510182: step 632, loss 0.44774, acc 0.796875
2020-02-08T01:40:11.727591: step 633, loss 0.529753, acc 0.75
2020-02-08T01:40:11.885655: step 634, loss 0.560283, acc 0.734375
2020-02-08T01:40:12.119129: step 635, loss 0.544861, acc 0.6875
2020-02-08T01:40:12.305467: step 636, loss 0.545635, acc 0.71875
2020-02-08T01:40:12.486884: step 637, loss 0.586661, acc 0.609375
2020-02-08T01:40:12.704837: step 638, loss 0.48482, acc 0.75
2020-02-08T01:40:12.927761: step 639, loss 0.524496, acc 0.71875
2020-02-08T01:40:13.138946: step 640, loss 0.508996, acc 0.796875
2020-02-08T01:40:13.404479: step 641, loss 0.564164, acc 0.75
2020-02-08T01:40:13.687838: step 642, loss 0.466755, acc 0.75
2020-02-08T01:40:13.923034: step 643, loss 0.546231, acc 0.671875
2020-02-08T01:40:14.146794: step 644, loss 0.447793, acc 0.8125
2020-02-08T01:40:14.357732: step 645, loss 0.571859, acc 0.65625
2020-02-08T01:40:14.632767: step 646, loss 0.505033, acc 0.734375
2020-02-08T01:40:14.837508: step 647, loss 0.482077, acc 0.734375
2020-02-08T01:40:15.082577: step 648, loss 0.590868, acc 0.703125
2020-02-08T01:40:15.296468: step 649, loss 0.514758, acc 0.75
2020-02-08T01:40:15.502899: step 650, loss 0.507723, acc 0.703125
2020-02-08T01:40:15.825545: step 651, loss 0.388212, acc 0.828125
2020-02-08T01:40:16.156466: step 652, loss 0.498787, acc 0.75
2020-02-08T01:40:16.338887: step 653, loss 0.478314, acc 0.796875
2020-02-08T01:40:16.533981: step 654, loss 0.388084, acc 0.859375
2020-02-08T01:40:16.744488: step 655, loss 0.542752, acc 0.671875
2020-02-08T01:40:17.133289: step 656, loss 0.562465, acc 0.734375
2020-02-08T01:40:17.444193: step 657, loss 0.467304, acc 0.765625
2020-02-08T01:40:17.686293: step 658, loss 0.598702, acc 0.6875
2020-02-08T01:40:17.883946: step 659, loss 0.377427, acc 0.8125
2020-02-08T01:40:18.172087: step 660, loss 0.532582, acc 0.703125
2020-02-08T01:40:18.383294: step 661, loss 0.62042, acc 0.65625
2020-02-08T01:40:18.538922: step 662, loss 0.34205, acc 0.84375
2020-02-08T01:40:18.715366: step 663, loss 0.531353, acc 0.6875
2020-02-08T01:40:18.877866: step 664, loss 0.489612, acc 0.734375
2020-02-08T01:40:19.045354: step 665, loss 0.443157, acc 0.828125
2020-02-08T01:40:19.194588: step 666, loss 0.535722, acc 0.65625
2020-02-08T01:40:19.352602: step 667, loss 0.522855, acc 0.734375
2020-02-08T01:40:19.531367: step 668, loss 0.493944, acc 0.75
2020-02-08T01:40:19.793222: step 669, loss 0.546467, acc 0.71875
2020-02-08T01:40:19.991605: step 670, loss 0.466191, acc 0.8125
2020-02-08T01:40:20.144534: step 671, loss 0.64665, acc 0.6875
2020-02-08T01:40:20.344161: step 672, loss 0.44293, acc 0.765625
2020-02-08T01:40:20.594528: step 673, loss 0.595201, acc 0.71875
2020-02-08T01:40:20.840949: step 674, loss 0.486962, acc 0.734375
2020-02-08T01:40:21.072408: step 675, loss 0.681046, acc 0.671875
2020-02-08T01:40:21.241748: step 676, loss 0.601083, acc 0.71875
2020-02-08T01:40:21.427312: step 677, loss 0.514346, acc 0.6875
2020-02-08T01:40:21.686939: step 678, loss 0.472645, acc 0.796875
2020-02-08T01:40:21.869521: step 679, loss 0.66528, acc 0.640625
2020-02-08T01:40:22.038485: step 680, loss 0.642622, acc 0.671875
2020-02-08T01:40:22.221307: step 681, loss 0.389408, acc 0.84375
2020-02-08T01:40:22.418640: step 682, loss 0.508508, acc 0.75
2020-02-08T01:40:22.622539: step 683, loss 0.577614, acc 0.671875
2020-02-08T01:40:22.811709: step 684, loss 0.645883, acc 0.6875
2020-02-08T01:40:23.025810: step 685, loss 0.497246, acc 0.796875
2020-02-08T01:40:23.218278: step 686, loss 0.505803, acc 0.71875
2020-02-08T01:40:23.389979: step 687, loss 0.746741, acc 0.65625
2020-02-08T01:40:23.624970: step 688, loss 0.517477, acc 0.71875
2020-02-08T01:40:23.806560: step 689, loss 0.428217, acc 0.828125
2020-02-08T01:40:23.994929: step 690, loss 0.575886, acc 0.703125
2020-02-08T01:40:24.259848: step 691, loss 0.454731, acc 0.796875
2020-02-08T01:40:24.484570: step 692, loss 0.430609, acc 0.78125
2020-02-08T01:40:24.702602: step 693, loss 0.535631, acc 0.734375
2020-02-08T01:40:24.894112: step 694, loss 0.453028, acc 0.734375
2020-02-08T01:40:25.163559: step 695, loss 0.407415, acc 0.796875
2020-02-08T01:40:25.369548: step 696, loss 0.58224, acc 0.71875
2020-02-08T01:40:25.590115: step 697, loss 0.466155, acc 0.78125
2020-02-08T01:40:25.783592: step 698, loss 0.528843, acc 0.78125
2020-02-08T01:40:25.968492: step 699, loss 0.56449, acc 0.734375
2020-02-08T01:40:26.143827: step 700, loss 0.534076, acc 0.734375

Evaluation:
2020-02-08T01:40:26.477710: step 700, loss 0.592568, acc 0.679174

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-700

2020-02-08T01:40:28.114163: step 701, loss 0.48483, acc 0.765625
2020-02-08T01:40:28.288581: step 702, loss 0.476443, acc 0.78125
2020-02-08T01:40:28.460307: step 703, loss 0.602009, acc 0.6875
2020-02-08T01:40:28.639442: step 704, loss 0.430896, acc 0.84375
2020-02-08T01:40:28.829543: step 705, loss 0.379304, acc 0.8125
2020-02-08T01:40:29.059437: step 706, loss 0.516555, acc 0.703125
2020-02-08T01:40:29.262937: step 707, loss 0.467661, acc 0.828125
2020-02-08T01:40:29.475912: step 708, loss 0.512461, acc 0.78125
2020-02-08T01:40:29.659670: step 709, loss 0.739973, acc 0.671875
2020-02-08T01:40:29.836137: step 710, loss 0.462114, acc 0.765625
2020-02-08T01:40:30.067405: step 711, loss 0.497385, acc 0.765625
2020-02-08T01:40:30.277408: step 712, loss 0.550448, acc 0.6875
2020-02-08T01:40:30.448134: step 713, loss 0.45831, acc 0.75
2020-02-08T01:40:30.636671: step 714, loss 0.419405, acc 0.78125
2020-02-08T01:40:30.807628: step 715, loss 0.551416, acc 0.703125
2020-02-08T01:40:30.981252: step 716, loss 0.557345, acc 0.703125
2020-02-08T01:40:31.162233: step 717, loss 0.478086, acc 0.765625
2020-02-08T01:40:31.343677: step 718, loss 0.477307, acc 0.765625
2020-02-08T01:40:31.540464: step 719, loss 0.443148, acc 0.78125
2020-02-08T01:40:31.760776: step 720, loss 0.40403, acc 0.796875
2020-02-08T01:40:31.947946: step 721, loss 0.427089, acc 0.796875
2020-02-08T01:40:32.144241: step 722, loss 0.545687, acc 0.734375
2020-02-08T01:40:32.333420: step 723, loss 0.572655, acc 0.6875
2020-02-08T01:40:32.539210: step 724, loss 0.461499, acc 0.8125
2020-02-08T01:40:32.759646: step 725, loss 0.6241, acc 0.6875
2020-02-08T01:40:32.960029: step 726, loss 0.530487, acc 0.734375
2020-02-08T01:40:33.146193: step 727, loss 0.617223, acc 0.71875
2020-02-08T01:40:33.340822: step 728, loss 0.41398, acc 0.828125
2020-02-08T01:40:33.539997: step 729, loss 0.545511, acc 0.703125
2020-02-08T01:40:33.746871: step 730, loss 0.596452, acc 0.71875
2020-02-08T01:40:33.940991: step 731, loss 0.480824, acc 0.796875
2020-02-08T01:40:34.133518: step 732, loss 0.482159, acc 0.75
2020-02-08T01:40:34.323938: step 733, loss 0.430292, acc 0.78125
2020-02-08T01:40:34.501785: step 734, loss 0.433556, acc 0.796875
2020-02-08T01:40:34.710020: step 735, loss 0.497584, acc 0.78125
2020-02-08T01:40:34.882428: step 736, loss 0.463267, acc 0.796875
2020-02-08T01:40:35.065502: step 737, loss 0.607662, acc 0.671875
2020-02-08T01:40:35.244650: step 738, loss 0.499792, acc 0.78125
2020-02-08T01:40:35.416462: step 739, loss 0.492329, acc 0.765625
2020-02-08T01:40:35.728077: step 740, loss 0.465923, acc 0.796875
2020-02-08T01:40:36.001169: step 741, loss 0.527944, acc 0.765625
2020-02-08T01:40:36.208623: step 742, loss 0.490154, acc 0.75
2020-02-08T01:40:36.382155: step 743, loss 0.509153, acc 0.734375
2020-02-08T01:40:36.567794: step 744, loss 0.619919, acc 0.6875
2020-02-08T01:40:36.763529: step 745, loss 0.416268, acc 0.796875
2020-02-08T01:40:36.943505: step 746, loss 0.563595, acc 0.71875
2020-02-08T01:40:37.124360: step 747, loss 0.458459, acc 0.78125
2020-02-08T01:40:37.299235: step 748, loss 0.600256, acc 0.671875
2020-02-08T01:40:37.480579: step 749, loss 0.478346, acc 0.75
2020-02-08T01:40:37.669552: step 750, loss 0.475781, acc 0.75
2020-02-08T01:40:37.851364: step 751, loss 0.452266, acc 0.859375
2020-02-08T01:40:38.031040: step 752, loss 0.381002, acc 0.8125
2020-02-08T01:40:38.201551: step 753, loss 0.340735, acc 0.859375
2020-02-08T01:40:38.386739: step 754, loss 0.568279, acc 0.734375
2020-02-08T01:40:38.580099: step 755, loss 0.415715, acc 0.8125
2020-02-08T01:40:38.753329: step 756, loss 0.384848, acc 0.84375
2020-02-08T01:40:38.949709: step 757, loss 0.382008, acc 0.84375
2020-02-08T01:40:39.149376: step 758, loss 0.394837, acc 0.828125
2020-02-08T01:40:39.332299: step 759, loss 0.527972, acc 0.71875
2020-02-08T01:40:39.526018: step 760, loss 0.430342, acc 0.796875
2020-02-08T01:40:39.772512: step 761, loss 0.38993, acc 0.84375
2020-02-08T01:40:39.954076: step 762, loss 0.390225, acc 0.8125
2020-02-08T01:40:40.137839: step 763, loss 0.355707, acc 0.84375
2020-02-08T01:40:40.319143: step 764, loss 0.497592, acc 0.78125
2020-02-08T01:40:40.502223: step 765, loss 0.462059, acc 0.796875
2020-02-08T01:40:40.697406: step 766, loss 0.459041, acc 0.8125
2020-02-08T01:40:40.881901: step 767, loss 0.488599, acc 0.765625
2020-02-08T01:40:41.065762: step 768, loss 0.435117, acc 0.78125
2020-02-08T01:40:41.247909: step 769, loss 0.337977, acc 0.90625
2020-02-08T01:40:41.488313: step 770, loss 0.474439, acc 0.78125
2020-02-08T01:40:41.705318: step 771, loss 0.434663, acc 0.8125
2020-02-08T01:40:41.988485: step 772, loss 0.538556, acc 0.796875
2020-02-08T01:40:42.238774: step 773, loss 0.50355, acc 0.75
2020-02-08T01:40:42.451119: step 774, loss 0.363407, acc 0.828125
2020-02-08T01:40:42.666662: step 775, loss 0.403695, acc 0.84375
2020-02-08T01:40:42.898126: step 776, loss 0.311207, acc 0.921875
2020-02-08T01:40:43.100256: step 777, loss 0.383851, acc 0.828125
2020-02-08T01:40:43.302776: step 778, loss 0.406135, acc 0.75
2020-02-08T01:40:43.674167: step 779, loss 0.36787, acc 0.875
2020-02-08T01:40:43.949910: step 780, loss 0.438524, acc 0.765625
2020-02-08T01:40:44.127632: step 781, loss 0.453718, acc 0.75
2020-02-08T01:40:44.275293: step 782, loss 0.399781, acc 0.828125
2020-02-08T01:40:44.424067: step 783, loss 0.394843, acc 0.84375
2020-02-08T01:40:44.619061: step 784, loss 0.446065, acc 0.84375
2020-02-08T01:40:44.789634: step 785, loss 0.509353, acc 0.703125
2020-02-08T01:40:44.939696: step 786, loss 0.454012, acc 0.796875
2020-02-08T01:40:45.088459: step 787, loss 0.492186, acc 0.8125
2020-02-08T01:40:45.251946: step 788, loss 0.47246, acc 0.78125
2020-02-08T01:40:45.386196: step 789, loss 0.592364, acc 0.71875
2020-02-08T01:40:45.525638: step 790, loss 0.401424, acc 0.828125
2020-02-08T01:40:45.669899: step 791, loss 0.320342, acc 0.859375
2020-02-08T01:40:45.806697: step 792, loss 0.451275, acc 0.765625
2020-02-08T01:40:46.090908: step 793, loss 0.416629, acc 0.796875
2020-02-08T01:40:46.289534: step 794, loss 0.48835, acc 0.78125
2020-02-08T01:40:46.446088: step 795, loss 0.281205, acc 0.890625
2020-02-08T01:40:46.907447: step 796, loss 0.538283, acc 0.71875
2020-02-08T01:40:47.163364: step 797, loss 0.510899, acc 0.71875
2020-02-08T01:40:47.416646: step 798, loss 0.500751, acc 0.828125
2020-02-08T01:40:47.696819: step 799, loss 0.497297, acc 0.734375
2020-02-08T01:40:48.126608: step 800, loss 0.428703, acc 0.84375

Evaluation:
2020-02-08T01:40:48.933110: step 800, loss 0.610832, acc 0.663227

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-800

2020-02-08T01:40:50.596446: step 801, loss 0.350438, acc 0.875
2020-02-08T01:40:50.769189: step 802, loss 0.497935, acc 0.71875
2020-02-08T01:40:51.010361: step 803, loss 0.430813, acc 0.8125
2020-02-08T01:40:51.257234: step 804, loss 0.395939, acc 0.828125
2020-02-08T01:40:51.473527: step 805, loss 0.50796, acc 0.8125
2020-02-08T01:40:51.709372: step 806, loss 0.432873, acc 0.828125
2020-02-08T01:40:51.992565: step 807, loss 0.430836, acc 0.765625
2020-02-08T01:40:52.215955: step 808, loss 0.415791, acc 0.8125
2020-02-08T01:40:52.429939: step 809, loss 0.371235, acc 0.828125
2020-02-08T01:40:52.677255: step 810, loss 0.495065, acc 0.734375
2020-02-08T01:40:52.868724: step 811, loss 0.37083, acc 0.859375
2020-02-08T01:40:53.042944: step 812, loss 0.418698, acc 0.796875
2020-02-08T01:40:53.204814: step 813, loss 0.383676, acc 0.828125
2020-02-08T01:40:53.383481: step 814, loss 0.49663, acc 0.8125
2020-02-08T01:40:53.576350: step 815, loss 0.475584, acc 0.765625
2020-02-08T01:40:53.734798: step 816, loss 0.421326, acc 0.84375
2020-02-08T01:40:53.896618: step 817, loss 0.336556, acc 0.859375
2020-02-08T01:40:54.383076: step 818, loss 0.415279, acc 0.828125
2020-02-08T01:40:54.594086: step 819, loss 0.354383, acc 0.84375
2020-02-08T01:40:54.832749: step 820, loss 0.398054, acc 0.84375
2020-02-08T01:40:55.085933: step 821, loss 0.359133, acc 0.828125
2020-02-08T01:40:55.300834: step 822, loss 0.434537, acc 0.84375
2020-02-08T01:40:55.585229: step 823, loss 0.408738, acc 0.84375
2020-02-08T01:40:55.800331: step 824, loss 0.345808, acc 0.828125
2020-02-08T01:40:56.123204: step 825, loss 0.323957, acc 0.859375
2020-02-08T01:40:56.385899: step 826, loss 0.492378, acc 0.75
2020-02-08T01:40:56.640159: step 827, loss 0.530923, acc 0.765625
2020-02-08T01:40:56.789980: step 828, loss 0.390791, acc 0.828125
2020-02-08T01:40:57.000731: step 829, loss 0.462121, acc 0.75
2020-02-08T01:40:57.145339: step 830, loss 0.301419, acc 0.859375
2020-02-08T01:40:57.297732: step 831, loss 0.445275, acc 0.75
2020-02-08T01:40:57.436291: step 832, loss 0.335423, acc 0.859375
2020-02-08T01:40:57.657589: step 833, loss 0.389692, acc 0.78125
2020-02-08T01:40:57.826933: step 834, loss 0.556713, acc 0.8125
2020-02-08T01:40:58.023984: step 835, loss 0.486062, acc 0.765625
2020-02-08T01:40:58.182420: step 836, loss 0.464509, acc 0.75
2020-02-08T01:40:58.377181: step 837, loss 0.463948, acc 0.765625
2020-02-08T01:40:58.540181: step 838, loss 0.339004, acc 0.859375
2020-02-08T01:40:58.787685: step 839, loss 0.375775, acc 0.8125
2020-02-08T01:40:58.989319: step 840, loss 0.464969, acc 0.78125
2020-02-08T01:40:59.178123: step 841, loss 0.694015, acc 0.65625
2020-02-08T01:40:59.349991: step 842, loss 0.638102, acc 0.671875
2020-02-08T01:40:59.538746: step 843, loss 0.557858, acc 0.71875
2020-02-08T01:40:59.807548: step 844, loss 0.354059, acc 0.875
2020-02-08T01:40:59.990831: step 845, loss 0.380609, acc 0.765625
2020-02-08T01:41:00.349619: step 846, loss 0.454336, acc 0.828125
2020-02-08T01:41:00.522706: step 847, loss 0.372917, acc 0.859375
2020-02-08T01:41:00.770859: step 848, loss 0.33851, acc 0.875
2020-02-08T01:41:00.956089: step 849, loss 0.366903, acc 0.8125
2020-02-08T01:41:01.103286: step 850, loss 0.430947, acc 0.796875
2020-02-08T01:41:01.247624: step 851, loss 0.418608, acc 0.84375
2020-02-08T01:41:01.405959: step 852, loss 0.471923, acc 0.78125
2020-02-08T01:41:01.604399: step 853, loss 0.454358, acc 0.78125
2020-02-08T01:41:01.787572: step 854, loss 0.666882, acc 0.6875
2020-02-08T01:41:02.049400: step 855, loss 0.484133, acc 0.796875
2020-02-08T01:41:02.253461: step 856, loss 0.603419, acc 0.6875
2020-02-08T01:41:02.522206: step 857, loss 0.351397, acc 0.8125
2020-02-08T01:41:02.723345: step 858, loss 0.547208, acc 0.75
2020-02-08T01:41:02.958460: step 859, loss 0.449807, acc 0.8125
2020-02-08T01:41:03.198057: step 860, loss 0.366545, acc 0.828125
2020-02-08T01:41:03.392341: step 861, loss 0.57074, acc 0.71875
2020-02-08T01:41:03.685412: step 862, loss 0.475274, acc 0.8125
2020-02-08T01:41:03.958734: step 863, loss 0.3665, acc 0.859375
2020-02-08T01:41:04.291689: step 864, loss 0.655714, acc 0.6875
2020-02-08T01:41:04.452960: step 865, loss 0.457813, acc 0.78125
2020-02-08T01:41:04.635413: step 866, loss 0.451573, acc 0.703125
2020-02-08T01:41:04.860287: step 867, loss 0.525596, acc 0.703125
2020-02-08T01:41:05.089467: step 868, loss 0.493744, acc 0.765625
2020-02-08T01:41:05.455408: step 869, loss 0.443608, acc 0.796875
2020-02-08T01:41:05.740286: step 870, loss 0.359024, acc 0.8125
2020-02-08T01:41:06.068815: step 871, loss 0.399583, acc 0.765625
2020-02-08T01:41:06.253204: step 872, loss 0.440893, acc 0.8125
2020-02-08T01:41:06.440618: step 873, loss 0.479123, acc 0.765625
2020-02-08T01:41:06.627253: step 874, loss 0.343799, acc 0.84375
2020-02-08T01:41:06.822390: step 875, loss 0.446348, acc 0.78125
2020-02-08T01:41:07.044304: step 876, loss 0.436501, acc 0.78125
2020-02-08T01:41:07.384920: step 877, loss 0.416931, acc 0.828125
2020-02-08T01:41:07.680527: step 878, loss 0.416222, acc 0.765625
2020-02-08T01:41:07.983816: step 879, loss 0.694592, acc 0.65625
2020-02-08T01:41:08.250898: step 880, loss 0.521146, acc 0.75
2020-02-08T01:41:08.441371: step 881, loss 0.425304, acc 0.75
2020-02-08T01:41:08.635308: step 882, loss 0.462857, acc 0.765625
2020-02-08T01:41:08.829658: step 883, loss 0.433008, acc 0.78125
2020-02-08T01:41:09.042667: step 884, loss 0.427205, acc 0.8125
2020-02-08T01:41:09.312780: step 885, loss 0.44429, acc 0.734375
2020-02-08T01:41:09.541564: step 886, loss 0.532995, acc 0.765625
2020-02-08T01:41:09.779801: step 887, loss 0.4289, acc 0.828125
2020-02-08T01:41:10.021669: step 888, loss 0.639922, acc 0.625
2020-02-08T01:41:10.243596: step 889, loss 0.386843, acc 0.828125
2020-02-08T01:41:10.473269: step 890, loss 0.323666, acc 0.875
2020-02-08T01:41:10.672672: step 891, loss 0.469011, acc 0.734375
2020-02-08T01:41:10.863057: step 892, loss 0.580414, acc 0.765625
2020-02-08T01:41:11.045254: step 893, loss 0.393231, acc 0.84375
2020-02-08T01:41:11.250679: step 894, loss 0.709561, acc 0.71875
2020-02-08T01:41:11.440777: step 895, loss 0.334224, acc 0.859375
2020-02-08T01:41:11.639710: step 896, loss 0.411061, acc 0.84375
2020-02-08T01:41:11.829010: step 897, loss 0.489275, acc 0.75
2020-02-08T01:41:12.036376: step 898, loss 0.373295, acc 0.859375
2020-02-08T01:41:12.226681: step 899, loss 0.410548, acc 0.8125
2020-02-08T01:41:12.407014: step 900, loss 0.443344, acc 0.85

Evaluation:
2020-02-08T01:41:12.740160: step 900, loss 0.570994, acc 0.703565

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-900

2020-02-08T01:41:14.345277: step 901, loss 0.451596, acc 0.796875
2020-02-08T01:41:14.539627: step 902, loss 0.333273, acc 0.875
2020-02-08T01:41:14.732279: step 903, loss 0.271316, acc 0.890625
2020-02-08T01:41:14.923819: step 904, loss 0.310673, acc 0.875
2020-02-08T01:41:15.106226: step 905, loss 0.391198, acc 0.859375
2020-02-08T01:41:15.294786: step 906, loss 0.376563, acc 0.828125
2020-02-08T01:41:15.496266: step 907, loss 0.408871, acc 0.8125
2020-02-08T01:41:15.730165: step 908, loss 0.41337, acc 0.78125
2020-02-08T01:41:15.927443: step 909, loss 0.492155, acc 0.75
2020-02-08T01:41:16.125040: step 910, loss 0.418958, acc 0.8125
2020-02-08T01:41:16.313619: step 911, loss 0.379826, acc 0.84375
2020-02-08T01:41:16.515015: step 912, loss 0.45761, acc 0.796875
2020-02-08T01:41:16.765139: step 913, loss 0.34505, acc 0.8125
2020-02-08T01:41:16.973772: step 914, loss 0.375089, acc 0.828125
2020-02-08T01:41:17.178928: step 915, loss 0.314665, acc 0.859375
2020-02-08T01:41:17.362248: step 916, loss 0.274442, acc 0.890625
2020-02-08T01:41:17.572220: step 917, loss 0.324554, acc 0.890625
2020-02-08T01:41:17.767806: step 918, loss 0.393492, acc 0.84375
2020-02-08T01:41:17.974611: step 919, loss 0.249622, acc 0.921875
2020-02-08T01:41:18.163336: step 920, loss 0.342486, acc 0.859375
2020-02-08T01:41:18.356185: step 921, loss 0.344019, acc 0.859375
2020-02-08T01:41:18.560216: step 922, loss 0.399516, acc 0.828125
2020-02-08T01:41:18.759655: step 923, loss 0.413696, acc 0.796875
2020-02-08T01:41:18.943178: step 924, loss 0.404502, acc 0.828125
2020-02-08T01:41:19.222500: step 925, loss 0.233638, acc 0.921875
2020-02-08T01:41:19.430548: step 926, loss 0.343478, acc 0.84375
2020-02-08T01:41:19.645814: step 927, loss 0.331959, acc 0.890625
2020-02-08T01:41:19.849315: step 928, loss 0.287356, acc 0.875
2020-02-08T01:41:20.038823: step 929, loss 0.255898, acc 0.90625
2020-02-08T01:41:20.232524: step 930, loss 0.383507, acc 0.875
2020-02-08T01:41:20.423041: step 931, loss 0.354313, acc 0.84375
2020-02-08T01:41:20.621176: step 932, loss 0.355511, acc 0.8125
2020-02-08T01:41:20.796119: step 933, loss 0.344358, acc 0.8125
2020-02-08T01:41:20.975216: step 934, loss 0.29069, acc 0.875
2020-02-08T01:41:21.156207: step 935, loss 0.246392, acc 0.9375
2020-02-08T01:41:21.341235: step 936, loss 0.34953, acc 0.84375
2020-02-08T01:41:21.611570: step 937, loss 0.33032, acc 0.84375
2020-02-08T01:41:21.801326: step 938, loss 0.33504, acc 0.875
2020-02-08T01:41:21.983910: step 939, loss 0.249981, acc 0.90625
2020-02-08T01:41:22.179870: step 940, loss 0.450248, acc 0.8125
2020-02-08T01:41:22.360230: step 941, loss 0.325948, acc 0.84375
2020-02-08T01:41:22.552934: step 942, loss 0.324048, acc 0.890625
2020-02-08T01:41:22.751391: step 943, loss 0.362172, acc 0.875
2020-02-08T01:41:22.941113: step 944, loss 0.340596, acc 0.875
2020-02-08T01:41:23.143662: step 945, loss 0.253597, acc 0.90625
2020-02-08T01:41:23.329337: step 946, loss 0.40986, acc 0.859375
2020-02-08T01:41:23.526564: step 947, loss 0.407305, acc 0.8125
2020-02-08T01:41:23.720173: step 948, loss 0.375778, acc 0.859375
2020-02-08T01:41:23.902625: step 949, loss 0.297509, acc 0.921875
2020-02-08T01:41:24.100067: step 950, loss 0.351785, acc 0.828125
2020-02-08T01:41:24.277154: step 951, loss 0.417112, acc 0.796875
2020-02-08T01:41:24.466123: step 952, loss 0.404689, acc 0.78125
2020-02-08T01:41:24.660579: step 953, loss 0.383566, acc 0.859375
2020-02-08T01:41:24.846551: step 954, loss 0.518844, acc 0.78125
2020-02-08T01:41:25.026660: step 955, loss 0.275193, acc 0.890625
2020-02-08T01:41:25.203790: step 956, loss 0.45738, acc 0.78125
2020-02-08T01:41:25.383881: step 957, loss 0.432184, acc 0.78125
2020-02-08T01:41:25.566283: step 958, loss 0.433706, acc 0.796875
2020-02-08T01:41:25.741571: step 959, loss 0.476204, acc 0.78125
2020-02-08T01:41:25.926383: step 960, loss 0.38031, acc 0.84375
2020-02-08T01:41:26.112258: step 961, loss 0.384421, acc 0.78125
2020-02-08T01:41:26.302621: step 962, loss 0.28502, acc 0.875
2020-02-08T01:41:26.491710: step 963, loss 0.392298, acc 0.859375
2020-02-08T01:41:26.684124: step 964, loss 0.423329, acc 0.8125
2020-02-08T01:41:26.878356: step 965, loss 0.361065, acc 0.84375
2020-02-08T01:41:27.061943: step 966, loss 0.529121, acc 0.75
2020-02-08T01:41:27.243377: step 967, loss 0.310217, acc 0.859375
2020-02-08T01:41:27.432146: step 968, loss 0.419979, acc 0.828125
2020-02-08T01:41:27.615867: step 969, loss 0.384084, acc 0.8125
2020-02-08T01:41:27.801732: step 970, loss 0.384057, acc 0.796875
2020-02-08T01:41:27.982988: step 971, loss 0.410509, acc 0.84375
2020-02-08T01:41:28.164045: step 972, loss 0.269802, acc 0.875
2020-02-08T01:41:28.362548: step 973, loss 0.300891, acc 0.859375
2020-02-08T01:41:28.552498: step 974, loss 0.423924, acc 0.8125
2020-02-08T01:41:28.752408: step 975, loss 0.395686, acc 0.859375
2020-02-08T01:41:28.958278: step 976, loss 0.247137, acc 0.90625
2020-02-08T01:41:29.152254: step 977, loss 0.408347, acc 0.84375
2020-02-08T01:41:29.364558: step 978, loss 0.344507, acc 0.84375
2020-02-08T01:41:29.612464: step 979, loss 0.333897, acc 0.875
2020-02-08T01:41:29.805931: step 980, loss 0.412499, acc 0.78125
2020-02-08T01:41:30.022776: step 981, loss 0.446345, acc 0.84375
2020-02-08T01:41:30.234209: step 982, loss 0.358111, acc 0.828125
2020-02-08T01:41:30.474853: step 983, loss 0.419938, acc 0.84375
2020-02-08T01:41:30.808508: step 984, loss 0.30234, acc 0.859375
2020-02-08T01:41:31.087303: step 985, loss 0.390005, acc 0.8125
2020-02-08T01:41:31.339957: step 986, loss 0.357161, acc 0.859375
2020-02-08T01:41:31.551070: step 987, loss 0.315858, acc 0.859375
2020-02-08T01:41:31.772362: step 988, loss 0.441626, acc 0.796875
2020-02-08T01:41:31.991405: step 989, loss 0.409988, acc 0.796875
2020-02-08T01:41:32.202173: step 990, loss 0.365221, acc 0.796875
2020-02-08T01:41:32.400890: step 991, loss 0.349751, acc 0.890625
2020-02-08T01:41:32.679860: step 992, loss 0.43737, acc 0.78125
2020-02-08T01:41:32.930040: step 993, loss 0.328995, acc 0.828125
2020-02-08T01:41:33.132295: step 994, loss 0.515018, acc 0.734375
2020-02-08T01:41:33.330328: step 995, loss 0.310807, acc 0.890625
2020-02-08T01:41:33.531381: step 996, loss 0.445912, acc 0.78125
2020-02-08T01:41:33.721876: step 997, loss 0.328476, acc 0.84375
2020-02-08T01:41:33.928504: step 998, loss 0.263315, acc 0.90625
2020-02-08T01:41:34.122158: step 999, loss 0.390019, acc 0.8125
2020-02-08T01:41:34.339756: step 1000, loss 0.27381, acc 0.859375

Evaluation:
2020-02-08T01:41:34.740292: step 1000, loss 0.570551, acc 0.708255

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1000

2020-02-08T01:41:36.339090: step 1001, loss 0.341895, acc 0.84375
2020-02-08T01:41:36.518549: step 1002, loss 0.379596, acc 0.8125
2020-02-08T01:41:36.706624: step 1003, loss 0.376447, acc 0.859375
2020-02-08T01:41:36.889804: step 1004, loss 0.385219, acc 0.859375
2020-02-08T01:41:37.069145: step 1005, loss 0.503707, acc 0.71875
2020-02-08T01:41:37.238931: step 1006, loss 0.43699, acc 0.765625
2020-02-08T01:41:37.414006: step 1007, loss 0.316911, acc 0.859375
2020-02-08T01:41:37.596923: step 1008, loss 0.512637, acc 0.734375
2020-02-08T01:41:37.778533: step 1009, loss 0.277759, acc 0.921875
2020-02-08T01:41:37.963669: step 1010, loss 0.5032, acc 0.734375
2020-02-08T01:41:38.146417: step 1011, loss 0.406744, acc 0.8125
2020-02-08T01:41:38.328392: step 1012, loss 0.339061, acc 0.84375
2020-02-08T01:41:38.512202: step 1013, loss 0.330496, acc 0.875
2020-02-08T01:41:38.706387: step 1014, loss 0.330558, acc 0.875
2020-02-08T01:41:38.891637: step 1015, loss 0.520029, acc 0.765625
2020-02-08T01:41:39.091047: step 1016, loss 0.33697, acc 0.875
2020-02-08T01:41:39.271955: step 1017, loss 0.333425, acc 0.859375
2020-02-08T01:41:39.452101: step 1018, loss 0.427522, acc 0.8125
2020-02-08T01:41:39.633492: step 1019, loss 0.314508, acc 0.90625
2020-02-08T01:41:39.820590: step 1020, loss 0.503912, acc 0.703125
2020-02-08T01:41:39.991263: step 1021, loss 0.360238, acc 0.84375
2020-02-08T01:41:40.162186: step 1022, loss 0.419652, acc 0.8125
2020-02-08T01:41:40.350238: step 1023, loss 0.440136, acc 0.796875
2020-02-08T01:41:40.528652: step 1024, loss 0.385142, acc 0.828125
2020-02-08T01:41:40.719623: step 1025, loss 0.414684, acc 0.796875
2020-02-08T01:41:40.895674: step 1026, loss 0.49566, acc 0.796875
2020-02-08T01:41:41.075644: step 1027, loss 0.548929, acc 0.734375
2020-02-08T01:41:41.255449: step 1028, loss 0.366524, acc 0.84375
2020-02-08T01:41:41.437236: step 1029, loss 0.36028, acc 0.796875
2020-02-08T01:41:41.610301: step 1030, loss 0.363377, acc 0.828125
2020-02-08T01:41:41.790416: step 1031, loss 0.329707, acc 0.828125
2020-02-08T01:41:41.957174: step 1032, loss 0.357103, acc 0.859375
2020-02-08T01:41:42.135699: step 1033, loss 0.314953, acc 0.890625
2020-02-08T01:41:42.312564: step 1034, loss 0.395554, acc 0.796875
2020-02-08T01:41:42.495358: step 1035, loss 0.456507, acc 0.75
2020-02-08T01:41:42.686443: step 1036, loss 0.304356, acc 0.890625
2020-02-08T01:41:42.867011: step 1037, loss 0.541702, acc 0.734375
2020-02-08T01:41:43.043736: step 1038, loss 0.329831, acc 0.875
2020-02-08T01:41:43.226536: step 1039, loss 0.426845, acc 0.8125
2020-02-08T01:41:43.402031: step 1040, loss 0.553936, acc 0.765625
2020-02-08T01:41:43.578765: step 1041, loss 0.305268, acc 0.875
2020-02-08T01:41:43.756884: step 1042, loss 0.324394, acc 0.859375
2020-02-08T01:41:43.941342: step 1043, loss 0.325989, acc 0.859375
2020-02-08T01:41:44.113061: step 1044, loss 0.52259, acc 0.765625
2020-02-08T01:41:44.294813: step 1045, loss 0.392357, acc 0.78125
2020-02-08T01:41:44.467299: step 1046, loss 0.404275, acc 0.84375
2020-02-08T01:41:44.650669: step 1047, loss 0.486875, acc 0.78125
2020-02-08T01:41:44.829392: step 1048, loss 0.429197, acc 0.828125
2020-02-08T01:41:45.003487: step 1049, loss 0.399918, acc 0.78125
2020-02-08T01:41:45.164770: step 1050, loss 0.41002, acc 0.8
2020-02-08T01:41:45.340211: step 1051, loss 0.277211, acc 0.90625
2020-02-08T01:41:45.515942: step 1052, loss 0.231206, acc 0.890625
2020-02-08T01:41:45.704204: step 1053, loss 0.189534, acc 0.9375
2020-02-08T01:41:45.875505: step 1054, loss 0.36477, acc 0.8125
2020-02-08T01:41:46.044134: step 1055, loss 0.35226, acc 0.84375
2020-02-08T01:41:46.216273: step 1056, loss 0.374292, acc 0.828125
2020-02-08T01:41:46.383030: step 1057, loss 0.260994, acc 0.890625
2020-02-08T01:41:46.556193: step 1058, loss 0.335711, acc 0.828125
2020-02-08T01:41:46.740286: step 1059, loss 0.231745, acc 0.921875
2020-02-08T01:41:46.911563: step 1060, loss 0.287506, acc 0.90625
2020-02-08T01:41:47.083912: step 1061, loss 0.316675, acc 0.859375
2020-02-08T01:41:47.265298: step 1062, loss 0.283966, acc 0.875
2020-02-08T01:41:47.430311: step 1063, loss 0.274415, acc 0.890625
2020-02-08T01:41:47.603202: step 1064, loss 0.270023, acc 0.890625
2020-02-08T01:41:47.774175: step 1065, loss 0.229284, acc 0.90625
2020-02-08T01:41:47.996233: step 1066, loss 0.318544, acc 0.890625
2020-02-08T01:41:48.191593: step 1067, loss 0.273934, acc 0.875
2020-02-08T01:41:48.390901: step 1068, loss 0.268383, acc 0.921875
2020-02-08T01:41:48.577276: step 1069, loss 0.203694, acc 0.9375
2020-02-08T01:41:48.748846: step 1070, loss 0.387866, acc 0.859375
2020-02-08T01:41:48.929705: step 1071, loss 0.252584, acc 0.890625
2020-02-08T01:41:49.119504: step 1072, loss 0.277868, acc 0.859375
2020-02-08T01:41:49.309612: step 1073, loss 0.33512, acc 0.859375
2020-02-08T01:41:49.486065: step 1074, loss 0.387116, acc 0.828125
2020-02-08T01:41:49.677217: step 1075, loss 0.262882, acc 0.9375
2020-02-08T01:41:49.846461: step 1076, loss 0.273314, acc 0.90625
2020-02-08T01:41:50.016151: step 1077, loss 0.249421, acc 0.890625
2020-02-08T01:41:50.188074: step 1078, loss 0.261601, acc 0.84375
2020-02-08T01:41:50.367291: step 1079, loss 0.339807, acc 0.859375
2020-02-08T01:41:50.546136: step 1080, loss 0.391059, acc 0.796875
2020-02-08T01:41:50.734559: step 1081, loss 0.386281, acc 0.796875
2020-02-08T01:41:50.908366: step 1082, loss 0.237821, acc 0.890625
2020-02-08T01:41:51.095215: step 1083, loss 0.27549, acc 0.890625
2020-02-08T01:41:51.498945: step 1084, loss 0.295141, acc 0.90625
2020-02-08T01:41:51.727888: step 1085, loss 0.329368, acc 0.859375
2020-02-08T01:41:51.931120: step 1086, loss 0.264703, acc 0.9375
2020-02-08T01:41:52.134406: step 1087, loss 0.344943, acc 0.84375
2020-02-08T01:41:52.311003: step 1088, loss 0.247728, acc 0.875
2020-02-08T01:41:52.498290: step 1089, loss 0.306262, acc 0.875
2020-02-08T01:41:52.697328: step 1090, loss 0.303883, acc 0.84375
2020-02-08T01:41:52.880665: step 1091, loss 0.319257, acc 0.84375
2020-02-08T01:41:53.061865: step 1092, loss 0.293525, acc 0.921875
2020-02-08T01:41:53.260351: step 1093, loss 0.272171, acc 0.890625
2020-02-08T01:41:53.446584: step 1094, loss 0.173527, acc 0.96875
2020-02-08T01:41:53.631586: step 1095, loss 0.285, acc 0.859375
2020-02-08T01:41:53.804909: step 1096, loss 0.239648, acc 0.890625
2020-02-08T01:41:53.985734: step 1097, loss 0.361577, acc 0.828125
2020-02-08T01:41:54.180231: step 1098, loss 0.354144, acc 0.796875
2020-02-08T01:41:54.357092: step 1099, loss 0.235599, acc 0.875
2020-02-08T01:41:54.550026: step 1100, loss 0.199466, acc 0.953125

Evaluation:
2020-02-08T01:41:54.990839: step 1100, loss 0.566711, acc 0.706379

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1100

2020-02-08T01:41:57.441079: step 1101, loss 0.474422, acc 0.765625
2020-02-08T01:41:57.632937: step 1102, loss 0.327967, acc 0.859375
2020-02-08T01:41:57.803727: step 1103, loss 0.298629, acc 0.90625
2020-02-08T01:41:57.986729: step 1104, loss 0.4848, acc 0.828125
2020-02-08T01:41:58.173769: step 1105, loss 0.208432, acc 0.90625
2020-02-08T01:41:58.371824: step 1106, loss 0.240299, acc 0.921875
2020-02-08T01:41:58.570063: step 1107, loss 0.357505, acc 0.828125
2020-02-08T01:41:58.767667: step 1108, loss 0.465419, acc 0.765625
2020-02-08T01:41:58.949317: step 1109, loss 0.280641, acc 0.859375
2020-02-08T01:41:59.154486: step 1110, loss 0.297058, acc 0.875
2020-02-08T01:41:59.359066: step 1111, loss 0.192746, acc 0.90625
2020-02-08T01:41:59.580398: step 1112, loss 0.403474, acc 0.796875
2020-02-08T01:41:59.766022: step 1113, loss 0.289296, acc 0.921875
2020-02-08T01:42:00.017681: step 1114, loss 0.293785, acc 0.84375
2020-02-08T01:42:00.239603: step 1115, loss 0.324945, acc 0.875
2020-02-08T01:42:00.472103: step 1116, loss 0.465124, acc 0.78125
2020-02-08T01:42:00.642201: step 1117, loss 0.26774, acc 0.875
2020-02-08T01:42:00.825003: step 1118, loss 0.276798, acc 0.90625
2020-02-08T01:42:01.006350: step 1119, loss 0.305649, acc 0.859375
2020-02-08T01:42:01.191932: step 1120, loss 0.289593, acc 0.890625
2020-02-08T01:42:01.377589: step 1121, loss 0.388725, acc 0.828125
2020-02-08T01:42:01.576882: step 1122, loss 0.271521, acc 0.859375
2020-02-08T01:42:01.770805: step 1123, loss 0.298922, acc 0.875
2020-02-08T01:42:01.971918: step 1124, loss 0.314255, acc 0.84375
2020-02-08T01:42:02.164026: step 1125, loss 0.242492, acc 0.890625
2020-02-08T01:42:02.352976: step 1126, loss 0.324438, acc 0.890625
2020-02-08T01:42:02.555658: step 1127, loss 0.250873, acc 0.90625
2020-02-08T01:42:02.762132: step 1128, loss 0.433312, acc 0.8125
2020-02-08T01:42:02.950451: step 1129, loss 0.476113, acc 0.84375
2020-02-08T01:42:03.143807: step 1130, loss 0.302937, acc 0.890625
2020-02-08T01:42:03.341275: step 1131, loss 0.284848, acc 0.875
2020-02-08T01:42:03.545650: step 1132, loss 0.377488, acc 0.84375
2020-02-08T01:42:03.744963: step 1133, loss 0.201671, acc 0.953125
2020-02-08T01:42:03.940904: step 1134, loss 0.290996, acc 0.8125
2020-02-08T01:42:04.125725: step 1135, loss 0.328224, acc 0.890625
2020-02-08T01:42:04.313394: step 1136, loss 0.346596, acc 0.875
2020-02-08T01:42:04.503642: step 1137, loss 0.390349, acc 0.859375
2020-02-08T01:42:04.698615: step 1138, loss 0.270201, acc 0.921875
2020-02-08T01:42:04.881934: step 1139, loss 0.253752, acc 0.921875
2020-02-08T01:42:05.072831: step 1140, loss 0.201435, acc 0.921875
2020-02-08T01:42:05.256262: step 1141, loss 0.279909, acc 0.875
2020-02-08T01:42:05.440107: step 1142, loss 0.408263, acc 0.84375
2020-02-08T01:42:05.621327: step 1143, loss 0.227229, acc 0.90625
2020-02-08T01:42:05.806420: step 1144, loss 0.265366, acc 0.890625
2020-02-08T01:42:05.994923: step 1145, loss 0.251569, acc 0.890625
2020-02-08T01:42:06.179297: step 1146, loss 0.247519, acc 0.921875
2020-02-08T01:42:06.371027: step 1147, loss 0.284935, acc 0.90625
2020-02-08T01:42:06.560412: step 1148, loss 0.278988, acc 0.921875
2020-02-08T01:42:06.757392: step 1149, loss 0.240657, acc 0.921875
2020-02-08T01:42:06.945458: step 1150, loss 0.36803, acc 0.84375
2020-02-08T01:42:07.131139: step 1151, loss 0.210807, acc 0.890625
2020-02-08T01:42:07.319010: step 1152, loss 0.274039, acc 0.890625
2020-02-08T01:42:07.517512: step 1153, loss 0.30172, acc 0.890625
2020-02-08T01:42:07.735862: step 1154, loss 0.324708, acc 0.828125
2020-02-08T01:42:07.943291: step 1155, loss 0.267379, acc 0.921875
2020-02-08T01:42:08.131435: step 1156, loss 0.332637, acc 0.8125
2020-02-08T01:42:08.320549: step 1157, loss 0.325224, acc 0.875
2020-02-08T01:42:08.514679: step 1158, loss 0.269802, acc 0.90625
2020-02-08T01:42:08.724246: step 1159, loss 0.255022, acc 0.890625
2020-02-08T01:42:08.917189: step 1160, loss 0.33855, acc 0.84375
2020-02-08T01:42:09.125035: step 1161, loss 0.320458, acc 0.890625
2020-02-08T01:42:09.322337: step 1162, loss 0.303627, acc 0.875
2020-02-08T01:42:09.513945: step 1163, loss 0.293196, acc 0.859375
2020-02-08T01:42:09.732153: step 1164, loss 0.345731, acc 0.875
2020-02-08T01:42:09.922997: step 1165, loss 0.351103, acc 0.859375
2020-02-08T01:42:10.124125: step 1166, loss 0.249684, acc 0.890625
2020-02-08T01:42:10.317950: step 1167, loss 0.38396, acc 0.796875
2020-02-08T01:42:10.526613: step 1168, loss 0.26859, acc 0.859375
2020-02-08T01:42:10.739743: step 1169, loss 0.266898, acc 0.921875
2020-02-08T01:42:10.941912: step 1170, loss 0.290351, acc 0.84375
2020-02-08T01:42:11.133197: step 1171, loss 0.14729, acc 0.96875
2020-02-08T01:42:11.337441: step 1172, loss 0.267825, acc 0.921875
2020-02-08T01:42:11.537570: step 1173, loss 0.426511, acc 0.8125
2020-02-08T01:42:11.733908: step 1174, loss 0.271277, acc 0.90625
2020-02-08T01:42:11.939100: step 1175, loss 0.330551, acc 0.828125
2020-02-08T01:42:12.133717: step 1176, loss 0.294112, acc 0.890625
2020-02-08T01:42:12.327052: step 1177, loss 0.348023, acc 0.859375
2020-02-08T01:42:12.519856: step 1178, loss 0.322801, acc 0.875
2020-02-08T01:42:12.728437: step 1179, loss 0.281473, acc 0.875
2020-02-08T01:42:12.923922: step 1180, loss 0.323842, acc 0.875
2020-02-08T01:42:13.126986: step 1181, loss 0.341414, acc 0.859375
2020-02-08T01:42:13.326705: step 1182, loss 0.315339, acc 0.890625
2020-02-08T01:42:13.542495: step 1183, loss 0.187986, acc 0.90625
2020-02-08T01:42:13.756947: step 1184, loss 0.193131, acc 0.953125
2020-02-08T01:42:13.956888: step 1185, loss 0.186244, acc 0.953125
2020-02-08T01:42:14.149148: step 1186, loss 0.20994, acc 0.890625
2020-02-08T01:42:14.349778: step 1187, loss 0.135319, acc 0.953125
2020-02-08T01:42:14.547498: step 1188, loss 0.298729, acc 0.90625
2020-02-08T01:42:14.744707: step 1189, loss 0.287226, acc 0.859375
2020-02-08T01:42:14.932633: step 1190, loss 0.284103, acc 0.875
2020-02-08T01:42:15.127531: step 1191, loss 0.315992, acc 0.859375
2020-02-08T01:42:15.327393: step 1192, loss 0.456756, acc 0.765625
2020-02-08T01:42:15.525568: step 1193, loss 0.273607, acc 0.875
2020-02-08T01:42:15.744870: step 1194, loss 0.289445, acc 0.875
2020-02-08T01:42:15.941373: step 1195, loss 0.26761, acc 0.84375
2020-02-08T01:42:16.144299: step 1196, loss 0.361947, acc 0.828125
2020-02-08T01:42:16.335426: step 1197, loss 0.226916, acc 0.921875
2020-02-08T01:42:16.530758: step 1198, loss 0.313278, acc 0.84375
2020-02-08T01:42:16.744326: step 1199, loss 0.268761, acc 0.875
2020-02-08T01:42:16.935696: step 1200, loss 0.367987, acc 0.866667

Evaluation:
2020-02-08T01:42:17.283990: step 1200, loss 0.567538, acc 0.724203

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1200

2020-02-08T01:42:19.783724: step 1201, loss 0.212078, acc 0.9375
2020-02-08T01:42:20.043848: step 1202, loss 0.25045, acc 0.890625
2020-02-08T01:42:20.286875: step 1203, loss 0.252283, acc 0.890625
2020-02-08T01:42:20.537642: step 1204, loss 0.274044, acc 0.875
2020-02-08T01:42:20.799605: step 1205, loss 0.291426, acc 0.875
2020-02-08T01:42:20.998556: step 1206, loss 0.346875, acc 0.859375
2020-02-08T01:42:21.200321: step 1207, loss 0.171548, acc 0.96875
2020-02-08T01:42:21.530941: step 1208, loss 0.224027, acc 0.9375
2020-02-08T01:42:21.750054: step 1209, loss 0.311335, acc 0.859375
2020-02-08T01:42:21.938568: step 1210, loss 0.173046, acc 0.953125
2020-02-08T01:42:22.155657: step 1211, loss 0.274097, acc 0.875
2020-02-08T01:42:22.351106: step 1212, loss 0.253272, acc 0.90625
2020-02-08T01:42:22.547317: step 1213, loss 0.185965, acc 0.953125
2020-02-08T01:42:22.748350: step 1214, loss 0.120486, acc 0.96875
2020-02-08T01:42:22.938880: step 1215, loss 0.229134, acc 0.921875
2020-02-08T01:42:23.137724: step 1216, loss 0.245914, acc 0.90625
2020-02-08T01:42:23.337153: step 1217, loss 0.24145, acc 0.921875
2020-02-08T01:42:23.535766: step 1218, loss 0.270498, acc 0.875
2020-02-08T01:42:23.747771: step 1219, loss 0.268835, acc 0.875
2020-02-08T01:42:23.944410: step 1220, loss 0.322514, acc 0.875
2020-02-08T01:42:24.150240: step 1221, loss 0.357247, acc 0.8125
2020-02-08T01:42:24.351666: step 1222, loss 0.334317, acc 0.875
2020-02-08T01:42:24.580830: step 1223, loss 0.292836, acc 0.90625
2020-02-08T01:42:24.805995: step 1224, loss 0.25491, acc 0.84375
2020-02-08T01:42:25.027551: step 1225, loss 0.352873, acc 0.8125
2020-02-08T01:42:25.236419: step 1226, loss 0.218041, acc 0.90625
2020-02-08T01:42:25.457879: step 1227, loss 0.127565, acc 0.96875
2020-02-08T01:42:25.664693: step 1228, loss 0.249085, acc 0.890625
2020-02-08T01:42:25.865618: step 1229, loss 0.220748, acc 0.9375
2020-02-08T01:42:26.066766: step 1230, loss 0.191061, acc 0.921875
2020-02-08T01:42:26.265810: step 1231, loss 0.291725, acc 0.875
2020-02-08T01:42:26.450448: step 1232, loss 0.230605, acc 0.90625
2020-02-08T01:42:26.639936: step 1233, loss 0.282285, acc 0.890625
2020-02-08T01:42:26.823364: step 1234, loss 0.230114, acc 0.90625
2020-02-08T01:42:27.151360: step 1235, loss 0.239818, acc 0.921875
2020-02-08T01:42:27.384589: step 1236, loss 0.299827, acc 0.890625
2020-02-08T01:42:27.622416: step 1237, loss 0.277989, acc 0.859375
2020-02-08T01:42:27.818288: step 1238, loss 0.272937, acc 0.859375
2020-02-08T01:42:28.008324: step 1239, loss 0.158519, acc 0.953125
2020-02-08T01:42:28.225265: step 1240, loss 0.188885, acc 0.921875
2020-02-08T01:42:28.448065: step 1241, loss 0.206136, acc 0.9375
2020-02-08T01:42:28.644320: step 1242, loss 0.159518, acc 0.9375
2020-02-08T01:42:28.888357: step 1243, loss 0.184751, acc 0.9375
2020-02-08T01:42:29.132536: step 1244, loss 0.20381, acc 0.921875
2020-02-08T01:42:29.341659: step 1245, loss 0.156675, acc 0.953125
2020-02-08T01:42:29.602726: step 1246, loss 0.357419, acc 0.8125
2020-02-08T01:42:29.825651: step 1247, loss 0.249928, acc 0.859375
2020-02-08T01:42:30.055078: step 1248, loss 0.256182, acc 0.890625
2020-02-08T01:42:30.269445: step 1249, loss 0.307704, acc 0.84375
2020-02-08T01:42:30.484436: step 1250, loss 0.147076, acc 0.953125
2020-02-08T01:42:30.725015: step 1251, loss 0.235623, acc 0.921875
2020-02-08T01:42:30.974536: step 1252, loss 0.316655, acc 0.84375
2020-02-08T01:42:31.201597: step 1253, loss 0.248575, acc 0.890625
2020-02-08T01:42:31.453061: step 1254, loss 0.376631, acc 0.828125
2020-02-08T01:42:31.692249: step 1255, loss 0.282546, acc 0.890625
2020-02-08T01:42:31.935452: step 1256, loss 0.244902, acc 0.890625
2020-02-08T01:42:32.168974: step 1257, loss 0.227423, acc 0.90625
2020-02-08T01:42:32.425872: step 1258, loss 0.226957, acc 0.953125
2020-02-08T01:42:32.657763: step 1259, loss 0.307248, acc 0.875
2020-02-08T01:42:32.889595: step 1260, loss 0.224527, acc 0.90625
2020-02-08T01:42:33.103526: step 1261, loss 0.216173, acc 0.9375
2020-02-08T01:42:33.309296: step 1262, loss 0.232692, acc 0.953125
2020-02-08T01:42:33.531477: step 1263, loss 0.219035, acc 0.90625
2020-02-08T01:42:33.753228: step 1264, loss 0.179762, acc 0.9375
2020-02-08T01:42:33.959164: step 1265, loss 0.364762, acc 0.875
2020-02-08T01:42:34.169802: step 1266, loss 0.278626, acc 0.890625
2020-02-08T01:42:34.403219: step 1267, loss 0.289113, acc 0.875
2020-02-08T01:42:34.612122: step 1268, loss 0.324144, acc 0.8125
2020-02-08T01:42:34.828391: step 1269, loss 0.307726, acc 0.859375
2020-02-08T01:42:35.056684: step 1270, loss 0.282873, acc 0.875
2020-02-08T01:42:35.295821: step 1271, loss 0.233077, acc 0.90625
2020-02-08T01:42:35.547825: step 1272, loss 0.179811, acc 0.953125
2020-02-08T01:42:35.796622: step 1273, loss 0.25988, acc 0.90625
2020-02-08T01:42:36.029689: step 1274, loss 0.151153, acc 0.96875
2020-02-08T01:42:36.260241: step 1275, loss 0.198522, acc 0.953125
2020-02-08T01:42:36.503844: step 1276, loss 0.191809, acc 0.9375
2020-02-08T01:42:36.762980: step 1277, loss 0.234265, acc 0.90625
2020-02-08T01:42:36.978456: step 1278, loss 0.293163, acc 0.90625
2020-02-08T01:42:37.226094: step 1279, loss 0.232737, acc 0.890625
2020-02-08T01:42:37.456128: step 1280, loss 0.197661, acc 0.921875
2020-02-08T01:42:37.719827: step 1281, loss 0.187993, acc 0.890625
2020-02-08T01:42:37.961609: step 1282, loss 0.283863, acc 0.859375
2020-02-08T01:42:38.206885: step 1283, loss 0.176365, acc 0.921875
2020-02-08T01:42:38.506267: step 1284, loss 0.257221, acc 0.921875
2020-02-08T01:42:38.690568: step 1285, loss 0.249856, acc 0.890625
2020-02-08T01:42:38.963454: step 1286, loss 0.138875, acc 0.953125
2020-02-08T01:42:39.197259: step 1287, loss 0.197754, acc 0.921875
2020-02-08T01:42:39.428730: step 1288, loss 0.197294, acc 0.921875
2020-02-08T01:42:39.746677: step 1289, loss 0.199932, acc 0.921875
2020-02-08T01:42:40.009630: step 1290, loss 0.210183, acc 0.921875
2020-02-08T01:42:40.223211: step 1291, loss 0.246204, acc 0.890625
2020-02-08T01:42:40.479501: step 1292, loss 0.171642, acc 0.953125
2020-02-08T01:42:40.813774: step 1293, loss 0.208046, acc 0.9375
2020-02-08T01:42:41.040794: step 1294, loss 0.162628, acc 0.96875
2020-02-08T01:42:41.307276: step 1295, loss 0.287194, acc 0.890625
2020-02-08T01:42:41.525750: step 1296, loss 0.17512, acc 0.90625
2020-02-08T01:42:41.760044: step 1297, loss 0.294838, acc 0.875
2020-02-08T01:42:41.983361: step 1298, loss 0.303729, acc 0.875
2020-02-08T01:42:42.245818: step 1299, loss 0.214472, acc 0.953125
2020-02-08T01:42:42.448065: step 1300, loss 0.290288, acc 0.875

Evaluation:
2020-02-08T01:42:42.911544: step 1300, loss 0.570579, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1300

2020-02-08T01:42:44.779535: step 1301, loss 0.292125, acc 0.84375
2020-02-08T01:42:45.046072: step 1302, loss 0.263126, acc 0.90625
2020-02-08T01:42:45.326267: step 1303, loss 0.23027, acc 0.875
2020-02-08T01:42:45.604386: step 1304, loss 0.214959, acc 0.921875
2020-02-08T01:42:45.912671: step 1305, loss 0.244856, acc 0.890625
2020-02-08T01:42:46.144451: step 1306, loss 0.237425, acc 0.921875
2020-02-08T01:42:46.350773: step 1307, loss 0.259375, acc 0.890625
2020-02-08T01:42:46.560830: step 1308, loss 0.199216, acc 0.953125
2020-02-08T01:42:46.774242: step 1309, loss 0.514685, acc 0.796875
2020-02-08T01:42:47.063920: step 1310, loss 0.125055, acc 0.9375
2020-02-08T01:42:47.309468: step 1311, loss 0.290061, acc 0.890625
2020-02-08T01:42:47.544054: step 1312, loss 0.191683, acc 0.953125
2020-02-08T01:42:47.761007: step 1313, loss 0.244999, acc 0.90625
2020-02-08T01:42:47.948498: step 1314, loss 0.228775, acc 0.875
2020-02-08T01:42:48.160086: step 1315, loss 0.251218, acc 0.90625
2020-02-08T01:42:48.368678: step 1316, loss 0.369383, acc 0.84375
2020-02-08T01:42:48.565401: step 1317, loss 0.272463, acc 0.859375
2020-02-08T01:42:48.801025: step 1318, loss 0.345129, acc 0.84375
2020-02-08T01:42:49.003484: step 1319, loss 0.203266, acc 0.953125
2020-02-08T01:42:49.244134: step 1320, loss 0.309787, acc 0.859375
2020-02-08T01:42:49.448742: step 1321, loss 0.349677, acc 0.828125
2020-02-08T01:42:49.686011: step 1322, loss 0.272199, acc 0.875
2020-02-08T01:42:49.909263: step 1323, loss 0.224217, acc 0.875
2020-02-08T01:42:50.120699: step 1324, loss 0.363328, acc 0.84375
2020-02-08T01:42:50.330903: step 1325, loss 0.163237, acc 0.90625
2020-02-08T01:42:50.545032: step 1326, loss 0.32668, acc 0.875
2020-02-08T01:42:50.767214: step 1327, loss 0.22273, acc 0.875
2020-02-08T01:42:50.998697: step 1328, loss 0.171463, acc 0.90625
2020-02-08T01:42:51.254202: step 1329, loss 0.364034, acc 0.859375
2020-02-08T01:42:51.468743: step 1330, loss 0.253144, acc 0.890625
2020-02-08T01:42:51.695965: step 1331, loss 0.265484, acc 0.875
2020-02-08T01:42:51.902329: step 1332, loss 0.244292, acc 0.90625
2020-02-08T01:42:52.113344: step 1333, loss 0.168535, acc 0.953125
2020-02-08T01:42:52.337633: step 1334, loss 0.226895, acc 0.9375
2020-02-08T01:42:52.571281: step 1335, loss 0.264449, acc 0.890625
2020-02-08T01:42:52.798288: step 1336, loss 0.205165, acc 0.9375
2020-02-08T01:42:53.016480: step 1337, loss 0.24537, acc 0.890625
2020-02-08T01:42:53.234771: step 1338, loss 0.187693, acc 0.921875
2020-02-08T01:42:53.454732: step 1339, loss 0.283875, acc 0.859375
2020-02-08T01:42:53.682837: step 1340, loss 0.471578, acc 0.8125
2020-02-08T01:42:53.899818: step 1341, loss 0.333515, acc 0.875
2020-02-08T01:42:54.100472: step 1342, loss 0.180266, acc 0.921875
2020-02-08T01:42:54.305488: step 1343, loss 0.239799, acc 0.921875
2020-02-08T01:42:54.544086: step 1344, loss 0.142474, acc 0.984375
2020-02-08T01:42:54.763428: step 1345, loss 0.347052, acc 0.875
2020-02-08T01:42:54.966360: step 1346, loss 0.209811, acc 0.90625
2020-02-08T01:42:55.198712: step 1347, loss 0.242713, acc 0.859375
2020-02-08T01:42:55.398482: step 1348, loss 0.289027, acc 0.859375
2020-02-08T01:42:55.614832: step 1349, loss 0.222474, acc 0.921875
2020-02-08T01:42:55.806404: step 1350, loss 0.195799, acc 0.95
2020-02-08T01:42:56.017054: step 1351, loss 0.232399, acc 0.90625
2020-02-08T01:42:56.236692: step 1352, loss 0.271051, acc 0.890625
2020-02-08T01:42:56.429469: step 1353, loss 0.244494, acc 0.921875
2020-02-08T01:42:56.640089: step 1354, loss 0.17145, acc 0.890625
2020-02-08T01:42:56.855023: step 1355, loss 0.270229, acc 0.859375
2020-02-08T01:42:57.060474: step 1356, loss 0.127402, acc 0.96875
2020-02-08T01:42:57.271549: step 1357, loss 0.31174, acc 0.859375
2020-02-08T01:42:57.486805: step 1358, loss 0.308527, acc 0.859375
2020-02-08T01:42:57.699385: step 1359, loss 0.0872718, acc 0.96875
2020-02-08T01:42:57.908876: step 1360, loss 0.191287, acc 0.9375
2020-02-08T01:42:58.138361: step 1361, loss 0.212188, acc 0.90625
2020-02-08T01:42:58.308854: step 1362, loss 0.279185, acc 0.875
2020-02-08T01:42:58.514896: step 1363, loss 0.139097, acc 0.953125
2020-02-08T01:42:58.719343: step 1364, loss 0.175648, acc 0.90625
2020-02-08T01:42:58.933492: step 1365, loss 0.222414, acc 0.890625
2020-02-08T01:42:59.177411: step 1366, loss 0.2725, acc 0.890625
2020-02-08T01:42:59.382535: step 1367, loss 0.204938, acc 0.9375
2020-02-08T01:42:59.607663: step 1368, loss 0.0949723, acc 0.96875
2020-02-08T01:42:59.821992: step 1369, loss 0.291468, acc 0.890625
2020-02-08T01:43:00.071147: step 1370, loss 0.125456, acc 0.96875
2020-02-08T01:43:00.383943: step 1371, loss 0.190361, acc 0.9375
2020-02-08T01:43:00.638171: step 1372, loss 0.126599, acc 0.96875
2020-02-08T01:43:00.858377: step 1373, loss 0.110894, acc 0.953125
2020-02-08T01:43:01.106056: step 1374, loss 0.255358, acc 0.890625
2020-02-08T01:43:01.359001: step 1375, loss 0.224729, acc 0.90625
2020-02-08T01:43:01.637999: step 1376, loss 0.23848, acc 0.921875
2020-02-08T01:43:01.890684: step 1377, loss 0.095545, acc 1
2020-02-08T01:43:02.116144: step 1378, loss 0.177341, acc 0.90625
2020-02-08T01:43:02.387124: step 1379, loss 0.170593, acc 0.953125
2020-02-08T01:43:02.639678: step 1380, loss 0.107132, acc 0.96875
2020-02-08T01:43:02.885727: step 1381, loss 0.19817, acc 0.90625
2020-02-08T01:43:03.062478: step 1382, loss 0.26624, acc 0.875
2020-02-08T01:43:03.292347: step 1383, loss 0.0845498, acc 0.984375
2020-02-08T01:43:03.521331: step 1384, loss 0.32477, acc 0.8125
2020-02-08T01:43:03.744727: step 1385, loss 0.226693, acc 0.890625
2020-02-08T01:43:03.969456: step 1386, loss 0.187693, acc 0.890625
2020-02-08T01:43:04.207054: step 1387, loss 0.242885, acc 0.890625
2020-02-08T01:43:04.421049: step 1388, loss 0.23332, acc 0.890625
2020-02-08T01:43:04.637433: step 1389, loss 0.15024, acc 0.984375
2020-02-08T01:43:04.844505: step 1390, loss 0.142989, acc 0.953125
2020-02-08T01:43:05.068234: step 1391, loss 0.182439, acc 0.890625
2020-02-08T01:43:05.287311: step 1392, loss 0.306442, acc 0.859375
2020-02-08T01:43:05.487093: step 1393, loss 0.159259, acc 0.96875
2020-02-08T01:43:05.711986: step 1394, loss 0.23995, acc 0.90625
2020-02-08T01:43:05.894546: step 1395, loss 0.167348, acc 0.90625
2020-02-08T01:43:06.110149: step 1396, loss 0.207698, acc 0.921875
2020-02-08T01:43:06.336604: step 1397, loss 0.219042, acc 0.890625
2020-02-08T01:43:06.556547: step 1398, loss 0.149868, acc 0.953125
2020-02-08T01:43:06.762148: step 1399, loss 0.178838, acc 0.921875
2020-02-08T01:43:06.975436: step 1400, loss 0.168588, acc 0.953125

Evaluation:
2020-02-08T01:43:07.388401: step 1400, loss 0.582621, acc 0.734522

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1400

2020-02-08T01:43:09.872106: step 1401, loss 0.0883159, acc 1
2020-02-08T01:43:10.080359: step 1402, loss 0.233002, acc 0.921875
2020-02-08T01:43:10.297741: step 1403, loss 0.243406, acc 0.890625
2020-02-08T01:43:10.519246: step 1404, loss 0.169716, acc 0.9375
2020-02-08T01:43:10.738048: step 1405, loss 0.186521, acc 0.921875
2020-02-08T01:43:10.978037: step 1406, loss 0.172081, acc 0.890625
2020-02-08T01:43:11.209305: step 1407, loss 0.166639, acc 0.921875
2020-02-08T01:43:11.423160: step 1408, loss 0.283948, acc 0.875
2020-02-08T01:43:11.645531: step 1409, loss 0.149281, acc 0.953125
2020-02-08T01:43:11.860765: step 1410, loss 0.186141, acc 0.921875
2020-02-08T01:43:12.081176: step 1411, loss 0.129855, acc 0.96875
2020-02-08T01:43:12.306820: step 1412, loss 0.172733, acc 0.9375
2020-02-08T01:43:12.520666: step 1413, loss 0.137087, acc 0.921875
2020-02-08T01:43:12.757033: step 1414, loss 0.207778, acc 0.921875
2020-02-08T01:43:12.962689: step 1415, loss 0.280661, acc 0.90625
2020-02-08T01:43:13.168282: step 1416, loss 0.174321, acc 0.953125
2020-02-08T01:43:13.390425: step 1417, loss 0.213022, acc 0.890625
2020-02-08T01:43:13.622002: step 1418, loss 0.235261, acc 0.890625
2020-02-08T01:43:13.863944: step 1419, loss 0.17556, acc 0.9375
2020-02-08T01:43:14.060472: step 1420, loss 0.126396, acc 0.953125
2020-02-08T01:43:14.263306: step 1421, loss 0.114193, acc 0.984375
2020-02-08T01:43:14.466528: step 1422, loss 0.157766, acc 0.953125
2020-02-08T01:43:14.699681: step 1423, loss 0.108299, acc 0.9375
2020-02-08T01:43:14.914754: step 1424, loss 0.22812, acc 0.890625
2020-02-08T01:43:15.094830: step 1425, loss 0.230603, acc 0.90625
2020-02-08T01:43:15.309752: step 1426, loss 0.236076, acc 0.9375
2020-02-08T01:43:15.524371: step 1427, loss 0.152809, acc 0.921875
2020-02-08T01:43:15.728106: step 1428, loss 0.126798, acc 0.9375
2020-02-08T01:43:15.931619: step 1429, loss 0.305639, acc 0.84375
2020-02-08T01:43:16.141255: step 1430, loss 0.0962681, acc 0.953125
2020-02-08T01:43:16.359786: step 1431, loss 0.12239, acc 0.96875
2020-02-08T01:43:16.563142: step 1432, loss 0.208897, acc 0.90625
2020-02-08T01:43:16.782953: step 1433, loss 0.128363, acc 0.96875
2020-02-08T01:43:17.007370: step 1434, loss 0.219408, acc 0.921875
2020-02-08T01:43:17.215829: step 1435, loss 0.118754, acc 0.984375
2020-02-08T01:43:17.419096: step 1436, loss 0.1514, acc 0.953125
2020-02-08T01:43:17.644228: step 1437, loss 0.190029, acc 0.921875
2020-02-08T01:43:17.845853: step 1438, loss 0.248959, acc 0.890625
2020-02-08T01:43:18.093908: step 1439, loss 0.207197, acc 0.953125
2020-02-08T01:43:18.305919: step 1440, loss 0.311367, acc 0.90625
2020-02-08T01:43:18.533046: step 1441, loss 0.240451, acc 0.90625
2020-02-08T01:43:18.713139: step 1442, loss 0.241698, acc 0.90625
2020-02-08T01:43:18.916219: step 1443, loss 0.24379, acc 0.890625
2020-02-08T01:43:19.184025: step 1444, loss 0.193946, acc 0.921875
2020-02-08T01:43:19.434133: step 1445, loss 0.114215, acc 0.953125
2020-02-08T01:43:19.706103: step 1446, loss 0.149044, acc 0.9375
2020-02-08T01:43:19.950066: step 1447, loss 0.252324, acc 0.953125
2020-02-08T01:43:20.210312: step 1448, loss 0.232182, acc 0.90625
2020-02-08T01:43:20.426734: step 1449, loss 0.272993, acc 0.90625
2020-02-08T01:43:20.630943: step 1450, loss 0.176618, acc 0.9375
2020-02-08T01:43:20.833823: step 1451, loss 0.165901, acc 0.9375
2020-02-08T01:43:21.032660: step 1452, loss 0.113793, acc 0.96875
2020-02-08T01:43:21.240215: step 1453, loss 0.135286, acc 0.9375
2020-02-08T01:43:21.544120: step 1454, loss 0.174116, acc 0.953125
2020-02-08T01:43:21.764899: step 1455, loss 0.217439, acc 0.921875
2020-02-08T01:43:21.991103: step 1456, loss 0.157358, acc 0.953125
2020-02-08T01:43:22.218984: step 1457, loss 0.0898806, acc 0.984375
2020-02-08T01:43:22.428534: step 1458, loss 0.145953, acc 0.953125
2020-02-08T01:43:22.646583: step 1459, loss 0.156643, acc 0.953125
2020-02-08T01:43:22.849472: step 1460, loss 0.192676, acc 0.9375
2020-02-08T01:43:23.054414: step 1461, loss 0.140591, acc 0.953125
2020-02-08T01:43:23.262668: step 1462, loss 0.189999, acc 0.9375
2020-02-08T01:43:23.464739: step 1463, loss 0.182736, acc 0.921875
2020-02-08T01:43:23.672137: step 1464, loss 0.255696, acc 0.875
2020-02-08T01:43:23.880696: step 1465, loss 0.205884, acc 0.890625
2020-02-08T01:43:24.070443: step 1466, loss 0.160768, acc 0.9375
2020-02-08T01:43:24.278227: step 1467, loss 0.171554, acc 0.9375
2020-02-08T01:43:24.499089: step 1468, loss 0.295172, acc 0.875
2020-02-08T01:43:24.714440: step 1469, loss 0.207984, acc 0.921875
2020-02-08T01:43:24.911575: step 1470, loss 0.154917, acc 0.9375
2020-02-08T01:43:25.136421: step 1471, loss 0.195117, acc 0.9375
2020-02-08T01:43:25.349419: step 1472, loss 0.127279, acc 0.953125
2020-02-08T01:43:25.560260: step 1473, loss 0.156929, acc 0.9375
2020-02-08T01:43:25.777207: step 1474, loss 0.133446, acc 0.9375
2020-02-08T01:43:25.997716: step 1475, loss 0.287402, acc 0.890625
2020-02-08T01:43:26.198323: step 1476, loss 0.173774, acc 0.9375
2020-02-08T01:43:26.414858: step 1477, loss 0.106179, acc 0.96875
2020-02-08T01:43:26.634358: step 1478, loss 0.169308, acc 0.921875
2020-02-08T01:43:26.848431: step 1479, loss 0.303378, acc 0.875
2020-02-08T01:43:27.071302: step 1480, loss 0.161654, acc 0.921875
2020-02-08T01:43:27.291102: step 1481, loss 0.171, acc 0.9375
2020-02-08T01:43:27.499305: step 1482, loss 0.23316, acc 0.921875
2020-02-08T01:43:27.718917: step 1483, loss 0.227253, acc 0.9375
2020-02-08T01:43:27.932637: step 1484, loss 0.222924, acc 0.9375
2020-02-08T01:43:28.150103: step 1485, loss 0.13468, acc 0.953125
2020-02-08T01:43:28.361976: step 1486, loss 0.164663, acc 0.921875
2020-02-08T01:43:28.587680: step 1487, loss 0.136598, acc 0.9375
2020-02-08T01:43:28.805678: step 1488, loss 0.207765, acc 0.890625
2020-02-08T01:43:29.055716: step 1489, loss 0.112271, acc 0.953125
2020-02-08T01:43:29.268440: step 1490, loss 0.290416, acc 0.875
2020-02-08T01:43:29.471946: step 1491, loss 0.133027, acc 0.9375
2020-02-08T01:43:29.697656: step 1492, loss 0.405691, acc 0.859375
2020-02-08T01:43:29.902580: step 1493, loss 0.229407, acc 0.890625
2020-02-08T01:43:30.117795: step 1494, loss 0.119545, acc 0.953125
2020-02-08T01:43:30.322791: step 1495, loss 0.345191, acc 0.859375
2020-02-08T01:43:30.543007: step 1496, loss 0.179704, acc 0.9375
2020-02-08T01:43:30.757397: step 1497, loss 0.288528, acc 0.890625
2020-02-08T01:43:30.958895: step 1498, loss 0.159877, acc 0.9375
2020-02-08T01:43:31.163927: step 1499, loss 0.164197, acc 0.953125
2020-02-08T01:43:31.366065: step 1500, loss 0.162285, acc 0.933333

Evaluation:
2020-02-08T01:43:31.740629: step 1500, loss 0.623872, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1500

2020-02-08T01:43:33.372110: step 1501, loss 0.132694, acc 0.96875
2020-02-08T01:43:33.569184: step 1502, loss 0.125468, acc 0.96875
2020-02-08T01:43:33.771841: step 1503, loss 0.119825, acc 0.953125
2020-02-08T01:43:33.970047: step 1504, loss 0.182759, acc 0.9375
2020-02-08T01:43:34.166724: step 1505, loss 0.107159, acc 0.96875
2020-02-08T01:43:34.359362: step 1506, loss 0.237456, acc 0.890625
2020-02-08T01:43:34.566748: step 1507, loss 0.245273, acc 0.890625
2020-02-08T01:43:34.766362: step 1508, loss 0.132608, acc 0.984375
2020-02-08T01:43:34.968348: step 1509, loss 0.154999, acc 0.9375
2020-02-08T01:43:35.169306: step 1510, loss 0.152848, acc 0.953125
2020-02-08T01:43:35.404441: step 1511, loss 0.104829, acc 0.96875
2020-02-08T01:43:35.581998: step 1512, loss 0.180623, acc 0.9375
2020-02-08T01:43:35.786241: step 1513, loss 0.156988, acc 0.96875
2020-02-08T01:43:35.990063: step 1514, loss 0.149893, acc 0.9375
2020-02-08T01:43:36.207163: step 1515, loss 0.094227, acc 0.96875
2020-02-08T01:43:36.407480: step 1516, loss 0.180102, acc 0.890625
2020-02-08T01:43:36.587999: step 1517, loss 0.0846436, acc 0.984375
2020-02-08T01:43:36.804079: step 1518, loss 0.186807, acc 0.9375
2020-02-08T01:43:36.974376: step 1519, loss 0.1305, acc 0.9375
2020-02-08T01:43:37.185386: step 1520, loss 0.176831, acc 0.9375
2020-02-08T01:43:37.392612: step 1521, loss 0.112199, acc 0.953125
2020-02-08T01:43:37.609912: step 1522, loss 0.154143, acc 0.96875
2020-02-08T01:43:37.810359: step 1523, loss 0.215968, acc 0.9375
2020-02-08T01:43:38.021178: step 1524, loss 0.210015, acc 0.90625
2020-02-08T01:43:38.211446: step 1525, loss 0.120377, acc 0.9375
2020-02-08T01:43:38.414044: step 1526, loss 0.193502, acc 0.90625
2020-02-08T01:43:38.625883: step 1527, loss 0.108767, acc 0.9375
2020-02-08T01:43:38.821821: step 1528, loss 0.204913, acc 0.890625
2020-02-08T01:43:39.007989: step 1529, loss 0.134092, acc 0.96875
2020-02-08T01:43:39.223446: step 1530, loss 0.131509, acc 0.96875
2020-02-08T01:43:39.439496: step 1531, loss 0.219604, acc 0.921875
2020-02-08T01:43:39.646238: step 1532, loss 0.110067, acc 0.9375
2020-02-08T01:43:39.888025: step 1533, loss 0.227295, acc 0.921875
2020-02-08T01:43:40.094047: step 1534, loss 0.17293, acc 0.953125
2020-02-08T01:43:40.344884: step 1535, loss 0.191474, acc 0.9375
2020-02-08T01:43:40.712288: step 1536, loss 0.132132, acc 0.9375
2020-02-08T01:43:40.989912: step 1537, loss 0.332139, acc 0.890625
2020-02-08T01:43:41.228404: step 1538, loss 0.139192, acc 0.953125
2020-02-08T01:43:41.426318: step 1539, loss 0.101951, acc 0.96875
2020-02-08T01:43:41.640257: step 1540, loss 0.119081, acc 0.953125
2020-02-08T01:43:41.838302: step 1541, loss 0.0615151, acc 1
2020-02-08T01:43:42.026635: step 1542, loss 0.11785, acc 0.96875
2020-02-08T01:43:42.235191: step 1543, loss 0.178893, acc 0.921875
2020-02-08T01:43:42.424230: step 1544, loss 0.177111, acc 0.9375
2020-02-08T01:43:42.642506: step 1545, loss 0.0733216, acc 0.96875
2020-02-08T01:43:42.832265: step 1546, loss 0.0651077, acc 0.984375
2020-02-08T01:43:43.026597: step 1547, loss 0.118485, acc 0.96875
2020-02-08T01:43:43.218729: step 1548, loss 0.162548, acc 0.9375
2020-02-08T01:43:43.420549: step 1549, loss 0.121881, acc 0.96875
2020-02-08T01:43:43.642260: step 1550, loss 0.147855, acc 0.9375
2020-02-08T01:43:43.836249: step 1551, loss 0.175824, acc 0.921875
2020-02-08T01:43:44.024839: step 1552, loss 0.12994, acc 0.96875
2020-02-08T01:43:44.212832: step 1553, loss 0.194987, acc 0.9375
2020-02-08T01:43:44.397962: step 1554, loss 0.140421, acc 0.953125
2020-02-08T01:43:44.587233: step 1555, loss 0.11629, acc 0.96875
2020-02-08T01:43:44.768758: step 1556, loss 0.181509, acc 0.9375
2020-02-08T01:43:44.951416: step 1557, loss 0.0611179, acc 0.984375
2020-02-08T01:43:45.135354: step 1558, loss 0.196734, acc 0.953125
2020-02-08T01:43:45.348383: step 1559, loss 0.153244, acc 0.90625
2020-02-08T01:43:45.541340: step 1560, loss 0.116324, acc 0.96875
2020-02-08T01:43:45.739059: step 1561, loss 0.103687, acc 0.96875
2020-02-08T01:43:45.921175: step 1562, loss 0.104358, acc 0.96875
2020-02-08T01:43:46.114950: step 1563, loss 0.203727, acc 0.921875
2020-02-08T01:43:46.306507: step 1564, loss 0.0720469, acc 0.984375
2020-02-08T01:43:46.492257: step 1565, loss 0.188678, acc 0.921875
2020-02-08T01:43:46.688878: step 1566, loss 0.100006, acc 0.9375
2020-02-08T01:43:46.871067: step 1567, loss 0.140412, acc 0.9375
2020-02-08T01:43:47.063009: step 1568, loss 0.163225, acc 0.921875
2020-02-08T01:43:47.245091: step 1569, loss 0.105464, acc 0.984375
2020-02-08T01:43:47.427237: step 1570, loss 0.159378, acc 0.953125
2020-02-08T01:43:47.610030: step 1571, loss 0.152044, acc 0.921875
2020-02-08T01:43:47.783194: step 1572, loss 0.0930935, acc 0.984375
2020-02-08T01:43:47.981099: step 1573, loss 0.0820433, acc 0.984375
2020-02-08T01:43:48.170738: step 1574, loss 0.170738, acc 0.953125
2020-02-08T01:43:48.348685: step 1575, loss 0.0723543, acc 0.953125
2020-02-08T01:43:48.542659: step 1576, loss 0.162532, acc 0.921875
2020-02-08T01:43:48.737700: step 1577, loss 0.142665, acc 0.953125
2020-02-08T01:43:48.922875: step 1578, loss 0.092596, acc 0.96875
2020-02-08T01:43:49.130865: step 1579, loss 0.170659, acc 0.953125
2020-02-08T01:43:49.312609: step 1580, loss 0.10797, acc 0.96875
2020-02-08T01:43:49.489285: step 1581, loss 0.111758, acc 0.953125
2020-02-08T01:43:49.677240: step 1582, loss 0.116996, acc 0.96875
2020-02-08T01:43:49.863484: step 1583, loss 0.130654, acc 0.984375
2020-02-08T01:43:50.042336: step 1584, loss 0.107475, acc 0.953125
2020-02-08T01:43:50.219595: step 1585, loss 0.0959192, acc 0.96875
2020-02-08T01:43:50.409860: step 1586, loss 0.198858, acc 0.9375
2020-02-08T01:43:50.586802: step 1587, loss 0.0856311, acc 0.984375
2020-02-08T01:43:50.773984: step 1588, loss 0.201221, acc 0.9375
2020-02-08T01:43:50.958669: step 1589, loss 0.0889187, acc 0.96875
2020-02-08T01:43:51.151536: step 1590, loss 0.102206, acc 0.96875
2020-02-08T01:43:51.348375: step 1591, loss 0.150241, acc 0.9375
2020-02-08T01:43:51.557347: step 1592, loss 0.145215, acc 0.953125
2020-02-08T01:43:51.799809: step 1593, loss 0.169515, acc 0.953125
2020-02-08T01:43:52.007754: step 1594, loss 0.105221, acc 0.96875
2020-02-08T01:43:52.196468: step 1595, loss 0.0748521, acc 0.984375
2020-02-08T01:43:52.393545: step 1596, loss 0.14148, acc 0.96875
2020-02-08T01:43:52.571201: step 1597, loss 0.140583, acc 0.953125
2020-02-08T01:43:52.764671: step 1598, loss 0.0969654, acc 0.984375
2020-02-08T01:43:52.951489: step 1599, loss 0.207388, acc 0.9375
2020-02-08T01:43:53.158179: step 1600, loss 0.113759, acc 0.9375

Evaluation:
2020-02-08T01:43:53.510123: step 1600, loss 0.647256, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1600

2020-02-08T01:43:55.163701: step 1601, loss 0.167838, acc 0.953125
2020-02-08T01:43:55.349908: step 1602, loss 0.145321, acc 0.921875
2020-02-08T01:43:55.530091: step 1603, loss 0.120038, acc 0.96875
2020-02-08T01:43:55.716902: step 1604, loss 0.133626, acc 0.96875
2020-02-08T01:43:55.895297: step 1605, loss 0.134714, acc 0.9375
2020-02-08T01:43:56.087674: step 1606, loss 0.15479, acc 0.953125
2020-02-08T01:43:56.281762: step 1607, loss 0.160579, acc 0.90625
2020-02-08T01:43:56.453702: step 1608, loss 0.116649, acc 0.953125
2020-02-08T01:43:56.646286: step 1609, loss 0.0883183, acc 0.96875
2020-02-08T01:43:56.832135: step 1610, loss 0.183364, acc 0.9375
2020-02-08T01:43:57.015258: step 1611, loss 0.141807, acc 0.96875
2020-02-08T01:43:57.204764: step 1612, loss 0.177464, acc 0.921875
2020-02-08T01:43:57.385786: step 1613, loss 0.238028, acc 0.890625
2020-02-08T01:43:57.570877: step 1614, loss 0.197556, acc 0.890625
2020-02-08T01:43:57.759866: step 1615, loss 0.105969, acc 0.96875
2020-02-08T01:43:57.944538: step 1616, loss 0.156265, acc 0.921875
2020-02-08T01:43:58.129163: step 1617, loss 0.134978, acc 0.9375
2020-02-08T01:43:58.309888: step 1618, loss 0.286925, acc 0.90625
2020-02-08T01:43:58.496895: step 1619, loss 0.0643108, acc 0.984375
2020-02-08T01:43:58.698285: step 1620, loss 0.133858, acc 0.953125
2020-02-08T01:43:58.882629: step 1621, loss 0.108133, acc 0.953125
2020-02-08T01:43:59.069678: step 1622, loss 0.191993, acc 0.90625
2020-02-08T01:43:59.263902: step 1623, loss 0.1591, acc 0.984375
2020-02-08T01:43:59.442521: step 1624, loss 0.11303, acc 0.96875
2020-02-08T01:43:59.625689: step 1625, loss 0.066038, acc 0.984375
2020-02-08T01:43:59.810541: step 1626, loss 0.0787597, acc 0.984375
2020-02-08T01:44:00.011821: step 1627, loss 0.0953581, acc 0.953125
2020-02-08T01:44:00.193803: step 1628, loss 0.125065, acc 0.9375
2020-02-08T01:44:00.368426: step 1629, loss 0.154108, acc 0.953125
2020-02-08T01:44:00.558923: step 1630, loss 0.117833, acc 0.96875
2020-02-08T01:44:00.760611: step 1631, loss 0.137137, acc 0.953125
2020-02-08T01:44:00.942580: step 1632, loss 0.215074, acc 0.890625
2020-02-08T01:44:01.136240: step 1633, loss 0.152299, acc 0.9375
2020-02-08T01:44:01.327467: step 1634, loss 0.221673, acc 0.890625
2020-02-08T01:44:01.519672: step 1635, loss 0.127869, acc 0.953125
2020-02-08T01:44:01.716496: step 1636, loss 0.161765, acc 0.9375
2020-02-08T01:44:01.906327: step 1637, loss 0.255254, acc 0.875
2020-02-08T01:44:02.106683: step 1638, loss 0.0788041, acc 0.984375
2020-02-08T01:44:02.296700: step 1639, loss 0.202466, acc 0.90625
2020-02-08T01:44:02.516968: step 1640, loss 0.191433, acc 0.9375
2020-02-08T01:44:02.715796: step 1641, loss 0.0510474, acc 1
2020-02-08T01:44:02.899610: step 1642, loss 0.182086, acc 0.9375
2020-02-08T01:44:03.103590: step 1643, loss 0.119369, acc 0.96875
2020-02-08T01:44:03.301152: step 1644, loss 0.148996, acc 0.953125
2020-02-08T01:44:03.496151: step 1645, loss 0.16516, acc 0.953125
2020-02-08T01:44:03.693857: step 1646, loss 0.196467, acc 0.96875
2020-02-08T01:44:03.885377: step 1647, loss 0.0623938, acc 1
2020-02-08T01:44:04.071506: step 1648, loss 0.136611, acc 0.921875
2020-02-08T01:44:04.251172: step 1649, loss 0.138949, acc 0.9375
2020-02-08T01:44:04.433889: step 1650, loss 0.226867, acc 0.916667
2020-02-08T01:44:04.626493: step 1651, loss 0.220231, acc 0.90625
2020-02-08T01:44:04.815197: step 1652, loss 0.208058, acc 0.9375
2020-02-08T01:44:05.003811: step 1653, loss 0.15004, acc 0.96875
2020-02-08T01:44:05.190031: step 1654, loss 0.118564, acc 0.953125
2020-02-08T01:44:05.387453: step 1655, loss 0.14249, acc 0.96875
2020-02-08T01:44:05.596286: step 1656, loss 0.132667, acc 0.953125
2020-02-08T01:44:05.786020: step 1657, loss 0.0718677, acc 0.984375
2020-02-08T01:44:05.980051: step 1658, loss 0.193613, acc 0.90625
2020-02-08T01:44:06.159731: step 1659, loss 0.0734885, acc 0.984375
2020-02-08T01:44:06.355668: step 1660, loss 0.0813752, acc 0.96875
2020-02-08T01:44:06.546760: step 1661, loss 0.223494, acc 0.90625
2020-02-08T01:44:06.740172: step 1662, loss 0.0923962, acc 0.96875
2020-02-08T01:44:06.935489: step 1663, loss 0.186977, acc 0.921875
2020-02-08T01:44:07.125107: step 1664, loss 0.120251, acc 0.96875
2020-02-08T01:44:07.309155: step 1665, loss 0.0715438, acc 0.984375
2020-02-08T01:44:07.498837: step 1666, loss 0.0665454, acc 0.96875
2020-02-08T01:44:07.702192: step 1667, loss 0.128273, acc 0.9375
2020-02-08T01:44:07.899427: step 1668, loss 0.0693105, acc 1
2020-02-08T01:44:08.104904: step 1669, loss 0.0713139, acc 0.984375
2020-02-08T01:44:08.297975: step 1670, loss 0.0570168, acc 1
2020-02-08T01:44:08.495231: step 1671, loss 0.0948675, acc 0.984375
2020-02-08T01:44:08.707505: step 1672, loss 0.108699, acc 0.953125
2020-02-08T01:44:08.900163: step 1673, loss 0.0721712, acc 0.984375
2020-02-08T01:44:09.104647: step 1674, loss 0.0670232, acc 0.96875
2020-02-08T01:44:09.291685: step 1675, loss 0.115339, acc 0.953125
2020-02-08T01:44:09.490715: step 1676, loss 0.0667535, acc 0.96875
2020-02-08T01:44:09.704373: step 1677, loss 0.11521, acc 0.953125
2020-02-08T01:44:09.902056: step 1678, loss 0.133542, acc 0.9375
2020-02-08T01:44:10.151207: step 1679, loss 0.113978, acc 0.96875
2020-02-08T01:44:10.355612: step 1680, loss 0.16984, acc 0.921875
2020-02-08T01:44:10.589607: step 1681, loss 0.279082, acc 0.9375
2020-02-08T01:44:10.787262: step 1682, loss 0.101204, acc 0.96875
2020-02-08T01:44:10.977149: step 1683, loss 0.10009, acc 0.96875
2020-02-08T01:44:11.173370: step 1684, loss 0.0669143, acc 0.984375
2020-02-08T01:44:11.373018: step 1685, loss 0.117727, acc 0.96875
2020-02-08T01:44:11.571371: step 1686, loss 0.113701, acc 0.953125
2020-02-08T01:44:11.773820: step 1687, loss 0.0806189, acc 0.984375
2020-02-08T01:44:11.966081: step 1688, loss 0.0536173, acc 0.984375
2020-02-08T01:44:12.182391: step 1689, loss 0.0550275, acc 0.984375
2020-02-08T01:44:12.373843: step 1690, loss 0.0783131, acc 0.953125
2020-02-08T01:44:12.565283: step 1691, loss 0.110625, acc 0.953125
2020-02-08T01:44:12.767966: step 1692, loss 0.0894285, acc 0.96875
2020-02-08T01:44:12.955491: step 1693, loss 0.140363, acc 0.921875
2020-02-08T01:44:13.145597: step 1694, loss 0.0791173, acc 0.96875
2020-02-08T01:44:13.342973: step 1695, loss 0.0570381, acc 0.96875
2020-02-08T01:44:13.562512: step 1696, loss 0.101939, acc 0.9375
2020-02-08T01:44:13.787366: step 1697, loss 0.127795, acc 0.96875
2020-02-08T01:44:13.983680: step 1698, loss 0.0975208, acc 0.9375
2020-02-08T01:44:14.203663: step 1699, loss 0.162276, acc 0.921875
2020-02-08T01:44:14.411940: step 1700, loss 0.260697, acc 0.875

Evaluation:
2020-02-08T01:44:14.799098: step 1700, loss 0.661799, acc 0.734522

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1700

2020-02-08T01:44:17.507164: step 1701, loss 0.155847, acc 0.953125
2020-02-08T01:44:17.724028: step 1702, loss 0.0784963, acc 0.96875
2020-02-08T01:44:17.910360: step 1703, loss 0.120253, acc 0.953125
2020-02-08T01:44:18.109344: step 1704, loss 0.12458, acc 0.96875
2020-02-08T01:44:18.405238: step 1705, loss 0.151874, acc 0.9375
2020-02-08T01:44:18.578681: step 1706, loss 0.0744447, acc 0.984375
2020-02-08T01:44:18.760319: step 1707, loss 0.107559, acc 0.9375
2020-02-08T01:44:18.961823: step 1708, loss 0.137449, acc 0.9375
2020-02-08T01:44:19.145022: step 1709, loss 0.169348, acc 0.9375
2020-02-08T01:44:19.323721: step 1710, loss 0.106553, acc 0.96875
2020-02-08T01:44:19.505677: step 1711, loss 0.148272, acc 0.921875
2020-02-08T01:44:19.697205: step 1712, loss 0.0366287, acc 1
2020-02-08T01:44:19.880971: step 1713, loss 0.0814655, acc 0.984375
2020-02-08T01:44:20.072626: step 1714, loss 0.113741, acc 0.96875
2020-02-08T01:44:20.252410: step 1715, loss 0.0838671, acc 0.96875
2020-02-08T01:44:20.443373: step 1716, loss 0.11683, acc 0.96875
2020-02-08T01:44:20.641989: step 1717, loss 0.113496, acc 0.953125
2020-02-08T01:44:20.822989: step 1718, loss 0.14963, acc 0.9375
2020-02-08T01:44:21.004902: step 1719, loss 0.0896506, acc 0.953125
2020-02-08T01:44:21.181993: step 1720, loss 0.0743558, acc 0.984375
2020-02-08T01:44:21.392913: step 1721, loss 0.0456232, acc 0.984375
2020-02-08T01:44:21.587281: step 1722, loss 0.107359, acc 0.953125
2020-02-08T01:44:21.813945: step 1723, loss 0.0863815, acc 0.96875
2020-02-08T01:44:21.989008: step 1724, loss 0.190879, acc 0.921875
2020-02-08T01:44:22.183024: step 1725, loss 0.113291, acc 0.96875
2020-02-08T01:44:22.363915: step 1726, loss 0.1265, acc 0.9375
2020-02-08T01:44:22.554489: step 1727, loss 0.179144, acc 0.9375
2020-02-08T01:44:22.751826: step 1728, loss 0.0377222, acc 1
2020-02-08T01:44:22.937016: step 1729, loss 0.13152, acc 0.953125
2020-02-08T01:44:23.117918: step 1730, loss 0.106317, acc 0.96875
2020-02-08T01:44:23.313054: step 1731, loss 0.119617, acc 0.9375
2020-02-08T01:44:23.500544: step 1732, loss 0.185194, acc 0.9375
2020-02-08T01:44:23.701684: step 1733, loss 0.116832, acc 0.96875
2020-02-08T01:44:23.892484: step 1734, loss 0.103063, acc 0.9375
2020-02-08T01:44:24.081870: step 1735, loss 0.0912078, acc 0.9375
2020-02-08T01:44:24.261695: step 1736, loss 0.124569, acc 0.953125
2020-02-08T01:44:24.507351: step 1737, loss 0.117051, acc 0.953125
2020-02-08T01:44:24.720477: step 1738, loss 0.0965456, acc 0.984375
2020-02-08T01:44:24.914098: step 1739, loss 0.0400175, acc 1
2020-02-08T01:44:25.098171: step 1740, loss 0.116896, acc 0.96875
2020-02-08T01:44:25.282170: step 1741, loss 0.117524, acc 0.96875
2020-02-08T01:44:25.473574: step 1742, loss 0.076619, acc 0.96875
2020-02-08T01:44:25.696130: step 1743, loss 0.0742429, acc 0.984375
2020-02-08T01:44:25.882802: step 1744, loss 0.128852, acc 0.96875
2020-02-08T01:44:26.070829: step 1745, loss 0.155194, acc 0.953125
2020-02-08T01:44:26.280635: step 1746, loss 0.177348, acc 0.96875
2020-02-08T01:44:26.515189: step 1747, loss 0.0625277, acc 0.984375
2020-02-08T01:44:26.766523: step 1748, loss 0.115058, acc 0.9375
2020-02-08T01:44:26.972774: step 1749, loss 0.106494, acc 0.96875
2020-02-08T01:44:27.176634: step 1750, loss 0.0629671, acc 1
2020-02-08T01:44:27.499201: step 1751, loss 0.148902, acc 0.953125
2020-02-08T01:44:27.815989: step 1752, loss 0.134496, acc 0.96875
2020-02-08T01:44:28.016372: step 1753, loss 0.104629, acc 0.96875
2020-02-08T01:44:28.216962: step 1754, loss 0.112202, acc 0.953125
2020-02-08T01:44:28.417409: step 1755, loss 0.133466, acc 0.9375
2020-02-08T01:44:28.632832: step 1756, loss 0.0508077, acc 0.984375
2020-02-08T01:44:28.847102: step 1757, loss 0.201552, acc 0.921875
2020-02-08T01:44:29.066631: step 1758, loss 0.111143, acc 0.953125
2020-02-08T01:44:29.297056: step 1759, loss 0.0715446, acc 0.984375
2020-02-08T01:44:29.550128: step 1760, loss 0.0503751, acc 1
2020-02-08T01:44:29.816913: step 1761, loss 0.135682, acc 0.921875
2020-02-08T01:44:30.038309: step 1762, loss 0.0409174, acc 1
2020-02-08T01:44:30.251070: step 1763, loss 0.14158, acc 0.953125
2020-02-08T01:44:30.448472: step 1764, loss 0.108422, acc 0.96875
2020-02-08T01:44:30.667574: step 1765, loss 0.0854893, acc 0.96875
2020-02-08T01:44:30.866636: step 1766, loss 0.124201, acc 0.9375
2020-02-08T01:44:31.064954: step 1767, loss 0.067432, acc 0.96875
2020-02-08T01:44:31.287025: step 1768, loss 0.0605782, acc 0.96875
2020-02-08T01:44:31.499566: step 1769, loss 0.0830374, acc 0.96875
2020-02-08T01:44:31.712246: step 1770, loss 0.114148, acc 0.984375
2020-02-08T01:44:31.933815: step 1771, loss 0.12947, acc 0.953125
2020-02-08T01:44:32.139670: step 1772, loss 0.0363073, acc 1
2020-02-08T01:44:32.349601: step 1773, loss 0.185385, acc 0.9375
2020-02-08T01:44:32.568319: step 1774, loss 0.21926, acc 0.90625
2020-02-08T01:44:32.799117: step 1775, loss 0.0971432, acc 0.953125
2020-02-08T01:44:33.015788: step 1776, loss 0.160172, acc 0.921875
2020-02-08T01:44:33.214893: step 1777, loss 0.133606, acc 0.96875
2020-02-08T01:44:33.414607: step 1778, loss 0.0807533, acc 0.96875
2020-02-08T01:44:33.630359: step 1779, loss 0.165155, acc 0.9375
2020-02-08T01:44:33.832975: step 1780, loss 0.178791, acc 0.921875
2020-02-08T01:44:34.034116: step 1781, loss 0.0731072, acc 0.984375
2020-02-08T01:44:34.230229: step 1782, loss 0.17108, acc 0.90625
2020-02-08T01:44:34.434281: step 1783, loss 0.132157, acc 0.953125
2020-02-08T01:44:34.717019: step 1784, loss 0.0567938, acc 0.984375
2020-02-08T01:44:34.959733: step 1785, loss 0.104833, acc 0.9375
2020-02-08T01:44:35.166052: step 1786, loss 0.130342, acc 0.96875
2020-02-08T01:44:35.364635: step 1787, loss 0.154396, acc 0.921875
2020-02-08T01:44:35.574546: step 1788, loss 0.0881948, acc 0.96875
2020-02-08T01:44:35.805721: step 1789, loss 0.051701, acc 0.984375
2020-02-08T01:44:36.015204: step 1790, loss 0.0401272, acc 1
2020-02-08T01:44:36.214903: step 1791, loss 0.0864269, acc 0.96875
2020-02-08T01:44:36.399917: step 1792, loss 0.119409, acc 0.953125
2020-02-08T01:44:36.605511: step 1793, loss 0.183225, acc 0.953125
2020-02-08T01:44:36.817045: step 1794, loss 0.120799, acc 0.9375
2020-02-08T01:44:37.019548: step 1795, loss 0.195664, acc 0.921875
2020-02-08T01:44:37.223796: step 1796, loss 0.0664855, acc 1
2020-02-08T01:44:37.431619: step 1797, loss 0.171953, acc 0.9375
2020-02-08T01:44:37.638678: step 1798, loss 0.149456, acc 0.9375
2020-02-08T01:44:37.837567: step 1799, loss 0.155341, acc 0.90625
2020-02-08T01:44:38.032930: step 1800, loss 0.0709068, acc 0.966667

Evaluation:
2020-02-08T01:44:38.391134: step 1800, loss 0.675597, acc 0.736398

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1800

2020-02-08T01:44:40.183209: step 1801, loss 0.0744481, acc 0.984375
2020-02-08T01:44:40.377079: step 1802, loss 0.0527388, acc 0.984375
2020-02-08T01:44:40.589539: step 1803, loss 0.0833744, acc 0.984375
2020-02-08T01:44:40.799593: step 1804, loss 0.109718, acc 0.953125
2020-02-08T01:44:40.986967: step 1805, loss 0.145613, acc 0.9375
2020-02-08T01:44:41.181134: step 1806, loss 0.0403133, acc 1
2020-02-08T01:44:41.383518: step 1807, loss 0.0801918, acc 0.96875
2020-02-08T01:44:41.589718: step 1808, loss 0.0864475, acc 0.984375
2020-02-08T01:44:41.784200: step 1809, loss 0.0626303, acc 0.984375
2020-02-08T01:44:41.991115: step 1810, loss 0.177269, acc 0.96875
2020-02-08T01:44:42.187613: step 1811, loss 0.0714968, acc 0.953125
2020-02-08T01:44:42.374862: step 1812, loss 0.111874, acc 0.953125
2020-02-08T01:44:42.598658: step 1813, loss 0.0873246, acc 0.96875
2020-02-08T01:44:42.788647: step 1814, loss 0.0711024, acc 0.96875
2020-02-08T01:44:42.985144: step 1815, loss 0.107869, acc 0.96875
2020-02-08T01:44:43.187619: step 1816, loss 0.0712029, acc 0.984375
2020-02-08T01:44:43.391494: step 1817, loss 0.0796574, acc 0.96875
2020-02-08T01:44:43.589961: step 1818, loss 0.0594392, acc 0.984375
2020-02-08T01:44:43.777097: step 1819, loss 0.091601, acc 0.984375
2020-02-08T01:44:43.986849: step 1820, loss 0.153801, acc 0.9375
2020-02-08T01:44:44.165028: step 1821, loss 0.0388732, acc 1
2020-02-08T01:44:44.371608: step 1822, loss 0.0321725, acc 1
2020-02-08T01:44:44.571022: step 1823, loss 0.0689473, acc 0.96875
2020-02-08T01:44:44.774413: step 1824, loss 0.0518826, acc 0.984375
2020-02-08T01:44:44.964981: step 1825, loss 0.146845, acc 0.96875
2020-02-08T01:44:45.161034: step 1826, loss 0.0693306, acc 0.984375
2020-02-08T01:44:45.359673: step 1827, loss 0.0257654, acc 1
2020-02-08T01:44:45.565535: step 1828, loss 0.0475455, acc 0.984375
2020-02-08T01:44:45.757651: step 1829, loss 0.123896, acc 0.953125
2020-02-08T01:44:45.950814: step 1830, loss 0.0643194, acc 0.953125
2020-02-08T01:44:46.150519: step 1831, loss 0.0835621, acc 0.984375
2020-02-08T01:44:46.337569: step 1832, loss 0.0693393, acc 0.96875
2020-02-08T01:44:46.543895: step 1833, loss 0.14201, acc 0.9375
2020-02-08T01:44:46.748945: step 1834, loss 0.0817524, acc 0.984375
2020-02-08T01:44:46.943733: step 1835, loss 0.0934067, acc 0.984375
2020-02-08T01:44:47.136782: step 1836, loss 0.179875, acc 0.921875
2020-02-08T01:44:47.335368: step 1837, loss 0.135704, acc 0.9375
2020-02-08T01:44:47.536100: step 1838, loss 0.108432, acc 0.96875
2020-02-08T01:44:47.735462: step 1839, loss 0.0751042, acc 0.953125
2020-02-08T01:44:47.932249: step 1840, loss 0.0823978, acc 0.96875
2020-02-08T01:44:48.115223: step 1841, loss 0.101585, acc 0.96875
2020-02-08T01:44:48.307883: step 1842, loss 0.0972372, acc 0.953125
2020-02-08T01:44:48.504582: step 1843, loss 0.0584638, acc 0.984375
2020-02-08T01:44:48.712582: step 1844, loss 0.0802691, acc 0.953125
2020-02-08T01:44:48.906958: step 1845, loss 0.0965759, acc 0.96875
2020-02-08T01:44:49.136985: step 1846, loss 0.069627, acc 0.96875
2020-02-08T01:44:49.344758: step 1847, loss 0.127486, acc 0.96875
2020-02-08T01:44:49.553545: step 1848, loss 0.114504, acc 0.9375
2020-02-08T01:44:49.796474: step 1849, loss 0.0699613, acc 0.984375
2020-02-08T01:44:50.035293: step 1850, loss 0.0344465, acc 1
2020-02-08T01:44:50.308097: step 1851, loss 0.0937097, acc 0.96875
2020-02-08T01:44:50.531585: step 1852, loss 0.0894304, acc 0.96875
2020-02-08T01:44:50.796322: step 1853, loss 0.114722, acc 0.96875
2020-02-08T01:44:51.077786: step 1854, loss 0.0776285, acc 0.984375
2020-02-08T01:44:51.348334: step 1855, loss 0.110553, acc 0.953125
2020-02-08T01:44:51.605985: step 1856, loss 0.0842421, acc 0.96875
2020-02-08T01:44:51.859625: step 1857, loss 0.11469, acc 0.953125
2020-02-08T01:44:52.095636: step 1858, loss 0.0320446, acc 1
2020-02-08T01:44:52.305157: step 1859, loss 0.0728328, acc 0.984375
2020-02-08T01:44:52.500057: step 1860, loss 0.073415, acc 0.953125
2020-02-08T01:44:52.706786: step 1861, loss 0.133424, acc 0.953125
2020-02-08T01:44:52.906103: step 1862, loss 0.0414303, acc 0.984375
2020-02-08T01:44:53.093589: step 1863, loss 0.0926773, acc 0.953125
2020-02-08T01:44:53.397993: step 1864, loss 0.0778449, acc 0.96875
2020-02-08T01:44:53.623238: step 1865, loss 0.0843533, acc 0.96875
2020-02-08T01:44:53.800237: step 1866, loss 0.0477772, acc 0.984375
2020-02-08T01:44:53.982037: step 1867, loss 0.057, acc 0.984375
2020-02-08T01:44:54.174999: step 1868, loss 0.0822482, acc 0.984375
2020-02-08T01:44:54.358872: step 1869, loss 0.100385, acc 0.953125
2020-02-08T01:44:54.547913: step 1870, loss 0.0909485, acc 0.953125
2020-02-08T01:44:54.743961: step 1871, loss 0.133335, acc 0.9375
2020-02-08T01:44:54.930586: step 1872, loss 0.0883131, acc 0.953125
2020-02-08T01:44:55.130426: step 1873, loss 0.122544, acc 0.9375
2020-02-08T01:44:55.316132: step 1874, loss 0.0625461, acc 0.96875
2020-02-08T01:44:55.522413: step 1875, loss 0.0363512, acc 1
2020-02-08T01:44:55.730737: step 1876, loss 0.060541, acc 0.984375
2020-02-08T01:44:55.926127: step 1877, loss 0.0887265, acc 0.984375
2020-02-08T01:44:56.128552: step 1878, loss 0.129021, acc 0.9375
2020-02-08T01:44:56.327319: step 1879, loss 0.0321777, acc 1
2020-02-08T01:44:56.531611: step 1880, loss 0.112502, acc 0.9375
2020-02-08T01:44:56.738416: step 1881, loss 0.0784475, acc 0.96875
2020-02-08T01:44:56.930444: step 1882, loss 0.0703383, acc 0.984375
2020-02-08T01:44:57.131588: step 1883, loss 0.0881283, acc 0.953125
2020-02-08T01:44:57.326182: step 1884, loss 0.0793058, acc 0.96875
2020-02-08T01:44:57.508484: step 1885, loss 0.0968576, acc 0.953125
2020-02-08T01:44:57.699180: step 1886, loss 0.0862941, acc 0.953125
2020-02-08T01:44:57.901288: step 1887, loss 0.0721626, acc 0.96875
2020-02-08T01:44:58.108947: step 1888, loss 0.0962852, acc 0.96875
2020-02-08T01:44:58.301078: step 1889, loss 0.111837, acc 0.96875
2020-02-08T01:44:58.508253: step 1890, loss 0.0497457, acc 0.984375
2020-02-08T01:44:58.706685: step 1891, loss 0.0942711, acc 0.984375
2020-02-08T01:44:58.902590: step 1892, loss 0.0717506, acc 0.984375
2020-02-08T01:44:59.117885: step 1893, loss 0.0620781, acc 0.984375
2020-02-08T01:44:59.304833: step 1894, loss 0.0714975, acc 0.96875
2020-02-08T01:44:59.491483: step 1895, loss 0.0487573, acc 0.96875
2020-02-08T01:44:59.699975: step 1896, loss 0.0294715, acc 1
2020-02-08T01:44:59.890321: step 1897, loss 0.0873381, acc 0.96875
2020-02-08T01:45:00.098183: step 1898, loss 0.100452, acc 0.96875
2020-02-08T01:45:00.286382: step 1899, loss 0.065754, acc 1
2020-02-08T01:45:00.482611: step 1900, loss 0.0439694, acc 1

Evaluation:
2020-02-08T01:45:00.841421: step 1900, loss 0.695345, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-1900

2020-02-08T01:45:02.514044: step 1901, loss 0.0398339, acc 0.984375
2020-02-08T01:45:02.733171: step 1902, loss 0.0653123, acc 0.96875
2020-02-08T01:45:02.931448: step 1903, loss 0.109898, acc 0.921875
2020-02-08T01:45:03.127177: step 1904, loss 0.0573148, acc 0.984375
2020-02-08T01:45:03.323743: step 1905, loss 0.130684, acc 0.9375
2020-02-08T01:45:03.507335: step 1906, loss 0.130152, acc 0.953125
2020-02-08T01:45:03.708325: step 1907, loss 0.0916759, acc 0.953125
2020-02-08T01:45:03.911000: step 1908, loss 0.068917, acc 0.96875
2020-02-08T01:45:04.105133: step 1909, loss 0.0688263, acc 0.96875
2020-02-08T01:45:04.316596: step 1910, loss 0.125684, acc 0.984375
2020-02-08T01:45:04.540593: step 1911, loss 0.0680588, acc 0.96875
2020-02-08T01:45:04.748014: step 1912, loss 0.0804417, acc 0.953125
2020-02-08T01:45:04.931447: step 1913, loss 0.153675, acc 0.9375
2020-02-08T01:45:05.139399: step 1914, loss 0.0599068, acc 0.984375
2020-02-08T01:45:05.350762: step 1915, loss 0.105492, acc 0.9375
2020-02-08T01:45:05.679564: step 1916, loss 0.055754, acc 0.984375
2020-02-08T01:45:05.989028: step 1917, loss 0.106174, acc 0.96875
2020-02-08T01:45:06.199807: step 1918, loss 0.0912827, acc 0.984375
2020-02-08T01:45:06.398021: step 1919, loss 0.059515, acc 0.96875
2020-02-08T01:45:06.597143: step 1920, loss 0.101338, acc 0.96875
2020-02-08T01:45:06.799416: step 1921, loss 0.121458, acc 0.921875
2020-02-08T01:45:06.995442: step 1922, loss 0.0495889, acc 0.984375
2020-02-08T01:45:07.183515: step 1923, loss 0.0978734, acc 0.96875
2020-02-08T01:45:07.371616: step 1924, loss 0.0789477, acc 0.96875
2020-02-08T01:45:07.560694: step 1925, loss 0.14696, acc 0.9375
2020-02-08T01:45:07.762642: step 1926, loss 0.135113, acc 0.953125
2020-02-08T01:45:07.952958: step 1927, loss 0.151586, acc 0.9375
2020-02-08T01:45:08.144320: step 1928, loss 0.0687012, acc 0.96875
2020-02-08T01:45:08.339726: step 1929, loss 0.0503687, acc 0.984375
2020-02-08T01:45:08.540512: step 1930, loss 0.0857331, acc 0.9375
2020-02-08T01:45:08.747397: step 1931, loss 0.160124, acc 0.9375
2020-02-08T01:45:08.927532: step 1932, loss 0.132383, acc 0.953125
2020-02-08T01:45:09.134436: step 1933, loss 0.0459187, acc 0.984375
2020-02-08T01:45:09.332534: step 1934, loss 0.112916, acc 0.953125
2020-02-08T01:45:09.512899: step 1935, loss 0.0731731, acc 0.953125
2020-02-08T01:45:09.707610: step 1936, loss 0.14601, acc 0.9375
2020-02-08T01:45:09.901550: step 1937, loss 0.0376134, acc 0.984375
2020-02-08T01:45:10.098025: step 1938, loss 0.0396533, acc 0.96875
2020-02-08T01:45:10.292593: step 1939, loss 0.05407, acc 0.984375
2020-02-08T01:45:10.490257: step 1940, loss 0.0631399, acc 0.96875
2020-02-08T01:45:10.692000: step 1941, loss 0.0894914, acc 0.96875
2020-02-08T01:45:10.888842: step 1942, loss 0.0998941, acc 0.96875
2020-02-08T01:45:11.066959: step 1943, loss 0.0342185, acc 1
2020-02-08T01:45:11.242405: step 1944, loss 0.221834, acc 0.921875
2020-02-08T01:45:11.424112: step 1945, loss 0.0957048, acc 0.953125
2020-02-08T01:45:11.618646: step 1946, loss 0.171497, acc 0.90625
2020-02-08T01:45:11.816853: step 1947, loss 0.0935992, acc 0.96875
2020-02-08T01:45:12.001213: step 1948, loss 0.103981, acc 0.96875
2020-02-08T01:45:12.184520: step 1949, loss 0.125939, acc 0.9375
2020-02-08T01:45:12.366891: step 1950, loss 0.148219, acc 0.95
2020-02-08T01:45:12.558685: step 1951, loss 0.111809, acc 0.9375
2020-02-08T01:45:12.758270: step 1952, loss 0.0731739, acc 0.953125
2020-02-08T01:45:12.948256: step 1953, loss 0.0784317, acc 0.96875
2020-02-08T01:45:13.126286: step 1954, loss 0.0734122, acc 0.96875
2020-02-08T01:45:13.317370: step 1955, loss 0.0570028, acc 0.984375
2020-02-08T01:45:13.510543: step 1956, loss 0.0596417, acc 0.984375
2020-02-08T01:45:13.705329: step 1957, loss 0.0533971, acc 1
2020-02-08T01:45:13.890755: step 1958, loss 0.0523883, acc 0.984375
2020-02-08T01:45:14.088097: step 1959, loss 0.0453011, acc 0.984375
2020-02-08T01:45:14.273761: step 1960, loss 0.0565412, acc 0.96875
2020-02-08T01:45:14.452219: step 1961, loss 0.0421792, acc 1
2020-02-08T01:45:14.650695: step 1962, loss 0.0656259, acc 0.984375
2020-02-08T01:45:14.832765: step 1963, loss 0.0388727, acc 0.984375
2020-02-08T01:45:15.017017: step 1964, loss 0.0294629, acc 1
2020-02-08T01:45:15.208178: step 1965, loss 0.0452046, acc 0.984375
2020-02-08T01:45:15.401324: step 1966, loss 0.0286903, acc 1
2020-02-08T01:45:15.575043: step 1967, loss 0.0546061, acc 0.984375
2020-02-08T01:45:15.766146: step 1968, loss 0.0868043, acc 0.96875
2020-02-08T01:45:15.953791: step 1969, loss 0.0779351, acc 0.984375
2020-02-08T01:45:16.141718: step 1970, loss 0.0934615, acc 0.953125
2020-02-08T01:45:16.331175: step 1971, loss 0.0909812, acc 0.984375
2020-02-08T01:45:16.509118: step 1972, loss 0.0630904, acc 0.984375
2020-02-08T01:45:16.699181: step 1973, loss 0.0880298, acc 0.96875
2020-02-08T01:45:16.885187: step 1974, loss 0.0738101, acc 0.96875
2020-02-08T01:45:17.065317: step 1975, loss 0.0902508, acc 0.96875
2020-02-08T01:45:17.246623: step 1976, loss 0.0283229, acc 1
2020-02-08T01:45:17.430453: step 1977, loss 0.0449316, acc 1
2020-02-08T01:45:17.620158: step 1978, loss 0.0195431, acc 1
2020-02-08T01:45:17.800421: step 1979, loss 0.0897912, acc 0.953125
2020-02-08T01:45:17.978031: step 1980, loss 0.0636919, acc 0.96875
2020-02-08T01:45:18.167991: step 1981, loss 0.0277146, acc 1
2020-02-08T01:45:18.366040: step 1982, loss 0.0426033, acc 0.984375
2020-02-08T01:45:18.562141: step 1983, loss 0.035752, acc 1
2020-02-08T01:45:18.765653: step 1984, loss 0.0310215, acc 1
2020-02-08T01:45:18.959612: step 1985, loss 0.0823004, acc 0.984375
2020-02-08T01:45:19.163107: step 1986, loss 0.0490185, acc 0.984375
2020-02-08T01:45:19.351753: step 1987, loss 0.0571194, acc 0.984375
2020-02-08T01:45:19.534241: step 1988, loss 0.0451501, acc 0.984375
2020-02-08T01:45:19.739379: step 1989, loss 0.0286147, acc 1
2020-02-08T01:45:19.922447: step 1990, loss 0.0779613, acc 0.953125
2020-02-08T01:45:20.106571: step 1991, loss 0.0627553, acc 0.984375
2020-02-08T01:45:20.295429: step 1992, loss 0.0292038, acc 1
2020-02-08T01:45:20.486694: step 1993, loss 0.0582094, acc 0.96875
2020-02-08T01:45:20.676136: step 1994, loss 0.0173834, acc 1
2020-02-08T01:45:20.852569: step 1995, loss 0.0856586, acc 0.9375
2020-02-08T01:45:21.034785: step 1996, loss 0.0240907, acc 1
2020-02-08T01:45:21.229112: step 1997, loss 0.0785778, acc 0.953125
2020-02-08T01:45:21.431495: step 1998, loss 0.0548503, acc 0.984375
2020-02-08T01:45:21.635445: step 1999, loss 0.0664108, acc 0.984375
2020-02-08T01:45:21.863329: step 2000, loss 0.088324, acc 0.984375

Evaluation:
2020-02-08T01:45:22.215315: step 2000, loss 0.73744, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2000

2020-02-08T01:45:25.212833: step 2001, loss 0.0139967, acc 1
2020-02-08T01:45:25.457764: step 2002, loss 0.0521154, acc 0.984375
2020-02-08T01:45:25.667298: step 2003, loss 0.047594, acc 1
2020-02-08T01:45:25.905140: step 2004, loss 0.0655224, acc 0.984375
2020-02-08T01:45:26.130586: step 2005, loss 0.0973711, acc 0.9375
2020-02-08T01:45:26.360863: step 2006, loss 0.0451026, acc 1
2020-02-08T01:45:26.582398: step 2007, loss 0.0208531, acc 1
2020-02-08T01:45:26.843477: step 2008, loss 0.0963947, acc 0.96875
2020-02-08T01:45:27.060050: step 2009, loss 0.0422511, acc 1
2020-02-08T01:45:27.275069: step 2010, loss 0.0200214, acc 1
2020-02-08T01:45:27.472675: step 2011, loss 0.0521578, acc 0.984375
2020-02-08T01:45:27.696016: step 2012, loss 0.0506242, acc 0.96875
2020-02-08T01:45:27.960211: step 2013, loss 0.0257051, acc 1
2020-02-08T01:45:28.187988: step 2014, loss 0.0358969, acc 1
2020-02-08T01:45:28.382608: step 2015, loss 0.123335, acc 0.96875
2020-02-08T01:45:28.564960: step 2016, loss 0.111298, acc 0.953125
2020-02-08T01:45:28.757087: step 2017, loss 0.100418, acc 0.953125
2020-02-08T01:45:28.932949: step 2018, loss 0.0290852, acc 0.984375
2020-02-08T01:45:29.127153: step 2019, loss 0.0317822, acc 1
2020-02-08T01:45:29.310975: step 2020, loss 0.0837716, acc 0.96875
2020-02-08T01:45:29.503234: step 2021, loss 0.0721191, acc 0.953125
2020-02-08T01:45:29.693104: step 2022, loss 0.0542663, acc 0.984375
2020-02-08T01:45:29.873932: step 2023, loss 0.0193039, acc 1
2020-02-08T01:45:30.049041: step 2024, loss 0.0456314, acc 0.96875
2020-02-08T01:45:30.232546: step 2025, loss 0.122304, acc 0.953125
2020-02-08T01:45:30.408996: step 2026, loss 0.0292716, acc 1
2020-02-08T01:45:30.592531: step 2027, loss 0.0796456, acc 0.96875
2020-02-08T01:45:30.772612: step 2028, loss 0.0481778, acc 1
2020-02-08T01:45:30.949636: step 2029, loss 0.0695722, acc 0.984375
2020-02-08T01:45:31.129725: step 2030, loss 0.0775143, acc 0.9375
2020-02-08T01:45:31.306082: step 2031, loss 0.110552, acc 0.96875
2020-02-08T01:45:31.484485: step 2032, loss 0.0239921, acc 1
2020-02-08T01:45:31.668277: step 2033, loss 0.0422109, acc 1
2020-02-08T01:45:31.851390: step 2034, loss 0.0463454, acc 0.984375
2020-02-08T01:45:32.029407: step 2035, loss 0.108209, acc 0.96875
2020-02-08T01:45:32.201265: step 2036, loss 0.0992765, acc 0.953125
2020-02-08T01:45:32.384805: step 2037, loss 0.124854, acc 0.9375
2020-02-08T01:45:32.582494: step 2038, loss 0.0137372, acc 1
2020-02-08T01:45:32.769477: step 2039, loss 0.0911934, acc 0.96875
2020-02-08T01:45:32.957251: step 2040, loss 0.062268, acc 0.96875
2020-02-08T01:45:33.144760: step 2041, loss 0.057195, acc 0.984375
2020-02-08T01:45:33.319374: step 2042, loss 0.0750743, acc 0.96875
2020-02-08T01:45:33.513443: step 2043, loss 0.199396, acc 0.9375
2020-02-08T01:45:33.698951: step 2044, loss 0.0645771, acc 0.984375
2020-02-08T01:45:33.885316: step 2045, loss 0.0583613, acc 0.984375
2020-02-08T01:45:34.077723: step 2046, loss 0.0139172, acc 1
2020-02-08T01:45:34.244015: step 2047, loss 0.0813242, acc 0.96875
2020-02-08T01:45:34.414102: step 2048, loss 0.0360475, acc 1
2020-02-08T01:45:34.602284: step 2049, loss 0.0644909, acc 0.984375
2020-02-08T01:45:34.794209: step 2050, loss 0.117954, acc 0.921875
2020-02-08T01:45:34.968047: step 2051, loss 0.154724, acc 0.953125
2020-02-08T01:45:35.147225: step 2052, loss 0.0541409, acc 0.984375
2020-02-08T01:45:35.324672: step 2053, loss 0.0345427, acc 0.984375
2020-02-08T01:45:35.504462: step 2054, loss 0.16942, acc 0.9375
2020-02-08T01:45:35.690979: step 2055, loss 0.059287, acc 1
2020-02-08T01:45:35.862308: step 2056, loss 0.0659406, acc 0.96875
2020-02-08T01:45:36.035458: step 2057, loss 0.0313953, acc 1
2020-02-08T01:45:36.230849: step 2058, loss 0.0464068, acc 1
2020-02-08T01:45:36.403632: step 2059, loss 0.0956038, acc 0.96875
2020-02-08T01:45:36.586915: step 2060, loss 0.0543212, acc 0.96875
2020-02-08T01:45:36.765757: step 2061, loss 0.130457, acc 0.953125
2020-02-08T01:45:36.946849: step 2062, loss 0.105857, acc 0.953125
2020-02-08T01:45:37.130401: step 2063, loss 0.0383167, acc 1
2020-02-08T01:45:37.305499: step 2064, loss 0.155317, acc 0.953125
2020-02-08T01:45:37.489957: step 2065, loss 0.0548519, acc 0.984375
2020-02-08T01:45:37.676874: step 2066, loss 0.103888, acc 0.96875
2020-02-08T01:45:37.848176: step 2067, loss 0.0953702, acc 0.953125
2020-02-08T01:45:38.016838: step 2068, loss 0.136114, acc 0.9375
2020-02-08T01:45:38.187285: step 2069, loss 0.0363749, acc 0.984375
2020-02-08T01:45:38.360716: step 2070, loss 0.106387, acc 0.9375
2020-02-08T01:45:38.548922: step 2071, loss 0.0229097, acc 1
2020-02-08T01:45:38.735781: step 2072, loss 0.0651523, acc 0.96875
2020-02-08T01:45:38.920215: step 2073, loss 0.0595362, acc 0.96875
2020-02-08T01:45:39.119595: step 2074, loss 0.0493199, acc 0.984375
2020-02-08T01:45:39.304925: step 2075, loss 0.0419366, acc 0.984375
2020-02-08T01:45:39.489764: step 2076, loss 0.0972763, acc 0.953125
2020-02-08T01:45:39.689340: step 2077, loss 0.0365205, acc 0.984375
2020-02-08T01:45:39.872253: step 2078, loss 0.0760263, acc 0.96875
2020-02-08T01:45:40.049938: step 2079, loss 0.0567103, acc 0.984375
2020-02-08T01:45:40.229137: step 2080, loss 0.108107, acc 0.96875
2020-02-08T01:45:40.403066: step 2081, loss 0.0418669, acc 0.984375
2020-02-08T01:45:40.581257: step 2082, loss 0.0627102, acc 0.96875
2020-02-08T01:45:40.760953: step 2083, loss 0.0498302, acc 0.984375
2020-02-08T01:45:40.947353: step 2084, loss 0.106976, acc 0.9375
2020-02-08T01:45:41.122581: step 2085, loss 0.10282, acc 0.984375
2020-02-08T01:45:41.305648: step 2086, loss 0.131529, acc 0.9375
2020-02-08T01:45:41.489661: step 2087, loss 0.0119872, acc 1
2020-02-08T01:45:41.694766: step 2088, loss 0.0393042, acc 0.984375
2020-02-08T01:45:41.870461: step 2089, loss 0.158768, acc 0.984375
2020-02-08T01:45:42.044344: step 2090, loss 0.095241, acc 0.96875
2020-02-08T01:45:42.219979: step 2091, loss 0.0202841, acc 1
2020-02-08T01:45:42.391509: step 2092, loss 0.0250095, acc 1
2020-02-08T01:45:42.579694: step 2093, loss 0.0402587, acc 1
2020-02-08T01:45:42.771276: step 2094, loss 0.071416, acc 0.984375
2020-02-08T01:45:42.955550: step 2095, loss 0.0491943, acc 0.984375
2020-02-08T01:45:43.140052: step 2096, loss 0.0236339, acc 1
2020-02-08T01:45:43.334623: step 2097, loss 0.193723, acc 0.90625
2020-02-08T01:45:43.513011: step 2098, loss 0.127846, acc 0.953125
2020-02-08T01:45:43.705152: step 2099, loss 0.0574287, acc 0.984375
2020-02-08T01:45:43.879702: step 2100, loss 0.0344384, acc 0.983333

Evaluation:
2020-02-08T01:45:44.222872: step 2100, loss 0.762838, acc 0.738274

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2100

2020-02-08T01:45:45.860223: step 2101, loss 0.025267, acc 1
2020-02-08T01:45:46.037689: step 2102, loss 0.106145, acc 0.96875
2020-02-08T01:45:46.217630: step 2103, loss 0.0711257, acc 0.984375
2020-02-08T01:45:46.400755: step 2104, loss 0.0132506, acc 1
2020-02-08T01:45:46.569658: step 2105, loss 0.0240399, acc 1
2020-02-08T01:45:46.756684: step 2106, loss 0.0348284, acc 0.984375
2020-02-08T01:45:46.940491: step 2107, loss 0.028431, acc 1
2020-02-08T01:45:47.125412: step 2108, loss 0.047622, acc 0.984375
2020-02-08T01:45:47.305864: step 2109, loss 0.0427593, acc 0.96875
2020-02-08T01:45:47.490163: step 2110, loss 0.0395934, acc 0.984375
2020-02-08T01:45:47.676609: step 2111, loss 0.134078, acc 0.9375
2020-02-08T01:45:47.848728: step 2112, loss 0.0341564, acc 1
2020-02-08T01:45:48.025459: step 2113, loss 0.0420493, acc 0.984375
2020-02-08T01:45:48.205609: step 2114, loss 0.0159199, acc 1
2020-02-08T01:45:48.374007: step 2115, loss 0.0568836, acc 0.96875
2020-02-08T01:45:48.563652: step 2116, loss 0.0375147, acc 1
2020-02-08T01:45:48.759707: step 2117, loss 0.113978, acc 0.953125
2020-02-08T01:45:48.954033: step 2118, loss 0.0580834, acc 0.953125
2020-02-08T01:45:49.163307: step 2119, loss 0.0828396, acc 0.984375
2020-02-08T01:45:49.357327: step 2120, loss 0.10968, acc 0.953125
2020-02-08T01:45:49.546713: step 2121, loss 0.0346235, acc 1
2020-02-08T01:45:49.742684: step 2122, loss 0.0273207, acc 1
2020-02-08T01:45:49.935292: step 2123, loss 0.0437529, acc 1
2020-02-08T01:45:50.117350: step 2124, loss 0.0361027, acc 1
2020-02-08T01:45:50.308459: step 2125, loss 0.0599121, acc 0.984375
2020-02-08T01:45:50.490881: step 2126, loss 0.0216667, acc 1
2020-02-08T01:45:50.689064: step 2127, loss 0.0391503, acc 0.984375
2020-02-08T01:45:50.862226: step 2128, loss 0.03779, acc 0.984375
2020-02-08T01:45:51.054854: step 2129, loss 0.0187911, acc 1
2020-02-08T01:45:51.238668: step 2130, loss 0.0813092, acc 0.96875
2020-02-08T01:45:51.432749: step 2131, loss 0.0290241, acc 1
2020-02-08T01:45:51.706624: step 2132, loss 0.079578, acc 0.96875
2020-02-08T01:45:51.924856: step 2133, loss 0.0152758, acc 1
2020-02-08T01:45:52.112497: step 2134, loss 0.0289735, acc 0.984375
2020-02-08T01:45:52.301350: step 2135, loss 0.0503738, acc 0.96875
2020-02-08T01:45:52.493464: step 2136, loss 0.0446207, acc 0.984375
2020-02-08T01:45:52.689629: step 2137, loss 0.0268801, acc 0.984375
2020-02-08T01:45:52.870223: step 2138, loss 0.071773, acc 0.984375
2020-02-08T01:45:53.058217: step 2139, loss 0.0394433, acc 0.984375
2020-02-08T01:45:53.244912: step 2140, loss 0.0188036, acc 1
2020-02-08T01:45:53.444792: step 2141, loss 0.0432757, acc 0.984375
2020-02-08T01:45:53.638628: step 2142, loss 0.0314791, acc 0.984375
2020-02-08T01:45:53.821231: step 2143, loss 0.0759796, acc 0.984375
2020-02-08T01:45:54.000299: step 2144, loss 0.0337361, acc 1
2020-02-08T01:45:54.186128: step 2145, loss 0.0458506, acc 0.984375
2020-02-08T01:45:54.365571: step 2146, loss 0.0361365, acc 1
2020-02-08T01:45:54.546512: step 2147, loss 0.0766948, acc 0.96875
2020-02-08T01:45:54.738928: step 2148, loss 0.0361247, acc 1
2020-02-08T01:45:54.919153: step 2149, loss 0.0294996, acc 1
2020-02-08T01:45:55.097145: step 2150, loss 0.0328452, acc 0.984375
2020-02-08T01:45:55.291101: step 2151, loss 0.121648, acc 0.96875
2020-02-08T01:45:55.468708: step 2152, loss 0.0271478, acc 1
2020-02-08T01:45:55.647576: step 2153, loss 0.0527346, acc 0.984375
2020-02-08T01:45:55.819402: step 2154, loss 0.0422725, acc 0.984375
2020-02-08T01:45:56.016978: step 2155, loss 0.118962, acc 0.96875
2020-02-08T01:45:56.196768: step 2156, loss 0.0211484, acc 1
2020-02-08T01:45:56.373979: step 2157, loss 0.0451136, acc 0.984375
2020-02-08T01:45:56.552149: step 2158, loss 0.0679632, acc 0.96875
2020-02-08T01:45:56.738787: step 2159, loss 0.0723368, acc 0.953125
2020-02-08T01:45:56.919539: step 2160, loss 0.11953, acc 0.9375
2020-02-08T01:45:57.105013: step 2161, loss 0.0398556, acc 1
2020-02-08T01:45:57.294570: step 2162, loss 0.0278296, acc 1
2020-02-08T01:45:57.481188: step 2163, loss 0.0790394, acc 0.96875
2020-02-08T01:45:57.688496: step 2164, loss 0.0410091, acc 1
2020-02-08T01:45:57.862375: step 2165, loss 0.0280029, acc 1
2020-02-08T01:45:58.042012: step 2166, loss 0.0808701, acc 0.953125
2020-02-08T01:45:58.218480: step 2167, loss 0.0883685, acc 0.96875
2020-02-08T01:45:58.398239: step 2168, loss 0.0288629, acc 1
2020-02-08T01:45:58.590028: step 2169, loss 0.0510415, acc 0.984375
2020-02-08T01:45:58.803236: step 2170, loss 0.0251308, acc 1
2020-02-08T01:45:58.987671: step 2171, loss 0.0520668, acc 0.96875
2020-02-08T01:45:59.195462: step 2172, loss 0.0458933, acc 0.984375
2020-02-08T01:45:59.395043: step 2173, loss 0.0365499, acc 1
2020-02-08T01:45:59.581478: step 2174, loss 0.0132373, acc 1
2020-02-08T01:45:59.775289: step 2175, loss 0.0482313, acc 0.984375
2020-02-08T01:45:59.961660: step 2176, loss 0.0518219, acc 0.984375
2020-02-08T01:46:00.160894: step 2177, loss 0.102373, acc 0.953125
2020-02-08T01:46:00.345976: step 2178, loss 0.0763912, acc 0.984375
2020-02-08T01:46:00.541145: step 2179, loss 0.0380415, acc 0.984375
2020-02-08T01:46:00.768218: step 2180, loss 0.026785, acc 1
2020-02-08T01:46:00.978668: step 2181, loss 0.0303986, acc 1
2020-02-08T01:46:01.218684: step 2182, loss 0.0637108, acc 0.984375
2020-02-08T01:46:01.463325: step 2183, loss 0.0534886, acc 0.984375
2020-02-08T01:46:01.709454: step 2184, loss 0.0204086, acc 1
2020-02-08T01:46:01.926053: step 2185, loss 0.0692176, acc 0.96875
2020-02-08T01:46:02.172850: step 2186, loss 0.0295272, acc 0.984375
2020-02-08T01:46:02.394374: step 2187, loss 0.0173609, acc 1
2020-02-08T01:46:02.618993: step 2188, loss 0.0587767, acc 0.984375
2020-02-08T01:46:02.848879: step 2189, loss 0.0424016, acc 0.984375
2020-02-08T01:46:03.075139: step 2190, loss 0.0276047, acc 1
2020-02-08T01:46:03.292988: step 2191, loss 0.0884994, acc 0.953125
2020-02-08T01:46:03.494073: step 2192, loss 0.0551325, acc 0.984375
2020-02-08T01:46:03.701689: step 2193, loss 0.100838, acc 0.984375
2020-02-08T01:46:03.893109: step 2194, loss 0.0994668, acc 0.984375
2020-02-08T01:46:04.078945: step 2195, loss 0.0146031, acc 1
2020-02-08T01:46:04.268042: step 2196, loss 0.0220359, acc 1
2020-02-08T01:46:04.458840: step 2197, loss 0.0774489, acc 0.953125
2020-02-08T01:46:04.659010: step 2198, loss 0.0731381, acc 0.984375
2020-02-08T01:46:04.846496: step 2199, loss 0.0924648, acc 0.953125
2020-02-08T01:46:05.040777: step 2200, loss 0.0450717, acc 0.984375

Evaluation:
2020-02-08T01:46:05.368723: step 2200, loss 0.790144, acc 0.743902

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2200

2020-02-08T01:46:07.348315: step 2201, loss 0.027356, acc 1
2020-02-08T01:46:07.534246: step 2202, loss 0.0630031, acc 0.96875
2020-02-08T01:46:07.732748: step 2203, loss 0.0148809, acc 1
2020-02-08T01:46:07.919069: step 2204, loss 0.0385503, acc 0.984375
2020-02-08T01:46:08.112327: step 2205, loss 0.0909682, acc 0.96875
2020-02-08T01:46:08.307052: step 2206, loss 0.0701534, acc 0.96875
2020-02-08T01:46:08.520573: step 2207, loss 0.0541498, acc 0.953125
2020-02-08T01:46:08.745595: step 2208, loss 0.0707456, acc 0.984375
2020-02-08T01:46:08.954677: step 2209, loss 0.0442107, acc 0.984375
2020-02-08T01:46:09.159953: step 2210, loss 0.0398341, acc 1
2020-02-08T01:46:09.342582: step 2211, loss 0.0333729, acc 0.984375
2020-02-08T01:46:09.528269: step 2212, loss 0.0295303, acc 1
2020-02-08T01:46:09.717495: step 2213, loss 0.015371, acc 1
2020-02-08T01:46:09.911291: step 2214, loss 0.0401682, acc 0.984375
2020-02-08T01:46:10.095653: step 2215, loss 0.0466526, acc 0.984375
2020-02-08T01:46:10.294943: step 2216, loss 0.0246272, acc 1
2020-02-08T01:46:10.487786: step 2217, loss 0.0322719, acc 1
2020-02-08T01:46:10.681228: step 2218, loss 0.0790651, acc 0.953125
2020-02-08T01:46:10.866981: step 2219, loss 0.0630053, acc 0.96875
2020-02-08T01:46:11.050958: step 2220, loss 0.0199883, acc 1
2020-02-08T01:46:11.231534: step 2221, loss 0.0342181, acc 1
2020-02-08T01:46:11.412235: step 2222, loss 0.0877836, acc 0.96875
2020-02-08T01:46:11.598885: step 2223, loss 0.0242129, acc 1
2020-02-08T01:46:11.792955: step 2224, loss 0.0679568, acc 0.96875
2020-02-08T01:46:11.968879: step 2225, loss 0.0930526, acc 0.953125
2020-02-08T01:46:12.162978: step 2226, loss 0.0302328, acc 1
2020-02-08T01:46:12.354064: step 2227, loss 0.0375385, acc 0.984375
2020-02-08T01:46:12.550970: step 2228, loss 0.0314204, acc 1
2020-02-08T01:46:12.746073: step 2229, loss 0.0331536, acc 0.984375
2020-02-08T01:46:12.924801: step 2230, loss 0.0568359, acc 0.984375
2020-02-08T01:46:13.113487: step 2231, loss 0.0353569, acc 1
2020-02-08T01:46:13.292666: step 2232, loss 0.0781019, acc 0.96875
2020-02-08T01:46:13.489659: step 2233, loss 0.031275, acc 1
2020-02-08T01:46:13.701011: step 2234, loss 0.0303246, acc 1
2020-02-08T01:46:13.900746: step 2235, loss 0.040423, acc 0.984375
2020-02-08T01:46:14.085868: step 2236, loss 0.0958469, acc 0.953125
2020-02-08T01:46:14.260816: step 2237, loss 0.0431141, acc 0.984375
2020-02-08T01:46:14.440550: step 2238, loss 0.0390606, acc 1
2020-02-08T01:46:14.632484: step 2239, loss 0.0549806, acc 0.984375
2020-02-08T01:46:14.812017: step 2240, loss 0.0507543, acc 0.96875
2020-02-08T01:46:14.989063: step 2241, loss 0.0294434, acc 1
2020-02-08T01:46:15.176311: step 2242, loss 0.0785202, acc 0.984375
2020-02-08T01:46:15.350950: step 2243, loss 0.0119693, acc 1
2020-02-08T01:46:15.535951: step 2244, loss 0.0159718, acc 1
2020-02-08T01:46:15.731078: step 2245, loss 0.0894842, acc 0.953125
2020-02-08T01:46:15.918192: step 2246, loss 0.0314708, acc 1
2020-02-08T01:46:16.098586: step 2247, loss 0.0500284, acc 0.96875
2020-02-08T01:46:16.281233: step 2248, loss 0.043207, acc 0.984375
2020-02-08T01:46:16.462108: step 2249, loss 0.0422447, acc 0.984375
2020-02-08T01:46:16.648094: step 2250, loss 0.0242307, acc 1
2020-02-08T01:46:16.830916: step 2251, loss 0.0125907, acc 1
2020-02-08T01:46:17.020523: step 2252, loss 0.0521275, acc 0.96875
2020-02-08T01:46:17.210776: step 2253, loss 0.0300291, acc 0.984375
2020-02-08T01:46:17.396851: step 2254, loss 0.041358, acc 0.984375
2020-02-08T01:46:17.607056: step 2255, loss 0.0524801, acc 0.984375
2020-02-08T01:46:17.796016: step 2256, loss 0.0276827, acc 1
2020-02-08T01:46:17.972613: step 2257, loss 0.0664286, acc 0.96875
2020-02-08T01:46:18.155354: step 2258, loss 0.0471004, acc 0.984375
2020-02-08T01:46:18.342302: step 2259, loss 0.0139674, acc 1
2020-02-08T01:46:18.533546: step 2260, loss 0.0422853, acc 0.984375
2020-02-08T01:46:18.729160: step 2261, loss 0.0910761, acc 0.953125
2020-02-08T01:46:18.917179: step 2262, loss 0.0544202, acc 0.984375
2020-02-08T01:46:19.110209: step 2263, loss 0.0244757, acc 1
2020-02-08T01:46:19.336115: step 2264, loss 0.0197072, acc 1
2020-02-08T01:46:19.585356: step 2265, loss 0.0364862, acc 0.984375
2020-02-08T01:46:19.789908: step 2266, loss 0.0385645, acc 1
2020-02-08T01:46:19.984318: step 2267, loss 0.0565909, acc 0.96875
2020-02-08T01:46:20.159838: step 2268, loss 0.0522808, acc 0.984375
2020-02-08T01:46:20.346492: step 2269, loss 0.0523803, acc 0.96875
2020-02-08T01:46:20.523485: step 2270, loss 0.158522, acc 0.921875
2020-02-08T01:46:20.708713: step 2271, loss 0.0609244, acc 0.984375
2020-02-08T01:46:20.888619: step 2272, loss 0.0163918, acc 1
2020-02-08T01:46:21.069785: step 2273, loss 0.0498346, acc 0.984375
2020-02-08T01:46:21.426144: step 2274, loss 0.0207387, acc 1
2020-02-08T01:46:21.642435: step 2275, loss 0.103407, acc 0.953125
2020-02-08T01:46:21.820987: step 2276, loss 0.015303, acc 1
2020-02-08T01:46:22.009193: step 2277, loss 0.0932816, acc 0.984375
2020-02-08T01:46:22.197808: step 2278, loss 0.0556586, acc 0.984375
2020-02-08T01:46:22.376526: step 2279, loss 0.0727137, acc 0.96875
2020-02-08T01:46:22.573066: step 2280, loss 0.0673145, acc 0.96875
2020-02-08T01:46:22.770403: step 2281, loss 0.0372135, acc 0.984375
2020-02-08T01:46:22.960678: step 2282, loss 0.0123931, acc 1
2020-02-08T01:46:23.164339: step 2283, loss 0.0110211, acc 1
2020-02-08T01:46:23.359557: step 2284, loss 0.0451165, acc 0.96875
2020-02-08T01:46:23.558627: step 2285, loss 0.0563953, acc 0.984375
2020-02-08T01:46:23.755622: step 2286, loss 0.0435771, acc 0.984375
2020-02-08T01:46:23.940088: step 2287, loss 0.079106, acc 0.96875
2020-02-08T01:46:24.128043: step 2288, loss 0.0506626, acc 0.96875
2020-02-08T01:46:24.319967: step 2289, loss 0.0181727, acc 1
2020-02-08T01:46:24.505812: step 2290, loss 0.0386774, acc 0.984375
2020-02-08T01:46:24.704316: step 2291, loss 0.0362007, acc 0.984375
2020-02-08T01:46:24.897778: step 2292, loss 0.0284474, acc 1
2020-02-08T01:46:25.086749: step 2293, loss 0.0338877, acc 0.984375
2020-02-08T01:46:25.265559: step 2294, loss 0.0371559, acc 0.984375
2020-02-08T01:46:25.456060: step 2295, loss 0.0165468, acc 1
2020-02-08T01:46:25.646930: step 2296, loss 0.154969, acc 0.953125
2020-02-08T01:46:25.836083: step 2297, loss 0.0861411, acc 0.96875
2020-02-08T01:46:26.028043: step 2298, loss 0.104133, acc 0.953125
2020-02-08T01:46:26.217579: step 2299, loss 0.0690919, acc 0.96875
2020-02-08T01:46:26.401954: step 2300, loss 0.0118493, acc 1

Evaluation:
2020-02-08T01:46:26.740057: step 2300, loss 0.835509, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2300

2020-02-08T01:46:29.620717: step 2301, loss 0.0100727, acc 1
2020-02-08T01:46:29.807911: step 2302, loss 0.0127208, acc 1
2020-02-08T01:46:29.991355: step 2303, loss 0.0936448, acc 0.953125
2020-02-08T01:46:30.188489: step 2304, loss 0.0498067, acc 0.96875
2020-02-08T01:46:30.372191: step 2305, loss 0.0641803, acc 0.984375
2020-02-08T01:46:30.567228: step 2306, loss 0.0529866, acc 0.96875
2020-02-08T01:46:30.776388: step 2307, loss 0.0672304, acc 0.96875
2020-02-08T01:46:30.958969: step 2308, loss 0.0651812, acc 0.984375
2020-02-08T01:46:31.146210: step 2309, loss 0.0178204, acc 1
2020-02-08T01:46:31.340945: step 2310, loss 0.0592077, acc 0.96875
2020-02-08T01:46:31.520059: step 2311, loss 0.00838345, acc 1
2020-02-08T01:46:31.721237: step 2312, loss 0.0922918, acc 0.953125
2020-02-08T01:46:31.906977: step 2313, loss 0.0559623, acc 0.984375
2020-02-08T01:46:32.098074: step 2314, loss 0.0676569, acc 0.984375
2020-02-08T01:46:32.291752: step 2315, loss 0.0335535, acc 0.984375
2020-02-08T01:46:32.477938: step 2316, loss 0.0154844, acc 1
2020-02-08T01:46:32.673879: step 2317, loss 0.0884823, acc 0.953125
2020-02-08T01:46:32.854871: step 2318, loss 0.0209744, acc 1
2020-02-08T01:46:33.038132: step 2319, loss 0.0375134, acc 0.984375
2020-02-08T01:46:33.232739: step 2320, loss 0.0284263, acc 0.984375
2020-02-08T01:46:33.429380: step 2321, loss 0.0655375, acc 0.984375
2020-02-08T01:46:33.619278: step 2322, loss 0.0660843, acc 0.96875
2020-02-08T01:46:33.821462: step 2323, loss 0.0717686, acc 0.953125
2020-02-08T01:46:33.991133: step 2324, loss 0.0360546, acc 0.984375
2020-02-08T01:46:34.177537: step 2325, loss 0.0404701, acc 1
2020-02-08T01:46:34.358165: step 2326, loss 0.101684, acc 0.96875
2020-02-08T01:46:34.547146: step 2327, loss 0.0296645, acc 0.984375
2020-02-08T01:46:34.739549: step 2328, loss 0.0166433, acc 1
2020-02-08T01:46:34.942720: step 2329, loss 0.0390476, acc 1
2020-02-08T01:46:35.131645: step 2330, loss 0.014961, acc 1
2020-02-08T01:46:35.330815: step 2331, loss 0.0829817, acc 0.984375
2020-02-08T01:46:35.560597: step 2332, loss 0.0241595, acc 1
2020-02-08T01:46:35.791426: step 2333, loss 0.0365532, acc 0.984375
2020-02-08T01:46:36.015479: step 2334, loss 0.0180161, acc 1
2020-02-08T01:46:36.262909: step 2335, loss 0.0154576, acc 1
2020-02-08T01:46:36.545166: step 2336, loss 0.043414, acc 0.96875
2020-02-08T01:46:36.829588: step 2337, loss 0.0311716, acc 0.984375
2020-02-08T01:46:37.063532: step 2338, loss 0.0353399, acc 0.96875
2020-02-08T01:46:37.293699: step 2339, loss 0.0137289, acc 1
2020-02-08T01:46:37.543997: step 2340, loss 0.0207196, acc 1
2020-02-08T01:46:37.778479: step 2341, loss 0.0474165, acc 0.984375
2020-02-08T01:46:38.016074: step 2342, loss 0.03644, acc 0.984375
2020-02-08T01:46:38.227572: step 2343, loss 0.0328868, acc 0.984375
2020-02-08T01:46:38.450512: step 2344, loss 0.0732331, acc 0.96875
2020-02-08T01:46:38.679532: step 2345, loss 0.0215214, acc 1
2020-02-08T01:46:38.897098: step 2346, loss 0.0406402, acc 0.96875
2020-02-08T01:46:39.114788: step 2347, loss 0.0116749, acc 1
2020-02-08T01:46:39.308255: step 2348, loss 0.0342976, acc 0.984375
2020-02-08T01:46:39.501400: step 2349, loss 0.0327687, acc 0.984375
2020-02-08T01:46:39.686301: step 2350, loss 0.0252619, acc 1
2020-02-08T01:46:39.948185: step 2351, loss 0.107762, acc 0.96875
2020-02-08T01:46:40.165682: step 2352, loss 0.0295562, acc 1
2020-02-08T01:46:40.373257: step 2353, loss 0.030055, acc 0.984375
2020-02-08T01:46:40.571532: step 2354, loss 0.0316448, acc 1
2020-02-08T01:46:40.760237: step 2355, loss 0.0503167, acc 0.96875
2020-02-08T01:46:40.945739: step 2356, loss 0.0243203, acc 1
2020-02-08T01:46:41.130607: step 2357, loss 0.0446695, acc 1
2020-02-08T01:46:41.324516: step 2358, loss 0.0157625, acc 1
2020-02-08T01:46:41.527957: step 2359, loss 0.0324772, acc 0.984375
2020-02-08T01:46:41.721977: step 2360, loss 0.0052255, acc 1
2020-02-08T01:46:41.916809: step 2361, loss 0.0312443, acc 1
2020-02-08T01:46:42.118241: step 2362, loss 0.0432673, acc 0.96875
2020-02-08T01:46:42.317146: step 2363, loss 0.0318608, acc 0.984375
2020-02-08T01:46:42.512970: step 2364, loss 0.0161462, acc 1
2020-02-08T01:46:42.719990: step 2365, loss 0.0738719, acc 0.96875
2020-02-08T01:46:42.912434: step 2366, loss 0.0223579, acc 1
2020-02-08T01:46:43.101756: step 2367, loss 0.0237214, acc 0.984375
2020-02-08T01:46:43.296636: step 2368, loss 0.0341478, acc 1
2020-02-08T01:46:43.505919: step 2369, loss 0.0328399, acc 1
2020-02-08T01:46:43.714653: step 2370, loss 0.0577279, acc 0.96875
2020-02-08T01:46:43.900934: step 2371, loss 0.0767249, acc 0.96875
2020-02-08T01:46:44.085304: step 2372, loss 0.00860203, acc 1
2020-02-08T01:46:44.281986: step 2373, loss 0.0157851, acc 1
2020-02-08T01:46:44.476512: step 2374, loss 0.0260194, acc 0.984375
2020-02-08T01:46:44.683026: step 2375, loss 0.0617885, acc 0.96875
2020-02-08T01:46:44.871933: step 2376, loss 0.0141302, acc 1
2020-02-08T01:46:45.061249: step 2377, loss 0.0890997, acc 0.96875
2020-02-08T01:46:45.250292: step 2378, loss 0.0233639, acc 1
2020-02-08T01:46:45.431969: step 2379, loss 0.0400867, acc 0.984375
2020-02-08T01:46:45.622624: step 2380, loss 0.0136088, acc 1
2020-02-08T01:46:45.815907: step 2381, loss 0.0829221, acc 0.9375
2020-02-08T01:46:46.003930: step 2382, loss 0.0724815, acc 0.953125
2020-02-08T01:46:46.196095: step 2383, loss 0.0457437, acc 0.984375
2020-02-08T01:46:46.398956: step 2384, loss 0.0335091, acc 0.984375
2020-02-08T01:46:46.591185: step 2385, loss 0.0239076, acc 1
2020-02-08T01:46:46.782042: step 2386, loss 0.0459701, acc 1
2020-02-08T01:46:46.966044: step 2387, loss 0.0954125, acc 0.96875
2020-02-08T01:46:47.156315: step 2388, loss 0.0387378, acc 0.984375
2020-02-08T01:46:47.350556: step 2389, loss 0.0444344, acc 0.984375
2020-02-08T01:46:47.557238: step 2390, loss 0.0355801, acc 1
2020-02-08T01:46:47.765272: step 2391, loss 0.020094, acc 1
2020-02-08T01:46:47.956154: step 2392, loss 0.0384442, acc 1
2020-02-08T01:46:48.153524: step 2393, loss 0.0381183, acc 0.984375
2020-02-08T01:46:48.352998: step 2394, loss 0.0310444, acc 1
2020-02-08T01:46:48.550240: step 2395, loss 0.0438351, acc 0.984375
2020-02-08T01:46:48.756154: step 2396, loss 0.0388605, acc 0.984375
2020-02-08T01:46:48.957834: step 2397, loss 0.0325174, acc 0.984375
2020-02-08T01:46:49.167060: step 2398, loss 0.0458055, acc 0.984375
2020-02-08T01:46:49.360128: step 2399, loss 0.0158622, acc 1
2020-02-08T01:46:49.553561: step 2400, loss 0.0254534, acc 1

Evaluation:
2020-02-08T01:46:49.905925: step 2400, loss 0.862652, acc 0.731707

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2400

2020-02-08T01:46:52.049210: step 2401, loss 0.00617544, acc 1
2020-02-08T01:46:52.292281: step 2402, loss 0.053163, acc 0.96875
2020-02-08T01:46:52.512658: step 2403, loss 0.043872, acc 0.984375
2020-02-08T01:46:52.722938: step 2404, loss 0.0340082, acc 0.984375
2020-02-08T01:46:52.915460: step 2405, loss 0.0157137, acc 1
2020-02-08T01:46:53.120888: step 2406, loss 0.0181889, acc 1
2020-02-08T01:46:53.325857: step 2407, loss 0.0182964, acc 1
2020-02-08T01:46:53.541363: step 2408, loss 0.0512041, acc 0.984375
2020-02-08T01:46:53.747875: step 2409, loss 0.0232969, acc 1
2020-02-08T01:46:53.946183: step 2410, loss 0.0793507, acc 0.984375
2020-02-08T01:46:54.153451: step 2411, loss 0.0320738, acc 0.984375
2020-02-08T01:46:54.423155: step 2412, loss 0.0167776, acc 1
2020-02-08T01:46:54.695748: step 2413, loss 0.022123, acc 1
2020-02-08T01:46:54.917253: step 2414, loss 0.0110941, acc 1
2020-02-08T01:46:55.118410: step 2415, loss 0.0175071, acc 1
2020-02-08T01:46:55.338300: step 2416, loss 0.0262297, acc 0.984375
2020-02-08T01:46:55.551548: step 2417, loss 0.00908608, acc 1
2020-02-08T01:46:55.778323: step 2418, loss 0.0343704, acc 0.984375
2020-02-08T01:46:55.990736: step 2419, loss 0.0187998, acc 1
2020-02-08T01:46:56.225101: step 2420, loss 0.017164, acc 1
2020-02-08T01:46:56.420347: step 2421, loss 0.0755088, acc 0.96875
2020-02-08T01:46:56.622321: step 2422, loss 0.0676798, acc 0.984375
2020-02-08T01:46:56.821455: step 2423, loss 0.0120356, acc 1
2020-02-08T01:46:57.016889: step 2424, loss 0.0420016, acc 0.984375
2020-02-08T01:46:57.216580: step 2425, loss 0.0111309, acc 1
2020-02-08T01:46:57.422801: step 2426, loss 0.0490156, acc 0.984375
2020-02-08T01:46:57.658205: step 2427, loss 0.0180135, acc 1
2020-02-08T01:46:57.859247: step 2428, loss 0.0184849, acc 1
2020-02-08T01:46:58.095503: step 2429, loss 0.0280984, acc 0.984375
2020-02-08T01:46:58.288387: step 2430, loss 0.0179345, acc 1
2020-02-08T01:46:58.498615: step 2431, loss 0.0184714, acc 1
2020-02-08T01:46:58.721705: step 2432, loss 0.0248852, acc 1
2020-02-08T01:46:58.939104: step 2433, loss 0.0346691, acc 1
2020-02-08T01:46:59.156266: step 2434, loss 0.0511123, acc 0.984375
2020-02-08T01:46:59.358828: step 2435, loss 0.00861919, acc 1
2020-02-08T01:46:59.563017: step 2436, loss 0.0339908, acc 0.984375
2020-02-08T01:46:59.790058: step 2437, loss 0.0123498, acc 1
2020-02-08T01:46:59.987630: step 2438, loss 0.0150356, acc 1
2020-02-08T01:47:00.196021: step 2439, loss 0.0762553, acc 0.984375
2020-02-08T01:47:00.407545: step 2440, loss 0.0136847, acc 1
2020-02-08T01:47:00.609020: step 2441, loss 0.0440901, acc 0.984375
2020-02-08T01:47:00.809742: step 2442, loss 0.0199763, acc 1
2020-02-08T01:47:01.019826: step 2443, loss 0.0827086, acc 0.953125
2020-02-08T01:47:01.209587: step 2444, loss 0.00595731, acc 1
2020-02-08T01:47:01.408011: step 2445, loss 0.0250076, acc 0.984375
2020-02-08T01:47:01.612281: step 2446, loss 0.0202306, acc 1
2020-02-08T01:47:01.823245: step 2447, loss 0.0123146, acc 1
2020-02-08T01:47:02.013504: step 2448, loss 0.0128167, acc 1
2020-02-08T01:47:02.213551: step 2449, loss 0.0293679, acc 0.984375
2020-02-08T01:47:02.410424: step 2450, loss 0.0423294, acc 1
2020-02-08T01:47:02.624645: step 2451, loss 0.0179522, acc 1
2020-02-08T01:47:02.813095: step 2452, loss 0.00568265, acc 1
2020-02-08T01:47:03.010908: step 2453, loss 0.0166955, acc 1
2020-02-08T01:47:03.211269: step 2454, loss 0.0293464, acc 1
2020-02-08T01:47:03.414967: step 2455, loss 0.077447, acc 0.984375
2020-02-08T01:47:03.614426: step 2456, loss 0.0611049, acc 0.96875
2020-02-08T01:47:03.813293: step 2457, loss 0.0420786, acc 0.984375
2020-02-08T01:47:04.013104: step 2458, loss 0.0326459, acc 0.984375
2020-02-08T01:47:04.204660: step 2459, loss 0.0737188, acc 0.984375
2020-02-08T01:47:04.393556: step 2460, loss 0.0449623, acc 1
2020-02-08T01:47:04.576817: step 2461, loss 0.0618069, acc 0.96875
2020-02-08T01:47:04.778548: step 2462, loss 0.0665799, acc 0.953125
2020-02-08T01:47:04.974724: step 2463, loss 0.0511492, acc 0.984375
2020-02-08T01:47:05.166924: step 2464, loss 0.0477582, acc 0.984375
2020-02-08T01:47:05.357298: step 2465, loss 0.0656623, acc 0.96875
2020-02-08T01:47:05.559534: step 2466, loss 0.0186094, acc 1
2020-02-08T01:47:05.747600: step 2467, loss 0.0590561, acc 0.984375
2020-02-08T01:47:05.940582: step 2468, loss 0.0258455, acc 1
2020-02-08T01:47:06.138742: step 2469, loss 0.0101003, acc 1
2020-02-08T01:47:06.335358: step 2470, loss 0.0725181, acc 0.984375
2020-02-08T01:47:06.531181: step 2471, loss 0.054967, acc 0.96875
2020-02-08T01:47:06.742011: step 2472, loss 0.0585062, acc 0.984375
2020-02-08T01:47:06.924866: step 2473, loss 0.0217881, acc 1
2020-02-08T01:47:07.109407: step 2474, loss 0.0193726, acc 1
2020-02-08T01:47:07.299295: step 2475, loss 0.0786234, acc 0.96875
2020-02-08T01:47:07.490886: step 2476, loss 0.0596725, acc 0.984375
2020-02-08T01:47:07.686333: step 2477, loss 0.0207522, acc 1
2020-02-08T01:47:07.868355: step 2478, loss 0.0424713, acc 0.96875
2020-02-08T01:47:08.050137: step 2479, loss 0.032586, acc 0.984375
2020-02-08T01:47:08.227716: step 2480, loss 0.0272922, acc 1
2020-02-08T01:47:08.443678: step 2481, loss 0.026042, acc 1
2020-02-08T01:47:08.623136: step 2482, loss 0.0313986, acc 0.984375
2020-02-08T01:47:08.808907: step 2483, loss 0.0442845, acc 0.96875
2020-02-08T01:47:09.008760: step 2484, loss 0.0831753, acc 0.96875
2020-02-08T01:47:09.206290: step 2485, loss 0.0235649, acc 1
2020-02-08T01:47:09.387698: step 2486, loss 0.0183753, acc 1
2020-02-08T01:47:09.582811: step 2487, loss 0.009791, acc 1
2020-02-08T01:47:09.788229: step 2488, loss 0.0243506, acc 0.984375
2020-02-08T01:47:10.063528: step 2489, loss 0.0569537, acc 0.96875
2020-02-08T01:47:10.281540: step 2490, loss 0.0324688, acc 0.984375
2020-02-08T01:47:10.499628: step 2491, loss 0.017191, acc 1
2020-02-08T01:47:10.745361: step 2492, loss 0.0620277, acc 0.984375
2020-02-08T01:47:11.066946: step 2493, loss 0.0366993, acc 0.984375
2020-02-08T01:47:11.310919: step 2494, loss 0.0175682, acc 0.984375
2020-02-08T01:47:11.518563: step 2495, loss 0.028123, acc 1
2020-02-08T01:47:11.764111: step 2496, loss 0.0159287, acc 1
2020-02-08T01:47:12.013237: step 2497, loss 0.0293389, acc 0.984375
2020-02-08T01:47:12.265064: step 2498, loss 0.0802699, acc 0.984375
2020-02-08T01:47:12.516156: step 2499, loss 0.0176646, acc 0.984375
2020-02-08T01:47:12.812875: step 2500, loss 0.0230756, acc 1

Evaluation:
2020-02-08T01:47:13.182610: step 2500, loss 0.895161, acc 0.741088

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2500

2020-02-08T01:47:14.925498: step 2501, loss 0.0254796, acc 0.984375
2020-02-08T01:47:15.146969: step 2502, loss 0.0458953, acc 0.96875
2020-02-08T01:47:15.368508: step 2503, loss 0.0202858, acc 1
2020-02-08T01:47:15.587019: step 2504, loss 0.0500207, acc 0.984375
2020-02-08T01:47:15.809444: step 2505, loss 0.0858731, acc 0.953125
2020-02-08T01:47:16.012803: step 2506, loss 0.01259, acc 1
2020-02-08T01:47:16.221704: step 2507, loss 0.0263661, acc 0.984375
2020-02-08T01:47:16.431921: step 2508, loss 0.0913756, acc 0.953125
2020-02-08T01:47:16.650261: step 2509, loss 0.0471133, acc 0.984375
2020-02-08T01:47:16.846118: step 2510, loss 0.0238143, acc 1
2020-02-08T01:47:17.048649: step 2511, loss 0.0276677, acc 1
2020-02-08T01:47:17.247052: step 2512, loss 0.01513, acc 1
2020-02-08T01:47:17.442288: step 2513, loss 0.0237144, acc 1
2020-02-08T01:47:17.640208: step 2514, loss 0.0105672, acc 1
2020-02-08T01:47:17.841897: step 2515, loss 0.0145416, acc 1
2020-02-08T01:47:18.030450: step 2516, loss 0.0324909, acc 0.984375
2020-02-08T01:47:18.223145: step 2517, loss 0.0485281, acc 0.984375
2020-02-08T01:47:18.410756: step 2518, loss 0.115775, acc 0.96875
2020-02-08T01:47:18.605396: step 2519, loss 0.027184, acc 0.984375
2020-02-08T01:47:18.807539: step 2520, loss 0.0432115, acc 0.984375
2020-02-08T01:47:19.004300: step 2521, loss 0.0218884, acc 0.984375
2020-02-08T01:47:19.207705: step 2522, loss 0.0531714, acc 0.984375
2020-02-08T01:47:19.406589: step 2523, loss 0.0370868, acc 1
2020-02-08T01:47:19.619224: step 2524, loss 0.0284344, acc 1
2020-02-08T01:47:19.805648: step 2525, loss 0.0185919, acc 1
2020-02-08T01:47:20.017737: step 2526, loss 0.110063, acc 0.953125
2020-02-08T01:47:20.207610: step 2527, loss 0.0713395, acc 0.984375
2020-02-08T01:47:20.405616: step 2528, loss 0.0535969, acc 0.984375
2020-02-08T01:47:20.614962: step 2529, loss 0.0508197, acc 0.96875
2020-02-08T01:47:20.814236: step 2530, loss 0.044035, acc 0.984375
2020-02-08T01:47:21.018761: step 2531, loss 0.0418354, acc 0.984375
2020-02-08T01:47:21.206847: step 2532, loss 0.0134057, acc 1
2020-02-08T01:47:21.396456: step 2533, loss 0.00846811, acc 1
2020-02-08T01:47:21.600539: step 2534, loss 0.0468915, acc 0.984375
2020-02-08T01:47:21.816691: step 2535, loss 0.0322107, acc 0.984375
2020-02-08T01:47:22.010819: step 2536, loss 0.0101351, acc 1
2020-02-08T01:47:22.208296: step 2537, loss 0.0131682, acc 1
2020-02-08T01:47:22.399720: step 2538, loss 0.0112419, acc 1
2020-02-08T01:47:22.600765: step 2539, loss 0.0333053, acc 1
2020-02-08T01:47:22.782888: step 2540, loss 0.0114541, acc 1
2020-02-08T01:47:22.968004: step 2541, loss 0.0271771, acc 1
2020-02-08T01:47:23.161070: step 2542, loss 0.0268699, acc 0.984375
2020-02-08T01:47:23.359590: step 2543, loss 0.0186786, acc 1
2020-02-08T01:47:23.567541: step 2544, loss 0.0666728, acc 0.96875
2020-02-08T01:47:23.769885: step 2545, loss 0.0899205, acc 0.984375
2020-02-08T01:47:23.957270: step 2546, loss 0.0394076, acc 0.984375
2020-02-08T01:47:24.159897: step 2547, loss 0.0416325, acc 0.984375
2020-02-08T01:47:24.350904: step 2548, loss 0.0225541, acc 1
2020-02-08T01:47:24.538544: step 2549, loss 0.0376031, acc 0.96875
2020-02-08T01:47:24.736366: step 2550, loss 0.044312, acc 1
2020-02-08T01:47:24.925940: step 2551, loss 0.0266372, acc 1
2020-02-08T01:47:25.126157: step 2552, loss 0.0598251, acc 0.984375
2020-02-08T01:47:25.316371: step 2553, loss 0.0625741, acc 0.984375
2020-02-08T01:47:25.498313: step 2554, loss 0.00553987, acc 1
2020-02-08T01:47:25.688929: step 2555, loss 0.0223478, acc 1
2020-02-08T01:47:25.867570: step 2556, loss 0.0705514, acc 0.96875
2020-02-08T01:47:26.043276: step 2557, loss 0.0197095, acc 1
2020-02-08T01:47:26.216067: step 2558, loss 0.02625, acc 0.984375
2020-02-08T01:47:26.406784: step 2559, loss 0.00883244, acc 1
2020-02-08T01:47:26.610949: step 2560, loss 0.00617998, acc 1
2020-02-08T01:47:26.806528: step 2561, loss 0.0845679, acc 0.96875
2020-02-08T01:47:26.999648: step 2562, loss 0.0233402, acc 1
2020-02-08T01:47:27.189905: step 2563, loss 0.00875958, acc 1
2020-02-08T01:47:27.398329: step 2564, loss 0.0208534, acc 1
2020-02-08T01:47:27.599021: step 2565, loss 0.0209844, acc 1
2020-02-08T01:47:27.805035: step 2566, loss 0.029649, acc 0.984375
2020-02-08T01:47:28.024121: step 2567, loss 0.0146249, acc 1
2020-02-08T01:47:28.215625: step 2568, loss 0.011298, acc 1
2020-02-08T01:47:28.419864: step 2569, loss 0.014195, acc 1
2020-02-08T01:47:28.645852: step 2570, loss 0.0285689, acc 0.984375
2020-02-08T01:47:28.893476: step 2571, loss 0.0170272, acc 1
2020-02-08T01:47:29.123726: step 2572, loss 0.0198621, acc 1
2020-02-08T01:47:29.285563: step 2573, loss 0.0174858, acc 0.984375
2020-02-08T01:47:29.523345: step 2574, loss 0.0174468, acc 1
2020-02-08T01:47:29.771115: step 2575, loss 0.0940533, acc 0.96875
2020-02-08T01:47:29.991465: step 2576, loss 0.0081916, acc 1
2020-02-08T01:47:30.173777: step 2577, loss 0.00869694, acc 1
2020-02-08T01:47:30.368703: step 2578, loss 0.0134376, acc 1
2020-02-08T01:47:30.555081: step 2579, loss 0.0221703, acc 1
2020-02-08T01:47:30.743772: step 2580, loss 0.0681932, acc 0.96875
2020-02-08T01:47:30.936962: step 2581, loss 0.0115175, acc 1
2020-02-08T01:47:31.126593: step 2582, loss 0.0193795, acc 0.984375
2020-02-08T01:47:31.319466: step 2583, loss 0.0315549, acc 0.984375
2020-02-08T01:47:31.526213: step 2584, loss 0.0206213, acc 1
2020-02-08T01:47:31.744254: step 2585, loss 0.0151485, acc 1
2020-02-08T01:47:31.929035: step 2586, loss 0.0211483, acc 1
2020-02-08T01:47:32.136375: step 2587, loss 0.0908697, acc 0.953125
2020-02-08T01:47:32.324813: step 2588, loss 0.155679, acc 0.9375
2020-02-08T01:47:32.520760: step 2589, loss 0.0108559, acc 1
2020-02-08T01:47:32.715401: step 2590, loss 0.012441, acc 1
2020-02-08T01:47:32.911807: step 2591, loss 0.0486535, acc 0.96875
2020-02-08T01:47:33.096472: step 2592, loss 0.0208754, acc 0.984375
2020-02-08T01:47:33.296147: step 2593, loss 0.046145, acc 0.96875
2020-02-08T01:47:33.495709: step 2594, loss 0.0349451, acc 0.984375
2020-02-08T01:47:33.708717: step 2595, loss 0.0251529, acc 0.984375
2020-02-08T01:47:33.903008: step 2596, loss 0.00931301, acc 1
2020-02-08T01:47:34.095034: step 2597, loss 0.0282786, acc 0.984375
2020-02-08T01:47:34.286377: step 2598, loss 0.0156629, acc 1
2020-02-08T01:47:34.486326: step 2599, loss 0.0452519, acc 0.96875
2020-02-08T01:47:34.673349: step 2600, loss 0.0175799, acc 1

Evaluation:
2020-02-08T01:47:35.003940: step 2600, loss 0.948157, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2600

2020-02-08T01:47:36.820122: step 2601, loss 0.0347685, acc 0.984375
2020-02-08T01:47:37.022036: step 2602, loss 0.0050929, acc 1
2020-02-08T01:47:37.259266: step 2603, loss 0.0488899, acc 0.984375
2020-02-08T01:47:37.419194: step 2604, loss 0.0713801, acc 0.984375
2020-02-08T01:47:37.629013: step 2605, loss 0.0154389, acc 1
2020-02-08T01:47:37.810774: step 2606, loss 0.0162139, acc 1
2020-02-08T01:47:37.987387: step 2607, loss 0.0514573, acc 0.984375
2020-02-08T01:47:38.169635: step 2608, loss 0.0152785, acc 1
2020-02-08T01:47:38.363582: step 2609, loss 0.00681926, acc 1
2020-02-08T01:47:38.558317: step 2610, loss 0.00327612, acc 1
2020-02-08T01:47:38.756902: step 2611, loss 0.0246508, acc 1
2020-02-08T01:47:38.956193: step 2612, loss 0.00654389, acc 1
2020-02-08T01:47:39.158628: step 2613, loss 0.0161964, acc 1
2020-02-08T01:47:39.344766: step 2614, loss 0.014476, acc 1
2020-02-08T01:47:39.532645: step 2615, loss 0.0666206, acc 0.96875
2020-02-08T01:47:39.730309: step 2616, loss 0.0321603, acc 0.984375
2020-02-08T01:47:39.916815: step 2617, loss 0.0261648, acc 1
2020-02-08T01:47:40.094000: step 2618, loss 0.0184854, acc 1
2020-02-08T01:47:40.267996: step 2619, loss 0.0243389, acc 1
2020-02-08T01:47:40.456211: step 2620, loss 0.0205045, acc 0.984375
2020-02-08T01:47:40.645479: step 2621, loss 0.0123072, acc 1
2020-02-08T01:47:40.845639: step 2622, loss 0.0132221, acc 1
2020-02-08T01:47:41.044234: step 2623, loss 0.0124902, acc 1
2020-02-08T01:47:41.247380: step 2624, loss 0.159943, acc 0.953125
2020-02-08T01:47:41.444467: step 2625, loss 0.0121288, acc 1
2020-02-08T01:47:41.648135: step 2626, loss 0.0199151, acc 1
2020-02-08T01:47:41.824401: step 2627, loss 0.0549517, acc 0.984375
2020-02-08T01:47:42.020343: step 2628, loss 0.0202166, acc 0.984375
2020-02-08T01:47:42.230483: step 2629, loss 0.00883954, acc 1
2020-02-08T01:47:42.416552: step 2630, loss 0.0223546, acc 1
2020-02-08T01:47:42.622976: step 2631, loss 0.0111112, acc 1
2020-02-08T01:47:42.817597: step 2632, loss 0.0363126, acc 0.984375
2020-02-08T01:47:43.007659: step 2633, loss 0.012753, acc 1
2020-02-08T01:47:43.206011: step 2634, loss 0.0239045, acc 0.984375
2020-02-08T01:47:43.397165: step 2635, loss 0.0217253, acc 1
2020-02-08T01:47:43.610114: step 2636, loss 0.00942091, acc 1
2020-02-08T01:47:43.800890: step 2637, loss 0.0382444, acc 0.984375
2020-02-08T01:47:44.000787: step 2638, loss 0.0907085, acc 0.96875
2020-02-08T01:47:44.189792: step 2639, loss 0.02297, acc 0.984375
2020-02-08T01:47:44.382581: step 2640, loss 0.0694124, acc 0.96875
2020-02-08T01:47:44.569153: step 2641, loss 0.0139283, acc 1
2020-02-08T01:47:44.764289: step 2642, loss 0.0134159, acc 1
2020-02-08T01:47:44.958570: step 2643, loss 0.0337762, acc 0.984375
2020-02-08T01:47:45.145369: step 2644, loss 0.020254, acc 1
2020-02-08T01:47:45.342148: step 2645, loss 0.0280427, acc 0.984375
2020-02-08T01:47:45.553283: step 2646, loss 0.0428004, acc 0.984375
2020-02-08T01:47:45.753396: step 2647, loss 0.0270803, acc 0.984375
2020-02-08T01:47:45.955295: step 2648, loss 0.0364852, acc 0.984375
2020-02-08T01:47:46.165438: step 2649, loss 0.00799144, acc 1
2020-02-08T01:47:46.351846: step 2650, loss 0.0146907, acc 1
2020-02-08T01:47:46.551804: step 2651, loss 0.134478, acc 0.953125
2020-02-08T01:47:46.766191: step 2652, loss 0.0348074, acc 0.984375
2020-02-08T01:47:46.960948: step 2653, loss 0.0897601, acc 0.96875
2020-02-08T01:47:47.148789: step 2654, loss 0.00946736, acc 1
2020-02-08T01:47:47.352522: step 2655, loss 0.0150697, acc 1
2020-02-08T01:47:47.584733: step 2656, loss 0.00903365, acc 1
2020-02-08T01:47:47.785231: step 2657, loss 0.00810354, acc 1
2020-02-08T01:47:47.978648: step 2658, loss 0.110806, acc 0.984375
2020-02-08T01:47:48.169641: step 2659, loss 0.0432608, acc 0.984375
2020-02-08T01:47:48.383440: step 2660, loss 0.0263827, acc 1
2020-02-08T01:47:48.567672: step 2661, loss 0.0164507, acc 1
2020-02-08T01:47:48.771396: step 2662, loss 0.0117017, acc 1
2020-02-08T01:47:48.968841: step 2663, loss 0.0881926, acc 0.96875
2020-02-08T01:47:49.176099: step 2664, loss 0.0174343, acc 1
2020-02-08T01:47:49.376278: step 2665, loss 0.00572165, acc 1
2020-02-08T01:47:49.584981: step 2666, loss 0.0488462, acc 0.96875
2020-02-08T01:47:49.793087: step 2667, loss 0.0135105, acc 1
2020-02-08T01:47:50.018350: step 2668, loss 0.0319065, acc 1
2020-02-08T01:47:50.231915: step 2669, loss 0.00923479, acc 1
2020-02-08T01:47:50.457418: step 2670, loss 0.0145491, acc 1
2020-02-08T01:47:50.754023: step 2671, loss 0.0284908, acc 0.984375
2020-02-08T01:47:51.001974: step 2672, loss 0.0189147, acc 1
2020-02-08T01:47:51.232153: step 2673, loss 0.0438281, acc 0.984375
2020-02-08T01:47:51.786299: step 2674, loss 0.0287977, acc 0.984375
2020-02-08T01:47:52.002681: step 2675, loss 0.0112395, acc 1
2020-02-08T01:47:52.300545: step 2676, loss 0.016525, acc 1
2020-02-08T01:47:52.554533: step 2677, loss 0.0104258, acc 1
2020-02-08T01:47:52.801139: step 2678, loss 0.0233995, acc 1
2020-02-08T01:47:53.004013: step 2679, loss 0.0177545, acc 1
2020-02-08T01:47:53.221816: step 2680, loss 0.0240387, acc 0.984375
2020-02-08T01:47:53.433601: step 2681, loss 0.0262467, acc 0.984375
2020-02-08T01:47:53.648586: step 2682, loss 0.0356608, acc 0.984375
2020-02-08T01:47:53.852752: step 2683, loss 0.0491573, acc 0.984375
2020-02-08T01:47:54.050041: step 2684, loss 0.0200522, acc 1
2020-02-08T01:47:54.234966: step 2685, loss 0.0121606, acc 1
2020-02-08T01:47:54.428832: step 2686, loss 0.0211652, acc 0.984375
2020-02-08T01:47:54.637125: step 2687, loss 0.00636365, acc 1
2020-02-08T01:47:54.832879: step 2688, loss 0.0409867, acc 0.984375
2020-02-08T01:47:55.020532: step 2689, loss 0.0134865, acc 1
2020-02-08T01:47:55.210169: step 2690, loss 0.0195325, acc 1
2020-02-08T01:47:55.406027: step 2691, loss 0.02013, acc 1
2020-02-08T01:47:55.611539: step 2692, loss 0.0418079, acc 1
2020-02-08T01:47:55.802725: step 2693, loss 0.0231928, acc 1
2020-02-08T01:47:56.004788: step 2694, loss 0.165195, acc 0.9375
2020-02-08T01:47:56.203960: step 2695, loss 0.0271831, acc 1
2020-02-08T01:47:56.413917: step 2696, loss 0.00524312, acc 1
2020-02-08T01:47:56.608044: step 2697, loss 0.0457423, acc 0.984375
2020-02-08T01:47:56.844265: step 2698, loss 0.0836768, acc 0.96875
2020-02-08T01:47:57.056684: step 2699, loss 0.00628991, acc 1
2020-02-08T01:47:57.261558: step 2700, loss 0.1363, acc 0.966667

Evaluation:
2020-02-08T01:47:57.609980: step 2700, loss 0.959905, acc 0.738274

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2700

2020-02-08T01:48:00.024298: step 2701, loss 0.0133581, acc 1
2020-02-08T01:48:00.209924: step 2702, loss 0.0105381, acc 1
2020-02-08T01:48:00.407598: step 2703, loss 0.0151717, acc 1
2020-02-08T01:48:00.615299: step 2704, loss 0.0259443, acc 0.984375
2020-02-08T01:48:00.810837: step 2705, loss 0.028638, acc 0.984375
2020-02-08T01:48:01.010097: step 2706, loss 0.0505114, acc 0.984375
2020-02-08T01:48:01.211349: step 2707, loss 0.0135309, acc 1
2020-02-08T01:48:01.411338: step 2708, loss 0.0267813, acc 1
2020-02-08T01:48:01.607985: step 2709, loss 0.0211426, acc 0.984375
2020-02-08T01:48:01.808492: step 2710, loss 0.0220766, acc 1
2020-02-08T01:48:01.994104: step 2711, loss 0.00893115, acc 1
2020-02-08T01:48:02.200775: step 2712, loss 0.021409, acc 0.984375
2020-02-08T01:48:02.389783: step 2713, loss 0.0211789, acc 0.984375
2020-02-08T01:48:02.584575: step 2714, loss 0.0388154, acc 0.984375
2020-02-08T01:48:02.788854: step 2715, loss 0.0951671, acc 0.96875
2020-02-08T01:48:02.984939: step 2716, loss 0.0223119, acc 1
2020-02-08T01:48:03.182805: step 2717, loss 0.0158297, acc 1
2020-02-08T01:48:03.382885: step 2718, loss 0.00954753, acc 1
2020-02-08T01:48:03.583823: step 2719, loss 0.0106289, acc 1
2020-02-08T01:48:03.787672: step 2720, loss 0.0370183, acc 0.984375
2020-02-08T01:48:03.982668: step 2721, loss 0.0379171, acc 0.984375
2020-02-08T01:48:04.196554: step 2722, loss 0.0227868, acc 0.984375
2020-02-08T01:48:04.404452: step 2723, loss 0.00843277, acc 1
2020-02-08T01:48:04.652729: step 2724, loss 0.0386639, acc 0.984375
2020-02-08T01:48:04.882721: step 2725, loss 0.0381367, acc 0.984375
2020-02-08T01:48:05.090200: step 2726, loss 0.00990807, acc 1
2020-02-08T01:48:05.306384: step 2727, loss 0.0180604, acc 1
2020-02-08T01:48:05.503616: step 2728, loss 0.0530679, acc 0.984375
2020-02-08T01:48:05.711989: step 2729, loss 0.0128727, acc 1
2020-02-08T01:48:05.898797: step 2730, loss 0.00951044, acc 1
2020-02-08T01:48:06.097900: step 2731, loss 0.00579753, acc 1
2020-02-08T01:48:06.295464: step 2732, loss 0.0360571, acc 0.984375
2020-02-08T01:48:06.490147: step 2733, loss 0.0296974, acc 0.984375
2020-02-08T01:48:06.694802: step 2734, loss 0.0209312, acc 1
2020-02-08T01:48:06.889692: step 2735, loss 0.00404268, acc 1
2020-02-08T01:48:07.089037: step 2736, loss 0.0152293, acc 1
2020-02-08T01:48:07.278944: step 2737, loss 0.0317049, acc 0.984375
2020-02-08T01:48:07.466325: step 2738, loss 0.0207215, acc 1
2020-02-08T01:48:07.673000: step 2739, loss 0.072229, acc 0.984375
2020-02-08T01:48:07.857690: step 2740, loss 0.0273013, acc 0.984375
2020-02-08T01:48:08.047678: step 2741, loss 0.0875579, acc 0.984375
2020-02-08T01:48:08.236086: step 2742, loss 0.0527098, acc 0.984375
2020-02-08T01:48:08.426625: step 2743, loss 0.0393892, acc 0.984375
2020-02-08T01:48:08.623920: step 2744, loss 0.022971, acc 1
2020-02-08T01:48:08.821252: step 2745, loss 0.0116493, acc 1
2020-02-08T01:48:09.007730: step 2746, loss 0.00695184, acc 1
2020-02-08T01:48:09.215121: step 2747, loss 0.0684585, acc 0.96875
2020-02-08T01:48:09.403703: step 2748, loss 0.015544, acc 0.984375
2020-02-08T01:48:09.595210: step 2749, loss 0.00563287, acc 1
2020-02-08T01:48:09.790777: step 2750, loss 0.0122241, acc 1
2020-02-08T01:48:09.989861: step 2751, loss 0.0297157, acc 0.984375
2020-02-08T01:48:10.180081: step 2752, loss 0.00503745, acc 1
2020-02-08T01:48:10.389703: step 2753, loss 0.00862208, acc 1
2020-02-08T01:48:10.577193: step 2754, loss 0.0238393, acc 1
2020-02-08T01:48:10.793172: step 2755, loss 0.00935976, acc 1
2020-02-08T01:48:10.977233: step 2756, loss 0.0215383, acc 0.984375
2020-02-08T01:48:11.164544: step 2757, loss 0.0122021, acc 1
2020-02-08T01:48:11.357694: step 2758, loss 0.0055618, acc 1
2020-02-08T01:48:11.552899: step 2759, loss 0.0331873, acc 0.984375
2020-02-08T01:48:11.757197: step 2760, loss 0.0261408, acc 1
2020-02-08T01:48:11.955856: step 2761, loss 0.0130611, acc 1
2020-02-08T01:48:12.142077: step 2762, loss 0.0221944, acc 1
2020-02-08T01:48:12.342666: step 2763, loss 0.0547695, acc 0.984375
2020-02-08T01:48:12.528094: step 2764, loss 0.00703303, acc 1
2020-02-08T01:48:12.742084: step 2765, loss 0.0421378, acc 0.96875
2020-02-08T01:48:12.939254: step 2766, loss 0.0211017, acc 0.984375
2020-02-08T01:48:13.133823: step 2767, loss 0.0324042, acc 0.984375
2020-02-08T01:48:13.337256: step 2768, loss 0.0642282, acc 0.984375
2020-02-08T01:48:13.546424: step 2769, loss 0.0541335, acc 0.96875
2020-02-08T01:48:13.745855: step 2770, loss 0.0417343, acc 0.984375
2020-02-08T01:48:13.947263: step 2771, loss 0.117691, acc 0.953125
2020-02-08T01:48:14.133768: step 2772, loss 0.015412, acc 0.984375
2020-02-08T01:48:14.320363: step 2773, loss 0.0203061, acc 0.984375
2020-02-08T01:48:14.528002: step 2774, loss 0.0200935, acc 0.984375
2020-02-08T01:48:14.730891: step 2775, loss 0.00987684, acc 1
2020-02-08T01:48:14.919757: step 2776, loss 0.0216469, acc 1
2020-02-08T01:48:15.113940: step 2777, loss 0.0479662, acc 0.984375
2020-02-08T01:48:15.308041: step 2778, loss 0.00780906, acc 1
2020-02-08T01:48:15.507519: step 2779, loss 0.0107596, acc 1
2020-02-08T01:48:15.712582: step 2780, loss 0.0564996, acc 0.984375
2020-02-08T01:48:15.893944: step 2781, loss 0.00807566, acc 1
2020-02-08T01:48:16.079711: step 2782, loss 0.00938684, acc 1
2020-02-08T01:48:16.268652: step 2783, loss 0.00967734, acc 1
2020-02-08T01:48:16.459310: step 2784, loss 0.0240729, acc 0.984375
2020-02-08T01:48:16.648738: step 2785, loss 0.046017, acc 0.96875
2020-02-08T01:48:16.829123: step 2786, loss 0.0751729, acc 0.96875
2020-02-08T01:48:17.016294: step 2787, loss 0.0224684, acc 0.984375
2020-02-08T01:48:17.201101: step 2788, loss 0.014147, acc 1
2020-02-08T01:48:17.394911: step 2789, loss 0.0193928, acc 1
2020-02-08T01:48:17.597165: step 2790, loss 0.00716246, acc 1
2020-02-08T01:48:17.802478: step 2791, loss 0.035052, acc 0.984375
2020-02-08T01:48:17.985326: step 2792, loss 0.0153577, acc 1
2020-02-08T01:48:18.182945: step 2793, loss 0.0464556, acc 0.984375
2020-02-08T01:48:18.384135: step 2794, loss 0.00557904, acc 1
2020-02-08T01:48:18.577427: step 2795, loss 0.0219126, acc 0.984375
2020-02-08T01:48:18.799901: step 2796, loss 0.0111688, acc 1
2020-02-08T01:48:19.044392: step 2797, loss 0.0089166, acc 1
2020-02-08T01:48:19.266319: step 2798, loss 0.0160777, acc 1
2020-02-08T01:48:19.451360: step 2799, loss 0.0508687, acc 0.984375
2020-02-08T01:48:19.660354: step 2800, loss 0.016627, acc 1

Evaluation:
2020-02-08T01:48:19.986467: step 2800, loss 0.985605, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2800

2020-02-08T01:48:21.667981: step 2801, loss 0.0184939, acc 0.984375
2020-02-08T01:48:21.851192: step 2802, loss 0.00977985, acc 1
2020-02-08T01:48:22.178628: step 2803, loss 0.0177159, acc 0.984375
2020-02-08T01:48:22.387365: step 2804, loss 0.0202157, acc 1
2020-02-08T01:48:22.594769: step 2805, loss 0.0213591, acc 1
2020-02-08T01:48:22.780371: step 2806, loss 0.0125988, acc 1
2020-02-08T01:48:22.963328: step 2807, loss 0.0951784, acc 0.984375
2020-02-08T01:48:23.148991: step 2808, loss 0.101178, acc 0.953125
2020-02-08T01:48:23.342878: step 2809, loss 0.0121821, acc 1
2020-02-08T01:48:23.538268: step 2810, loss 0.00568024, acc 1
2020-02-08T01:48:23.741797: step 2811, loss 0.0106871, acc 1
2020-02-08T01:48:23.933593: step 2812, loss 0.00633409, acc 1
2020-02-08T01:48:24.120084: step 2813, loss 0.0223845, acc 0.984375
2020-02-08T01:48:24.304324: step 2814, loss 0.0150638, acc 1
2020-02-08T01:48:24.493177: step 2815, loss 0.00293604, acc 1
2020-02-08T01:48:24.681384: step 2816, loss 0.0064301, acc 1
2020-02-08T01:48:24.879751: step 2817, loss 0.0158198, acc 1
2020-02-08T01:48:25.105059: step 2818, loss 0.0443495, acc 0.984375
2020-02-08T01:48:25.310146: step 2819, loss 0.0465784, acc 0.984375
2020-02-08T01:48:25.534542: step 2820, loss 0.00647701, acc 1
2020-02-08T01:48:25.763345: step 2821, loss 0.0634393, acc 0.984375
2020-02-08T01:48:26.025948: step 2822, loss 0.039442, acc 0.984375
2020-02-08T01:48:26.274545: step 2823, loss 0.0661765, acc 0.953125
2020-02-08T01:48:26.542363: step 2824, loss 0.00909447, acc 1
2020-02-08T01:48:26.842076: step 2825, loss 0.0202218, acc 1
2020-02-08T01:48:27.045600: step 2826, loss 0.00463441, acc 1
2020-02-08T01:48:27.266154: step 2827, loss 0.0404413, acc 0.984375
2020-02-08T01:48:27.498100: step 2828, loss 0.0128362, acc 1
2020-02-08T01:48:27.765271: step 2829, loss 0.0108333, acc 1
2020-02-08T01:48:27.990220: step 2830, loss 0.0457834, acc 0.984375
2020-02-08T01:48:28.221628: step 2831, loss 0.0237635, acc 1
2020-02-08T01:48:28.424376: step 2832, loss 0.0179984, acc 1
2020-02-08T01:48:28.622242: step 2833, loss 0.00915092, acc 1
2020-02-08T01:48:28.824522: step 2834, loss 0.00507198, acc 1
2020-02-08T01:48:29.036291: step 2835, loss 0.0234805, acc 0.984375
2020-02-08T01:48:29.262412: step 2836, loss 0.012762, acc 1
2020-02-08T01:48:29.465936: step 2837, loss 0.013368, acc 1
2020-02-08T01:48:29.672567: step 2838, loss 0.00225336, acc 1
2020-02-08T01:48:29.867726: step 2839, loss 0.00784222, acc 1
2020-02-08T01:48:30.073219: step 2840, loss 0.0171156, acc 1
2020-02-08T01:48:30.270452: step 2841, loss 0.0129252, acc 1
2020-02-08T01:48:30.464476: step 2842, loss 0.0141554, acc 1
2020-02-08T01:48:30.669342: step 2843, loss 0.0091343, acc 1
2020-02-08T01:48:30.859609: step 2844, loss 0.00351859, acc 1
2020-02-08T01:48:31.066121: step 2845, loss 0.0186293, acc 1
2020-02-08T01:48:31.263597: step 2846, loss 0.0594052, acc 0.984375
2020-02-08T01:48:31.453983: step 2847, loss 0.00601622, acc 1
2020-02-08T01:48:31.669475: step 2848, loss 0.0148581, acc 1
2020-02-08T01:48:31.867807: step 2849, loss 0.0263571, acc 0.984375
2020-02-08T01:48:32.054845: step 2850, loss 0.0307101, acc 0.983333
2020-02-08T01:48:32.256070: step 2851, loss 0.01137, acc 1
2020-02-08T01:48:32.457878: step 2852, loss 0.00854122, acc 1
2020-02-08T01:48:32.667037: step 2853, loss 0.0100457, acc 1
2020-02-08T01:48:32.856426: step 2854, loss 0.0063056, acc 1
2020-02-08T01:48:33.053079: step 2855, loss 0.0310213, acc 1
2020-02-08T01:48:33.256531: step 2856, loss 0.0674357, acc 0.96875
2020-02-08T01:48:33.469236: step 2857, loss 0.0389369, acc 0.984375
2020-02-08T01:48:33.707911: step 2858, loss 0.00575158, acc 1
2020-02-08T01:48:33.909412: step 2859, loss 0.00972771, acc 1
2020-02-08T01:48:34.106118: step 2860, loss 0.0374169, acc 0.984375
2020-02-08T01:48:34.306137: step 2861, loss 0.00631381, acc 1
2020-02-08T01:48:34.504019: step 2862, loss 0.00580246, acc 1
2020-02-08T01:48:34.706016: step 2863, loss 0.0323883, acc 0.984375
2020-02-08T01:48:34.908583: step 2864, loss 0.00460126, acc 1
2020-02-08T01:48:35.118029: step 2865, loss 0.0257404, acc 0.984375
2020-02-08T01:48:35.319779: step 2866, loss 0.00625617, acc 1
2020-02-08T01:48:35.535130: step 2867, loss 0.0224689, acc 0.984375
2020-02-08T01:48:35.752277: step 2868, loss 0.0055277, acc 1
2020-02-08T01:48:35.958021: step 2869, loss 0.00515529, acc 1
2020-02-08T01:48:36.158575: step 2870, loss 0.0327798, acc 0.984375
2020-02-08T01:48:36.367248: step 2871, loss 0.00818799, acc 1
2020-02-08T01:48:36.578886: step 2872, loss 0.0204731, acc 1
2020-02-08T01:48:36.778661: step 2873, loss 0.0215556, acc 0.984375
2020-02-08T01:48:36.977602: step 2874, loss 0.0323909, acc 0.984375
2020-02-08T01:48:37.168353: step 2875, loss 0.00447164, acc 1
2020-02-08T01:48:37.387380: step 2876, loss 0.0195827, acc 0.984375
2020-02-08T01:48:37.615826: step 2877, loss 0.00667706, acc 1
2020-02-08T01:48:37.842209: step 2878, loss 0.0144315, acc 1
2020-02-08T01:48:38.021198: step 2879, loss 0.0346278, acc 0.96875
2020-02-08T01:48:38.238485: step 2880, loss 0.0299483, acc 0.984375
2020-02-08T01:48:38.438373: step 2881, loss 0.00738909, acc 1
2020-02-08T01:48:38.639532: step 2882, loss 0.0828303, acc 0.96875
2020-02-08T01:48:38.838205: step 2883, loss 0.00636512, acc 1
2020-02-08T01:48:39.050297: step 2884, loss 0.00994669, acc 1
2020-02-08T01:48:39.275384: step 2885, loss 0.0345993, acc 0.984375
2020-02-08T01:48:39.488807: step 2886, loss 0.0287188, acc 0.984375
2020-02-08T01:48:39.762500: step 2887, loss 0.00535514, acc 1
2020-02-08T01:48:40.008930: step 2888, loss 0.0166056, acc 0.984375
2020-02-08T01:48:40.247885: step 2889, loss 0.0322934, acc 0.984375
2020-02-08T01:48:40.508014: step 2890, loss 0.0396562, acc 0.96875
2020-02-08T01:48:40.789169: step 2891, loss 0.00743113, acc 1
2020-02-08T01:48:41.030984: step 2892, loss 0.041558, acc 0.96875
2020-02-08T01:48:41.231793: step 2893, loss 0.0179509, acc 1
2020-02-08T01:48:41.431302: step 2894, loss 0.0221885, acc 1
2020-02-08T01:48:41.659139: step 2895, loss 0.00817542, acc 1
2020-02-08T01:48:41.853264: step 2896, loss 0.00720805, acc 1
2020-02-08T01:48:42.059827: step 2897, loss 0.00560015, acc 1
2020-02-08T01:48:42.248660: step 2898, loss 0.0354126, acc 0.984375
2020-02-08T01:48:42.447750: step 2899, loss 0.0105826, acc 1
2020-02-08T01:48:42.649091: step 2900, loss 0.012373, acc 1

Evaluation:
2020-02-08T01:48:42.996790: step 2900, loss 0.999543, acc 0.737336

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-2900

2020-02-08T01:48:45.786152: step 2901, loss 0.0321757, acc 0.984375
2020-02-08T01:48:45.991121: step 2902, loss 0.0474016, acc 0.96875
2020-02-08T01:48:46.198270: step 2903, loss 0.0239652, acc 0.984375
2020-02-08T01:48:46.379017: step 2904, loss 0.0504846, acc 0.984375
2020-02-08T01:48:46.575237: step 2905, loss 0.043261, acc 0.984375
2020-02-08T01:48:46.779228: step 2906, loss 0.00797229, acc 1
2020-02-08T01:48:46.966274: step 2907, loss 0.0125758, acc 1
2020-02-08T01:48:47.160686: step 2908, loss 0.0518396, acc 0.96875
2020-02-08T01:48:47.350994: step 2909, loss 0.00683023, acc 1
2020-02-08T01:48:47.564353: step 2910, loss 0.0026281, acc 1
2020-02-08T01:48:47.767035: step 2911, loss 0.012045, acc 1
2020-02-08T01:48:47.961198: step 2912, loss 0.0230368, acc 0.984375
2020-02-08T01:48:48.152070: step 2913, loss 0.00493525, acc 1
2020-02-08T01:48:48.340668: step 2914, loss 0.0110854, acc 1
2020-02-08T01:48:48.543090: step 2915, loss 0.0181393, acc 1
2020-02-08T01:48:48.746837: step 2916, loss 0.0367289, acc 0.984375
2020-02-08T01:48:48.937663: step 2917, loss 0.00336874, acc 1
2020-02-08T01:48:49.158712: step 2918, loss 0.0333718, acc 0.984375
2020-02-08T01:48:49.348496: step 2919, loss 0.00803627, acc 1
2020-02-08T01:48:49.548819: step 2920, loss 0.0160683, acc 1
2020-02-08T01:48:49.748732: step 2921, loss 0.00409087, acc 1
2020-02-08T01:48:49.941665: step 2922, loss 0.0768886, acc 0.984375
2020-02-08T01:48:50.148392: step 2923, loss 0.0641035, acc 0.96875
2020-02-08T01:48:50.345071: step 2924, loss 0.0121078, acc 1
2020-02-08T01:48:50.542971: step 2925, loss 0.0162921, acc 0.984375
2020-02-08T01:48:50.736552: step 2926, loss 0.0225261, acc 1
2020-02-08T01:48:50.927142: step 2927, loss 0.0497301, acc 0.984375
2020-02-08T01:48:51.125650: step 2928, loss 0.0253868, acc 1
2020-02-08T01:48:51.329089: step 2929, loss 0.0221791, acc 1
2020-02-08T01:48:51.515113: step 2930, loss 0.031465, acc 0.984375
2020-02-08T01:48:51.726274: step 2931, loss 0.0688785, acc 0.96875
2020-02-08T01:48:51.923824: step 2932, loss 0.00397959, acc 1
2020-02-08T01:48:52.102456: step 2933, loss 0.0136549, acc 1
2020-02-08T01:48:52.314936: step 2934, loss 0.0044149, acc 1
2020-02-08T01:48:52.503565: step 2935, loss 0.00687232, acc 1
2020-02-08T01:48:52.719340: step 2936, loss 0.0143228, acc 1
2020-02-08T01:48:52.880964: step 2937, loss 0.0289024, acc 1
2020-02-08T01:48:53.060697: step 2938, loss 0.0122586, acc 1
2020-02-08T01:48:53.248795: step 2939, loss 0.0224851, acc 0.984375
2020-02-08T01:48:53.432512: step 2940, loss 0.0128141, acc 1
2020-02-08T01:48:53.620455: step 2941, loss 0.00919916, acc 1
2020-02-08T01:48:53.815630: step 2942, loss 0.0323038, acc 0.96875
2020-02-08T01:48:53.993638: step 2943, loss 0.0193776, acc 0.984375
2020-02-08T01:48:54.194614: step 2944, loss 0.00727301, acc 1
2020-02-08T01:48:54.380070: step 2945, loss 0.0610461, acc 0.96875
2020-02-08T01:48:54.570989: step 2946, loss 0.0277007, acc 0.984375
2020-02-08T01:48:54.762779: step 2947, loss 0.00835668, acc 1
2020-02-08T01:48:54.938178: step 2948, loss 0.00927371, acc 1
2020-02-08T01:48:55.128341: step 2949, loss 0.00748492, acc 1
2020-02-08T01:48:55.304329: step 2950, loss 0.00486897, acc 1
2020-02-08T01:48:55.482190: step 2951, loss 0.036927, acc 0.96875
2020-02-08T01:48:55.683038: step 2952, loss 0.00717189, acc 1
2020-02-08T01:48:55.873247: step 2953, loss 0.013793, acc 1
2020-02-08T01:48:56.063752: step 2954, loss 0.00735897, acc 1
2020-02-08T01:48:56.239610: step 2955, loss 0.0780998, acc 0.96875
2020-02-08T01:48:56.417032: step 2956, loss 0.0380024, acc 0.984375
2020-02-08T01:48:56.604691: step 2957, loss 0.0363076, acc 0.984375
2020-02-08T01:48:56.794362: step 2958, loss 0.0128486, acc 1
2020-02-08T01:48:56.974852: step 2959, loss 0.0877061, acc 0.96875
2020-02-08T01:48:57.171353: step 2960, loss 0.00969705, acc 1
2020-02-08T01:48:57.367337: step 2961, loss 0.00632921, acc 1
2020-02-08T01:48:57.552937: step 2962, loss 0.00733478, acc 1
2020-02-08T01:48:57.746472: step 2963, loss 0.0040757, acc 1
2020-02-08T01:48:57.933110: step 2964, loss 0.0119607, acc 1
2020-02-08T01:48:58.119291: step 2965, loss 0.0621067, acc 0.984375
2020-02-08T01:48:58.302554: step 2966, loss 0.0197998, acc 1
2020-02-08T01:48:58.498021: step 2967, loss 0.00587483, acc 1
2020-02-08T01:48:58.689666: step 2968, loss 0.0296963, acc 0.984375
2020-02-08T01:48:58.878060: step 2969, loss 0.0349817, acc 0.96875
2020-02-08T01:48:59.077828: step 2970, loss 0.00907329, acc 1
2020-02-08T01:48:59.262675: step 2971, loss 0.032479, acc 0.984375
2020-02-08T01:48:59.459029: step 2972, loss 0.0552922, acc 0.984375
2020-02-08T01:48:59.658180: step 2973, loss 0.0116579, acc 1
2020-02-08T01:48:59.852578: step 2974, loss 0.0353813, acc 0.984375
2020-02-08T01:49:00.037726: step 2975, loss 0.00408509, acc 1
2020-02-08T01:49:00.220863: step 2976, loss 0.00330115, acc 1
2020-02-08T01:49:00.443989: step 2977, loss 0.0149473, acc 1
2020-02-08T01:49:00.653185: step 2978, loss 0.0108211, acc 1
2020-02-08T01:49:00.883684: step 2979, loss 0.0201983, acc 0.984375
2020-02-08T01:49:01.132921: step 2980, loss 0.0496161, acc 1
2020-02-08T01:49:01.355126: step 2981, loss 0.00877469, acc 1
2020-02-08T01:49:01.513381: step 2982, loss 0.00409851, acc 1
2020-02-08T01:49:01.712756: step 2983, loss 0.0283662, acc 0.984375
2020-02-08T01:49:01.901394: step 2984, loss 0.0294978, acc 0.984375
2020-02-08T01:49:02.089092: step 2985, loss 0.0399627, acc 0.96875
2020-02-08T01:49:02.282687: step 2986, loss 0.0111694, acc 1
2020-02-08T01:49:02.468694: step 2987, loss 0.013896, acc 1
2020-02-08T01:49:02.681147: step 2988, loss 0.0278904, acc 0.984375
2020-02-08T01:49:02.862677: step 2989, loss 0.00805982, acc 1
2020-02-08T01:49:03.047538: step 2990, loss 0.0293304, acc 0.984375
2020-02-08T01:49:03.272587: step 2991, loss 0.0425634, acc 0.984375
2020-02-08T01:49:03.479382: step 2992, loss 0.0303945, acc 0.984375
2020-02-08T01:49:03.718774: step 2993, loss 0.00686252, acc 1
2020-02-08T01:49:03.934451: step 2994, loss 0.00564289, acc 1
2020-02-08T01:49:04.118948: step 2995, loss 0.0065875, acc 1
2020-02-08T01:49:04.317168: step 2996, loss 0.0252766, acc 0.984375
2020-02-08T01:49:04.505253: step 2997, loss 0.0128943, acc 1
2020-02-08T01:49:04.712251: step 2998, loss 0.0170546, acc 0.984375
2020-02-08T01:49:04.888477: step 2999, loss 0.0212127, acc 1
2020-02-08T01:49:05.068178: step 3000, loss 0.0142975, acc 1

Evaluation:
2020-02-08T01:49:05.389335: step 3000, loss 1.02322, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581097075/checkpoints/model-3000

