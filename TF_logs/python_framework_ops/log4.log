WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:00:37.806346 4407377344 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:00:37.806731 4407377344 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:00:37.806971 4407377344 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:00:38.547162 4407377344 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:00:38.547397 4407377344 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:00:38.547605: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:00:38.565161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff5ce125730 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:00:38.565233: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:00:38.565758 4407377344 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:00:38.573732 4407377344 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:00:38.599383 4407377344 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:00:38.636460 4407377344 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:00:38.696899 4407377344 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:00:38.716048 4407377344 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:00:38.716336 4407377344 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:00:38.744271 4407377344 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:00:38.747894 4407377344 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:00:38.803793 4407377344 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:00:39.306997 4407377344 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:00:39.307896 4407377344 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:00:39.319493 4407377344 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:00:39.356501 4407377344 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:00:39.358994 4407377344 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:00:39.396452 4407377344 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:00:39.398802 4407377344 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:00:39.433734 4407377344 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:00:39.435109 4407377344 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:00:39.471662 4407377344 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:00:39.475816 4407377344 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:00:39.510230 4407377344 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:00:39.513746 4407377344 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:00:39.547237 4407377344 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:00:39.548595 4407377344 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:00:39.582759 4407377344 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:00:39.584484 4407377344 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:00:39.628645 4407377344 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:00:39.630023 4407377344 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:00:39.664340 4407377344 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:00:39.666368 4407377344 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:00:39.676126 4407377344 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:00:40.084811 4407377344 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:00:40.085005 4407377344 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:00:40.190281 4407377344 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:00:41.050467 4407377344 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:02:45.346234 4407377344 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439

2020-02-08T02:00:41.050031: step 1, loss 3.06081, acc 0.46875
2020-02-08T02:00:41.254602: step 2, loss 2.29602, acc 0.515625
2020-02-08T02:00:41.421497: step 3, loss 2.11485, acc 0.453125
2020-02-08T02:00:41.583287: step 4, loss 2.14719, acc 0.53125
2020-02-08T02:00:41.777338: step 5, loss 2.82161, acc 0.390625
2020-02-08T02:00:41.958341: step 6, loss 2.15852, acc 0.53125
2020-02-08T02:00:42.140512: step 7, loss 2.71865, acc 0.375
2020-02-08T02:00:42.314844: step 8, loss 2.4084, acc 0.390625
2020-02-08T02:00:42.492041: step 9, loss 2.42152, acc 0.46875
2020-02-08T02:00:42.681674: step 10, loss 2.19692, acc 0.4375
2020-02-08T02:00:42.859903: step 11, loss 1.35353, acc 0.546875
2020-02-08T02:00:43.043449: step 12, loss 1.84504, acc 0.515625
2020-02-08T02:00:43.220592: step 13, loss 1.24612, acc 0.671875
2020-02-08T02:00:43.404648: step 14, loss 1.95962, acc 0.484375
2020-02-08T02:00:43.597899: step 15, loss 1.94521, acc 0.578125
2020-02-08T02:00:43.787730: step 16, loss 1.72418, acc 0.5
2020-02-08T02:00:43.972796: step 17, loss 2.34455, acc 0.4375
2020-02-08T02:00:44.154118: step 18, loss 1.8328, acc 0.515625
2020-02-08T02:00:44.332373: step 19, loss 1.6621, acc 0.5625
2020-02-08T02:00:44.516816: step 20, loss 2.11527, acc 0.515625
2020-02-08T02:00:44.701064: step 21, loss 1.77054, acc 0.546875
2020-02-08T02:00:44.886164: step 22, loss 1.8407, acc 0.625
2020-02-08T02:00:45.066136: step 23, loss 2.32961, acc 0.40625
2020-02-08T02:00:45.251408: step 24, loss 1.76067, acc 0.484375
2020-02-08T02:00:45.425897: step 25, loss 2.03065, acc 0.4375
2020-02-08T02:00:45.606405: step 26, loss 2.31328, acc 0.453125
2020-02-08T02:00:45.794004: step 27, loss 1.52138, acc 0.546875
2020-02-08T02:00:45.976806: step 28, loss 1.80096, acc 0.53125
2020-02-08T02:00:46.155136: step 29, loss 1.95676, acc 0.515625
2020-02-08T02:00:46.329510: step 30, loss 1.86327, acc 0.5
2020-02-08T02:00:46.505418: step 31, loss 2.06663, acc 0.515625
2020-02-08T02:00:46.697522: step 32, loss 1.41549, acc 0.578125
2020-02-08T02:00:46.876183: step 33, loss 1.82959, acc 0.5
2020-02-08T02:00:47.045848: step 34, loss 1.6182, acc 0.515625
2020-02-08T02:00:47.213430: step 35, loss 1.55145, acc 0.578125
2020-02-08T02:00:47.388470: step 36, loss 1.66546, acc 0.484375
2020-02-08T02:00:47.564909: step 37, loss 1.47726, acc 0.546875
2020-02-08T02:00:47.754221: step 38, loss 1.69299, acc 0.546875
2020-02-08T02:00:47.931791: step 39, loss 1.98235, acc 0.453125
2020-02-08T02:00:48.104714: step 40, loss 1.55768, acc 0.546875
2020-02-08T02:00:48.287570: step 41, loss 1.3354, acc 0.46875
2020-02-08T02:00:48.478322: step 42, loss 1.54657, acc 0.515625
2020-02-08T02:00:48.651438: step 43, loss 1.98857, acc 0.453125
2020-02-08T02:00:48.833420: step 44, loss 1.41473, acc 0.546875
2020-02-08T02:00:49.013189: step 45, loss 1.50731, acc 0.546875
2020-02-08T02:00:49.203559: step 46, loss 1.96999, acc 0.40625
2020-02-08T02:00:49.375785: step 47, loss 2.21926, acc 0.453125
2020-02-08T02:00:49.551212: step 48, loss 1.24421, acc 0.578125
2020-02-08T02:00:49.747402: step 49, loss 1.89831, acc 0.421875
2020-02-08T02:00:49.923191: step 50, loss 1.45378, acc 0.515625
2020-02-08T02:00:50.112425: step 51, loss 1.81848, acc 0.40625
2020-02-08T02:00:50.297593: step 52, loss 1.55202, acc 0.5
2020-02-08T02:00:50.482785: step 53, loss 1.40583, acc 0.71875
2020-02-08T02:00:50.666405: step 54, loss 1.8356, acc 0.4375
2020-02-08T02:00:50.840137: step 55, loss 1.55767, acc 0.546875
2020-02-08T02:00:51.015558: step 56, loss 1.67403, acc 0.515625
2020-02-08T02:00:51.186145: step 57, loss 1.37696, acc 0.59375
2020-02-08T02:00:51.408132: step 58, loss 1.8969, acc 0.421875
2020-02-08T02:00:51.607712: step 59, loss 1.46795, acc 0.46875
2020-02-08T02:00:51.800608: step 60, loss 1.63793, acc 0.453125
2020-02-08T02:00:51.981380: step 61, loss 1.3798, acc 0.546875
2020-02-08T02:00:52.181555: step 62, loss 1.44582, acc 0.515625
2020-02-08T02:00:52.356721: step 63, loss 1.53133, acc 0.5
2020-02-08T02:00:52.537097: step 64, loss 1.65241, acc 0.515625
2020-02-08T02:00:52.734536: step 65, loss 1.37008, acc 0.515625
2020-02-08T02:00:52.917298: step 66, loss 1.45493, acc 0.421875
2020-02-08T02:00:53.091175: step 67, loss 1.70217, acc 0.5625
2020-02-08T02:00:53.272045: step 68, loss 1.60191, acc 0.546875
2020-02-08T02:00:53.458124: step 69, loss 1.15008, acc 0.671875
2020-02-08T02:00:53.655240: step 70, loss 1.59603, acc 0.546875
2020-02-08T02:00:53.835499: step 71, loss 1.60089, acc 0.5
2020-02-08T02:00:54.009720: step 72, loss 1.44111, acc 0.5625
2020-02-08T02:00:54.185745: step 73, loss 1.40793, acc 0.546875
2020-02-08T02:00:54.354219: step 74, loss 1.30967, acc 0.484375
2020-02-08T02:00:54.541726: step 75, loss 1.6056, acc 0.578125
2020-02-08T02:00:54.734239: step 76, loss 1.99915, acc 0.453125
2020-02-08T02:00:54.912691: step 77, loss 1.63626, acc 0.4375
2020-02-08T02:00:55.090589: step 78, loss 1.15958, acc 0.5625
2020-02-08T02:00:55.266005: step 79, loss 1.32849, acc 0.5625
2020-02-08T02:00:55.440654: step 80, loss 1.71549, acc 0.453125
2020-02-08T02:00:55.643939: step 81, loss 1.25919, acc 0.53125
2020-02-08T02:00:55.816501: step 82, loss 1.7798, acc 0.5
2020-02-08T02:00:55.998282: step 83, loss 1.43267, acc 0.59375
2020-02-08T02:00:56.180744: step 84, loss 1.50133, acc 0.515625
2020-02-08T02:00:56.354602: step 85, loss 1.3713, acc 0.515625
2020-02-08T02:00:56.533847: step 86, loss 1.95792, acc 0.359375
2020-02-08T02:00:56.726045: step 87, loss 1.4419, acc 0.484375
2020-02-08T02:00:56.908970: step 88, loss 1.38561, acc 0.53125
2020-02-08T02:00:57.094591: step 89, loss 1.5431, acc 0.53125
2020-02-08T02:00:57.271883: step 90, loss 1.47858, acc 0.453125
2020-02-08T02:00:57.448707: step 91, loss 1.57802, acc 0.53125
2020-02-08T02:00:57.629341: step 92, loss 1.14944, acc 0.671875
2020-02-08T02:00:57.810884: step 93, loss 1.01564, acc 0.578125
2020-02-08T02:00:57.996764: step 94, loss 1.50361, acc 0.5
2020-02-08T02:00:58.179359: step 95, loss 1.54361, acc 0.5625
2020-02-08T02:00:58.358337: step 96, loss 1.57326, acc 0.515625
2020-02-08T02:00:58.550718: step 97, loss 1.7476, acc 0.53125
2020-02-08T02:00:58.736066: step 98, loss 1.08704, acc 0.59375
2020-02-08T02:00:58.917868: step 99, loss 1.23894, acc 0.5625
2020-02-08T02:00:59.107284: step 100, loss 1.27416, acc 0.53125

Evaluation:
2020-02-08T02:00:59.485169: step 100, loss 0.919736, acc 0.541276

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-100

2020-02-08T02:01:01.722145: step 101, loss 0.973996, acc 0.671875
2020-02-08T02:01:01.918725: step 102, loss 1.41586, acc 0.515625
2020-02-08T02:01:02.119177: step 103, loss 1.91994, acc 0.484375
2020-02-08T02:01:02.299286: step 104, loss 1.79462, acc 0.46875
2020-02-08T02:01:02.476476: step 105, loss 1.74607, acc 0.515625
2020-02-08T02:01:02.682713: step 106, loss 1.49545, acc 0.515625
2020-02-08T02:01:02.879695: step 107, loss 1.33488, acc 0.4375
2020-02-08T02:01:03.067088: step 108, loss 1.71363, acc 0.421875
2020-02-08T02:01:03.255983: step 109, loss 1.34116, acc 0.46875
2020-02-08T02:01:03.442879: step 110, loss 2.08165, acc 0.4375
2020-02-08T02:01:03.634275: step 111, loss 1.27367, acc 0.5625
2020-02-08T02:01:03.818705: step 112, loss 1.36086, acc 0.578125
2020-02-08T02:01:03.993393: step 113, loss 1.16826, acc 0.578125
2020-02-08T02:01:04.168799: step 114, loss 1.33133, acc 0.546875
2020-02-08T02:01:04.348882: step 115, loss 1.4037, acc 0.53125
2020-02-08T02:01:04.529260: step 116, loss 1.30236, acc 0.53125
2020-02-08T02:01:04.714887: step 117, loss 1.36697, acc 0.515625
2020-02-08T02:01:04.903816: step 118, loss 1.4684, acc 0.515625
2020-02-08T02:01:05.087342: step 119, loss 1.49443, acc 0.546875
2020-02-08T02:01:05.276504: step 120, loss 1.42311, acc 0.515625
2020-02-08T02:01:05.443693: step 121, loss 0.949473, acc 0.65625
2020-02-08T02:01:05.623050: step 122, loss 1.74366, acc 0.375
2020-02-08T02:01:05.806595: step 123, loss 2.04117, acc 0.390625
2020-02-08T02:01:05.987225: step 124, loss 1.24605, acc 0.609375
2020-02-08T02:01:06.161207: step 125, loss 1.66207, acc 0.5
2020-02-08T02:01:06.339326: step 126, loss 1.28563, acc 0.546875
2020-02-08T02:01:06.526717: step 127, loss 1.33397, acc 0.59375
2020-02-08T02:01:06.720591: step 128, loss 1.1065, acc 0.625
2020-02-08T02:01:06.896146: step 129, loss 1.35168, acc 0.53125
2020-02-08T02:01:07.072766: step 130, loss 0.95272, acc 0.65625
2020-02-08T02:01:07.245751: step 131, loss 1.38282, acc 0.640625
2020-02-08T02:01:07.435925: step 132, loss 1.60451, acc 0.546875
2020-02-08T02:01:07.631218: step 133, loss 1.16627, acc 0.609375
2020-02-08T02:01:07.825296: step 134, loss 1.6748, acc 0.515625
2020-02-08T02:01:08.008705: step 135, loss 1.39078, acc 0.515625
2020-02-08T02:01:08.191783: step 136, loss 1.36084, acc 0.484375
2020-02-08T02:01:08.372248: step 137, loss 1.41485, acc 0.515625
2020-02-08T02:01:08.565785: step 138, loss 1.14061, acc 0.625
2020-02-08T02:01:08.766045: step 139, loss 1.09341, acc 0.609375
2020-02-08T02:01:08.988997: step 140, loss 1.5008, acc 0.515625
2020-02-08T02:01:09.205390: step 141, loss 1.4849, acc 0.390625
2020-02-08T02:01:09.393559: step 142, loss 1.30599, acc 0.453125
2020-02-08T02:01:09.581157: step 143, loss 1.39715, acc 0.5
2020-02-08T02:01:09.788763: step 144, loss 1.11337, acc 0.59375
2020-02-08T02:01:09.994275: step 145, loss 1.40006, acc 0.46875
2020-02-08T02:01:10.179834: step 146, loss 1.27063, acc 0.5
2020-02-08T02:01:10.365351: step 147, loss 1.28935, acc 0.609375
2020-02-08T02:01:10.552481: step 148, loss 1.01928, acc 0.578125
2020-02-08T02:01:10.741821: step 149, loss 0.960742, acc 0.546875
2020-02-08T02:01:10.917966: step 150, loss 1.17318, acc 0.5
2020-02-08T02:01:11.107149: step 151, loss 0.861107, acc 0.609375
2020-02-08T02:01:11.284057: step 152, loss 1.15966, acc 0.53125
2020-02-08T02:01:11.474950: step 153, loss 0.917242, acc 0.625
2020-02-08T02:01:11.650053: step 154, loss 0.775894, acc 0.640625
2020-02-08T02:01:11.832070: step 155, loss 0.899297, acc 0.640625
2020-02-08T02:01:12.027349: step 156, loss 1.2003, acc 0.609375
2020-02-08T02:01:12.231342: step 157, loss 0.930428, acc 0.625
2020-02-08T02:01:12.429884: step 158, loss 0.926454, acc 0.625
2020-02-08T02:01:12.608149: step 159, loss 0.914641, acc 0.640625
2020-02-08T02:01:12.795431: step 160, loss 0.95819, acc 0.65625
2020-02-08T02:01:12.970515: step 161, loss 0.879525, acc 0.671875
2020-02-08T02:01:13.144591: step 162, loss 1.2499, acc 0.578125
2020-02-08T02:01:13.320889: step 163, loss 1.40338, acc 0.53125
2020-02-08T02:01:13.503821: step 164, loss 0.847484, acc 0.640625
2020-02-08T02:01:13.698405: step 165, loss 0.72769, acc 0.75
2020-02-08T02:01:13.886176: step 166, loss 0.864875, acc 0.6875
2020-02-08T02:01:14.099286: step 167, loss 0.873022, acc 0.609375
2020-02-08T02:01:14.281291: step 168, loss 0.932144, acc 0.625
2020-02-08T02:01:14.455731: step 169, loss 0.652497, acc 0.734375
2020-02-08T02:01:14.636146: step 170, loss 1.13072, acc 0.578125
2020-02-08T02:01:14.819497: step 171, loss 0.712679, acc 0.703125
2020-02-08T02:01:14.997441: step 172, loss 1.14181, acc 0.546875
2020-02-08T02:01:15.177211: step 173, loss 1.11507, acc 0.625
2020-02-08T02:01:15.347464: step 174, loss 1.10002, acc 0.546875
2020-02-08T02:01:15.529857: step 175, loss 1.07448, acc 0.53125
2020-02-08T02:01:15.718681: step 176, loss 0.911528, acc 0.625
2020-02-08T02:01:15.895594: step 177, loss 1.14235, acc 0.578125
2020-02-08T02:01:16.059957: step 178, loss 0.988676, acc 0.484375
2020-02-08T02:01:16.226559: step 179, loss 0.950206, acc 0.515625
2020-02-08T02:01:16.395166: step 180, loss 0.946565, acc 0.5625
2020-02-08T02:01:16.561965: step 181, loss 0.941134, acc 0.59375
2020-02-08T02:01:16.743349: step 182, loss 1.01694, acc 0.5625
2020-02-08T02:01:16.919322: step 183, loss 0.771834, acc 0.6875
2020-02-08T02:01:17.095896: step 184, loss 0.876165, acc 0.625
2020-02-08T02:01:17.270670: step 185, loss 0.806285, acc 0.625
2020-02-08T02:01:17.442452: step 186, loss 0.784493, acc 0.65625
2020-02-08T02:01:17.618295: step 187, loss 0.996458, acc 0.5625
2020-02-08T02:01:17.800267: step 188, loss 0.804309, acc 0.609375
2020-02-08T02:01:17.977722: step 189, loss 0.863254, acc 0.65625
2020-02-08T02:01:18.154282: step 190, loss 1.10402, acc 0.5625
2020-02-08T02:01:18.330267: step 191, loss 1.00731, acc 0.59375
2020-02-08T02:01:18.505286: step 192, loss 1.1696, acc 0.546875
2020-02-08T02:01:18.689817: step 193, loss 0.966615, acc 0.625
2020-02-08T02:01:18.877226: step 194, loss 0.798925, acc 0.65625
2020-02-08T02:01:19.063677: step 195, loss 0.797285, acc 0.640625
2020-02-08T02:01:19.248847: step 196, loss 1.22654, acc 0.515625
2020-02-08T02:01:19.418627: step 197, loss 0.965477, acc 0.59375
2020-02-08T02:01:19.597136: step 198, loss 1.05092, acc 0.609375
2020-02-08T02:01:19.783439: step 199, loss 1.05078, acc 0.53125
2020-02-08T02:01:19.962476: step 200, loss 0.780724, acc 0.671875

Evaluation:
2020-02-08T02:01:20.287753: step 200, loss 0.675262, acc 0.599437

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-200

2020-02-08T02:01:21.833971: step 201, loss 1.06485, acc 0.5
2020-02-08T02:01:22.054647: step 202, loss 0.742343, acc 0.734375
2020-02-08T02:01:22.240845: step 203, loss 0.967092, acc 0.65625
2020-02-08T02:01:22.413993: step 204, loss 1.19529, acc 0.53125
2020-02-08T02:01:22.596382: step 205, loss 0.943431, acc 0.609375
2020-02-08T02:01:22.779253: step 206, loss 1.00123, acc 0.5625
2020-02-08T02:01:22.951370: step 207, loss 0.96018, acc 0.578125
2020-02-08T02:01:23.120775: step 208, loss 0.755399, acc 0.625
2020-02-08T02:01:23.304664: step 209, loss 0.870066, acc 0.65625
2020-02-08T02:01:23.481931: step 210, loss 1.13236, acc 0.515625
2020-02-08T02:01:23.660751: step 211, loss 1.11975, acc 0.59375
2020-02-08T02:01:23.836171: step 212, loss 0.889327, acc 0.703125
2020-02-08T02:01:24.005946: step 213, loss 0.809211, acc 0.65625
2020-02-08T02:01:24.188535: step 214, loss 1.05178, acc 0.453125
2020-02-08T02:01:24.366274: step 215, loss 0.871928, acc 0.65625
2020-02-08T02:01:24.545193: step 216, loss 0.955433, acc 0.5625
2020-02-08T02:01:24.727349: step 217, loss 0.851681, acc 0.640625
2020-02-08T02:01:24.914405: step 218, loss 0.85411, acc 0.671875
2020-02-08T02:01:25.091622: step 219, loss 1.02016, acc 0.578125
2020-02-08T02:01:25.265747: step 220, loss 0.630744, acc 0.6875
2020-02-08T02:01:25.436809: step 221, loss 0.676575, acc 0.703125
2020-02-08T02:01:25.602510: step 222, loss 0.96058, acc 0.6875
2020-02-08T02:01:25.787867: step 223, loss 0.693703, acc 0.65625
2020-02-08T02:01:25.966327: step 224, loss 0.756162, acc 0.65625
2020-02-08T02:01:26.142931: step 225, loss 1.15663, acc 0.546875
2020-02-08T02:01:26.319168: step 226, loss 1.04572, acc 0.53125
2020-02-08T02:01:26.492982: step 227, loss 0.801807, acc 0.625
2020-02-08T02:01:26.671007: step 228, loss 0.888372, acc 0.609375
2020-02-08T02:01:26.842544: step 229, loss 1.04016, acc 0.578125
2020-02-08T02:01:27.019440: step 230, loss 0.815486, acc 0.65625
2020-02-08T02:01:27.197531: step 231, loss 0.99431, acc 0.5625
2020-02-08T02:01:27.374302: step 232, loss 0.886167, acc 0.578125
2020-02-08T02:01:27.557978: step 233, loss 0.709979, acc 0.65625
2020-02-08T02:01:27.742470: step 234, loss 0.968459, acc 0.5
2020-02-08T02:01:27.922690: step 235, loss 1.17097, acc 0.515625
2020-02-08T02:01:28.216068: step 236, loss 0.933556, acc 0.578125
2020-02-08T02:01:28.389311: step 237, loss 1.02071, acc 0.46875
2020-02-08T02:01:28.572066: step 238, loss 0.89678, acc 0.59375
2020-02-08T02:01:28.749947: step 239, loss 0.813592, acc 0.578125
2020-02-08T02:01:28.938101: step 240, loss 1.15695, acc 0.546875
2020-02-08T02:01:29.127779: step 241, loss 0.791045, acc 0.65625
2020-02-08T02:01:29.315262: step 242, loss 0.928677, acc 0.609375
2020-02-08T02:01:29.497072: step 243, loss 1.08756, acc 0.546875
2020-02-08T02:01:29.689770: step 244, loss 0.912853, acc 0.5
2020-02-08T02:01:29.933885: step 245, loss 0.66394, acc 0.59375
2020-02-08T02:01:30.130451: step 246, loss 1.0153, acc 0.578125
2020-02-08T02:01:30.326629: step 247, loss 0.842855, acc 0.625
2020-02-08T02:01:30.485295: step 248, loss 0.989285, acc 0.5
2020-02-08T02:01:30.690733: step 249, loss 1.06543, acc 0.578125
2020-02-08T02:01:30.870002: step 250, loss 0.982417, acc 0.609375
2020-02-08T02:01:31.052808: step 251, loss 0.913447, acc 0.609375
2020-02-08T02:01:31.235238: step 252, loss 0.813774, acc 0.609375
2020-02-08T02:01:31.405308: step 253, loss 0.991039, acc 0.546875
2020-02-08T02:01:31.591687: step 254, loss 0.753357, acc 0.65625
2020-02-08T02:01:31.795830: step 255, loss 0.887969, acc 0.5625
2020-02-08T02:01:31.988276: step 256, loss 0.747252, acc 0.640625
2020-02-08T02:01:32.194871: step 257, loss 0.824504, acc 0.609375
2020-02-08T02:01:32.398015: step 258, loss 0.801279, acc 0.65625
2020-02-08T02:01:32.585608: step 259, loss 0.749265, acc 0.671875
2020-02-08T02:01:32.770079: step 260, loss 0.946258, acc 0.609375
2020-02-08T02:01:32.955568: step 261, loss 0.878521, acc 0.609375
2020-02-08T02:01:33.137004: step 262, loss 0.645312, acc 0.6875
2020-02-08T02:01:33.312150: step 263, loss 0.773716, acc 0.65625
2020-02-08T02:01:33.496621: step 264, loss 0.987675, acc 0.546875
2020-02-08T02:01:33.694472: step 265, loss 0.58479, acc 0.640625
2020-02-08T02:01:33.876720: step 266, loss 0.816381, acc 0.625
2020-02-08T02:01:34.055877: step 267, loss 0.775242, acc 0.671875
2020-02-08T02:01:34.239381: step 268, loss 1.13797, acc 0.53125
2020-02-08T02:01:34.404660: step 269, loss 1.20962, acc 0.5625
2020-02-08T02:01:34.588092: step 270, loss 0.896887, acc 0.59375
2020-02-08T02:01:34.788015: step 271, loss 0.773378, acc 0.640625
2020-02-08T02:01:34.970474: step 272, loss 0.842673, acc 0.546875
2020-02-08T02:01:35.154293: step 273, loss 0.931525, acc 0.5625
2020-02-08T02:01:35.329522: step 274, loss 1.04549, acc 0.578125
2020-02-08T02:01:35.513981: step 275, loss 0.958518, acc 0.59375
2020-02-08T02:01:35.710858: step 276, loss 0.934879, acc 0.46875
2020-02-08T02:01:35.903365: step 277, loss 0.784618, acc 0.6875
2020-02-08T02:01:36.087528: step 278, loss 0.878507, acc 0.53125
2020-02-08T02:01:36.261697: step 279, loss 0.927079, acc 0.671875
2020-02-08T02:01:36.436928: step 280, loss 0.952203, acc 0.578125
2020-02-08T02:01:36.624270: step 281, loss 0.800084, acc 0.671875
2020-02-08T02:01:36.810297: step 282, loss 0.899414, acc 0.578125
2020-02-08T02:01:36.996707: step 283, loss 0.73594, acc 0.578125
2020-02-08T02:01:37.180837: step 284, loss 1.16488, acc 0.4375
2020-02-08T02:01:37.356179: step 285, loss 0.782385, acc 0.640625
2020-02-08T02:01:37.551476: step 286, loss 0.6893, acc 0.609375
2020-02-08T02:01:37.743237: step 287, loss 0.831379, acc 0.640625
2020-02-08T02:01:37.917277: step 288, loss 0.854177, acc 0.625
2020-02-08T02:01:38.105838: step 289, loss 0.678837, acc 0.734375
2020-02-08T02:01:38.293793: step 290, loss 0.804805, acc 0.640625
2020-02-08T02:01:38.477917: step 291, loss 0.966775, acc 0.609375
2020-02-08T02:01:38.658436: step 292, loss 0.726903, acc 0.640625
2020-02-08T02:01:38.835438: step 293, loss 0.850544, acc 0.5625
2020-02-08T02:01:39.031166: step 294, loss 0.610185, acc 0.75
2020-02-08T02:01:39.226767: step 295, loss 0.812361, acc 0.671875
2020-02-08T02:01:39.396786: step 296, loss 1.00014, acc 0.515625
2020-02-08T02:01:39.590020: step 297, loss 0.74254, acc 0.6875
2020-02-08T02:01:39.792989: step 298, loss 0.574909, acc 0.703125
2020-02-08T02:01:39.995141: step 299, loss 0.844935, acc 0.59375
2020-02-08T02:01:40.183304: step 300, loss 0.733549, acc 0.616667

Evaluation:
2020-02-08T02:01:40.535450: step 300, loss 0.634622, acc 0.652908

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-300

2020-02-08T02:01:42.146100: step 301, loss 0.807802, acc 0.625
2020-02-08T02:01:42.329648: step 302, loss 0.664919, acc 0.640625
2020-02-08T02:01:42.530502: step 303, loss 0.662315, acc 0.671875
2020-02-08T02:01:42.727445: step 304, loss 0.733577, acc 0.625
2020-02-08T02:01:42.906595: step 305, loss 1.02672, acc 0.5
2020-02-08T02:01:43.111049: step 306, loss 0.693248, acc 0.703125
2020-02-08T02:01:43.348938: step 307, loss 0.646857, acc 0.6875
2020-02-08T02:01:43.546328: step 308, loss 0.734039, acc 0.671875
2020-02-08T02:01:43.796746: step 309, loss 0.691494, acc 0.703125
2020-02-08T02:01:44.034430: step 310, loss 0.561168, acc 0.71875
2020-02-08T02:01:44.265882: step 311, loss 0.681063, acc 0.578125
2020-02-08T02:01:44.481343: step 312, loss 0.708039, acc 0.671875
2020-02-08T02:01:44.654308: step 313, loss 0.604038, acc 0.703125
2020-02-08T02:01:44.847903: step 314, loss 0.690859, acc 0.625
2020-02-08T02:01:45.083152: step 315, loss 0.608362, acc 0.75
2020-02-08T02:01:45.263425: step 316, loss 0.594669, acc 0.625
2020-02-08T02:01:45.458935: step 317, loss 0.646664, acc 0.671875
2020-02-08T02:01:45.694888: step 318, loss 0.623608, acc 0.65625
2020-02-08T02:01:45.884123: step 319, loss 0.616819, acc 0.703125
2020-02-08T02:01:46.053533: step 320, loss 0.868433, acc 0.609375
2020-02-08T02:01:46.232044: step 321, loss 0.724872, acc 0.640625
2020-02-08T02:01:46.400779: step 322, loss 0.710307, acc 0.671875
2020-02-08T02:01:46.583212: step 323, loss 0.634904, acc 0.6875
2020-02-08T02:01:46.768709: step 324, loss 0.592981, acc 0.703125
2020-02-08T02:01:46.952335: step 325, loss 0.735356, acc 0.59375
2020-02-08T02:01:47.139040: step 326, loss 0.538696, acc 0.734375
2020-02-08T02:01:47.317434: step 327, loss 0.618104, acc 0.671875
2020-02-08T02:01:47.503005: step 328, loss 0.540507, acc 0.734375
2020-02-08T02:01:47.687357: step 329, loss 0.922368, acc 0.546875
2020-02-08T02:01:47.877256: step 330, loss 0.715351, acc 0.625
2020-02-08T02:01:48.060707: step 331, loss 0.571364, acc 0.71875
2020-02-08T02:01:48.253683: step 332, loss 0.823812, acc 0.578125
2020-02-08T02:01:48.442653: step 333, loss 0.621712, acc 0.609375
2020-02-08T02:01:48.633871: step 334, loss 0.654626, acc 0.703125
2020-02-08T02:01:48.832218: step 335, loss 0.63756, acc 0.734375
2020-02-08T02:01:49.030999: step 336, loss 0.758933, acc 0.640625
2020-02-08T02:01:49.233877: step 337, loss 0.857424, acc 0.609375
2020-02-08T02:01:49.417094: step 338, loss 0.813908, acc 0.5625
2020-02-08T02:01:49.599052: step 339, loss 0.67369, acc 0.6875
2020-02-08T02:01:49.795880: step 340, loss 0.510262, acc 0.75
2020-02-08T02:01:49.990120: step 341, loss 0.778599, acc 0.6875
2020-02-08T02:01:50.182922: step 342, loss 0.602671, acc 0.65625
2020-02-08T02:01:50.384830: step 343, loss 0.879551, acc 0.625
2020-02-08T02:01:50.572551: step 344, loss 0.70999, acc 0.671875
2020-02-08T02:01:50.778165: step 345, loss 0.749413, acc 0.6875
2020-02-08T02:01:50.970050: step 346, loss 0.706199, acc 0.5625
2020-02-08T02:01:51.157279: step 347, loss 0.59314, acc 0.703125
2020-02-08T02:01:51.345541: step 348, loss 0.679601, acc 0.5625
2020-02-08T02:01:51.704509: step 349, loss 0.69962, acc 0.65625
2020-02-08T02:01:51.911855: step 350, loss 0.744356, acc 0.578125
2020-02-08T02:01:52.105352: step 351, loss 0.598053, acc 0.671875
2020-02-08T02:01:52.293165: step 352, loss 0.646845, acc 0.6875
2020-02-08T02:01:52.469572: step 353, loss 0.637998, acc 0.671875
2020-02-08T02:01:52.664469: step 354, loss 0.712052, acc 0.65625
2020-02-08T02:01:52.845465: step 355, loss 0.529775, acc 0.734375
2020-02-08T02:01:53.029177: step 356, loss 0.689321, acc 0.671875
2020-02-08T02:01:53.217162: step 357, loss 0.888296, acc 0.578125
2020-02-08T02:01:53.402718: step 358, loss 0.539091, acc 0.796875
2020-02-08T02:01:53.586746: step 359, loss 0.627077, acc 0.640625
2020-02-08T02:01:53.784408: step 360, loss 0.601115, acc 0.640625
2020-02-08T02:01:53.969487: step 361, loss 0.628987, acc 0.6875
2020-02-08T02:01:54.148686: step 362, loss 0.6533, acc 0.640625
2020-02-08T02:01:54.330109: step 363, loss 0.653343, acc 0.703125
2020-02-08T02:01:54.512237: step 364, loss 0.677828, acc 0.6875
2020-02-08T02:01:54.693216: step 365, loss 0.563819, acc 0.75
2020-02-08T02:01:54.863106: step 366, loss 0.719398, acc 0.609375
2020-02-08T02:01:55.058042: step 367, loss 0.585169, acc 0.703125
2020-02-08T02:01:55.236167: step 368, loss 0.625952, acc 0.671875
2020-02-08T02:01:55.421039: step 369, loss 0.75095, acc 0.65625
2020-02-08T02:01:55.605123: step 370, loss 0.674142, acc 0.6875
2020-02-08T02:01:55.795867: step 371, loss 0.662509, acc 0.6875
2020-02-08T02:01:55.982887: step 372, loss 0.553636, acc 0.65625
2020-02-08T02:01:56.172431: step 373, loss 0.582161, acc 0.734375
2020-02-08T02:01:56.354317: step 374, loss 0.711134, acc 0.671875
2020-02-08T02:01:56.540947: step 375, loss 0.670945, acc 0.671875
2020-02-08T02:01:56.724917: step 376, loss 0.633246, acc 0.734375
2020-02-08T02:01:56.912064: step 377, loss 0.763509, acc 0.578125
2020-02-08T02:01:57.099008: step 378, loss 0.774731, acc 0.625
2020-02-08T02:01:57.265212: step 379, loss 0.516369, acc 0.71875
2020-02-08T02:01:57.445199: step 380, loss 0.475659, acc 0.796875
2020-02-08T02:01:57.627988: step 381, loss 0.699845, acc 0.609375
2020-02-08T02:01:57.804187: step 382, loss 0.612718, acc 0.65625
2020-02-08T02:01:57.996639: step 383, loss 0.562248, acc 0.65625
2020-02-08T02:01:58.163736: step 384, loss 0.758741, acc 0.625
2020-02-08T02:01:58.348555: step 385, loss 0.487034, acc 0.75
2020-02-08T02:01:58.536118: step 386, loss 0.726633, acc 0.625
2020-02-08T02:01:58.742680: step 387, loss 0.566792, acc 0.78125
2020-02-08T02:01:58.939997: step 388, loss 0.622006, acc 0.640625
2020-02-08T02:01:59.148699: step 389, loss 0.675534, acc 0.625
2020-02-08T02:01:59.335572: step 390, loss 0.686568, acc 0.625
2020-02-08T02:01:59.522529: step 391, loss 0.649467, acc 0.65625
2020-02-08T02:01:59.721193: step 392, loss 0.728459, acc 0.609375
2020-02-08T02:01:59.899080: step 393, loss 0.639864, acc 0.625
2020-02-08T02:02:00.071918: step 394, loss 0.511456, acc 0.703125
2020-02-08T02:02:00.246954: step 395, loss 0.672565, acc 0.640625
2020-02-08T02:02:00.414844: step 396, loss 0.65894, acc 0.671875
2020-02-08T02:02:00.585937: step 397, loss 0.674182, acc 0.703125
2020-02-08T02:02:00.775146: step 398, loss 0.719381, acc 0.609375
2020-02-08T02:02:00.971685: step 399, loss 0.635625, acc 0.640625
2020-02-08T02:02:01.158886: step 400, loss 0.665253, acc 0.703125

Evaluation:
2020-02-08T02:02:01.514887: step 400, loss 0.634036, acc 0.640713

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-400

2020-02-08T02:02:03.125468: step 401, loss 0.604407, acc 0.71875
2020-02-08T02:02:03.326697: step 402, loss 0.781532, acc 0.515625
2020-02-08T02:02:03.530514: step 403, loss 0.71088, acc 0.65625
2020-02-08T02:02:03.745734: step 404, loss 0.592571, acc 0.703125
2020-02-08T02:02:03.926928: step 405, loss 0.737918, acc 0.640625
2020-02-08T02:02:04.109305: step 406, loss 0.584213, acc 0.65625
2020-02-08T02:02:04.299199: step 407, loss 0.607554, acc 0.671875
2020-02-08T02:02:04.503483: step 408, loss 0.772814, acc 0.609375
2020-02-08T02:02:04.710002: step 409, loss 0.710643, acc 0.609375
2020-02-08T02:02:04.894346: step 410, loss 0.655601, acc 0.703125
2020-02-08T02:02:05.072438: step 411, loss 0.717865, acc 0.65625
2020-02-08T02:02:05.255242: step 412, loss 0.611773, acc 0.703125
2020-02-08T02:02:05.440156: step 413, loss 0.57492, acc 0.6875
2020-02-08T02:02:05.636787: step 414, loss 0.619095, acc 0.734375
2020-02-08T02:02:05.821118: step 415, loss 0.487601, acc 0.765625
2020-02-08T02:02:06.012056: step 416, loss 0.562353, acc 0.6875
2020-02-08T02:02:06.202213: step 417, loss 0.389485, acc 0.859375
2020-02-08T02:02:06.380537: step 418, loss 0.594439, acc 0.734375
2020-02-08T02:02:06.584746: step 419, loss 0.552813, acc 0.71875
2020-02-08T02:02:06.787344: step 420, loss 0.636539, acc 0.609375
2020-02-08T02:02:06.979641: step 421, loss 0.678997, acc 0.609375
2020-02-08T02:02:07.162317: step 422, loss 0.611526, acc 0.6875
2020-02-08T02:02:07.356058: step 423, loss 0.690348, acc 0.65625
2020-02-08T02:02:07.538686: step 424, loss 0.699758, acc 0.71875
2020-02-08T02:02:07.745968: step 425, loss 0.597749, acc 0.703125
2020-02-08T02:02:07.936871: step 426, loss 0.595957, acc 0.765625
2020-02-08T02:02:08.118625: step 427, loss 0.659647, acc 0.65625
2020-02-08T02:02:08.306846: step 428, loss 0.672274, acc 0.734375
2020-02-08T02:02:08.502453: step 429, loss 0.608303, acc 0.703125
2020-02-08T02:02:08.712312: step 430, loss 0.584241, acc 0.734375
2020-02-08T02:02:08.907489: step 431, loss 0.735859, acc 0.59375
2020-02-08T02:02:09.122260: step 432, loss 0.714559, acc 0.546875
2020-02-08T02:02:09.313134: step 433, loss 0.612373, acc 0.71875
2020-02-08T02:02:09.506618: step 434, loss 0.682243, acc 0.609375
2020-02-08T02:02:09.691805: step 435, loss 0.634409, acc 0.671875
2020-02-08T02:02:09.904594: step 436, loss 0.569751, acc 0.671875
2020-02-08T02:02:10.091247: step 437, loss 0.721461, acc 0.578125
2020-02-08T02:02:10.278128: step 438, loss 0.77925, acc 0.609375
2020-02-08T02:02:10.469715: step 439, loss 0.714561, acc 0.609375
2020-02-08T02:02:10.658123: step 440, loss 0.675443, acc 0.609375
2020-02-08T02:02:10.846353: step 441, loss 0.589265, acc 0.671875
2020-02-08T02:02:11.042205: step 442, loss 0.595205, acc 0.6875
2020-02-08T02:02:11.237300: step 443, loss 0.668834, acc 0.671875
2020-02-08T02:02:11.414018: step 444, loss 0.723681, acc 0.59375
2020-02-08T02:02:11.600913: step 445, loss 0.540324, acc 0.640625
2020-02-08T02:02:11.812586: step 446, loss 0.568177, acc 0.71875
2020-02-08T02:02:11.998642: step 447, loss 0.510878, acc 0.734375
2020-02-08T02:02:12.206702: step 448, loss 0.564586, acc 0.640625
2020-02-08T02:02:12.399294: step 449, loss 0.611339, acc 0.6875
2020-02-08T02:02:12.589155: step 450, loss 0.571966, acc 0.7
2020-02-08T02:02:12.785133: step 451, loss 0.756409, acc 0.65625
2020-02-08T02:02:12.985383: step 452, loss 0.57668, acc 0.703125
2020-02-08T02:02:13.182567: step 453, loss 0.606717, acc 0.734375
2020-02-08T02:02:13.366187: step 454, loss 0.602078, acc 0.703125
2020-02-08T02:02:13.576314: step 455, loss 0.512283, acc 0.765625
2020-02-08T02:02:13.794643: step 456, loss 0.553307, acc 0.765625
2020-02-08T02:02:13.986923: step 457, loss 0.544773, acc 0.71875
2020-02-08T02:02:14.173123: step 458, loss 0.4889, acc 0.765625
2020-02-08T02:02:14.355452: step 459, loss 0.535252, acc 0.75
2020-02-08T02:02:14.542438: step 460, loss 0.526825, acc 0.71875
2020-02-08T02:02:14.729906: step 461, loss 0.544037, acc 0.71875
2020-02-08T02:02:14.906144: step 462, loss 0.477416, acc 0.765625
2020-02-08T02:02:15.091500: step 463, loss 0.579775, acc 0.6875
2020-02-08T02:02:15.280954: step 464, loss 0.580029, acc 0.640625
2020-02-08T02:02:15.479836: step 465, loss 0.521122, acc 0.734375
2020-02-08T02:02:15.671944: step 466, loss 0.522366, acc 0.78125
2020-02-08T02:02:15.859252: step 467, loss 0.460684, acc 0.78125
2020-02-08T02:02:16.044914: step 468, loss 0.55188, acc 0.703125
2020-02-08T02:02:16.228117: step 469, loss 0.659813, acc 0.703125
2020-02-08T02:02:16.407447: step 470, loss 0.407681, acc 0.84375
2020-02-08T02:02:16.592227: step 471, loss 0.461059, acc 0.765625
2020-02-08T02:02:16.770716: step 472, loss 0.581878, acc 0.703125
2020-02-08T02:02:16.959682: step 473, loss 0.561629, acc 0.734375
2020-02-08T02:02:17.151540: step 474, loss 0.50231, acc 0.734375
2020-02-08T02:02:17.343186: step 475, loss 0.652442, acc 0.703125
2020-02-08T02:02:17.530497: step 476, loss 0.555962, acc 0.6875
2020-02-08T02:02:17.713705: step 477, loss 0.569213, acc 0.734375
2020-02-08T02:02:17.900912: step 478, loss 0.491866, acc 0.703125
2020-02-08T02:02:18.083890: step 479, loss 0.50427, acc 0.765625
2020-02-08T02:02:18.277898: step 480, loss 0.485753, acc 0.6875
2020-02-08T02:02:18.453226: step 481, loss 0.412167, acc 0.875
2020-02-08T02:02:18.658133: step 482, loss 0.561303, acc 0.703125
2020-02-08T02:02:18.846833: step 483, loss 0.526221, acc 0.765625
2020-02-08T02:02:19.025268: step 484, loss 0.753782, acc 0.578125
2020-02-08T02:02:19.230323: step 485, loss 0.556865, acc 0.765625
2020-02-08T02:02:19.427895: step 486, loss 0.646671, acc 0.640625
2020-02-08T02:02:19.646777: step 487, loss 0.554447, acc 0.6875
2020-02-08T02:02:19.964120: step 488, loss 0.580913, acc 0.75
2020-02-08T02:02:20.147116: step 489, loss 0.444449, acc 0.78125
2020-02-08T02:02:20.345974: step 490, loss 0.678128, acc 0.59375
2020-02-08T02:02:20.531023: step 491, loss 0.454836, acc 0.8125
2020-02-08T02:02:20.731499: step 492, loss 0.777305, acc 0.5625
2020-02-08T02:02:20.912134: step 493, loss 0.492843, acc 0.8125
2020-02-08T02:02:21.102942: step 494, loss 0.588877, acc 0.671875
2020-02-08T02:02:21.293968: step 495, loss 0.5817, acc 0.6875
2020-02-08T02:02:21.495604: step 496, loss 0.557272, acc 0.765625
2020-02-08T02:02:21.719386: step 497, loss 0.543208, acc 0.765625
2020-02-08T02:02:21.911988: step 498, loss 0.675724, acc 0.609375
2020-02-08T02:02:22.102231: step 499, loss 0.644564, acc 0.65625
2020-02-08T02:02:22.294722: step 500, loss 0.566746, acc 0.734375

Evaluation:
2020-02-08T02:02:22.634195: step 500, loss 0.615872, acc 0.655722

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-500

2020-02-08T02:02:24.233750: step 501, loss 0.662818, acc 0.6875
2020-02-08T02:02:24.418037: step 502, loss 0.563304, acc 0.6875
2020-02-08T02:02:24.599454: step 503, loss 0.515638, acc 0.765625
2020-02-08T02:02:24.813887: step 504, loss 0.518098, acc 0.734375
2020-02-08T02:02:24.995827: step 505, loss 0.622223, acc 0.640625
2020-02-08T02:02:25.194730: step 506, loss 0.579408, acc 0.75
2020-02-08T02:02:25.377328: step 507, loss 0.438517, acc 0.796875
2020-02-08T02:02:25.556536: step 508, loss 0.597493, acc 0.703125
2020-02-08T02:02:25.743334: step 509, loss 0.481923, acc 0.765625
2020-02-08T02:02:25.916191: step 510, loss 0.645177, acc 0.65625
2020-02-08T02:02:26.098740: step 511, loss 0.539302, acc 0.671875
2020-02-08T02:02:26.283999: step 512, loss 0.546205, acc 0.703125
2020-02-08T02:02:26.462579: step 513, loss 0.560597, acc 0.765625
2020-02-08T02:02:26.649106: step 514, loss 0.574526, acc 0.71875
2020-02-08T02:02:26.833750: step 515, loss 0.548806, acc 0.75
2020-02-08T02:02:27.018634: step 516, loss 0.485702, acc 0.734375
2020-02-08T02:02:27.190262: step 517, loss 0.576968, acc 0.6875
2020-02-08T02:02:27.372270: step 518, loss 0.43214, acc 0.8125
2020-02-08T02:02:27.554789: step 519, loss 0.651578, acc 0.671875
2020-02-08T02:02:27.754377: step 520, loss 0.58708, acc 0.65625
2020-02-08T02:02:27.936709: step 521, loss 0.65423, acc 0.703125
2020-02-08T02:02:28.114270: step 522, loss 0.623178, acc 0.6875
2020-02-08T02:02:28.299834: step 523, loss 0.491457, acc 0.765625
2020-02-08T02:02:28.484071: step 524, loss 0.471183, acc 0.84375
2020-02-08T02:02:28.658030: step 525, loss 0.578363, acc 0.6875
2020-02-08T02:02:28.836896: step 526, loss 0.45356, acc 0.78125
2020-02-08T02:02:29.015567: step 527, loss 0.521024, acc 0.75
2020-02-08T02:02:29.214899: step 528, loss 0.6594, acc 0.6875
2020-02-08T02:02:29.391305: step 529, loss 0.573932, acc 0.703125
2020-02-08T02:02:29.582160: step 530, loss 0.564292, acc 0.734375
2020-02-08T02:02:29.783827: step 531, loss 0.747184, acc 0.671875
2020-02-08T02:02:29.967503: step 532, loss 0.535143, acc 0.796875
2020-02-08T02:02:30.159641: step 533, loss 0.608027, acc 0.671875
2020-02-08T02:02:30.352722: step 534, loss 0.475357, acc 0.78125
2020-02-08T02:02:30.548795: step 535, loss 0.512059, acc 0.828125
2020-02-08T02:02:30.744697: step 536, loss 0.70213, acc 0.65625
2020-02-08T02:02:30.924788: step 537, loss 0.440728, acc 0.859375
2020-02-08T02:02:31.123269: step 538, loss 0.595787, acc 0.703125
2020-02-08T02:02:31.314724: step 539, loss 0.56533, acc 0.6875
2020-02-08T02:02:31.492015: step 540, loss 0.552094, acc 0.703125
2020-02-08T02:02:31.684462: step 541, loss 0.410604, acc 0.8125
2020-02-08T02:02:31.870653: step 542, loss 0.569884, acc 0.75
2020-02-08T02:02:32.051949: step 543, loss 0.642724, acc 0.65625
2020-02-08T02:02:32.237717: step 544, loss 0.569169, acc 0.75
2020-02-08T02:02:32.421267: step 545, loss 0.492889, acc 0.765625
2020-02-08T02:02:32.605914: step 546, loss 0.50559, acc 0.8125
2020-02-08T02:02:32.802536: step 547, loss 0.615874, acc 0.671875
2020-02-08T02:02:32.999733: step 548, loss 0.47097, acc 0.796875
2020-02-08T02:02:33.193005: step 549, loss 0.520167, acc 0.71875
2020-02-08T02:02:33.385822: step 550, loss 0.573094, acc 0.671875
2020-02-08T02:02:33.565813: step 551, loss 0.574632, acc 0.734375
2020-02-08T02:02:33.769878: step 552, loss 0.503893, acc 0.75
2020-02-08T02:02:33.963397: step 553, loss 0.739794, acc 0.578125
2020-02-08T02:02:34.151552: step 554, loss 0.517739, acc 0.75
2020-02-08T02:02:34.339692: step 555, loss 0.602755, acc 0.734375
2020-02-08T02:02:34.528075: step 556, loss 0.54705, acc 0.75
2020-02-08T02:02:34.756634: step 557, loss 0.539568, acc 0.75
2020-02-08T02:02:34.949047: step 558, loss 0.48936, acc 0.78125
2020-02-08T02:02:35.143767: step 559, loss 0.58909, acc 0.734375
2020-02-08T02:02:35.336671: step 560, loss 0.479744, acc 0.734375
2020-02-08T02:02:35.534156: step 561, loss 0.491133, acc 0.75
2020-02-08T02:02:35.719349: step 562, loss 0.474489, acc 0.78125
2020-02-08T02:02:35.900404: step 563, loss 0.503626, acc 0.765625
2020-02-08T02:02:36.073490: step 564, loss 0.569914, acc 0.75
2020-02-08T02:02:36.258846: step 565, loss 0.58966, acc 0.71875
2020-02-08T02:02:36.640331: step 566, loss 0.505357, acc 0.78125
2020-02-08T02:02:36.926990: step 567, loss 0.588986, acc 0.671875
2020-02-08T02:02:37.218963: step 568, loss 0.562219, acc 0.6875
2020-02-08T02:02:37.457811: step 569, loss 0.491254, acc 0.734375
2020-02-08T02:02:37.676597: step 570, loss 0.421719, acc 0.8125
2020-02-08T02:02:37.852314: step 571, loss 0.594516, acc 0.671875
2020-02-08T02:02:38.043648: step 572, loss 0.728118, acc 0.625
2020-02-08T02:02:38.252447: step 573, loss 0.63152, acc 0.65625
2020-02-08T02:02:38.441988: step 574, loss 0.547334, acc 0.78125
2020-02-08T02:02:38.646508: step 575, loss 0.460418, acc 0.78125
2020-02-08T02:02:38.861569: step 576, loss 0.589136, acc 0.703125
2020-02-08T02:02:39.089203: step 577, loss 0.566214, acc 0.71875
2020-02-08T02:02:39.295171: step 578, loss 0.509399, acc 0.75
2020-02-08T02:02:39.493327: step 579, loss 0.56343, acc 0.703125
2020-02-08T02:02:39.711350: step 580, loss 0.639279, acc 0.640625
2020-02-08T02:02:39.905529: step 581, loss 0.49719, acc 0.71875
2020-02-08T02:02:40.096844: step 582, loss 0.622797, acc 0.6875
2020-02-08T02:02:40.322064: step 583, loss 0.570581, acc 0.71875
2020-02-08T02:02:40.521195: step 584, loss 0.465819, acc 0.734375
2020-02-08T02:02:40.722430: step 585, loss 0.558394, acc 0.703125
2020-02-08T02:02:40.940151: step 586, loss 0.551544, acc 0.71875
2020-02-08T02:02:41.141444: step 587, loss 0.482457, acc 0.734375
2020-02-08T02:02:41.339076: step 588, loss 0.544471, acc 0.765625
2020-02-08T02:02:41.537722: step 589, loss 0.576227, acc 0.734375
2020-02-08T02:02:41.758896: step 590, loss 0.522223, acc 0.6875
2020-02-08T02:02:41.951220: step 591, loss 0.713742, acc 0.609375
2020-02-08T02:02:42.138606: step 592, loss 0.562058, acc 0.703125
2020-02-08T02:02:42.338534: step 593, loss 0.489609, acc 0.796875
2020-02-08T02:02:42.531228: step 594, loss 0.494243, acc 0.78125
2020-02-08T02:02:42.742107: step 595, loss 0.574986, acc 0.734375
2020-02-08T02:02:42.932463: step 596, loss 0.618095, acc 0.65625
2020-02-08T02:02:43.131931: step 597, loss 0.423214, acc 0.8125
2020-02-08T02:02:43.326086: step 598, loss 0.44793, acc 0.75
2020-02-08T02:02:43.508307: step 599, loss 0.687057, acc 0.59375
2020-02-08T02:02:43.713263: step 600, loss 0.464277, acc 0.783333

Evaluation:
2020-02-08T02:02:44.065904: step 600, loss 0.647107, acc 0.625704

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-600

2020-02-08T02:02:45.643358: step 601, loss 0.499085, acc 0.796875
2020-02-08T02:02:45.851491: step 602, loss 0.570093, acc 0.703125
2020-02-08T02:02:46.041183: step 603, loss 0.525437, acc 0.78125
2020-02-08T02:02:46.203846: step 604, loss 0.492531, acc 0.796875
2020-02-08T02:02:46.392836: step 605, loss 0.524857, acc 0.703125
2020-02-08T02:02:46.578760: step 606, loss 0.486128, acc 0.734375
2020-02-08T02:02:46.762335: step 607, loss 0.5625, acc 0.71875
2020-02-08T02:02:46.957813: step 608, loss 0.550687, acc 0.734375
2020-02-08T02:02:47.150721: step 609, loss 0.576884, acc 0.6875
2020-02-08T02:02:47.343372: step 610, loss 0.454203, acc 0.765625
2020-02-08T02:02:47.538950: step 611, loss 0.635867, acc 0.71875
2020-02-08T02:02:47.737284: step 612, loss 0.440971, acc 0.84375
2020-02-08T02:02:47.942953: step 613, loss 0.495908, acc 0.78125
2020-02-08T02:02:48.129165: step 614, loss 0.512909, acc 0.75
2020-02-08T02:02:48.329764: step 615, loss 0.528986, acc 0.78125
2020-02-08T02:02:48.528980: step 616, loss 0.480494, acc 0.78125
2020-02-08T02:02:48.728079: step 617, loss 0.554382, acc 0.703125
2020-02-08T02:02:48.917029: step 618, loss 0.486063, acc 0.765625
2020-02-08T02:02:49.123089: step 619, loss 0.396206, acc 0.8125
2020-02-08T02:02:49.317885: step 620, loss 0.429366, acc 0.84375
2020-02-08T02:02:49.501025: step 621, loss 0.505197, acc 0.765625
2020-02-08T02:02:49.710637: step 622, loss 0.505793, acc 0.734375
2020-02-08T02:02:49.909446: step 623, loss 0.508332, acc 0.734375
2020-02-08T02:02:50.142687: step 624, loss 0.534528, acc 0.71875
2020-02-08T02:02:50.347803: step 625, loss 0.494046, acc 0.71875
2020-02-08T02:02:50.559841: step 626, loss 0.480271, acc 0.734375
2020-02-08T02:02:50.752263: step 627, loss 0.508631, acc 0.703125
2020-02-08T02:02:50.952518: step 628, loss 0.525317, acc 0.796875
2020-02-08T02:02:51.142579: step 629, loss 0.453157, acc 0.796875
2020-02-08T02:02:51.348783: step 630, loss 0.377654, acc 0.84375
2020-02-08T02:02:51.595828: step 631, loss 0.568112, acc 0.71875
2020-02-08T02:02:51.794619: step 632, loss 0.586943, acc 0.734375
2020-02-08T02:02:51.994527: step 633, loss 0.457011, acc 0.8125
2020-02-08T02:02:52.224965: step 634, loss 0.52421, acc 0.78125
2020-02-08T02:02:52.435444: step 635, loss 0.534227, acc 0.71875
2020-02-08T02:02:52.631978: step 636, loss 0.52249, acc 0.765625
2020-02-08T02:02:52.846352: step 637, loss 0.595587, acc 0.71875
2020-02-08T02:02:53.079529: step 638, loss 0.487588, acc 0.765625
2020-02-08T02:02:53.327368: step 639, loss 0.465963, acc 0.75
2020-02-08T02:02:53.505611: step 640, loss 0.506599, acc 0.734375
2020-02-08T02:02:53.780368: step 641, loss 0.460104, acc 0.75
2020-02-08T02:02:53.999682: step 642, loss 0.616236, acc 0.703125
2020-02-08T02:02:54.197786: step 643, loss 0.564187, acc 0.671875
2020-02-08T02:02:54.412914: step 644, loss 0.581371, acc 0.703125
2020-02-08T02:02:54.646024: step 645, loss 0.539496, acc 0.71875
2020-02-08T02:02:54.851055: step 646, loss 0.350281, acc 0.875
2020-02-08T02:02:55.048259: step 647, loss 0.488823, acc 0.75
2020-02-08T02:02:55.253799: step 648, loss 0.465641, acc 0.734375
2020-02-08T02:02:55.529862: step 649, loss 0.437149, acc 0.8125
2020-02-08T02:02:55.764118: step 650, loss 0.411654, acc 0.78125
2020-02-08T02:02:55.967531: step 651, loss 0.550763, acc 0.703125
2020-02-08T02:02:56.180032: step 652, loss 0.536952, acc 0.78125
2020-02-08T02:02:56.405372: step 653, loss 0.529043, acc 0.78125
2020-02-08T02:02:56.651021: step 654, loss 0.434337, acc 0.78125
2020-02-08T02:02:56.879841: step 655, loss 0.466469, acc 0.765625
2020-02-08T02:02:57.083390: step 656, loss 0.464761, acc 0.75
2020-02-08T02:02:57.287443: step 657, loss 0.572819, acc 0.65625
2020-02-08T02:02:57.498709: step 658, loss 0.59976, acc 0.65625
2020-02-08T02:02:57.745206: step 659, loss 0.388579, acc 0.796875
2020-02-08T02:02:57.972965: step 660, loss 0.434077, acc 0.84375
2020-02-08T02:02:58.205585: step 661, loss 0.496381, acc 0.75
2020-02-08T02:02:58.437081: step 662, loss 0.478903, acc 0.71875
2020-02-08T02:02:58.669265: step 663, loss 0.570533, acc 0.65625
2020-02-08T02:02:58.856835: step 664, loss 0.521061, acc 0.71875
2020-02-08T02:02:59.056282: step 665, loss 0.613914, acc 0.71875
2020-02-08T02:02:59.261464: step 666, loss 0.543168, acc 0.734375
2020-02-08T02:02:59.452149: step 667, loss 0.484258, acc 0.75
2020-02-08T02:02:59.651047: step 668, loss 0.477528, acc 0.734375
2020-02-08T02:02:59.848390: step 669, loss 0.458228, acc 0.765625
2020-02-08T02:03:00.050890: step 670, loss 0.434967, acc 0.765625
2020-02-08T02:03:00.240281: step 671, loss 0.550984, acc 0.734375
2020-02-08T02:03:00.436766: step 672, loss 0.46168, acc 0.78125
2020-02-08T02:03:00.643074: step 673, loss 0.614826, acc 0.6875
2020-02-08T02:03:00.842179: step 674, loss 0.427085, acc 0.765625
2020-02-08T02:03:01.041751: step 675, loss 0.53813, acc 0.75
2020-02-08T02:03:01.238117: step 676, loss 0.568648, acc 0.671875
2020-02-08T02:03:01.429423: step 677, loss 0.527888, acc 0.71875
2020-02-08T02:03:01.637083: step 678, loss 0.405274, acc 0.8125
2020-02-08T02:03:01.830735: step 679, loss 0.601875, acc 0.671875
2020-02-08T02:03:02.039899: step 680, loss 0.420536, acc 0.8125
2020-02-08T02:03:02.238613: step 681, loss 0.462595, acc 0.765625
2020-02-08T02:03:02.425323: step 682, loss 0.43798, acc 0.78125
2020-02-08T02:03:02.623300: step 683, loss 0.512181, acc 0.75
2020-02-08T02:03:02.823887: step 684, loss 0.488889, acc 0.765625
2020-02-08T02:03:03.024918: step 685, loss 0.511748, acc 0.671875
2020-02-08T02:03:03.218713: step 686, loss 0.413502, acc 0.828125
2020-02-08T02:03:03.405545: step 687, loss 0.485708, acc 0.8125
2020-02-08T02:03:03.617322: step 688, loss 0.462472, acc 0.8125
2020-02-08T02:03:03.815386: step 689, loss 0.412538, acc 0.8125
2020-02-08T02:03:04.003576: step 690, loss 0.444034, acc 0.765625
2020-02-08T02:03:04.199570: step 691, loss 0.364073, acc 0.796875
2020-02-08T02:03:04.386282: step 692, loss 0.445452, acc 0.765625
2020-02-08T02:03:04.576633: step 693, loss 0.412936, acc 0.78125
2020-02-08T02:03:04.780450: step 694, loss 0.48644, acc 0.75
2020-02-08T02:03:04.969080: step 695, loss 0.444562, acc 0.75
2020-02-08T02:03:05.158465: step 696, loss 0.401751, acc 0.828125
2020-02-08T02:03:05.355080: step 697, loss 0.458825, acc 0.75
2020-02-08T02:03:05.536944: step 698, loss 0.410692, acc 0.796875
2020-02-08T02:03:05.731257: step 699, loss 0.540662, acc 0.734375
2020-02-08T02:03:05.928006: step 700, loss 0.451463, acc 0.8125

Evaluation:
2020-02-08T02:03:06.265405: step 700, loss 0.592646, acc 0.672608

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-700

2020-02-08T02:03:07.942577: step 701, loss 0.567216, acc 0.6875
2020-02-08T02:03:08.139276: step 702, loss 0.559072, acc 0.765625
2020-02-08T02:03:08.321125: step 703, loss 0.504923, acc 0.75
2020-02-08T02:03:08.514993: step 704, loss 0.576039, acc 0.671875
2020-02-08T02:03:08.715997: step 705, loss 0.396598, acc 0.8125
2020-02-08T02:03:08.909164: step 706, loss 0.528481, acc 0.75
2020-02-08T02:03:09.109419: step 707, loss 0.558497, acc 0.6875
2020-02-08T02:03:09.302548: step 708, loss 0.393796, acc 0.859375
2020-02-08T02:03:09.484363: step 709, loss 0.525484, acc 0.75
2020-02-08T02:03:09.691097: step 710, loss 0.506652, acc 0.71875
2020-02-08T02:03:09.877775: step 711, loss 0.473074, acc 0.734375
2020-02-08T02:03:10.076536: step 712, loss 0.474787, acc 0.796875
2020-02-08T02:03:10.249836: step 713, loss 0.39765, acc 0.828125
2020-02-08T02:03:10.437737: step 714, loss 0.524354, acc 0.703125
2020-02-08T02:03:10.641012: step 715, loss 0.61889, acc 0.6875
2020-02-08T02:03:10.835112: step 716, loss 0.500633, acc 0.796875
2020-02-08T02:03:11.032730: step 717, loss 0.496049, acc 0.734375
2020-02-08T02:03:11.217726: step 718, loss 0.694314, acc 0.640625
2020-02-08T02:03:11.419105: step 719, loss 0.465632, acc 0.75
2020-02-08T02:03:11.616701: step 720, loss 0.41132, acc 0.859375
2020-02-08T02:03:11.820291: step 721, loss 0.555857, acc 0.734375
2020-02-08T02:03:12.010676: step 722, loss 0.481091, acc 0.765625
2020-02-08T02:03:12.206281: step 723, loss 0.457569, acc 0.828125
2020-02-08T02:03:12.411035: step 724, loss 0.645449, acc 0.671875
2020-02-08T02:03:12.603921: step 725, loss 0.485025, acc 0.765625
2020-02-08T02:03:12.799682: step 726, loss 0.520181, acc 0.71875
2020-02-08T02:03:12.979180: step 727, loss 0.506875, acc 0.75
2020-02-08T02:03:13.171731: step 728, loss 0.401826, acc 0.828125
2020-02-08T02:03:13.354866: step 729, loss 0.52709, acc 0.734375
2020-02-08T02:03:13.546704: step 730, loss 0.555587, acc 0.734375
2020-02-08T02:03:13.737052: step 731, loss 0.562251, acc 0.671875
2020-02-08T02:03:13.924226: step 732, loss 0.540517, acc 0.71875
2020-02-08T02:03:14.114001: step 733, loss 0.50486, acc 0.765625
2020-02-08T02:03:14.298342: step 734, loss 0.504928, acc 0.75
2020-02-08T02:03:14.480881: step 735, loss 0.520723, acc 0.734375
2020-02-08T02:03:14.686354: step 736, loss 0.492901, acc 0.765625
2020-02-08T02:03:14.858734: step 737, loss 0.594711, acc 0.640625
2020-02-08T02:03:15.075635: step 738, loss 0.424004, acc 0.8125
2020-02-08T02:03:15.254824: step 739, loss 0.542047, acc 0.6875
2020-02-08T02:03:15.434923: step 740, loss 0.462431, acc 0.75
2020-02-08T02:03:15.612392: step 741, loss 0.52986, acc 0.71875
2020-02-08T02:03:15.798004: step 742, loss 0.413965, acc 0.78125
2020-02-08T02:03:15.992429: step 743, loss 0.415172, acc 0.828125
2020-02-08T02:03:16.190222: step 744, loss 0.370355, acc 0.8125
2020-02-08T02:03:16.389959: step 745, loss 0.63411, acc 0.734375
2020-02-08T02:03:16.580010: step 746, loss 0.411852, acc 0.765625
2020-02-08T02:03:16.760992: step 747, loss 0.42268, acc 0.796875
2020-02-08T02:03:16.949287: step 748, loss 0.462021, acc 0.78125
2020-02-08T02:03:17.139343: step 749, loss 0.454278, acc 0.8125
2020-02-08T02:03:17.315091: step 750, loss 0.467234, acc 0.85
2020-02-08T02:03:17.505750: step 751, loss 0.438128, acc 0.84375
2020-02-08T02:03:17.706130: step 752, loss 0.383958, acc 0.84375
2020-02-08T02:03:17.905476: step 753, loss 0.36324, acc 0.890625
2020-02-08T02:03:18.095604: step 754, loss 0.444735, acc 0.796875
2020-02-08T02:03:18.275717: step 755, loss 0.359139, acc 0.859375
2020-02-08T02:03:18.461637: step 756, loss 0.501283, acc 0.71875
2020-02-08T02:03:18.675297: step 757, loss 0.429502, acc 0.796875
2020-02-08T02:03:18.859584: step 758, loss 0.420673, acc 0.828125
2020-02-08T02:03:19.044860: step 759, loss 0.486075, acc 0.8125
2020-02-08T02:03:19.256746: step 760, loss 0.404065, acc 0.8125
2020-02-08T02:03:19.440609: step 761, loss 0.563082, acc 0.78125
2020-02-08T02:03:19.635775: step 762, loss 0.332924, acc 0.859375
2020-02-08T02:03:19.827775: step 763, loss 0.444784, acc 0.796875
2020-02-08T02:03:20.013092: step 764, loss 0.382509, acc 0.8125
2020-02-08T02:03:20.204607: step 765, loss 0.29974, acc 0.90625
2020-02-08T02:03:20.394598: step 766, loss 0.369237, acc 0.84375
2020-02-08T02:03:20.583314: step 767, loss 0.360598, acc 0.84375
2020-02-08T02:03:20.795071: step 768, loss 0.41052, acc 0.84375
2020-02-08T02:03:20.986410: step 769, loss 0.378206, acc 0.796875
2020-02-08T02:03:21.187301: step 770, loss 0.592362, acc 0.71875
2020-02-08T02:03:21.650070: step 771, loss 0.39409, acc 0.828125
2020-02-08T02:03:21.848718: step 772, loss 0.383069, acc 0.875
2020-02-08T02:03:22.050391: step 773, loss 0.461122, acc 0.828125
2020-02-08T02:03:22.239584: step 774, loss 0.343752, acc 0.859375
2020-02-08T02:03:22.422041: step 775, loss 0.446642, acc 0.8125
2020-02-08T02:03:22.601535: step 776, loss 0.314993, acc 0.875
2020-02-08T02:03:22.802267: step 777, loss 0.415356, acc 0.796875
2020-02-08T02:03:22.987714: step 778, loss 0.308061, acc 0.9375
2020-02-08T02:03:23.180980: step 779, loss 0.338535, acc 0.890625
2020-02-08T02:03:23.369300: step 780, loss 0.347311, acc 0.875
2020-02-08T02:03:23.558399: step 781, loss 0.354266, acc 0.859375
2020-02-08T02:03:23.747208: step 782, loss 0.380491, acc 0.78125
2020-02-08T02:03:23.942939: step 783, loss 0.454121, acc 0.765625
2020-02-08T02:03:24.127774: step 784, loss 0.399486, acc 0.828125
2020-02-08T02:03:24.309309: step 785, loss 0.383596, acc 0.828125
2020-02-08T02:03:24.480710: step 786, loss 0.443466, acc 0.84375
2020-02-08T02:03:24.676441: step 787, loss 0.367167, acc 0.84375
2020-02-08T02:03:24.858121: step 788, loss 0.42007, acc 0.78125
2020-02-08T02:03:25.048457: step 789, loss 0.506366, acc 0.734375
2020-02-08T02:03:25.234393: step 790, loss 0.511491, acc 0.71875
2020-02-08T02:03:25.431454: step 791, loss 0.373662, acc 0.828125
2020-02-08T02:03:25.617257: step 792, loss 0.364472, acc 0.84375
2020-02-08T02:03:25.805808: step 793, loss 0.328582, acc 0.8125
2020-02-08T02:03:25.994440: step 794, loss 0.400864, acc 0.84375
2020-02-08T02:03:26.182943: step 795, loss 0.385923, acc 0.8125
2020-02-08T02:03:26.365733: step 796, loss 0.403755, acc 0.796875
2020-02-08T02:03:26.556368: step 797, loss 0.510139, acc 0.71875
2020-02-08T02:03:26.746197: step 798, loss 0.451833, acc 0.78125
2020-02-08T02:03:26.933428: step 799, loss 0.353599, acc 0.84375
2020-02-08T02:03:27.111794: step 800, loss 0.436248, acc 0.78125

Evaluation:
2020-02-08T02:03:27.420703: step 800, loss 0.584992, acc 0.679174

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-800

2020-02-08T02:03:29.041955: step 801, loss 0.412443, acc 0.828125
2020-02-08T02:03:29.231021: step 802, loss 0.491558, acc 0.765625
2020-02-08T02:03:29.420439: step 803, loss 0.323432, acc 0.90625
2020-02-08T02:03:29.604375: step 804, loss 0.398755, acc 0.8125
2020-02-08T02:03:29.808736: step 805, loss 0.458359, acc 0.828125
2020-02-08T02:03:29.995893: step 806, loss 0.467465, acc 0.78125
2020-02-08T02:03:30.301821: step 807, loss 0.549725, acc 0.71875
2020-02-08T02:03:30.484617: step 808, loss 0.325283, acc 0.859375
2020-02-08T02:03:30.668428: step 809, loss 0.441611, acc 0.734375
2020-02-08T02:03:30.841041: step 810, loss 0.479045, acc 0.765625
2020-02-08T02:03:31.020655: step 811, loss 0.5555, acc 0.734375
2020-02-08T02:03:31.190506: step 812, loss 0.386673, acc 0.8125
2020-02-08T02:03:31.367895: step 813, loss 0.314734, acc 0.875
2020-02-08T02:03:31.547184: step 814, loss 0.391644, acc 0.8125
2020-02-08T02:03:31.733476: step 815, loss 0.556615, acc 0.734375
2020-02-08T02:03:31.905877: step 816, loss 0.553057, acc 0.75
2020-02-08T02:03:32.082167: step 817, loss 0.505181, acc 0.8125
2020-02-08T02:03:32.250216: step 818, loss 0.406412, acc 0.84375
2020-02-08T02:03:32.422513: step 819, loss 0.349853, acc 0.84375
2020-02-08T02:03:32.604647: step 820, loss 0.500931, acc 0.75
2020-02-08T02:03:32.791332: step 821, loss 0.480783, acc 0.765625
2020-02-08T02:03:32.971608: step 822, loss 0.463444, acc 0.75
2020-02-08T02:03:33.158192: step 823, loss 0.421953, acc 0.8125
2020-02-08T02:03:33.339738: step 824, loss 0.32483, acc 0.875
2020-02-08T02:03:33.535057: step 825, loss 0.387602, acc 0.8125
2020-02-08T02:03:33.723509: step 826, loss 0.279784, acc 0.921875
2020-02-08T02:03:33.901212: step 827, loss 0.407659, acc 0.796875
2020-02-08T02:03:34.076342: step 828, loss 0.442065, acc 0.828125
2020-02-08T02:03:34.249689: step 829, loss 0.423929, acc 0.8125
2020-02-08T02:03:34.410643: step 830, loss 0.376949, acc 0.875
2020-02-08T02:03:34.587306: step 831, loss 0.414832, acc 0.75
2020-02-08T02:03:34.790896: step 832, loss 0.404105, acc 0.890625
2020-02-08T02:03:34.966346: step 833, loss 0.42705, acc 0.765625
2020-02-08T02:03:35.139009: step 834, loss 0.449252, acc 0.796875
2020-02-08T02:03:35.320647: step 835, loss 0.678666, acc 0.703125
2020-02-08T02:03:35.496429: step 836, loss 0.508264, acc 0.78125
2020-02-08T02:03:35.671395: step 837, loss 0.392986, acc 0.796875
2020-02-08T02:03:35.842444: step 838, loss 0.388265, acc 0.828125
2020-02-08T02:03:36.012907: step 839, loss 0.340256, acc 0.84375
2020-02-08T02:03:36.180826: step 840, loss 0.629955, acc 0.65625
2020-02-08T02:03:36.356544: step 841, loss 0.573261, acc 0.71875
2020-02-08T02:03:36.548165: step 842, loss 0.569206, acc 0.734375
2020-02-08T02:03:36.755941: step 843, loss 0.472594, acc 0.78125
2020-02-08T02:03:36.943602: step 844, loss 0.286013, acc 0.90625
2020-02-08T02:03:37.125994: step 845, loss 0.383615, acc 0.875
2020-02-08T02:03:37.305831: step 846, loss 0.431993, acc 0.796875
2020-02-08T02:03:37.487916: step 847, loss 0.439269, acc 0.78125
2020-02-08T02:03:37.659683: step 848, loss 0.389932, acc 0.859375
2020-02-08T02:03:37.837537: step 849, loss 0.409549, acc 0.828125
2020-02-08T02:03:38.005579: step 850, loss 0.413135, acc 0.78125
2020-02-08T02:03:38.187095: step 851, loss 0.421603, acc 0.875
2020-02-08T02:03:38.364228: step 852, loss 0.504459, acc 0.765625
2020-02-08T02:03:38.542365: step 853, loss 0.511354, acc 0.734375
2020-02-08T02:03:38.739304: step 854, loss 0.484781, acc 0.78125
2020-02-08T02:03:38.931962: step 855, loss 0.382488, acc 0.875
2020-02-08T02:03:39.126246: step 856, loss 0.487283, acc 0.765625
2020-02-08T02:03:39.321962: step 857, loss 0.287443, acc 0.90625
2020-02-08T02:03:39.507715: step 858, loss 0.48241, acc 0.765625
2020-02-08T02:03:39.697052: step 859, loss 0.413534, acc 0.859375
2020-02-08T02:03:39.879647: step 860, loss 0.335402, acc 0.859375
2020-02-08T02:03:40.057873: step 861, loss 0.505613, acc 0.75
2020-02-08T02:03:40.237840: step 862, loss 0.344955, acc 0.84375
2020-02-08T02:03:40.407557: step 863, loss 0.454427, acc 0.734375
2020-02-08T02:03:40.576459: step 864, loss 0.45832, acc 0.75
2020-02-08T02:03:40.760398: step 865, loss 0.448111, acc 0.796875
2020-02-08T02:03:40.936846: step 866, loss 0.477406, acc 0.78125
2020-02-08T02:03:41.110401: step 867, loss 0.443974, acc 0.78125
2020-02-08T02:03:41.286634: step 868, loss 0.477503, acc 0.71875
2020-02-08T02:03:41.454086: step 869, loss 0.47584, acc 0.796875
2020-02-08T02:03:41.623949: step 870, loss 0.536607, acc 0.78125
2020-02-08T02:03:41.798584: step 871, loss 0.391602, acc 0.84375
2020-02-08T02:03:41.972379: step 872, loss 0.287924, acc 0.875
2020-02-08T02:03:42.150256: step 873, loss 0.446324, acc 0.8125
2020-02-08T02:03:42.327593: step 874, loss 0.492082, acc 0.71875
2020-02-08T02:03:42.507566: step 875, loss 0.646719, acc 0.734375
2020-02-08T02:03:42.695940: step 876, loss 0.551594, acc 0.734375
2020-02-08T02:03:42.884292: step 877, loss 0.524823, acc 0.75
2020-02-08T02:03:43.057667: step 878, loss 0.350148, acc 0.828125
2020-02-08T02:03:43.239395: step 879, loss 0.628559, acc 0.71875
2020-02-08T02:03:43.419633: step 880, loss 0.394557, acc 0.796875
2020-02-08T02:03:43.606591: step 881, loss 0.488586, acc 0.78125
2020-02-08T02:03:43.802247: step 882, loss 0.548008, acc 0.734375
2020-02-08T02:03:43.989158: step 883, loss 0.442609, acc 0.78125
2020-02-08T02:03:44.173520: step 884, loss 0.497886, acc 0.78125
2020-02-08T02:03:44.359734: step 885, loss 0.385553, acc 0.8125
2020-02-08T02:03:44.550501: step 886, loss 0.463913, acc 0.734375
2020-02-08T02:03:44.744118: step 887, loss 0.430391, acc 0.84375
2020-02-08T02:03:44.926808: step 888, loss 0.561986, acc 0.71875
2020-02-08T02:03:45.104104: step 889, loss 0.433588, acc 0.796875
2020-02-08T02:03:45.278840: step 890, loss 0.305261, acc 0.859375
2020-02-08T02:03:45.456854: step 891, loss 0.51647, acc 0.765625
2020-02-08T02:03:45.630182: step 892, loss 0.517126, acc 0.796875
2020-02-08T02:03:45.804008: step 893, loss 0.378953, acc 0.921875
2020-02-08T02:03:45.975952: step 894, loss 0.624345, acc 0.640625
2020-02-08T02:03:46.158908: step 895, loss 0.377708, acc 0.8125
2020-02-08T02:03:46.343638: step 896, loss 0.413221, acc 0.828125
2020-02-08T02:03:46.537234: step 897, loss 0.55332, acc 0.765625
2020-02-08T02:03:46.711959: step 898, loss 0.319566, acc 0.859375
2020-02-08T02:03:46.881148: step 899, loss 0.25567, acc 0.90625
2020-02-08T02:03:47.053946: step 900, loss 0.482289, acc 0.75

Evaluation:
2020-02-08T02:03:47.348911: step 900, loss 0.577318, acc 0.693246

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-900

2020-02-08T02:03:48.902379: step 901, loss 0.503562, acc 0.734375
2020-02-08T02:03:49.095657: step 902, loss 0.262381, acc 0.921875
2020-02-08T02:03:49.372203: step 903, loss 0.408972, acc 0.8125
2020-02-08T02:03:49.580207: step 904, loss 0.343718, acc 0.796875
2020-02-08T02:03:49.791849: step 905, loss 0.349336, acc 0.859375
2020-02-08T02:03:49.997934: step 906, loss 0.382578, acc 0.84375
2020-02-08T02:03:50.199054: step 907, loss 0.484562, acc 0.75
2020-02-08T02:03:50.390162: step 908, loss 0.421387, acc 0.75
2020-02-08T02:03:50.581494: step 909, loss 0.466977, acc 0.734375
2020-02-08T02:03:50.786991: step 910, loss 0.359196, acc 0.78125
2020-02-08T02:03:50.976749: step 911, loss 0.336216, acc 0.828125
2020-02-08T02:03:51.170909: step 912, loss 0.303829, acc 0.859375
2020-02-08T02:03:51.370315: step 913, loss 0.275371, acc 0.90625
2020-02-08T02:03:51.683289: step 914, loss 0.387749, acc 0.796875
2020-02-08T02:03:51.883034: step 915, loss 0.274176, acc 0.890625
2020-02-08T02:03:52.097810: step 916, loss 0.307153, acc 0.890625
2020-02-08T02:03:52.312840: step 917, loss 0.363335, acc 0.8125
2020-02-08T02:03:52.522078: step 918, loss 0.272608, acc 0.90625
2020-02-08T02:03:52.711154: step 919, loss 0.261863, acc 0.859375
2020-02-08T02:03:52.896925: step 920, loss 0.327887, acc 0.875
2020-02-08T02:03:53.112740: step 921, loss 0.415421, acc 0.78125
2020-02-08T02:03:53.350016: step 922, loss 0.3359, acc 0.875
2020-02-08T02:03:53.525237: step 923, loss 0.359196, acc 0.8125
2020-02-08T02:03:53.762945: step 924, loss 0.304734, acc 0.875
2020-02-08T02:03:53.957648: step 925, loss 0.353933, acc 0.84375
2020-02-08T02:03:54.139676: step 926, loss 0.337579, acc 0.890625
2020-02-08T02:03:54.326752: step 927, loss 0.358133, acc 0.828125
2020-02-08T02:03:54.532206: step 928, loss 0.384869, acc 0.8125
2020-02-08T02:03:54.754534: step 929, loss 0.290722, acc 0.90625
2020-02-08T02:03:54.994340: step 930, loss 0.323179, acc 0.875
2020-02-08T02:03:55.183350: step 931, loss 0.39625, acc 0.8125
2020-02-08T02:03:55.392442: step 932, loss 0.399849, acc 0.8125
2020-02-08T02:03:55.584595: step 933, loss 0.244258, acc 0.9375
2020-02-08T02:03:55.800403: step 934, loss 0.288633, acc 0.90625
2020-02-08T02:03:56.027933: step 935, loss 0.377793, acc 0.8125
2020-02-08T02:03:56.249622: step 936, loss 0.269804, acc 0.921875
2020-02-08T02:03:56.441752: step 937, loss 0.34457, acc 0.828125
2020-02-08T02:03:56.680398: step 938, loss 0.408119, acc 0.75
2020-02-08T02:03:56.883169: step 939, loss 0.253737, acc 0.921875
2020-02-08T02:03:57.094125: step 940, loss 0.332905, acc 0.90625
2020-02-08T02:03:57.313848: step 941, loss 0.267162, acc 0.875
2020-02-08T02:03:57.527032: step 942, loss 0.304303, acc 0.890625
2020-02-08T02:03:57.730061: step 943, loss 0.268159, acc 0.890625
2020-02-08T02:03:57.943718: step 944, loss 0.313588, acc 0.84375
2020-02-08T02:03:58.152000: step 945, loss 0.36934, acc 0.828125
2020-02-08T02:03:58.367852: step 946, loss 0.342084, acc 0.859375
2020-02-08T02:03:58.570294: step 947, loss 0.209791, acc 0.921875
2020-02-08T02:03:58.815556: step 948, loss 0.348291, acc 0.859375
2020-02-08T02:03:59.025552: step 949, loss 0.448108, acc 0.796875
2020-02-08T02:03:59.250846: step 950, loss 0.374589, acc 0.796875
2020-02-08T02:03:59.462058: step 951, loss 0.497144, acc 0.78125
2020-02-08T02:03:59.667903: step 952, loss 0.397782, acc 0.828125
2020-02-08T02:03:59.865944: step 953, loss 0.33931, acc 0.875
2020-02-08T02:04:00.116152: step 954, loss 0.335997, acc 0.84375
2020-02-08T02:04:00.333906: step 955, loss 0.369675, acc 0.875
2020-02-08T02:04:00.562968: step 956, loss 0.440503, acc 0.828125
2020-02-08T02:04:00.781561: step 957, loss 0.380455, acc 0.8125
2020-02-08T02:04:00.978606: step 958, loss 0.27222, acc 0.890625
2020-02-08T02:04:01.200584: step 959, loss 0.465646, acc 0.78125
2020-02-08T02:04:01.448277: step 960, loss 0.505011, acc 0.75
2020-02-08T02:04:01.672933: step 961, loss 0.376215, acc 0.84375
2020-02-08T02:04:01.872350: step 962, loss 0.379799, acc 0.859375
2020-02-08T02:04:02.088972: step 963, loss 0.406685, acc 0.765625
2020-02-08T02:04:02.306603: step 964, loss 0.243616, acc 0.890625
2020-02-08T02:04:02.500395: step 965, loss 0.449303, acc 0.8125
2020-02-08T02:04:02.697653: step 966, loss 0.394065, acc 0.796875
2020-02-08T02:04:02.902433: step 967, loss 0.417188, acc 0.796875
2020-02-08T02:04:03.119582: step 968, loss 0.368652, acc 0.859375
2020-02-08T02:04:03.354061: step 969, loss 0.508105, acc 0.765625
2020-02-08T02:04:03.555419: step 970, loss 0.340916, acc 0.8125
2020-02-08T02:04:03.779804: step 971, loss 0.540666, acc 0.78125
2020-02-08T02:04:04.006517: step 972, loss 0.294413, acc 0.890625
2020-02-08T02:04:04.207472: step 973, loss 0.289856, acc 0.90625
2020-02-08T02:04:04.403313: step 974, loss 0.331875, acc 0.875
2020-02-08T02:04:04.616198: step 975, loss 0.485498, acc 0.828125
2020-02-08T02:04:04.841333: step 976, loss 0.303922, acc 0.84375
2020-02-08T02:04:05.038559: step 977, loss 0.333374, acc 0.859375
2020-02-08T02:04:05.244197: step 978, loss 0.220617, acc 0.953125
2020-02-08T02:04:05.466504: step 979, loss 0.30821, acc 0.890625
2020-02-08T02:04:05.666452: step 980, loss 0.414203, acc 0.84375
2020-02-08T02:04:05.852041: step 981, loss 0.397108, acc 0.828125
2020-02-08T02:04:06.085943: step 982, loss 0.35633, acc 0.859375
2020-02-08T02:04:06.276285: step 983, loss 0.364453, acc 0.859375
2020-02-08T02:04:06.472476: step 984, loss 0.303923, acc 0.859375
2020-02-08T02:04:06.772489: step 985, loss 0.295226, acc 0.875
2020-02-08T02:04:07.005100: step 986, loss 0.23481, acc 0.921875
2020-02-08T02:04:07.184685: step 987, loss 0.321938, acc 0.859375
2020-02-08T02:04:07.400452: step 988, loss 0.271628, acc 0.921875
2020-02-08T02:04:07.624823: step 989, loss 0.467631, acc 0.796875
2020-02-08T02:04:07.849816: step 990, loss 0.373545, acc 0.84375
2020-02-08T02:04:08.039957: step 991, loss 0.328179, acc 0.859375
2020-02-08T02:04:08.247250: step 992, loss 0.312051, acc 0.8125
2020-02-08T02:04:08.508299: step 993, loss 0.38836, acc 0.84375
2020-02-08T02:04:08.736077: step 994, loss 0.326715, acc 0.875
2020-02-08T02:04:08.952761: step 995, loss 0.401343, acc 0.765625
2020-02-08T02:04:09.170860: step 996, loss 0.28886, acc 0.890625
2020-02-08T02:04:09.386888: step 997, loss 0.254702, acc 0.9375
2020-02-08T02:04:09.597897: step 998, loss 0.428424, acc 0.71875
2020-02-08T02:04:09.836013: step 999, loss 0.47334, acc 0.75
2020-02-08T02:04:10.050923: step 1000, loss 0.361807, acc 0.78125

Evaluation:
2020-02-08T02:04:10.395128: step 1000, loss 0.589337, acc 0.696998

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1000

2020-02-08T02:04:12.046940: step 1001, loss 0.387273, acc 0.875
2020-02-08T02:04:12.281855: step 1002, loss 0.334921, acc 0.78125
2020-02-08T02:04:12.497409: step 1003, loss 0.319223, acc 0.875
2020-02-08T02:04:12.675977: step 1004, loss 0.469451, acc 0.765625
2020-02-08T02:04:12.870205: step 1005, loss 0.459383, acc 0.8125
2020-02-08T02:04:13.080798: step 1006, loss 0.483178, acc 0.84375
2020-02-08T02:04:13.292075: step 1007, loss 0.461957, acc 0.71875
2020-02-08T02:04:13.519601: step 1008, loss 0.512457, acc 0.78125
2020-02-08T02:04:13.736568: step 1009, loss 0.409319, acc 0.84375
2020-02-08T02:04:13.924747: step 1010, loss 0.438053, acc 0.75
2020-02-08T02:04:14.156717: step 1011, loss 0.307723, acc 0.84375
2020-02-08T02:04:14.351810: step 1012, loss 0.39852, acc 0.8125
2020-02-08T02:04:14.540630: step 1013, loss 0.279492, acc 0.84375
2020-02-08T02:04:14.763376: step 1014, loss 0.338827, acc 0.890625
2020-02-08T02:04:14.993626: step 1015, loss 0.489474, acc 0.796875
2020-02-08T02:04:15.219461: step 1016, loss 0.329561, acc 0.859375
2020-02-08T02:04:15.420452: step 1017, loss 0.311209, acc 0.828125
2020-02-08T02:04:15.610720: step 1018, loss 0.384319, acc 0.875
2020-02-08T02:04:15.839564: step 1019, loss 0.377177, acc 0.84375
2020-02-08T02:04:16.037795: step 1020, loss 0.323327, acc 0.890625
2020-02-08T02:04:16.223984: step 1021, loss 0.451942, acc 0.796875
2020-02-08T02:04:16.427866: step 1022, loss 0.402871, acc 0.8125
2020-02-08T02:04:16.660208: step 1023, loss 0.2339, acc 0.9375
2020-02-08T02:04:16.850120: step 1024, loss 0.364279, acc 0.8125
2020-02-08T02:04:17.059267: step 1025, loss 0.298558, acc 0.875
2020-02-08T02:04:17.284448: step 1026, loss 0.447274, acc 0.765625
2020-02-08T02:04:17.494660: step 1027, loss 0.399624, acc 0.875
2020-02-08T02:04:17.686152: step 1028, loss 0.280647, acc 0.890625
2020-02-08T02:04:17.912850: step 1029, loss 0.353854, acc 0.859375
2020-02-08T02:04:18.123189: step 1030, loss 0.366581, acc 0.859375
2020-02-08T02:04:18.324858: step 1031, loss 0.302896, acc 0.90625
2020-02-08T02:04:18.519803: step 1032, loss 0.416929, acc 0.765625
2020-02-08T02:04:18.760000: step 1033, loss 0.380657, acc 0.796875
2020-02-08T02:04:18.957735: step 1034, loss 0.343809, acc 0.828125
2020-02-08T02:04:19.154174: step 1035, loss 0.366292, acc 0.84375
2020-02-08T02:04:19.376216: step 1036, loss 0.421882, acc 0.875
2020-02-08T02:04:19.579296: step 1037, loss 0.463277, acc 0.734375
2020-02-08T02:04:19.808802: step 1038, loss 0.402775, acc 0.8125
2020-02-08T02:04:20.004099: step 1039, loss 0.447547, acc 0.765625
2020-02-08T02:04:20.181431: step 1040, loss 0.409886, acc 0.84375
2020-02-08T02:04:20.380772: step 1041, loss 0.350768, acc 0.828125
2020-02-08T02:04:20.605031: step 1042, loss 0.287127, acc 0.859375
2020-02-08T02:04:20.804603: step 1043, loss 0.228102, acc 0.921875
2020-02-08T02:04:21.013562: step 1044, loss 0.466289, acc 0.78125
2020-02-08T02:04:21.210061: step 1045, loss 0.271934, acc 0.9375
2020-02-08T02:04:21.410783: step 1046, loss 0.2531, acc 0.890625
2020-02-08T02:04:21.653723: step 1047, loss 0.566176, acc 0.71875
2020-02-08T02:04:21.864244: step 1048, loss 0.323691, acc 0.875
2020-02-08T02:04:22.057704: step 1049, loss 0.388672, acc 0.828125
2020-02-08T02:04:22.256700: step 1050, loss 0.349514, acc 0.85
2020-02-08T02:04:22.450361: step 1051, loss 0.225571, acc 0.875
2020-02-08T02:04:22.643050: step 1052, loss 0.286105, acc 0.90625
2020-02-08T02:04:22.848572: step 1053, loss 0.307257, acc 0.84375
2020-02-08T02:04:23.057757: step 1054, loss 0.352891, acc 0.84375
2020-02-08T02:04:23.243747: step 1055, loss 0.358555, acc 0.828125
2020-02-08T02:04:23.499030: step 1056, loss 0.274323, acc 0.890625
2020-02-08T02:04:23.734303: step 1057, loss 0.241377, acc 0.890625
2020-02-08T02:04:23.937123: step 1058, loss 0.368704, acc 0.828125
2020-02-08T02:04:24.111748: step 1059, loss 0.319382, acc 0.875
2020-02-08T02:04:24.326439: step 1060, loss 0.407158, acc 0.8125
2020-02-08T02:04:24.507543: step 1061, loss 0.289604, acc 0.84375
2020-02-08T02:04:24.708455: step 1062, loss 0.325519, acc 0.890625
2020-02-08T02:04:24.907293: step 1063, loss 0.224043, acc 0.921875
2020-02-08T02:04:25.105513: step 1064, loss 0.330595, acc 0.859375
2020-02-08T02:04:25.275619: step 1065, loss 0.218708, acc 0.921875
2020-02-08T02:04:25.448392: step 1066, loss 0.328932, acc 0.890625
2020-02-08T02:04:25.695103: step 1067, loss 0.329638, acc 0.859375
2020-02-08T02:04:25.929217: step 1068, loss 0.204458, acc 0.90625
2020-02-08T02:04:26.141409: step 1069, loss 0.225385, acc 0.890625
2020-02-08T02:04:26.322516: step 1070, loss 0.312095, acc 0.875
2020-02-08T02:04:26.510649: step 1071, loss 0.278685, acc 0.90625
2020-02-08T02:04:26.726935: step 1072, loss 0.353037, acc 0.796875
2020-02-08T02:04:26.911118: step 1073, loss 0.368506, acc 0.84375
2020-02-08T02:04:27.097888: step 1074, loss 0.259797, acc 0.890625
2020-02-08T02:04:27.296641: step 1075, loss 0.332477, acc 0.84375
2020-02-08T02:04:27.511909: step 1076, loss 0.434721, acc 0.78125
2020-02-08T02:04:27.696245: step 1077, loss 0.395907, acc 0.828125
2020-02-08T02:04:27.902966: step 1078, loss 0.33468, acc 0.890625
2020-02-08T02:04:28.102179: step 1079, loss 0.27553, acc 0.90625
2020-02-08T02:04:28.303873: step 1080, loss 0.293761, acc 0.875
2020-02-08T02:04:28.491208: step 1081, loss 0.48123, acc 0.828125
2020-02-08T02:04:28.718372: step 1082, loss 0.15447, acc 0.953125
2020-02-08T02:04:28.906488: step 1083, loss 0.241319, acc 0.921875
2020-02-08T02:04:29.111997: step 1084, loss 0.264295, acc 0.890625
2020-02-08T02:04:29.299373: step 1085, loss 0.295755, acc 0.859375
2020-02-08T02:04:29.501331: step 1086, loss 0.314681, acc 0.875
2020-02-08T02:04:29.694901: step 1087, loss 0.306512, acc 0.84375
2020-02-08T02:04:29.881477: step 1088, loss 0.257872, acc 0.90625
2020-02-08T02:04:30.072471: step 1089, loss 0.200878, acc 0.890625
2020-02-08T02:04:30.262466: step 1090, loss 0.246295, acc 0.890625
2020-02-08T02:04:30.451148: step 1091, loss 0.33008, acc 0.859375
2020-02-08T02:04:30.646261: step 1092, loss 0.280355, acc 0.875
2020-02-08T02:04:30.823097: step 1093, loss 0.266429, acc 0.921875
2020-02-08T02:04:31.014169: step 1094, loss 0.158596, acc 0.953125
2020-02-08T02:04:31.210537: step 1095, loss 0.275164, acc 0.890625
2020-02-08T02:04:31.402041: step 1096, loss 0.293942, acc 0.890625
2020-02-08T02:04:31.607910: step 1097, loss 0.236599, acc 0.9375
2020-02-08T02:04:31.803765: step 1098, loss 0.302417, acc 0.84375
2020-02-08T02:04:32.002552: step 1099, loss 0.267166, acc 0.890625
2020-02-08T02:04:32.197846: step 1100, loss 0.290091, acc 0.828125

Evaluation:
2020-02-08T02:04:32.534947: step 1100, loss 0.578004, acc 0.712008

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1100

2020-02-08T02:04:34.849127: step 1101, loss 0.470332, acc 0.796875
2020-02-08T02:04:35.040067: step 1102, loss 0.259326, acc 0.875
2020-02-08T02:04:35.237210: step 1103, loss 0.257365, acc 0.890625
2020-02-08T02:04:35.422014: step 1104, loss 0.259971, acc 0.96875
2020-02-08T02:04:35.603630: step 1105, loss 0.292291, acc 0.84375
2020-02-08T02:04:35.871253: step 1106, loss 0.246182, acc 0.953125
2020-02-08T02:04:36.104025: step 1107, loss 0.336604, acc 0.78125
2020-02-08T02:04:36.302376: step 1108, loss 0.355889, acc 0.84375
2020-02-08T02:04:36.499312: step 1109, loss 0.209752, acc 0.921875
2020-02-08T02:04:36.683802: step 1110, loss 0.286276, acc 0.875
2020-02-08T02:04:36.887142: step 1111, loss 0.248848, acc 0.921875
2020-02-08T02:04:37.066565: step 1112, loss 0.255527, acc 0.890625
2020-02-08T02:04:37.269031: step 1113, loss 0.292185, acc 0.890625
2020-02-08T02:04:37.447175: step 1114, loss 0.198025, acc 0.953125
2020-02-08T02:04:37.637719: step 1115, loss 0.348283, acc 0.8125
2020-02-08T02:04:37.840575: step 1116, loss 0.250165, acc 0.890625
2020-02-08T02:04:38.033990: step 1117, loss 0.200831, acc 0.890625
2020-02-08T02:04:38.226119: step 1118, loss 0.295086, acc 0.859375
2020-02-08T02:04:38.415806: step 1119, loss 0.222098, acc 0.921875
2020-02-08T02:04:38.613797: step 1120, loss 0.248688, acc 0.90625
2020-02-08T02:04:38.831451: step 1121, loss 0.327295, acc 0.90625
2020-02-08T02:04:39.021589: step 1122, loss 0.264003, acc 0.875
2020-02-08T02:04:39.239648: step 1123, loss 0.291441, acc 0.890625
2020-02-08T02:04:39.438592: step 1124, loss 0.335573, acc 0.859375
2020-02-08T02:04:39.640896: step 1125, loss 0.286012, acc 0.875
2020-02-08T02:04:39.837905: step 1126, loss 0.30967, acc 0.84375
2020-02-08T02:04:40.030344: step 1127, loss 0.39767, acc 0.796875
2020-02-08T02:04:40.218029: step 1128, loss 0.299736, acc 0.84375
2020-02-08T02:04:40.401742: step 1129, loss 0.304957, acc 0.8125
2020-02-08T02:04:40.612934: step 1130, loss 0.20705, acc 0.921875
2020-02-08T02:04:40.819282: step 1131, loss 0.345453, acc 0.84375
2020-02-08T02:04:41.005780: step 1132, loss 0.271872, acc 0.90625
2020-02-08T02:04:41.204587: step 1133, loss 0.176901, acc 0.953125
2020-02-08T02:04:41.398616: step 1134, loss 0.297498, acc 0.875
2020-02-08T02:04:41.588323: step 1135, loss 0.235283, acc 0.90625
2020-02-08T02:04:41.791882: step 1136, loss 0.314863, acc 0.859375
2020-02-08T02:04:41.981000: step 1137, loss 0.344925, acc 0.84375
2020-02-08T02:04:42.184222: step 1138, loss 0.277485, acc 0.859375
2020-02-08T02:04:42.371074: step 1139, loss 0.291239, acc 0.875
2020-02-08T02:04:42.558860: step 1140, loss 0.300586, acc 0.875
2020-02-08T02:04:42.768103: step 1141, loss 0.304216, acc 0.84375
2020-02-08T02:04:42.967095: step 1142, loss 0.280396, acc 0.875
2020-02-08T02:04:43.152038: step 1143, loss 0.217842, acc 0.890625
2020-02-08T02:04:43.333090: step 1144, loss 0.338774, acc 0.890625
2020-02-08T02:04:43.522564: step 1145, loss 0.215103, acc 0.90625
2020-02-08T02:04:43.736213: step 1146, loss 0.253044, acc 0.890625
2020-02-08T02:04:43.939183: step 1147, loss 0.308605, acc 0.859375
2020-02-08T02:04:44.117040: step 1148, loss 0.457148, acc 0.84375
2020-02-08T02:04:44.299431: step 1149, loss 0.333876, acc 0.859375
2020-02-08T02:04:44.481542: step 1150, loss 0.223138, acc 0.9375
2020-02-08T02:04:44.673047: step 1151, loss 0.217708, acc 0.953125
2020-02-08T02:04:44.851442: step 1152, loss 0.235096, acc 0.90625
2020-02-08T02:04:45.029725: step 1153, loss 0.37804, acc 0.890625
2020-02-08T02:04:45.200456: step 1154, loss 0.240536, acc 0.921875
2020-02-08T02:04:45.376256: step 1155, loss 0.298185, acc 0.875
2020-02-08T02:04:45.557091: step 1156, loss 0.191496, acc 0.921875
2020-02-08T02:04:45.738118: step 1157, loss 0.374792, acc 0.8125
2020-02-08T02:04:45.912555: step 1158, loss 0.21352, acc 0.921875
2020-02-08T02:04:46.090517: step 1159, loss 0.341536, acc 0.828125
2020-02-08T02:04:46.263864: step 1160, loss 0.356529, acc 0.8125
2020-02-08T02:04:46.436208: step 1161, loss 0.209761, acc 0.921875
2020-02-08T02:04:46.612280: step 1162, loss 0.277664, acc 0.84375
2020-02-08T02:04:46.801284: step 1163, loss 0.285633, acc 0.890625
2020-02-08T02:04:46.981356: step 1164, loss 0.329369, acc 0.828125
2020-02-08T02:04:47.151892: step 1165, loss 0.297942, acc 0.875
2020-02-08T02:04:47.320247: step 1166, loss 0.362595, acc 0.859375
2020-02-08T02:04:47.503013: step 1167, loss 0.30626, acc 0.890625
2020-02-08T02:04:47.674763: step 1168, loss 0.277398, acc 0.90625
2020-02-08T02:04:47.847971: step 1169, loss 0.28602, acc 0.84375
2020-02-08T02:04:48.040878: step 1170, loss 0.262847, acc 0.90625
2020-02-08T02:04:48.221370: step 1171, loss 0.319715, acc 0.828125
2020-02-08T02:04:48.400391: step 1172, loss 0.367739, acc 0.84375
2020-02-08T02:04:48.595114: step 1173, loss 0.33526, acc 0.859375
2020-02-08T02:04:48.793504: step 1174, loss 0.269089, acc 0.90625
2020-02-08T02:04:48.969221: step 1175, loss 0.256776, acc 0.890625
2020-02-08T02:04:49.177652: step 1176, loss 0.232766, acc 0.84375
2020-02-08T02:04:49.368599: step 1177, loss 0.329838, acc 0.875
2020-02-08T02:04:49.552367: step 1178, loss 0.290919, acc 0.90625
2020-02-08T02:04:49.756075: step 1179, loss 0.318646, acc 0.859375
2020-02-08T02:04:49.928879: step 1180, loss 0.305821, acc 0.875
2020-02-08T02:04:50.121166: step 1181, loss 0.440167, acc 0.8125
2020-02-08T02:04:50.329194: step 1182, loss 0.35632, acc 0.875
2020-02-08T02:04:50.537921: step 1183, loss 0.27541, acc 0.890625
2020-02-08T02:04:50.736274: step 1184, loss 0.255354, acc 0.90625
2020-02-08T02:04:50.931713: step 1185, loss 0.328353, acc 0.875
2020-02-08T02:04:51.121324: step 1186, loss 0.418887, acc 0.796875
2020-02-08T02:04:51.306596: step 1187, loss 0.259886, acc 0.90625
2020-02-08T02:04:51.495749: step 1188, loss 0.207887, acc 0.9375
2020-02-08T02:04:51.795276: step 1189, loss 0.36758, acc 0.8125
2020-02-08T02:04:52.006730: step 1190, loss 0.277153, acc 0.90625
2020-02-08T02:04:52.194088: step 1191, loss 0.37845, acc 0.84375
2020-02-08T02:04:52.392625: step 1192, loss 0.304427, acc 0.875
2020-02-08T02:04:52.581251: step 1193, loss 0.281331, acc 0.828125
2020-02-08T02:04:52.794353: step 1194, loss 0.247263, acc 0.875
2020-02-08T02:04:52.973225: step 1195, loss 0.322423, acc 0.796875
2020-02-08T02:04:53.160309: step 1196, loss 0.285423, acc 0.875
2020-02-08T02:04:53.373713: step 1197, loss 0.168376, acc 0.9375
2020-02-08T02:04:53.563301: step 1198, loss 0.340428, acc 0.828125
2020-02-08T02:04:53.790836: step 1199, loss 0.354069, acc 0.765625
2020-02-08T02:04:53.974280: step 1200, loss 0.240153, acc 0.883333

Evaluation:
2020-02-08T02:04:54.370701: step 1200, loss 0.590687, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1200

2020-02-08T02:04:57.022113: step 1201, loss 0.138426, acc 0.96875
2020-02-08T02:04:57.217152: step 1202, loss 0.209741, acc 0.90625
2020-02-08T02:04:57.443533: step 1203, loss 0.155428, acc 0.984375
2020-02-08T02:04:57.673641: step 1204, loss 0.209, acc 0.90625
2020-02-08T02:04:57.897981: step 1205, loss 0.237919, acc 0.890625
2020-02-08T02:04:58.143685: step 1206, loss 0.263906, acc 0.875
2020-02-08T02:04:58.377270: step 1207, loss 0.239869, acc 0.890625
2020-02-08T02:04:58.640720: step 1208, loss 0.260704, acc 0.921875
2020-02-08T02:04:58.878994: step 1209, loss 0.240549, acc 0.90625
2020-02-08T02:04:59.144122: step 1210, loss 0.293, acc 0.875
2020-02-08T02:04:59.358953: step 1211, loss 0.286404, acc 0.84375
2020-02-08T02:04:59.594414: step 1212, loss 0.210461, acc 0.9375
2020-02-08T02:04:59.831628: step 1213, loss 0.252061, acc 0.90625
2020-02-08T02:05:00.061179: step 1214, loss 0.145832, acc 0.953125
2020-02-08T02:05:00.281117: step 1215, loss 0.173441, acc 0.9375
2020-02-08T02:05:00.517160: step 1216, loss 0.305841, acc 0.859375
2020-02-08T02:05:00.745299: step 1217, loss 0.318583, acc 0.890625
2020-02-08T02:05:00.974043: step 1218, loss 0.307065, acc 0.921875
2020-02-08T02:05:01.211590: step 1219, loss 0.169894, acc 0.96875
2020-02-08T02:05:01.450705: step 1220, loss 0.179923, acc 0.9375
2020-02-08T02:05:01.701461: step 1221, loss 0.254099, acc 0.90625
2020-02-08T02:05:01.932086: step 1222, loss 0.189418, acc 0.921875
2020-02-08T02:05:02.152774: step 1223, loss 0.447666, acc 0.828125
2020-02-08T02:05:02.381922: step 1224, loss 0.313282, acc 0.875
2020-02-08T02:05:02.611019: step 1225, loss 0.190406, acc 0.90625
2020-02-08T02:05:02.849360: step 1226, loss 0.172828, acc 0.90625
2020-02-08T02:05:03.067227: step 1227, loss 0.139219, acc 0.953125
2020-02-08T02:05:03.244922: step 1228, loss 0.329495, acc 0.890625
2020-02-08T02:05:03.470172: step 1229, loss 0.194312, acc 0.9375
2020-02-08T02:05:03.713779: step 1230, loss 0.272989, acc 0.890625
2020-02-08T02:05:03.932352: step 1231, loss 0.190262, acc 0.953125
2020-02-08T02:05:04.161539: step 1232, loss 0.211817, acc 0.875
2020-02-08T02:05:04.399286: step 1233, loss 0.278883, acc 0.90625
2020-02-08T02:05:04.629384: step 1234, loss 0.171449, acc 0.953125
2020-02-08T02:05:04.863304: step 1235, loss 0.181087, acc 0.921875
2020-02-08T02:05:05.080732: step 1236, loss 0.221749, acc 0.921875
2020-02-08T02:05:05.300502: step 1237, loss 0.192891, acc 0.921875
2020-02-08T02:05:05.529721: step 1238, loss 0.191602, acc 0.9375
2020-02-08T02:05:05.760623: step 1239, loss 0.185527, acc 0.9375
2020-02-08T02:05:05.997391: step 1240, loss 0.208287, acc 0.953125
2020-02-08T02:05:06.270436: step 1241, loss 0.176857, acc 0.9375
2020-02-08T02:05:06.495510: step 1242, loss 0.136227, acc 0.953125
2020-02-08T02:05:06.763097: step 1243, loss 0.245302, acc 0.890625
2020-02-08T02:05:06.972840: step 1244, loss 0.266827, acc 0.859375
2020-02-08T02:05:07.190078: step 1245, loss 0.150474, acc 0.953125
2020-02-08T02:05:07.363922: step 1246, loss 0.22808, acc 0.890625
2020-02-08T02:05:07.584447: step 1247, loss 0.169633, acc 0.90625
2020-02-08T02:05:07.821603: step 1248, loss 0.323258, acc 0.859375
2020-02-08T02:05:08.049443: step 1249, loss 0.193833, acc 0.9375
2020-02-08T02:05:08.262561: step 1250, loss 0.197379, acc 0.953125
2020-02-08T02:05:08.481816: step 1251, loss 0.237018, acc 0.875
2020-02-08T02:05:08.709504: step 1252, loss 0.23338, acc 0.890625
2020-02-08T02:05:08.948698: step 1253, loss 0.194784, acc 0.9375
2020-02-08T02:05:09.119838: step 1254, loss 0.230442, acc 0.875
2020-02-08T02:05:09.326798: step 1255, loss 0.224478, acc 0.921875
2020-02-08T02:05:09.520850: step 1256, loss 0.253989, acc 0.890625
2020-02-08T02:05:09.750836: step 1257, loss 0.233071, acc 0.890625
2020-02-08T02:05:09.961336: step 1258, loss 0.202578, acc 0.9375
2020-02-08T02:05:10.184319: step 1259, loss 0.177026, acc 0.921875
2020-02-08T02:05:10.400648: step 1260, loss 0.207793, acc 0.890625
2020-02-08T02:05:10.632451: step 1261, loss 0.177318, acc 0.953125
2020-02-08T02:05:10.839177: step 1262, loss 0.233644, acc 0.875
2020-02-08T02:05:11.051578: step 1263, loss 0.252319, acc 0.859375
2020-02-08T02:05:11.251839: step 1264, loss 0.18202, acc 0.921875
2020-02-08T02:05:11.467307: step 1265, loss 0.227082, acc 0.90625
2020-02-08T02:05:11.678948: step 1266, loss 0.2144, acc 0.921875
2020-02-08T02:05:11.893046: step 1267, loss 0.317092, acc 0.84375
2020-02-08T02:05:12.085304: step 1268, loss 0.230938, acc 0.90625
2020-02-08T02:05:12.299931: step 1269, loss 0.258081, acc 0.890625
2020-02-08T02:05:12.505758: step 1270, loss 0.18487, acc 0.96875
2020-02-08T02:05:12.721419: step 1271, loss 0.268307, acc 0.875
2020-02-08T02:05:12.921112: step 1272, loss 0.199647, acc 0.953125
2020-02-08T02:05:13.120628: step 1273, loss 0.257899, acc 0.875
2020-02-08T02:05:13.328008: step 1274, loss 0.210182, acc 0.921875
2020-02-08T02:05:13.537920: step 1275, loss 0.151036, acc 0.9375
2020-02-08T02:05:13.754465: step 1276, loss 0.218607, acc 0.9375
2020-02-08T02:05:13.955442: step 1277, loss 0.244006, acc 0.859375
2020-02-08T02:05:14.150936: step 1278, loss 0.343636, acc 0.890625
2020-02-08T02:05:14.368351: step 1279, loss 0.230737, acc 0.84375
2020-02-08T02:05:14.573915: step 1280, loss 0.208873, acc 0.90625
2020-02-08T02:05:14.788975: step 1281, loss 0.209296, acc 0.90625
2020-02-08T02:05:14.987090: step 1282, loss 0.28997, acc 0.875
2020-02-08T02:05:15.185293: step 1283, loss 0.323997, acc 0.90625
2020-02-08T02:05:15.386381: step 1284, loss 0.320588, acc 0.859375
2020-02-08T02:05:15.582236: step 1285, loss 0.282851, acc 0.890625
2020-02-08T02:05:15.789617: step 1286, loss 0.216145, acc 0.890625
2020-02-08T02:05:15.986948: step 1287, loss 0.191434, acc 0.9375
2020-02-08T02:05:16.192898: step 1288, loss 0.188211, acc 0.890625
2020-02-08T02:05:16.404749: step 1289, loss 0.23695, acc 0.890625
2020-02-08T02:05:16.604817: step 1290, loss 0.196555, acc 0.890625
2020-02-08T02:05:16.850399: step 1291, loss 0.246151, acc 0.921875
2020-02-08T02:05:17.057780: step 1292, loss 0.276571, acc 0.84375
2020-02-08T02:05:17.249707: step 1293, loss 0.259078, acc 0.90625
2020-02-08T02:05:17.451471: step 1294, loss 0.317826, acc 0.84375
2020-02-08T02:05:17.654495: step 1295, loss 0.175163, acc 0.984375
2020-02-08T02:05:17.860740: step 1296, loss 0.266869, acc 0.875
2020-02-08T02:05:18.070362: step 1297, loss 0.181594, acc 0.9375
2020-02-08T02:05:18.268207: step 1298, loss 0.170408, acc 0.9375
2020-02-08T02:05:18.472089: step 1299, loss 0.217942, acc 0.90625
2020-02-08T02:05:18.684378: step 1300, loss 0.210339, acc 0.90625

Evaluation:
2020-02-08T02:05:19.123954: step 1300, loss 0.619633, acc 0.710131

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1300

2020-02-08T02:05:21.237745: step 1301, loss 0.190546, acc 0.921875
2020-02-08T02:05:21.492235: step 1302, loss 0.243174, acc 0.90625
2020-02-08T02:05:21.780489: step 1303, loss 0.227036, acc 0.890625
2020-02-08T02:05:21.978452: step 1304, loss 0.233011, acc 0.890625
2020-02-08T02:05:22.177206: step 1305, loss 0.206426, acc 0.9375
2020-02-08T02:05:22.390391: step 1306, loss 0.240264, acc 0.875
2020-02-08T02:05:22.612859: step 1307, loss 0.281088, acc 0.84375
2020-02-08T02:05:22.834169: step 1308, loss 0.131623, acc 0.984375
2020-02-08T02:05:23.063750: step 1309, loss 0.334078, acc 0.859375
2020-02-08T02:05:23.307805: step 1310, loss 0.0842686, acc 1
2020-02-08T02:05:23.529684: step 1311, loss 0.261004, acc 0.90625
2020-02-08T02:05:23.775104: step 1312, loss 0.197477, acc 0.921875
2020-02-08T02:05:23.989396: step 1313, loss 0.257962, acc 0.859375
2020-02-08T02:05:24.200962: step 1314, loss 0.21621, acc 0.90625
2020-02-08T02:05:24.465441: step 1315, loss 0.317217, acc 0.875
2020-02-08T02:05:24.731357: step 1316, loss 0.375947, acc 0.796875
2020-02-08T02:05:24.972261: step 1317, loss 0.286863, acc 0.90625
2020-02-08T02:05:25.144662: step 1318, loss 0.183181, acc 0.90625
2020-02-08T02:05:25.359042: step 1319, loss 0.181406, acc 0.921875
2020-02-08T02:05:25.568890: step 1320, loss 0.213114, acc 0.890625
2020-02-08T02:05:25.793237: step 1321, loss 0.286206, acc 0.890625
2020-02-08T02:05:26.012056: step 1322, loss 0.297916, acc 0.859375
2020-02-08T02:05:26.229634: step 1323, loss 0.201892, acc 0.921875
2020-02-08T02:05:26.440672: step 1324, loss 0.247935, acc 0.90625
2020-02-08T02:05:26.663403: step 1325, loss 0.191585, acc 0.921875
2020-02-08T02:05:26.912935: step 1326, loss 0.195651, acc 0.953125
2020-02-08T02:05:27.158096: step 1327, loss 0.305477, acc 0.84375
2020-02-08T02:05:27.392023: step 1328, loss 0.146791, acc 0.96875
2020-02-08T02:05:27.650838: step 1329, loss 0.26377, acc 0.921875
2020-02-08T02:05:27.894545: step 1330, loss 0.155707, acc 0.9375
2020-02-08T02:05:28.126122: step 1331, loss 0.29398, acc 0.890625
2020-02-08T02:05:28.343037: step 1332, loss 0.304574, acc 0.796875
2020-02-08T02:05:28.578046: step 1333, loss 0.199963, acc 0.890625
2020-02-08T02:05:28.832773: step 1334, loss 0.175067, acc 0.953125
2020-02-08T02:05:29.047978: step 1335, loss 0.242286, acc 0.90625
2020-02-08T02:05:29.290479: step 1336, loss 0.256658, acc 0.828125
2020-02-08T02:05:29.530978: step 1337, loss 0.316132, acc 0.828125
2020-02-08T02:05:29.756213: step 1338, loss 0.35701, acc 0.828125
2020-02-08T02:05:29.962171: step 1339, loss 0.25007, acc 0.921875
2020-02-08T02:05:30.197620: step 1340, loss 0.205616, acc 0.90625
2020-02-08T02:05:30.399888: step 1341, loss 0.215836, acc 0.859375
2020-02-08T02:05:30.608942: step 1342, loss 0.345293, acc 0.859375
2020-02-08T02:05:30.845453: step 1343, loss 0.282485, acc 0.921875
2020-02-08T02:05:31.045433: step 1344, loss 0.154322, acc 0.9375
2020-02-08T02:05:31.226764: step 1345, loss 0.245459, acc 0.90625
2020-02-08T02:05:31.469165: step 1346, loss 0.171261, acc 0.921875
2020-02-08T02:05:31.674968: step 1347, loss 0.234238, acc 0.921875
2020-02-08T02:05:31.875377: step 1348, loss 0.243159, acc 0.84375
2020-02-08T02:05:32.094348: step 1349, loss 0.181954, acc 0.9375
2020-02-08T02:05:32.305387: step 1350, loss 0.170359, acc 0.933333
2020-02-08T02:05:32.537730: step 1351, loss 0.22337, acc 0.890625
2020-02-08T02:05:32.781472: step 1352, loss 0.172765, acc 0.953125
2020-02-08T02:05:32.995757: step 1353, loss 0.308903, acc 0.875
2020-02-08T02:05:33.194155: step 1354, loss 0.177709, acc 0.9375
2020-02-08T02:05:33.397056: step 1355, loss 0.216455, acc 0.859375
2020-02-08T02:05:33.613002: step 1356, loss 0.173146, acc 0.9375
2020-02-08T02:05:33.803388: step 1357, loss 0.21517, acc 0.875
2020-02-08T02:05:34.006242: step 1358, loss 0.247146, acc 0.90625
2020-02-08T02:05:34.230078: step 1359, loss 0.187446, acc 0.90625
2020-02-08T02:05:34.453353: step 1360, loss 0.198698, acc 0.90625
2020-02-08T02:05:34.641574: step 1361, loss 0.234458, acc 0.890625
2020-02-08T02:05:34.832416: step 1362, loss 0.194245, acc 0.90625
2020-02-08T02:05:35.030235: step 1363, loss 0.196434, acc 0.90625
2020-02-08T02:05:35.282009: step 1364, loss 0.235892, acc 0.890625
2020-02-08T02:05:35.527247: step 1365, loss 0.248665, acc 0.875
2020-02-08T02:05:35.743896: step 1366, loss 0.218803, acc 0.90625
2020-02-08T02:05:35.932183: step 1367, loss 0.195279, acc 0.9375
2020-02-08T02:05:36.141653: step 1368, loss 0.204232, acc 0.9375
2020-02-08T02:05:36.334665: step 1369, loss 0.136337, acc 0.953125
2020-02-08T02:05:36.530516: step 1370, loss 0.182464, acc 0.96875
2020-02-08T02:05:36.761761: step 1371, loss 0.144628, acc 0.96875
2020-02-08T02:05:36.952856: step 1372, loss 0.183131, acc 0.953125
2020-02-08T02:05:37.147128: step 1373, loss 0.303535, acc 0.875
2020-02-08T02:05:37.356300: step 1374, loss 0.19597, acc 0.9375
2020-02-08T02:05:37.548965: step 1375, loss 0.174997, acc 0.953125
2020-02-08T02:05:37.753904: step 1376, loss 0.200497, acc 0.9375
2020-02-08T02:05:37.943542: step 1377, loss 0.344618, acc 0.875
2020-02-08T02:05:38.137678: step 1378, loss 0.168605, acc 0.90625
2020-02-08T02:05:38.324476: step 1379, loss 0.134185, acc 0.9375
2020-02-08T02:05:38.518315: step 1380, loss 0.15409, acc 0.953125
2020-02-08T02:05:38.743954: step 1381, loss 0.261109, acc 0.859375
2020-02-08T02:05:38.930564: step 1382, loss 0.280337, acc 0.890625
2020-02-08T02:05:39.146313: step 1383, loss 0.145075, acc 0.9375
2020-02-08T02:05:39.343526: step 1384, loss 0.169643, acc 0.9375
2020-02-08T02:05:39.619457: step 1385, loss 0.232392, acc 0.90625
2020-02-08T02:05:39.799730: step 1386, loss 0.155953, acc 0.953125
2020-02-08T02:05:40.000720: step 1387, loss 0.168016, acc 0.9375
2020-02-08T02:05:40.190054: step 1388, loss 0.136134, acc 0.96875
2020-02-08T02:05:40.401688: step 1389, loss 0.059473, acc 1
2020-02-08T02:05:40.583755: step 1390, loss 0.152382, acc 0.953125
2020-02-08T02:05:40.799482: step 1391, loss 0.239765, acc 0.90625
2020-02-08T02:05:40.987910: step 1392, loss 0.114708, acc 0.96875
2020-02-08T02:05:41.179811: step 1393, loss 0.245127, acc 0.875
2020-02-08T02:05:41.369066: step 1394, loss 0.220645, acc 0.890625
2020-02-08T02:05:41.613856: step 1395, loss 0.317322, acc 0.890625
2020-02-08T02:05:41.819662: step 1396, loss 0.227097, acc 0.921875
2020-02-08T02:05:42.032447: step 1397, loss 0.161423, acc 0.9375
2020-02-08T02:05:42.213066: step 1398, loss 0.145136, acc 0.953125
2020-02-08T02:05:42.394348: step 1399, loss 0.219988, acc 0.921875
2020-02-08T02:05:42.573764: step 1400, loss 0.210451, acc 0.96875

Evaluation:
2020-02-08T02:05:42.946839: step 1400, loss 0.607536, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1400

2020-02-08T02:05:44.623043: step 1401, loss 0.138177, acc 0.953125
2020-02-08T02:05:44.806846: step 1402, loss 0.176258, acc 0.921875
2020-02-08T02:05:45.014275: step 1403, loss 0.29776, acc 0.84375
2020-02-08T02:05:45.206153: step 1404, loss 0.0909179, acc 0.984375
2020-02-08T02:05:45.408733: step 1405, loss 0.188598, acc 0.90625
2020-02-08T02:05:45.607546: step 1406, loss 0.177892, acc 0.921875
2020-02-08T02:05:45.842955: step 1407, loss 0.163549, acc 0.953125
2020-02-08T02:05:46.020497: step 1408, loss 0.220403, acc 0.921875
2020-02-08T02:05:46.217089: step 1409, loss 0.293312, acc 0.890625
2020-02-08T02:05:46.407653: step 1410, loss 0.251057, acc 0.859375
2020-02-08T02:05:46.615786: step 1411, loss 0.170175, acc 0.953125
2020-02-08T02:05:46.802202: step 1412, loss 0.195751, acc 0.921875
2020-02-08T02:05:46.989600: step 1413, loss 0.288508, acc 0.84375
2020-02-08T02:05:47.187966: step 1414, loss 0.0887591, acc 0.96875
2020-02-08T02:05:47.381843: step 1415, loss 0.198341, acc 0.9375
2020-02-08T02:05:47.571754: step 1416, loss 0.161728, acc 0.953125
2020-02-08T02:05:47.773717: step 1417, loss 0.287736, acc 0.90625
2020-02-08T02:05:47.953037: step 1418, loss 0.158888, acc 0.921875
2020-02-08T02:05:48.185297: step 1419, loss 0.126953, acc 0.921875
2020-02-08T02:05:48.409500: step 1420, loss 0.150357, acc 0.9375
2020-02-08T02:05:48.616100: step 1421, loss 0.121191, acc 0.953125
2020-02-08T02:05:48.815917: step 1422, loss 0.173249, acc 0.953125
2020-02-08T02:05:49.008506: step 1423, loss 0.0900827, acc 0.96875
2020-02-08T02:05:49.249690: step 1424, loss 0.16115, acc 0.953125
2020-02-08T02:05:49.472866: step 1425, loss 0.256563, acc 0.875
2020-02-08T02:05:49.720805: step 1426, loss 0.179259, acc 0.9375
2020-02-08T02:05:49.921985: step 1427, loss 0.207299, acc 0.9375
2020-02-08T02:05:50.109507: step 1428, loss 0.133813, acc 0.984375
2020-02-08T02:05:50.303705: step 1429, loss 0.210136, acc 0.890625
2020-02-08T02:05:50.513215: step 1430, loss 0.121408, acc 0.953125
2020-02-08T02:05:50.757004: step 1431, loss 0.169651, acc 0.921875
2020-02-08T02:05:50.953160: step 1432, loss 0.283031, acc 0.90625
2020-02-08T02:05:51.139780: step 1433, loss 0.126069, acc 0.953125
2020-02-08T02:05:51.334192: step 1434, loss 0.13931, acc 0.9375
2020-02-08T02:05:51.544109: step 1435, loss 0.142431, acc 0.9375
2020-02-08T02:05:51.759003: step 1436, loss 0.192726, acc 0.9375
2020-02-08T02:05:51.968130: step 1437, loss 0.188048, acc 0.9375
2020-02-08T02:05:52.160928: step 1438, loss 0.15483, acc 0.96875
2020-02-08T02:05:52.390549: step 1439, loss 0.328165, acc 0.90625
2020-02-08T02:05:52.581422: step 1440, loss 0.165746, acc 0.9375
2020-02-08T02:05:52.778693: step 1441, loss 0.195966, acc 0.921875
2020-02-08T02:05:52.977269: step 1442, loss 0.246775, acc 0.875
2020-02-08T02:05:53.171592: step 1443, loss 0.179753, acc 0.9375
2020-02-08T02:05:53.337395: step 1444, loss 0.217908, acc 0.890625
2020-02-08T02:05:53.550289: step 1445, loss 0.135124, acc 0.9375
2020-02-08T02:05:53.743002: step 1446, loss 0.163661, acc 0.953125
2020-02-08T02:05:53.939120: step 1447, loss 0.225182, acc 0.875
2020-02-08T02:05:54.127448: step 1448, loss 0.277436, acc 0.890625
2020-02-08T02:05:54.337745: step 1449, loss 0.212374, acc 0.9375
2020-02-08T02:05:54.516172: step 1450, loss 0.116336, acc 0.96875
2020-02-08T02:05:54.702580: step 1451, loss 0.170168, acc 0.921875
2020-02-08T02:05:54.873869: step 1452, loss 0.10184, acc 0.984375
2020-02-08T02:05:55.067672: step 1453, loss 0.123363, acc 0.953125
2020-02-08T02:05:55.258939: step 1454, loss 0.129934, acc 0.9375
2020-02-08T02:05:55.441348: step 1455, loss 0.150895, acc 0.9375
2020-02-08T02:05:55.641324: step 1456, loss 0.174728, acc 0.953125
2020-02-08T02:05:55.844430: step 1457, loss 0.0851694, acc 0.984375
2020-02-08T02:05:56.043720: step 1458, loss 0.317436, acc 0.828125
2020-02-08T02:05:56.246257: step 1459, loss 0.119951, acc 0.953125
2020-02-08T02:05:56.438305: step 1460, loss 0.154846, acc 0.921875
2020-02-08T02:05:56.640456: step 1461, loss 0.192125, acc 0.90625
2020-02-08T02:05:56.826977: step 1462, loss 0.163066, acc 0.953125
2020-02-08T02:05:57.012302: step 1463, loss 0.231971, acc 0.890625
2020-02-08T02:05:57.196326: step 1464, loss 0.183772, acc 0.9375
2020-02-08T02:05:57.371027: step 1465, loss 0.207216, acc 0.90625
2020-02-08T02:05:57.549986: step 1466, loss 0.0986855, acc 0.953125
2020-02-08T02:05:57.742826: step 1467, loss 0.236654, acc 0.90625
2020-02-08T02:05:57.919129: step 1468, loss 0.0818744, acc 1
2020-02-08T02:05:58.087254: step 1469, loss 0.170697, acc 0.953125
2020-02-08T02:05:58.270993: step 1470, loss 0.13448, acc 0.9375
2020-02-08T02:05:58.445496: step 1471, loss 0.193506, acc 0.875
2020-02-08T02:05:58.629601: step 1472, loss 0.219731, acc 0.890625
2020-02-08T02:05:58.806951: step 1473, loss 0.221506, acc 0.890625
2020-02-08T02:05:58.988150: step 1474, loss 0.261957, acc 0.875
2020-02-08T02:05:59.186427: step 1475, loss 0.160284, acc 0.921875
2020-02-08T02:05:59.389124: step 1476, loss 0.189503, acc 0.921875
2020-02-08T02:05:59.564688: step 1477, loss 0.19405, acc 0.9375
2020-02-08T02:05:59.760262: step 1478, loss 0.0972086, acc 1
2020-02-08T02:05:59.939108: step 1479, loss 0.252633, acc 0.90625
2020-02-08T02:06:00.121542: step 1480, loss 0.181188, acc 0.921875
2020-02-08T02:06:00.303729: step 1481, loss 0.123542, acc 0.96875
2020-02-08T02:06:00.488105: step 1482, loss 0.172894, acc 0.921875
2020-02-08T02:06:00.670122: step 1483, loss 0.136228, acc 0.953125
2020-02-08T02:06:00.852008: step 1484, loss 0.208127, acc 0.9375
2020-02-08T02:06:01.032893: step 1485, loss 0.185108, acc 0.90625
2020-02-08T02:06:01.196810: step 1486, loss 0.13506, acc 0.953125
2020-02-08T02:06:01.375539: step 1487, loss 0.231072, acc 0.875
2020-02-08T02:06:01.559704: step 1488, loss 0.115284, acc 0.96875
2020-02-08T02:06:01.755372: step 1489, loss 0.213026, acc 0.875
2020-02-08T02:06:01.933038: step 1490, loss 0.175919, acc 0.9375
2020-02-08T02:06:02.129930: step 1491, loss 0.083861, acc 0.984375
2020-02-08T02:06:02.311859: step 1492, loss 0.276596, acc 0.84375
2020-02-08T02:06:02.484029: step 1493, loss 0.229443, acc 0.921875
2020-02-08T02:06:02.660295: step 1494, loss 0.137653, acc 0.953125
2020-02-08T02:06:02.840092: step 1495, loss 0.187492, acc 0.90625
2020-02-08T02:06:03.008695: step 1496, loss 0.133592, acc 0.921875
2020-02-08T02:06:03.184239: step 1497, loss 0.296056, acc 0.90625
2020-02-08T02:06:03.362383: step 1498, loss 0.23742, acc 0.90625
2020-02-08T02:06:03.549769: step 1499, loss 0.273418, acc 0.90625
2020-02-08T02:06:03.735460: step 1500, loss 0.0833357, acc 0.966667

Evaluation:
2020-02-08T02:06:04.054381: step 1500, loss 0.625312, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1500

2020-02-08T02:06:05.593615: step 1501, loss 0.0691938, acc 0.984375
2020-02-08T02:06:05.782209: step 1502, loss 0.15356, acc 0.96875
2020-02-08T02:06:05.958236: step 1503, loss 0.0944671, acc 0.953125
2020-02-08T02:06:06.133685: step 1504, loss 0.130811, acc 0.9375
2020-02-08T02:06:06.314050: step 1505, loss 0.155569, acc 0.9375
2020-02-08T02:06:06.496649: step 1506, loss 0.163628, acc 0.9375
2020-02-08T02:06:06.684586: step 1507, loss 0.100401, acc 0.984375
2020-02-08T02:06:06.855760: step 1508, loss 0.176322, acc 0.90625
2020-02-08T02:06:07.018594: step 1509, loss 0.0954868, acc 0.96875
2020-02-08T02:06:07.189921: step 1510, loss 0.117922, acc 0.953125
2020-02-08T02:06:07.359087: step 1511, loss 0.164392, acc 0.921875
2020-02-08T02:06:07.530443: step 1512, loss 0.153615, acc 0.953125
2020-02-08T02:06:07.713892: step 1513, loss 0.165105, acc 0.953125
2020-02-08T02:06:07.890044: step 1514, loss 0.116408, acc 0.96875
2020-02-08T02:06:08.068572: step 1515, loss 0.143406, acc 0.953125
2020-02-08T02:06:08.242111: step 1516, loss 0.143011, acc 0.953125
2020-02-08T02:06:08.413627: step 1517, loss 0.202371, acc 0.921875
2020-02-08T02:06:08.601460: step 1518, loss 0.124017, acc 0.9375
2020-02-08T02:06:08.801803: step 1519, loss 0.120266, acc 0.953125
2020-02-08T02:06:08.992537: step 1520, loss 0.119196, acc 0.96875
2020-02-08T02:06:09.178198: step 1521, loss 0.140463, acc 0.921875
2020-02-08T02:06:09.363697: step 1522, loss 0.150198, acc 0.953125
2020-02-08T02:06:09.543038: step 1523, loss 0.135897, acc 0.9375
2020-02-08T02:06:09.725446: step 1524, loss 0.0717968, acc 0.984375
2020-02-08T02:06:09.912325: step 1525, loss 0.0810179, acc 0.984375
2020-02-08T02:06:10.106179: step 1526, loss 0.201681, acc 0.90625
2020-02-08T02:06:10.281034: step 1527, loss 0.22174, acc 0.890625
2020-02-08T02:06:10.456594: step 1528, loss 0.326842, acc 0.8125
2020-02-08T02:06:10.629964: step 1529, loss 0.11936, acc 0.953125
2020-02-08T02:06:10.812444: step 1530, loss 0.108824, acc 0.953125
2020-02-08T02:06:10.996097: step 1531, loss 0.145379, acc 0.9375
2020-02-08T02:06:11.165992: step 1532, loss 0.101374, acc 0.953125
2020-02-08T02:06:11.351393: step 1533, loss 0.186304, acc 0.921875
2020-02-08T02:06:11.532609: step 1534, loss 0.124123, acc 0.9375
2020-02-08T02:06:11.714204: step 1535, loss 0.0834257, acc 0.96875
2020-02-08T02:06:11.897249: step 1536, loss 0.178593, acc 0.9375
2020-02-08T02:06:12.081344: step 1537, loss 0.0936881, acc 0.96875
2020-02-08T02:06:12.259915: step 1538, loss 0.139811, acc 0.921875
2020-02-08T02:06:12.442375: step 1539, loss 0.099678, acc 0.96875
2020-02-08T02:06:12.626036: step 1540, loss 0.22394, acc 0.9375
2020-02-08T02:06:12.827863: step 1541, loss 0.158986, acc 0.984375
2020-02-08T02:06:13.008991: step 1542, loss 0.20623, acc 0.921875
2020-02-08T02:06:13.199916: step 1543, loss 0.125498, acc 0.953125
2020-02-08T02:06:13.392250: step 1544, loss 0.050911, acc 0.96875
2020-02-08T02:06:13.575498: step 1545, loss 0.141244, acc 0.953125
2020-02-08T02:06:13.770588: step 1546, loss 0.139174, acc 0.921875
2020-02-08T02:06:13.958204: step 1547, loss 0.0972981, acc 0.9375
2020-02-08T02:06:14.136285: step 1548, loss 0.135335, acc 0.953125
2020-02-08T02:06:14.316341: step 1549, loss 0.142002, acc 0.9375
2020-02-08T02:06:14.491645: step 1550, loss 0.062862, acc 0.984375
2020-02-08T02:06:14.671425: step 1551, loss 0.114717, acc 0.96875
2020-02-08T02:06:14.852175: step 1552, loss 0.16513, acc 0.9375
2020-02-08T02:06:15.021246: step 1553, loss 0.181867, acc 0.921875
2020-02-08T02:06:15.205983: step 1554, loss 0.132762, acc 0.921875
2020-02-08T02:06:15.394607: step 1555, loss 0.213748, acc 0.9375
2020-02-08T02:06:15.563250: step 1556, loss 0.142814, acc 0.953125
2020-02-08T02:06:15.747523: step 1557, loss 0.103471, acc 0.953125
2020-02-08T02:06:15.930530: step 1558, loss 0.153147, acc 0.953125
2020-02-08T02:06:16.119877: step 1559, loss 0.12363, acc 0.984375
2020-02-08T02:06:16.311103: step 1560, loss 0.109278, acc 0.953125
2020-02-08T02:06:16.480690: step 1561, loss 0.124708, acc 0.953125
2020-02-08T02:06:16.653582: step 1562, loss 0.111725, acc 0.9375
2020-02-08T02:06:16.827049: step 1563, loss 0.259575, acc 0.84375
2020-02-08T02:06:17.017901: step 1564, loss 0.204245, acc 0.9375
2020-02-08T02:06:17.200185: step 1565, loss 0.128854, acc 0.9375
2020-02-08T02:06:17.381961: step 1566, loss 0.187184, acc 0.921875
2020-02-08T02:06:17.564848: step 1567, loss 0.121936, acc 0.953125
2020-02-08T02:06:17.760736: step 1568, loss 0.268749, acc 0.9375
2020-02-08T02:06:17.936080: step 1569, loss 0.199318, acc 0.9375
2020-02-08T02:06:18.117389: step 1570, loss 0.170357, acc 0.90625
2020-02-08T02:06:18.290091: step 1571, loss 0.200447, acc 0.9375
2020-02-08T02:06:18.481673: step 1572, loss 0.152255, acc 0.921875
2020-02-08T02:06:18.666358: step 1573, loss 0.204976, acc 0.921875
2020-02-08T02:06:18.833683: step 1574, loss 0.137046, acc 0.953125
2020-02-08T02:06:19.017142: step 1575, loss 0.059731, acc 0.984375
2020-02-08T02:06:19.213385: step 1576, loss 0.148243, acc 0.921875
2020-02-08T02:06:19.399127: step 1577, loss 0.119391, acc 0.9375
2020-02-08T02:06:19.576988: step 1578, loss 0.122062, acc 0.984375
2020-02-08T02:06:19.769473: step 1579, loss 0.0747192, acc 0.984375
2020-02-08T02:06:19.949515: step 1580, loss 0.126838, acc 0.953125
2020-02-08T02:06:20.139989: step 1581, loss 0.089592, acc 0.96875
2020-02-08T02:06:20.319419: step 1582, loss 0.163819, acc 0.9375
2020-02-08T02:06:20.507919: step 1583, loss 0.146423, acc 0.921875
2020-02-08T02:06:20.707268: step 1584, loss 0.11332, acc 0.953125
2020-02-08T02:06:20.890857: step 1585, loss 0.0737604, acc 0.96875
2020-02-08T02:06:21.133192: step 1586, loss 0.0602642, acc 0.96875
2020-02-08T02:06:21.335635: step 1587, loss 0.0984434, acc 0.953125
2020-02-08T02:06:21.557182: step 1588, loss 0.0654179, acc 0.984375
2020-02-08T02:06:21.768637: step 1589, loss 0.0835048, acc 0.953125
2020-02-08T02:06:21.982565: step 1590, loss 0.141396, acc 0.953125
2020-02-08T02:06:22.164913: step 1591, loss 0.175174, acc 0.90625
2020-02-08T02:06:22.341041: step 1592, loss 0.177278, acc 0.953125
2020-02-08T02:06:22.522031: step 1593, loss 0.0738388, acc 1
2020-02-08T02:06:22.716453: step 1594, loss 0.158295, acc 0.921875
2020-02-08T02:06:22.891755: step 1595, loss 0.213023, acc 0.890625
2020-02-08T02:06:23.084721: step 1596, loss 0.107007, acc 0.96875
2020-02-08T02:06:23.276517: step 1597, loss 0.0874607, acc 0.96875
2020-02-08T02:06:23.459600: step 1598, loss 0.122795, acc 0.9375
2020-02-08T02:06:23.643652: step 1599, loss 0.140117, acc 0.953125
2020-02-08T02:06:23.829923: step 1600, loss 0.075104, acc 0.984375

Evaluation:
2020-02-08T02:06:24.160352: step 1600, loss 0.660888, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1600

2020-02-08T02:06:25.734350: step 1601, loss 0.206668, acc 0.890625
2020-02-08T02:06:25.912597: step 1602, loss 0.124983, acc 0.9375
2020-02-08T02:06:26.095819: step 1603, loss 0.151416, acc 0.9375
2020-02-08T02:06:26.288074: step 1604, loss 0.214889, acc 0.90625
2020-02-08T02:06:26.484965: step 1605, loss 0.0600887, acc 0.984375
2020-02-08T02:06:26.677893: step 1606, loss 0.123653, acc 0.921875
2020-02-08T02:06:26.872913: step 1607, loss 0.115132, acc 0.96875
2020-02-08T02:06:27.067497: step 1608, loss 0.162821, acc 0.9375
2020-02-08T02:06:27.269295: step 1609, loss 0.106233, acc 0.96875
2020-02-08T02:06:27.456985: step 1610, loss 0.101647, acc 0.96875
2020-02-08T02:06:27.643757: step 1611, loss 0.205603, acc 0.890625
2020-02-08T02:06:27.839701: step 1612, loss 0.166645, acc 0.9375
2020-02-08T02:06:28.040599: step 1613, loss 0.103066, acc 0.96875
2020-02-08T02:06:28.223732: step 1614, loss 0.190421, acc 0.890625
2020-02-08T02:06:28.424794: step 1615, loss 0.196856, acc 0.9375
2020-02-08T02:06:28.638646: step 1616, loss 0.125664, acc 0.9375
2020-02-08T02:06:28.839993: step 1617, loss 0.0977332, acc 0.96875
2020-02-08T02:06:29.042776: step 1618, loss 0.0795079, acc 0.984375
2020-02-08T02:06:29.259339: step 1619, loss 0.311452, acc 0.890625
2020-02-08T02:06:29.450792: step 1620, loss 0.279327, acc 0.890625
2020-02-08T02:06:29.667528: step 1621, loss 0.154272, acc 0.953125
2020-02-08T02:06:29.867607: step 1622, loss 0.200235, acc 0.90625
2020-02-08T02:06:30.065303: step 1623, loss 0.0745381, acc 0.984375
2020-02-08T02:06:30.252581: step 1624, loss 0.169683, acc 0.9375
2020-02-08T02:06:30.456394: step 1625, loss 0.142553, acc 0.921875
2020-02-08T02:06:30.656986: step 1626, loss 0.0632098, acc 0.984375
2020-02-08T02:06:30.855248: step 1627, loss 0.219137, acc 0.9375
2020-02-08T02:06:31.052165: step 1628, loss 0.134013, acc 0.9375
2020-02-08T02:06:31.244952: step 1629, loss 0.09117, acc 0.96875
2020-02-08T02:06:31.442868: step 1630, loss 0.120504, acc 0.953125
2020-02-08T02:06:31.667994: step 1631, loss 0.190765, acc 0.921875
2020-02-08T02:06:31.870789: step 1632, loss 0.181608, acc 0.9375
2020-02-08T02:06:32.070486: step 1633, loss 0.199914, acc 0.953125
2020-02-08T02:06:32.259814: step 1634, loss 0.0937599, acc 0.984375
2020-02-08T02:06:32.449501: step 1635, loss 0.123905, acc 0.9375
2020-02-08T02:06:32.649188: step 1636, loss 0.242191, acc 0.875
2020-02-08T02:06:32.849700: step 1637, loss 0.26478, acc 0.9375
2020-02-08T02:06:33.041476: step 1638, loss 0.123959, acc 0.9375
2020-02-08T02:06:33.246897: step 1639, loss 0.197239, acc 0.90625
2020-02-08T02:06:33.453251: step 1640, loss 0.188352, acc 0.9375
2020-02-08T02:06:33.640525: step 1641, loss 0.1825, acc 0.90625
2020-02-08T02:06:33.823049: step 1642, loss 0.118204, acc 0.953125
2020-02-08T02:06:34.014507: step 1643, loss 0.143395, acc 0.953125
2020-02-08T02:06:34.202777: step 1644, loss 0.135309, acc 0.921875
2020-02-08T02:06:34.393940: step 1645, loss 0.158256, acc 0.953125
2020-02-08T02:06:34.605725: step 1646, loss 0.106946, acc 0.953125
2020-02-08T02:06:34.813890: step 1647, loss 0.158665, acc 0.921875
2020-02-08T02:06:35.011290: step 1648, loss 0.231638, acc 0.921875
2020-02-08T02:06:35.203697: step 1649, loss 0.138135, acc 0.953125
2020-02-08T02:06:35.392219: step 1650, loss 0.139402, acc 0.933333
2020-02-08T02:06:35.592157: step 1651, loss 0.0640386, acc 1
2020-02-08T02:06:35.792850: step 1652, loss 0.0769271, acc 0.984375
2020-02-08T02:06:35.987293: step 1653, loss 0.0937614, acc 0.96875
2020-02-08T02:06:36.177458: step 1654, loss 0.0754397, acc 1
2020-02-08T02:06:36.365715: step 1655, loss 0.121545, acc 0.96875
2020-02-08T02:06:36.578658: step 1656, loss 0.085833, acc 0.96875
2020-02-08T02:06:36.776199: step 1657, loss 0.106693, acc 0.96875
2020-02-08T02:06:36.973631: step 1658, loss 0.0549514, acc 0.96875
2020-02-08T02:06:37.165112: step 1659, loss 0.138592, acc 0.953125
2020-02-08T02:06:37.359825: step 1660, loss 0.0531223, acc 0.984375
2020-02-08T02:06:37.564659: step 1661, loss 0.096352, acc 0.9375
2020-02-08T02:06:37.756347: step 1662, loss 0.0857406, acc 0.984375
2020-02-08T02:06:37.951970: step 1663, loss 0.0772793, acc 0.96875
2020-02-08T02:06:38.156224: step 1664, loss 0.0414628, acc 1
2020-02-08T02:06:38.350346: step 1665, loss 0.0703781, acc 0.984375
2020-02-08T02:06:38.556488: step 1666, loss 0.127198, acc 0.953125
2020-02-08T02:06:38.766079: step 1667, loss 0.143849, acc 0.984375
2020-02-08T02:06:38.973679: step 1668, loss 0.126705, acc 0.953125
2020-02-08T02:06:39.194935: step 1669, loss 0.0611658, acc 1
2020-02-08T02:06:39.396400: step 1670, loss 0.11481, acc 0.984375
2020-02-08T02:06:39.603211: step 1671, loss 0.0697125, acc 0.96875
2020-02-08T02:06:39.802762: step 1672, loss 0.0710421, acc 1
2020-02-08T02:06:39.996709: step 1673, loss 0.115995, acc 0.953125
2020-02-08T02:06:40.195888: step 1674, loss 0.0715317, acc 0.984375
2020-02-08T02:06:40.393209: step 1675, loss 0.0822861, acc 0.984375
2020-02-08T02:06:40.579826: step 1676, loss 0.107979, acc 0.9375
2020-02-08T02:06:40.769169: step 1677, loss 0.0701063, acc 0.984375
2020-02-08T02:06:40.967853: step 1678, loss 0.132228, acc 0.9375
2020-02-08T02:06:41.152070: step 1679, loss 0.116234, acc 0.9375
2020-02-08T02:06:41.339866: step 1680, loss 0.237446, acc 0.859375
2020-02-08T02:06:41.601091: step 1681, loss 0.0521016, acc 0.984375
2020-02-08T02:06:41.800258: step 1682, loss 0.105648, acc 0.96875
2020-02-08T02:06:42.061764: step 1683, loss 0.0850525, acc 0.96875
2020-02-08T02:06:42.274912: step 1684, loss 0.0747836, acc 0.96875
2020-02-08T02:06:42.460324: step 1685, loss 0.201648, acc 0.890625
2020-02-08T02:06:42.648111: step 1686, loss 0.165214, acc 0.9375
2020-02-08T02:06:42.851103: step 1687, loss 0.108686, acc 0.96875
2020-02-08T02:06:43.029867: step 1688, loss 0.114927, acc 0.953125
2020-02-08T02:06:43.219964: step 1689, loss 0.109012, acc 0.953125
2020-02-08T02:06:43.410453: step 1690, loss 0.0853798, acc 0.984375
2020-02-08T02:06:43.605520: step 1691, loss 0.0717675, acc 0.96875
2020-02-08T02:06:43.855014: step 1692, loss 0.0647915, acc 1
2020-02-08T02:06:44.063702: step 1693, loss 0.103569, acc 0.96875
2020-02-08T02:06:44.247247: step 1694, loss 0.160808, acc 0.9375
2020-02-08T02:06:44.441880: step 1695, loss 0.0701172, acc 0.984375
2020-02-08T02:06:44.676322: step 1696, loss 0.0904479, acc 0.96875
2020-02-08T02:06:44.877058: step 1697, loss 0.0922175, acc 0.96875
2020-02-08T02:06:45.060083: step 1698, loss 0.103288, acc 0.96875
2020-02-08T02:06:45.264593: step 1699, loss 0.0667255, acc 0.984375
2020-02-08T02:06:45.485359: step 1700, loss 0.172401, acc 0.9375

Evaluation:
2020-02-08T02:06:45.803856: step 1700, loss 0.67852, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1700

2020-02-08T02:06:47.665373: step 1701, loss 0.100919, acc 0.953125
2020-02-08T02:06:47.869164: step 1702, loss 0.0817579, acc 0.96875
2020-02-08T02:06:48.110464: step 1703, loss 0.135241, acc 0.9375
2020-02-08T02:06:48.281620: step 1704, loss 0.14797, acc 0.953125
2020-02-08T02:06:48.466328: step 1705, loss 0.152445, acc 0.9375
2020-02-08T02:06:48.705720: step 1706, loss 0.111894, acc 0.96875
2020-02-08T02:06:48.910901: step 1707, loss 0.0634696, acc 1
2020-02-08T02:06:49.134535: step 1708, loss 0.123808, acc 0.953125
2020-02-08T02:06:49.352754: step 1709, loss 0.0729876, acc 0.984375
2020-02-08T02:06:49.549008: step 1710, loss 0.110316, acc 0.9375
2020-02-08T02:06:49.755357: step 1711, loss 0.159269, acc 0.9375
2020-02-08T02:06:49.998689: step 1712, loss 0.0980906, acc 0.96875
2020-02-08T02:06:50.220131: step 1713, loss 0.0856613, acc 0.953125
2020-02-08T02:06:50.419693: step 1714, loss 0.133377, acc 0.984375
2020-02-08T02:06:50.619035: step 1715, loss 0.15555, acc 0.96875
2020-02-08T02:06:50.837052: step 1716, loss 0.0876033, acc 1
2020-02-08T02:06:51.024131: step 1717, loss 0.134993, acc 0.9375
2020-02-08T02:06:51.261846: step 1718, loss 0.0762441, acc 0.96875
2020-02-08T02:06:51.523189: step 1719, loss 0.0929849, acc 0.953125
2020-02-08T02:06:51.768780: step 1720, loss 0.121576, acc 0.953125
2020-02-08T02:06:51.973568: step 1721, loss 0.102946, acc 0.953125
2020-02-08T02:06:52.175156: step 1722, loss 0.12358, acc 0.921875
2020-02-08T02:06:52.411968: step 1723, loss 0.105248, acc 0.96875
2020-02-08T02:06:52.620092: step 1724, loss 0.0667606, acc 0.984375
2020-02-08T02:06:52.810001: step 1725, loss 0.0792421, acc 0.96875
2020-02-08T02:06:53.036099: step 1726, loss 0.113777, acc 0.984375
2020-02-08T02:06:53.249237: step 1727, loss 0.0823685, acc 0.984375
2020-02-08T02:06:53.445366: step 1728, loss 0.0546859, acc 0.984375
2020-02-08T02:06:53.663058: step 1729, loss 0.122417, acc 0.953125
2020-02-08T02:06:53.867340: step 1730, loss 0.213557, acc 0.953125
2020-02-08T02:06:54.043198: step 1731, loss 0.0855092, acc 0.953125
2020-02-08T02:06:54.236765: step 1732, loss 0.0730066, acc 0.96875
2020-02-08T02:06:54.414953: step 1733, loss 0.132346, acc 0.953125
2020-02-08T02:06:54.600126: step 1734, loss 0.153524, acc 0.9375
2020-02-08T02:06:54.822418: step 1735, loss 0.129387, acc 0.921875
2020-02-08T02:06:55.051550: step 1736, loss 0.0810859, acc 0.96875
2020-02-08T02:06:55.261655: step 1737, loss 0.0576786, acc 0.984375
2020-02-08T02:06:55.440416: step 1738, loss 0.0547831, acc 0.96875
2020-02-08T02:06:55.648202: step 1739, loss 0.0731482, acc 0.96875
2020-02-08T02:06:55.842484: step 1740, loss 0.0532584, acc 0.984375
2020-02-08T02:06:56.038471: step 1741, loss 0.183336, acc 0.90625
2020-02-08T02:06:56.237974: step 1742, loss 0.176579, acc 0.921875
2020-02-08T02:06:56.424642: step 1743, loss 0.0810484, acc 0.96875
2020-02-08T02:06:56.609484: step 1744, loss 0.133834, acc 0.9375
2020-02-08T02:06:56.832295: step 1745, loss 0.0770181, acc 0.96875
2020-02-08T02:06:57.027653: step 1746, loss 0.184989, acc 0.9375
2020-02-08T02:06:57.227218: step 1747, loss 0.111516, acc 0.96875
2020-02-08T02:06:57.420751: step 1748, loss 0.102987, acc 0.9375
2020-02-08T02:06:57.632572: step 1749, loss 0.110985, acc 0.953125
2020-02-08T02:06:57.818346: step 1750, loss 0.12264, acc 0.96875
2020-02-08T02:06:58.007356: step 1751, loss 0.0729997, acc 0.96875
2020-02-08T02:06:58.217545: step 1752, loss 0.127427, acc 0.921875
2020-02-08T02:06:58.408570: step 1753, loss 0.0661342, acc 0.984375
2020-02-08T02:06:58.616326: step 1754, loss 0.106271, acc 0.953125
2020-02-08T02:06:58.817241: step 1755, loss 0.0730171, acc 0.96875
2020-02-08T02:06:59.003915: step 1756, loss 0.102896, acc 0.953125
2020-02-08T02:06:59.211637: step 1757, loss 0.105837, acc 0.96875
2020-02-08T02:06:59.410246: step 1758, loss 0.0885278, acc 0.96875
2020-02-08T02:06:59.606871: step 1759, loss 0.139392, acc 0.953125
2020-02-08T02:06:59.802045: step 1760, loss 0.037828, acc 1
2020-02-08T02:07:00.022393: step 1761, loss 0.0959072, acc 0.96875
2020-02-08T02:07:00.213232: step 1762, loss 0.131536, acc 0.96875
2020-02-08T02:07:00.409142: step 1763, loss 0.152099, acc 0.96875
2020-02-08T02:07:00.620015: step 1764, loss 0.0693517, acc 0.984375
2020-02-08T02:07:00.857830: step 1765, loss 0.0858423, acc 0.984375
2020-02-08T02:07:01.057633: step 1766, loss 0.0931096, acc 0.96875
2020-02-08T02:07:01.262139: step 1767, loss 0.139906, acc 0.921875
2020-02-08T02:07:01.475668: step 1768, loss 0.0918259, acc 0.953125
2020-02-08T02:07:01.741734: step 1769, loss 0.0794055, acc 0.96875
2020-02-08T02:07:01.982398: step 1770, loss 0.089503, acc 0.96875
2020-02-08T02:07:02.232904: step 1771, loss 0.128397, acc 0.9375
2020-02-08T02:07:02.436786: step 1772, loss 0.0811082, acc 0.953125
2020-02-08T02:07:02.663227: step 1773, loss 0.0906219, acc 0.953125
2020-02-08T02:07:02.940403: step 1774, loss 0.140509, acc 0.984375
2020-02-08T02:07:03.203963: step 1775, loss 0.120317, acc 0.9375
2020-02-08T02:07:03.423961: step 1776, loss 0.111306, acc 0.9375
2020-02-08T02:07:03.652038: step 1777, loss 0.0787775, acc 0.953125
2020-02-08T02:07:03.925894: step 1778, loss 0.133579, acc 0.953125
2020-02-08T02:07:04.158810: step 1779, loss 0.201708, acc 0.90625
2020-02-08T02:07:04.384678: step 1780, loss 0.0872773, acc 0.96875
2020-02-08T02:07:04.607405: step 1781, loss 0.064164, acc 0.984375
2020-02-08T02:07:04.853939: step 1782, loss 0.0434781, acc 1
2020-02-08T02:07:05.078308: step 1783, loss 0.0842334, acc 0.96875
2020-02-08T02:07:05.327999: step 1784, loss 0.0997071, acc 0.9375
2020-02-08T02:07:05.562148: step 1785, loss 0.133461, acc 0.96875
2020-02-08T02:07:05.814526: step 1786, loss 0.0883608, acc 0.9375
2020-02-08T02:07:06.059572: step 1787, loss 0.113174, acc 0.9375
2020-02-08T02:07:06.269781: step 1788, loss 0.116763, acc 0.96875
2020-02-08T02:07:06.496801: step 1789, loss 0.17952, acc 0.921875
2020-02-08T02:07:06.739925: step 1790, loss 0.10835, acc 0.953125
2020-02-08T02:07:06.940966: step 1791, loss 0.0999531, acc 0.953125
2020-02-08T02:07:07.172860: step 1792, loss 0.31125, acc 0.90625
2020-02-08T02:07:07.409903: step 1793, loss 0.100218, acc 0.953125
2020-02-08T02:07:07.647990: step 1794, loss 0.15643, acc 0.953125
2020-02-08T02:07:07.926512: step 1795, loss 0.206294, acc 0.90625
2020-02-08T02:07:08.159682: step 1796, loss 0.0956555, acc 0.953125
2020-02-08T02:07:08.424636: step 1797, loss 0.140166, acc 0.9375
2020-02-08T02:07:08.666108: step 1798, loss 0.112722, acc 0.953125
2020-02-08T02:07:08.909983: step 1799, loss 0.0799927, acc 0.984375
2020-02-08T02:07:09.126993: step 1800, loss 0.131526, acc 0.95

Evaluation:
2020-02-08T02:07:09.565711: step 1800, loss 0.709954, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1800

2020-02-08T02:07:11.608091: step 1801, loss 0.10427, acc 0.96875
2020-02-08T02:07:11.860631: step 1802, loss 0.0513, acc 1
2020-02-08T02:07:12.079472: step 1803, loss 0.056831, acc 0.984375
2020-02-08T02:07:12.315663: step 1804, loss 0.0513892, acc 0.984375
2020-02-08T02:07:12.529145: step 1805, loss 0.0723478, acc 0.984375
2020-02-08T02:07:12.768962: step 1806, loss 0.0927267, acc 0.96875
2020-02-08T02:07:13.007340: step 1807, loss 0.0753492, acc 0.953125
2020-02-08T02:07:13.231305: step 1808, loss 0.106392, acc 0.953125
2020-02-08T02:07:13.467403: step 1809, loss 0.0693015, acc 0.984375
2020-02-08T02:07:13.710528: step 1810, loss 0.0960832, acc 0.96875
2020-02-08T02:07:13.935356: step 1811, loss 0.0669041, acc 0.96875
2020-02-08T02:07:14.158758: step 1812, loss 0.0751261, acc 0.96875
2020-02-08T02:07:14.413275: step 1813, loss 0.0513417, acc 0.984375
2020-02-08T02:07:14.598207: step 1814, loss 0.0902759, acc 0.96875
2020-02-08T02:07:14.825049: step 1815, loss 0.039486, acc 1
2020-02-08T02:07:15.048391: step 1816, loss 0.0535073, acc 0.984375
2020-02-08T02:07:15.278053: step 1817, loss 0.0715199, acc 0.984375
2020-02-08T02:07:15.467261: step 1818, loss 0.083796, acc 0.96875
2020-02-08T02:07:15.690754: step 1819, loss 0.117413, acc 0.9375
2020-02-08T02:07:15.915171: step 1820, loss 0.0561087, acc 0.984375
2020-02-08T02:07:16.133950: step 1821, loss 0.0572328, acc 1
2020-02-08T02:07:16.364938: step 1822, loss 0.0720743, acc 0.984375
2020-02-08T02:07:16.580804: step 1823, loss 0.112982, acc 0.96875
2020-02-08T02:07:16.810103: step 1824, loss 0.0452761, acc 1
2020-02-08T02:07:17.028099: step 1825, loss 0.0563812, acc 0.984375
2020-02-08T02:07:17.246071: step 1826, loss 0.0960106, acc 0.953125
2020-02-08T02:07:17.476643: step 1827, loss 0.0716033, acc 0.96875
2020-02-08T02:07:17.699706: step 1828, loss 0.0665808, acc 1
2020-02-08T02:07:17.917668: step 1829, loss 0.0380075, acc 1
2020-02-08T02:07:18.135754: step 1830, loss 0.0587556, acc 0.984375
2020-02-08T02:07:18.312638: step 1831, loss 0.0501712, acc 0.984375
2020-02-08T02:07:18.546214: step 1832, loss 0.133709, acc 0.953125
2020-02-08T02:07:18.753493: step 1833, loss 0.031291, acc 1
2020-02-08T02:07:18.966102: step 1834, loss 0.0960633, acc 0.96875
2020-02-08T02:07:19.216896: step 1835, loss 0.0543112, acc 0.984375
2020-02-08T02:07:19.423209: step 1836, loss 0.166108, acc 0.953125
2020-02-08T02:07:19.655932: step 1837, loss 0.0751413, acc 0.984375
2020-02-08T02:07:19.820726: step 1838, loss 0.100443, acc 0.953125
2020-02-08T02:07:20.033232: step 1839, loss 0.0500991, acc 0.984375
2020-02-08T02:07:20.233191: step 1840, loss 0.101558, acc 0.953125
2020-02-08T02:07:20.437447: step 1841, loss 0.154156, acc 0.921875
2020-02-08T02:07:20.664211: step 1842, loss 0.0887951, acc 0.96875
2020-02-08T02:07:20.871089: step 1843, loss 0.238137, acc 0.90625
2020-02-08T02:07:21.103211: step 1844, loss 0.0827418, acc 0.96875
2020-02-08T02:07:21.322460: step 1845, loss 0.190495, acc 0.953125
2020-02-08T02:07:21.551560: step 1846, loss 0.0730474, acc 0.953125
2020-02-08T02:07:21.799880: step 1847, loss 0.138258, acc 0.953125
2020-02-08T02:07:22.016624: step 1848, loss 0.156754, acc 0.96875
2020-02-08T02:07:22.232699: step 1849, loss 0.104912, acc 0.953125
2020-02-08T02:07:22.449036: step 1850, loss 0.0457391, acc 0.96875
2020-02-08T02:07:22.661005: step 1851, loss 0.086101, acc 0.953125
2020-02-08T02:07:22.889452: step 1852, loss 0.0958742, acc 0.921875
2020-02-08T02:07:23.116120: step 1853, loss 0.0985455, acc 0.96875
2020-02-08T02:07:23.327923: step 1854, loss 0.107588, acc 0.96875
2020-02-08T02:07:23.555883: step 1855, loss 0.0931813, acc 0.953125
2020-02-08T02:07:23.801640: step 1856, loss 0.170298, acc 0.921875
2020-02-08T02:07:24.050007: step 1857, loss 0.0717379, acc 0.96875
2020-02-08T02:07:24.226001: step 1858, loss 0.107198, acc 0.953125
2020-02-08T02:07:24.452612: step 1859, loss 0.0728811, acc 0.96875
2020-02-08T02:07:24.687927: step 1860, loss 0.0499639, acc 0.984375
2020-02-08T02:07:24.902914: step 1861, loss 0.156767, acc 0.921875
2020-02-08T02:07:25.135544: step 1862, loss 0.122014, acc 0.953125
2020-02-08T02:07:25.353215: step 1863, loss 0.117649, acc 0.953125
2020-02-08T02:07:25.585354: step 1864, loss 0.145279, acc 0.921875
2020-02-08T02:07:25.802930: step 1865, loss 0.0555353, acc 0.984375
2020-02-08T02:07:26.015904: step 1866, loss 0.115917, acc 0.96875
2020-02-08T02:07:26.234248: step 1867, loss 0.0431943, acc 0.984375
2020-02-08T02:07:26.458453: step 1868, loss 0.122242, acc 0.953125
2020-02-08T02:07:26.689459: step 1869, loss 0.127162, acc 0.953125
2020-02-08T02:07:26.910322: step 1870, loss 0.0421516, acc 0.984375
2020-02-08T02:07:27.136095: step 1871, loss 0.0557026, acc 0.984375
2020-02-08T02:07:27.358483: step 1872, loss 0.0516248, acc 1
2020-02-08T02:07:27.582333: step 1873, loss 0.0782946, acc 0.96875
2020-02-08T02:07:27.806946: step 1874, loss 0.0777193, acc 0.984375
2020-02-08T02:07:28.041393: step 1875, loss 0.0586996, acc 0.984375
2020-02-08T02:07:28.240666: step 1876, loss 0.0906683, acc 0.984375
2020-02-08T02:07:28.455414: step 1877, loss 0.103711, acc 0.9375
2020-02-08T02:07:28.672061: step 1878, loss 0.0655165, acc 0.984375
2020-02-08T02:07:28.904958: step 1879, loss 0.0752345, acc 0.96875
2020-02-08T02:07:29.152066: step 1880, loss 0.122195, acc 0.9375
2020-02-08T02:07:29.364355: step 1881, loss 0.113412, acc 0.921875
2020-02-08T02:07:29.592155: step 1882, loss 0.112502, acc 0.96875
2020-02-08T02:07:29.816867: step 1883, loss 0.0450679, acc 1
2020-02-08T02:07:30.050923: step 1884, loss 0.0760366, acc 0.96875
2020-02-08T02:07:30.268863: step 1885, loss 0.0845473, acc 0.96875
2020-02-08T02:07:30.508562: step 1886, loss 0.118068, acc 0.96875
2020-02-08T02:07:30.747151: step 1887, loss 0.056196, acc 0.96875
2020-02-08T02:07:30.976265: step 1888, loss 0.0468774, acc 0.984375
2020-02-08T02:07:31.209627: step 1889, loss 0.0573714, acc 0.984375
2020-02-08T02:07:31.434468: step 1890, loss 0.0635764, acc 0.984375
2020-02-08T02:07:31.657658: step 1891, loss 0.0782496, acc 0.953125
2020-02-08T02:07:31.849650: step 1892, loss 0.0343086, acc 1
2020-02-08T02:07:32.062456: step 1893, loss 0.0679291, acc 0.96875
2020-02-08T02:07:32.260413: step 1894, loss 0.0645073, acc 0.984375
2020-02-08T02:07:32.477819: step 1895, loss 0.0593208, acc 0.984375
2020-02-08T02:07:32.719776: step 1896, loss 0.0799256, acc 0.984375
2020-02-08T02:07:32.954217: step 1897, loss 0.0631283, acc 0.96875
2020-02-08T02:07:33.175941: step 1898, loss 0.0799613, acc 0.953125
2020-02-08T02:07:33.387817: step 1899, loss 0.107586, acc 0.96875
2020-02-08T02:07:33.606829: step 1900, loss 0.0762404, acc 0.96875

Evaluation:
2020-02-08T02:07:34.031110: step 1900, loss 0.724307, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-1900

2020-02-08T02:07:35.770172: step 1901, loss 0.0459241, acc 0.984375
2020-02-08T02:07:35.991191: step 1902, loss 0.0481431, acc 1
2020-02-08T02:07:36.208943: step 1903, loss 0.202787, acc 0.90625
2020-02-08T02:07:36.438416: step 1904, loss 0.0219811, acc 1
2020-02-08T02:07:36.673297: step 1905, loss 0.0772845, acc 0.984375
2020-02-08T02:07:36.897416: step 1906, loss 0.122642, acc 0.953125
2020-02-08T02:07:37.108960: step 1907, loss 0.0916641, acc 0.96875
2020-02-08T02:07:37.336636: step 1908, loss 0.100514, acc 0.984375
2020-02-08T02:07:37.552231: step 1909, loss 0.0751399, acc 0.96875
2020-02-08T02:07:37.791713: step 1910, loss 0.198704, acc 0.9375
2020-02-08T02:07:37.990022: step 1911, loss 0.0668076, acc 0.984375
2020-02-08T02:07:38.186726: step 1912, loss 0.0850293, acc 0.953125
2020-02-08T02:07:38.410763: step 1913, loss 0.0928129, acc 0.953125
2020-02-08T02:07:38.660944: step 1914, loss 0.0391029, acc 1
2020-02-08T02:07:38.827933: step 1915, loss 0.094606, acc 0.953125
2020-02-08T02:07:39.054305: step 1916, loss 0.0378507, acc 1
2020-02-08T02:07:39.266462: step 1917, loss 0.109187, acc 0.984375
2020-02-08T02:07:39.467391: step 1918, loss 0.109558, acc 0.953125
2020-02-08T02:07:39.672694: step 1919, loss 0.147588, acc 0.9375
2020-02-08T02:07:39.881186: step 1920, loss 0.0692853, acc 0.96875
2020-02-08T02:07:40.098050: step 1921, loss 0.0688952, acc 0.953125
2020-02-08T02:07:40.316905: step 1922, loss 0.0799731, acc 0.953125
2020-02-08T02:07:40.525066: step 1923, loss 0.0661986, acc 0.984375
2020-02-08T02:07:40.747887: step 1924, loss 0.0560411, acc 0.96875
2020-02-08T02:07:40.966222: step 1925, loss 0.0429848, acc 0.984375
2020-02-08T02:07:41.179885: step 1926, loss 0.144165, acc 0.953125
2020-02-08T02:07:41.396605: step 1927, loss 0.0982975, acc 0.96875
2020-02-08T02:07:41.612384: step 1928, loss 0.0633167, acc 0.984375
2020-02-08T02:07:41.844753: step 1929, loss 0.0964093, acc 0.953125
2020-02-08T02:07:42.068098: step 1930, loss 0.0606258, acc 0.984375
2020-02-08T02:07:42.285407: step 1931, loss 0.133189, acc 0.96875
2020-02-08T02:07:42.531302: step 1932, loss 0.124789, acc 0.96875
2020-02-08T02:07:42.797569: step 1933, loss 0.112539, acc 0.9375
2020-02-08T02:07:43.045503: step 1934, loss 0.105105, acc 0.921875
2020-02-08T02:07:43.296008: step 1935, loss 0.0627243, acc 0.984375
2020-02-08T02:07:43.516976: step 1936, loss 0.0683723, acc 0.984375
2020-02-08T02:07:43.728819: step 1937, loss 0.0847463, acc 0.953125
2020-02-08T02:07:43.948041: step 1938, loss 0.055687, acc 1
2020-02-08T02:07:44.175755: step 1939, loss 0.0648995, acc 0.96875
2020-02-08T02:07:44.410487: step 1940, loss 0.129822, acc 0.96875
2020-02-08T02:07:44.661663: step 1941, loss 0.0558884, acc 0.96875
2020-02-08T02:07:44.896350: step 1942, loss 0.0748152, acc 0.96875
2020-02-08T02:07:45.135647: step 1943, loss 0.0893452, acc 0.96875
2020-02-08T02:07:45.377653: step 1944, loss 0.124703, acc 0.96875
2020-02-08T02:07:45.602417: step 1945, loss 0.0244597, acc 1
2020-02-08T02:07:45.846940: step 1946, loss 0.0927316, acc 0.984375
2020-02-08T02:07:46.097770: step 1947, loss 0.131805, acc 0.953125
2020-02-08T02:07:46.340746: step 1948, loss 0.0965169, acc 0.96875
2020-02-08T02:07:46.580915: step 1949, loss 0.0920187, acc 0.96875
2020-02-08T02:07:46.827968: step 1950, loss 0.130763, acc 0.95
2020-02-08T02:07:47.083546: step 1951, loss 0.0550662, acc 0.984375
2020-02-08T02:07:47.314995: step 1952, loss 0.113261, acc 0.96875
2020-02-08T02:07:47.546120: step 1953, loss 0.0662444, acc 0.96875
2020-02-08T02:07:47.792387: step 1954, loss 0.0390563, acc 0.984375
2020-02-08T02:07:47.998707: step 1955, loss 0.0166491, acc 1
2020-02-08T02:07:48.232905: step 1956, loss 0.0318075, acc 1
2020-02-08T02:07:48.482315: step 1957, loss 0.0500714, acc 0.96875
2020-02-08T02:07:48.730042: step 1958, loss 0.044723, acc 1
2020-02-08T02:07:48.996025: step 1959, loss 0.049226, acc 1
2020-02-08T02:07:49.246872: step 1960, loss 0.104431, acc 0.9375
2020-02-08T02:07:49.480356: step 1961, loss 0.0337155, acc 1
2020-02-08T02:07:49.718009: step 1962, loss 0.0431525, acc 0.984375
2020-02-08T02:07:49.951921: step 1963, loss 0.0244426, acc 1
2020-02-08T02:07:50.196876: step 1964, loss 0.0424104, acc 1
2020-02-08T02:07:50.419212: step 1965, loss 0.0946397, acc 0.9375
2020-02-08T02:07:50.683649: step 1966, loss 0.0572148, acc 0.984375
2020-02-08T02:07:50.893270: step 1967, loss 0.0802861, acc 0.984375
2020-02-08T02:07:51.134320: step 1968, loss 0.0413469, acc 1
2020-02-08T02:07:51.367092: step 1969, loss 0.0385048, acc 1
2020-02-08T02:07:51.620240: step 1970, loss 0.0645187, acc 0.984375
2020-02-08T02:07:51.846811: step 1971, loss 0.051381, acc 1
2020-02-08T02:07:52.115205: step 1972, loss 0.0641164, acc 0.96875
2020-02-08T02:07:52.334552: step 1973, loss 0.0461641, acc 0.984375
2020-02-08T02:07:52.554227: step 1974, loss 0.0293114, acc 0.984375
2020-02-08T02:07:52.768288: step 1975, loss 0.0369641, acc 1
2020-02-08T02:07:52.984143: step 1976, loss 0.0573799, acc 0.984375
2020-02-08T02:07:53.215033: step 1977, loss 0.0916858, acc 0.953125
2020-02-08T02:07:53.427716: step 1978, loss 0.0219401, acc 1
2020-02-08T02:07:53.660534: step 1979, loss 0.116771, acc 0.953125
2020-02-08T02:07:53.886363: step 1980, loss 0.0792596, acc 0.96875
2020-02-08T02:07:54.103597: step 1981, loss 0.0643454, acc 0.96875
2020-02-08T02:07:54.318216: step 1982, loss 0.0398243, acc 1
2020-02-08T02:07:54.564362: step 1983, loss 0.0808321, acc 0.984375
2020-02-08T02:07:54.767255: step 1984, loss 0.0571637, acc 0.984375
2020-02-08T02:07:54.983852: step 1985, loss 0.0750507, acc 0.984375
2020-02-08T02:07:55.223727: step 1986, loss 0.0768571, acc 0.984375
2020-02-08T02:07:55.451237: step 1987, loss 0.0605087, acc 0.984375
2020-02-08T02:07:55.648294: step 1988, loss 0.067957, acc 0.96875
2020-02-08T02:07:55.869866: step 1989, loss 0.0325102, acc 0.984375
2020-02-08T02:07:56.103016: step 1990, loss 0.0313703, acc 1
2020-02-08T02:07:56.333214: step 1991, loss 0.0824661, acc 0.953125
2020-02-08T02:07:56.552725: step 1992, loss 0.0659856, acc 0.984375
2020-02-08T02:07:56.735927: step 1993, loss 0.0544364, acc 0.984375
2020-02-08T02:07:56.950897: step 1994, loss 0.0350704, acc 1
2020-02-08T02:07:57.164877: step 1995, loss 0.0461266, acc 1
2020-02-08T02:07:57.397150: step 1996, loss 0.0421584, acc 0.984375
2020-02-08T02:07:57.606493: step 1997, loss 0.0339966, acc 0.984375
2020-02-08T02:07:57.857451: step 1998, loss 0.0767546, acc 0.96875
2020-02-08T02:07:58.142867: step 1999, loss 0.0511757, acc 0.984375
2020-02-08T02:07:58.400098: step 2000, loss 0.0573484, acc 1

Evaluation:
2020-02-08T02:07:58.830892: step 2000, loss 0.777712, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2000

2020-02-08T02:08:00.585297: step 2001, loss 0.0632767, acc 0.984375
2020-02-08T02:08:00.789191: step 2002, loss 0.101034, acc 0.953125
2020-02-08T02:08:01.033029: step 2003, loss 0.0781132, acc 0.953125
2020-02-08T02:08:01.241303: step 2004, loss 0.0415795, acc 0.984375
2020-02-08T02:08:01.483407: step 2005, loss 0.02971, acc 1
2020-02-08T02:08:01.741312: step 2006, loss 0.0378847, acc 0.984375
2020-02-08T02:08:01.975994: step 2007, loss 0.0954058, acc 0.984375
2020-02-08T02:08:02.210309: step 2008, loss 0.0743941, acc 0.96875
2020-02-08T02:08:02.464994: step 2009, loss 0.0499519, acc 0.984375
2020-02-08T02:08:02.693011: step 2010, loss 0.0393927, acc 1
2020-02-08T02:08:02.991027: step 2011, loss 0.0284911, acc 1
2020-02-08T02:08:03.272257: step 2012, loss 0.0834318, acc 0.96875
2020-02-08T02:08:03.555230: step 2013, loss 0.064044, acc 0.984375
2020-02-08T02:08:03.781645: step 2014, loss 0.0771255, acc 0.953125
2020-02-08T02:08:04.021465: step 2015, loss 0.0585961, acc 1
2020-02-08T02:08:04.256888: step 2016, loss 0.108806, acc 0.96875
2020-02-08T02:08:04.474577: step 2017, loss 0.152894, acc 0.921875
2020-02-08T02:08:04.709848: step 2018, loss 0.0261857, acc 1
2020-02-08T02:08:04.938519: step 2019, loss 0.0270483, acc 0.984375
2020-02-08T02:08:05.186969: step 2020, loss 0.049836, acc 1
2020-02-08T02:08:05.399972: step 2021, loss 0.0645077, acc 0.96875
2020-02-08T02:08:05.620344: step 2022, loss 0.0565548, acc 0.984375
2020-02-08T02:08:05.878728: step 2023, loss 0.0411629, acc 1
2020-02-08T02:08:06.092571: step 2024, loss 0.0416746, acc 1
2020-02-08T02:08:06.342570: step 2025, loss 0.064788, acc 0.96875
2020-02-08T02:08:06.608814: step 2026, loss 0.128975, acc 0.953125
2020-02-08T02:08:06.838062: step 2027, loss 0.0452354, acc 0.984375
2020-02-08T02:08:07.060492: step 2028, loss 0.0696403, acc 0.96875
2020-02-08T02:08:07.334282: step 2029, loss 0.0487552, acc 0.984375
2020-02-08T02:08:07.541127: step 2030, loss 0.0795931, acc 0.96875
2020-02-08T02:08:07.788303: step 2031, loss 0.0346799, acc 0.984375
2020-02-08T02:08:08.004404: step 2032, loss 0.0574018, acc 0.984375
2020-02-08T02:08:08.255320: step 2033, loss 0.0847998, acc 0.953125
2020-02-08T02:08:08.485958: step 2034, loss 0.0618723, acc 0.96875
2020-02-08T02:08:08.706757: step 2035, loss 0.0422274, acc 1
2020-02-08T02:08:08.954255: step 2036, loss 0.0328137, acc 1
2020-02-08T02:08:09.184979: step 2037, loss 0.0513042, acc 0.984375
2020-02-08T02:08:09.391851: step 2038, loss 0.0503111, acc 0.984375
2020-02-08T02:08:09.662650: step 2039, loss 0.0436415, acc 1
2020-02-08T02:08:09.897668: step 2040, loss 0.0839956, acc 0.984375
2020-02-08T02:08:10.111621: step 2041, loss 0.0469606, acc 0.984375
2020-02-08T02:08:10.343574: step 2042, loss 0.0905654, acc 0.9375
2020-02-08T02:08:10.564301: step 2043, loss 0.0493906, acc 0.984375
2020-02-08T02:08:10.742755: step 2044, loss 0.0578793, acc 0.96875
2020-02-08T02:08:10.932613: step 2045, loss 0.0570316, acc 0.984375
2020-02-08T02:08:11.178729: step 2046, loss 0.0281551, acc 1
2020-02-08T02:08:11.375391: step 2047, loss 0.0352803, acc 1
2020-02-08T02:08:11.590981: step 2048, loss 0.0733662, acc 0.96875
2020-02-08T02:08:11.832049: step 2049, loss 0.0529367, acc 0.984375
2020-02-08T02:08:12.046171: step 2050, loss 0.0491803, acc 0.96875
2020-02-08T02:08:12.256846: step 2051, loss 0.127254, acc 0.96875
2020-02-08T02:08:12.490351: step 2052, loss 0.0708227, acc 0.96875
2020-02-08T02:08:12.741057: step 2053, loss 0.163987, acc 0.921875
2020-02-08T02:08:12.978687: step 2054, loss 0.0180645, acc 1
2020-02-08T02:08:13.181552: step 2055, loss 0.0210251, acc 1
2020-02-08T02:08:13.395211: step 2056, loss 0.0540117, acc 0.984375
2020-02-08T02:08:13.619776: step 2057, loss 0.0770913, acc 0.96875
2020-02-08T02:08:13.827458: step 2058, loss 0.0611559, acc 0.984375
2020-02-08T02:08:14.064764: step 2059, loss 0.0690135, acc 0.953125
2020-02-08T02:08:14.299434: step 2060, loss 0.108039, acc 0.984375
2020-02-08T02:08:14.509017: step 2061, loss 0.0306076, acc 1
2020-02-08T02:08:14.725506: step 2062, loss 0.0372849, acc 0.984375
2020-02-08T02:08:14.961199: step 2063, loss 0.0520414, acc 0.96875
2020-02-08T02:08:15.143707: step 2064, loss 0.0760547, acc 0.96875
2020-02-08T02:08:15.341773: step 2065, loss 0.0345257, acc 1
2020-02-08T02:08:15.572762: step 2066, loss 0.105818, acc 0.953125
2020-02-08T02:08:15.765758: step 2067, loss 0.0357621, acc 1
2020-02-08T02:08:15.958920: step 2068, loss 0.0531914, acc 0.96875
2020-02-08T02:08:16.191734: step 2069, loss 0.0919316, acc 0.953125
2020-02-08T02:08:16.424766: step 2070, loss 0.112336, acc 0.953125
2020-02-08T02:08:16.646647: step 2071, loss 0.0504262, acc 0.984375
2020-02-08T02:08:16.862769: step 2072, loss 0.0324554, acc 1
2020-02-08T02:08:17.111350: step 2073, loss 0.127509, acc 0.9375
2020-02-08T02:08:17.346003: step 2074, loss 0.0508518, acc 0.984375
2020-02-08T02:08:17.574156: step 2075, loss 0.0929118, acc 0.953125
2020-02-08T02:08:17.791468: step 2076, loss 0.0251131, acc 1
2020-02-08T02:08:17.992154: step 2077, loss 0.0251357, acc 1
2020-02-08T02:08:18.208469: step 2078, loss 0.0876135, acc 0.9375
2020-02-08T02:08:18.431727: step 2079, loss 0.0719053, acc 0.984375
2020-02-08T02:08:18.663798: step 2080, loss 0.135004, acc 0.953125
2020-02-08T02:08:18.931618: step 2081, loss 0.105232, acc 0.96875
2020-02-08T02:08:19.163888: step 2082, loss 0.0585444, acc 0.984375
2020-02-08T02:08:19.386233: step 2083, loss 0.053331, acc 0.96875
2020-02-08T02:08:19.626508: step 2084, loss 0.0840902, acc 0.96875
2020-02-08T02:08:19.880465: step 2085, loss 0.0660435, acc 0.984375
2020-02-08T02:08:20.096259: step 2086, loss 0.081428, acc 0.96875
2020-02-08T02:08:20.300524: step 2087, loss 0.0418781, acc 0.96875
2020-02-08T02:08:20.499591: step 2088, loss 0.062409, acc 0.96875
2020-02-08T02:08:20.722099: step 2089, loss 0.0684466, acc 0.96875
2020-02-08T02:08:20.945611: step 2090, loss 0.116117, acc 0.953125
2020-02-08T02:08:21.151016: step 2091, loss 0.0358561, acc 0.984375
2020-02-08T02:08:21.392014: step 2092, loss 0.024879, acc 1
2020-02-08T02:08:21.702037: step 2093, loss 0.0601165, acc 0.984375
2020-02-08T02:08:21.930711: step 2094, loss 0.168946, acc 0.953125
2020-02-08T02:08:22.141443: step 2095, loss 0.0891617, acc 0.953125
2020-02-08T02:08:22.466175: step 2096, loss 0.120804, acc 0.953125
2020-02-08T02:08:22.800440: step 2097, loss 0.1428, acc 0.953125
2020-02-08T02:08:23.071771: step 2098, loss 0.0882668, acc 0.96875
2020-02-08T02:08:23.341362: step 2099, loss 0.0938773, acc 0.984375
2020-02-08T02:08:23.575047: step 2100, loss 0.124625, acc 0.966667

Evaluation:
2020-02-08T02:08:24.156797: step 2100, loss 0.791811, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2100

2020-02-08T02:08:25.972263: step 2101, loss 0.0598294, acc 0.984375
2020-02-08T02:08:26.254204: step 2102, loss 0.029466, acc 1
2020-02-08T02:08:26.547870: step 2103, loss 0.038488, acc 1
2020-02-08T02:08:26.811531: step 2104, loss 0.016577, acc 1
2020-02-08T02:08:27.071570: step 2105, loss 0.0241522, acc 1
2020-02-08T02:08:27.335132: step 2106, loss 0.0410266, acc 0.984375
2020-02-08T02:08:27.551067: step 2107, loss 0.055131, acc 0.984375
2020-02-08T02:08:27.770416: step 2108, loss 0.0800643, acc 0.96875
2020-02-08T02:08:28.053695: step 2109, loss 0.029592, acc 1
2020-02-08T02:08:28.322849: step 2110, loss 0.0195665, acc 1
2020-02-08T02:08:28.601510: step 2111, loss 0.0273654, acc 1
2020-02-08T02:08:28.824600: step 2112, loss 0.0494329, acc 0.984375
2020-02-08T02:08:29.018572: step 2113, loss 0.03651, acc 0.984375
2020-02-08T02:08:29.299940: step 2114, loss 0.0844778, acc 0.96875
2020-02-08T02:08:29.569730: step 2115, loss 0.087084, acc 0.96875
2020-02-08T02:08:29.840897: step 2116, loss 0.0472619, acc 0.984375
2020-02-08T02:08:30.100851: step 2117, loss 0.0430661, acc 1
2020-02-08T02:08:30.253258: step 2118, loss 0.0651235, acc 0.984375
2020-02-08T02:08:30.497553: step 2119, loss 0.078129, acc 0.96875
2020-02-08T02:08:30.704487: step 2120, loss 0.109312, acc 0.9375
2020-02-08T02:08:30.932375: step 2121, loss 0.0369161, acc 0.984375
2020-02-08T02:08:31.155549: step 2122, loss 0.0204791, acc 1
2020-02-08T02:08:31.409095: step 2123, loss 0.0389188, acc 1
2020-02-08T02:08:31.640461: step 2124, loss 0.0162683, acc 1
2020-02-08T02:08:31.883082: step 2125, loss 0.0416152, acc 0.984375
2020-02-08T02:08:32.122868: step 2126, loss 0.0514168, acc 0.984375
2020-02-08T02:08:32.353223: step 2127, loss 0.0530398, acc 0.984375
2020-02-08T02:08:32.602769: step 2128, loss 0.03271, acc 1
2020-02-08T02:08:32.820061: step 2129, loss 0.0224925, acc 1
2020-02-08T02:08:33.063614: step 2130, loss 0.0352718, acc 1
2020-02-08T02:08:33.306145: step 2131, loss 0.0573109, acc 0.96875
2020-02-08T02:08:33.558191: step 2132, loss 0.0496429, acc 0.96875
2020-02-08T02:08:33.839755: step 2133, loss 0.0174422, acc 1
2020-02-08T02:08:34.025028: step 2134, loss 0.0323231, acc 1
2020-02-08T02:08:34.273573: step 2135, loss 0.0721573, acc 0.984375
2020-02-08T02:08:34.542804: step 2136, loss 0.045474, acc 0.984375
2020-02-08T02:08:34.773226: step 2137, loss 0.0547342, acc 0.984375
2020-02-08T02:08:35.067992: step 2138, loss 0.0775556, acc 0.96875
2020-02-08T02:08:35.326226: step 2139, loss 0.0946721, acc 0.96875
2020-02-08T02:08:35.606123: step 2140, loss 0.0391739, acc 1
2020-02-08T02:08:35.865882: step 2141, loss 0.0295726, acc 1
2020-02-08T02:08:36.122041: step 2142, loss 0.0408898, acc 0.984375
2020-02-08T02:08:36.388685: step 2143, loss 0.128131, acc 0.9375
2020-02-08T02:08:36.659039: step 2144, loss 0.0249176, acc 1
2020-02-08T02:08:36.933945: step 2145, loss 0.077548, acc 0.96875
2020-02-08T02:08:37.204047: step 2146, loss 0.0640827, acc 0.96875
2020-02-08T02:08:37.449464: step 2147, loss 0.10411, acc 0.9375
2020-02-08T02:08:37.716370: step 2148, loss 0.0399944, acc 0.984375
2020-02-08T02:08:37.989465: step 2149, loss 0.0308258, acc 1
2020-02-08T02:08:38.245344: step 2150, loss 0.0188331, acc 1
2020-02-08T02:08:38.470193: step 2151, loss 0.044443, acc 0.984375
2020-02-08T02:08:38.724250: step 2152, loss 0.0475245, acc 0.984375
2020-02-08T02:08:38.901347: step 2153, loss 0.0807351, acc 0.953125
2020-02-08T02:08:39.191886: step 2154, loss 0.0473636, acc 0.984375
2020-02-08T02:08:39.428471: step 2155, loss 0.108516, acc 0.9375
2020-02-08T02:08:39.680893: step 2156, loss 0.115166, acc 0.9375
2020-02-08T02:08:39.953899: step 2157, loss 0.0326095, acc 1
2020-02-08T02:08:40.207702: step 2158, loss 0.0501983, acc 0.984375
2020-02-08T02:08:40.473152: step 2159, loss 0.0740134, acc 0.984375
2020-02-08T02:08:40.729764: step 2160, loss 0.0764104, acc 0.953125
2020-02-08T02:08:40.927530: step 2161, loss 0.0253766, acc 1
2020-02-08T02:08:41.175499: step 2162, loss 0.042985, acc 0.984375
2020-02-08T02:08:41.400004: step 2163, loss 0.106974, acc 0.96875
2020-02-08T02:08:41.655802: step 2164, loss 0.0311224, acc 1
2020-02-08T02:08:41.875674: step 2165, loss 0.0280566, acc 1
2020-02-08T02:08:42.131921: step 2166, loss 0.0662911, acc 0.984375
2020-02-08T02:08:42.403255: step 2167, loss 0.0316672, acc 1
2020-02-08T02:08:42.631125: step 2168, loss 0.0351343, acc 0.96875
2020-02-08T02:08:42.873343: step 2169, loss 0.0113274, acc 1
2020-02-08T02:08:43.130315: step 2170, loss 0.0738385, acc 0.96875
2020-02-08T02:08:43.360827: step 2171, loss 0.0522267, acc 0.96875
2020-02-08T02:08:43.598593: step 2172, loss 0.035286, acc 0.984375
2020-02-08T02:08:43.822911: step 2173, loss 0.0406409, acc 0.984375
2020-02-08T02:08:44.023453: step 2174, loss 0.0812292, acc 0.96875
2020-02-08T02:08:44.224984: step 2175, loss 0.0474944, acc 0.984375
2020-02-08T02:08:44.432885: step 2176, loss 0.0457268, acc 0.984375
2020-02-08T02:08:44.655139: step 2177, loss 0.0791842, acc 0.96875
2020-02-08T02:08:44.871073: step 2178, loss 0.0688125, acc 0.96875
2020-02-08T02:08:45.080338: step 2179, loss 0.0319047, acc 0.984375
2020-02-08T02:08:45.316514: step 2180, loss 0.0277286, acc 1
2020-02-08T02:08:45.524190: step 2181, loss 0.0423914, acc 0.984375
2020-02-08T02:08:45.740360: step 2182, loss 0.088182, acc 0.96875
2020-02-08T02:08:45.959679: step 2183, loss 0.095952, acc 0.96875
2020-02-08T02:08:46.159704: step 2184, loss 0.0360534, acc 1
2020-02-08T02:08:46.378738: step 2185, loss 0.0274354, acc 1
2020-02-08T02:08:46.597240: step 2186, loss 0.0340642, acc 0.984375
2020-02-08T02:08:46.872626: step 2187, loss 0.0741403, acc 0.984375
2020-02-08T02:08:47.055754: step 2188, loss 0.0420336, acc 0.984375
2020-02-08T02:08:47.274264: step 2189, loss 0.039723, acc 0.984375
2020-02-08T02:08:47.492243: step 2190, loss 0.0537804, acc 0.96875
2020-02-08T02:08:47.674380: step 2191, loss 0.0776796, acc 0.96875
2020-02-08T02:08:47.884378: step 2192, loss 0.0425176, acc 1
2020-02-08T02:08:48.117470: step 2193, loss 0.11247, acc 0.984375
2020-02-08T02:08:48.358600: step 2194, loss 0.0370156, acc 0.984375
2020-02-08T02:08:48.597279: step 2195, loss 0.0536649, acc 0.96875
2020-02-08T02:08:48.822443: step 2196, loss 0.0811915, acc 0.96875
2020-02-08T02:08:49.068102: step 2197, loss 0.057136, acc 0.96875
2020-02-08T02:08:49.293386: step 2198, loss 0.0636748, acc 0.96875
2020-02-08T02:08:49.513142: step 2199, loss 0.0231984, acc 1
2020-02-08T02:08:49.749731: step 2200, loss 0.0440648, acc 0.984375

Evaluation:
2020-02-08T02:08:50.163304: step 2200, loss 0.845699, acc 0.726079

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2200

2020-02-08T02:08:51.916440: step 2201, loss 0.024948, acc 0.984375
2020-02-08T02:08:52.165641: step 2202, loss 0.0585897, acc 0.984375
2020-02-08T02:08:52.376008: step 2203, loss 0.0980741, acc 0.953125
2020-02-08T02:08:52.585884: step 2204, loss 0.0615311, acc 0.984375
2020-02-08T02:08:52.814725: step 2205, loss 0.0431446, acc 0.984375
2020-02-08T02:08:53.050706: step 2206, loss 0.0444677, acc 0.984375
2020-02-08T02:08:53.293646: step 2207, loss 0.0281032, acc 1
2020-02-08T02:08:53.511497: step 2208, loss 0.0743183, acc 0.96875
2020-02-08T02:08:53.731852: step 2209, loss 0.0285262, acc 1
2020-02-08T02:08:53.951963: step 2210, loss 0.0688641, acc 0.96875
2020-02-08T02:08:54.177596: step 2211, loss 0.0971091, acc 0.96875
2020-02-08T02:08:54.411269: step 2212, loss 0.0711152, acc 0.953125
2020-02-08T02:08:54.648062: step 2213, loss 0.0502424, acc 0.984375
2020-02-08T02:08:54.833216: step 2214, loss 0.0204153, acc 1
2020-02-08T02:08:55.058663: step 2215, loss 0.0603396, acc 0.984375
2020-02-08T02:08:55.269298: step 2216, loss 0.0264309, acc 1
2020-02-08T02:08:55.497003: step 2217, loss 0.0501791, acc 0.984375
2020-02-08T02:08:55.676386: step 2218, loss 0.0596781, acc 0.953125
2020-02-08T02:08:55.896979: step 2219, loss 0.0163493, acc 1
2020-02-08T02:08:56.103014: step 2220, loss 0.0277616, acc 1
2020-02-08T02:08:56.341927: step 2221, loss 0.102897, acc 0.96875
2020-02-08T02:08:56.570066: step 2222, loss 0.0432666, acc 0.984375
2020-02-08T02:08:56.830348: step 2223, loss 0.0497317, acc 0.96875
2020-02-08T02:08:57.058568: step 2224, loss 0.074864, acc 0.96875
2020-02-08T02:08:57.251797: step 2225, loss 0.0368172, acc 1
2020-02-08T02:08:57.503117: step 2226, loss 0.0314586, acc 1
2020-02-08T02:08:57.693099: step 2227, loss 0.0562097, acc 0.96875
2020-02-08T02:08:57.912326: step 2228, loss 0.0410291, acc 0.96875
2020-02-08T02:08:58.120690: step 2229, loss 0.0886049, acc 0.96875
2020-02-08T02:08:58.315493: step 2230, loss 0.0392986, acc 0.984375
2020-02-08T02:08:58.545213: step 2231, loss 0.0470548, acc 0.96875
2020-02-08T02:08:58.766402: step 2232, loss 0.239276, acc 0.953125
2020-02-08T02:08:58.991194: step 2233, loss 0.089946, acc 0.984375
2020-02-08T02:08:59.202843: step 2234, loss 0.0249111, acc 1
2020-02-08T02:08:59.411035: step 2235, loss 0.032442, acc 0.984375
2020-02-08T02:08:59.634596: step 2236, loss 0.0275222, acc 1
2020-02-08T02:08:59.852750: step 2237, loss 0.0680059, acc 0.984375
2020-02-08T02:09:00.069698: step 2238, loss 0.101424, acc 0.953125
2020-02-08T02:09:00.267539: step 2239, loss 0.0181195, acc 1
2020-02-08T02:09:00.470919: step 2240, loss 0.0501449, acc 0.984375
2020-02-08T02:09:00.688730: step 2241, loss 0.0598677, acc 0.96875
2020-02-08T02:09:00.950623: step 2242, loss 0.0496771, acc 0.984375
2020-02-08T02:09:01.163721: step 2243, loss 0.0929248, acc 0.984375
2020-02-08T02:09:01.374194: step 2244, loss 0.0169135, acc 1
2020-02-08T02:09:01.603606: step 2245, loss 0.0532049, acc 0.984375
2020-02-08T02:09:01.822137: step 2246, loss 0.0413529, acc 0.984375
2020-02-08T02:09:02.051289: step 2247, loss 0.0575238, acc 0.984375
2020-02-08T02:09:02.265347: step 2248, loss 0.0195863, acc 1
2020-02-08T02:09:02.491510: step 2249, loss 0.114674, acc 0.9375
2020-02-08T02:09:02.704870: step 2250, loss 0.0450995, acc 0.983333
2020-02-08T02:09:02.918078: step 2251, loss 0.0247906, acc 1
2020-02-08T02:09:03.121855: step 2252, loss 0.0604922, acc 0.984375
2020-02-08T02:09:03.325426: step 2253, loss 0.0525393, acc 0.984375
2020-02-08T02:09:03.564387: step 2254, loss 0.023822, acc 1
2020-02-08T02:09:03.781788: step 2255, loss 0.0221468, acc 1
2020-02-08T02:09:03.986786: step 2256, loss 0.0163766, acc 1
2020-02-08T02:09:04.199415: step 2257, loss 0.0374439, acc 0.984375
2020-02-08T02:09:04.413917: step 2258, loss 0.0168892, acc 1
2020-02-08T02:09:04.615913: step 2259, loss 0.0389142, acc 0.984375
2020-02-08T02:09:04.835479: step 2260, loss 0.0162562, acc 1
2020-02-08T02:09:05.051846: step 2261, loss 0.0765066, acc 0.96875
2020-02-08T02:09:05.252429: step 2262, loss 0.0813045, acc 0.984375
2020-02-08T02:09:05.454434: step 2263, loss 0.0255101, acc 0.984375
2020-02-08T02:09:05.672010: step 2264, loss 0.0210783, acc 1
2020-02-08T02:09:05.901181: step 2265, loss 0.0144128, acc 1
2020-02-08T02:09:06.115995: step 2266, loss 0.0192077, acc 1
2020-02-08T02:09:06.318529: step 2267, loss 0.0285427, acc 0.984375
2020-02-08T02:09:06.532470: step 2268, loss 0.0767341, acc 0.953125
2020-02-08T02:09:06.749379: step 2269, loss 0.0481796, acc 0.984375
2020-02-08T02:09:06.966162: step 2270, loss 0.0822574, acc 0.96875
2020-02-08T02:09:07.162433: step 2271, loss 0.0437815, acc 0.984375
2020-02-08T02:09:07.372148: step 2272, loss 0.0360845, acc 1
2020-02-08T02:09:07.588667: step 2273, loss 0.0401998, acc 1
2020-02-08T02:09:07.804240: step 2274, loss 0.0786305, acc 0.96875
2020-02-08T02:09:08.005147: step 2275, loss 0.0198966, acc 1
2020-02-08T02:09:08.205754: step 2276, loss 0.0955143, acc 0.96875
2020-02-08T02:09:08.429674: step 2277, loss 0.118173, acc 0.953125
2020-02-08T02:09:08.648169: step 2278, loss 0.104142, acc 0.953125
2020-02-08T02:09:08.846019: step 2279, loss 0.0266651, acc 1
2020-02-08T02:09:09.069866: step 2280, loss 0.0561664, acc 0.984375
2020-02-08T02:09:09.280906: step 2281, loss 0.0179208, acc 1
2020-02-08T02:09:09.470139: step 2282, loss 0.0580947, acc 0.984375
2020-02-08T02:09:09.671576: step 2283, loss 0.0158093, acc 1
2020-02-08T02:09:09.870652: step 2284, loss 0.0531171, acc 0.984375
2020-02-08T02:09:10.069942: step 2285, loss 0.0288722, acc 1
2020-02-08T02:09:10.268857: step 2286, loss 0.0616981, acc 0.984375
2020-02-08T02:09:10.472595: step 2287, loss 0.0122231, acc 1
2020-02-08T02:09:10.672312: step 2288, loss 0.0553739, acc 0.96875
2020-02-08T02:09:10.890247: step 2289, loss 0.0795487, acc 0.96875
2020-02-08T02:09:11.088461: step 2290, loss 0.0180609, acc 1
2020-02-08T02:09:11.278022: step 2291, loss 0.0622685, acc 0.96875
2020-02-08T02:09:11.472133: step 2292, loss 0.0535879, acc 0.984375
2020-02-08T02:09:11.670726: step 2293, loss 0.0304112, acc 1
2020-02-08T02:09:11.863253: step 2294, loss 0.038964, acc 0.984375
2020-02-08T02:09:12.059477: step 2295, loss 0.0376769, acc 0.984375
2020-02-08T02:09:12.253890: step 2296, loss 0.0550695, acc 0.984375
2020-02-08T02:09:12.444063: step 2297, loss 0.032776, acc 1
2020-02-08T02:09:12.640324: step 2298, loss 0.0184684, acc 1
2020-02-08T02:09:12.826042: step 2299, loss 0.0676311, acc 0.96875
2020-02-08T02:09:13.018118: step 2300, loss 0.0522936, acc 0.984375

Evaluation:
2020-02-08T02:09:13.364228: step 2300, loss 0.851913, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2300

2020-02-08T02:09:15.561209: step 2301, loss 0.046199, acc 0.984375
2020-02-08T02:09:15.756719: step 2302, loss 0.0178558, acc 1
2020-02-08T02:09:15.938360: step 2303, loss 0.0565934, acc 0.984375
2020-02-08T02:09:16.126439: step 2304, loss 0.0272626, acc 1
2020-02-08T02:09:16.311360: step 2305, loss 0.0392118, acc 0.984375
2020-02-08T02:09:16.500369: step 2306, loss 0.0480273, acc 0.96875
2020-02-08T02:09:16.694934: step 2307, loss 0.0232921, acc 1
2020-02-08T02:09:16.874930: step 2308, loss 0.0166587, acc 1
2020-02-08T02:09:17.060685: step 2309, loss 0.0694224, acc 0.984375
2020-02-08T02:09:17.339894: step 2310, loss 0.0519692, acc 0.984375
2020-02-08T02:09:17.554423: step 2311, loss 0.0121987, acc 1
2020-02-08T02:09:17.761876: step 2312, loss 0.0334336, acc 0.984375
2020-02-08T02:09:17.951474: step 2313, loss 0.0260843, acc 1
2020-02-08T02:09:18.145073: step 2314, loss 0.0134894, acc 1
2020-02-08T02:09:18.321193: step 2315, loss 0.0552135, acc 0.96875
2020-02-08T02:09:18.524117: step 2316, loss 0.0551289, acc 0.984375
2020-02-08T02:09:18.741975: step 2317, loss 0.019326, acc 1
2020-02-08T02:09:18.960464: step 2318, loss 0.0484601, acc 0.96875
2020-02-08T02:09:19.177197: step 2319, loss 0.0404042, acc 0.984375
2020-02-08T02:09:19.389013: step 2320, loss 0.0115889, acc 1
2020-02-08T02:09:19.596293: step 2321, loss 0.0423237, acc 1
2020-02-08T02:09:19.805905: step 2322, loss 0.021048, acc 1
2020-02-08T02:09:19.992782: step 2323, loss 0.047083, acc 0.984375
2020-02-08T02:09:20.194949: step 2324, loss 0.0482871, acc 0.96875
2020-02-08T02:09:20.411957: step 2325, loss 0.0437051, acc 0.984375
2020-02-08T02:09:20.626948: step 2326, loss 0.0614317, acc 0.96875
2020-02-08T02:09:20.854666: step 2327, loss 0.0289948, acc 0.984375
2020-02-08T02:09:21.032684: step 2328, loss 0.0320738, acc 0.984375
2020-02-08T02:09:21.228373: step 2329, loss 0.049629, acc 0.96875
2020-02-08T02:09:21.517116: step 2330, loss 0.0404252, acc 0.96875
2020-02-08T02:09:21.745471: step 2331, loss 0.0743088, acc 0.984375
2020-02-08T02:09:21.946110: step 2332, loss 0.0550448, acc 1
2020-02-08T02:09:22.181783: step 2333, loss 0.0315649, acc 0.984375
2020-02-08T02:09:22.395209: step 2334, loss 0.0296424, acc 1
2020-02-08T02:09:22.582683: step 2335, loss 0.062367, acc 0.96875
2020-02-08T02:09:22.811266: step 2336, loss 0.0287696, acc 0.984375
2020-02-08T02:09:23.044553: step 2337, loss 0.0418944, acc 1
2020-02-08T02:09:23.249486: step 2338, loss 0.105445, acc 0.953125
2020-02-08T02:09:23.483009: step 2339, loss 0.0325731, acc 1
2020-02-08T02:09:23.722158: step 2340, loss 0.0674459, acc 0.953125
2020-02-08T02:09:23.922671: step 2341, loss 0.0375272, acc 1
2020-02-08T02:09:24.125265: step 2342, loss 0.0402393, acc 0.984375
2020-02-08T02:09:24.348251: step 2343, loss 0.0225409, acc 1
2020-02-08T02:09:24.557409: step 2344, loss 0.0117611, acc 1
2020-02-08T02:09:24.758979: step 2345, loss 0.0382255, acc 0.984375
2020-02-08T02:09:24.949384: step 2346, loss 0.0825493, acc 0.96875
2020-02-08T02:09:25.162573: step 2347, loss 0.00885165, acc 1
2020-02-08T02:09:25.379120: step 2348, loss 0.00982614, acc 1
2020-02-08T02:09:25.606692: step 2349, loss 0.0170567, acc 1
2020-02-08T02:09:25.825708: step 2350, loss 0.0943434, acc 0.9375
2020-02-08T02:09:26.014429: step 2351, loss 0.0789519, acc 0.984375
2020-02-08T02:09:26.211368: step 2352, loss 0.0804603, acc 0.953125
2020-02-08T02:09:26.407775: step 2353, loss 0.0266805, acc 0.984375
2020-02-08T02:09:26.615836: step 2354, loss 0.0188595, acc 1
2020-02-08T02:09:26.847555: step 2355, loss 0.0421611, acc 0.984375
2020-02-08T02:09:27.047942: step 2356, loss 0.0195177, acc 0.984375
2020-02-08T02:09:27.245162: step 2357, loss 0.0232465, acc 0.984375
2020-02-08T02:09:27.467543: step 2358, loss 0.0758884, acc 0.96875
2020-02-08T02:09:27.674328: step 2359, loss 0.0710504, acc 0.984375
2020-02-08T02:09:27.870866: step 2360, loss 0.0103615, acc 1
2020-02-08T02:09:28.114177: step 2361, loss 0.0300367, acc 1
2020-02-08T02:09:28.331973: step 2362, loss 0.0597492, acc 0.953125
2020-02-08T02:09:28.561897: step 2363, loss 0.0302754, acc 1
2020-02-08T02:09:28.915109: step 2364, loss 0.0464215, acc 0.984375
2020-02-08T02:09:29.200128: step 2365, loss 0.0366924, acc 0.984375
2020-02-08T02:09:29.457380: step 2366, loss 0.0249734, acc 1
2020-02-08T02:09:29.691953: step 2367, loss 0.0635913, acc 0.984375
2020-02-08T02:09:29.883676: step 2368, loss 0.0698217, acc 0.984375
2020-02-08T02:09:30.099637: step 2369, loss 0.0621028, acc 0.984375
2020-02-08T02:09:30.302213: step 2370, loss 0.030617, acc 1
2020-02-08T02:09:30.561324: step 2371, loss 0.0350676, acc 1
2020-02-08T02:09:30.785470: step 2372, loss 0.0809482, acc 0.96875
2020-02-08T02:09:31.006283: step 2373, loss 0.0423573, acc 0.984375
2020-02-08T02:09:31.209601: step 2374, loss 0.0401595, acc 0.984375
2020-02-08T02:09:31.413381: step 2375, loss 0.0416765, acc 1
2020-02-08T02:09:31.675811: step 2376, loss 0.0245686, acc 1
2020-02-08T02:09:31.882618: step 2377, loss 0.0250651, acc 0.984375
2020-02-08T02:09:32.085322: step 2378, loss 0.0424541, acc 0.984375
2020-02-08T02:09:32.312151: step 2379, loss 0.0808842, acc 0.953125
2020-02-08T02:09:32.524103: step 2380, loss 0.0269735, acc 1
2020-02-08T02:09:32.762970: step 2381, loss 0.0282293, acc 1
2020-02-08T02:09:32.983189: step 2382, loss 0.044602, acc 0.984375
2020-02-08T02:09:33.214360: step 2383, loss 0.0771189, acc 0.984375
2020-02-08T02:09:33.413117: step 2384, loss 0.0505159, acc 0.96875
2020-02-08T02:09:33.649754: step 2385, loss 0.0464554, acc 0.984375
2020-02-08T02:09:33.831103: step 2386, loss 0.0127604, acc 1
2020-02-08T02:09:34.052131: step 2387, loss 0.0715655, acc 0.984375
2020-02-08T02:09:34.265053: step 2388, loss 0.0433608, acc 0.984375
2020-02-08T02:09:34.457622: step 2389, loss 0.0571556, acc 0.96875
2020-02-08T02:09:34.704372: step 2390, loss 0.0103928, acc 1
2020-02-08T02:09:34.931824: step 2391, loss 0.0601868, acc 0.96875
2020-02-08T02:09:35.151357: step 2392, loss 0.0471303, acc 0.984375
2020-02-08T02:09:35.403049: step 2393, loss 0.0548975, acc 0.984375
2020-02-08T02:09:35.579182: step 2394, loss 0.100775, acc 0.96875
2020-02-08T02:09:35.812130: step 2395, loss 0.0766624, acc 0.953125
2020-02-08T02:09:36.044220: step 2396, loss 0.0374072, acc 1
2020-02-08T02:09:36.285037: step 2397, loss 0.0586666, acc 0.96875
2020-02-08T02:09:36.470913: step 2398, loss 0.0364741, acc 0.984375
2020-02-08T02:09:36.731575: step 2399, loss 0.0198462, acc 0.984375
2020-02-08T02:09:36.951728: step 2400, loss 0.0695325, acc 0.983333

Evaluation:
2020-02-08T02:09:37.341272: step 2400, loss 0.8822, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2400

2020-02-08T02:09:39.204971: step 2401, loss 0.00986183, acc 1
2020-02-08T02:09:39.420535: step 2402, loss 0.0229557, acc 1
2020-02-08T02:09:39.699519: step 2403, loss 0.0337755, acc 0.984375
2020-02-08T02:09:39.939236: step 2404, loss 0.016344, acc 1
2020-02-08T02:09:40.153506: step 2405, loss 0.0137423, acc 1
2020-02-08T02:09:40.361775: step 2406, loss 0.0307782, acc 1
2020-02-08T02:09:40.584652: step 2407, loss 0.0153785, acc 1
2020-02-08T02:09:40.786623: step 2408, loss 0.038003, acc 0.984375
2020-02-08T02:09:41.017751: step 2409, loss 0.0369231, acc 1
2020-02-08T02:09:41.258810: step 2410, loss 0.0200187, acc 1
2020-02-08T02:09:41.510868: step 2411, loss 0.0336103, acc 0.984375
2020-02-08T02:09:41.757782: step 2412, loss 0.0305788, acc 1
2020-02-08T02:09:41.978425: step 2413, loss 0.0308588, acc 0.984375
2020-02-08T02:09:42.193020: step 2414, loss 0.0123477, acc 1
2020-02-08T02:09:42.411999: step 2415, loss 0.010129, acc 1
2020-02-08T02:09:42.691598: step 2416, loss 0.0151874, acc 1
2020-02-08T02:09:42.869718: step 2417, loss 0.0552464, acc 0.984375
2020-02-08T02:09:43.064352: step 2418, loss 0.00652333, acc 1
2020-02-08T02:09:43.261485: step 2419, loss 0.020648, acc 1
2020-02-08T02:09:43.471560: step 2420, loss 0.119806, acc 0.921875
2020-02-08T02:09:43.699676: step 2421, loss 0.0486917, acc 0.96875
2020-02-08T02:09:43.954967: step 2422, loss 0.0115199, acc 1
2020-02-08T02:09:44.207455: step 2423, loss 0.0347411, acc 0.984375
2020-02-08T02:09:44.432795: step 2424, loss 0.0405683, acc 0.984375
2020-02-08T02:09:44.674394: step 2425, loss 0.0645741, acc 0.96875
2020-02-08T02:09:44.924706: step 2426, loss 0.020673, acc 1
2020-02-08T02:09:45.162788: step 2427, loss 0.0348378, acc 0.984375
2020-02-08T02:09:45.394773: step 2428, loss 0.0164291, acc 1
2020-02-08T02:09:45.619667: step 2429, loss 0.0121342, acc 1
2020-02-08T02:09:45.832931: step 2430, loss 0.00636127, acc 1
2020-02-08T02:09:46.029121: step 2431, loss 0.0368511, acc 0.984375
2020-02-08T02:09:46.240683: step 2432, loss 0.0217033, acc 0.984375
2020-02-08T02:09:46.441373: step 2433, loss 0.0287016, acc 1
2020-02-08T02:09:46.667151: step 2434, loss 0.0128404, acc 1
2020-02-08T02:09:46.861518: step 2435, loss 0.0220497, acc 1
2020-02-08T02:09:47.095157: step 2436, loss 0.0209828, acc 1
2020-02-08T02:09:47.306126: step 2437, loss 0.023808, acc 1
2020-02-08T02:09:47.525876: step 2438, loss 0.00821626, acc 1
2020-02-08T02:09:47.757525: step 2439, loss 0.0124069, acc 1
2020-02-08T02:09:47.988305: step 2440, loss 0.0212981, acc 1
2020-02-08T02:09:48.205010: step 2441, loss 0.0228061, acc 0.984375
2020-02-08T02:09:48.413792: step 2442, loss 0.0166831, acc 1
2020-02-08T02:09:48.637734: step 2443, loss 0.0262738, acc 0.984375
2020-02-08T02:09:48.857547: step 2444, loss 0.00981733, acc 1
2020-02-08T02:09:49.126636: step 2445, loss 0.0204897, acc 1
2020-02-08T02:09:49.342002: step 2446, loss 0.0490687, acc 0.984375
2020-02-08T02:09:49.592686: step 2447, loss 0.0231227, acc 1
2020-02-08T02:09:49.826669: step 2448, loss 0.0138132, acc 1
2020-02-08T02:09:50.060089: step 2449, loss 0.0360256, acc 0.984375
2020-02-08T02:09:50.274657: step 2450, loss 0.0158753, acc 1
2020-02-08T02:09:50.491483: step 2451, loss 0.0323046, acc 0.984375
2020-02-08T02:09:50.726114: step 2452, loss 0.0883913, acc 0.953125
2020-02-08T02:09:50.946550: step 2453, loss 0.0181817, acc 1
2020-02-08T02:09:51.207226: step 2454, loss 0.0139394, acc 1
2020-02-08T02:09:51.439094: step 2455, loss 0.0668239, acc 0.984375
2020-02-08T02:09:51.638259: step 2456, loss 0.0820341, acc 0.953125
2020-02-08T02:09:51.847727: step 2457, loss 0.00634905, acc 1
2020-02-08T02:09:52.073950: step 2458, loss 0.0313274, acc 0.984375
2020-02-08T02:09:52.344708: step 2459, loss 0.0499392, acc 0.984375
2020-02-08T02:09:52.576299: step 2460, loss 0.0828566, acc 0.96875
2020-02-08T02:09:52.803962: step 2461, loss 0.048565, acc 0.984375
2020-02-08T02:09:52.968338: step 2462, loss 0.0445225, acc 0.96875
2020-02-08T02:09:53.193500: step 2463, loss 0.0691459, acc 0.96875
2020-02-08T02:09:53.439278: step 2464, loss 0.0197226, acc 1
2020-02-08T02:09:53.681190: step 2465, loss 0.0756642, acc 0.984375
2020-02-08T02:09:53.857286: step 2466, loss 0.0554936, acc 0.984375
2020-02-08T02:09:54.098246: step 2467, loss 0.0512803, acc 0.984375
2020-02-08T02:09:54.310098: step 2468, loss 0.02888, acc 1
2020-02-08T02:09:54.496011: step 2469, loss 0.0317727, acc 0.984375
2020-02-08T02:09:54.734879: step 2470, loss 0.0330753, acc 1
2020-02-08T02:09:54.959471: step 2471, loss 0.0068209, acc 1
2020-02-08T02:09:55.181895: step 2472, loss 0.0163903, acc 1
2020-02-08T02:09:55.367664: step 2473, loss 0.0123204, acc 1
2020-02-08T02:09:55.596533: step 2474, loss 0.00243132, acc 1
2020-02-08T02:09:55.827426: step 2475, loss 0.0280479, acc 0.984375
2020-02-08T02:09:56.089552: step 2476, loss 0.0270508, acc 0.984375
2020-02-08T02:09:56.309570: step 2477, loss 0.0449616, acc 0.984375
2020-02-08T02:09:56.516778: step 2478, loss 0.014036, acc 1
2020-02-08T02:09:56.746713: step 2479, loss 0.0269081, acc 1
2020-02-08T02:09:56.975709: step 2480, loss 0.0174783, acc 1
2020-02-08T02:09:57.204364: step 2481, loss 0.0260251, acc 1
2020-02-08T02:09:57.427149: step 2482, loss 0.0235968, acc 1
2020-02-08T02:09:57.615734: step 2483, loss 0.0142758, acc 1
2020-02-08T02:09:57.900164: step 2484, loss 0.0258241, acc 1
2020-02-08T02:09:58.168125: step 2485, loss 0.0267682, acc 1
2020-02-08T02:09:58.397023: step 2486, loss 0.0241326, acc 1
2020-02-08T02:09:58.609796: step 2487, loss 0.0110621, acc 1
2020-02-08T02:09:58.842055: step 2488, loss 0.0197384, acc 1
2020-02-08T02:09:59.079594: step 2489, loss 0.029536, acc 1
2020-02-08T02:09:59.293431: step 2490, loss 0.0157427, acc 1
2020-02-08T02:09:59.514816: step 2491, loss 0.0116346, acc 1
2020-02-08T02:09:59.717492: step 2492, loss 0.0299556, acc 1
2020-02-08T02:09:59.932608: step 2493, loss 0.0381178, acc 0.984375
2020-02-08T02:10:00.128186: step 2494, loss 0.00658853, acc 1
2020-02-08T02:10:00.349836: step 2495, loss 0.0230862, acc 1
2020-02-08T02:10:00.571528: step 2496, loss 0.0343701, acc 1
2020-02-08T02:10:00.798353: step 2497, loss 0.0347553, acc 0.984375
2020-02-08T02:10:01.042695: step 2498, loss 0.0371289, acc 0.984375
2020-02-08T02:10:01.251152: step 2499, loss 0.0106387, acc 1
2020-02-08T02:10:01.470621: step 2500, loss 0.0489318, acc 0.96875

Evaluation:
2020-02-08T02:10:01.886029: step 2500, loss 0.931328, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2500

2020-02-08T02:10:03.586563: step 2501, loss 0.0834561, acc 0.96875
2020-02-08T02:10:03.830049: step 2502, loss 0.00959574, acc 1
2020-02-08T02:10:04.084672: step 2503, loss 0.04635, acc 0.984375
2020-02-08T02:10:04.302743: step 2504, loss 0.0271168, acc 0.984375
2020-02-08T02:10:04.529110: step 2505, loss 0.00415875, acc 1
2020-02-08T02:10:04.776732: step 2506, loss 0.0175059, acc 0.984375
2020-02-08T02:10:04.980207: step 2507, loss 0.0402109, acc 0.984375
2020-02-08T02:10:05.182859: step 2508, loss 0.00605891, acc 1
2020-02-08T02:10:05.417722: step 2509, loss 0.0203529, acc 1
2020-02-08T02:10:05.636284: step 2510, loss 0.0481573, acc 0.96875
2020-02-08T02:10:05.876467: step 2511, loss 0.0337721, acc 1
2020-02-08T02:10:06.089875: step 2512, loss 0.0214731, acc 1
2020-02-08T02:10:06.324556: step 2513, loss 0.00950084, acc 1
2020-02-08T02:10:06.503297: step 2514, loss 0.0168019, acc 1
2020-02-08T02:10:06.737103: step 2515, loss 0.0538921, acc 0.984375
2020-02-08T02:10:06.952303: step 2516, loss 0.00659461, acc 1
2020-02-08T02:10:07.116761: step 2517, loss 0.0227795, acc 1
2020-02-08T02:10:07.319003: step 2518, loss 0.039377, acc 0.984375
2020-02-08T02:10:07.515008: step 2519, loss 0.0285404, acc 1
2020-02-08T02:10:07.754337: step 2520, loss 0.0473785, acc 0.953125
2020-02-08T02:10:07.963537: step 2521, loss 0.0668845, acc 0.953125
2020-02-08T02:10:08.165124: step 2522, loss 0.0305466, acc 0.984375
2020-02-08T02:10:08.371451: step 2523, loss 0.0284312, acc 0.984375
2020-02-08T02:10:08.584178: step 2524, loss 0.0262915, acc 1
2020-02-08T02:10:08.822385: step 2525, loss 0.0263665, acc 0.984375
2020-02-08T02:10:09.035729: step 2526, loss 0.10375, acc 0.9375
2020-02-08T02:10:09.253846: step 2527, loss 0.0349706, acc 1
2020-02-08T02:10:09.457429: step 2528, loss 0.0647722, acc 0.96875
2020-02-08T02:10:09.671110: step 2529, loss 0.0373294, acc 0.984375
2020-02-08T02:10:09.868780: step 2530, loss 0.0292655, acc 1
2020-02-08T02:10:10.082865: step 2531, loss 0.00880837, acc 1
2020-02-08T02:10:10.284439: step 2532, loss 0.00822716, acc 1
2020-02-08T02:10:10.486580: step 2533, loss 0.0180091, acc 1
2020-02-08T02:10:10.698660: step 2534, loss 0.0204573, acc 1
2020-02-08T02:10:10.916122: step 2535, loss 0.0111376, acc 1
2020-02-08T02:10:11.135074: step 2536, loss 0.0216502, acc 1
2020-02-08T02:10:11.356861: step 2537, loss 0.0233745, acc 1
2020-02-08T02:10:11.567034: step 2538, loss 0.0126644, acc 1
2020-02-08T02:10:11.752162: step 2539, loss 0.0674467, acc 0.96875
2020-02-08T02:10:11.964535: step 2540, loss 0.00994917, acc 1
2020-02-08T02:10:12.174620: step 2541, loss 0.0735113, acc 0.984375
2020-02-08T02:10:12.393262: step 2542, loss 0.0200729, acc 1
2020-02-08T02:10:12.610064: step 2543, loss 0.0213246, acc 0.984375
2020-02-08T02:10:12.830562: step 2544, loss 0.0104268, acc 1
2020-02-08T02:10:13.050259: step 2545, loss 0.00836269, acc 1
2020-02-08T02:10:13.249979: step 2546, loss 0.100526, acc 0.9375
2020-02-08T02:10:13.457268: step 2547, loss 0.00753391, acc 1
2020-02-08T02:10:13.679995: step 2548, loss 0.0352489, acc 1
2020-02-08T02:10:13.883433: step 2549, loss 0.0242264, acc 1
2020-02-08T02:10:14.085741: step 2550, loss 0.0330977, acc 0.983333
2020-02-08T02:10:14.291260: step 2551, loss 0.0233692, acc 1
2020-02-08T02:10:14.538802: step 2552, loss 0.0274585, acc 0.984375
2020-02-08T02:10:14.770544: step 2553, loss 0.0185234, acc 1
2020-02-08T02:10:14.971569: step 2554, loss 0.0465583, acc 0.96875
2020-02-08T02:10:15.189265: step 2555, loss 0.0109497, acc 1
2020-02-08T02:10:15.387508: step 2556, loss 0.0324031, acc 0.984375
2020-02-08T02:10:15.593162: step 2557, loss 0.0541893, acc 0.96875
2020-02-08T02:10:15.803528: step 2558, loss 0.0322605, acc 0.984375
2020-02-08T02:10:16.007500: step 2559, loss 0.0178626, acc 1
2020-02-08T02:10:16.224594: step 2560, loss 0.0164987, acc 1
2020-02-08T02:10:16.432009: step 2561, loss 0.023445, acc 0.984375
2020-02-08T02:10:16.647671: step 2562, loss 0.0182645, acc 1
2020-02-08T02:10:16.858218: step 2563, loss 0.0108798, acc 1
2020-02-08T02:10:17.072535: step 2564, loss 0.0315601, acc 0.984375
2020-02-08T02:10:17.269409: step 2565, loss 0.010429, acc 1
2020-02-08T02:10:17.465843: step 2566, loss 0.00996382, acc 1
2020-02-08T02:10:17.701565: step 2567, loss 0.0512087, acc 0.953125
2020-02-08T02:10:17.871817: step 2568, loss 0.011293, acc 1
2020-02-08T02:10:18.067574: step 2569, loss 0.0295532, acc 0.984375
2020-02-08T02:10:18.263102: step 2570, loss 0.0193471, acc 0.984375
2020-02-08T02:10:18.468154: step 2571, loss 0.0155918, acc 1
2020-02-08T02:10:18.668533: step 2572, loss 0.0374786, acc 1
2020-02-08T02:10:18.876950: step 2573, loss 0.0159866, acc 1
2020-02-08T02:10:19.077349: step 2574, loss 0.033647, acc 0.984375
2020-02-08T02:10:19.292363: step 2575, loss 0.0204287, acc 1
2020-02-08T02:10:19.503178: step 2576, loss 0.0161217, acc 1
2020-02-08T02:10:19.714333: step 2577, loss 0.0202952, acc 0.984375
2020-02-08T02:10:19.936010: step 2578, loss 0.0226548, acc 0.984375
2020-02-08T02:10:20.128511: step 2579, loss 0.0130337, acc 1
2020-02-08T02:10:20.339467: step 2580, loss 0.016246, acc 1
2020-02-08T02:10:20.528745: step 2581, loss 0.0165948, acc 1
2020-02-08T02:10:20.744701: step 2582, loss 0.0337898, acc 1
2020-02-08T02:10:20.954673: step 2583, loss 0.0168354, acc 0.984375
2020-02-08T02:10:21.170758: step 2584, loss 0.00518604, acc 1
2020-02-08T02:10:21.363830: step 2585, loss 0.01316, acc 1
2020-02-08T02:10:21.581383: step 2586, loss 0.0244205, acc 1
2020-02-08T02:10:21.822385: step 2587, loss 0.00740843, acc 1
2020-02-08T02:10:22.039095: step 2588, loss 0.0383305, acc 0.984375
2020-02-08T02:10:22.236688: step 2589, loss 0.0106047, acc 1
2020-02-08T02:10:22.440479: step 2590, loss 0.0251818, acc 1
2020-02-08T02:10:22.662567: step 2591, loss 0.0282152, acc 0.984375
2020-02-08T02:10:22.861653: step 2592, loss 0.011401, acc 1
2020-02-08T02:10:23.089040: step 2593, loss 0.00679333, acc 1
2020-02-08T02:10:23.308305: step 2594, loss 0.021957, acc 1
2020-02-08T02:10:23.515620: step 2595, loss 0.0405058, acc 1
2020-02-08T02:10:23.753235: step 2596, loss 0.0177987, acc 1
2020-02-08T02:10:23.988776: step 2597, loss 0.0284211, acc 1
2020-02-08T02:10:24.220448: step 2598, loss 0.0523636, acc 0.984375
2020-02-08T02:10:24.408618: step 2599, loss 0.0364618, acc 0.984375
2020-02-08T02:10:24.641620: step 2600, loss 0.00920834, acc 1

Evaluation:
2020-02-08T02:10:25.058253: step 2600, loss 0.951835, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2600

2020-02-08T02:10:28.404743: step 2601, loss 0.00744664, acc 1
2020-02-08T02:10:28.620966: step 2602, loss 0.0170003, acc 1
2020-02-08T02:10:28.863712: step 2603, loss 0.0177746, acc 1
2020-02-08T02:10:29.059651: step 2604, loss 0.0121652, acc 1
2020-02-08T02:10:29.313558: step 2605, loss 0.00798474, acc 1
2020-02-08T02:10:29.566368: step 2606, loss 0.0144234, acc 1
2020-02-08T02:10:29.788272: step 2607, loss 0.00968464, acc 1
2020-02-08T02:10:30.003847: step 2608, loss 0.00854278, acc 1
2020-02-08T02:10:30.269861: step 2609, loss 0.00592891, acc 1
2020-02-08T02:10:30.506293: step 2610, loss 0.0100096, acc 1
2020-02-08T02:10:30.747139: step 2611, loss 0.0682233, acc 0.96875
2020-02-08T02:10:30.998046: step 2612, loss 0.0184078, acc 1
2020-02-08T02:10:31.235999: step 2613, loss 0.0321519, acc 1
2020-02-08T02:10:31.481146: step 2614, loss 0.0201702, acc 1
2020-02-08T02:10:31.660576: step 2615, loss 0.0603848, acc 0.984375
2020-02-08T02:10:31.840199: step 2616, loss 0.0354789, acc 0.984375
2020-02-08T02:10:32.079911: step 2617, loss 0.0299348, acc 0.984375
2020-02-08T02:10:32.335127: step 2618, loss 0.0114508, acc 1
2020-02-08T02:10:32.567855: step 2619, loss 0.0378445, acc 0.984375
2020-02-08T02:10:32.815750: step 2620, loss 0.0236149, acc 0.984375
2020-02-08T02:10:33.059746: step 2621, loss 0.0289301, acc 0.984375
2020-02-08T02:10:33.317713: step 2622, loss 0.0212475, acc 1
2020-02-08T02:10:33.533481: step 2623, loss 0.0286797, acc 0.984375
2020-02-08T02:10:33.764885: step 2624, loss 0.0344452, acc 0.984375
2020-02-08T02:10:33.977410: step 2625, loss 0.0104644, acc 1
2020-02-08T02:10:34.138861: step 2626, loss 0.0190144, acc 1
2020-02-08T02:10:34.397121: step 2627, loss 0.00918485, acc 1
2020-02-08T02:10:34.659797: step 2628, loss 0.0582324, acc 0.96875
2020-02-08T02:10:34.883726: step 2629, loss 0.00984177, acc 1
2020-02-08T02:10:35.118434: step 2630, loss 0.0386512, acc 1
2020-02-08T02:10:35.314139: step 2631, loss 0.0364795, acc 1
2020-02-08T02:10:35.538355: step 2632, loss 0.0162491, acc 1
2020-02-08T02:10:35.819517: step 2633, loss 0.0189099, acc 1
2020-02-08T02:10:36.127389: step 2634, loss 0.0196522, acc 1
2020-02-08T02:10:36.423118: step 2635, loss 0.0378613, acc 1
2020-02-08T02:10:36.701981: step 2636, loss 0.0075007, acc 1
2020-02-08T02:10:36.980934: step 2637, loss 0.0198997, acc 1
2020-02-08T02:10:37.202901: step 2638, loss 0.0223895, acc 0.984375
2020-02-08T02:10:37.469775: step 2639, loss 0.0115535, acc 1
2020-02-08T02:10:37.713939: step 2640, loss 0.0242211, acc 1
2020-02-08T02:10:37.951529: step 2641, loss 0.0102968, acc 1
2020-02-08T02:10:38.204282: step 2642, loss 0.0129638, acc 1
2020-02-08T02:10:38.471012: step 2643, loss 0.0586952, acc 0.984375
2020-02-08T02:10:38.737501: step 2644, loss 0.0219157, acc 0.984375
2020-02-08T02:10:38.971438: step 2645, loss 0.00782661, acc 1
2020-02-08T02:10:39.219157: step 2646, loss 0.0181804, acc 1
2020-02-08T02:10:39.470236: step 2647, loss 0.0870825, acc 0.984375
2020-02-08T02:10:39.703533: step 2648, loss 0.026873, acc 0.984375
2020-02-08T02:10:39.950479: step 2649, loss 0.00324441, acc 1
2020-02-08T02:10:40.153251: step 2650, loss 0.00498414, acc 1
2020-02-08T02:10:40.370642: step 2651, loss 0.0629178, acc 0.984375
2020-02-08T02:10:40.573611: step 2652, loss 0.0373271, acc 0.984375
2020-02-08T02:10:40.808726: step 2653, loss 0.00375643, acc 1
2020-02-08T02:10:41.026328: step 2654, loss 0.0106671, acc 1
2020-02-08T02:10:41.204869: step 2655, loss 0.0226549, acc 0.984375
2020-02-08T02:10:41.457027: step 2656, loss 0.0216656, acc 1
2020-02-08T02:10:41.699130: step 2657, loss 0.00765269, acc 1
2020-02-08T02:10:41.900430: step 2658, loss 0.0136574, acc 1
2020-02-08T02:10:42.107499: step 2659, loss 0.0376597, acc 0.984375
2020-02-08T02:10:42.329395: step 2660, loss 0.0745332, acc 0.953125
2020-02-08T02:10:42.556738: step 2661, loss 0.0268347, acc 1
2020-02-08T02:10:42.804510: step 2662, loss 0.0191232, acc 1
2020-02-08T02:10:43.016384: step 2663, loss 0.027449, acc 0.984375
2020-02-08T02:10:43.228668: step 2664, loss 0.0306093, acc 0.984375
2020-02-08T02:10:43.459664: step 2665, loss 0.00971828, acc 1
2020-02-08T02:10:43.682584: step 2666, loss 0.064776, acc 0.984375
2020-02-08T02:10:43.912479: step 2667, loss 0.0152083, acc 1
2020-02-08T02:10:44.099158: step 2668, loss 0.00773392, acc 1
2020-02-08T02:10:44.354539: step 2669, loss 0.114959, acc 0.953125
2020-02-08T02:10:44.575024: step 2670, loss 0.0226634, acc 1
2020-02-08T02:10:44.844840: step 2671, loss 0.0258556, acc 0.984375
2020-02-08T02:10:45.117508: step 2672, loss 0.00754596, acc 1
2020-02-08T02:10:45.379403: step 2673, loss 0.0233494, acc 1
2020-02-08T02:10:45.654450: step 2674, loss 0.0102311, acc 1
2020-02-08T02:10:45.910062: step 2675, loss 0.0127661, acc 1
2020-02-08T02:10:46.141837: step 2676, loss 0.00753501, acc 1
2020-02-08T02:10:46.423271: step 2677, loss 0.0498033, acc 0.96875
2020-02-08T02:10:46.680871: step 2678, loss 0.0179902, acc 1
2020-02-08T02:10:46.935730: step 2679, loss 0.013484, acc 1
2020-02-08T02:10:47.222940: step 2680, loss 0.0458708, acc 0.96875
2020-02-08T02:10:47.467465: step 2681, loss 0.0196092, acc 1
2020-02-08T02:10:47.733138: step 2682, loss 0.0267293, acc 0.984375
2020-02-08T02:10:47.976233: step 2683, loss 0.00950642, acc 1
2020-02-08T02:10:48.208645: step 2684, loss 0.0148076, acc 1
2020-02-08T02:10:48.464268: step 2685, loss 0.0171709, acc 1
2020-02-08T02:10:48.688099: step 2686, loss 0.0192367, acc 1
2020-02-08T02:10:48.916873: step 2687, loss 0.0101868, acc 1
2020-02-08T02:10:49.192696: step 2688, loss 0.00894623, acc 1
2020-02-08T02:10:49.387201: step 2689, loss 0.0310749, acc 0.984375
2020-02-08T02:10:49.555717: step 2690, loss 0.039398, acc 0.984375
2020-02-08T02:10:49.783222: step 2691, loss 0.0455347, acc 0.984375
2020-02-08T02:10:49.994152: step 2692, loss 0.0636288, acc 0.984375
2020-02-08T02:10:50.223127: step 2693, loss 0.0323057, acc 0.984375
2020-02-08T02:10:50.443935: step 2694, loss 0.0192135, acc 1
2020-02-08T02:10:50.677299: step 2695, loss 0.0432629, acc 0.984375
2020-02-08T02:10:50.894641: step 2696, loss 0.0239932, acc 1
2020-02-08T02:10:51.143108: step 2697, loss 0.0648505, acc 0.984375
2020-02-08T02:10:51.339115: step 2698, loss 0.0145353, acc 1
2020-02-08T02:10:51.578393: step 2699, loss 0.0268123, acc 0.984375
2020-02-08T02:10:51.828807: step 2700, loss 0.0312301, acc 1

Evaluation:
2020-02-08T02:10:52.271215: step 2700, loss 0.982241, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2700

2020-02-08T02:10:53.978527: step 2701, loss 0.0491996, acc 0.96875
2020-02-08T02:10:54.225116: step 2702, loss 0.00813405, acc 1
2020-02-08T02:10:54.465277: step 2703, loss 0.00851666, acc 1
2020-02-08T02:10:54.742518: step 2704, loss 0.0142927, acc 1
2020-02-08T02:10:54.991871: step 2705, loss 0.0639961, acc 0.96875
2020-02-08T02:10:55.225499: step 2706, loss 0.0126696, acc 1
2020-02-08T02:10:55.489094: step 2707, loss 0.0226291, acc 0.984375
2020-02-08T02:10:55.723753: step 2708, loss 0.05445, acc 0.984375
2020-02-08T02:10:56.019895: step 2709, loss 0.0320423, acc 0.984375
2020-02-08T02:10:56.158821: step 2710, loss 0.0124568, acc 1
2020-02-08T02:10:56.292668: step 2711, loss 0.00492932, acc 1
2020-02-08T02:10:56.459320: step 2712, loss 0.0123191, acc 1
2020-02-08T02:10:56.629187: step 2713, loss 0.0193586, acc 1
2020-02-08T02:10:56.812289: step 2714, loss 0.0216526, acc 1
2020-02-08T02:10:56.993405: step 2715, loss 0.0198432, acc 1
2020-02-08T02:10:57.212284: step 2716, loss 0.0162388, acc 1
2020-02-08T02:10:57.359361: step 2717, loss 0.0416054, acc 0.984375
2020-02-08T02:10:57.523127: step 2718, loss 0.015777, acc 1
2020-02-08T02:10:57.696022: step 2719, loss 0.0145006, acc 1
2020-02-08T02:10:57.852732: step 2720, loss 0.0269636, acc 0.984375
2020-02-08T02:10:57.995593: step 2721, loss 0.025699, acc 0.984375
2020-02-08T02:10:58.155841: step 2722, loss 0.00544538, acc 1
2020-02-08T02:10:58.311490: step 2723, loss 0.0337002, acc 0.984375
2020-02-08T02:10:58.480864: step 2724, loss 0.0181755, acc 1
2020-02-08T02:10:58.689528: step 2725, loss 0.0315231, acc 1
2020-02-08T02:10:58.840444: step 2726, loss 0.0215017, acc 1
2020-02-08T02:10:58.995763: step 2727, loss 0.00866849, acc 1
2020-02-08T02:10:59.159714: step 2728, loss 0.0280165, acc 0.984375
2020-02-08T02:10:59.314672: step 2729, loss 0.0343115, acc 0.984375
2020-02-08T02:10:59.478205: step 2730, loss 0.0228399, acc 1
2020-02-08T02:10:59.638882: step 2731, loss 0.00770451, acc 1
2020-02-08T02:10:59.803496: step 2732, loss 0.0280823, acc 0.984375
2020-02-08T02:10:59.963804: step 2733, loss 0.011677, acc 1
2020-02-08T02:11:00.158326: step 2734, loss 0.0685992, acc 0.96875
2020-02-08T02:11:00.294707: step 2735, loss 0.00847412, acc 1
2020-02-08T02:11:00.424655: step 2736, loss 0.00415959, acc 1
2020-02-08T02:11:00.569888: step 2737, loss 0.0273861, acc 0.984375
2020-02-08T02:11:00.725804: step 2738, loss 0.02185, acc 0.984375
2020-02-08T02:11:00.881683: step 2739, loss 0.0476075, acc 0.96875
2020-02-08T02:11:01.042956: step 2740, loss 0.0516294, acc 0.96875
2020-02-08T02:11:01.206556: step 2741, loss 0.0202031, acc 1
2020-02-08T02:11:01.371262: step 2742, loss 0.00918514, acc 1
2020-02-08T02:11:01.533354: step 2743, loss 0.0150175, acc 1
2020-02-08T02:11:01.708677: step 2744, loss 0.0227664, acc 1
2020-02-08T02:11:01.903192: step 2745, loss 0.012267, acc 1
2020-02-08T02:11:02.047669: step 2746, loss 0.01531, acc 1
2020-02-08T02:11:02.179596: step 2747, loss 0.0123381, acc 1
2020-02-08T02:11:02.329408: step 2748, loss 0.00966338, acc 1
2020-02-08T02:11:02.479077: step 2749, loss 0.0183657, acc 1
2020-02-08T02:11:02.631752: step 2750, loss 0.0212241, acc 0.984375
2020-02-08T02:11:02.781839: step 2751, loss 0.00977231, acc 1
2020-02-08T02:11:02.933515: step 2752, loss 0.0165255, acc 1
2020-02-08T02:11:03.093438: step 2753, loss 0.0352895, acc 0.984375
2020-02-08T02:11:03.254240: step 2754, loss 0.0179557, acc 1
2020-02-08T02:11:03.453339: step 2755, loss 0.0133049, acc 1
2020-02-08T02:11:03.597447: step 2756, loss 0.03423, acc 0.984375
2020-02-08T02:11:03.748206: step 2757, loss 0.0125572, acc 1
2020-02-08T02:11:03.909837: step 2758, loss 0.0117873, acc 1
2020-02-08T02:11:04.067082: step 2759, loss 0.0399843, acc 0.984375
2020-02-08T02:11:04.226609: step 2760, loss 0.0155474, acc 1
2020-02-08T02:11:04.383055: step 2761, loss 0.0267211, acc 1
2020-02-08T02:11:04.548449: step 2762, loss 0.00926414, acc 1
2020-02-08T02:11:04.720894: step 2763, loss 0.0321924, acc 0.984375
2020-02-08T02:11:04.879228: step 2764, loss 0.0201751, acc 0.984375
2020-02-08T02:11:05.045981: step 2765, loss 0.0197384, acc 1
2020-02-08T02:11:05.207734: step 2766, loss 0.00353691, acc 1
2020-02-08T02:11:05.365629: step 2767, loss 0.00999243, acc 1
2020-02-08T02:11:05.530368: step 2768, loss 0.0123887, acc 1
2020-02-08T02:11:05.701500: step 2769, loss 0.00979923, acc 1
2020-02-08T02:11:05.864859: step 2770, loss 0.0225663, acc 0.984375
2020-02-08T02:11:06.035497: step 2771, loss 0.0183703, acc 1
2020-02-08T02:11:06.199781: step 2772, loss 0.0427588, acc 0.984375
2020-02-08T02:11:06.368397: step 2773, loss 0.0141427, acc 1
2020-02-08T02:11:06.539933: step 2774, loss 0.0194628, acc 0.984375
2020-02-08T02:11:06.720920: step 2775, loss 0.0246802, acc 0.984375
2020-02-08T02:11:06.883236: step 2776, loss 0.0223369, acc 1
2020-02-08T02:11:07.047534: step 2777, loss 0.0269682, acc 0.984375
2020-02-08T02:11:07.218421: step 2778, loss 0.0714169, acc 0.984375
2020-02-08T02:11:07.407335: step 2779, loss 0.0152977, acc 1
2020-02-08T02:11:07.538866: step 2780, loss 0.0150928, acc 1
2020-02-08T02:11:07.673023: step 2781, loss 0.0139398, acc 1
2020-02-08T02:11:07.810342: step 2782, loss 0.0118156, acc 1
2020-02-08T02:11:07.954446: step 2783, loss 0.0095601, acc 1
2020-02-08T02:11:08.103376: step 2784, loss 0.00566076, acc 1
2020-02-08T02:11:08.274802: step 2785, loss 0.0241243, acc 1
2020-02-08T02:11:08.428263: step 2786, loss 0.0198641, acc 1
2020-02-08T02:11:08.598195: step 2787, loss 0.00589575, acc 1
2020-02-08T02:11:08.768691: step 2788, loss 0.00417245, acc 1
2020-02-08T02:11:08.930727: step 2789, loss 0.0303762, acc 0.984375
2020-02-08T02:11:09.097570: step 2790, loss 0.0189433, acc 1
2020-02-08T02:11:09.259910: step 2791, loss 0.0412779, acc 0.984375
2020-02-08T02:11:09.419137: step 2792, loss 0.030115, acc 1
2020-02-08T02:11:09.582144: step 2793, loss 0.0117943, acc 1
2020-02-08T02:11:09.760452: step 2794, loss 0.00983179, acc 1
2020-02-08T02:11:09.924928: step 2795, loss 0.025503, acc 0.984375
2020-02-08T02:11:10.097219: step 2796, loss 0.0160941, acc 1
2020-02-08T02:11:10.258364: step 2797, loss 0.0127241, acc 1
2020-02-08T02:11:10.420342: step 2798, loss 0.020951, acc 1
2020-02-08T02:11:10.585595: step 2799, loss 0.0196112, acc 1
2020-02-08T02:11:10.758501: step 2800, loss 0.0316892, acc 0.984375

Evaluation:
2020-02-08T02:11:11.037592: step 2800, loss 1.00918, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2800

2020-02-08T02:11:12.642273: step 2801, loss 0.0171209, acc 1
2020-02-08T02:11:12.814319: step 2802, loss 0.0102726, acc 1
2020-02-08T02:11:12.980026: step 2803, loss 0.00688396, acc 1
2020-02-08T02:11:13.148296: step 2804, loss 0.00741319, acc 1
2020-02-08T02:11:13.312310: step 2805, loss 0.00785949, acc 1
2020-02-08T02:11:13.479581: step 2806, loss 0.0419039, acc 0.984375
2020-02-08T02:11:13.652607: step 2807, loss 0.0185186, acc 1
2020-02-08T02:11:13.819070: step 2808, loss 0.0168898, acc 1
2020-02-08T02:11:13.986656: step 2809, loss 0.0484786, acc 0.984375
2020-02-08T02:11:14.159474: step 2810, loss 0.00804949, acc 1
2020-02-08T02:11:14.330587: step 2811, loss 0.0284896, acc 1
2020-02-08T02:11:14.503977: step 2812, loss 0.0418364, acc 0.984375
2020-02-08T02:11:14.684085: step 2813, loss 0.0267018, acc 0.984375
2020-02-08T02:11:14.855751: step 2814, loss 0.0142739, acc 1
2020-02-08T02:11:15.034066: step 2815, loss 0.0112839, acc 1
2020-02-08T02:11:15.203317: step 2816, loss 0.0237312, acc 1
2020-02-08T02:11:15.381217: step 2817, loss 0.00582632, acc 1
2020-02-08T02:11:15.555084: step 2818, loss 0.0641444, acc 0.96875
2020-02-08T02:11:15.736332: step 2819, loss 0.02764, acc 1
2020-02-08T02:11:15.913562: step 2820, loss 0.0102485, acc 1
2020-02-08T02:11:16.090331: step 2821, loss 0.0130394, acc 1
2020-02-08T02:11:16.266532: step 2822, loss 0.00583334, acc 1
2020-02-08T02:11:16.440759: step 2823, loss 0.0261027, acc 0.984375
2020-02-08T02:11:16.611843: step 2824, loss 0.0106883, acc 1
2020-02-08T02:11:16.824239: step 2825, loss 0.0242832, acc 0.984375
2020-02-08T02:11:16.977470: step 2826, loss 0.00585029, acc 1
2020-02-08T02:11:17.112407: step 2827, loss 0.0317448, acc 0.984375
2020-02-08T02:11:17.256905: step 2828, loss 0.0526623, acc 0.953125
2020-02-08T02:11:17.403282: step 2829, loss 0.0575364, acc 0.96875
2020-02-08T02:11:17.555479: step 2830, loss 0.0111931, acc 1
2020-02-08T02:11:17.707274: step 2831, loss 0.034092, acc 0.96875
2020-02-08T02:11:17.857340: step 2832, loss 0.0508504, acc 0.984375
2020-02-08T02:11:18.006048: step 2833, loss 0.00634334, acc 1
2020-02-08T02:11:18.152430: step 2834, loss 0.00897948, acc 1
2020-02-08T02:11:18.304284: step 2835, loss 0.0194397, acc 1
2020-02-08T02:11:18.471377: step 2836, loss 0.00689229, acc 1
2020-02-08T02:11:18.630567: step 2837, loss 0.0353524, acc 0.984375
2020-02-08T02:11:18.799060: step 2838, loss 0.0376869, acc 0.984375
2020-02-08T02:11:18.952990: step 2839, loss 0.0079868, acc 1
2020-02-08T02:11:19.104225: step 2840, loss 0.0510813, acc 0.984375
2020-02-08T02:11:19.265688: step 2841, loss 0.0426656, acc 0.984375
2020-02-08T02:11:19.424115: step 2842, loss 0.0495425, acc 0.984375
2020-02-08T02:11:19.587336: step 2843, loss 0.00658963, acc 1
2020-02-08T02:11:19.752750: step 2844, loss 0.0262863, acc 1
2020-02-08T02:11:19.915088: step 2845, loss 0.0195715, acc 1
2020-02-08T02:11:20.073691: step 2846, loss 0.0400496, acc 0.984375
2020-02-08T02:11:20.230812: step 2847, loss 0.0364279, acc 0.984375
2020-02-08T02:11:20.388606: step 2848, loss 0.0322227, acc 1
2020-02-08T02:11:20.555187: step 2849, loss 0.0165724, acc 1
2020-02-08T02:11:20.717975: step 2850, loss 0.0141786, acc 1
2020-02-08T02:11:20.874636: step 2851, loss 0.00770288, acc 1
2020-02-08T02:11:21.040299: step 2852, loss 0.00627996, acc 1
2020-02-08T02:11:21.207096: step 2853, loss 0.00438536, acc 1
2020-02-08T02:11:21.511980: step 2854, loss 0.019835, acc 1
2020-02-08T02:11:21.661998: step 2855, loss 0.0122384, acc 1
2020-02-08T02:11:21.805505: step 2856, loss 0.00581686, acc 1
2020-02-08T02:11:21.958285: step 2857, loss 0.00495733, acc 1
2020-02-08T02:11:22.123947: step 2858, loss 0.00462528, acc 1
2020-02-08T02:11:22.276356: step 2859, loss 0.00661546, acc 1
2020-02-08T02:11:22.439054: step 2860, loss 0.0244006, acc 0.984375
2020-02-08T02:11:22.604020: step 2861, loss 0.011532, acc 1
2020-02-08T02:11:22.772606: step 2862, loss 0.0252527, acc 1
2020-02-08T02:11:22.954589: step 2863, loss 0.08163, acc 0.984375
2020-02-08T02:11:23.110088: step 2864, loss 0.00256263, acc 1
2020-02-08T02:11:23.250983: step 2865, loss 0.0306961, acc 0.984375
2020-02-08T02:11:23.414546: step 2866, loss 0.00907895, acc 1
2020-02-08T02:11:23.577624: step 2867, loss 0.00727689, acc 1
2020-02-08T02:11:23.759732: step 2868, loss 0.0287458, acc 0.984375
2020-02-08T02:11:23.925004: step 2869, loss 0.00859655, acc 1
2020-02-08T02:11:24.091528: step 2870, loss 0.0122479, acc 1
2020-02-08T02:11:24.255331: step 2871, loss 0.0357993, acc 0.984375
2020-02-08T02:11:24.416835: step 2872, loss 0.0148357, acc 1
2020-02-08T02:11:24.574617: step 2873, loss 0.0156005, acc 0.984375
2020-02-08T02:11:24.748974: step 2874, loss 0.0308587, acc 0.984375
2020-02-08T02:11:24.909818: step 2875, loss 0.0343678, acc 0.984375
2020-02-08T02:11:25.068822: step 2876, loss 0.00867743, acc 1
2020-02-08T02:11:25.226103: step 2877, loss 0.00995896, acc 1
2020-02-08T02:11:25.393103: step 2878, loss 0.0192024, acc 1
2020-02-08T02:11:25.554977: step 2879, loss 0.0148186, acc 1
2020-02-08T02:11:25.722437: step 2880, loss 0.0120392, acc 1
2020-02-08T02:11:25.883879: step 2881, loss 0.0144339, acc 1
2020-02-08T02:11:26.045257: step 2882, loss 0.0121741, acc 1
2020-02-08T02:11:26.207340: step 2883, loss 0.00636288, acc 1
2020-02-08T02:11:26.372844: step 2884, loss 0.0109246, acc 1
2020-02-08T02:11:26.538576: step 2885, loss 0.00550356, acc 1
2020-02-08T02:11:26.714430: step 2886, loss 0.00559742, acc 1
2020-02-08T02:11:26.878627: step 2887, loss 0.00372658, acc 1
2020-02-08T02:11:27.045459: step 2888, loss 0.00427434, acc 1
2020-02-08T02:11:27.208529: step 2889, loss 0.0175559, acc 0.984375
2020-02-08T02:11:27.383035: step 2890, loss 0.0173476, acc 1
2020-02-08T02:11:27.551869: step 2891, loss 0.011739, acc 1
2020-02-08T02:11:27.721041: step 2892, loss 0.0316635, acc 0.984375
2020-02-08T02:11:27.883529: step 2893, loss 0.0389915, acc 0.96875
2020-02-08T02:11:28.051223: step 2894, loss 0.00680186, acc 1
2020-02-08T02:11:28.217972: step 2895, loss 0.0259195, acc 0.984375
2020-02-08T02:11:28.385331: step 2896, loss 0.0366171, acc 0.984375
2020-02-08T02:11:28.561351: step 2897, loss 0.0120634, acc 1
2020-02-08T02:11:28.740861: step 2898, loss 0.0621065, acc 0.984375
2020-02-08T02:11:28.909191: step 2899, loss 0.00621809, acc 1
2020-02-08T02:11:29.074538: step 2900, loss 0.00762118, acc 1

Evaluation:
2020-02-08T02:11:29.520540: step 2900, loss 1.02252, acc 0.724203

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-2900

2020-02-08T02:11:31.121985: step 2901, loss 0.00501218, acc 1
2020-02-08T02:11:31.290826: step 2902, loss 0.0234356, acc 0.984375
2020-02-08T02:11:31.462769: step 2903, loss 0.00959446, acc 1
2020-02-08T02:11:31.634716: step 2904, loss 0.0571248, acc 0.96875
2020-02-08T02:11:31.808512: step 2905, loss 0.0157531, acc 1
2020-02-08T02:11:31.974602: step 2906, loss 0.0181879, acc 1
2020-02-08T02:11:32.144502: step 2907, loss 0.0129296, acc 1
2020-02-08T02:11:32.318562: step 2908, loss 0.0170433, acc 1
2020-02-08T02:11:32.488862: step 2909, loss 0.0160725, acc 1
2020-02-08T02:11:32.659455: step 2910, loss 0.0113371, acc 1
2020-02-08T02:11:32.829386: step 2911, loss 0.00551244, acc 1
2020-02-08T02:11:32.999328: step 2912, loss 0.0885043, acc 0.984375
2020-02-08T02:11:33.169859: step 2913, loss 0.0108335, acc 1
2020-02-08T02:11:33.336824: step 2914, loss 0.011024, acc 1
2020-02-08T02:11:33.507677: step 2915, loss 0.00486932, acc 1
2020-02-08T02:11:33.675938: step 2916, loss 0.00439698, acc 1
2020-02-08T02:11:33.838765: step 2917, loss 0.00873457, acc 1
2020-02-08T02:11:34.009187: step 2918, loss 0.0877481, acc 0.96875
2020-02-08T02:11:34.177030: step 2919, loss 0.00989067, acc 1
2020-02-08T02:11:34.355577: step 2920, loss 0.0102195, acc 1
2020-02-08T02:11:34.515314: step 2921, loss 0.0173513, acc 0.984375
2020-02-08T02:11:34.687518: step 2922, loss 0.0160071, acc 1
2020-02-08T02:11:34.855923: step 2923, loss 0.0153219, acc 1
2020-02-08T02:11:35.016326: step 2924, loss 0.0769763, acc 0.96875
2020-02-08T02:11:35.182373: step 2925, loss 0.0325394, acc 0.984375
2020-02-08T02:11:35.356699: step 2926, loss 0.0379014, acc 0.984375
2020-02-08T02:11:35.530001: step 2927, loss 0.00784006, acc 1
2020-02-08T02:11:35.710159: step 2928, loss 0.0870126, acc 0.953125
2020-02-08T02:11:35.873034: step 2929, loss 0.0233358, acc 1
2020-02-08T02:11:36.026349: step 2930, loss 0.0233833, acc 0.984375
2020-02-08T02:11:36.187622: step 2931, loss 0.0118653, acc 1
2020-02-08T02:11:36.359867: step 2932, loss 0.00508736, acc 1
2020-02-08T02:11:36.528354: step 2933, loss 0.0134231, acc 1
2020-02-08T02:11:36.710651: step 2934, loss 0.014368, acc 1
2020-02-08T02:11:36.875440: step 2935, loss 0.0329532, acc 0.984375
2020-02-08T02:11:37.033431: step 2936, loss 0.00688093, acc 1
2020-02-08T02:11:37.206347: step 2937, loss 0.0344725, acc 0.984375
2020-02-08T02:11:37.370339: step 2938, loss 0.0221839, acc 0.984375
2020-02-08T02:11:37.532666: step 2939, loss 0.0116039, acc 1
2020-02-08T02:11:37.715246: step 2940, loss 0.0113973, acc 1
2020-02-08T02:11:37.901147: step 2941, loss 0.0186915, acc 1
2020-02-08T02:11:38.066290: step 2942, loss 0.00177216, acc 1
2020-02-08T02:11:38.229148: step 2943, loss 0.0510671, acc 0.984375
2020-02-08T02:11:38.401377: step 2944, loss 0.00448294, acc 1
2020-02-08T02:11:38.573037: step 2945, loss 0.0632214, acc 0.96875
2020-02-08T02:11:38.755932: step 2946, loss 0.0118801, acc 1
2020-02-08T02:11:38.918335: step 2947, loss 0.00414923, acc 1
2020-02-08T02:11:39.098374: step 2948, loss 0.00812231, acc 1
2020-02-08T02:11:39.288267: step 2949, loss 0.007452, acc 1
2020-02-08T02:11:39.464432: step 2950, loss 0.0179902, acc 1
2020-02-08T02:11:39.623606: step 2951, loss 0.0100774, acc 1
2020-02-08T02:11:39.814417: step 2952, loss 0.020676, acc 0.984375
2020-02-08T02:11:39.982939: step 2953, loss 0.0265968, acc 1
2020-02-08T02:11:40.157221: step 2954, loss 0.00478419, acc 1
2020-02-08T02:11:40.345111: step 2955, loss 0.0126718, acc 1
2020-02-08T02:11:40.520224: step 2956, loss 0.0110478, acc 1
2020-02-08T02:11:40.703226: step 2957, loss 0.00967662, acc 1
2020-02-08T02:11:40.889118: step 2958, loss 0.0115113, acc 1
2020-02-08T02:11:41.075701: step 2959, loss 0.024883, acc 0.984375
2020-02-08T02:11:41.242202: step 2960, loss 0.0111911, acc 1
2020-02-08T02:11:41.414022: step 2961, loss 0.00574981, acc 1
2020-02-08T02:11:41.580551: step 2962, loss 0.0108377, acc 1
2020-02-08T02:11:41.764181: step 2963, loss 0.0247978, acc 1
2020-02-08T02:11:41.933578: step 2964, loss 0.0214223, acc 1
2020-02-08T02:11:42.106982: step 2965, loss 0.00455594, acc 1
2020-02-08T02:11:42.277642: step 2966, loss 0.0227454, acc 0.984375
2020-02-08T02:11:42.444254: step 2967, loss 0.0151513, acc 1
2020-02-08T02:11:42.614775: step 2968, loss 0.0721388, acc 0.96875
2020-02-08T02:11:42.797265: step 2969, loss 0.0134867, acc 1
2020-02-08T02:11:42.970393: step 2970, loss 0.0064663, acc 1
2020-02-08T02:11:43.147493: step 2971, loss 0.00497805, acc 1
2020-02-08T02:11:43.318446: step 2972, loss 0.0165561, acc 1
2020-02-08T02:11:43.499679: step 2973, loss 0.0197549, acc 1
2020-02-08T02:11:43.670782: step 2974, loss 0.013103, acc 1
2020-02-08T02:11:43.847084: step 2975, loss 0.10062, acc 0.9375
2020-02-08T02:11:44.017254: step 2976, loss 0.0213356, acc 1
2020-02-08T02:11:44.186640: step 2977, loss 0.00584485, acc 1
2020-02-08T02:11:44.366160: step 2978, loss 0.0101755, acc 1
2020-02-08T02:11:44.535555: step 2979, loss 0.00396677, acc 1
2020-02-08T02:11:44.718932: step 2980, loss 0.00951265, acc 1
2020-02-08T02:11:44.893072: step 2981, loss 0.0249903, acc 0.984375
2020-02-08T02:11:45.060980: step 2982, loss 0.0111243, acc 1
2020-02-08T02:11:45.224551: step 2983, loss 0.00902338, acc 1
2020-02-08T02:11:45.394959: step 2984, loss 0.0407656, acc 0.984375
2020-02-08T02:11:45.572712: step 2985, loss 0.0111729, acc 1
2020-02-08T02:11:45.752787: step 2986, loss 0.0481447, acc 0.984375
2020-02-08T02:11:45.920899: step 2987, loss 0.00910452, acc 1
2020-02-08T02:11:46.098428: step 2988, loss 0.00830908, acc 1
2020-02-08T02:11:46.268042: step 2989, loss 0.00260309, acc 1
2020-02-08T02:11:46.429247: step 2990, loss 0.00476464, acc 1
2020-02-08T02:11:46.604349: step 2991, loss 0.0568256, acc 0.96875
2020-02-08T02:11:46.781726: step 2992, loss 0.0693923, acc 0.96875
2020-02-08T02:11:46.948451: step 2993, loss 0.0382546, acc 0.984375
2020-02-08T02:11:47.117115: step 2994, loss 0.0703562, acc 0.984375
2020-02-08T02:11:47.291497: step 2995, loss 0.00747216, acc 1
2020-02-08T02:11:47.459539: step 2996, loss 0.0535924, acc 0.984375
2020-02-08T02:11:47.625503: step 2997, loss 0.00674498, acc 1
2020-02-08T02:11:47.800609: step 2998, loss 0.0228083, acc 1
2020-02-08T02:11:47.978850: step 2999, loss 0.0143665, acc 1
2020-02-08T02:11:48.138963: step 3000, loss 0.0208452, acc 1

Evaluation:
2020-02-08T02:11:48.435185: step 3000, loss 1.08015, acc 0.716698

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581098439/checkpoints/model-3000

