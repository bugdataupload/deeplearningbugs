WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:11:58.098305 4542004672 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:11:58.098871 4542004672 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:11:58.099131 4542004672 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:11:58.791152 4542004672 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:11:58.791543 4542004672 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:11:58.791852: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:11:58.814111: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9420ea1c10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:11:58.814156: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:11:58.815259 4542004672 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:11:58.822021 4542004672 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:11:58.841629 4542004672 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:11:58.859581 4542004672 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:11:58.906980 4542004672 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:11:58.921496 4542004672 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:11:58.921755 4542004672 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:11:58.942646 4542004672 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:11:58.946002 4542004672 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:11:59.000361 4542004672 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:11:59.422682 4542004672 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:11:59.422934 4542004672 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:11:59.428693 4542004672 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:11:59.463202 4542004672 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:11:59.466929 4542004672 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:11:59.495911 4542004672 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:11:59.498836 4542004672 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:11:59.524147 4542004672 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:11:59.525724 4542004672 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:11:59.555824 4542004672 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:11:59.557010 4542004672 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:11:59.577269 4542004672 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:11:59.578362 4542004672 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:11:59.609475 4542004672 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:11:59.610874 4542004672 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:11:59.639973 4542004672 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:11:59.643147 4542004672 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:11:59.671422 4542004672 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:11:59.672869 4542004672 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:11:59.703287 4542004672 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:11:59.704822 4542004672 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:11:59.708335 4542004672 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:12:00.078104 4542004672 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:12:00.078510 4542004672 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:12:00.199995 4542004672 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:12:00.971678 4542004672 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:13:43.956241 4542004672 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119

2020-02-08T02:12:00.971236: step 1, loss 4.21426, acc 0.515625
2020-02-08T02:12:01.155016: step 2, loss 2.64614, acc 0.46875
2020-02-08T02:12:01.321284: step 3, loss 2.3749, acc 0.453125
2020-02-08T02:12:01.498908: step 4, loss 1.96262, acc 0.53125
2020-02-08T02:12:01.668277: step 5, loss 1.95553, acc 0.59375
2020-02-08T02:12:01.827361: step 6, loss 2.42702, acc 0.453125
2020-02-08T02:12:01.995506: step 7, loss 2.57822, acc 0.5
2020-02-08T02:12:02.170328: step 8, loss 2.65987, acc 0.5
2020-02-08T02:12:02.342516: step 9, loss 1.77532, acc 0.515625
2020-02-08T02:12:02.514135: step 10, loss 3.13295, acc 0.390625
2020-02-08T02:12:02.689833: step 11, loss 2.15685, acc 0.4375
2020-02-08T02:12:02.856363: step 12, loss 1.67729, acc 0.515625
2020-02-08T02:12:03.022244: step 13, loss 2.05459, acc 0.46875
2020-02-08T02:12:03.196278: step 14, loss 1.40451, acc 0.640625
2020-02-08T02:12:03.369373: step 15, loss 1.8405, acc 0.578125
2020-02-08T02:12:03.543631: step 16, loss 1.96768, acc 0.546875
2020-02-08T02:12:03.726226: step 17, loss 2.17999, acc 0.484375
2020-02-08T02:12:03.900047: step 18, loss 2.17222, acc 0.5
2020-02-08T02:12:04.070221: step 19, loss 2.11214, acc 0.40625
2020-02-08T02:12:04.231290: step 20, loss 2.09659, acc 0.46875
2020-02-08T02:12:04.407432: step 21, loss 1.67185, acc 0.546875
2020-02-08T02:12:04.605291: step 22, loss 2.14104, acc 0.515625
2020-02-08T02:12:04.785148: step 23, loss 1.59395, acc 0.625
2020-02-08T02:12:04.950911: step 24, loss 1.74093, acc 0.421875
2020-02-08T02:12:05.118576: step 25, loss 1.11337, acc 0.609375
2020-02-08T02:12:05.278983: step 26, loss 1.50173, acc 0.53125
2020-02-08T02:12:05.444801: step 27, loss 1.79224, acc 0.515625
2020-02-08T02:12:05.610700: step 28, loss 2.0336, acc 0.46875
2020-02-08T02:12:05.788848: step 29, loss 1.8425, acc 0.5625
2020-02-08T02:12:06.001397: step 30, loss 1.97147, acc 0.40625
2020-02-08T02:12:06.441876: step 31, loss 2.41823, acc 0.453125
2020-02-08T02:12:06.812750: step 32, loss 1.4869, acc 0.5625
2020-02-08T02:12:07.116011: step 33, loss 1.46554, acc 0.59375
2020-02-08T02:12:07.251422: step 34, loss 2.47858, acc 0.375
2020-02-08T02:12:07.387689: step 35, loss 1.7236, acc 0.4375
2020-02-08T02:12:07.540953: step 36, loss 1.57427, acc 0.546875
2020-02-08T02:12:07.730625: step 37, loss 1.78347, acc 0.515625
2020-02-08T02:12:07.966225: step 38, loss 1.99311, acc 0.53125
2020-02-08T02:12:08.239226: step 39, loss 1.32638, acc 0.59375
2020-02-08T02:12:08.507288: step 40, loss 1.77797, acc 0.578125
2020-02-08T02:12:08.691385: step 41, loss 1.5809, acc 0.5
2020-02-08T02:12:08.966541: step 42, loss 1.36394, acc 0.609375
2020-02-08T02:12:09.197027: step 43, loss 1.27448, acc 0.609375
2020-02-08T02:12:09.355433: step 44, loss 1.55691, acc 0.5625
2020-02-08T02:12:09.655712: step 45, loss 1.62759, acc 0.484375
2020-02-08T02:12:09.905078: step 46, loss 1.6976, acc 0.4375
2020-02-08T02:12:10.078876: step 47, loss 1.79451, acc 0.46875
2020-02-08T02:12:10.222448: step 48, loss 2.10989, acc 0.515625
2020-02-08T02:12:10.363032: step 49, loss 1.92454, acc 0.390625
2020-02-08T02:12:10.567783: step 50, loss 1.25131, acc 0.609375
2020-02-08T02:12:10.810142: step 51, loss 1.99763, acc 0.484375
2020-02-08T02:12:10.964169: step 52, loss 1.86762, acc 0.5
2020-02-08T02:12:11.104385: step 53, loss 1.63051, acc 0.5
2020-02-08T02:12:11.247692: step 54, loss 1.87729, acc 0.546875
2020-02-08T02:12:11.398968: step 55, loss 1.63295, acc 0.453125
2020-02-08T02:12:11.551311: step 56, loss 1.29151, acc 0.609375
2020-02-08T02:12:11.791685: step 57, loss 1.12242, acc 0.65625
2020-02-08T02:12:11.956526: step 58, loss 1.37633, acc 0.578125
2020-02-08T02:12:12.097037: step 59, loss 1.37159, acc 0.515625
2020-02-08T02:12:12.244643: step 60, loss 1.18507, acc 0.5
2020-02-08T02:12:12.457514: step 61, loss 1.21789, acc 0.5625
2020-02-08T02:12:12.614251: step 62, loss 1.36816, acc 0.625
2020-02-08T02:12:12.766464: step 63, loss 1.27946, acc 0.609375
2020-02-08T02:12:12.912298: step 64, loss 1.39558, acc 0.546875
2020-02-08T02:12:13.104970: step 65, loss 1.30807, acc 0.53125
2020-02-08T02:12:13.272388: step 66, loss 1.62469, acc 0.546875
2020-02-08T02:12:13.416856: step 67, loss 2.20277, acc 0.40625
2020-02-08T02:12:13.566223: step 68, loss 1.34266, acc 0.640625
2020-02-08T02:12:13.743048: step 69, loss 1.5012, acc 0.578125
2020-02-08T02:12:13.951875: step 70, loss 1.25899, acc 0.578125
2020-02-08T02:12:14.110588: step 71, loss 1.04555, acc 0.59375
2020-02-08T02:12:14.322872: step 72, loss 1.53855, acc 0.53125
2020-02-08T02:12:14.488617: step 73, loss 1.55995, acc 0.453125
2020-02-08T02:12:14.626728: step 74, loss 1.53832, acc 0.453125
2020-02-08T02:12:14.774666: step 75, loss 1.40217, acc 0.53125
2020-02-08T02:12:14.912694: step 76, loss 1.5461, acc 0.46875
2020-02-08T02:12:15.060644: step 77, loss 1.23495, acc 0.484375
2020-02-08T02:12:15.208507: step 78, loss 1.38035, acc 0.546875
2020-02-08T02:12:15.346150: step 79, loss 1.64821, acc 0.578125
2020-02-08T02:12:15.482093: step 80, loss 1.55409, acc 0.546875
2020-02-08T02:12:15.625360: step 81, loss 1.1433, acc 0.640625
2020-02-08T02:12:15.769790: step 82, loss 1.78493, acc 0.484375
2020-02-08T02:12:15.922978: step 83, loss 1.09373, acc 0.65625
2020-02-08T02:12:16.074031: step 84, loss 1.84417, acc 0.46875
2020-02-08T02:12:16.297175: step 85, loss 1.36088, acc 0.59375
2020-02-08T02:12:16.432638: step 86, loss 1.38145, acc 0.46875
2020-02-08T02:12:16.569122: step 87, loss 1.17683, acc 0.578125
2020-02-08T02:12:16.717843: step 88, loss 1.34095, acc 0.515625
2020-02-08T02:12:16.862464: step 89, loss 1.42546, acc 0.5
2020-02-08T02:12:17.003698: step 90, loss 1.65288, acc 0.421875
2020-02-08T02:12:17.146015: step 91, loss 1.40703, acc 0.5
2020-02-08T02:12:17.282103: step 92, loss 1.57986, acc 0.5625
2020-02-08T02:12:17.459143: step 93, loss 1.268, acc 0.671875
2020-02-08T02:12:17.613772: step 94, loss 1.58159, acc 0.4375
2020-02-08T02:12:17.767218: step 95, loss 1.99247, acc 0.453125
2020-02-08T02:12:17.914683: step 96, loss 1.48735, acc 0.5
2020-02-08T02:12:18.054381: step 97, loss 1.79837, acc 0.453125
2020-02-08T02:12:18.200536: step 98, loss 1.48476, acc 0.578125
2020-02-08T02:12:18.346056: step 99, loss 1.54705, acc 0.53125
2020-02-08T02:12:18.488117: step 100, loss 1.46386, acc 0.5625

Evaluation:
2020-02-08T02:12:18.805352: step 100, loss 0.89616, acc 0.566604

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-100

2020-02-08T02:12:21.647511: step 101, loss 1.22288, acc 0.578125
2020-02-08T02:12:21.904365: step 102, loss 1.00062, acc 0.609375
2020-02-08T02:12:22.130991: step 103, loss 1.72619, acc 0.390625
2020-02-08T02:12:22.277685: step 104, loss 1.27678, acc 0.59375
2020-02-08T02:12:22.417750: step 105, loss 1.39323, acc 0.515625
2020-02-08T02:12:22.624101: step 106, loss 1.63784, acc 0.515625
2020-02-08T02:12:22.800186: step 107, loss 1.38262, acc 0.65625
2020-02-08T02:12:22.935120: step 108, loss 1.3474, acc 0.53125
2020-02-08T02:12:23.069391: step 109, loss 1.77364, acc 0.453125
2020-02-08T02:12:23.207994: step 110, loss 1.50871, acc 0.578125
2020-02-08T02:12:23.354840: step 111, loss 1.23153, acc 0.515625
2020-02-08T02:12:23.503583: step 112, loss 1.62702, acc 0.484375
2020-02-08T02:12:23.647119: step 113, loss 1.18458, acc 0.609375
2020-02-08T02:12:23.791107: step 114, loss 0.987033, acc 0.59375
2020-02-08T02:12:23.930236: step 115, loss 1.73011, acc 0.546875
2020-02-08T02:12:24.065142: step 116, loss 1.62572, acc 0.4375
2020-02-08T02:12:24.203643: step 117, loss 1.6132, acc 0.46875
2020-02-08T02:12:24.346663: step 118, loss 1.33035, acc 0.546875
2020-02-08T02:12:24.486239: step 119, loss 1.36703, acc 0.53125
2020-02-08T02:12:24.622406: step 120, loss 1.33977, acc 0.59375
2020-02-08T02:12:24.772221: step 121, loss 1.57198, acc 0.5625
2020-02-08T02:12:24.935811: step 122, loss 1.40381, acc 0.5625
2020-02-08T02:12:25.068366: step 123, loss 1.0891, acc 0.578125
2020-02-08T02:12:25.205620: step 124, loss 1.3852, acc 0.5625
2020-02-08T02:12:25.337510: step 125, loss 1.28971, acc 0.546875
2020-02-08T02:12:25.473504: step 126, loss 1.27269, acc 0.59375
2020-02-08T02:12:25.611187: step 127, loss 1.29028, acc 0.5625
2020-02-08T02:12:25.757142: step 128, loss 1.30384, acc 0.515625
2020-02-08T02:12:25.895326: step 129, loss 1.04093, acc 0.59375
2020-02-08T02:12:26.032253: step 130, loss 1.21217, acc 0.546875
2020-02-08T02:12:26.168333: step 131, loss 1.61221, acc 0.484375
2020-02-08T02:12:26.304028: step 132, loss 1.53477, acc 0.515625
2020-02-08T02:12:26.455569: step 133, loss 1.2421, acc 0.578125
2020-02-08T02:12:26.599271: step 134, loss 1.81553, acc 0.5
2020-02-08T02:12:26.739003: step 135, loss 1.4183, acc 0.5
2020-02-08T02:12:26.874922: step 136, loss 1.54462, acc 0.484375
2020-02-08T02:12:27.012736: step 137, loss 1.37157, acc 0.5
2020-02-08T02:12:27.146808: step 138, loss 1.43195, acc 0.5
2020-02-08T02:12:27.281870: step 139, loss 1.0292, acc 0.546875
2020-02-08T02:12:27.417205: step 140, loss 1.07083, acc 0.5625
2020-02-08T02:12:27.551093: step 141, loss 1.41242, acc 0.5625
2020-02-08T02:12:27.697142: step 142, loss 1.22269, acc 0.578125
2020-02-08T02:12:27.835232: step 143, loss 1.4765, acc 0.546875
2020-02-08T02:12:28.001254: step 144, loss 1.16175, acc 0.53125
2020-02-08T02:12:28.218050: step 145, loss 1.66, acc 0.546875
2020-02-08T02:12:28.365697: step 146, loss 1.10968, acc 0.625
2020-02-08T02:12:28.507617: step 147, loss 1.2964, acc 0.515625
2020-02-08T02:12:28.675794: step 148, loss 1.25483, acc 0.5
2020-02-08T02:12:28.824030: step 149, loss 1.5506, acc 0.421875
2020-02-08T02:12:28.967195: step 150, loss 1.1382, acc 0.55
2020-02-08T02:12:29.104842: step 151, loss 1.30997, acc 0.546875
2020-02-08T02:12:29.250376: step 152, loss 1.22155, acc 0.515625
2020-02-08T02:12:29.429365: step 153, loss 0.780879, acc 0.734375
2020-02-08T02:12:29.616346: step 154, loss 1.01866, acc 0.671875
2020-02-08T02:12:29.767072: step 155, loss 0.956109, acc 0.578125
2020-02-08T02:12:29.908183: step 156, loss 0.878684, acc 0.71875
2020-02-08T02:12:30.108051: step 157, loss 0.912903, acc 0.609375
2020-02-08T02:12:30.254799: step 158, loss 1.0757, acc 0.640625
2020-02-08T02:12:30.397204: step 159, loss 0.898915, acc 0.6875
2020-02-08T02:12:30.534325: step 160, loss 0.983223, acc 0.578125
2020-02-08T02:12:30.676646: step 161, loss 0.661927, acc 0.8125
2020-02-08T02:12:30.822856: step 162, loss 0.900358, acc 0.671875
2020-02-08T02:12:30.962753: step 163, loss 1.00084, acc 0.578125
2020-02-08T02:12:31.099348: step 164, loss 1.035, acc 0.65625
2020-02-08T02:12:31.233455: step 165, loss 1.26202, acc 0.53125
2020-02-08T02:12:31.369219: step 166, loss 1.07872, acc 0.546875
2020-02-08T02:12:31.504777: step 167, loss 0.883449, acc 0.6875
2020-02-08T02:12:31.644963: step 168, loss 0.972766, acc 0.578125
2020-02-08T02:12:31.783188: step 169, loss 1.00088, acc 0.625
2020-02-08T02:12:31.919749: step 170, loss 1.19232, acc 0.578125
2020-02-08T02:12:32.053545: step 171, loss 1.16664, acc 0.5625
2020-02-08T02:12:32.189934: step 172, loss 0.936664, acc 0.59375
2020-02-08T02:12:32.324412: step 173, loss 0.883219, acc 0.609375
2020-02-08T02:12:32.460936: step 174, loss 0.999553, acc 0.578125
2020-02-08T02:12:32.592695: step 175, loss 1.19105, acc 0.53125
2020-02-08T02:12:32.736797: step 176, loss 1.07909, acc 0.59375
2020-02-08T02:12:32.870298: step 177, loss 1.23663, acc 0.625
2020-02-08T02:12:33.011149: step 178, loss 1.18598, acc 0.53125
2020-02-08T02:12:33.144498: step 179, loss 0.838163, acc 0.578125
2020-02-08T02:12:33.276635: step 180, loss 1.09406, acc 0.625
2020-02-08T02:12:33.411862: step 181, loss 0.990415, acc 0.5625
2020-02-08T02:12:33.554445: step 182, loss 0.757929, acc 0.671875
2020-02-08T02:12:33.701405: step 183, loss 0.98902, acc 0.53125
2020-02-08T02:12:33.839640: step 184, loss 0.649541, acc 0.71875
2020-02-08T02:12:33.977691: step 185, loss 1.08485, acc 0.609375
2020-02-08T02:12:34.112119: step 186, loss 0.935351, acc 0.671875
2020-02-08T02:12:34.244647: step 187, loss 0.845542, acc 0.6875
2020-02-08T02:12:34.380253: step 188, loss 0.827837, acc 0.671875
2020-02-08T02:12:34.518394: step 189, loss 0.926544, acc 0.609375
2020-02-08T02:12:34.657247: step 190, loss 0.848236, acc 0.625
2020-02-08T02:12:34.792215: step 191, loss 0.91259, acc 0.609375
2020-02-08T02:12:34.924681: step 192, loss 0.901884, acc 0.671875
2020-02-08T02:12:35.060721: step 193, loss 0.846002, acc 0.609375
2020-02-08T02:12:35.196411: step 194, loss 0.809805, acc 0.671875
2020-02-08T02:12:35.336222: step 195, loss 0.939222, acc 0.640625
2020-02-08T02:12:35.473722: step 196, loss 1.07921, acc 0.5625
2020-02-08T02:12:35.614731: step 197, loss 0.965761, acc 0.578125
2020-02-08T02:12:35.758932: step 198, loss 1.17695, acc 0.5
2020-02-08T02:12:35.895046: step 199, loss 0.846948, acc 0.625
2020-02-08T02:12:36.029683: step 200, loss 0.706253, acc 0.671875

Evaluation:
2020-02-08T02:12:36.259817: step 200, loss 0.66874, acc 0.611632

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-200

2020-02-08T02:12:37.862293: step 201, loss 0.859407, acc 0.65625
2020-02-08T02:12:38.008942: step 202, loss 0.609095, acc 0.65625
2020-02-08T02:12:38.178502: step 203, loss 1.03456, acc 0.515625
2020-02-08T02:12:38.313810: step 204, loss 0.81412, acc 0.625
2020-02-08T02:12:38.451997: step 205, loss 0.831237, acc 0.640625
2020-02-08T02:12:38.584390: step 206, loss 1.06571, acc 0.59375
2020-02-08T02:12:38.738233: step 207, loss 0.989808, acc 0.625
2020-02-08T02:12:38.878140: step 208, loss 1.11937, acc 0.53125
2020-02-08T02:12:39.011788: step 209, loss 0.976325, acc 0.609375
2020-02-08T02:12:39.152715: step 210, loss 0.687553, acc 0.671875
2020-02-08T02:12:39.294372: step 211, loss 1.05706, acc 0.546875
2020-02-08T02:12:39.430005: step 212, loss 0.988851, acc 0.6875
2020-02-08T02:12:39.564956: step 213, loss 0.84932, acc 0.65625
2020-02-08T02:12:39.708453: step 214, loss 0.961488, acc 0.625
2020-02-08T02:12:39.854685: step 215, loss 1.00503, acc 0.640625
2020-02-08T02:12:40.031031: step 216, loss 0.870288, acc 0.625
2020-02-08T02:12:40.173061: step 217, loss 1.02332, acc 0.515625
2020-02-08T02:12:40.304149: step 218, loss 0.895307, acc 0.609375
2020-02-08T02:12:40.445459: step 219, loss 0.934225, acc 0.640625
2020-02-08T02:12:40.598711: step 220, loss 0.827571, acc 0.609375
2020-02-08T02:12:40.740910: step 221, loss 0.668008, acc 0.734375
2020-02-08T02:12:40.879358: step 222, loss 0.888793, acc 0.609375
2020-02-08T02:12:41.025990: step 223, loss 0.780019, acc 0.671875
2020-02-08T02:12:41.160304: step 224, loss 0.887792, acc 0.640625
2020-02-08T02:12:41.316538: step 225, loss 0.959609, acc 0.609375
2020-02-08T02:12:41.548834: step 226, loss 0.867567, acc 0.625
2020-02-08T02:12:41.695219: step 227, loss 0.760694, acc 0.609375
2020-02-08T02:12:41.831312: step 228, loss 0.821237, acc 0.671875
2020-02-08T02:12:41.966336: step 229, loss 1.09981, acc 0.5625
2020-02-08T02:12:42.149812: step 230, loss 0.983505, acc 0.515625
2020-02-08T02:12:42.322300: step 231, loss 1.12429, acc 0.625
2020-02-08T02:12:42.483288: step 232, loss 0.703239, acc 0.75
2020-02-08T02:12:42.619610: step 233, loss 0.76209, acc 0.65625
2020-02-08T02:12:42.762853: step 234, loss 0.92813, acc 0.640625
2020-02-08T02:12:42.908689: step 235, loss 0.994079, acc 0.578125
2020-02-08T02:12:43.048602: step 236, loss 1.05214, acc 0.53125
2020-02-08T02:12:43.182553: step 237, loss 1.11903, acc 0.59375
2020-02-08T02:12:43.317369: step 238, loss 0.888406, acc 0.546875
2020-02-08T02:12:43.449219: step 239, loss 0.884368, acc 0.640625
2020-02-08T02:12:43.591991: step 240, loss 0.860091, acc 0.515625
2020-02-08T02:12:43.739864: step 241, loss 0.810228, acc 0.640625
2020-02-08T02:12:43.878083: step 242, loss 1.0247, acc 0.546875
2020-02-08T02:12:44.015558: step 243, loss 0.724647, acc 0.6875
2020-02-08T02:12:44.150871: step 244, loss 0.793426, acc 0.640625
2020-02-08T02:12:44.280343: step 245, loss 0.646065, acc 0.734375
2020-02-08T02:12:44.415741: step 246, loss 0.692343, acc 0.703125
2020-02-08T02:12:44.557739: step 247, loss 1.10142, acc 0.546875
2020-02-08T02:12:44.694741: step 248, loss 1.1726, acc 0.484375
2020-02-08T02:12:44.827477: step 249, loss 0.931147, acc 0.546875
2020-02-08T02:12:44.961434: step 250, loss 0.854361, acc 0.65625
2020-02-08T02:12:45.099199: step 251, loss 0.741928, acc 0.640625
2020-02-08T02:12:45.235528: step 252, loss 0.958098, acc 0.625
2020-02-08T02:12:45.373938: step 253, loss 0.962809, acc 0.546875
2020-02-08T02:12:45.512202: step 254, loss 0.77786, acc 0.640625
2020-02-08T02:12:45.653208: step 255, loss 0.802557, acc 0.609375
2020-02-08T02:12:45.790297: step 256, loss 0.723341, acc 0.609375
2020-02-08T02:12:45.925066: step 257, loss 0.927408, acc 0.53125
2020-02-08T02:12:46.062797: step 258, loss 0.889984, acc 0.6875
2020-02-08T02:12:46.198064: step 259, loss 0.787431, acc 0.640625
2020-02-08T02:12:46.333433: step 260, loss 0.630714, acc 0.640625
2020-02-08T02:12:46.471560: step 261, loss 0.792276, acc 0.734375
2020-02-08T02:12:46.602619: step 262, loss 0.66359, acc 0.703125
2020-02-08T02:12:46.747924: step 263, loss 0.562451, acc 0.75
2020-02-08T02:12:46.882995: step 264, loss 0.642515, acc 0.65625
2020-02-08T02:12:47.019267: step 265, loss 0.773675, acc 0.6875
2020-02-08T02:12:47.157971: step 266, loss 0.853883, acc 0.609375
2020-02-08T02:12:47.287827: step 267, loss 0.753643, acc 0.65625
2020-02-08T02:12:47.426212: step 268, loss 0.907666, acc 0.609375
2020-02-08T02:12:47.565695: step 269, loss 0.651513, acc 0.6875
2020-02-08T02:12:47.710045: step 270, loss 0.840439, acc 0.6875
2020-02-08T02:12:47.848123: step 271, loss 0.671771, acc 0.671875
2020-02-08T02:12:47.981272: step 272, loss 0.873834, acc 0.546875
2020-02-08T02:12:48.128090: step 273, loss 1.00293, acc 0.578125
2020-02-08T02:12:48.280018: step 274, loss 0.824158, acc 0.671875
2020-02-08T02:12:48.441834: step 275, loss 0.700574, acc 0.640625
2020-02-08T02:12:48.609622: step 276, loss 0.955086, acc 0.578125
2020-02-08T02:12:48.772028: step 277, loss 1.05294, acc 0.578125
2020-02-08T02:12:48.970207: step 278, loss 0.773759, acc 0.703125
2020-02-08T02:12:49.167540: step 279, loss 0.602325, acc 0.734375
2020-02-08T02:12:49.385627: step 280, loss 0.589643, acc 0.703125
2020-02-08T02:12:49.581084: step 281, loss 0.932229, acc 0.609375
2020-02-08T02:12:49.735191: step 282, loss 0.843081, acc 0.609375
2020-02-08T02:12:49.873905: step 283, loss 0.807023, acc 0.59375
2020-02-08T02:12:50.016775: step 284, loss 0.897699, acc 0.5625
2020-02-08T02:12:50.164128: step 285, loss 0.811941, acc 0.65625
2020-02-08T02:12:50.313669: step 286, loss 0.797659, acc 0.625
2020-02-08T02:12:50.454650: step 287, loss 0.929169, acc 0.53125
2020-02-08T02:12:50.737220: step 288, loss 0.9309, acc 0.546875
2020-02-08T02:12:50.943207: step 289, loss 0.986726, acc 0.578125
2020-02-08T02:12:51.096365: step 290, loss 0.868165, acc 0.546875
2020-02-08T02:12:51.223161: step 291, loss 0.935447, acc 0.546875
2020-02-08T02:12:51.520143: step 292, loss 0.848225, acc 0.609375
2020-02-08T02:12:51.667987: step 293, loss 0.787648, acc 0.65625
2020-02-08T02:12:51.803979: step 294, loss 0.743287, acc 0.65625
2020-02-08T02:12:51.924855: step 295, loss 0.781353, acc 0.6875
2020-02-08T02:12:52.047523: step 296, loss 0.750987, acc 0.6875
2020-02-08T02:12:52.188170: step 297, loss 0.787153, acc 0.59375
2020-02-08T02:12:52.372627: step 298, loss 0.855902, acc 0.5625
2020-02-08T02:12:52.502354: step 299, loss 0.7899, acc 0.65625
2020-02-08T02:12:52.623521: step 300, loss 0.858583, acc 0.566667

Evaluation:
2020-02-08T02:12:52.963646: step 300, loss 0.647802, acc 0.619137

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-300

2020-02-08T02:12:54.540238: step 301, loss 0.974688, acc 0.53125
2020-02-08T02:12:54.767163: step 302, loss 0.643941, acc 0.671875
2020-02-08T02:12:55.056757: step 303, loss 0.678373, acc 0.6875
2020-02-08T02:12:55.186895: step 304, loss 0.590554, acc 0.734375
2020-02-08T02:12:55.389150: step 305, loss 0.856758, acc 0.578125
2020-02-08T02:12:55.585489: step 306, loss 0.676529, acc 0.640625
2020-02-08T02:12:55.747525: step 307, loss 0.692389, acc 0.71875
2020-02-08T02:12:55.883664: step 308, loss 0.555229, acc 0.65625
2020-02-08T02:12:56.061925: step 309, loss 0.723311, acc 0.671875
2020-02-08T02:12:56.186709: step 310, loss 0.897184, acc 0.5625
2020-02-08T02:12:56.328671: step 311, loss 0.8433, acc 0.625
2020-02-08T02:12:56.458948: step 312, loss 0.594882, acc 0.71875
2020-02-08T02:12:56.616052: step 313, loss 0.702254, acc 0.6875
2020-02-08T02:12:56.768504: step 314, loss 0.740804, acc 0.71875
2020-02-08T02:12:56.900104: step 315, loss 0.532955, acc 0.734375
2020-02-08T02:12:57.030381: step 316, loss 0.862842, acc 0.671875
2020-02-08T02:12:57.164491: step 317, loss 0.760012, acc 0.640625
2020-02-08T02:12:57.302795: step 318, loss 0.775064, acc 0.640625
2020-02-08T02:12:57.440812: step 319, loss 0.75858, acc 0.71875
2020-02-08T02:12:57.584731: step 320, loss 0.792676, acc 0.671875
2020-02-08T02:12:57.766413: step 321, loss 0.862111, acc 0.625
2020-02-08T02:12:57.901492: step 322, loss 0.785308, acc 0.59375
2020-02-08T02:12:58.023150: step 323, loss 0.661301, acc 0.640625
2020-02-08T02:12:58.152617: step 324, loss 0.55829, acc 0.6875
2020-02-08T02:12:58.300007: step 325, loss 0.875381, acc 0.59375
2020-02-08T02:12:58.437312: step 326, loss 0.650355, acc 0.609375
2020-02-08T02:12:58.705503: step 327, loss 0.649568, acc 0.640625
2020-02-08T02:12:58.834243: step 328, loss 0.834218, acc 0.640625
2020-02-08T02:12:58.958183: step 329, loss 0.672668, acc 0.703125
2020-02-08T02:12:59.100456: step 330, loss 0.758698, acc 0.6875
2020-02-08T02:12:59.249519: step 331, loss 0.865136, acc 0.625
2020-02-08T02:12:59.513143: step 332, loss 0.613713, acc 0.703125
2020-02-08T02:12:59.765912: step 333, loss 0.825331, acc 0.59375
2020-02-08T02:12:59.916991: step 334, loss 0.744135, acc 0.625
2020-02-08T02:13:00.072871: step 335, loss 0.726809, acc 0.671875
2020-02-08T02:13:00.276704: step 336, loss 0.71054, acc 0.671875
2020-02-08T02:13:00.424451: step 337, loss 0.584245, acc 0.6875
2020-02-08T02:13:00.570351: step 338, loss 0.776415, acc 0.578125
2020-02-08T02:13:00.720840: step 339, loss 0.620554, acc 0.6875
2020-02-08T02:13:00.846007: step 340, loss 0.675404, acc 0.703125
2020-02-08T02:13:00.976878: step 341, loss 0.666463, acc 0.640625
2020-02-08T02:13:01.142416: step 342, loss 0.774691, acc 0.578125
2020-02-08T02:13:01.308690: step 343, loss 0.800597, acc 0.609375
2020-02-08T02:13:01.440636: step 344, loss 0.707155, acc 0.640625
2020-02-08T02:13:01.639038: step 345, loss 0.591197, acc 0.6875
2020-02-08T02:13:01.818383: step 346, loss 0.630384, acc 0.6875
2020-02-08T02:13:01.961993: step 347, loss 0.616658, acc 0.703125
2020-02-08T02:13:02.104202: step 348, loss 0.680276, acc 0.703125
2020-02-08T02:13:02.282326: step 349, loss 0.682432, acc 0.703125
2020-02-08T02:13:02.426382: step 350, loss 0.589755, acc 0.765625
2020-02-08T02:13:02.575793: step 351, loss 0.589004, acc 0.734375
2020-02-08T02:13:02.740919: step 352, loss 0.805721, acc 0.625
2020-02-08T02:13:02.880031: step 353, loss 0.566615, acc 0.703125
2020-02-08T02:13:03.095743: step 354, loss 0.826994, acc 0.53125
2020-02-08T02:13:03.251013: step 355, loss 0.51508, acc 0.78125
2020-02-08T02:13:03.381271: step 356, loss 0.727357, acc 0.578125
2020-02-08T02:13:03.509869: step 357, loss 0.902228, acc 0.578125
2020-02-08T02:13:03.637685: step 358, loss 0.670623, acc 0.65625
2020-02-08T02:13:03.771327: step 359, loss 0.735275, acc 0.59375
2020-02-08T02:13:03.899048: step 360, loss 0.498184, acc 0.796875
2020-02-08T02:13:04.025852: step 361, loss 0.573857, acc 0.6875
2020-02-08T02:13:04.154535: step 362, loss 0.491301, acc 0.8125
2020-02-08T02:13:04.279312: step 363, loss 0.55424, acc 0.734375
2020-02-08T02:13:04.411752: step 364, loss 0.751935, acc 0.640625
2020-02-08T02:13:04.624156: step 365, loss 0.937255, acc 0.515625
2020-02-08T02:13:04.773737: step 366, loss 0.746608, acc 0.578125
2020-02-08T02:13:04.919436: step 367, loss 0.604565, acc 0.6875
2020-02-08T02:13:05.067872: step 368, loss 0.530408, acc 0.796875
2020-02-08T02:13:05.201812: step 369, loss 0.629305, acc 0.640625
2020-02-08T02:13:05.334816: step 370, loss 0.501411, acc 0.734375
2020-02-08T02:13:05.465734: step 371, loss 0.481624, acc 0.734375
2020-02-08T02:13:05.644834: step 372, loss 0.643884, acc 0.65625
2020-02-08T02:13:05.783269: step 373, loss 0.47896, acc 0.734375
2020-02-08T02:13:05.946792: step 374, loss 0.691162, acc 0.6875
2020-02-08T02:13:06.089816: step 375, loss 0.702142, acc 0.6875
2020-02-08T02:13:06.317578: step 376, loss 0.629594, acc 0.6875
2020-02-08T02:13:06.497179: step 377, loss 0.557509, acc 0.6875
2020-02-08T02:13:06.690041: step 378, loss 0.58909, acc 0.703125
2020-02-08T02:13:06.873241: step 379, loss 0.697243, acc 0.640625
2020-02-08T02:13:07.054033: step 380, loss 0.570521, acc 0.71875
2020-02-08T02:13:07.229261: step 381, loss 0.683384, acc 0.640625
2020-02-08T02:13:07.528365: step 382, loss 0.576819, acc 0.65625
2020-02-08T02:13:07.739255: step 383, loss 0.561131, acc 0.71875
2020-02-08T02:13:07.980829: step 384, loss 0.911047, acc 0.546875
2020-02-08T02:13:08.175714: step 385, loss 0.695184, acc 0.71875
2020-02-08T02:13:08.337752: step 386, loss 0.440765, acc 0.796875
2020-02-08T02:13:08.509468: step 387, loss 0.515674, acc 0.78125
2020-02-08T02:13:08.667219: step 388, loss 0.70241, acc 0.671875
2020-02-08T02:13:08.820844: step 389, loss 0.687071, acc 0.65625
2020-02-08T02:13:08.964991: step 390, loss 0.812755, acc 0.546875
2020-02-08T02:13:09.108836: step 391, loss 0.716611, acc 0.640625
2020-02-08T02:13:09.249300: step 392, loss 0.752042, acc 0.640625
2020-02-08T02:13:09.395443: step 393, loss 0.591385, acc 0.6875
2020-02-08T02:13:09.546863: step 394, loss 0.825243, acc 0.609375
2020-02-08T02:13:09.707103: step 395, loss 0.608074, acc 0.734375
2020-02-08T02:13:09.910254: step 396, loss 0.706856, acc 0.5625
2020-02-08T02:13:10.075650: step 397, loss 0.675005, acc 0.640625
2020-02-08T02:13:10.239233: step 398, loss 0.59667, acc 0.65625
2020-02-08T02:13:10.444116: step 399, loss 0.569505, acc 0.75
2020-02-08T02:13:10.595130: step 400, loss 0.669164, acc 0.671875

Evaluation:
2020-02-08T02:13:10.825818: step 400, loss 0.649252, acc 0.621013

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-400

2020-02-08T02:13:12.418399: step 401, loss 0.576087, acc 0.71875
2020-02-08T02:13:12.555963: step 402, loss 0.664083, acc 0.671875
2020-02-08T02:13:12.728778: step 403, loss 0.646164, acc 0.71875
2020-02-08T02:13:12.863473: step 404, loss 0.655086, acc 0.65625
2020-02-08T02:13:12.998534: step 405, loss 0.606417, acc 0.65625
2020-02-08T02:13:13.124090: step 406, loss 0.646888, acc 0.65625
2020-02-08T02:13:13.251920: step 407, loss 0.684069, acc 0.59375
2020-02-08T02:13:13.383281: step 408, loss 0.754943, acc 0.703125
2020-02-08T02:13:13.522221: step 409, loss 0.539771, acc 0.703125
2020-02-08T02:13:13.654519: step 410, loss 0.665219, acc 0.703125
2020-02-08T02:13:13.782216: step 411, loss 0.715696, acc 0.671875
2020-02-08T02:13:13.908862: step 412, loss 0.659589, acc 0.6875
2020-02-08T02:13:14.039205: step 413, loss 0.507335, acc 0.765625
2020-02-08T02:13:14.170329: step 414, loss 0.532578, acc 0.703125
2020-02-08T02:13:14.298258: step 415, loss 0.65458, acc 0.578125
2020-02-08T02:13:14.429137: step 416, loss 0.733747, acc 0.640625
2020-02-08T02:13:14.567380: step 417, loss 0.57618, acc 0.71875
2020-02-08T02:13:14.706809: step 418, loss 0.573709, acc 0.6875
2020-02-08T02:13:14.838888: step 419, loss 0.601438, acc 0.6875
2020-02-08T02:13:14.970440: step 420, loss 0.590935, acc 0.671875
2020-02-08T02:13:15.100151: step 421, loss 0.722268, acc 0.65625
2020-02-08T02:13:15.234456: step 422, loss 0.534876, acc 0.65625
2020-02-08T02:13:15.379055: step 423, loss 0.677176, acc 0.625
2020-02-08T02:13:15.633631: step 424, loss 0.743483, acc 0.65625
2020-02-08T02:13:15.819544: step 425, loss 0.704899, acc 0.625
2020-02-08T02:13:16.005889: step 426, loss 0.756267, acc 0.640625
2020-02-08T02:13:16.239637: step 427, loss 0.749501, acc 0.609375
2020-02-08T02:13:16.420140: step 428, loss 0.704077, acc 0.6875
2020-02-08T02:13:16.601452: step 429, loss 0.592504, acc 0.671875
2020-02-08T02:13:16.763206: step 430, loss 0.636233, acc 0.71875
2020-02-08T02:13:16.887874: step 431, loss 0.616041, acc 0.65625
2020-02-08T02:13:17.015663: step 432, loss 0.79569, acc 0.59375
2020-02-08T02:13:17.148157: step 433, loss 0.653702, acc 0.625
2020-02-08T02:13:17.278292: step 434, loss 0.630999, acc 0.703125
2020-02-08T02:13:17.410357: step 435, loss 0.745835, acc 0.6875
2020-02-08T02:13:17.536952: step 436, loss 0.71137, acc 0.65625
2020-02-08T02:13:17.666859: step 437, loss 0.552424, acc 0.75
2020-02-08T02:13:17.793606: step 438, loss 0.647129, acc 0.65625
2020-02-08T02:13:17.923489: step 439, loss 0.608101, acc 0.703125
2020-02-08T02:13:18.050485: step 440, loss 0.723093, acc 0.625
2020-02-08T02:13:18.176797: step 441, loss 0.688805, acc 0.609375
2020-02-08T02:13:18.303145: step 442, loss 0.533252, acc 0.75
2020-02-08T02:13:18.431159: step 443, loss 0.661661, acc 0.671875
2020-02-08T02:13:18.563213: step 444, loss 0.669942, acc 0.671875
2020-02-08T02:13:18.712619: step 445, loss 0.631636, acc 0.671875
2020-02-08T02:13:18.847624: step 446, loss 0.659805, acc 0.71875
2020-02-08T02:13:18.985596: step 447, loss 0.70261, acc 0.640625
2020-02-08T02:13:19.122100: step 448, loss 0.75469, acc 0.546875
2020-02-08T02:13:19.247471: step 449, loss 0.558057, acc 0.71875
2020-02-08T02:13:19.371622: step 450, loss 0.670857, acc 0.666667
2020-02-08T02:13:19.506843: step 451, loss 0.496877, acc 0.71875
2020-02-08T02:13:19.645560: step 452, loss 0.579688, acc 0.734375
2020-02-08T02:13:19.778497: step 453, loss 0.51654, acc 0.765625
2020-02-08T02:13:19.909981: step 454, loss 0.436581, acc 0.859375
2020-02-08T02:13:20.047889: step 455, loss 0.552646, acc 0.734375
2020-02-08T02:13:20.179555: step 456, loss 0.630088, acc 0.609375
2020-02-08T02:13:20.315834: step 457, loss 0.736909, acc 0.671875
2020-02-08T02:13:20.448211: step 458, loss 0.571743, acc 0.765625
2020-02-08T02:13:20.579662: step 459, loss 0.575131, acc 0.703125
2020-02-08T02:13:20.724109: step 460, loss 0.595893, acc 0.703125
2020-02-08T02:13:20.863916: step 461, loss 0.60013, acc 0.6875
2020-02-08T02:13:20.993395: step 462, loss 0.428973, acc 0.828125
2020-02-08T02:13:21.123949: step 463, loss 0.57698, acc 0.75
2020-02-08T02:13:21.315198: step 464, loss 0.611583, acc 0.671875
2020-02-08T02:13:21.597354: step 465, loss 0.49726, acc 0.765625
2020-02-08T02:13:21.856045: step 466, loss 0.599804, acc 0.640625
2020-02-08T02:13:22.060076: step 467, loss 0.566672, acc 0.703125
2020-02-08T02:13:22.255272: step 468, loss 0.610607, acc 0.71875
2020-02-08T02:13:22.421010: step 469, loss 0.487846, acc 0.734375
2020-02-08T02:13:22.572092: step 470, loss 0.492844, acc 0.765625
2020-02-08T02:13:22.713368: step 471, loss 0.495494, acc 0.765625
2020-02-08T02:13:22.849489: step 472, loss 0.649888, acc 0.65625
2020-02-08T02:13:22.974313: step 473, loss 0.575717, acc 0.703125
2020-02-08T02:13:23.104512: step 474, loss 0.512419, acc 0.703125
2020-02-08T02:13:23.229387: step 475, loss 0.741752, acc 0.609375
2020-02-08T02:13:23.362383: step 476, loss 0.621323, acc 0.703125
2020-02-08T02:13:23.495757: step 477, loss 0.44009, acc 0.765625
2020-02-08T02:13:23.623436: step 478, loss 0.526998, acc 0.796875
2020-02-08T02:13:23.762563: step 479, loss 0.605057, acc 0.765625
2020-02-08T02:13:23.898492: step 480, loss 0.640344, acc 0.671875
2020-02-08T02:13:24.042760: step 481, loss 0.491525, acc 0.734375
2020-02-08T02:13:24.169667: step 482, loss 0.640377, acc 0.65625
2020-02-08T02:13:24.306276: step 483, loss 0.576814, acc 0.671875
2020-02-08T02:13:24.440798: step 484, loss 0.697477, acc 0.625
2020-02-08T02:13:24.570292: step 485, loss 0.632431, acc 0.71875
2020-02-08T02:13:24.706536: step 486, loss 0.596742, acc 0.734375
2020-02-08T02:13:24.843484: step 487, loss 0.556677, acc 0.71875
2020-02-08T02:13:24.984731: step 488, loss 0.67908, acc 0.546875
2020-02-08T02:13:25.121562: step 489, loss 0.521498, acc 0.765625
2020-02-08T02:13:25.335223: step 490, loss 0.633452, acc 0.625
2020-02-08T02:13:25.596040: step 491, loss 0.580009, acc 0.640625
2020-02-08T02:13:25.825613: step 492, loss 0.48315, acc 0.84375
2020-02-08T02:13:26.031423: step 493, loss 0.479033, acc 0.828125
2020-02-08T02:13:26.211730: step 494, loss 0.627819, acc 0.71875
2020-02-08T02:13:26.412610: step 495, loss 0.438637, acc 0.796875
2020-02-08T02:13:26.568737: step 496, loss 0.639174, acc 0.734375
2020-02-08T02:13:26.705177: step 497, loss 0.614204, acc 0.734375
2020-02-08T02:13:26.831006: step 498, loss 0.492488, acc 0.78125
2020-02-08T02:13:26.954240: step 499, loss 0.528954, acc 0.671875
2020-02-08T02:13:27.087028: step 500, loss 0.592947, acc 0.671875

Evaluation:
2020-02-08T02:13:27.319146: step 500, loss 0.622305, acc 0.657598

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-500

2020-02-08T02:13:28.858875: step 501, loss 0.640735, acc 0.703125
2020-02-08T02:13:28.987979: step 502, loss 0.608102, acc 0.625
2020-02-08T02:13:29.121591: step 503, loss 0.50822, acc 0.71875
2020-02-08T02:13:29.252872: step 504, loss 0.581789, acc 0.703125
2020-02-08T02:13:29.383905: step 505, loss 0.535033, acc 0.703125
2020-02-08T02:13:29.516481: step 506, loss 0.698331, acc 0.546875
2020-02-08T02:13:29.647226: step 507, loss 0.687266, acc 0.71875
2020-02-08T02:13:29.778714: step 508, loss 0.552754, acc 0.765625
2020-02-08T02:13:29.984762: step 509, loss 0.516375, acc 0.703125
2020-02-08T02:13:30.302579: step 510, loss 0.573979, acc 0.765625
2020-02-08T02:13:30.542488: step 511, loss 0.586974, acc 0.75
2020-02-08T02:13:30.714377: step 512, loss 0.541161, acc 0.75
2020-02-08T02:13:30.873380: step 513, loss 0.423476, acc 0.8125
2020-02-08T02:13:31.167668: step 514, loss 0.637391, acc 0.703125
2020-02-08T02:13:31.299385: step 515, loss 0.61001, acc 0.75
2020-02-08T02:13:31.438624: step 516, loss 0.499027, acc 0.75
2020-02-08T02:13:31.575452: step 517, loss 0.442563, acc 0.765625
2020-02-08T02:13:31.708156: step 518, loss 0.628235, acc 0.703125
2020-02-08T02:13:31.858870: step 519, loss 0.699275, acc 0.671875
2020-02-08T02:13:31.992458: step 520, loss 0.621313, acc 0.71875
2020-02-08T02:13:32.122386: step 521, loss 0.642564, acc 0.65625
2020-02-08T02:13:32.253648: step 522, loss 0.549593, acc 0.734375
2020-02-08T02:13:32.388969: step 523, loss 0.715927, acc 0.546875
2020-02-08T02:13:32.522219: step 524, loss 0.603307, acc 0.703125
2020-02-08T02:13:32.658691: step 525, loss 0.585391, acc 0.703125
2020-02-08T02:13:32.796333: step 526, loss 0.676389, acc 0.578125
2020-02-08T02:13:32.926178: step 527, loss 0.651342, acc 0.65625
2020-02-08T02:13:33.059515: step 528, loss 0.549666, acc 0.75
2020-02-08T02:13:33.197624: step 529, loss 0.594392, acc 0.71875
2020-02-08T02:13:33.323359: step 530, loss 0.529444, acc 0.734375
2020-02-08T02:13:33.460579: step 531, loss 0.633124, acc 0.59375
2020-02-08T02:13:33.582789: step 532, loss 0.556718, acc 0.65625
2020-02-08T02:13:33.716872: step 533, loss 0.439908, acc 0.8125
2020-02-08T02:13:33.843198: step 534, loss 0.532838, acc 0.71875
2020-02-08T02:13:33.971061: step 535, loss 0.491472, acc 0.78125
2020-02-08T02:13:34.099927: step 536, loss 0.598482, acc 0.71875
2020-02-08T02:13:34.224590: step 537, loss 0.508383, acc 0.78125
2020-02-08T02:13:34.348709: step 538, loss 0.675246, acc 0.671875
2020-02-08T02:13:34.476591: step 539, loss 0.688852, acc 0.671875
2020-02-08T02:13:34.605653: step 540, loss 0.678845, acc 0.671875
2020-02-08T02:13:34.736184: step 541, loss 0.575349, acc 0.71875
2020-02-08T02:13:34.862357: step 542, loss 0.535635, acc 0.734375
2020-02-08T02:13:34.990062: step 543, loss 0.745207, acc 0.59375
2020-02-08T02:13:35.115061: step 544, loss 0.487666, acc 0.75
2020-02-08T02:13:35.240905: step 545, loss 0.496068, acc 0.75
2020-02-08T02:13:35.366920: step 546, loss 0.738345, acc 0.5625
2020-02-08T02:13:35.491773: step 547, loss 0.501564, acc 0.765625
2020-02-08T02:13:35.620762: step 548, loss 0.567627, acc 0.75
2020-02-08T02:13:35.754127: step 549, loss 0.776556, acc 0.671875
2020-02-08T02:13:35.878965: step 550, loss 0.60543, acc 0.65625
2020-02-08T02:13:36.006933: step 551, loss 0.565168, acc 0.765625
2020-02-08T02:13:36.130825: step 552, loss 0.608869, acc 0.65625
2020-02-08T02:13:36.255276: step 553, loss 0.585741, acc 0.703125
2020-02-08T02:13:36.381519: step 554, loss 0.469363, acc 0.84375
2020-02-08T02:13:36.506954: step 555, loss 0.547113, acc 0.65625
2020-02-08T02:13:36.643230: step 556, loss 0.628719, acc 0.71875
2020-02-08T02:13:36.775731: step 557, loss 0.508886, acc 0.765625
2020-02-08T02:13:36.902575: step 558, loss 0.546408, acc 0.765625
2020-02-08T02:13:37.027732: step 559, loss 0.547376, acc 0.734375
2020-02-08T02:13:37.155864: step 560, loss 0.554793, acc 0.703125
2020-02-08T02:13:37.280863: step 561, loss 0.593521, acc 0.6875
2020-02-08T02:13:37.409063: step 562, loss 0.5811, acc 0.734375
2020-02-08T02:13:37.543041: step 563, loss 0.545446, acc 0.71875
2020-02-08T02:13:37.679244: step 564, loss 0.529629, acc 0.71875
2020-02-08T02:13:37.814100: step 565, loss 0.662113, acc 0.65625
2020-02-08T02:13:37.951318: step 566, loss 0.561495, acc 0.734375
2020-02-08T02:13:38.083346: step 567, loss 0.61002, acc 0.6875
2020-02-08T02:13:38.217066: step 568, loss 0.561922, acc 0.75
2020-02-08T02:13:38.358093: step 569, loss 0.489388, acc 0.734375
2020-02-08T02:13:38.487555: step 570, loss 0.775914, acc 0.515625
2020-02-08T02:13:38.623603: step 571, loss 0.641949, acc 0.671875
2020-02-08T02:13:38.767278: step 572, loss 0.557759, acc 0.71875
2020-02-08T02:13:38.908131: step 573, loss 0.61754, acc 0.65625
2020-02-08T02:13:39.037994: step 574, loss 0.628837, acc 0.640625
2020-02-08T02:13:39.177996: step 575, loss 0.555064, acc 0.71875
2020-02-08T02:13:39.311308: step 576, loss 0.583063, acc 0.78125
2020-02-08T02:13:39.442653: step 577, loss 0.594687, acc 0.75
2020-02-08T02:13:39.572400: step 578, loss 0.541335, acc 0.734375
2020-02-08T02:13:39.709538: step 579, loss 0.584157, acc 0.6875
2020-02-08T02:13:39.833521: step 580, loss 0.554734, acc 0.71875
2020-02-08T02:13:39.963935: step 581, loss 0.608917, acc 0.6875
2020-02-08T02:13:40.100844: step 582, loss 0.645071, acc 0.640625
2020-02-08T02:13:40.236565: step 583, loss 0.59617, acc 0.671875
2020-02-08T02:13:40.365628: step 584, loss 0.571515, acc 0.703125
2020-02-08T02:13:40.491810: step 585, loss 0.448737, acc 0.78125
2020-02-08T02:13:40.618378: step 586, loss 0.428224, acc 0.84375
2020-02-08T02:13:40.755922: step 587, loss 0.570855, acc 0.6875
2020-02-08T02:13:40.883255: step 588, loss 0.55516, acc 0.75
2020-02-08T02:13:41.010159: step 589, loss 0.594261, acc 0.734375
2020-02-08T02:13:41.134833: step 590, loss 0.673211, acc 0.671875
2020-02-08T02:13:41.262267: step 591, loss 0.575144, acc 0.6875
2020-02-08T02:13:41.389192: step 592, loss 0.499136, acc 0.8125
2020-02-08T02:13:41.514070: step 593, loss 0.475601, acc 0.796875
2020-02-08T02:13:41.642376: step 594, loss 0.515919, acc 0.703125
2020-02-08T02:13:41.772290: step 595, loss 0.481919, acc 0.734375
2020-02-08T02:13:41.903215: step 596, loss 0.55072, acc 0.71875
2020-02-08T02:13:42.030543: step 597, loss 0.462894, acc 0.796875
2020-02-08T02:13:42.157437: step 598, loss 0.501729, acc 0.75
2020-02-08T02:13:42.283663: step 599, loss 0.729921, acc 0.59375
2020-02-08T02:13:42.404046: step 600, loss 0.557944, acc 0.75

Evaluation:
2020-02-08T02:13:42.618022: step 600, loss 0.635051, acc 0.639775

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-600

2020-02-08T02:13:44.163445: step 601, loss 0.477246, acc 0.765625
2020-02-08T02:13:44.288364: step 602, loss 0.507558, acc 0.765625
2020-02-08T02:13:44.415969: step 603, loss 0.57537, acc 0.765625
2020-02-08T02:13:44.542444: step 604, loss 0.466337, acc 0.796875
2020-02-08T02:13:44.670664: step 605, loss 0.403907, acc 0.828125
2020-02-08T02:13:44.798405: step 606, loss 0.462809, acc 0.8125
2020-02-08T02:13:44.924443: step 607, loss 0.557513, acc 0.734375
2020-02-08T02:13:45.052331: step 608, loss 0.547211, acc 0.765625
2020-02-08T02:13:45.180106: step 609, loss 0.568258, acc 0.6875
2020-02-08T02:13:45.306624: step 610, loss 0.440997, acc 0.8125
2020-02-08T02:13:45.435680: step 611, loss 0.574743, acc 0.65625
2020-02-08T02:13:45.561877: step 612, loss 0.454335, acc 0.8125
2020-02-08T02:13:45.691783: step 613, loss 0.372216, acc 0.828125
2020-02-08T02:13:45.822872: step 614, loss 0.633641, acc 0.59375
2020-02-08T02:13:45.950925: step 615, loss 0.593284, acc 0.78125
2020-02-08T02:13:46.077176: step 616, loss 0.44038, acc 0.828125
2020-02-08T02:13:46.202846: step 617, loss 0.579051, acc 0.625
2020-02-08T02:13:46.327667: step 618, loss 0.550108, acc 0.65625
2020-02-08T02:13:46.453494: step 619, loss 0.497468, acc 0.75
2020-02-08T02:13:46.580739: step 620, loss 0.411836, acc 0.84375
2020-02-08T02:13:46.710328: step 621, loss 0.482567, acc 0.734375
2020-02-08T02:13:46.832317: step 622, loss 0.532561, acc 0.78125
2020-02-08T02:13:46.961899: step 623, loss 0.463576, acc 0.78125
2020-02-08T02:13:47.083968: step 624, loss 0.437091, acc 0.8125
2020-02-08T02:13:47.212272: step 625, loss 0.345234, acc 0.859375
2020-02-08T02:13:47.337084: step 626, loss 0.603146, acc 0.6875
2020-02-08T02:13:47.465484: step 627, loss 0.396621, acc 0.828125
2020-02-08T02:13:47.594533: step 628, loss 0.554995, acc 0.765625
2020-02-08T02:13:47.727077: step 629, loss 0.550158, acc 0.765625
2020-02-08T02:13:47.854558: step 630, loss 0.509565, acc 0.703125
2020-02-08T02:13:47.977704: step 631, loss 0.502148, acc 0.734375
2020-02-08T02:13:48.104148: step 632, loss 0.495448, acc 0.78125
2020-02-08T02:13:48.230618: step 633, loss 0.513186, acc 0.796875
2020-02-08T02:13:48.356574: step 634, loss 0.430107, acc 0.78125
2020-02-08T02:13:48.481250: step 635, loss 0.574771, acc 0.734375
2020-02-08T02:13:48.605254: step 636, loss 0.435312, acc 0.796875
2020-02-08T02:13:48.735229: step 637, loss 0.553966, acc 0.703125
2020-02-08T02:13:48.861830: step 638, loss 0.334676, acc 0.8125
2020-02-08T02:13:48.987091: step 639, loss 0.584554, acc 0.703125
2020-02-08T02:13:49.120857: step 640, loss 0.448094, acc 0.84375
2020-02-08T02:13:49.242923: step 641, loss 0.45565, acc 0.84375
2020-02-08T02:13:49.368840: step 642, loss 0.47297, acc 0.78125
2020-02-08T02:13:49.496009: step 643, loss 0.494399, acc 0.8125
2020-02-08T02:13:49.616538: step 644, loss 0.568621, acc 0.734375
2020-02-08T02:13:49.743437: step 645, loss 0.630779, acc 0.71875
2020-02-08T02:13:49.870079: step 646, loss 0.52358, acc 0.765625
2020-02-08T02:13:49.993476: step 647, loss 0.488541, acc 0.75
2020-02-08T02:13:50.118655: step 648, loss 0.552328, acc 0.796875
2020-02-08T02:13:50.241300: step 649, loss 0.436775, acc 0.84375
2020-02-08T02:13:50.366571: step 650, loss 0.407032, acc 0.828125
2020-02-08T02:13:50.495664: step 651, loss 0.439644, acc 0.78125
2020-02-08T02:13:50.621896: step 652, loss 0.412128, acc 0.84375
2020-02-08T02:13:50.754728: step 653, loss 0.559758, acc 0.75
2020-02-08T02:13:50.880136: step 654, loss 0.399043, acc 0.828125
2020-02-08T02:13:51.004132: step 655, loss 0.618178, acc 0.71875
2020-02-08T02:13:51.132677: step 656, loss 0.480815, acc 0.703125
2020-02-08T02:13:51.966382: step 657, loss 0.421667, acc 0.796875
2020-02-08T02:13:52.095196: step 658, loss 0.473437, acc 0.78125
2020-02-08T02:13:52.221458: step 659, loss 0.431403, acc 0.796875
2020-02-08T02:13:52.345644: step 660, loss 0.402211, acc 0.78125
2020-02-08T02:13:52.470114: step 661, loss 0.562634, acc 0.703125
2020-02-08T02:13:52.596276: step 662, loss 0.424602, acc 0.84375
2020-02-08T02:13:52.732948: step 663, loss 0.674359, acc 0.65625
2020-02-08T02:13:52.857766: step 664, loss 0.445613, acc 0.84375
2020-02-08T02:13:52.981366: step 665, loss 0.478623, acc 0.796875
2020-02-08T02:13:53.106768: step 666, loss 0.56163, acc 0.78125
2020-02-08T02:13:53.231605: step 667, loss 0.371821, acc 0.859375
2020-02-08T02:13:53.355969: step 668, loss 0.550558, acc 0.734375
2020-02-08T02:13:53.482319: step 669, loss 0.575142, acc 0.71875
2020-02-08T02:13:53.613500: step 670, loss 0.669937, acc 0.65625
2020-02-08T02:13:53.751449: step 671, loss 0.49207, acc 0.765625
2020-02-08T02:13:53.874716: step 672, loss 0.466677, acc 0.828125
2020-02-08T02:13:54.004847: step 673, loss 0.454269, acc 0.796875
2020-02-08T02:13:54.133514: step 674, loss 0.474146, acc 0.75
2020-02-08T02:13:54.260253: step 675, loss 0.443885, acc 0.78125
2020-02-08T02:13:54.384872: step 676, loss 0.624408, acc 0.71875
2020-02-08T02:13:54.514980: step 677, loss 0.348618, acc 0.84375
2020-02-08T02:13:54.642171: step 678, loss 0.472109, acc 0.765625
2020-02-08T02:13:54.773940: step 679, loss 0.553826, acc 0.734375
2020-02-08T02:13:54.899610: step 680, loss 0.496549, acc 0.71875
2020-02-08T02:13:55.025092: step 681, loss 0.500113, acc 0.734375
2020-02-08T02:13:55.153225: step 682, loss 0.552829, acc 0.734375
2020-02-08T02:13:55.279069: step 683, loss 0.375175, acc 0.828125
2020-02-08T02:13:55.405190: step 684, loss 0.440998, acc 0.765625
2020-02-08T02:13:55.529153: step 685, loss 0.535598, acc 0.765625
2020-02-08T02:13:55.656416: step 686, loss 0.537609, acc 0.765625
2020-02-08T02:13:55.781416: step 687, loss 0.498878, acc 0.75
2020-02-08T02:13:55.906171: step 688, loss 0.489059, acc 0.765625
2020-02-08T02:13:56.030837: step 689, loss 0.383854, acc 0.859375
2020-02-08T02:13:56.154730: step 690, loss 0.598612, acc 0.671875
2020-02-08T02:13:56.278151: step 691, loss 0.498096, acc 0.765625
2020-02-08T02:13:56.405106: step 692, loss 0.499025, acc 0.75
2020-02-08T02:13:56.531376: step 693, loss 0.441483, acc 0.765625
2020-02-08T02:13:56.660337: step 694, loss 0.43097, acc 0.859375
2020-02-08T02:13:56.785131: step 695, loss 0.432987, acc 0.84375
2020-02-08T02:13:56.913101: step 696, loss 0.50089, acc 0.6875
2020-02-08T02:13:57.036351: step 697, loss 0.63148, acc 0.671875
2020-02-08T02:13:57.159183: step 698, loss 0.561394, acc 0.71875
2020-02-08T02:13:57.283209: step 699, loss 0.494223, acc 0.78125
2020-02-08T02:13:57.408122: step 700, loss 0.492224, acc 0.828125

Evaluation:
2020-02-08T02:13:57.619262: step 700, loss 0.595833, acc 0.67636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-700

2020-02-08T02:14:00.058718: step 701, loss 0.472986, acc 0.796875
2020-02-08T02:14:00.183316: step 702, loss 0.533707, acc 0.78125
2020-02-08T02:14:00.310829: step 703, loss 0.437953, acc 0.796875
2020-02-08T02:14:00.432277: step 704, loss 0.448297, acc 0.75
2020-02-08T02:14:00.557581: step 705, loss 0.443536, acc 0.765625
2020-02-08T02:14:00.684465: step 706, loss 0.618949, acc 0.71875
2020-02-08T02:14:00.811799: step 707, loss 0.502726, acc 0.765625
2020-02-08T02:14:00.936240: step 708, loss 0.386916, acc 0.875
2020-02-08T02:14:01.063350: step 709, loss 0.468697, acc 0.78125
2020-02-08T02:14:01.184946: step 710, loss 0.50931, acc 0.734375
2020-02-08T02:14:01.309172: step 711, loss 0.410541, acc 0.796875
2020-02-08T02:14:01.433970: step 712, loss 0.471088, acc 0.734375
2020-02-08T02:14:01.557573: step 713, loss 0.512234, acc 0.6875
2020-02-08T02:14:01.679530: step 714, loss 0.684647, acc 0.6875
2020-02-08T02:14:01.807076: step 715, loss 0.553358, acc 0.71875
2020-02-08T02:14:01.932766: step 716, loss 0.500595, acc 0.734375
2020-02-08T02:14:02.060823: step 717, loss 0.426681, acc 0.828125
2020-02-08T02:14:02.185931: step 718, loss 0.449336, acc 0.828125
2020-02-08T02:14:02.311129: step 719, loss 0.386298, acc 0.8125
2020-02-08T02:14:02.433921: step 720, loss 0.585284, acc 0.734375
2020-02-08T02:14:02.562726: step 721, loss 0.501125, acc 0.765625
2020-02-08T02:14:02.690625: step 722, loss 0.457511, acc 0.75
2020-02-08T02:14:02.818375: step 723, loss 0.465602, acc 0.828125
2020-02-08T02:14:02.940438: step 724, loss 0.48257, acc 0.734375
2020-02-08T02:14:03.067005: step 725, loss 0.495841, acc 0.6875
2020-02-08T02:14:03.188533: step 726, loss 0.531558, acc 0.734375
2020-02-08T02:14:03.316472: step 727, loss 0.549852, acc 0.71875
2020-02-08T02:14:03.438434: step 728, loss 0.519396, acc 0.765625
2020-02-08T02:14:03.566446: step 729, loss 0.705658, acc 0.6875
2020-02-08T02:14:03.695882: step 730, loss 0.466213, acc 0.796875
2020-02-08T02:14:03.819641: step 731, loss 0.615623, acc 0.6875
2020-02-08T02:14:03.941169: step 732, loss 0.598939, acc 0.6875
2020-02-08T02:14:04.068966: step 733, loss 0.643405, acc 0.65625
2020-02-08T02:14:04.195383: step 734, loss 0.548223, acc 0.765625
2020-02-08T02:14:04.323920: step 735, loss 0.590303, acc 0.703125
2020-02-08T02:14:04.451477: step 736, loss 0.573773, acc 0.765625
2020-02-08T02:14:04.580845: step 737, loss 0.416253, acc 0.796875
2020-02-08T02:14:04.716298: step 738, loss 0.460977, acc 0.765625
2020-02-08T02:14:04.842194: step 739, loss 0.561874, acc 0.71875
2020-02-08T02:14:04.967449: step 740, loss 0.579022, acc 0.734375
2020-02-08T02:14:05.090411: step 741, loss 0.474534, acc 0.671875
2020-02-08T02:14:05.217509: step 742, loss 0.635277, acc 0.671875
2020-02-08T02:14:05.341792: step 743, loss 0.428522, acc 0.8125
2020-02-08T02:14:05.468304: step 744, loss 0.550331, acc 0.796875
2020-02-08T02:14:05.595353: step 745, loss 0.647557, acc 0.625
2020-02-08T02:14:05.725988: step 746, loss 0.443424, acc 0.75
2020-02-08T02:14:05.853357: step 747, loss 0.583098, acc 0.71875
2020-02-08T02:14:05.978722: step 748, loss 0.59867, acc 0.65625
2020-02-08T02:14:06.105648: step 749, loss 0.391652, acc 0.84375
2020-02-08T02:14:06.226547: step 750, loss 0.420942, acc 0.816667
2020-02-08T02:14:06.352228: step 751, loss 0.330827, acc 0.890625
2020-02-08T02:14:06.480668: step 752, loss 0.522992, acc 0.765625
2020-02-08T02:14:06.606322: step 753, loss 0.401201, acc 0.828125
2020-02-08T02:14:06.747137: step 754, loss 0.514077, acc 0.71875
2020-02-08T02:14:06.876208: step 755, loss 0.58292, acc 0.703125
2020-02-08T02:14:07.002216: step 756, loss 0.425027, acc 0.859375
2020-02-08T02:14:07.127641: step 757, loss 0.416939, acc 0.78125
2020-02-08T02:14:07.256180: step 758, loss 0.305578, acc 0.859375
2020-02-08T02:14:07.389304: step 759, loss 0.326891, acc 0.90625
2020-02-08T02:14:07.523130: step 760, loss 0.552716, acc 0.78125
2020-02-08T02:14:07.647283: step 761, loss 0.477671, acc 0.6875
2020-02-08T02:14:07.775562: step 762, loss 0.285303, acc 0.890625
2020-02-08T02:14:07.899753: step 763, loss 0.333605, acc 0.828125
2020-02-08T02:14:08.024802: step 764, loss 0.389028, acc 0.828125
2020-02-08T02:14:08.154236: step 765, loss 0.425733, acc 0.8125
2020-02-08T02:14:08.293211: step 766, loss 0.355473, acc 0.828125
2020-02-08T02:14:08.416503: step 767, loss 0.487571, acc 0.8125
2020-02-08T02:14:08.540316: step 768, loss 0.458141, acc 0.765625
2020-02-08T02:14:08.666389: step 769, loss 0.349703, acc 0.828125
2020-02-08T02:14:08.795032: step 770, loss 0.474056, acc 0.765625
2020-02-08T02:14:08.923221: step 771, loss 0.373741, acc 0.890625
2020-02-08T02:14:09.047763: step 772, loss 0.279958, acc 0.921875
2020-02-08T02:14:09.175874: step 773, loss 0.572416, acc 0.765625
2020-02-08T02:14:09.301414: step 774, loss 0.327188, acc 0.859375
2020-02-08T02:14:09.427782: step 775, loss 0.507317, acc 0.6875
2020-02-08T02:14:09.551937: step 776, loss 0.466623, acc 0.71875
2020-02-08T02:14:09.679655: step 777, loss 0.333778, acc 0.875
2020-02-08T02:14:09.804517: step 778, loss 0.385977, acc 0.8125
2020-02-08T02:14:09.930701: step 779, loss 0.437851, acc 0.796875
2020-02-08T02:14:10.057801: step 780, loss 0.377737, acc 0.84375
2020-02-08T02:14:10.180670: step 781, loss 0.454176, acc 0.78125
2020-02-08T02:14:10.305697: step 782, loss 0.405462, acc 0.859375
2020-02-08T02:14:10.430233: step 783, loss 0.409084, acc 0.8125
2020-02-08T02:14:10.557519: step 784, loss 0.471874, acc 0.71875
2020-02-08T02:14:10.684926: step 785, loss 0.455559, acc 0.734375
2020-02-08T02:14:10.810843: step 786, loss 0.389229, acc 0.828125
2020-02-08T02:14:10.940481: step 787, loss 0.43398, acc 0.796875
2020-02-08T02:14:11.073352: step 788, loss 0.52277, acc 0.75
2020-02-08T02:14:11.200277: step 789, loss 0.434599, acc 0.78125
2020-02-08T02:14:11.325029: step 790, loss 0.495699, acc 0.75
2020-02-08T02:14:11.449485: step 791, loss 0.47733, acc 0.796875
2020-02-08T02:14:11.571618: step 792, loss 0.492884, acc 0.828125
2020-02-08T02:14:11.705989: step 793, loss 0.391235, acc 0.84375
2020-02-08T02:14:11.830448: step 794, loss 0.543876, acc 0.671875
2020-02-08T02:14:11.955788: step 795, loss 0.467015, acc 0.78125
2020-02-08T02:14:12.079604: step 796, loss 0.346329, acc 0.828125
2020-02-08T02:14:12.205588: step 797, loss 0.487695, acc 0.765625
2020-02-08T02:14:12.332007: step 798, loss 0.404898, acc 0.828125
2020-02-08T02:14:12.459876: step 799, loss 0.368188, acc 0.828125
2020-02-08T02:14:12.581643: step 800, loss 0.383974, acc 0.8125

Evaluation:
2020-02-08T02:14:12.798749: step 800, loss 0.583695, acc 0.692308

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-800

2020-02-08T02:14:14.282031: step 801, loss 0.336638, acc 0.890625
2020-02-08T02:14:14.405820: step 802, loss 0.515186, acc 0.765625
2020-02-08T02:14:14.533966: step 803, loss 0.502151, acc 0.8125
2020-02-08T02:14:14.663609: step 804, loss 0.385181, acc 0.828125
2020-02-08T02:14:14.786847: step 805, loss 0.424504, acc 0.8125
2020-02-08T02:14:14.912156: step 806, loss 0.344543, acc 0.890625
2020-02-08T02:14:15.035708: step 807, loss 0.573811, acc 0.78125
2020-02-08T02:14:15.160229: step 808, loss 0.362448, acc 0.84375
2020-02-08T02:14:15.284150: step 809, loss 0.506356, acc 0.8125
2020-02-08T02:14:15.410762: step 810, loss 0.685169, acc 0.625
2020-02-08T02:14:15.535021: step 811, loss 0.550485, acc 0.71875
2020-02-08T02:14:15.658812: step 812, loss 0.506895, acc 0.75
2020-02-08T02:14:15.784775: step 813, loss 0.361911, acc 0.859375
2020-02-08T02:14:15.910861: step 814, loss 0.264662, acc 0.953125
2020-02-08T02:14:16.042309: step 815, loss 0.455668, acc 0.78125
2020-02-08T02:14:16.168381: step 816, loss 0.487473, acc 0.765625
2020-02-08T02:14:16.289299: step 817, loss 0.371164, acc 0.828125
2020-02-08T02:14:16.413614: step 818, loss 0.446934, acc 0.828125
2020-02-08T02:14:16.539575: step 819, loss 0.255807, acc 0.890625
2020-02-08T02:14:16.669078: step 820, loss 0.379181, acc 0.84375
2020-02-08T02:14:16.796445: step 821, loss 0.360937, acc 0.828125
2020-02-08T02:14:16.924168: step 822, loss 0.436978, acc 0.828125
2020-02-08T02:14:17.051442: step 823, loss 0.36361, acc 0.8125
2020-02-08T02:14:17.180548: step 824, loss 0.531813, acc 0.734375
2020-02-08T02:14:17.301569: step 825, loss 0.40062, acc 0.796875
2020-02-08T02:14:17.426650: step 826, loss 0.372136, acc 0.84375
2020-02-08T02:14:17.552170: step 827, loss 0.417668, acc 0.796875
2020-02-08T02:14:17.677699: step 828, loss 0.412993, acc 0.8125
2020-02-08T02:14:17.801177: step 829, loss 0.29672, acc 0.875
2020-02-08T02:14:17.927579: step 830, loss 0.410319, acc 0.78125
2020-02-08T02:14:18.051931: step 831, loss 0.362305, acc 0.84375
2020-02-08T02:14:18.178402: step 832, loss 0.350052, acc 0.890625
2020-02-08T02:14:18.302167: step 833, loss 0.396152, acc 0.78125
2020-02-08T02:14:18.428781: step 834, loss 0.389134, acc 0.84375
2020-02-08T02:14:18.557832: step 835, loss 0.627202, acc 0.6875
2020-02-08T02:14:18.685725: step 836, loss 0.448795, acc 0.75
2020-02-08T02:14:18.811288: step 837, loss 0.432984, acc 0.8125
2020-02-08T02:14:18.931542: step 838, loss 0.391692, acc 0.828125
2020-02-08T02:14:19.062427: step 839, loss 0.416335, acc 0.8125
2020-02-08T02:14:19.185995: step 840, loss 0.429675, acc 0.828125
2020-02-08T02:14:19.311936: step 841, loss 0.542716, acc 0.71875
2020-02-08T02:14:19.434488: step 842, loss 0.445735, acc 0.828125
2020-02-08T02:14:19.562989: step 843, loss 0.515601, acc 0.78125
2020-02-08T02:14:19.691331: step 844, loss 0.467348, acc 0.8125
2020-02-08T02:14:19.817450: step 845, loss 0.513759, acc 0.78125
2020-02-08T02:14:19.941112: step 846, loss 0.368161, acc 0.828125
2020-02-08T02:14:20.065792: step 847, loss 0.337686, acc 0.890625
2020-02-08T02:14:20.195931: step 848, loss 0.461863, acc 0.75
2020-02-08T02:14:20.319809: step 849, loss 0.499111, acc 0.796875
2020-02-08T02:14:20.446302: step 850, loss 0.382477, acc 0.875
2020-02-08T02:14:20.579978: step 851, loss 0.367085, acc 0.828125
2020-02-08T02:14:20.718835: step 852, loss 0.408498, acc 0.875
2020-02-08T02:14:20.839871: step 853, loss 0.501511, acc 0.703125
2020-02-08T02:14:20.966577: step 854, loss 0.47355, acc 0.75
2020-02-08T02:14:21.092548: step 855, loss 0.366693, acc 0.84375
2020-02-08T02:14:21.216327: step 856, loss 0.678164, acc 0.640625
2020-02-08T02:14:21.389926: step 857, loss 0.401404, acc 0.875
2020-02-08T02:14:21.513118: step 858, loss 0.447888, acc 0.78125
2020-02-08T02:14:21.634114: step 859, loss 0.359236, acc 0.8125
2020-02-08T02:14:21.767156: step 860, loss 0.349553, acc 0.8125
2020-02-08T02:14:21.889898: step 861, loss 0.497161, acc 0.78125
2020-02-08T02:14:22.015111: step 862, loss 0.636316, acc 0.671875
2020-02-08T02:14:22.138542: step 863, loss 0.347151, acc 0.859375
2020-02-08T02:14:22.263383: step 864, loss 0.555139, acc 0.734375
2020-02-08T02:14:22.386827: step 865, loss 0.38317, acc 0.8125
2020-02-08T02:14:22.510382: step 866, loss 0.523595, acc 0.765625
2020-02-08T02:14:22.633670: step 867, loss 0.561859, acc 0.765625
2020-02-08T02:14:22.765275: step 868, loss 0.471051, acc 0.734375
2020-02-08T02:14:22.886056: step 869, loss 0.53216, acc 0.734375
2020-02-08T02:14:23.012528: step 870, loss 0.433329, acc 0.796875
2020-02-08T02:14:23.138436: step 871, loss 0.390255, acc 0.84375
2020-02-08T02:14:23.264325: step 872, loss 0.396183, acc 0.8125
2020-02-08T02:14:23.387502: step 873, loss 0.475908, acc 0.75
2020-02-08T02:14:23.513025: step 874, loss 0.482644, acc 0.765625
2020-02-08T02:14:23.634384: step 875, loss 0.3642, acc 0.84375
2020-02-08T02:14:23.764825: step 876, loss 0.404994, acc 0.765625
2020-02-08T02:14:23.888331: step 877, loss 0.369338, acc 0.828125
2020-02-08T02:14:24.013702: step 878, loss 0.415383, acc 0.796875
2020-02-08T02:14:24.140547: step 879, loss 0.608868, acc 0.734375
2020-02-08T02:14:24.264584: step 880, loss 0.453307, acc 0.796875
2020-02-08T02:14:24.388631: step 881, loss 0.362949, acc 0.8125
2020-02-08T02:14:24.514178: step 882, loss 0.482658, acc 0.8125
2020-02-08T02:14:24.636392: step 883, loss 0.539573, acc 0.765625
2020-02-08T02:14:24.765843: step 884, loss 0.415686, acc 0.8125
2020-02-08T02:14:24.888611: step 885, loss 0.551032, acc 0.703125
2020-02-08T02:14:25.015817: step 886, loss 0.416577, acc 0.75
2020-02-08T02:14:25.138120: step 887, loss 0.555939, acc 0.75
2020-02-08T02:14:25.263341: step 888, loss 0.567515, acc 0.75
2020-02-08T02:14:25.389043: step 889, loss 0.496243, acc 0.75
2020-02-08T02:14:25.514961: step 890, loss 0.560637, acc 0.71875
2020-02-08T02:14:25.637211: step 891, loss 0.392603, acc 0.84375
2020-02-08T02:14:25.766208: step 892, loss 0.464862, acc 0.765625
2020-02-08T02:14:25.891986: step 893, loss 0.52639, acc 0.6875
2020-02-08T02:14:26.017238: step 894, loss 0.540321, acc 0.6875
2020-02-08T02:14:26.147198: step 895, loss 0.43655, acc 0.796875
2020-02-08T02:14:26.270759: step 896, loss 0.283688, acc 0.890625
2020-02-08T02:14:26.397063: step 897, loss 0.480684, acc 0.78125
2020-02-08T02:14:26.522250: step 898, loss 0.336744, acc 0.875
2020-02-08T02:14:26.651910: step 899, loss 0.472567, acc 0.71875
2020-02-08T02:14:26.775634: step 900, loss 0.516702, acc 0.8

Evaluation:
2020-02-08T02:14:26.982828: step 900, loss 0.579093, acc 0.696998

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-900

2020-02-08T02:14:28.472379: step 901, loss 0.358511, acc 0.859375
2020-02-08T02:14:28.593366: step 902, loss 0.228259, acc 0.921875
2020-02-08T02:14:28.725242: step 903, loss 0.451498, acc 0.8125
2020-02-08T02:14:28.854530: step 904, loss 0.330265, acc 0.875
2020-02-08T02:14:29.011363: step 905, loss 0.362564, acc 0.8125
2020-02-08T02:14:29.135945: step 906, loss 0.390698, acc 0.8125
2020-02-08T02:14:29.270473: step 907, loss 0.442397, acc 0.8125
2020-02-08T02:14:29.394863: step 908, loss 0.347275, acc 0.84375
2020-02-08T02:14:29.520077: step 909, loss 0.374414, acc 0.84375
2020-02-08T02:14:29.643874: step 910, loss 0.26311, acc 0.90625
2020-02-08T02:14:29.769703: step 911, loss 0.286287, acc 0.90625
2020-02-08T02:14:29.892384: step 912, loss 0.318311, acc 0.90625
2020-02-08T02:14:30.022210: step 913, loss 0.295044, acc 0.859375
2020-02-08T02:14:30.148949: step 914, loss 0.355569, acc 0.859375
2020-02-08T02:14:30.270667: step 915, loss 0.340808, acc 0.875
2020-02-08T02:14:30.393790: step 916, loss 0.339042, acc 0.90625
2020-02-08T02:14:30.521549: step 917, loss 0.286903, acc 0.890625
2020-02-08T02:14:30.652142: step 918, loss 0.296246, acc 0.859375
2020-02-08T02:14:30.777821: step 919, loss 0.304103, acc 0.828125
2020-02-08T02:14:30.902812: step 920, loss 0.301645, acc 0.890625
2020-02-08T02:14:31.024964: step 921, loss 0.279921, acc 0.875
2020-02-08T02:14:31.149375: step 922, loss 0.343917, acc 0.859375
2020-02-08T02:14:31.275222: step 923, loss 0.354382, acc 0.828125
2020-02-08T02:14:31.400709: step 924, loss 0.287681, acc 0.921875
2020-02-08T02:14:31.526907: step 925, loss 0.296678, acc 0.875
2020-02-08T02:14:31.650870: step 926, loss 0.395641, acc 0.8125
2020-02-08T02:14:31.774766: step 927, loss 0.299682, acc 0.84375
2020-02-08T02:14:31.899982: step 928, loss 0.32393, acc 0.859375
2020-02-08T02:14:32.022141: step 929, loss 0.293183, acc 0.859375
2020-02-08T02:14:32.146034: step 930, loss 0.335364, acc 0.859375
2020-02-08T02:14:32.268294: step 931, loss 0.33064, acc 0.859375
2020-02-08T02:14:32.390320: step 932, loss 0.40981, acc 0.859375
2020-02-08T02:14:32.516962: step 933, loss 0.216444, acc 0.921875
2020-02-08T02:14:32.645102: step 934, loss 0.395672, acc 0.8125
2020-02-08T02:14:32.773458: step 935, loss 0.297686, acc 0.875
2020-02-08T02:14:32.900828: step 936, loss 0.324221, acc 0.859375
2020-02-08T02:14:33.027583: step 937, loss 0.259697, acc 0.890625
2020-02-08T02:14:33.154266: step 938, loss 0.382548, acc 0.828125
2020-02-08T02:14:33.278493: step 939, loss 0.377094, acc 0.84375
2020-02-08T02:14:33.406474: step 940, loss 0.454667, acc 0.734375
2020-02-08T02:14:33.532462: step 941, loss 0.397463, acc 0.765625
2020-02-08T02:14:33.659905: step 942, loss 0.436386, acc 0.796875
2020-02-08T02:14:33.786353: step 943, loss 0.417436, acc 0.875
2020-02-08T02:14:33.911167: step 944, loss 0.307537, acc 0.828125
2020-02-08T02:14:34.035085: step 945, loss 0.350371, acc 0.828125
2020-02-08T02:14:34.160083: step 946, loss 0.284586, acc 0.921875
2020-02-08T02:14:34.284945: step 947, loss 0.341555, acc 0.84375
2020-02-08T02:14:34.410107: step 948, loss 0.255297, acc 0.921875
2020-02-08T02:14:34.536027: step 949, loss 0.281872, acc 0.859375
2020-02-08T02:14:34.664203: step 950, loss 0.28888, acc 0.859375
2020-02-08T02:14:34.785590: step 951, loss 0.299143, acc 0.90625
2020-02-08T02:14:34.908262: step 952, loss 0.342317, acc 0.859375
2020-02-08T02:14:35.032862: step 953, loss 0.43786, acc 0.828125
2020-02-08T02:14:35.154495: step 954, loss 0.258783, acc 0.90625
2020-02-08T02:14:35.276941: step 955, loss 0.254699, acc 0.90625
2020-02-08T02:14:35.401488: step 956, loss 0.467634, acc 0.765625
2020-02-08T02:14:35.525598: step 957, loss 0.459001, acc 0.796875
2020-02-08T02:14:35.650265: step 958, loss 0.301899, acc 0.859375
2020-02-08T02:14:35.775294: step 959, loss 0.3903, acc 0.859375
2020-02-08T02:14:35.901063: step 960, loss 0.543304, acc 0.734375
2020-02-08T02:14:36.024470: step 961, loss 0.298727, acc 0.859375
2020-02-08T02:14:36.150432: step 962, loss 0.268758, acc 0.84375
2020-02-08T02:14:36.275795: step 963, loss 0.256918, acc 0.921875
2020-02-08T02:14:36.399615: step 964, loss 0.317434, acc 0.828125
2020-02-08T02:14:36.523730: step 965, loss 0.398023, acc 0.828125
2020-02-08T02:14:36.652796: step 966, loss 0.369532, acc 0.8125
2020-02-08T02:14:36.776442: step 967, loss 0.351604, acc 0.84375
2020-02-08T02:14:36.902386: step 968, loss 0.268602, acc 0.84375
2020-02-08T02:14:37.028820: step 969, loss 0.441044, acc 0.828125
2020-02-08T02:14:37.153639: step 970, loss 0.530751, acc 0.8125
2020-02-08T02:14:37.276127: step 971, loss 0.444282, acc 0.796875
2020-02-08T02:14:37.397517: step 972, loss 0.353314, acc 0.859375
2020-02-08T02:14:37.521120: step 973, loss 0.245821, acc 0.875
2020-02-08T02:14:37.645866: step 974, loss 0.449083, acc 0.78125
2020-02-08T02:14:37.773434: step 975, loss 0.253598, acc 0.953125
2020-02-08T02:14:37.897741: step 976, loss 0.257284, acc 0.890625
2020-02-08T02:14:38.023793: step 977, loss 0.296849, acc 0.875
2020-02-08T02:14:38.148743: step 978, loss 0.350668, acc 0.90625
2020-02-08T02:14:38.276643: step 979, loss 0.45247, acc 0.84375
2020-02-08T02:14:38.401056: step 980, loss 0.411145, acc 0.8125
2020-02-08T02:14:38.525682: step 981, loss 0.405919, acc 0.796875
2020-02-08T02:14:38.652163: step 982, loss 0.316183, acc 0.875
2020-02-08T02:14:38.776517: step 983, loss 0.298325, acc 0.859375
2020-02-08T02:14:38.902883: step 984, loss 0.296054, acc 0.890625
2020-02-08T02:14:39.029260: step 985, loss 0.3329, acc 0.890625
2020-02-08T02:14:39.156421: step 986, loss 0.509589, acc 0.765625
2020-02-08T02:14:39.277992: step 987, loss 0.336226, acc 0.84375
2020-02-08T02:14:39.404939: step 988, loss 0.326833, acc 0.859375
2020-02-08T02:14:39.529794: step 989, loss 0.329267, acc 0.828125
2020-02-08T02:14:39.655731: step 990, loss 0.364998, acc 0.84375
2020-02-08T02:14:39.779805: step 991, loss 0.276634, acc 0.875
2020-02-08T02:14:39.907527: step 992, loss 0.31451, acc 0.859375
2020-02-08T02:14:40.029389: step 993, loss 0.38619, acc 0.875
2020-02-08T02:14:40.155569: step 994, loss 0.45898, acc 0.84375
2020-02-08T02:14:40.280399: step 995, loss 0.33831, acc 0.875
2020-02-08T02:14:40.408097: step 996, loss 0.41928, acc 0.828125
2020-02-08T02:14:40.534045: step 997, loss 0.357405, acc 0.84375
2020-02-08T02:14:40.661017: step 998, loss 0.29733, acc 0.9375
2020-02-08T02:14:40.783786: step 999, loss 0.469368, acc 0.796875
2020-02-08T02:14:40.909068: step 1000, loss 0.33441, acc 0.796875

Evaluation:
2020-02-08T02:14:41.112926: step 1000, loss 0.580163, acc 0.706379

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1000

2020-02-08T02:14:43.267489: step 1001, loss 0.421997, acc 0.828125
2020-02-08T02:14:43.394524: step 1002, loss 0.339084, acc 0.84375
2020-02-08T02:14:43.522931: step 1003, loss 0.400108, acc 0.8125
2020-02-08T02:14:43.651148: step 1004, loss 0.47858, acc 0.78125
2020-02-08T02:14:43.780286: step 1005, loss 0.422158, acc 0.8125
2020-02-08T02:14:43.907361: step 1006, loss 0.532104, acc 0.765625
2020-02-08T02:14:44.031025: step 1007, loss 0.277967, acc 0.84375
2020-02-08T02:14:44.158136: step 1008, loss 0.434397, acc 0.8125
2020-02-08T02:14:44.282387: step 1009, loss 0.200231, acc 0.953125
2020-02-08T02:14:44.410830: step 1010, loss 0.340793, acc 0.828125
2020-02-08T02:14:44.531628: step 1011, loss 0.345097, acc 0.859375
2020-02-08T02:14:44.660077: step 1012, loss 0.397497, acc 0.84375
2020-02-08T02:14:44.785724: step 1013, loss 0.375292, acc 0.796875
2020-02-08T02:14:44.913321: step 1014, loss 0.293214, acc 0.875
2020-02-08T02:14:45.038585: step 1015, loss 0.406328, acc 0.796875
2020-02-08T02:14:45.164115: step 1016, loss 0.300505, acc 0.890625
2020-02-08T02:14:45.286573: step 1017, loss 0.344414, acc 0.796875
2020-02-08T02:14:45.411336: step 1018, loss 0.420387, acc 0.828125
2020-02-08T02:14:45.536069: step 1019, loss 0.340741, acc 0.875
2020-02-08T02:14:45.662530: step 1020, loss 0.456144, acc 0.828125
2020-02-08T02:14:45.786295: step 1021, loss 0.421545, acc 0.828125
2020-02-08T02:14:45.913220: step 1022, loss 0.355516, acc 0.859375
2020-02-08T02:14:46.106261: step 1023, loss 0.319535, acc 0.796875
2020-02-08T02:14:46.280086: step 1024, loss 0.477588, acc 0.78125
2020-02-08T02:14:46.423501: step 1025, loss 0.465434, acc 0.765625
2020-02-08T02:14:46.566370: step 1026, loss 0.380793, acc 0.859375
2020-02-08T02:14:46.734593: step 1027, loss 0.417769, acc 0.78125
2020-02-08T02:14:46.887549: step 1028, loss 0.373051, acc 0.828125
2020-02-08T02:14:47.035022: step 1029, loss 0.343644, acc 0.859375
2020-02-08T02:14:47.203829: step 1030, loss 0.365607, acc 0.8125
2020-02-08T02:14:47.356938: step 1031, loss 0.31137, acc 0.84375
2020-02-08T02:14:47.506063: step 1032, loss 0.357439, acc 0.859375
2020-02-08T02:14:47.661694: step 1033, loss 0.333303, acc 0.859375
2020-02-08T02:14:47.803367: step 1034, loss 0.418947, acc 0.8125
2020-02-08T02:14:47.944594: step 1035, loss 0.399764, acc 0.828125
2020-02-08T02:14:48.088147: step 1036, loss 0.300953, acc 0.859375
2020-02-08T02:14:48.230299: step 1037, loss 0.482113, acc 0.78125
2020-02-08T02:14:48.373770: step 1038, loss 0.468995, acc 0.8125
2020-02-08T02:14:48.517629: step 1039, loss 0.409146, acc 0.8125
2020-02-08T02:14:48.667185: step 1040, loss 0.468555, acc 0.734375
2020-02-08T02:14:48.813162: step 1041, loss 0.356435, acc 0.828125
2020-02-08T02:14:48.957431: step 1042, loss 0.200924, acc 0.9375
2020-02-08T02:14:49.101387: step 1043, loss 0.307325, acc 0.84375
2020-02-08T02:14:49.252555: step 1044, loss 0.464368, acc 0.8125
2020-02-08T02:14:49.405294: step 1045, loss 0.40192, acc 0.75
2020-02-08T02:14:49.559575: step 1046, loss 0.347207, acc 0.890625
2020-02-08T02:14:49.704084: step 1047, loss 0.460584, acc 0.796875
2020-02-08T02:14:49.849164: step 1048, loss 0.410455, acc 0.8125
2020-02-08T02:14:49.997068: step 1049, loss 0.27622, acc 0.90625
2020-02-08T02:14:50.142882: step 1050, loss 0.405426, acc 0.8
2020-02-08T02:14:50.285678: step 1051, loss 0.399235, acc 0.828125
2020-02-08T02:14:50.420374: step 1052, loss 0.206908, acc 0.921875
2020-02-08T02:14:50.565433: step 1053, loss 0.298124, acc 0.890625
2020-02-08T02:14:50.724124: step 1054, loss 0.259323, acc 0.875
2020-02-08T02:14:50.871569: step 1055, loss 0.220646, acc 0.875
2020-02-08T02:14:51.027248: step 1056, loss 0.398286, acc 0.828125
2020-02-08T02:14:51.171369: step 1057, loss 0.312859, acc 0.875
2020-02-08T02:14:51.515255: step 1058, loss 0.421869, acc 0.796875
2020-02-08T02:14:51.656585: step 1059, loss 0.270937, acc 0.875
2020-02-08T02:14:51.803420: step 1060, loss 0.239492, acc 0.921875
2020-02-08T02:14:51.955185: step 1061, loss 0.285043, acc 0.890625
2020-02-08T02:14:52.108760: step 1062, loss 0.275908, acc 0.890625
2020-02-08T02:14:52.258772: step 1063, loss 0.307618, acc 0.84375
2020-02-08T02:14:52.404791: step 1064, loss 0.297282, acc 0.875
2020-02-08T02:14:52.542401: step 1065, loss 0.229384, acc 0.9375
2020-02-08T02:14:52.693348: step 1066, loss 0.323804, acc 0.84375
2020-02-08T02:14:52.840826: step 1067, loss 0.276921, acc 0.875
2020-02-08T02:14:52.990020: step 1068, loss 0.331714, acc 0.859375
2020-02-08T02:14:53.139085: step 1069, loss 0.343218, acc 0.890625
2020-02-08T02:14:53.290256: step 1070, loss 0.232035, acc 0.921875
2020-02-08T02:14:53.439052: step 1071, loss 0.209651, acc 0.90625
2020-02-08T02:14:53.589141: step 1072, loss 0.378785, acc 0.796875
2020-02-08T02:14:53.747890: step 1073, loss 0.344262, acc 0.859375
2020-02-08T02:14:53.907537: step 1074, loss 0.370012, acc 0.828125
2020-02-08T02:14:54.045075: step 1075, loss 0.208517, acc 0.890625
2020-02-08T02:14:54.185332: step 1076, loss 0.314973, acc 0.875
2020-02-08T02:14:54.333719: step 1077, loss 0.290191, acc 0.84375
2020-02-08T02:14:54.477941: step 1078, loss 0.223543, acc 0.890625
2020-02-08T02:14:54.626378: step 1079, loss 0.393642, acc 0.828125
2020-02-08T02:14:54.771497: step 1080, loss 0.335223, acc 0.8125
2020-02-08T02:14:54.906284: step 1081, loss 0.281983, acc 0.890625
2020-02-08T02:14:55.038529: step 1082, loss 0.204367, acc 0.96875
2020-02-08T02:14:55.191940: step 1083, loss 0.402971, acc 0.859375
2020-02-08T02:14:55.353581: step 1084, loss 0.338535, acc 0.8125
2020-02-08T02:14:55.500988: step 1085, loss 0.525477, acc 0.75
2020-02-08T02:14:55.651953: step 1086, loss 0.389772, acc 0.8125
2020-02-08T02:14:55.793355: step 1087, loss 0.303624, acc 0.890625
2020-02-08T02:14:55.934391: step 1088, loss 0.201912, acc 0.921875
2020-02-08T02:14:56.087164: step 1089, loss 0.301892, acc 0.90625
2020-02-08T02:14:56.214665: step 1090, loss 0.29788, acc 0.859375
2020-02-08T02:14:56.338248: step 1091, loss 0.27687, acc 0.875
2020-02-08T02:14:56.466953: step 1092, loss 0.27897, acc 0.859375
2020-02-08T02:14:56.596627: step 1093, loss 0.203363, acc 0.921875
2020-02-08T02:14:56.743472: step 1094, loss 0.226523, acc 0.90625
2020-02-08T02:14:56.868965: step 1095, loss 0.348247, acc 0.828125
2020-02-08T02:14:56.994401: step 1096, loss 0.299623, acc 0.90625
2020-02-08T02:14:57.122483: step 1097, loss 0.241782, acc 0.90625
2020-02-08T02:14:57.248953: step 1098, loss 0.307833, acc 0.890625
2020-02-08T02:14:57.377474: step 1099, loss 0.254432, acc 0.9375
2020-02-08T02:14:57.504997: step 1100, loss 0.34938, acc 0.90625

Evaluation:
2020-02-08T02:14:57.722259: step 1100, loss 0.579211, acc 0.710131

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1100

2020-02-08T02:14:59.260823: step 1101, loss 0.305856, acc 0.875
2020-02-08T02:14:59.385793: step 1102, loss 0.351224, acc 0.8125
2020-02-08T02:14:59.514385: step 1103, loss 0.234109, acc 0.921875
2020-02-08T02:14:59.637422: step 1104, loss 0.331757, acc 0.859375
2020-02-08T02:14:59.770119: step 1105, loss 0.271766, acc 0.875
2020-02-08T02:14:59.891297: step 1106, loss 0.160448, acc 0.953125
2020-02-08T02:15:00.022939: step 1107, loss 0.452859, acc 0.796875
2020-02-08T02:15:00.151461: step 1108, loss 0.355846, acc 0.828125
2020-02-08T02:15:00.277518: step 1109, loss 0.268323, acc 0.890625
2020-02-08T02:15:00.408338: step 1110, loss 0.284274, acc 0.859375
2020-02-08T02:15:00.532188: step 1111, loss 0.371717, acc 0.8125
2020-02-08T02:15:00.660533: step 1112, loss 0.458114, acc 0.78125
2020-02-08T02:15:00.784710: step 1113, loss 0.327924, acc 0.859375
2020-02-08T02:15:00.910959: step 1114, loss 0.272827, acc 0.90625
2020-02-08T02:15:01.036684: step 1115, loss 0.206298, acc 0.90625
2020-02-08T02:15:01.173534: step 1116, loss 0.347524, acc 0.84375
2020-02-08T02:15:01.300736: step 1117, loss 0.332334, acc 0.828125
2020-02-08T02:15:01.426568: step 1118, loss 0.315332, acc 0.890625
2020-02-08T02:15:01.551131: step 1119, loss 0.207111, acc 0.90625
2020-02-08T02:15:01.680398: step 1120, loss 0.411277, acc 0.78125
2020-02-08T02:15:01.809862: step 1121, loss 0.179406, acc 0.921875
2020-02-08T02:15:01.935590: step 1122, loss 0.299455, acc 0.875
2020-02-08T02:15:02.061183: step 1123, loss 0.405241, acc 0.8125
2020-02-08T02:15:02.186966: step 1124, loss 0.276285, acc 0.859375
2020-02-08T02:15:02.313510: step 1125, loss 0.202199, acc 0.921875
2020-02-08T02:15:02.438734: step 1126, loss 0.211327, acc 0.921875
2020-02-08T02:15:02.564729: step 1127, loss 0.436023, acc 0.890625
2020-02-08T02:15:02.695160: step 1128, loss 0.412116, acc 0.8125
2020-02-08T02:15:02.825142: step 1129, loss 0.42799, acc 0.828125
2020-02-08T02:15:02.954756: step 1130, loss 0.431887, acc 0.796875
2020-02-08T02:15:03.083762: step 1131, loss 0.214337, acc 0.921875
2020-02-08T02:15:03.209863: step 1132, loss 0.370207, acc 0.796875
2020-02-08T02:15:03.340619: step 1133, loss 0.293066, acc 0.859375
2020-02-08T02:15:03.468967: step 1134, loss 0.314032, acc 0.859375
2020-02-08T02:15:03.589918: step 1135, loss 0.250355, acc 0.90625
2020-02-08T02:15:03.724165: step 1136, loss 0.271885, acc 0.890625
2020-02-08T02:15:03.851286: step 1137, loss 0.245303, acc 0.90625
2020-02-08T02:15:03.977025: step 1138, loss 0.233028, acc 0.90625
2020-02-08T02:15:04.107341: step 1139, loss 0.226837, acc 0.921875
2020-02-08T02:15:04.232402: step 1140, loss 0.265508, acc 0.890625
2020-02-08T02:15:04.358248: step 1141, loss 0.275456, acc 0.859375
2020-02-08T02:15:04.482895: step 1142, loss 0.250217, acc 0.859375
2020-02-08T02:15:04.609816: step 1143, loss 0.29349, acc 0.890625
2020-02-08T02:15:04.740260: step 1144, loss 0.289732, acc 0.84375
2020-02-08T02:15:04.867247: step 1145, loss 0.260066, acc 0.90625
2020-02-08T02:15:04.995035: step 1146, loss 0.267182, acc 0.875
2020-02-08T02:15:05.122829: step 1147, loss 0.317507, acc 0.828125
2020-02-08T02:15:05.252004: step 1148, loss 0.275599, acc 0.90625
2020-02-08T02:15:05.377008: step 1149, loss 0.397864, acc 0.828125
2020-02-08T02:15:05.508458: step 1150, loss 0.212013, acc 0.953125
2020-02-08T02:15:05.637789: step 1151, loss 0.377304, acc 0.84375
2020-02-08T02:15:05.770093: step 1152, loss 0.300843, acc 0.875
2020-02-08T02:15:05.896280: step 1153, loss 0.314268, acc 0.859375
2020-02-08T02:15:06.026125: step 1154, loss 0.285301, acc 0.875
2020-02-08T02:15:06.162578: step 1155, loss 0.419134, acc 0.828125
2020-02-08T02:15:06.291117: step 1156, loss 0.350861, acc 0.875
2020-02-08T02:15:06.421517: step 1157, loss 0.192455, acc 0.9375
2020-02-08T02:15:06.546520: step 1158, loss 0.266559, acc 0.890625
2020-02-08T02:15:06.684074: step 1159, loss 0.278199, acc 0.875
2020-02-08T02:15:06.818297: step 1160, loss 0.36787, acc 0.796875
2020-02-08T02:15:06.944122: step 1161, loss 0.2465, acc 0.859375
2020-02-08T02:15:07.069653: step 1162, loss 0.204248, acc 0.90625
2020-02-08T02:15:07.194543: step 1163, loss 0.27539, acc 0.90625
2020-02-08T02:15:07.323327: step 1164, loss 0.467996, acc 0.78125
2020-02-08T02:15:07.449645: step 1165, loss 0.383361, acc 0.84375
2020-02-08T02:15:07.577522: step 1166, loss 0.413054, acc 0.8125
2020-02-08T02:15:07.712295: step 1167, loss 0.595487, acc 0.734375
2020-02-08T02:15:07.837649: step 1168, loss 0.329433, acc 0.8125
2020-02-08T02:15:07.967006: step 1169, loss 0.277949, acc 0.875
2020-02-08T02:15:08.092295: step 1170, loss 0.391228, acc 0.8125
2020-02-08T02:15:08.219689: step 1171, loss 0.445674, acc 0.859375
2020-02-08T02:15:08.345101: step 1172, loss 0.238789, acc 0.875
2020-02-08T02:15:08.475558: step 1173, loss 0.420077, acc 0.75
2020-02-08T02:15:08.607501: step 1174, loss 0.186023, acc 0.921875
2020-02-08T02:15:08.738327: step 1175, loss 0.251599, acc 0.890625
2020-02-08T02:15:08.867590: step 1176, loss 0.281557, acc 0.875
2020-02-08T02:15:08.995600: step 1177, loss 0.450796, acc 0.828125
2020-02-08T02:15:09.127088: step 1178, loss 0.402895, acc 0.8125
2020-02-08T02:15:09.255556: step 1179, loss 0.332672, acc 0.875
2020-02-08T02:15:09.380932: step 1180, loss 0.464126, acc 0.84375
2020-02-08T02:15:09.507367: step 1181, loss 0.333766, acc 0.859375
2020-02-08T02:15:09.632298: step 1182, loss 0.335154, acc 0.84375
2020-02-08T02:15:09.763802: step 1183, loss 0.246239, acc 0.890625
2020-02-08T02:15:09.889897: step 1184, loss 0.215899, acc 0.921875
2020-02-08T02:15:10.015774: step 1185, loss 0.282458, acc 0.921875
2020-02-08T02:15:10.140876: step 1186, loss 0.340071, acc 0.875
2020-02-08T02:15:10.265143: step 1187, loss 0.274552, acc 0.890625
2020-02-08T02:15:10.393310: step 1188, loss 0.303578, acc 0.875
2020-02-08T02:15:10.520245: step 1189, loss 0.318927, acc 0.828125
2020-02-08T02:15:10.645974: step 1190, loss 0.17359, acc 0.953125
2020-02-08T02:15:10.775235: step 1191, loss 0.339272, acc 0.828125
2020-02-08T02:15:10.902643: step 1192, loss 0.451093, acc 0.78125
2020-02-08T02:15:11.031401: step 1193, loss 0.317035, acc 0.875
2020-02-08T02:15:11.157923: step 1194, loss 0.242317, acc 0.90625
2020-02-08T02:15:11.283054: step 1195, loss 0.290438, acc 0.890625
2020-02-08T02:15:11.406702: step 1196, loss 0.488969, acc 0.78125
2020-02-08T02:15:11.528439: step 1197, loss 0.238004, acc 0.9375
2020-02-08T02:15:11.659009: step 1198, loss 0.447393, acc 0.8125
2020-02-08T02:15:11.780425: step 1199, loss 0.311423, acc 0.84375
2020-02-08T02:15:11.902689: step 1200, loss 0.300177, acc 0.85

Evaluation:
2020-02-08T02:15:12.110877: step 1200, loss 0.578419, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1200

2020-02-08T02:15:13.993209: step 1201, loss 0.269021, acc 0.875
2020-02-08T02:15:14.120129: step 1202, loss 0.201048, acc 0.921875
2020-02-08T02:15:14.242424: step 1203, loss 0.242329, acc 0.90625
2020-02-08T02:15:14.370088: step 1204, loss 0.20806, acc 0.890625
2020-02-08T02:15:14.496822: step 1205, loss 0.21248, acc 0.921875
2020-02-08T02:15:14.625201: step 1206, loss 0.310253, acc 0.90625
2020-02-08T02:15:14.758877: step 1207, loss 0.188487, acc 0.9375
2020-02-08T02:15:14.884467: step 1208, loss 0.40103, acc 0.796875
2020-02-08T02:15:15.010874: step 1209, loss 0.172943, acc 0.96875
2020-02-08T02:15:15.137514: step 1210, loss 0.301814, acc 0.828125
2020-02-08T02:15:15.265024: step 1211, loss 0.305157, acc 0.859375
2020-02-08T02:15:15.391312: step 1212, loss 0.182937, acc 0.9375
2020-02-08T02:15:15.519845: step 1213, loss 0.2324, acc 0.9375
2020-02-08T02:15:15.646251: step 1214, loss 0.225888, acc 0.90625
2020-02-08T02:15:15.776971: step 1215, loss 0.218689, acc 0.859375
2020-02-08T02:15:15.908627: step 1216, loss 0.285814, acc 0.84375
2020-02-08T02:15:16.033356: step 1217, loss 0.158821, acc 0.90625
2020-02-08T02:15:16.163589: step 1218, loss 0.211372, acc 0.90625
2020-02-08T02:15:16.286723: step 1219, loss 0.419096, acc 0.8125
2020-02-08T02:15:16.414679: step 1220, loss 0.235857, acc 0.890625
2020-02-08T02:15:16.546011: step 1221, loss 0.180269, acc 0.9375
2020-02-08T02:15:16.673939: step 1222, loss 0.367729, acc 0.890625
2020-02-08T02:15:16.799408: step 1223, loss 0.215082, acc 0.890625
2020-02-08T02:15:16.927937: step 1224, loss 0.2625, acc 0.890625
2020-02-08T02:15:17.057801: step 1225, loss 0.204226, acc 0.90625
2020-02-08T02:15:17.184312: step 1226, loss 0.260231, acc 0.921875
2020-02-08T02:15:17.311170: step 1227, loss 0.141921, acc 0.953125
2020-02-08T02:15:17.434271: step 1228, loss 0.324829, acc 0.859375
2020-02-08T02:15:17.559647: step 1229, loss 0.13672, acc 0.96875
2020-02-08T02:15:17.686821: step 1230, loss 0.208668, acc 0.921875
2020-02-08T02:15:17.814097: step 1231, loss 0.25847, acc 0.90625
2020-02-08T02:15:17.939015: step 1232, loss 0.191086, acc 0.921875
2020-02-08T02:15:18.067407: step 1233, loss 0.189419, acc 0.921875
2020-02-08T02:15:18.194284: step 1234, loss 0.229357, acc 0.90625
2020-02-08T02:15:18.321525: step 1235, loss 0.374359, acc 0.84375
2020-02-08T02:15:18.447628: step 1236, loss 0.170032, acc 0.921875
2020-02-08T02:15:18.588127: step 1237, loss 0.272053, acc 0.875
2020-02-08T02:15:18.718696: step 1238, loss 0.236186, acc 0.890625
2020-02-08T02:15:18.843392: step 1239, loss 0.278801, acc 0.875
2020-02-08T02:15:18.972067: step 1240, loss 0.2112, acc 0.90625
2020-02-08T02:15:19.099161: step 1241, loss 0.257903, acc 0.9375
2020-02-08T02:15:19.229839: step 1242, loss 0.188812, acc 0.921875
2020-02-08T02:15:19.356826: step 1243, loss 0.224173, acc 0.9375
2020-02-08T02:15:19.482166: step 1244, loss 0.115348, acc 0.953125
2020-02-08T02:15:19.609225: step 1245, loss 0.148035, acc 0.96875
2020-02-08T02:15:19.737378: step 1246, loss 0.315838, acc 0.875
2020-02-08T02:15:19.863766: step 1247, loss 0.322447, acc 0.890625
2020-02-08T02:15:19.988330: step 1248, loss 0.235247, acc 0.890625
2020-02-08T02:15:20.115433: step 1249, loss 0.24772, acc 0.875
2020-02-08T02:15:20.241536: step 1250, loss 0.277026, acc 0.875
2020-02-08T02:15:20.364450: step 1251, loss 0.13671, acc 0.96875
2020-02-08T02:15:20.485799: step 1252, loss 0.338104, acc 0.875
2020-02-08T02:15:20.614183: step 1253, loss 0.177922, acc 0.953125
2020-02-08T02:15:20.748217: step 1254, loss 0.250711, acc 0.890625
2020-02-08T02:15:20.876163: step 1255, loss 0.134738, acc 0.96875
2020-02-08T02:15:20.998762: step 1256, loss 0.25734, acc 0.875
2020-02-08T02:15:21.127055: step 1257, loss 0.20864, acc 0.921875
2020-02-08T02:15:21.254313: step 1258, loss 0.254313, acc 0.875
2020-02-08T02:15:21.500106: step 1259, loss 0.239437, acc 0.875
2020-02-08T02:15:21.633019: step 1260, loss 0.190802, acc 0.890625
2020-02-08T02:15:21.765876: step 1261, loss 0.227422, acc 0.890625
2020-02-08T02:15:21.890819: step 1262, loss 0.16481, acc 0.953125
2020-02-08T02:15:22.018184: step 1263, loss 0.253602, acc 0.875
2020-02-08T02:15:22.142139: step 1264, loss 0.359089, acc 0.828125
2020-02-08T02:15:22.265664: step 1265, loss 0.277366, acc 0.875
2020-02-08T02:15:22.390033: step 1266, loss 0.196867, acc 0.9375
2020-02-08T02:15:22.519248: step 1267, loss 0.263661, acc 0.859375
2020-02-08T02:15:22.642338: step 1268, loss 0.277007, acc 0.890625
2020-02-08T02:15:22.774931: step 1269, loss 0.261878, acc 0.890625
2020-02-08T02:15:22.903660: step 1270, loss 0.180606, acc 0.9375
2020-02-08T02:15:23.030994: step 1271, loss 0.305619, acc 0.890625
2020-02-08T02:15:23.158052: step 1272, loss 0.187344, acc 0.90625
2020-02-08T02:15:23.280381: step 1273, loss 0.292954, acc 0.859375
2020-02-08T02:15:23.408290: step 1274, loss 0.160946, acc 0.96875
2020-02-08T02:15:23.533449: step 1275, loss 0.276616, acc 0.875
2020-02-08T02:15:23.662725: step 1276, loss 0.257357, acc 0.828125
2020-02-08T02:15:23.792815: step 1277, loss 0.181399, acc 0.9375
2020-02-08T02:15:23.920144: step 1278, loss 0.322897, acc 0.84375
2020-02-08T02:15:24.048799: step 1279, loss 0.263908, acc 0.90625
2020-02-08T02:15:24.172608: step 1280, loss 0.212493, acc 0.890625
2020-02-08T02:15:24.298503: step 1281, loss 0.22522, acc 0.90625
2020-02-08T02:15:24.423790: step 1282, loss 0.299797, acc 0.859375
2020-02-08T02:15:24.550526: step 1283, loss 0.182388, acc 0.9375
2020-02-08T02:15:24.681251: step 1284, loss 0.178618, acc 0.9375
2020-02-08T02:15:24.810562: step 1285, loss 0.241598, acc 0.90625
2020-02-08T02:15:24.934904: step 1286, loss 0.236417, acc 0.921875
2020-02-08T02:15:25.061399: step 1287, loss 0.280012, acc 0.90625
2020-02-08T02:15:25.186557: step 1288, loss 0.146371, acc 0.9375
2020-02-08T02:15:25.312830: step 1289, loss 0.218149, acc 0.9375
2020-02-08T02:15:25.434787: step 1290, loss 0.157073, acc 0.953125
2020-02-08T02:15:25.564223: step 1291, loss 0.352941, acc 0.84375
2020-02-08T02:15:25.690281: step 1292, loss 0.388693, acc 0.84375
2020-02-08T02:15:25.819011: step 1293, loss 0.268437, acc 0.90625
2020-02-08T02:15:25.943038: step 1294, loss 0.240569, acc 0.890625
2020-02-08T02:15:26.079498: step 1295, loss 0.343463, acc 0.875
2020-02-08T02:15:26.209111: step 1296, loss 0.199865, acc 0.890625
2020-02-08T02:15:26.334403: step 1297, loss 0.249872, acc 0.921875
2020-02-08T02:15:26.462804: step 1298, loss 0.160191, acc 0.9375
2020-02-08T02:15:26.589839: step 1299, loss 0.241698, acc 0.9375
2020-02-08T02:15:26.722736: step 1300, loss 0.257389, acc 0.859375

Evaluation:
2020-02-08T02:15:26.929298: step 1300, loss 0.625531, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1300

2020-02-08T02:15:29.685684: step 1301, loss 0.164657, acc 0.921875
2020-02-08T02:15:29.814932: step 1302, loss 0.316759, acc 0.84375
2020-02-08T02:15:29.940207: step 1303, loss 0.25142, acc 0.875
2020-02-08T02:15:30.066609: step 1304, loss 0.223565, acc 0.921875
2020-02-08T02:15:30.192004: step 1305, loss 0.334409, acc 0.859375
2020-02-08T02:15:30.318450: step 1306, loss 0.202846, acc 0.90625
2020-02-08T02:15:30.441340: step 1307, loss 0.275434, acc 0.890625
2020-02-08T02:15:30.567312: step 1308, loss 0.218207, acc 0.890625
2020-02-08T02:15:30.696690: step 1309, loss 0.39018, acc 0.8125
2020-02-08T02:15:30.821757: step 1310, loss 0.229066, acc 0.890625
2020-02-08T02:15:30.945907: step 1311, loss 0.185378, acc 0.921875
2020-02-08T02:15:31.072704: step 1312, loss 0.219973, acc 0.921875
2020-02-08T02:15:31.199195: step 1313, loss 0.202377, acc 0.921875
2020-02-08T02:15:31.328256: step 1314, loss 0.259063, acc 0.890625
2020-02-08T02:15:31.455485: step 1315, loss 0.131852, acc 0.984375
2020-02-08T02:15:31.579878: step 1316, loss 0.24855, acc 0.859375
2020-02-08T02:15:31.714118: step 1317, loss 0.249094, acc 0.875
2020-02-08T02:15:31.839649: step 1318, loss 0.232368, acc 0.890625
2020-02-08T02:15:31.964191: step 1319, loss 0.291536, acc 0.859375
2020-02-08T02:15:32.087520: step 1320, loss 0.26548, acc 0.859375
2020-02-08T02:15:32.212621: step 1321, loss 0.156014, acc 0.953125
2020-02-08T02:15:32.337597: step 1322, loss 0.297781, acc 0.890625
2020-02-08T02:15:32.463892: step 1323, loss 0.144384, acc 1
2020-02-08T02:15:32.592702: step 1324, loss 0.484289, acc 0.828125
2020-02-08T02:15:32.727509: step 1325, loss 0.243093, acc 0.890625
2020-02-08T02:15:32.857519: step 1326, loss 0.140193, acc 0.96875
2020-02-08T02:15:32.983321: step 1327, loss 0.320889, acc 0.859375
2020-02-08T02:15:33.110192: step 1328, loss 0.311734, acc 0.875
2020-02-08T02:15:33.235760: step 1329, loss 0.224097, acc 0.921875
2020-02-08T02:15:33.361039: step 1330, loss 0.308198, acc 0.90625
2020-02-08T02:15:33.488519: step 1331, loss 0.200707, acc 0.890625
2020-02-08T02:15:33.618347: step 1332, loss 0.191948, acc 0.921875
2020-02-08T02:15:33.752561: step 1333, loss 0.192515, acc 0.953125
2020-02-08T02:15:33.879003: step 1334, loss 0.19862, acc 0.90625
2020-02-08T02:15:34.011009: step 1335, loss 0.237372, acc 0.890625
2020-02-08T02:15:34.136303: step 1336, loss 0.251281, acc 0.84375
2020-02-08T02:15:34.261617: step 1337, loss 0.194841, acc 0.9375
2020-02-08T02:15:34.391842: step 1338, loss 0.287015, acc 0.875
2020-02-08T02:15:34.520432: step 1339, loss 0.297002, acc 0.875
2020-02-08T02:15:34.652011: step 1340, loss 0.161954, acc 0.921875
2020-02-08T02:15:34.780254: step 1341, loss 0.167268, acc 0.921875
2020-02-08T02:15:34.904978: step 1342, loss 0.35666, acc 0.84375
2020-02-08T02:15:35.031458: step 1343, loss 0.240265, acc 0.890625
2020-02-08T02:15:35.159062: step 1344, loss 0.211063, acc 0.875
2020-02-08T02:15:35.283336: step 1345, loss 0.266426, acc 0.890625
2020-02-08T02:15:35.407436: step 1346, loss 0.193178, acc 0.9375
2020-02-08T02:15:35.533744: step 1347, loss 0.191256, acc 0.9375
2020-02-08T02:15:35.663402: step 1348, loss 0.361961, acc 0.875
2020-02-08T02:15:35.789898: step 1349, loss 0.242044, acc 0.90625
2020-02-08T02:15:35.910495: step 1350, loss 0.339567, acc 0.85
2020-02-08T02:15:36.040636: step 1351, loss 0.272632, acc 0.890625
2020-02-08T02:15:36.167395: step 1352, loss 0.156995, acc 0.921875
2020-02-08T02:15:36.292837: step 1353, loss 0.238615, acc 0.890625
2020-02-08T02:15:36.415608: step 1354, loss 0.230459, acc 0.875
2020-02-08T02:15:36.541405: step 1355, loss 0.286902, acc 0.90625
2020-02-08T02:15:36.670029: step 1356, loss 0.184366, acc 0.921875
2020-02-08T02:15:36.799508: step 1357, loss 0.269888, acc 0.875
2020-02-08T02:15:36.926051: step 1358, loss 0.234386, acc 0.921875
2020-02-08T02:15:37.052468: step 1359, loss 0.202317, acc 0.90625
2020-02-08T02:15:37.177480: step 1360, loss 0.293274, acc 0.84375
2020-02-08T02:15:37.303987: step 1361, loss 0.233575, acc 0.90625
2020-02-08T02:15:37.431312: step 1362, loss 0.13121, acc 0.953125
2020-02-08T02:15:37.556964: step 1363, loss 0.209483, acc 0.890625
2020-02-08T02:15:37.683172: step 1364, loss 0.160747, acc 0.953125
2020-02-08T02:15:37.809971: step 1365, loss 0.174113, acc 0.9375
2020-02-08T02:15:37.933434: step 1366, loss 0.166527, acc 0.9375
2020-02-08T02:15:38.060205: step 1367, loss 0.11275, acc 0.953125
2020-02-08T02:15:38.188399: step 1368, loss 0.213302, acc 0.921875
2020-02-08T02:15:38.317145: step 1369, loss 0.255119, acc 0.90625
2020-02-08T02:15:38.442265: step 1370, loss 0.145067, acc 0.953125
2020-02-08T02:15:38.565877: step 1371, loss 0.212022, acc 0.890625
2020-02-08T02:15:38.695980: step 1372, loss 0.167235, acc 0.9375
2020-02-08T02:15:38.823133: step 1373, loss 0.140661, acc 0.984375
2020-02-08T02:15:38.949554: step 1374, loss 0.170342, acc 0.921875
2020-02-08T02:15:39.076634: step 1375, loss 0.184749, acc 0.921875
2020-02-08T02:15:39.206886: step 1376, loss 0.251349, acc 0.890625
2020-02-08T02:15:39.337325: step 1377, loss 0.240534, acc 0.890625
2020-02-08T02:15:39.464223: step 1378, loss 0.169966, acc 0.921875
2020-02-08T02:15:39.587806: step 1379, loss 0.227386, acc 0.875
2020-02-08T02:15:39.717228: step 1380, loss 0.120587, acc 0.953125
2020-02-08T02:15:39.843961: step 1381, loss 0.319978, acc 0.875
2020-02-08T02:15:39.971483: step 1382, loss 0.124593, acc 0.96875
2020-02-08T02:15:40.094266: step 1383, loss 0.181974, acc 0.921875
2020-02-08T02:15:40.221515: step 1384, loss 0.158261, acc 0.921875
2020-02-08T02:15:40.347022: step 1385, loss 0.164418, acc 0.9375
2020-02-08T02:15:40.473395: step 1386, loss 0.149113, acc 0.9375
2020-02-08T02:15:40.597870: step 1387, loss 0.167442, acc 0.921875
2020-02-08T02:15:40.731992: step 1388, loss 0.172242, acc 0.921875
2020-02-08T02:15:40.860914: step 1389, loss 0.146728, acc 0.9375
2020-02-08T02:15:40.986080: step 1390, loss 0.222275, acc 0.90625
2020-02-08T02:15:41.114072: step 1391, loss 0.178649, acc 0.90625
2020-02-08T02:15:41.239770: step 1392, loss 0.170481, acc 0.9375
2020-02-08T02:15:41.369555: step 1393, loss 0.285447, acc 0.90625
2020-02-08T02:15:41.497268: step 1394, loss 0.121346, acc 0.96875
2020-02-08T02:15:41.624557: step 1395, loss 0.131086, acc 0.9375
2020-02-08T02:15:41.759405: step 1396, loss 0.192883, acc 0.9375
2020-02-08T02:15:41.885132: step 1397, loss 0.131269, acc 0.984375
2020-02-08T02:15:42.012760: step 1398, loss 0.196235, acc 0.890625
2020-02-08T02:15:42.138855: step 1399, loss 0.274818, acc 0.90625
2020-02-08T02:15:42.264832: step 1400, loss 0.259615, acc 0.921875

Evaluation:
2020-02-08T02:15:42.475735: step 1400, loss 0.60535, acc 0.743902

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1400

2020-02-08T02:15:43.965610: step 1401, loss 0.202095, acc 0.9375
2020-02-08T02:15:44.090980: step 1402, loss 0.252071, acc 0.890625
2020-02-08T02:15:44.215136: step 1403, loss 0.241355, acc 0.875
2020-02-08T02:15:44.341715: step 1404, loss 0.310054, acc 0.90625
2020-02-08T02:15:44.464963: step 1405, loss 0.153833, acc 0.921875
2020-02-08T02:15:44.587501: step 1406, loss 0.174379, acc 0.90625
2020-02-08T02:15:44.720289: step 1407, loss 0.240571, acc 0.90625
2020-02-08T02:15:44.846878: step 1408, loss 0.253271, acc 0.875
2020-02-08T02:15:44.972700: step 1409, loss 0.222138, acc 0.90625
2020-02-08T02:15:45.095062: step 1410, loss 0.132568, acc 0.96875
2020-02-08T02:15:45.222445: step 1411, loss 0.157033, acc 0.921875
2020-02-08T02:15:45.349530: step 1412, loss 0.161083, acc 0.953125
2020-02-08T02:15:45.473206: step 1413, loss 0.175016, acc 0.921875
2020-02-08T02:15:45.595827: step 1414, loss 0.126007, acc 0.96875
2020-02-08T02:15:45.727608: step 1415, loss 0.237573, acc 0.890625
2020-02-08T02:15:45.854629: step 1416, loss 0.194279, acc 0.90625
2020-02-08T02:15:45.978768: step 1417, loss 0.168056, acc 0.9375
2020-02-08T02:15:46.106164: step 1418, loss 0.224549, acc 0.890625
2020-02-08T02:15:46.231928: step 1419, loss 0.115915, acc 0.96875
2020-02-08T02:15:46.359102: step 1420, loss 0.232371, acc 0.890625
2020-02-08T02:15:46.481074: step 1421, loss 0.254694, acc 0.890625
2020-02-08T02:15:46.609351: step 1422, loss 0.254192, acc 0.90625
2020-02-08T02:15:46.739591: step 1423, loss 0.136322, acc 0.953125
2020-02-08T02:15:46.865423: step 1424, loss 0.0926017, acc 1
2020-02-08T02:15:46.989709: step 1425, loss 0.173638, acc 0.90625
2020-02-08T02:15:47.118603: step 1426, loss 0.238265, acc 0.875
2020-02-08T02:15:47.241845: step 1427, loss 0.194192, acc 0.921875
2020-02-08T02:15:47.366493: step 1428, loss 0.218914, acc 0.9375
2020-02-08T02:15:47.489751: step 1429, loss 0.137122, acc 0.96875
2020-02-08T02:15:47.615573: step 1430, loss 0.146998, acc 0.953125
2020-02-08T02:15:47.743672: step 1431, loss 0.17801, acc 0.90625
2020-02-08T02:15:47.870043: step 1432, loss 0.242523, acc 0.90625
2020-02-08T02:15:47.992283: step 1433, loss 0.236198, acc 0.90625
2020-02-08T02:15:48.118293: step 1434, loss 0.107359, acc 0.96875
2020-02-08T02:15:48.241599: step 1435, loss 0.186631, acc 0.890625
2020-02-08T02:15:48.363788: step 1436, loss 0.165198, acc 0.9375
2020-02-08T02:15:48.485118: step 1437, loss 0.190198, acc 0.9375
2020-02-08T02:15:48.609444: step 1438, loss 0.261323, acc 0.921875
2020-02-08T02:15:48.736685: step 1439, loss 0.191444, acc 0.875
2020-02-08T02:15:48.862176: step 1440, loss 0.264609, acc 0.890625
2020-02-08T02:15:48.984818: step 1441, loss 0.15522, acc 0.96875
2020-02-08T02:15:49.112207: step 1442, loss 0.147554, acc 0.953125
2020-02-08T02:15:49.242096: step 1443, loss 0.27381, acc 0.890625
2020-02-08T02:15:49.368826: step 1444, loss 0.124971, acc 0.9375
2020-02-08T02:15:49.493856: step 1445, loss 0.120001, acc 0.96875
2020-02-08T02:15:49.621967: step 1446, loss 0.135219, acc 0.953125
2020-02-08T02:15:49.753752: step 1447, loss 0.182712, acc 0.9375
2020-02-08T02:15:49.878238: step 1448, loss 0.252526, acc 0.90625
2020-02-08T02:15:50.002901: step 1449, loss 0.172527, acc 0.953125
2020-02-08T02:15:50.128902: step 1450, loss 0.168342, acc 0.9375
2020-02-08T02:15:50.255266: step 1451, loss 0.244909, acc 0.9375
2020-02-08T02:15:50.379533: step 1452, loss 0.188884, acc 0.9375
2020-02-08T02:15:50.501772: step 1453, loss 0.207116, acc 0.890625
2020-02-08T02:15:50.627071: step 1454, loss 0.335737, acc 0.859375
2020-02-08T02:15:50.759689: step 1455, loss 0.188314, acc 0.9375
2020-02-08T02:15:50.884183: step 1456, loss 0.187052, acc 0.921875
2020-02-08T02:15:51.011262: step 1457, loss 0.121649, acc 0.9375
2020-02-08T02:15:51.136137: step 1458, loss 0.154195, acc 0.953125
2020-02-08T02:15:51.474072: step 1459, loss 0.0971586, acc 0.984375
2020-02-08T02:15:51.600324: step 1460, loss 0.163924, acc 0.9375
2020-02-08T02:15:51.732528: step 1461, loss 0.211305, acc 0.921875
2020-02-08T02:15:51.860992: step 1462, loss 0.119969, acc 0.953125
2020-02-08T02:15:51.984584: step 1463, loss 0.132773, acc 0.953125
2020-02-08T02:15:52.110957: step 1464, loss 0.214325, acc 0.890625
2020-02-08T02:15:52.233313: step 1465, loss 0.238525, acc 0.84375
2020-02-08T02:15:52.357853: step 1466, loss 0.082176, acc 0.984375
2020-02-08T02:15:52.480478: step 1467, loss 0.162631, acc 0.9375
2020-02-08T02:15:52.608869: step 1468, loss 0.184026, acc 0.90625
2020-02-08T02:15:52.738166: step 1469, loss 0.282194, acc 0.890625
2020-02-08T02:15:52.869577: step 1470, loss 0.141818, acc 0.9375
2020-02-08T02:15:52.994952: step 1471, loss 0.198773, acc 0.921875
2020-02-08T02:15:53.119261: step 1472, loss 0.321387, acc 0.875
2020-02-08T02:15:53.247637: step 1473, loss 0.247548, acc 0.875
2020-02-08T02:15:53.372320: step 1474, loss 0.305514, acc 0.90625
2020-02-08T02:15:53.498537: step 1475, loss 0.264825, acc 0.90625
2020-02-08T02:15:53.624969: step 1476, loss 0.22768, acc 0.9375
2020-02-08T02:15:53.756471: step 1477, loss 0.257194, acc 0.90625
2020-02-08T02:15:53.879855: step 1478, loss 0.254098, acc 0.90625
2020-02-08T02:15:54.009091: step 1479, loss 0.345511, acc 0.796875
2020-02-08T02:15:54.134131: step 1480, loss 0.213326, acc 0.921875
2020-02-08T02:15:54.259973: step 1481, loss 0.153546, acc 0.9375
2020-02-08T02:15:54.382365: step 1482, loss 0.124995, acc 0.9375
2020-02-08T02:15:54.509816: step 1483, loss 0.21523, acc 0.921875
2020-02-08T02:15:54.635086: step 1484, loss 0.18466, acc 0.921875
2020-02-08T02:15:54.768573: step 1485, loss 0.204227, acc 0.90625
2020-02-08T02:15:54.895154: step 1486, loss 0.286722, acc 0.90625
2020-02-08T02:15:55.023119: step 1487, loss 0.267159, acc 0.875
2020-02-08T02:15:55.147710: step 1488, loss 0.154146, acc 0.9375
2020-02-08T02:15:55.272929: step 1489, loss 0.186791, acc 0.90625
2020-02-08T02:15:55.396191: step 1490, loss 0.192795, acc 0.953125
2020-02-08T02:15:55.520113: step 1491, loss 0.170506, acc 0.90625
2020-02-08T02:15:55.647654: step 1492, loss 0.186552, acc 0.9375
2020-02-08T02:15:55.776552: step 1493, loss 0.239927, acc 0.921875
2020-02-08T02:15:55.906938: step 1494, loss 0.147789, acc 0.9375
2020-02-08T02:15:56.031566: step 1495, loss 0.246681, acc 0.90625
2020-02-08T02:15:56.160549: step 1496, loss 0.176912, acc 0.953125
2020-02-08T02:15:56.285245: step 1497, loss 0.202836, acc 0.921875
2020-02-08T02:15:56.412947: step 1498, loss 0.200981, acc 0.921875
2020-02-08T02:15:56.536383: step 1499, loss 0.244889, acc 0.921875
2020-02-08T02:15:56.662043: step 1500, loss 0.115825, acc 0.933333

Evaluation:
2020-02-08T02:15:56.870311: step 1500, loss 0.634261, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1500

2020-02-08T02:15:58.382661: step 1501, loss 0.133947, acc 0.953125
2020-02-08T02:15:58.510648: step 1502, loss 0.0922158, acc 0.96875
2020-02-08T02:15:58.635383: step 1503, loss 0.0846333, acc 0.984375
2020-02-08T02:15:58.768374: step 1504, loss 0.0928145, acc 1
2020-02-08T02:15:58.893328: step 1505, loss 0.139642, acc 0.96875
2020-02-08T02:15:59.021263: step 1506, loss 0.155313, acc 0.921875
2020-02-08T02:15:59.145868: step 1507, loss 0.106356, acc 0.953125
2020-02-08T02:15:59.275398: step 1508, loss 0.148885, acc 0.953125
2020-02-08T02:15:59.404246: step 1509, loss 0.160275, acc 0.90625
2020-02-08T02:15:59.532559: step 1510, loss 0.0818102, acc 0.984375
2020-02-08T02:15:59.659254: step 1511, loss 0.184118, acc 0.890625
2020-02-08T02:15:59.783349: step 1512, loss 0.188802, acc 0.921875
2020-02-08T02:15:59.910058: step 1513, loss 0.113155, acc 0.96875
2020-02-08T02:16:00.043862: step 1514, loss 0.132932, acc 0.984375
2020-02-08T02:16:00.170420: step 1515, loss 0.162733, acc 0.9375
2020-02-08T02:16:00.293419: step 1516, loss 0.113568, acc 0.96875
2020-02-08T02:16:00.420283: step 1517, loss 0.125258, acc 0.96875
2020-02-08T02:16:00.542623: step 1518, loss 0.187985, acc 0.921875
2020-02-08T02:16:00.670780: step 1519, loss 0.195285, acc 0.96875
2020-02-08T02:16:00.792680: step 1520, loss 0.114674, acc 0.96875
2020-02-08T02:16:00.942539: step 1521, loss 0.0432904, acc 1
2020-02-08T02:16:01.096480: step 1522, loss 0.0671241, acc 0.984375
2020-02-08T02:16:01.250611: step 1523, loss 0.174357, acc 0.953125
2020-02-08T02:16:01.377102: step 1524, loss 0.16921, acc 0.9375
2020-02-08T02:16:01.504575: step 1525, loss 0.0835007, acc 0.984375
2020-02-08T02:16:01.628894: step 1526, loss 0.0736502, acc 0.984375
2020-02-08T02:16:01.761628: step 1527, loss 0.14705, acc 0.953125
2020-02-08T02:16:01.886779: step 1528, loss 0.211793, acc 0.921875
2020-02-08T02:16:02.029106: step 1529, loss 0.210672, acc 0.921875
2020-02-08T02:16:02.170116: step 1530, loss 0.179131, acc 0.921875
2020-02-08T02:16:02.294284: step 1531, loss 0.148698, acc 0.9375
2020-02-08T02:16:02.432540: step 1532, loss 0.144165, acc 0.921875
2020-02-08T02:16:02.562691: step 1533, loss 0.2033, acc 0.9375
2020-02-08T02:16:02.734114: step 1534, loss 0.0993799, acc 0.96875
2020-02-08T02:16:02.865593: step 1535, loss 0.0731184, acc 1
2020-02-08T02:16:02.988904: step 1536, loss 0.135153, acc 0.9375
2020-02-08T02:16:03.114182: step 1537, loss 0.0843303, acc 0.984375
2020-02-08T02:16:03.239758: step 1538, loss 0.186944, acc 0.921875
2020-02-08T02:16:03.363404: step 1539, loss 0.125743, acc 0.9375
2020-02-08T02:16:03.488254: step 1540, loss 0.101643, acc 0.953125
2020-02-08T02:16:03.615201: step 1541, loss 0.237042, acc 0.90625
2020-02-08T02:16:03.745505: step 1542, loss 0.138385, acc 0.9375
2020-02-08T02:16:03.868837: step 1543, loss 0.160206, acc 0.953125
2020-02-08T02:16:03.992380: step 1544, loss 0.0876138, acc 0.984375
2020-02-08T02:16:04.117389: step 1545, loss 0.129145, acc 0.953125
2020-02-08T02:16:04.238191: step 1546, loss 0.166763, acc 0.90625
2020-02-08T02:16:04.364872: step 1547, loss 0.248429, acc 0.921875
2020-02-08T02:16:04.486547: step 1548, loss 0.221201, acc 0.890625
2020-02-08T02:16:04.612764: step 1549, loss 0.109733, acc 0.9375
2020-02-08T02:16:04.744773: step 1550, loss 0.125579, acc 0.9375
2020-02-08T02:16:04.870778: step 1551, loss 0.184193, acc 0.9375
2020-02-08T02:16:04.994644: step 1552, loss 0.182401, acc 0.9375
2020-02-08T02:16:05.119593: step 1553, loss 0.183056, acc 0.9375
2020-02-08T02:16:05.244672: step 1554, loss 0.146803, acc 0.953125
2020-02-08T02:16:05.372339: step 1555, loss 0.205155, acc 0.875
2020-02-08T02:16:05.495804: step 1556, loss 0.108394, acc 0.984375
2020-02-08T02:16:05.623685: step 1557, loss 0.0770057, acc 0.984375
2020-02-08T02:16:05.751832: step 1558, loss 0.305299, acc 0.90625
2020-02-08T02:16:05.878361: step 1559, loss 0.185674, acc 0.921875
2020-02-08T02:16:06.003621: step 1560, loss 0.137082, acc 0.96875
2020-02-08T02:16:06.127329: step 1561, loss 0.121442, acc 0.953125
2020-02-08T02:16:06.258998: step 1562, loss 0.129058, acc 0.953125
2020-02-08T02:16:06.382043: step 1563, loss 0.206022, acc 0.921875
2020-02-08T02:16:06.509347: step 1564, loss 0.150429, acc 0.9375
2020-02-08T02:16:06.632311: step 1565, loss 0.113668, acc 0.96875
2020-02-08T02:16:06.763991: step 1566, loss 0.126415, acc 0.9375
2020-02-08T02:16:06.888017: step 1567, loss 0.105379, acc 0.984375
2020-02-08T02:16:07.014689: step 1568, loss 0.145385, acc 0.921875
2020-02-08T02:16:07.139405: step 1569, loss 0.11117, acc 0.9375
2020-02-08T02:16:07.266895: step 1570, loss 0.106983, acc 0.96875
2020-02-08T02:16:07.390130: step 1571, loss 0.123247, acc 0.953125
2020-02-08T02:16:07.517945: step 1572, loss 0.110736, acc 0.96875
2020-02-08T02:16:07.639982: step 1573, loss 0.0752572, acc 0.984375
2020-02-08T02:16:07.772912: step 1574, loss 0.0990811, acc 0.96875
2020-02-08T02:16:07.898705: step 1575, loss 0.0959634, acc 0.96875
2020-02-08T02:16:08.021606: step 1576, loss 0.161336, acc 0.9375
2020-02-08T02:16:08.146402: step 1577, loss 0.106904, acc 0.96875
2020-02-08T02:16:08.273294: step 1578, loss 0.220773, acc 0.9375
2020-02-08T02:16:08.397627: step 1579, loss 0.142303, acc 0.9375
2020-02-08T02:16:08.523885: step 1580, loss 0.242803, acc 0.90625
2020-02-08T02:16:08.649296: step 1581, loss 0.103984, acc 0.984375
2020-02-08T02:16:08.776206: step 1582, loss 0.17647, acc 0.921875
2020-02-08T02:16:08.902541: step 1583, loss 0.115066, acc 0.96875
2020-02-08T02:16:09.028979: step 1584, loss 0.0957255, acc 0.96875
2020-02-08T02:16:09.156846: step 1585, loss 0.186977, acc 0.90625
2020-02-08T02:16:09.289342: step 1586, loss 0.12973, acc 0.953125
2020-02-08T02:16:09.413150: step 1587, loss 0.101068, acc 0.953125
2020-02-08T02:16:09.535915: step 1588, loss 0.198089, acc 0.9375
2020-02-08T02:16:09.663779: step 1589, loss 0.159672, acc 0.9375
2020-02-08T02:16:09.791131: step 1590, loss 0.0678795, acc 0.984375
2020-02-08T02:16:09.915756: step 1591, loss 0.240101, acc 0.953125
2020-02-08T02:16:10.038723: step 1592, loss 0.137116, acc 0.9375
2020-02-08T02:16:10.166129: step 1593, loss 0.127468, acc 0.984375
2020-02-08T02:16:10.289253: step 1594, loss 0.106678, acc 0.96875
2020-02-08T02:16:10.418180: step 1595, loss 0.185, acc 0.953125
2020-02-08T02:16:10.539834: step 1596, loss 0.0985695, acc 0.953125
2020-02-08T02:16:10.667353: step 1597, loss 0.171328, acc 0.890625
2020-02-08T02:16:10.790729: step 1598, loss 0.157702, acc 0.9375
2020-02-08T02:16:10.916811: step 1599, loss 0.135536, acc 0.921875
2020-02-08T02:16:11.042849: step 1600, loss 0.146056, acc 0.953125

Evaluation:
2020-02-08T02:16:11.253921: step 1600, loss 0.655214, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1600

2020-02-08T02:16:12.788792: step 1601, loss 0.19719, acc 0.953125
2020-02-08T02:16:12.917994: step 1602, loss 0.146025, acc 0.96875
2020-02-08T02:16:13.041975: step 1603, loss 0.0975709, acc 0.953125
2020-02-08T02:16:13.172842: step 1604, loss 0.220497, acc 0.90625
2020-02-08T02:16:13.296233: step 1605, loss 0.0824309, acc 0.984375
2020-02-08T02:16:13.424702: step 1606, loss 0.218105, acc 0.953125
2020-02-08T02:16:13.547365: step 1607, loss 0.20089, acc 0.9375
2020-02-08T02:16:13.677154: step 1608, loss 0.0747474, acc 0.984375
2020-02-08T02:16:13.808172: step 1609, loss 0.0628098, acc 0.984375
2020-02-08T02:16:13.934109: step 1610, loss 0.152858, acc 0.9375
2020-02-08T02:16:14.059235: step 1611, loss 0.132996, acc 0.9375
2020-02-08T02:16:14.186120: step 1612, loss 0.189001, acc 0.90625
2020-02-08T02:16:14.310512: step 1613, loss 0.178945, acc 0.890625
2020-02-08T02:16:14.436616: step 1614, loss 0.148797, acc 0.9375
2020-02-08T02:16:14.564143: step 1615, loss 0.151595, acc 0.9375
2020-02-08T02:16:14.692964: step 1616, loss 0.199397, acc 0.90625
2020-02-08T02:16:14.819367: step 1617, loss 0.113673, acc 0.96875
2020-02-08T02:16:14.943281: step 1618, loss 0.107216, acc 0.984375
2020-02-08T02:16:15.068811: step 1619, loss 0.180869, acc 0.953125
2020-02-08T02:16:15.192575: step 1620, loss 0.159115, acc 0.921875
2020-02-08T02:16:15.323560: step 1621, loss 0.197098, acc 0.921875
2020-02-08T02:16:15.445753: step 1622, loss 0.242667, acc 0.90625
2020-02-08T02:16:15.572503: step 1623, loss 0.124359, acc 0.9375
2020-02-08T02:16:15.703957: step 1624, loss 0.159722, acc 0.9375
2020-02-08T02:16:15.829892: step 1625, loss 0.0732488, acc 0.984375
2020-02-08T02:16:15.956451: step 1626, loss 0.0634469, acc 0.96875
2020-02-08T02:16:16.080689: step 1627, loss 0.160544, acc 0.9375
2020-02-08T02:16:16.208442: step 1628, loss 0.154418, acc 0.921875
2020-02-08T02:16:16.334573: step 1629, loss 0.190805, acc 0.921875
2020-02-08T02:16:16.461052: step 1630, loss 0.0889293, acc 0.984375
2020-02-08T02:16:16.585876: step 1631, loss 0.154798, acc 0.9375
2020-02-08T02:16:16.716325: step 1632, loss 0.242835, acc 0.9375
2020-02-08T02:16:16.843474: step 1633, loss 0.190581, acc 0.90625
2020-02-08T02:16:16.971423: step 1634, loss 0.193404, acc 0.890625
2020-02-08T02:16:17.094929: step 1635, loss 0.095759, acc 0.953125
2020-02-08T02:16:17.220228: step 1636, loss 0.131943, acc 0.9375
2020-02-08T02:16:17.341460: step 1637, loss 0.215944, acc 0.90625
2020-02-08T02:16:17.466525: step 1638, loss 0.15808, acc 0.90625
2020-02-08T02:16:17.590473: step 1639, loss 0.1842, acc 0.953125
2020-02-08T02:16:17.720395: step 1640, loss 0.132513, acc 0.96875
2020-02-08T02:16:17.843446: step 1641, loss 0.0966813, acc 1
2020-02-08T02:16:17.968217: step 1642, loss 0.129367, acc 0.953125
2020-02-08T02:16:18.093785: step 1643, loss 0.202883, acc 0.90625
2020-02-08T02:16:18.222708: step 1644, loss 0.122421, acc 0.953125
2020-02-08T02:16:18.350640: step 1645, loss 0.183445, acc 0.90625
2020-02-08T02:16:18.476209: step 1646, loss 0.157747, acc 0.921875
2020-02-08T02:16:18.602939: step 1647, loss 0.163287, acc 0.921875
2020-02-08T02:16:18.733038: step 1648, loss 0.138023, acc 0.921875
2020-02-08T02:16:18.860445: step 1649, loss 0.186585, acc 0.9375
2020-02-08T02:16:18.980464: step 1650, loss 0.16789, acc 0.933333
2020-02-08T02:16:19.109907: step 1651, loss 0.064526, acc 0.984375
2020-02-08T02:16:19.241130: step 1652, loss 0.0936054, acc 0.96875
2020-02-08T02:16:19.363313: step 1653, loss 0.0594798, acc 0.984375
2020-02-08T02:16:19.487381: step 1654, loss 0.153654, acc 0.953125
2020-02-08T02:16:19.614603: step 1655, loss 0.182719, acc 0.9375
2020-02-08T02:16:19.743432: step 1656, loss 0.159914, acc 0.921875
2020-02-08T02:16:19.872047: step 1657, loss 0.1045, acc 0.96875
2020-02-08T02:16:19.995327: step 1658, loss 0.162948, acc 0.953125
2020-02-08T02:16:20.121430: step 1659, loss 0.0855789, acc 0.984375
2020-02-08T02:16:20.250039: step 1660, loss 0.123763, acc 0.96875
2020-02-08T02:16:20.377733: step 1661, loss 0.0477479, acc 0.984375
2020-02-08T02:16:20.501532: step 1662, loss 0.124853, acc 0.96875
2020-02-08T02:16:20.627125: step 1663, loss 0.101326, acc 0.96875
2020-02-08T02:16:20.758548: step 1664, loss 0.102968, acc 0.953125
2020-02-08T02:16:20.887782: step 1665, loss 0.0989277, acc 0.953125
2020-02-08T02:16:21.014350: step 1666, loss 0.125993, acc 0.96875
2020-02-08T02:16:21.143081: step 1667, loss 0.120027, acc 0.953125
2020-02-08T02:16:21.268042: step 1668, loss 0.13697, acc 0.953125
2020-02-08T02:16:21.394069: step 1669, loss 0.102121, acc 0.953125
2020-02-08T02:16:21.600320: step 1670, loss 0.0666238, acc 0.984375
2020-02-08T02:16:21.739202: step 1671, loss 0.114097, acc 0.9375
2020-02-08T02:16:21.870043: step 1672, loss 0.109515, acc 0.96875
2020-02-08T02:16:22.005285: step 1673, loss 0.207486, acc 0.953125
2020-02-08T02:16:22.129164: step 1674, loss 0.127512, acc 0.96875
2020-02-08T02:16:22.255086: step 1675, loss 0.179008, acc 0.953125
2020-02-08T02:16:22.380420: step 1676, loss 0.150753, acc 0.953125
2020-02-08T02:16:22.509410: step 1677, loss 0.0798595, acc 0.984375
2020-02-08T02:16:22.636077: step 1678, loss 0.0892664, acc 0.984375
2020-02-08T02:16:22.769558: step 1679, loss 0.10944, acc 0.96875
2020-02-08T02:16:22.892338: step 1680, loss 0.149843, acc 0.9375
2020-02-08T02:16:23.016457: step 1681, loss 0.187681, acc 0.90625
2020-02-08T02:16:23.145301: step 1682, loss 0.160171, acc 0.9375
2020-02-08T02:16:23.272611: step 1683, loss 0.105221, acc 0.96875
2020-02-08T02:16:23.404606: step 1684, loss 0.148133, acc 0.9375
2020-02-08T02:16:23.531695: step 1685, loss 0.157838, acc 0.9375
2020-02-08T02:16:23.660834: step 1686, loss 0.135872, acc 0.9375
2020-02-08T02:16:23.786384: step 1687, loss 0.116115, acc 0.953125
2020-02-08T02:16:23.913516: step 1688, loss 0.129444, acc 0.96875
2020-02-08T02:16:24.038977: step 1689, loss 0.0458067, acc 1
2020-02-08T02:16:24.166804: step 1690, loss 0.0779085, acc 0.96875
2020-02-08T02:16:24.291994: step 1691, loss 0.0889101, acc 0.984375
2020-02-08T02:16:24.415370: step 1692, loss 0.059732, acc 1
2020-02-08T02:16:24.539398: step 1693, loss 0.112316, acc 0.96875
2020-02-08T02:16:24.668470: step 1694, loss 0.159053, acc 0.96875
2020-02-08T02:16:24.793630: step 1695, loss 0.0779797, acc 0.96875
2020-02-08T02:16:24.921267: step 1696, loss 0.11905, acc 0.9375
2020-02-08T02:16:25.045147: step 1697, loss 0.0678565, acc 1
2020-02-08T02:16:25.171886: step 1698, loss 0.114629, acc 0.96875
2020-02-08T02:16:25.296878: step 1699, loss 0.0503724, acc 1
2020-02-08T02:16:25.424784: step 1700, loss 0.118108, acc 0.953125

Evaluation:
2020-02-08T02:16:25.629689: step 1700, loss 0.708676, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1700

2020-02-08T02:16:27.387179: step 1701, loss 0.0528424, acc 0.984375
2020-02-08T02:16:27.515478: step 1702, loss 0.130786, acc 0.953125
2020-02-08T02:16:27.641538: step 1703, loss 0.101307, acc 0.96875
2020-02-08T02:16:27.774381: step 1704, loss 0.087606, acc 0.96875
2020-02-08T02:16:27.896175: step 1705, loss 0.137848, acc 0.9375
2020-02-08T02:16:28.020340: step 1706, loss 0.0525948, acc 0.984375
2020-02-08T02:16:28.147030: step 1707, loss 0.0778828, acc 0.96875
2020-02-08T02:16:28.271662: step 1708, loss 0.0922564, acc 0.96875
2020-02-08T02:16:28.397673: step 1709, loss 0.103908, acc 0.9375
2020-02-08T02:16:28.523680: step 1710, loss 0.0655355, acc 0.984375
2020-02-08T02:16:28.651765: step 1711, loss 0.133877, acc 0.9375
2020-02-08T02:16:28.778922: step 1712, loss 0.0871322, acc 0.96875
2020-02-08T02:16:28.904211: step 1713, loss 0.102755, acc 0.9375
2020-02-08T02:16:29.031562: step 1714, loss 0.16956, acc 0.921875
2020-02-08T02:16:29.161197: step 1715, loss 0.140757, acc 0.953125
2020-02-08T02:16:29.288380: step 1716, loss 0.0999732, acc 0.96875
2020-02-08T02:16:29.413715: step 1717, loss 0.165748, acc 0.9375
2020-02-08T02:16:29.538607: step 1718, loss 0.105075, acc 0.9375
2020-02-08T02:16:29.666219: step 1719, loss 0.0773111, acc 1
2020-02-08T02:16:29.793814: step 1720, loss 0.0698465, acc 0.984375
2020-02-08T02:16:29.917446: step 1721, loss 0.132025, acc 0.921875
2020-02-08T02:16:30.043504: step 1722, loss 0.156256, acc 0.9375
2020-02-08T02:16:30.171259: step 1723, loss 0.0511458, acc 0.96875
2020-02-08T02:16:30.296767: step 1724, loss 0.222074, acc 0.90625
2020-02-08T02:16:30.424267: step 1725, loss 0.12604, acc 0.953125
2020-02-08T02:16:30.550626: step 1726, loss 0.181258, acc 0.953125
2020-02-08T02:16:30.682338: step 1727, loss 0.0877382, acc 0.96875
2020-02-08T02:16:30.811760: step 1728, loss 0.19306, acc 0.921875
2020-02-08T02:16:30.938224: step 1729, loss 0.155031, acc 0.9375
2020-02-08T02:16:31.066776: step 1730, loss 0.176054, acc 0.9375
2020-02-08T02:16:31.190740: step 1731, loss 0.114759, acc 0.984375
2020-02-08T02:16:31.316891: step 1732, loss 0.18899, acc 0.90625
2020-02-08T02:16:31.442928: step 1733, loss 0.114956, acc 0.96875
2020-02-08T02:16:31.569958: step 1734, loss 0.0812719, acc 0.984375
2020-02-08T02:16:31.696945: step 1735, loss 0.192088, acc 0.90625
2020-02-08T02:16:31.821496: step 1736, loss 0.0461859, acc 1
2020-02-08T02:16:31.946892: step 1737, loss 0.209369, acc 0.90625
2020-02-08T02:16:32.072390: step 1738, loss 0.150379, acc 0.921875
2020-02-08T02:16:32.195479: step 1739, loss 0.114598, acc 0.9375
2020-02-08T02:16:32.322027: step 1740, loss 0.211897, acc 0.921875
2020-02-08T02:16:32.445349: step 1741, loss 0.0774957, acc 0.984375
2020-02-08T02:16:32.570224: step 1742, loss 0.157145, acc 0.9375
2020-02-08T02:16:32.698671: step 1743, loss 0.0871186, acc 0.96875
2020-02-08T02:16:32.825204: step 1744, loss 0.102055, acc 0.96875
2020-02-08T02:16:32.949507: step 1745, loss 0.0604137, acc 0.984375
2020-02-08T02:16:33.074220: step 1746, loss 0.129696, acc 0.9375
2020-02-08T02:16:33.197651: step 1747, loss 0.0652389, acc 0.984375
2020-02-08T02:16:33.322205: step 1748, loss 0.128397, acc 0.96875
2020-02-08T02:16:33.445479: step 1749, loss 0.120826, acc 0.9375
2020-02-08T02:16:33.569294: step 1750, loss 0.0746594, acc 0.96875
2020-02-08T02:16:33.695336: step 1751, loss 0.123793, acc 0.96875
2020-02-08T02:16:33.824254: step 1752, loss 0.152762, acc 0.921875
2020-02-08T02:16:33.952691: step 1753, loss 0.0639442, acc 0.984375
2020-02-08T02:16:34.079612: step 1754, loss 0.0867674, acc 0.96875
2020-02-08T02:16:34.204727: step 1755, loss 0.0763781, acc 0.953125
2020-02-08T02:16:34.331244: step 1756, loss 0.113572, acc 0.96875
2020-02-08T02:16:34.456537: step 1757, loss 0.119234, acc 0.9375
2020-02-08T02:16:34.583495: step 1758, loss 0.0808903, acc 0.96875
2020-02-08T02:16:34.714631: step 1759, loss 0.0999276, acc 0.96875
2020-02-08T02:16:34.837356: step 1760, loss 0.118953, acc 0.953125
2020-02-08T02:16:34.962601: step 1761, loss 0.121938, acc 0.9375
2020-02-08T02:16:35.085742: step 1762, loss 0.0821691, acc 0.96875
2020-02-08T02:16:35.211936: step 1763, loss 0.147765, acc 0.9375
2020-02-08T02:16:35.333359: step 1764, loss 0.132964, acc 0.953125
2020-02-08T02:16:35.455791: step 1765, loss 0.0425932, acc 1
2020-02-08T02:16:35.582371: step 1766, loss 0.186311, acc 0.9375
2020-02-08T02:16:35.716761: step 1767, loss 0.0769932, acc 0.984375
2020-02-08T02:16:35.839821: step 1768, loss 0.156861, acc 0.9375
2020-02-08T02:16:35.966266: step 1769, loss 0.113515, acc 0.984375
2020-02-08T02:16:36.091065: step 1770, loss 0.078191, acc 0.984375
2020-02-08T02:16:36.218544: step 1771, loss 0.125231, acc 0.9375
2020-02-08T02:16:36.340505: step 1772, loss 0.109304, acc 0.96875
2020-02-08T02:16:36.471251: step 1773, loss 0.138329, acc 0.921875
2020-02-08T02:16:36.597963: step 1774, loss 0.240259, acc 0.890625
2020-02-08T02:16:36.730639: step 1775, loss 0.0959994, acc 0.953125
2020-02-08T02:16:36.860664: step 1776, loss 0.105304, acc 0.953125
2020-02-08T02:16:36.986375: step 1777, loss 0.0941276, acc 0.953125
2020-02-08T02:16:37.108910: step 1778, loss 0.092543, acc 0.96875
2020-02-08T02:16:37.235613: step 1779, loss 0.167835, acc 0.953125
2020-02-08T02:16:37.361324: step 1780, loss 0.11612, acc 0.984375
2020-02-08T02:16:37.485205: step 1781, loss 0.170402, acc 0.921875
2020-02-08T02:16:37.613552: step 1782, loss 0.0730739, acc 0.96875
2020-02-08T02:16:37.745843: step 1783, loss 0.122656, acc 0.953125
2020-02-08T02:16:37.868793: step 1784, loss 0.0337944, acc 1
2020-02-08T02:16:37.995720: step 1785, loss 0.085764, acc 0.984375
2020-02-08T02:16:38.121725: step 1786, loss 0.109553, acc 0.9375
2020-02-08T02:16:38.246559: step 1787, loss 0.0976444, acc 0.96875
2020-02-08T02:16:38.370472: step 1788, loss 0.0646518, acc 0.984375
2020-02-08T02:16:38.496409: step 1789, loss 0.110989, acc 0.921875
2020-02-08T02:16:38.621292: step 1790, loss 0.0502854, acc 1
2020-02-08T02:16:38.751777: step 1791, loss 0.0668289, acc 0.96875
2020-02-08T02:16:38.876126: step 1792, loss 0.187277, acc 0.90625
2020-02-08T02:16:39.001927: step 1793, loss 0.12712, acc 0.953125
2020-02-08T02:16:39.132591: step 1794, loss 0.0884962, acc 0.984375
2020-02-08T02:16:39.265923: step 1795, loss 0.121791, acc 0.96875
2020-02-08T02:16:39.389106: step 1796, loss 0.0851283, acc 0.96875
2020-02-08T02:16:39.515263: step 1797, loss 0.0898321, acc 0.984375
2020-02-08T02:16:39.639042: step 1798, loss 0.132734, acc 0.984375
2020-02-08T02:16:39.781498: step 1799, loss 0.0579216, acc 0.96875
2020-02-08T02:16:39.905652: step 1800, loss 0.184324, acc 0.933333

Evaluation:
2020-02-08T02:16:40.117206: step 1800, loss 0.728014, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1800

2020-02-08T02:16:41.983188: step 1801, loss 0.0817597, acc 0.96875
2020-02-08T02:16:42.107162: step 1802, loss 0.0813909, acc 0.96875
2020-02-08T02:16:42.231019: step 1803, loss 0.10708, acc 0.953125
2020-02-08T02:16:42.359286: step 1804, loss 0.0685254, acc 0.984375
2020-02-08T02:16:42.482221: step 1805, loss 0.0878368, acc 0.96875
2020-02-08T02:16:42.609553: step 1806, loss 0.0816795, acc 0.96875
2020-02-08T02:16:42.739481: step 1807, loss 0.0571038, acc 0.984375
2020-02-08T02:16:42.866473: step 1808, loss 0.076597, acc 0.96875
2020-02-08T02:16:42.988071: step 1809, loss 0.153322, acc 0.9375
2020-02-08T02:16:43.113348: step 1810, loss 0.102529, acc 0.953125
2020-02-08T02:16:43.236792: step 1811, loss 0.147837, acc 0.953125
2020-02-08T02:16:43.362464: step 1812, loss 0.194107, acc 0.90625
2020-02-08T02:16:43.485975: step 1813, loss 0.0738427, acc 0.96875
2020-02-08T02:16:43.611722: step 1814, loss 0.0661585, acc 0.984375
2020-02-08T02:16:43.741929: step 1815, loss 0.128047, acc 0.96875
2020-02-08T02:16:43.866320: step 1816, loss 0.0501313, acc 0.984375
2020-02-08T02:16:43.988533: step 1817, loss 0.0927819, acc 0.953125
2020-02-08T02:16:44.115202: step 1818, loss 0.115611, acc 0.9375
2020-02-08T02:16:44.240162: step 1819, loss 0.0421152, acc 1
2020-02-08T02:16:44.364271: step 1820, loss 0.0987928, acc 0.96875
2020-02-08T02:16:44.486563: step 1821, loss 0.0799844, acc 0.96875
2020-02-08T02:16:44.613372: step 1822, loss 0.0504993, acc 0.984375
2020-02-08T02:16:44.740135: step 1823, loss 0.115368, acc 0.953125
2020-02-08T02:16:44.867454: step 1824, loss 0.0348311, acc 1
2020-02-08T02:16:44.991856: step 1825, loss 0.138384, acc 0.96875
2020-02-08T02:16:45.116954: step 1826, loss 0.0496601, acc 0.96875
2020-02-08T02:16:45.242218: step 1827, loss 0.0236946, acc 1
2020-02-08T02:16:45.368712: step 1828, loss 0.0943566, acc 0.96875
2020-02-08T02:16:45.489194: step 1829, loss 0.109985, acc 0.96875
2020-02-08T02:16:45.616855: step 1830, loss 0.0472426, acc 1
2020-02-08T02:16:45.744645: step 1831, loss 0.154049, acc 0.9375
2020-02-08T02:16:45.871926: step 1832, loss 0.122414, acc 0.9375
2020-02-08T02:16:45.997805: step 1833, loss 0.104818, acc 0.953125
2020-02-08T02:16:46.123580: step 1834, loss 0.139698, acc 0.953125
2020-02-08T02:16:46.250076: step 1835, loss 0.102808, acc 0.9375
2020-02-08T02:16:46.378549: step 1836, loss 0.176436, acc 0.9375
2020-02-08T02:16:46.505382: step 1837, loss 0.0919138, acc 0.96875
2020-02-08T02:16:46.630842: step 1838, loss 0.145486, acc 0.9375
2020-02-08T02:16:46.764854: step 1839, loss 0.0992524, acc 0.984375
2020-02-08T02:16:46.888989: step 1840, loss 0.114581, acc 0.984375
2020-02-08T02:16:47.014098: step 1841, loss 0.0793753, acc 0.984375
2020-02-08T02:16:47.139434: step 1842, loss 0.0980231, acc 0.96875
2020-02-08T02:16:47.264275: step 1843, loss 0.227883, acc 0.875
2020-02-08T02:16:47.389950: step 1844, loss 0.15766, acc 0.953125
2020-02-08T02:16:47.515713: step 1845, loss 0.133097, acc 0.9375
2020-02-08T02:16:47.640916: step 1846, loss 0.0934537, acc 0.96875
2020-02-08T02:16:47.774167: step 1847, loss 0.0197335, acc 1
2020-02-08T02:16:47.897385: step 1848, loss 0.103885, acc 0.96875
2020-02-08T02:16:48.024797: step 1849, loss 0.21133, acc 0.953125
2020-02-08T02:16:48.152184: step 1850, loss 0.0748659, acc 0.984375
2020-02-08T02:16:48.279898: step 1851, loss 0.097503, acc 0.984375
2020-02-08T02:16:48.410587: step 1852, loss 0.072241, acc 0.96875
2020-02-08T02:16:48.537314: step 1853, loss 0.102075, acc 0.96875
2020-02-08T02:16:48.665902: step 1854, loss 0.0740248, acc 0.984375
2020-02-08T02:16:48.792385: step 1855, loss 0.099368, acc 0.953125
2020-02-08T02:16:48.920767: step 1856, loss 0.18449, acc 0.953125
2020-02-08T02:16:49.048805: step 1857, loss 0.173927, acc 0.921875
2020-02-08T02:16:49.185085: step 1858, loss 0.0801197, acc 0.953125
2020-02-08T02:16:49.315971: step 1859, loss 0.0696669, acc 0.984375
2020-02-08T02:16:49.439478: step 1860, loss 0.0516729, acc 1
2020-02-08T02:16:49.565306: step 1861, loss 0.0677295, acc 0.984375
2020-02-08T02:16:49.693414: step 1862, loss 0.0735302, acc 0.96875
2020-02-08T02:16:49.819349: step 1863, loss 0.0549887, acc 0.984375
2020-02-08T02:16:49.944568: step 1864, loss 0.0651794, acc 0.984375
2020-02-08T02:16:50.070807: step 1865, loss 0.136423, acc 0.921875
2020-02-08T02:16:50.194952: step 1866, loss 0.119431, acc 0.9375
2020-02-08T02:16:50.321592: step 1867, loss 0.0592006, acc 0.984375
2020-02-08T02:16:50.446143: step 1868, loss 0.0623402, acc 0.984375
2020-02-08T02:16:50.576150: step 1869, loss 0.0442143, acc 1
2020-02-08T02:16:50.709126: step 1870, loss 0.0504025, acc 0.984375
2020-02-08T02:16:50.837561: step 1871, loss 0.0741307, acc 0.96875
2020-02-08T02:16:50.962405: step 1872, loss 0.110329, acc 0.921875
2020-02-08T02:16:51.089037: step 1873, loss 0.0758228, acc 0.984375
2020-02-08T02:16:51.214825: step 1874, loss 0.0856892, acc 0.96875
2020-02-08T02:16:51.825348: step 1875, loss 0.0856196, acc 0.96875
2020-02-08T02:16:51.955918: step 1876, loss 0.219328, acc 0.9375
2020-02-08T02:16:52.088589: step 1877, loss 0.021265, acc 1
2020-02-08T02:16:52.212286: step 1878, loss 0.0772938, acc 0.953125
2020-02-08T02:16:52.338178: step 1879, loss 0.0676673, acc 0.96875
2020-02-08T02:16:52.463028: step 1880, loss 0.0622763, acc 0.984375
2020-02-08T02:16:52.586112: step 1881, loss 0.0568325, acc 0.984375
2020-02-08T02:16:52.721290: step 1882, loss 0.123751, acc 0.9375
2020-02-08T02:16:52.847485: step 1883, loss 0.036273, acc 1
2020-02-08T02:16:52.972487: step 1884, loss 0.0859514, acc 0.96875
2020-02-08T02:16:53.098018: step 1885, loss 0.169701, acc 0.9375
2020-02-08T02:16:53.226587: step 1886, loss 0.0571999, acc 0.984375
2020-02-08T02:16:53.352651: step 1887, loss 0.150099, acc 0.9375
2020-02-08T02:16:53.480241: step 1888, loss 0.0713934, acc 0.984375
2020-02-08T02:16:53.605942: step 1889, loss 0.0614944, acc 0.984375
2020-02-08T02:16:53.738623: step 1890, loss 0.0479625, acc 0.984375
2020-02-08T02:16:53.863184: step 1891, loss 0.0651094, acc 1
2020-02-08T02:16:53.987253: step 1892, loss 0.0983066, acc 0.96875
2020-02-08T02:16:54.113440: step 1893, loss 0.221119, acc 0.9375
2020-02-08T02:16:54.237498: step 1894, loss 0.0954864, acc 0.96875
2020-02-08T02:16:54.361456: step 1895, loss 0.0518684, acc 0.984375
2020-02-08T02:16:54.486346: step 1896, loss 0.0609928, acc 1
2020-02-08T02:16:54.611237: step 1897, loss 0.0528784, acc 1
2020-02-08T02:16:54.740557: step 1898, loss 0.110495, acc 0.953125
2020-02-08T02:16:54.866176: step 1899, loss 0.0634298, acc 0.984375
2020-02-08T02:16:54.988965: step 1900, loss 0.0271142, acc 1

Evaluation:
2020-02-08T02:16:55.194368: step 1900, loss 0.715896, acc 0.741088

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-1900

2020-02-08T02:16:57.680191: step 1901, loss 0.0286136, acc 0.984375
2020-02-08T02:16:57.804016: step 1902, loss 0.0897196, acc 0.96875
2020-02-08T02:16:57.928017: step 1903, loss 0.0745942, acc 0.96875
2020-02-08T02:16:58.051570: step 1904, loss 0.134503, acc 0.953125
2020-02-08T02:16:58.176269: step 1905, loss 0.15251, acc 0.921875
2020-02-08T02:16:58.302033: step 1906, loss 0.0734681, acc 0.984375
2020-02-08T02:16:58.428438: step 1907, loss 0.115151, acc 0.953125
2020-02-08T02:16:58.553603: step 1908, loss 0.0823376, acc 0.96875
2020-02-08T02:16:58.680723: step 1909, loss 0.0807779, acc 0.96875
2020-02-08T02:16:58.809559: step 1910, loss 0.0389843, acc 1
2020-02-08T02:16:58.934659: step 1911, loss 0.0672766, acc 0.96875
2020-02-08T02:16:59.062465: step 1912, loss 0.0313193, acc 1
2020-02-08T02:16:59.189101: step 1913, loss 0.128781, acc 0.953125
2020-02-08T02:16:59.317159: step 1914, loss 0.0567425, acc 0.984375
2020-02-08T02:16:59.439300: step 1915, loss 0.0747454, acc 0.984375
2020-02-08T02:16:59.564710: step 1916, loss 0.0533668, acc 0.984375
2020-02-08T02:16:59.691432: step 1917, loss 0.0506048, acc 0.984375
2020-02-08T02:16:59.814821: step 1918, loss 0.0737618, acc 0.96875
2020-02-08T02:16:59.940506: step 1919, loss 0.0613609, acc 0.984375
2020-02-08T02:17:00.070966: step 1920, loss 0.0717024, acc 1
2020-02-08T02:17:00.197319: step 1921, loss 0.144754, acc 0.921875
2020-02-08T02:17:00.324290: step 1922, loss 0.0360186, acc 0.984375
2020-02-08T02:17:00.449781: step 1923, loss 0.0457494, acc 1
2020-02-08T02:17:00.577924: step 1924, loss 0.0537802, acc 1
2020-02-08T02:17:00.712603: step 1925, loss 0.09853, acc 0.96875
2020-02-08T02:17:00.837140: step 1926, loss 0.185945, acc 0.921875
2020-02-08T02:17:00.962542: step 1927, loss 0.166379, acc 0.9375
2020-02-08T02:17:01.085578: step 1928, loss 0.0979041, acc 0.953125
2020-02-08T02:17:01.212279: step 1929, loss 0.0916024, acc 0.96875
2020-02-08T02:17:01.338218: step 1930, loss 0.153204, acc 0.953125
2020-02-08T02:17:01.467520: step 1931, loss 0.0820194, acc 0.984375
2020-02-08T02:17:01.591046: step 1932, loss 0.134899, acc 0.9375
2020-02-08T02:17:01.726579: step 1933, loss 0.141071, acc 0.953125
2020-02-08T02:17:01.850852: step 1934, loss 0.0725064, acc 0.984375
2020-02-08T02:17:01.978688: step 1935, loss 0.0501529, acc 1
2020-02-08T02:17:02.101444: step 1936, loss 0.126718, acc 0.953125
2020-02-08T02:17:02.227115: step 1937, loss 0.100388, acc 0.953125
2020-02-08T02:17:02.351388: step 1938, loss 0.0590961, acc 0.984375
2020-02-08T02:17:02.479514: step 1939, loss 0.0737261, acc 0.984375
2020-02-08T02:17:02.606226: step 1940, loss 0.131173, acc 0.96875
2020-02-08T02:17:02.736016: step 1941, loss 0.129934, acc 0.953125
2020-02-08T02:17:02.869797: step 1942, loss 0.159028, acc 0.953125
2020-02-08T02:17:02.993972: step 1943, loss 0.0632023, acc 0.96875
2020-02-08T02:17:03.120262: step 1944, loss 0.0877373, acc 0.953125
2020-02-08T02:17:03.246250: step 1945, loss 0.0590697, acc 1
2020-02-08T02:17:03.370179: step 1946, loss 0.076377, acc 0.984375
2020-02-08T02:17:03.493475: step 1947, loss 0.0886314, acc 0.953125
2020-02-08T02:17:03.620484: step 1948, loss 0.100283, acc 0.953125
2020-02-08T02:17:03.748463: step 1949, loss 0.160624, acc 0.921875
2020-02-08T02:17:03.869843: step 1950, loss 0.101877, acc 0.95
2020-02-08T02:17:03.998509: step 1951, loss 0.0583424, acc 0.984375
2020-02-08T02:17:04.160427: step 1952, loss 0.0295573, acc 1
2020-02-08T02:17:04.285499: step 1953, loss 0.0558949, acc 0.984375
2020-02-08T02:17:04.456363: step 1954, loss 0.0524626, acc 0.984375
2020-02-08T02:17:04.614793: step 1955, loss 0.108101, acc 0.96875
2020-02-08T02:17:04.749366: step 1956, loss 0.0874771, acc 0.96875
2020-02-08T02:17:04.877003: step 1957, loss 0.0611819, acc 0.96875
2020-02-08T02:17:05.011126: step 1958, loss 0.0202288, acc 1
2020-02-08T02:17:05.139971: step 1959, loss 0.164955, acc 0.890625
2020-02-08T02:17:05.269732: step 1960, loss 0.0887258, acc 0.96875
2020-02-08T02:17:05.404248: step 1961, loss 0.0385795, acc 0.984375
2020-02-08T02:17:05.551012: step 1962, loss 0.0845436, acc 0.96875
2020-02-08T02:17:05.698620: step 1963, loss 0.0814394, acc 0.984375
2020-02-08T02:17:05.839630: step 1964, loss 0.0335843, acc 1
2020-02-08T02:17:05.992863: step 1965, loss 0.10032, acc 0.9375
2020-02-08T02:17:06.137200: step 1966, loss 0.0318968, acc 1
2020-02-08T02:17:06.262406: step 1967, loss 0.0276332, acc 1
2020-02-08T02:17:06.385970: step 1968, loss 0.0519906, acc 0.96875
2020-02-08T02:17:06.511996: step 1969, loss 0.0485019, acc 0.984375
2020-02-08T02:17:06.639456: step 1970, loss 0.0849543, acc 0.96875
2020-02-08T02:17:06.771738: step 1971, loss 0.0431635, acc 0.984375
2020-02-08T02:17:06.895404: step 1972, loss 0.0327204, acc 0.984375
2020-02-08T02:17:07.020837: step 1973, loss 0.0600226, acc 0.984375
2020-02-08T02:17:07.145794: step 1974, loss 0.0334194, acc 1
2020-02-08T02:17:07.272149: step 1975, loss 0.251501, acc 0.921875
2020-02-08T02:17:07.397531: step 1976, loss 0.0879654, acc 0.96875
2020-02-08T02:17:07.525404: step 1977, loss 0.0366639, acc 1
2020-02-08T02:17:07.651641: step 1978, loss 0.0731485, acc 0.984375
2020-02-08T02:17:07.778662: step 1979, loss 0.117915, acc 0.9375
2020-02-08T02:17:07.903297: step 1980, loss 0.072357, acc 0.96875
2020-02-08T02:17:08.027695: step 1981, loss 0.0666502, acc 0.953125
2020-02-08T02:17:08.156950: step 1982, loss 0.0394978, acc 0.984375
2020-02-08T02:17:08.283805: step 1983, loss 0.0330343, acc 1
2020-02-08T02:17:08.406544: step 1984, loss 0.0430368, acc 0.984375
2020-02-08T02:17:08.531099: step 1985, loss 0.0727556, acc 0.953125
2020-02-08T02:17:08.656743: step 1986, loss 0.13847, acc 0.96875
2020-02-08T02:17:08.784905: step 1987, loss 0.0526566, acc 0.984375
2020-02-08T02:17:08.910742: step 1988, loss 0.0522884, acc 0.984375
2020-02-08T02:17:09.035562: step 1989, loss 0.059917, acc 0.96875
2020-02-08T02:17:09.167626: step 1990, loss 0.0952764, acc 0.96875
2020-02-08T02:17:09.297974: step 1991, loss 0.0695627, acc 0.984375
2020-02-08T02:17:09.423351: step 1992, loss 0.0443518, acc 0.96875
2020-02-08T02:17:09.550785: step 1993, loss 0.058213, acc 0.96875
2020-02-08T02:17:09.680765: step 1994, loss 0.0934101, acc 0.96875
2020-02-08T02:17:09.803496: step 1995, loss 0.0828871, acc 0.984375
2020-02-08T02:17:09.934000: step 1996, loss 0.03747, acc 1
2020-02-08T02:17:10.057514: step 1997, loss 0.0760795, acc 0.96875
2020-02-08T02:17:10.185819: step 1998, loss 0.109042, acc 0.9375
2020-02-08T02:17:10.314251: step 1999, loss 0.0596267, acc 0.984375
2020-02-08T02:17:10.438448: step 2000, loss 0.0703114, acc 0.984375

Evaluation:
2020-02-08T02:17:10.652390: step 2000, loss 0.783868, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2000

2020-02-08T02:17:12.858883: step 2001, loss 0.0909568, acc 0.953125
2020-02-08T02:17:12.982794: step 2002, loss 0.190232, acc 0.90625
2020-02-08T02:17:13.109280: step 2003, loss 0.0834415, acc 0.96875
2020-02-08T02:17:13.237106: step 2004, loss 0.0206442, acc 1
2020-02-08T02:17:13.360825: step 2005, loss 0.0699346, acc 0.984375
2020-02-08T02:17:13.485646: step 2006, loss 0.042393, acc 1
2020-02-08T02:17:13.611605: step 2007, loss 0.078077, acc 0.984375
2020-02-08T02:17:13.743533: step 2008, loss 0.0869171, acc 0.96875
2020-02-08T02:17:13.873310: step 2009, loss 0.0960966, acc 0.953125
2020-02-08T02:17:13.998449: step 2010, loss 0.104181, acc 0.953125
2020-02-08T02:17:14.121807: step 2011, loss 0.0276183, acc 1
2020-02-08T02:17:14.245296: step 2012, loss 0.116132, acc 0.96875
2020-02-08T02:17:14.367800: step 2013, loss 0.0277842, acc 1
2020-02-08T02:17:14.488969: step 2014, loss 0.0999936, acc 0.96875
2020-02-08T02:17:14.613337: step 2015, loss 0.111266, acc 0.96875
2020-02-08T02:17:14.746862: step 2016, loss 0.0950896, acc 0.96875
2020-02-08T02:17:14.869807: step 2017, loss 0.0316273, acc 1
2020-02-08T02:17:14.997884: step 2018, loss 0.0538187, acc 0.984375
2020-02-08T02:17:15.124333: step 2019, loss 0.0706286, acc 0.953125
2020-02-08T02:17:15.250623: step 2020, loss 0.104338, acc 0.96875
2020-02-08T02:17:15.376918: step 2021, loss 0.0950084, acc 0.953125
2020-02-08T02:17:15.502722: step 2022, loss 0.103601, acc 0.953125
2020-02-08T02:17:15.629150: step 2023, loss 0.0514858, acc 0.984375
2020-02-08T02:17:15.760307: step 2024, loss 0.0838387, acc 0.96875
2020-02-08T02:17:15.885573: step 2025, loss 0.0623561, acc 0.96875
2020-02-08T02:17:16.009931: step 2026, loss 0.0488727, acc 0.984375
2020-02-08T02:17:16.134640: step 2027, loss 0.0433973, acc 0.96875
2020-02-08T02:17:16.264201: step 2028, loss 0.0873179, acc 0.953125
2020-02-08T02:17:16.387949: step 2029, loss 0.131077, acc 0.953125
2020-02-08T02:17:16.512626: step 2030, loss 0.0300961, acc 1
2020-02-08T02:17:16.637930: step 2031, loss 0.0842793, acc 0.96875
2020-02-08T02:17:16.770470: step 2032, loss 0.104087, acc 0.953125
2020-02-08T02:17:16.898286: step 2033, loss 0.0652578, acc 0.984375
2020-02-08T02:17:17.023922: step 2034, loss 0.152941, acc 0.9375
2020-02-08T02:17:17.147880: step 2035, loss 0.141158, acc 0.953125
2020-02-08T02:17:17.272273: step 2036, loss 0.0618105, acc 0.984375
2020-02-08T02:17:17.397231: step 2037, loss 0.15501, acc 0.9375
2020-02-08T02:17:17.521142: step 2038, loss 0.136695, acc 0.9375
2020-02-08T02:17:17.645114: step 2039, loss 0.0295531, acc 1
2020-02-08T02:17:17.776349: step 2040, loss 0.0409001, acc 1
2020-02-08T02:17:17.902402: step 2041, loss 0.052744, acc 0.984375
2020-02-08T02:17:18.028725: step 2042, loss 0.200723, acc 0.921875
2020-02-08T02:17:18.152186: step 2043, loss 0.0195112, acc 1
2020-02-08T02:17:18.275523: step 2044, loss 0.0574557, acc 0.984375
2020-02-08T02:17:18.400370: step 2045, loss 0.0543685, acc 0.984375
2020-02-08T02:17:18.523927: step 2046, loss 0.0811666, acc 0.953125
2020-02-08T02:17:18.654640: step 2047, loss 0.0297789, acc 1
2020-02-08T02:17:18.782341: step 2048, loss 0.0215105, acc 1
2020-02-08T02:17:18.910129: step 2049, loss 0.0395299, acc 1
2020-02-08T02:17:19.036782: step 2050, loss 0.0865236, acc 0.96875
2020-02-08T02:17:19.170302: step 2051, loss 0.0937561, acc 0.96875
2020-02-08T02:17:19.300105: step 2052, loss 0.109344, acc 0.96875
2020-02-08T02:17:19.426786: step 2053, loss 0.119181, acc 0.921875
2020-02-08T02:17:19.550646: step 2054, loss 0.0249622, acc 1
2020-02-08T02:17:19.676788: step 2055, loss 0.0512324, acc 0.984375
2020-02-08T02:17:19.801442: step 2056, loss 0.0557153, acc 0.96875
2020-02-08T02:17:19.927407: step 2057, loss 0.0458745, acc 1
2020-02-08T02:17:20.052960: step 2058, loss 0.0919058, acc 0.953125
2020-02-08T02:17:20.181556: step 2059, loss 0.10995, acc 0.9375
2020-02-08T02:17:20.311342: step 2060, loss 0.127396, acc 0.96875
2020-02-08T02:17:20.436789: step 2061, loss 0.050135, acc 0.96875
2020-02-08T02:17:20.563143: step 2062, loss 0.0346489, acc 1
2020-02-08T02:17:20.688118: step 2063, loss 0.075386, acc 0.96875
2020-02-08T02:17:20.820488: step 2064, loss 0.0845417, acc 0.96875
2020-02-08T02:17:20.942434: step 2065, loss 0.109976, acc 0.96875
2020-02-08T02:17:21.069986: step 2066, loss 0.150879, acc 0.953125
2020-02-08T02:17:21.376257: step 2067, loss 0.0427419, acc 1
2020-02-08T02:17:21.514333: step 2068, loss 0.0273483, acc 1
2020-02-08T02:17:21.639019: step 2069, loss 0.16582, acc 0.921875
2020-02-08T02:17:21.769070: step 2070, loss 0.0958088, acc 0.96875
2020-02-08T02:17:21.896158: step 2071, loss 0.0289426, acc 1
2020-02-08T02:17:22.023702: step 2072, loss 0.0658771, acc 0.984375
2020-02-08T02:17:22.149224: step 2073, loss 0.115987, acc 0.953125
2020-02-08T02:17:22.275216: step 2074, loss 0.104558, acc 0.953125
2020-02-08T02:17:22.397543: step 2075, loss 0.0480686, acc 0.984375
2020-02-08T02:17:22.527170: step 2076, loss 0.034545, acc 1
2020-02-08T02:17:22.654280: step 2077, loss 0.0479172, acc 0.96875
2020-02-08T02:17:22.784284: step 2078, loss 0.111795, acc 0.96875
2020-02-08T02:17:22.908268: step 2079, loss 0.0757565, acc 0.984375
2020-02-08T02:17:23.031974: step 2080, loss 0.0913957, acc 0.984375
2020-02-08T02:17:23.156616: step 2081, loss 0.0583706, acc 1
2020-02-08T02:17:23.280535: step 2082, loss 0.046662, acc 0.984375
2020-02-08T02:17:23.406690: step 2083, loss 0.0751981, acc 0.96875
2020-02-08T02:17:23.530478: step 2084, loss 0.0735308, acc 0.984375
2020-02-08T02:17:23.659616: step 2085, loss 0.066086, acc 0.984375
2020-02-08T02:17:23.785586: step 2086, loss 0.0946872, acc 0.953125
2020-02-08T02:17:23.911701: step 2087, loss 0.0686882, acc 0.96875
2020-02-08T02:17:24.036320: step 2088, loss 0.0417635, acc 1
2020-02-08T02:17:24.161302: step 2089, loss 0.0169772, acc 1
2020-02-08T02:17:24.287481: step 2090, loss 0.0396639, acc 1
2020-02-08T02:17:24.413198: step 2091, loss 0.106085, acc 0.953125
2020-02-08T02:17:24.538702: step 2092, loss 0.0470284, acc 1
2020-02-08T02:17:24.668488: step 2093, loss 0.0699919, acc 0.96875
2020-02-08T02:17:24.792412: step 2094, loss 0.166041, acc 0.9375
2020-02-08T02:17:24.919496: step 2095, loss 0.042393, acc 1
2020-02-08T02:17:25.043501: step 2096, loss 0.0489617, acc 1
2020-02-08T02:17:25.169551: step 2097, loss 0.0466395, acc 0.984375
2020-02-08T02:17:25.294810: step 2098, loss 0.132191, acc 0.9375
2020-02-08T02:17:25.422069: step 2099, loss 0.06433, acc 0.96875
2020-02-08T02:17:25.540719: step 2100, loss 0.106391, acc 0.966667

Evaluation:
2020-02-08T02:17:25.752647: step 2100, loss 0.800915, acc 0.742964

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2100

2020-02-08T02:17:27.358220: step 2101, loss 0.0273854, acc 1
2020-02-08T02:17:27.482552: step 2102, loss 0.0387495, acc 0.984375
2020-02-08T02:17:27.607903: step 2103, loss 0.0378475, acc 1
2020-02-08T02:17:27.740091: step 2104, loss 0.0524147, acc 0.96875
2020-02-08T02:17:27.868355: step 2105, loss 0.0161618, acc 1
2020-02-08T02:17:27.991550: step 2106, loss 0.0488226, acc 0.96875
2020-02-08T02:17:28.117435: step 2107, loss 0.0297977, acc 1
2020-02-08T02:17:28.241397: step 2108, loss 0.132339, acc 0.953125
2020-02-08T02:17:28.372125: step 2109, loss 0.0186074, acc 1
2020-02-08T02:17:28.499354: step 2110, loss 0.0998355, acc 0.96875
2020-02-08T02:17:28.625706: step 2111, loss 0.0739253, acc 0.96875
2020-02-08T02:17:28.758698: step 2112, loss 0.0596986, acc 0.984375
2020-02-08T02:17:28.883335: step 2113, loss 0.0802482, acc 0.96875
2020-02-08T02:17:29.007728: step 2114, loss 0.0174403, acc 1
2020-02-08T02:17:29.135907: step 2115, loss 0.0530331, acc 0.984375
2020-02-08T02:17:29.264002: step 2116, loss 0.0275132, acc 1
2020-02-08T02:17:29.387965: step 2117, loss 0.0904248, acc 0.953125
2020-02-08T02:17:29.513445: step 2118, loss 0.0411479, acc 0.984375
2020-02-08T02:17:29.637376: step 2119, loss 0.0483648, acc 0.984375
2020-02-08T02:17:29.768476: step 2120, loss 0.0371778, acc 1
2020-02-08T02:17:29.890586: step 2121, loss 0.068605, acc 0.984375
2020-02-08T02:17:30.014196: step 2122, loss 0.0367968, acc 1
2020-02-08T02:17:30.137755: step 2123, loss 0.0405835, acc 0.984375
2020-02-08T02:17:30.262253: step 2124, loss 0.025745, acc 1
2020-02-08T02:17:30.387268: step 2125, loss 0.0330263, acc 0.984375
2020-02-08T02:17:30.514070: step 2126, loss 0.0728891, acc 0.96875
2020-02-08T02:17:30.638199: step 2127, loss 0.0702709, acc 0.96875
2020-02-08T02:17:30.767345: step 2128, loss 0.0181514, acc 1
2020-02-08T02:17:30.894387: step 2129, loss 0.0331317, acc 0.984375
2020-02-08T02:17:31.020732: step 2130, loss 0.033565, acc 1
2020-02-08T02:17:31.144782: step 2131, loss 0.042251, acc 0.984375
2020-02-08T02:17:31.268187: step 2132, loss 0.142761, acc 0.953125
2020-02-08T02:17:31.392588: step 2133, loss 0.0859487, acc 0.953125
2020-02-08T02:17:31.521256: step 2134, loss 0.0643763, acc 0.96875
2020-02-08T02:17:31.645171: step 2135, loss 0.0771739, acc 0.96875
2020-02-08T02:17:31.774732: step 2136, loss 0.0688454, acc 0.984375
2020-02-08T02:17:31.900979: step 2137, loss 0.0351547, acc 1
2020-02-08T02:17:32.025625: step 2138, loss 0.0920921, acc 0.953125
2020-02-08T02:17:32.149221: step 2139, loss 0.0832098, acc 0.96875
2020-02-08T02:17:32.273766: step 2140, loss 0.0335842, acc 1
2020-02-08T02:17:32.398524: step 2141, loss 0.0248653, acc 1
2020-02-08T02:17:32.526130: step 2142, loss 0.0265906, acc 1
2020-02-08T02:17:32.651537: step 2143, loss 0.0346619, acc 1
2020-02-08T02:17:32.777755: step 2144, loss 0.0459681, acc 1
2020-02-08T02:17:32.902158: step 2145, loss 0.0487138, acc 0.96875
2020-02-08T02:17:33.026483: step 2146, loss 0.05374, acc 0.984375
2020-02-08T02:17:33.152115: step 2147, loss 0.019657, acc 1
2020-02-08T02:17:33.276608: step 2148, loss 0.031719, acc 0.984375
2020-02-08T02:17:33.403385: step 2149, loss 0.0444335, acc 0.96875
2020-02-08T02:17:33.528968: step 2150, loss 0.0452366, acc 0.96875
2020-02-08T02:17:33.656863: step 2151, loss 0.17246, acc 0.921875
2020-02-08T02:17:33.783723: step 2152, loss 0.0406962, acc 0.984375
2020-02-08T02:17:33.909980: step 2153, loss 0.0509414, acc 0.984375
2020-02-08T02:17:34.036364: step 2154, loss 0.0528714, acc 0.984375
2020-02-08T02:17:34.161407: step 2155, loss 0.0546557, acc 0.984375
2020-02-08T02:17:34.286573: step 2156, loss 0.0919877, acc 0.984375
2020-02-08T02:17:34.410685: step 2157, loss 0.0304481, acc 0.984375
2020-02-08T02:17:34.534969: step 2158, loss 0.0347825, acc 1
2020-02-08T02:17:34.663038: step 2159, loss 0.0697084, acc 0.96875
2020-02-08T02:17:34.788447: step 2160, loss 0.0454646, acc 0.984375
2020-02-08T02:17:34.914652: step 2161, loss 0.0106697, acc 1
2020-02-08T02:17:35.042052: step 2162, loss 0.0634194, acc 0.96875
2020-02-08T02:17:35.167582: step 2163, loss 0.112004, acc 0.953125
2020-02-08T02:17:35.294907: step 2164, loss 0.0336314, acc 0.984375
2020-02-08T02:17:35.422402: step 2165, loss 0.0414296, acc 0.984375
2020-02-08T02:17:35.548433: step 2166, loss 0.0363894, acc 1
2020-02-08T02:17:35.677574: step 2167, loss 0.0275679, acc 1
2020-02-08T02:17:35.801229: step 2168, loss 0.08006, acc 0.96875
2020-02-08T02:17:35.926434: step 2169, loss 0.0258133, acc 1
2020-02-08T02:17:36.051852: step 2170, loss 0.032851, acc 0.984375
2020-02-08T02:17:36.178190: step 2171, loss 0.0435213, acc 0.984375
2020-02-08T02:17:36.300869: step 2172, loss 0.0300611, acc 1
2020-02-08T02:17:36.426056: step 2173, loss 0.0403366, acc 0.984375
2020-02-08T02:17:36.555603: step 2174, loss 0.0508312, acc 0.96875
2020-02-08T02:17:36.691358: step 2175, loss 0.0325791, acc 0.984375
2020-02-08T02:17:36.831271: step 2176, loss 0.0373964, acc 0.984375
2020-02-08T02:17:36.955213: step 2177, loss 0.216883, acc 0.90625
2020-02-08T02:17:37.078402: step 2178, loss 0.0183951, acc 1
2020-02-08T02:17:37.204209: step 2179, loss 0.0231185, acc 1
2020-02-08T02:17:37.330367: step 2180, loss 0.038737, acc 1
2020-02-08T02:17:37.461706: step 2181, loss 0.139602, acc 0.953125
2020-02-08T02:17:37.585876: step 2182, loss 0.0358498, acc 0.984375
2020-02-08T02:17:37.717081: step 2183, loss 0.125193, acc 0.96875
2020-02-08T02:17:37.842743: step 2184, loss 0.0782889, acc 0.984375
2020-02-08T02:17:37.966999: step 2185, loss 0.11916, acc 0.953125
2020-02-08T02:17:38.093146: step 2186, loss 0.069025, acc 0.96875
2020-02-08T02:17:38.215735: step 2187, loss 0.0416158, acc 0.984375
2020-02-08T02:17:38.339723: step 2188, loss 0.0450737, acc 0.96875
2020-02-08T02:17:38.466552: step 2189, loss 0.0188333, acc 1
2020-02-08T02:17:38.591274: step 2190, loss 0.0163738, acc 1
2020-02-08T02:17:38.724231: step 2191, loss 0.0317926, acc 0.96875
2020-02-08T02:17:38.849991: step 2192, loss 0.116084, acc 0.9375
2020-02-08T02:17:38.971865: step 2193, loss 0.0230849, acc 1
2020-02-08T02:17:39.102341: step 2194, loss 0.0715398, acc 0.984375
2020-02-08T02:17:39.230649: step 2195, loss 0.0439239, acc 0.984375
2020-02-08T02:17:39.356397: step 2196, loss 0.036889, acc 1
2020-02-08T02:17:39.482643: step 2197, loss 0.0680254, acc 0.984375
2020-02-08T02:17:39.610312: step 2198, loss 0.0359092, acc 1
2020-02-08T02:17:39.738543: step 2199, loss 0.0321226, acc 1
2020-02-08T02:17:39.866991: step 2200, loss 0.0667577, acc 0.96875

Evaluation:
2020-02-08T02:17:40.073576: step 2200, loss 0.835924, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2200

2020-02-08T02:17:41.983106: step 2201, loss 0.0572627, acc 0.984375
2020-02-08T02:17:42.110525: step 2202, loss 0.0593213, acc 0.984375
2020-02-08T02:17:42.240206: step 2203, loss 0.0295908, acc 1
2020-02-08T02:17:42.368468: step 2204, loss 0.0328502, acc 0.984375
2020-02-08T02:17:42.496835: step 2205, loss 0.0232149, acc 1
2020-02-08T02:17:42.625284: step 2206, loss 0.0784618, acc 0.984375
2020-02-08T02:17:42.756159: step 2207, loss 0.149473, acc 0.953125
2020-02-08T02:17:42.883723: step 2208, loss 0.0456606, acc 0.984375
2020-02-08T02:17:43.007292: step 2209, loss 0.0317691, acc 0.984375
2020-02-08T02:17:43.131924: step 2210, loss 0.0791095, acc 0.96875
2020-02-08T02:17:43.259048: step 2211, loss 0.0427875, acc 0.984375
2020-02-08T02:17:43.384963: step 2212, loss 0.0372677, acc 0.984375
2020-02-08T02:17:43.512922: step 2213, loss 0.0522941, acc 0.984375
2020-02-08T02:17:43.639614: step 2214, loss 0.0992562, acc 0.96875
2020-02-08T02:17:43.774549: step 2215, loss 0.0223128, acc 1
2020-02-08T02:17:43.902560: step 2216, loss 0.0464521, acc 0.984375
2020-02-08T02:17:44.027772: step 2217, loss 0.0366478, acc 0.984375
2020-02-08T02:17:44.152590: step 2218, loss 0.0623217, acc 0.953125
2020-02-08T02:17:44.277284: step 2219, loss 0.0386161, acc 0.984375
2020-02-08T02:17:44.405285: step 2220, loss 0.0396649, acc 1
2020-02-08T02:17:44.530965: step 2221, loss 0.0722623, acc 0.96875
2020-02-08T02:17:44.658483: step 2222, loss 0.0576807, acc 0.984375
2020-02-08T02:17:44.785875: step 2223, loss 0.0235208, acc 1
2020-02-08T02:17:44.912882: step 2224, loss 0.102788, acc 0.96875
2020-02-08T02:17:45.039354: step 2225, loss 0.0633563, acc 0.984375
2020-02-08T02:17:45.166473: step 2226, loss 0.0613167, acc 0.984375
2020-02-08T02:17:45.291205: step 2227, loss 0.0982892, acc 0.96875
2020-02-08T02:17:45.415917: step 2228, loss 0.0849625, acc 0.96875
2020-02-08T02:17:45.541059: step 2229, loss 0.036839, acc 1
2020-02-08T02:17:45.667872: step 2230, loss 0.0565548, acc 0.984375
2020-02-08T02:17:45.793613: step 2231, loss 0.0377095, acc 0.984375
2020-02-08T02:17:45.920000: step 2232, loss 0.0367206, acc 0.984375
2020-02-08T02:17:46.048976: step 2233, loss 0.0461245, acc 0.984375
2020-02-08T02:17:46.174221: step 2234, loss 0.0441599, acc 0.984375
2020-02-08T02:17:46.297860: step 2235, loss 0.0640697, acc 0.984375
2020-02-08T02:17:46.423984: step 2236, loss 0.02715, acc 1
2020-02-08T02:17:46.549345: step 2237, loss 0.0415246, acc 0.984375
2020-02-08T02:17:46.679433: step 2238, loss 0.0335133, acc 1
2020-02-08T02:17:46.809453: step 2239, loss 0.0640201, acc 0.96875
2020-02-08T02:17:46.936922: step 2240, loss 0.050366, acc 1
2020-02-08T02:17:47.063467: step 2241, loss 0.0686909, acc 0.96875
2020-02-08T02:17:47.186832: step 2242, loss 0.0766464, acc 0.953125
2020-02-08T02:17:47.309422: step 2243, loss 0.035947, acc 1
2020-02-08T02:17:47.436652: step 2244, loss 0.0664417, acc 0.984375
2020-02-08T02:17:47.567335: step 2245, loss 0.120038, acc 0.953125
2020-02-08T02:17:47.695583: step 2246, loss 0.0206425, acc 1
2020-02-08T02:17:47.822673: step 2247, loss 0.0603016, acc 0.953125
2020-02-08T02:17:47.950624: step 2248, loss 0.144118, acc 0.921875
2020-02-08T02:17:48.077364: step 2249, loss 0.0589965, acc 0.96875
2020-02-08T02:17:48.197150: step 2250, loss 0.0611488, acc 0.983333
2020-02-08T02:17:48.324502: step 2251, loss 0.0284775, acc 1
2020-02-08T02:17:48.450980: step 2252, loss 0.038725, acc 0.984375
2020-02-08T02:17:48.579076: step 2253, loss 0.0510979, acc 0.984375
2020-02-08T02:17:48.714061: step 2254, loss 0.0152795, acc 1
2020-02-08T02:17:48.838564: step 2255, loss 0.0553716, acc 0.984375
2020-02-08T02:17:48.965556: step 2256, loss 0.00414683, acc 1
2020-02-08T02:17:49.090048: step 2257, loss 0.0174646, acc 1
2020-02-08T02:17:49.220772: step 2258, loss 0.0116464, acc 1
2020-02-08T02:17:49.346594: step 2259, loss 0.0236613, acc 1
2020-02-08T02:17:49.473183: step 2260, loss 0.0244429, acc 1
2020-02-08T02:17:49.599669: step 2261, loss 0.0957022, acc 0.953125
2020-02-08T02:17:49.730971: step 2262, loss 0.0207181, acc 1
2020-02-08T02:17:49.857420: step 2263, loss 0.0403347, acc 1
2020-02-08T02:17:49.981836: step 2264, loss 0.019204, acc 1
2020-02-08T02:17:50.109113: step 2265, loss 0.0942734, acc 0.984375
2020-02-08T02:17:50.236630: step 2266, loss 0.130437, acc 0.96875
2020-02-08T02:17:50.363077: step 2267, loss 0.0308452, acc 0.984375
2020-02-08T02:17:50.487606: step 2268, loss 0.148374, acc 0.953125
2020-02-08T02:17:50.613835: step 2269, loss 0.0319679, acc 0.984375
2020-02-08T02:17:50.744179: step 2270, loss 0.0226977, acc 1
2020-02-08T02:17:50.873178: step 2271, loss 0.0277394, acc 1
2020-02-08T02:17:50.999457: step 2272, loss 0.0189196, acc 1
2020-02-08T02:17:51.127355: step 2273, loss 0.0614256, acc 0.96875
2020-02-08T02:17:51.673435: step 2274, loss 0.0438786, acc 1
2020-02-08T02:17:51.799573: step 2275, loss 0.0471654, acc 0.984375
2020-02-08T02:17:51.925738: step 2276, loss 0.033127, acc 0.984375
2020-02-08T02:17:52.053555: step 2277, loss 0.0327994, acc 0.984375
2020-02-08T02:17:52.182236: step 2278, loss 0.0304685, acc 1
2020-02-08T02:17:52.310891: step 2279, loss 0.0332389, acc 0.984375
2020-02-08T02:17:52.437258: step 2280, loss 0.0498132, acc 0.984375
2020-02-08T02:17:52.566883: step 2281, loss 0.148859, acc 0.953125
2020-02-08T02:17:52.691298: step 2282, loss 0.0319215, acc 0.984375
2020-02-08T02:17:52.816315: step 2283, loss 0.0562711, acc 0.96875
2020-02-08T02:17:52.939908: step 2284, loss 0.0122668, acc 1
2020-02-08T02:17:53.067243: step 2285, loss 0.0745503, acc 0.953125
2020-02-08T02:17:53.190983: step 2286, loss 0.0182329, acc 1
2020-02-08T02:17:53.319872: step 2287, loss 0.0360538, acc 0.984375
2020-02-08T02:17:53.441751: step 2288, loss 0.0435058, acc 1
2020-02-08T02:17:53.567829: step 2289, loss 0.0540619, acc 0.96875
2020-02-08T02:17:53.695766: step 2290, loss 0.0297274, acc 1
2020-02-08T02:17:53.823446: step 2291, loss 0.0205016, acc 1
2020-02-08T02:17:53.950071: step 2292, loss 0.0608672, acc 0.96875
2020-02-08T02:17:54.076510: step 2293, loss 0.038429, acc 1
2020-02-08T02:17:54.200027: step 2294, loss 0.0202694, acc 1
2020-02-08T02:17:54.330700: step 2295, loss 0.0842121, acc 0.984375
2020-02-08T02:17:54.456249: step 2296, loss 0.057828, acc 0.984375
2020-02-08T02:17:54.581108: step 2297, loss 0.0407876, acc 0.984375
2020-02-08T02:17:54.713014: step 2298, loss 0.013491, acc 1
2020-02-08T02:17:54.838425: step 2299, loss 0.0878805, acc 0.9375
2020-02-08T02:17:54.966358: step 2300, loss 0.014502, acc 1

Evaluation:
2020-02-08T02:17:55.169996: step 2300, loss 0.864989, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2300

2020-02-08T02:17:56.695726: step 2301, loss 0.0170016, acc 1
2020-02-08T02:17:56.823663: step 2302, loss 0.0168385, acc 1
2020-02-08T02:17:56.948286: step 2303, loss 0.0758756, acc 0.953125
2020-02-08T02:17:57.075051: step 2304, loss 0.0186544, acc 0.984375
2020-02-08T02:17:57.201406: step 2305, loss 0.0205099, acc 1
2020-02-08T02:17:57.327816: step 2306, loss 0.0200618, acc 1
2020-02-08T02:17:57.454048: step 2307, loss 0.0288041, acc 1
2020-02-08T02:17:57.581883: step 2308, loss 0.0831537, acc 0.984375
2020-02-08T02:17:57.714504: step 2309, loss 0.0492683, acc 0.96875
2020-02-08T02:17:57.839069: step 2310, loss 0.0373284, acc 0.984375
2020-02-08T02:17:57.969802: step 2311, loss 0.0557907, acc 0.96875
2020-02-08T02:17:58.094047: step 2312, loss 0.0582949, acc 0.96875
2020-02-08T02:17:58.219646: step 2313, loss 0.0450244, acc 0.984375
2020-02-08T02:17:58.343879: step 2314, loss 0.0312393, acc 0.984375
2020-02-08T02:17:58.469399: step 2315, loss 0.0385976, acc 0.96875
2020-02-08T02:17:58.593445: step 2316, loss 0.0535009, acc 0.984375
2020-02-08T02:17:58.727353: step 2317, loss 0.0237336, acc 1
2020-02-08T02:17:58.852132: step 2318, loss 0.0638094, acc 0.953125
2020-02-08T02:17:58.977850: step 2319, loss 0.0940948, acc 0.96875
2020-02-08T02:17:59.107661: step 2320, loss 0.0778415, acc 0.984375
2020-02-08T02:17:59.244118: step 2321, loss 0.0396695, acc 0.984375
2020-02-08T02:17:59.370693: step 2322, loss 0.0358982, acc 0.96875
2020-02-08T02:17:59.494311: step 2323, loss 0.0629033, acc 0.984375
2020-02-08T02:17:59.621777: step 2324, loss 0.0418891, acc 0.984375
2020-02-08T02:17:59.752716: step 2325, loss 0.0305062, acc 1
2020-02-08T02:17:59.880577: step 2326, loss 0.0277472, acc 1
2020-02-08T02:18:00.010184: step 2327, loss 0.0642519, acc 0.96875
2020-02-08T02:18:00.137380: step 2328, loss 0.0514975, acc 0.96875
2020-02-08T02:18:00.260086: step 2329, loss 0.0957613, acc 0.984375
2020-02-08T02:18:00.387615: step 2330, loss 0.0628327, acc 0.953125
2020-02-08T02:18:00.513698: step 2331, loss 0.0170036, acc 1
2020-02-08T02:18:00.638860: step 2332, loss 0.0405141, acc 0.984375
2020-02-08T02:18:00.772861: step 2333, loss 0.0528218, acc 0.984375
2020-02-08T02:18:00.897721: step 2334, loss 0.0259394, acc 1
2020-02-08T02:18:01.024296: step 2335, loss 0.0301467, acc 0.984375
2020-02-08T02:18:01.148368: step 2336, loss 0.0566706, acc 0.984375
2020-02-08T02:18:01.275319: step 2337, loss 0.098771, acc 0.953125
2020-02-08T02:18:01.397901: step 2338, loss 0.030288, acc 1
2020-02-08T02:18:01.524227: step 2339, loss 0.0388418, acc 0.984375
2020-02-08T02:18:01.653116: step 2340, loss 0.016738, acc 1
2020-02-08T02:18:01.780848: step 2341, loss 0.0103746, acc 1
2020-02-08T02:18:01.906714: step 2342, loss 0.0331575, acc 0.984375
2020-02-08T02:18:02.032694: step 2343, loss 0.0223441, acc 1
2020-02-08T02:18:02.161949: step 2344, loss 0.0439508, acc 0.984375
2020-02-08T02:18:02.287547: step 2345, loss 0.0741269, acc 0.96875
2020-02-08T02:18:02.416463: step 2346, loss 0.114321, acc 0.96875
2020-02-08T02:18:02.541418: step 2347, loss 0.0174976, acc 1
2020-02-08T02:18:02.667776: step 2348, loss 0.0530287, acc 0.984375
2020-02-08T02:18:02.790805: step 2349, loss 0.0242713, acc 0.984375
2020-02-08T02:18:02.915590: step 2350, loss 0.0358925, acc 0.984375
2020-02-08T02:18:03.038734: step 2351, loss 0.0675572, acc 0.984375
2020-02-08T02:18:03.165573: step 2352, loss 0.0949064, acc 0.984375
2020-02-08T02:18:03.290903: step 2353, loss 0.0268783, acc 1
2020-02-08T02:18:03.415099: step 2354, loss 0.00911209, acc 1
2020-02-08T02:18:03.540441: step 2355, loss 0.0236459, acc 0.984375
2020-02-08T02:18:03.669084: step 2356, loss 0.0554609, acc 0.984375
2020-02-08T02:18:03.792762: step 2357, loss 0.0718667, acc 0.96875
2020-02-08T02:18:03.918313: step 2358, loss 0.0325602, acc 1
2020-02-08T02:18:04.042366: step 2359, loss 0.0201361, acc 1
2020-02-08T02:18:04.172447: step 2360, loss 0.0305628, acc 0.984375
2020-02-08T02:18:04.295453: step 2361, loss 0.0400232, acc 0.984375
2020-02-08T02:18:04.423333: step 2362, loss 0.0200039, acc 1
2020-02-08T02:18:04.545196: step 2363, loss 0.0335678, acc 1
2020-02-08T02:18:04.673672: step 2364, loss 0.0898142, acc 0.96875
2020-02-08T02:18:04.796447: step 2365, loss 0.0896426, acc 0.953125
2020-02-08T02:18:04.921848: step 2366, loss 0.0219143, acc 1
2020-02-08T02:18:05.049005: step 2367, loss 0.0621567, acc 0.96875
2020-02-08T02:18:05.174846: step 2368, loss 0.0278571, acc 0.984375
2020-02-08T02:18:05.300143: step 2369, loss 0.108409, acc 0.96875
2020-02-08T02:18:05.428122: step 2370, loss 0.0248302, acc 0.984375
2020-02-08T02:18:05.553195: step 2371, loss 0.0837619, acc 0.96875
2020-02-08T02:18:05.680362: step 2372, loss 0.0825322, acc 0.953125
2020-02-08T02:18:05.804858: step 2373, loss 0.0197326, acc 1
2020-02-08T02:18:05.929656: step 2374, loss 0.0421741, acc 0.984375
2020-02-08T02:18:06.053261: step 2375, loss 0.0518648, acc 0.96875
2020-02-08T02:18:06.179381: step 2376, loss 0.0792871, acc 0.96875
2020-02-08T02:18:06.306198: step 2377, loss 0.0474417, acc 0.984375
2020-02-08T02:18:06.430322: step 2378, loss 0.0120792, acc 1
2020-02-08T02:18:06.557967: step 2379, loss 0.0332199, acc 1
2020-02-08T02:18:06.684965: step 2380, loss 0.0444298, acc 0.984375
2020-02-08T02:18:06.810701: step 2381, loss 0.0592807, acc 0.953125
2020-02-08T02:18:06.936641: step 2382, loss 0.0230944, acc 1
2020-02-08T02:18:07.062777: step 2383, loss 0.0845727, acc 0.96875
2020-02-08T02:18:07.183752: step 2384, loss 0.0315106, acc 1
2020-02-08T02:18:07.312155: step 2385, loss 0.074413, acc 0.96875
2020-02-08T02:18:07.435496: step 2386, loss 0.0115844, acc 1
2020-02-08T02:18:07.560574: step 2387, loss 0.035952, acc 0.984375
2020-02-08T02:18:07.686345: step 2388, loss 0.0391811, acc 0.984375
2020-02-08T02:18:07.815866: step 2389, loss 0.187374, acc 0.890625
2020-02-08T02:18:07.937665: step 2390, loss 0.0487318, acc 0.96875
2020-02-08T02:18:08.064588: step 2391, loss 0.049461, acc 0.984375
2020-02-08T02:18:08.188417: step 2392, loss 0.0350199, acc 0.984375
2020-02-08T02:18:08.313771: step 2393, loss 0.0665792, acc 0.984375
2020-02-08T02:18:08.435872: step 2394, loss 0.0694228, acc 0.953125
2020-02-08T02:18:08.561811: step 2395, loss 0.07679, acc 0.96875
2020-02-08T02:18:08.684172: step 2396, loss 0.0660498, acc 0.96875
2020-02-08T02:18:08.814280: step 2397, loss 0.0689202, acc 0.96875
2020-02-08T02:18:08.938222: step 2398, loss 0.0183807, acc 1
2020-02-08T02:18:09.067604: step 2399, loss 0.0398744, acc 0.984375
2020-02-08T02:18:09.195111: step 2400, loss 0.0522353, acc 0.983333

Evaluation:
2020-02-08T02:18:09.409384: step 2400, loss 0.881019, acc 0.744841

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2400

2020-02-08T02:18:11.253200: step 2401, loss 0.0146393, acc 1
2020-02-08T02:18:11.379920: step 2402, loss 0.0166212, acc 1
2020-02-08T02:18:11.502463: step 2403, loss 0.0235438, acc 1
2020-02-08T02:18:11.628657: step 2404, loss 0.0499514, acc 0.984375
2020-02-08T02:18:11.757754: step 2405, loss 0.0473185, acc 0.984375
2020-02-08T02:18:11.886965: step 2406, loss 0.0505165, acc 0.96875
2020-02-08T02:18:12.012517: step 2407, loss 0.0228282, acc 0.984375
2020-02-08T02:18:12.134860: step 2408, loss 0.0147998, acc 1
2020-02-08T02:18:12.262348: step 2409, loss 0.0108419, acc 1
2020-02-08T02:18:12.385547: step 2410, loss 0.0551848, acc 0.96875
2020-02-08T02:18:12.509709: step 2411, loss 0.0207352, acc 1
2020-02-08T02:18:12.635344: step 2412, loss 0.0357171, acc 1
2020-02-08T02:18:12.767175: step 2413, loss 0.0135475, acc 1
2020-02-08T02:18:12.893112: step 2414, loss 0.019755, acc 1
2020-02-08T02:18:13.016196: step 2415, loss 0.0717909, acc 0.984375
2020-02-08T02:18:13.139430: step 2416, loss 0.0598952, acc 0.984375
2020-02-08T02:18:13.265484: step 2417, loss 0.0241356, acc 0.984375
2020-02-08T02:18:13.388307: step 2418, loss 0.0504738, acc 0.984375
2020-02-08T02:18:13.517208: step 2419, loss 0.0158776, acc 1
2020-02-08T02:18:13.640003: step 2420, loss 0.0159051, acc 1
2020-02-08T02:18:13.773688: step 2421, loss 0.132879, acc 0.9375
2020-02-08T02:18:13.899910: step 2422, loss 0.0427676, acc 0.984375
2020-02-08T02:18:14.027737: step 2423, loss 0.0117106, acc 1
2020-02-08T02:18:14.152988: step 2424, loss 0.0379816, acc 0.984375
2020-02-08T02:18:14.280153: step 2425, loss 0.0528641, acc 0.96875
2020-02-08T02:18:14.404689: step 2426, loss 0.0160811, acc 1
2020-02-08T02:18:14.532857: step 2427, loss 0.0420092, acc 0.984375
2020-02-08T02:18:14.662052: step 2428, loss 0.043902, acc 0.984375
2020-02-08T02:18:14.785686: step 2429, loss 0.015724, acc 1
2020-02-08T02:18:14.911762: step 2430, loss 0.0404738, acc 0.984375
2020-02-08T02:18:15.036424: step 2431, loss 0.100218, acc 0.953125
2020-02-08T02:18:15.164062: step 2432, loss 0.0619574, acc 0.984375
2020-02-08T02:18:15.290257: step 2433, loss 0.0164951, acc 1
2020-02-08T02:18:15.421499: step 2434, loss 0.0340539, acc 0.984375
2020-02-08T02:18:15.544369: step 2435, loss 0.0516424, acc 0.984375
2020-02-08T02:18:15.673133: step 2436, loss 0.0184911, acc 1
2020-02-08T02:18:15.800823: step 2437, loss 0.0451307, acc 0.984375
2020-02-08T02:18:15.930008: step 2438, loss 0.082538, acc 0.953125
2020-02-08T02:18:16.053432: step 2439, loss 0.0503201, acc 0.96875
2020-02-08T02:18:16.178848: step 2440, loss 0.0124333, acc 1
2020-02-08T02:18:16.306025: step 2441, loss 0.0148136, acc 1
2020-02-08T02:18:16.432711: step 2442, loss 0.0515424, acc 0.96875
2020-02-08T02:18:16.556902: step 2443, loss 0.0416659, acc 0.984375
2020-02-08T02:18:16.686033: step 2444, loss 0.0245836, acc 0.984375
2020-02-08T02:18:16.814265: step 2445, loss 0.0403185, acc 0.984375
2020-02-08T02:18:16.938981: step 2446, loss 0.0191166, acc 1
2020-02-08T02:18:17.064158: step 2447, loss 0.0215413, acc 1
2020-02-08T02:18:17.185967: step 2448, loss 0.012382, acc 1
2020-02-08T02:18:17.311788: step 2449, loss 0.046047, acc 0.984375
2020-02-08T02:18:17.434472: step 2450, loss 0.0406066, acc 0.984375
2020-02-08T02:18:17.563503: step 2451, loss 0.0778899, acc 0.96875
2020-02-08T02:18:17.693279: step 2452, loss 0.0547932, acc 0.984375
2020-02-08T02:18:17.819680: step 2453, loss 0.0126815, acc 1
2020-02-08T02:18:17.942478: step 2454, loss 0.0671116, acc 0.96875
2020-02-08T02:18:18.069082: step 2455, loss 0.0223493, acc 1
2020-02-08T02:18:18.192086: step 2456, loss 0.0308353, acc 1
2020-02-08T02:18:18.318237: step 2457, loss 0.0175484, acc 1
2020-02-08T02:18:18.445614: step 2458, loss 0.098935, acc 0.96875
2020-02-08T02:18:18.571904: step 2459, loss 0.0817971, acc 0.953125
2020-02-08T02:18:18.700090: step 2460, loss 0.0355167, acc 0.984375
2020-02-08T02:18:18.825577: step 2461, loss 0.0580221, acc 0.984375
2020-02-08T02:18:18.950141: step 2462, loss 0.0742677, acc 0.953125
2020-02-08T02:18:19.076517: step 2463, loss 0.0219197, acc 1
2020-02-08T02:18:19.204904: step 2464, loss 0.108279, acc 0.96875
2020-02-08T02:18:19.331705: step 2465, loss 0.0526748, acc 0.984375
2020-02-08T02:18:19.454557: step 2466, loss 0.100045, acc 0.953125
2020-02-08T02:18:19.582747: step 2467, loss 0.0275601, acc 0.984375
2020-02-08T02:18:19.714496: step 2468, loss 0.0117737, acc 1
2020-02-08T02:18:19.839342: step 2469, loss 0.0209286, acc 0.984375
2020-02-08T02:18:19.966676: step 2470, loss 0.0502947, acc 0.984375
2020-02-08T02:18:20.088656: step 2471, loss 0.0323988, acc 1
2020-02-08T02:18:20.215306: step 2472, loss 0.0232851, acc 1
2020-02-08T02:18:20.336865: step 2473, loss 0.0271506, acc 0.984375
2020-02-08T02:18:20.471318: step 2474, loss 0.0133626, acc 1
2020-02-08T02:18:20.597473: step 2475, loss 0.011743, acc 1
2020-02-08T02:18:20.732215: step 2476, loss 0.0269202, acc 1
2020-02-08T02:18:20.860360: step 2477, loss 0.0278556, acc 1
2020-02-08T02:18:20.985936: step 2478, loss 0.0275745, acc 1
2020-02-08T02:18:21.112708: step 2479, loss 0.0188249, acc 1
2020-02-08T02:18:21.235831: step 2480, loss 0.0212428, acc 1
2020-02-08T02:18:21.360578: step 2481, loss 0.068695, acc 0.984375
2020-02-08T02:18:21.620734: step 2482, loss 0.0663982, acc 0.96875
2020-02-08T02:18:21.762642: step 2483, loss 0.00589602, acc 1
2020-02-08T02:18:21.887242: step 2484, loss 0.102385, acc 0.96875
2020-02-08T02:18:22.013533: step 2485, loss 0.0340099, acc 0.984375
2020-02-08T02:18:22.136285: step 2486, loss 0.0299237, acc 1
2020-02-08T02:18:22.261761: step 2487, loss 0.0215695, acc 1
2020-02-08T02:18:22.386573: step 2488, loss 0.124145, acc 0.953125
2020-02-08T02:18:22.513157: step 2489, loss 0.02753, acc 1
2020-02-08T02:18:22.637627: step 2490, loss 0.0291856, acc 0.984375
2020-02-08T02:18:22.769405: step 2491, loss 0.0106424, acc 1
2020-02-08T02:18:22.893872: step 2492, loss 0.0511258, acc 0.984375
2020-02-08T02:18:23.020617: step 2493, loss 0.0116617, acc 1
2020-02-08T02:18:23.145330: step 2494, loss 0.0141573, acc 1
2020-02-08T02:18:23.271821: step 2495, loss 0.0608984, acc 0.96875
2020-02-08T02:18:23.397256: step 2496, loss 0.039722, acc 0.984375
2020-02-08T02:18:23.524294: step 2497, loss 0.0566029, acc 0.984375
2020-02-08T02:18:23.646458: step 2498, loss 0.0644364, acc 0.96875
2020-02-08T02:18:23.780359: step 2499, loss 0.024722, acc 0.984375
2020-02-08T02:18:23.906668: step 2500, loss 0.0419736, acc 0.984375

Evaluation:
2020-02-08T02:18:24.115492: step 2500, loss 0.922316, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2500

2020-02-08T02:18:26.037936: step 2501, loss 0.0110749, acc 1
2020-02-08T02:18:26.168659: step 2502, loss 0.0354799, acc 0.984375
2020-02-08T02:18:26.293067: step 2503, loss 0.0360738, acc 0.984375
2020-02-08T02:18:26.420604: step 2504, loss 0.0685484, acc 0.96875
2020-02-08T02:18:26.543905: step 2505, loss 0.0190921, acc 1
2020-02-08T02:18:26.671512: step 2506, loss 0.0355885, acc 0.984375
2020-02-08T02:18:26.794274: step 2507, loss 0.0167983, acc 1
2020-02-08T02:18:26.923583: step 2508, loss 0.0587959, acc 0.96875
2020-02-08T02:18:27.049637: step 2509, loss 0.0489565, acc 0.984375
2020-02-08T02:18:27.178945: step 2510, loss 0.0207203, acc 0.984375
2020-02-08T02:18:27.304584: step 2511, loss 0.138198, acc 0.9375
2020-02-08T02:18:27.429552: step 2512, loss 0.0265751, acc 1
2020-02-08T02:18:27.564168: step 2513, loss 0.0473325, acc 0.96875
2020-02-08T02:18:27.692177: step 2514, loss 0.049207, acc 0.984375
2020-02-08T02:18:27.823145: step 2515, loss 0.012556, acc 1
2020-02-08T02:18:27.949604: step 2516, loss 0.0134033, acc 1
2020-02-08T02:18:28.076447: step 2517, loss 0.086099, acc 0.984375
2020-02-08T02:18:28.200972: step 2518, loss 0.0342109, acc 0.984375
2020-02-08T02:18:28.326330: step 2519, loss 0.0649806, acc 0.96875
2020-02-08T02:18:28.448935: step 2520, loss 0.0253955, acc 0.984375
2020-02-08T02:18:28.576754: step 2521, loss 0.0310876, acc 0.984375
2020-02-08T02:18:28.709624: step 2522, loss 0.020862, acc 1
2020-02-08T02:18:28.835678: step 2523, loss 0.0630522, acc 0.984375
2020-02-08T02:18:28.960405: step 2524, loss 0.0249925, acc 1
2020-02-08T02:18:29.085224: step 2525, loss 0.0438484, acc 1
2020-02-08T02:18:29.217169: step 2526, loss 0.0313918, acc 0.984375
2020-02-08T02:18:29.339888: step 2527, loss 0.027838, acc 0.984375
2020-02-08T02:18:29.467291: step 2528, loss 0.0593834, acc 0.984375
2020-02-08T02:18:29.589563: step 2529, loss 0.0440803, acc 0.984375
2020-02-08T02:18:29.725156: step 2530, loss 0.0670524, acc 0.96875
2020-02-08T02:18:29.852031: step 2531, loss 0.0237716, acc 1
2020-02-08T02:18:29.976585: step 2532, loss 0.0242543, acc 1
2020-02-08T02:18:30.104135: step 2533, loss 0.0190004, acc 1
2020-02-08T02:18:30.231306: step 2534, loss 0.0402285, acc 0.984375
2020-02-08T02:18:30.357399: step 2535, loss 0.029687, acc 1
2020-02-08T02:18:30.484869: step 2536, loss 0.0286302, acc 0.984375
2020-02-08T02:18:30.609525: step 2537, loss 0.0117352, acc 1
2020-02-08T02:18:30.739530: step 2538, loss 0.0490229, acc 0.984375
2020-02-08T02:18:30.866566: step 2539, loss 0.0682809, acc 0.953125
2020-02-08T02:18:30.989369: step 2540, loss 0.026689, acc 0.984375
2020-02-08T02:18:31.117610: step 2541, loss 0.0675734, acc 0.984375
2020-02-08T02:18:31.242756: step 2542, loss 0.0232577, acc 1
2020-02-08T02:18:31.372236: step 2543, loss 0.120768, acc 0.96875
2020-02-08T02:18:31.497364: step 2544, loss 0.030273, acc 0.984375
2020-02-08T02:18:31.625223: step 2545, loss 0.0429881, acc 0.96875
2020-02-08T02:18:31.753789: step 2546, loss 0.0561554, acc 0.96875
2020-02-08T02:18:31.880624: step 2547, loss 0.0559268, acc 0.96875
2020-02-08T02:18:32.007278: step 2548, loss 0.0227763, acc 1
2020-02-08T02:18:32.130112: step 2549, loss 0.0223645, acc 1
2020-02-08T02:18:32.249721: step 2550, loss 0.0257888, acc 1
2020-02-08T02:18:32.375528: step 2551, loss 0.032627, acc 0.984375
2020-02-08T02:18:32.499978: step 2552, loss 0.0532714, acc 0.96875
2020-02-08T02:18:32.626259: step 2553, loss 0.0245234, acc 1
2020-02-08T02:18:32.756953: step 2554, loss 0.00250255, acc 1
2020-02-08T02:18:32.882353: step 2555, loss 0.0193058, acc 1
2020-02-08T02:18:33.009645: step 2556, loss 0.0449698, acc 0.96875
2020-02-08T02:18:33.133806: step 2557, loss 0.00809034, acc 1
2020-02-08T02:18:33.258590: step 2558, loss 0.0283832, acc 0.984375
2020-02-08T02:18:33.386610: step 2559, loss 0.020249, acc 1
2020-02-08T02:18:33.513682: step 2560, loss 0.00867723, acc 1
2020-02-08T02:18:33.643020: step 2561, loss 0.0134076, acc 1
2020-02-08T02:18:33.774180: step 2562, loss 0.016791, acc 1
2020-02-08T02:18:33.897582: step 2563, loss 0.0372362, acc 1
2020-02-08T02:18:34.022418: step 2564, loss 0.0262097, acc 0.984375
2020-02-08T02:18:34.148713: step 2565, loss 0.00725955, acc 1
2020-02-08T02:18:34.274443: step 2566, loss 0.0105552, acc 1
2020-02-08T02:18:34.400258: step 2567, loss 0.0122111, acc 1
2020-02-08T02:18:34.524240: step 2568, loss 0.00747516, acc 1
2020-02-08T02:18:34.651433: step 2569, loss 0.012607, acc 1
2020-02-08T02:18:34.778182: step 2570, loss 0.0148672, acc 1
2020-02-08T02:18:34.903517: step 2571, loss 0.00862059, acc 1
2020-02-08T02:18:35.039991: step 2572, loss 0.030859, acc 1
2020-02-08T02:18:35.162818: step 2573, loss 0.0101017, acc 1
2020-02-08T02:18:35.287101: step 2574, loss 0.0129205, acc 1
2020-02-08T02:18:35.411124: step 2575, loss 0.0721899, acc 0.984375
2020-02-08T02:18:35.534457: step 2576, loss 0.00820741, acc 1
2020-02-08T02:18:35.660757: step 2577, loss 0.00608524, acc 1
2020-02-08T02:18:35.789078: step 2578, loss 0.0131466, acc 1
2020-02-08T02:18:35.913034: step 2579, loss 0.0173492, acc 1
2020-02-08T02:18:36.034650: step 2580, loss 0.0166382, acc 1
2020-02-08T02:18:36.158724: step 2581, loss 0.0374055, acc 0.984375
2020-02-08T02:18:36.281821: step 2582, loss 0.0328278, acc 0.984375
2020-02-08T02:18:36.406747: step 2583, loss 0.0380629, acc 0.984375
2020-02-08T02:18:36.533603: step 2584, loss 0.0225742, acc 1
2020-02-08T02:18:36.664581: step 2585, loss 0.00799994, acc 1
2020-02-08T02:18:36.789279: step 2586, loss 0.0564834, acc 0.96875
2020-02-08T02:18:36.914279: step 2587, loss 0.0126999, acc 1
2020-02-08T02:18:37.041666: step 2588, loss 0.0202935, acc 1
2020-02-08T02:18:37.167032: step 2589, loss 0.0198058, acc 0.984375
2020-02-08T02:18:37.292943: step 2590, loss 0.0650847, acc 0.96875
2020-02-08T02:18:37.417817: step 2591, loss 0.0165105, acc 1
2020-02-08T02:18:37.544120: step 2592, loss 0.0155578, acc 1
2020-02-08T02:18:37.674345: step 2593, loss 0.015307, acc 1
2020-02-08T02:18:37.799940: step 2594, loss 0.0239314, acc 1
2020-02-08T02:18:37.930423: step 2595, loss 0.0526293, acc 0.984375
2020-02-08T02:18:38.056740: step 2596, loss 0.0410619, acc 0.984375
2020-02-08T02:18:38.182776: step 2597, loss 0.0464983, acc 0.984375
2020-02-08T02:18:38.311517: step 2598, loss 0.0219017, acc 1
2020-02-08T02:18:38.437677: step 2599, loss 0.0557171, acc 0.96875
2020-02-08T02:18:38.562974: step 2600, loss 0.00501575, acc 1

Evaluation:
2020-02-08T02:18:38.779265: step 2600, loss 0.947586, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2600

2020-02-08T02:18:40.329381: step 2601, loss 0.00619055, acc 1
2020-02-08T02:18:40.455999: step 2602, loss 0.0276185, acc 1
2020-02-08T02:18:40.582332: step 2603, loss 0.0130507, acc 1
2020-02-08T02:18:40.715441: step 2604, loss 0.00412654, acc 1
2020-02-08T02:18:40.842351: step 2605, loss 0.013149, acc 1
2020-02-08T02:18:40.965657: step 2606, loss 0.0412904, acc 0.984375
2020-02-08T02:18:41.093540: step 2607, loss 0.0258272, acc 1
2020-02-08T02:18:41.219547: step 2608, loss 0.0518446, acc 0.984375
2020-02-08T02:18:41.344182: step 2609, loss 0.00914879, acc 1
2020-02-08T02:18:41.469308: step 2610, loss 0.00831533, acc 1
2020-02-08T02:18:41.595147: step 2611, loss 0.0366685, acc 0.984375
2020-02-08T02:18:41.725561: step 2612, loss 0.0116384, acc 1
2020-02-08T02:18:41.852207: step 2613, loss 0.0101044, acc 1
2020-02-08T02:18:41.980028: step 2614, loss 0.0369331, acc 0.984375
2020-02-08T02:18:42.105100: step 2615, loss 0.0460249, acc 0.984375
2020-02-08T02:18:42.232053: step 2616, loss 0.0689151, acc 0.984375
2020-02-08T02:18:42.357830: step 2617, loss 0.0617264, acc 0.96875
2020-02-08T02:18:42.483596: step 2618, loss 0.00912959, acc 1
2020-02-08T02:18:42.613583: step 2619, loss 0.0136831, acc 1
2020-02-08T02:18:42.744246: step 2620, loss 0.0194698, acc 1
2020-02-08T02:18:42.870662: step 2621, loss 0.00718348, acc 1
2020-02-08T02:18:42.995445: step 2622, loss 0.0194732, acc 1
2020-02-08T02:18:43.124498: step 2623, loss 0.0277959, acc 0.984375
2020-02-08T02:18:43.253237: step 2624, loss 0.0792978, acc 0.96875
2020-02-08T02:18:43.381431: step 2625, loss 0.013497, acc 1
2020-02-08T02:18:43.512443: step 2626, loss 0.0073662, acc 1
2020-02-08T02:18:43.677392: step 2627, loss 0.0326883, acc 0.984375
2020-02-08T02:18:43.803029: step 2628, loss 0.0619601, acc 0.96875
2020-02-08T02:18:43.933071: step 2629, loss 0.0166463, acc 1
2020-02-08T02:18:44.065343: step 2630, loss 0.0185114, acc 1
2020-02-08T02:18:44.202021: step 2631, loss 0.00975124, acc 1
2020-02-08T02:18:44.332469: step 2632, loss 0.0205831, acc 1
2020-02-08T02:18:44.467663: step 2633, loss 0.0397533, acc 0.984375
2020-02-08T02:18:44.597453: step 2634, loss 0.019782, acc 1
2020-02-08T02:18:44.735145: step 2635, loss 0.00355638, acc 1
2020-02-08T02:18:44.866923: step 2636, loss 0.0180075, acc 1
2020-02-08T02:18:44.992382: step 2637, loss 0.0197821, acc 1
2020-02-08T02:18:45.121846: step 2638, loss 0.0359457, acc 0.96875
2020-02-08T02:18:45.249584: step 2639, loss 0.0483493, acc 0.96875
2020-02-08T02:18:45.384801: step 2640, loss 0.0134077, acc 1
2020-02-08T02:18:45.513894: step 2641, loss 0.018242, acc 1
2020-02-08T02:18:45.772566: step 2642, loss 0.00850093, acc 1
2020-02-08T02:18:45.919472: step 2643, loss 0.0108759, acc 1
2020-02-08T02:18:46.056780: step 2644, loss 0.0362467, acc 0.984375
2020-02-08T02:18:46.209827: step 2645, loss 0.0247165, acc 1
2020-02-08T02:18:46.371717: step 2646, loss 0.0128048, acc 1
2020-02-08T02:18:46.528443: step 2647, loss 0.0207735, acc 1
2020-02-08T02:18:46.677380: step 2648, loss 0.0291048, acc 0.984375
2020-02-08T02:18:46.823841: step 2649, loss 0.0166374, acc 1
2020-02-08T02:18:46.974734: step 2650, loss 0.0242003, acc 1
2020-02-08T02:18:47.119558: step 2651, loss 0.0164389, acc 1
2020-02-08T02:18:47.269077: step 2652, loss 0.0136178, acc 1
2020-02-08T02:18:47.411457: step 2653, loss 0.0160579, acc 1
2020-02-08T02:18:47.556363: step 2654, loss 0.0175554, acc 0.984375
2020-02-08T02:18:47.703722: step 2655, loss 0.0103874, acc 1
2020-02-08T02:18:47.844600: step 2656, loss 0.0630951, acc 0.984375
2020-02-08T02:18:47.985042: step 2657, loss 0.05839, acc 0.96875
2020-02-08T02:18:48.133487: step 2658, loss 0.018109, acc 1
2020-02-08T02:18:48.278535: step 2659, loss 0.0251689, acc 0.984375
2020-02-08T02:18:48.425644: step 2660, loss 0.011632, acc 1
2020-02-08T02:18:48.562981: step 2661, loss 0.0287096, acc 0.984375
2020-02-08T02:18:48.711988: step 2662, loss 0.0398477, acc 0.984375
2020-02-08T02:18:48.864496: step 2663, loss 0.074128, acc 0.984375
2020-02-08T02:18:49.017385: step 2664, loss 0.0301981, acc 0.984375
2020-02-08T02:18:49.162598: step 2665, loss 0.0515746, acc 0.984375
2020-02-08T02:18:49.308495: step 2666, loss 0.00669588, acc 1
2020-02-08T02:18:49.458187: step 2667, loss 0.0185853, acc 0.984375
2020-02-08T02:18:49.605888: step 2668, loss 0.0558743, acc 0.96875
2020-02-08T02:18:49.770169: step 2669, loss 0.125737, acc 0.9375
2020-02-08T02:18:49.921186: step 2670, loss 0.0555377, acc 0.96875
2020-02-08T02:18:50.064616: step 2671, loss 0.0308755, acc 0.984375
2020-02-08T02:18:50.199904: step 2672, loss 0.0117446, acc 1
2020-02-08T02:18:50.345090: step 2673, loss 0.0284862, acc 0.984375
2020-02-08T02:18:50.502290: step 2674, loss 0.039958, acc 0.96875
2020-02-08T02:18:50.656362: step 2675, loss 0.022406, acc 1
2020-02-08T02:18:50.813837: step 2676, loss 0.0133853, acc 1
2020-02-08T02:18:50.971162: step 2677, loss 0.0530417, acc 0.96875
2020-02-08T02:18:51.119630: step 2678, loss 0.0841463, acc 0.984375
2020-02-08T02:18:51.542077: step 2679, loss 0.10556, acc 0.953125
2020-02-08T02:18:51.691727: step 2680, loss 0.0515467, acc 0.96875
2020-02-08T02:18:51.852178: step 2681, loss 0.0248999, acc 1
2020-02-08T02:18:52.005386: step 2682, loss 0.0154633, acc 1
2020-02-08T02:18:52.164400: step 2683, loss 0.0134389, acc 1
2020-02-08T02:18:52.296396: step 2684, loss 0.0153838, acc 1
2020-02-08T02:18:52.438010: step 2685, loss 0.0116614, acc 1
2020-02-08T02:18:52.578428: step 2686, loss 0.0498474, acc 0.984375
2020-02-08T02:18:52.732684: step 2687, loss 0.0125582, acc 1
2020-02-08T02:18:52.885524: step 2688, loss 0.0400113, acc 0.984375
2020-02-08T02:18:53.037848: step 2689, loss 0.0271629, acc 1
2020-02-08T02:18:53.181491: step 2690, loss 0.0416537, acc 0.984375
2020-02-08T02:18:53.319682: step 2691, loss 0.0632044, acc 0.96875
2020-02-08T02:18:53.454401: step 2692, loss 0.0236207, acc 1
2020-02-08T02:18:53.607246: step 2693, loss 0.0114359, acc 1
2020-02-08T02:18:53.765723: step 2694, loss 0.0351456, acc 0.984375
2020-02-08T02:18:53.918131: step 2695, loss 0.0341541, acc 0.984375
2020-02-08T02:18:54.054648: step 2696, loss 0.00770923, acc 1
2020-02-08T02:18:54.202771: step 2697, loss 0.0629744, acc 0.96875
2020-02-08T02:18:54.354417: step 2698, loss 0.0171205, acc 1
2020-02-08T02:18:54.506206: step 2699, loss 0.0154787, acc 1
2020-02-08T02:18:54.664027: step 2700, loss 0.0509325, acc 0.966667

Evaluation:
2020-02-08T02:18:54.904874: step 2700, loss 0.98587, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2700

2020-02-08T02:18:56.546342: step 2701, loss 0.00540819, acc 1
2020-02-08T02:18:56.706675: step 2702, loss 0.00611064, acc 1
2020-02-08T02:18:56.865083: step 2703, loss 0.0149548, acc 1
2020-02-08T02:18:57.020533: step 2704, loss 0.0114784, acc 1
2020-02-08T02:18:57.172332: step 2705, loss 0.00493405, acc 1
2020-02-08T02:18:57.320986: step 2706, loss 0.0411441, acc 0.984375
2020-02-08T02:18:57.473703: step 2707, loss 0.00952072, acc 1
2020-02-08T02:18:57.612732: step 2708, loss 0.0096826, acc 1
2020-02-08T02:18:57.745055: step 2709, loss 0.00665768, acc 1
2020-02-08T02:18:57.879110: step 2710, loss 0.0354319, acc 0.96875
2020-02-08T02:18:58.006608: step 2711, loss 0.0307054, acc 1
2020-02-08T02:18:58.149299: step 2712, loss 0.0451564, acc 0.96875
2020-02-08T02:18:58.283671: step 2713, loss 0.0287868, acc 0.984375
2020-02-08T02:18:58.414606: step 2714, loss 0.0227971, acc 0.984375
2020-02-08T02:18:58.542428: step 2715, loss 0.0310455, acc 0.984375
2020-02-08T02:18:58.691619: step 2716, loss 0.00612742, acc 1
2020-02-08T02:18:58.831705: step 2717, loss 0.0100412, acc 1
2020-02-08T02:18:58.980137: step 2718, loss 0.0144997, acc 1
2020-02-08T02:18:59.114573: step 2719, loss 0.0247548, acc 0.984375
2020-02-08T02:18:59.241450: step 2720, loss 0.0163117, acc 1
2020-02-08T02:18:59.369328: step 2721, loss 0.00454457, acc 1
2020-02-08T02:18:59.495844: step 2722, loss 0.0040002, acc 1
2020-02-08T02:18:59.626626: step 2723, loss 0.0111752, acc 1
2020-02-08T02:18:59.763742: step 2724, loss 0.0303472, acc 0.984375
2020-02-08T02:18:59.896303: step 2725, loss 0.0137336, acc 1
2020-02-08T02:19:00.029590: step 2726, loss 0.0835127, acc 0.96875
2020-02-08T02:19:00.157824: step 2727, loss 0.011754, acc 1
2020-02-08T02:19:00.290419: step 2728, loss 0.0155608, acc 0.984375
2020-02-08T02:19:00.423449: step 2729, loss 0.0235436, acc 1
2020-02-08T02:19:00.547966: step 2730, loss 0.00717536, acc 1
2020-02-08T02:19:00.681875: step 2731, loss 0.00634729, acc 1
2020-02-08T02:19:00.809731: step 2732, loss 0.00669932, acc 1
2020-02-08T02:19:00.941094: step 2733, loss 0.0239615, acc 1
2020-02-08T02:19:01.070785: step 2734, loss 0.0501831, acc 0.984375
2020-02-08T02:19:01.194137: step 2735, loss 0.0151235, acc 1
2020-02-08T02:19:01.321671: step 2736, loss 0.00906774, acc 1
2020-02-08T02:19:01.443685: step 2737, loss 0.0277954, acc 0.984375
2020-02-08T02:19:01.571176: step 2738, loss 0.0105412, acc 1
2020-02-08T02:19:01.700391: step 2739, loss 0.00871511, acc 1
2020-02-08T02:19:01.824201: step 2740, loss 0.0095104, acc 1
2020-02-08T02:19:01.952526: step 2741, loss 0.0440114, acc 0.984375
2020-02-08T02:19:02.080261: step 2742, loss 0.0281742, acc 0.984375
2020-02-08T02:19:02.205830: step 2743, loss 0.00799366, acc 1
2020-02-08T02:19:02.331890: step 2744, loss 0.0329419, acc 1
2020-02-08T02:19:02.461964: step 2745, loss 0.0387583, acc 0.984375
2020-02-08T02:19:02.588866: step 2746, loss 0.00932316, acc 1
2020-02-08T02:19:02.717559: step 2747, loss 0.0193377, acc 0.984375
2020-02-08T02:19:02.843539: step 2748, loss 0.0126661, acc 1
2020-02-08T02:19:02.971754: step 2749, loss 0.00649233, acc 1
2020-02-08T02:19:03.095445: step 2750, loss 0.0191326, acc 1
2020-02-08T02:19:03.220150: step 2751, loss 0.0105857, acc 1
2020-02-08T02:19:03.347152: step 2752, loss 0.0142925, acc 1
2020-02-08T02:19:03.474036: step 2753, loss 0.019778, acc 1
2020-02-08T02:19:03.601359: step 2754, loss 0.0190669, acc 1
2020-02-08T02:19:03.732716: step 2755, loss 0.0791651, acc 0.96875
2020-02-08T02:19:03.859239: step 2756, loss 0.0469945, acc 0.984375
2020-02-08T02:19:03.991737: step 2757, loss 0.0415362, acc 0.984375
2020-02-08T02:19:04.121717: step 2758, loss 0.0144162, acc 1
2020-02-08T02:19:04.249402: step 2759, loss 0.005732, acc 1
2020-02-08T02:19:04.377359: step 2760, loss 0.0382536, acc 0.984375
2020-02-08T02:19:04.509759: step 2761, loss 0.0100499, acc 1
2020-02-08T02:19:04.636669: step 2762, loss 0.0163177, acc 1
2020-02-08T02:19:04.767981: step 2763, loss 0.00840796, acc 1
2020-02-08T02:19:04.892830: step 2764, loss 0.00682675, acc 1
2020-02-08T02:19:05.020207: step 2765, loss 0.0187425, acc 1
2020-02-08T02:19:05.146299: step 2766, loss 0.0110044, acc 1
2020-02-08T02:19:05.274666: step 2767, loss 0.0310398, acc 0.984375
2020-02-08T02:19:05.407246: step 2768, loss 0.00894, acc 1
2020-02-08T02:19:05.530347: step 2769, loss 0.0134039, acc 1
2020-02-08T02:19:05.658656: step 2770, loss 0.0252461, acc 0.984375
2020-02-08T02:19:05.786937: step 2771, loss 0.0999536, acc 0.984375
2020-02-08T02:19:05.914322: step 2772, loss 0.00430977, acc 1
2020-02-08T02:19:06.042017: step 2773, loss 0.0971448, acc 0.984375
2020-02-08T02:19:06.175826: step 2774, loss 0.00872385, acc 1
2020-02-08T02:19:06.302120: step 2775, loss 0.0283611, acc 0.984375
2020-02-08T02:19:06.429699: step 2776, loss 0.0129128, acc 1
2020-02-08T02:19:06.555022: step 2777, loss 0.0113317, acc 1
2020-02-08T02:19:06.681207: step 2778, loss 0.0175243, acc 1
2020-02-08T02:19:06.805626: step 2779, loss 0.0178585, acc 1
2020-02-08T02:19:06.937283: step 2780, loss 0.0400732, acc 0.984375
2020-02-08T02:19:07.059794: step 2781, loss 0.0162708, acc 1
2020-02-08T02:19:07.185005: step 2782, loss 0.029989, acc 0.984375
2020-02-08T02:19:07.311223: step 2783, loss 0.00469725, acc 1
2020-02-08T02:19:07.435305: step 2784, loss 0.0264399, acc 1
2020-02-08T02:19:07.561516: step 2785, loss 0.10286, acc 0.984375
2020-02-08T02:19:07.694381: step 2786, loss 0.0577552, acc 0.984375
2020-02-08T02:19:07.823279: step 2787, loss 0.0215087, acc 1
2020-02-08T02:19:07.950482: step 2788, loss 0.00692434, acc 1
2020-02-08T02:19:08.079359: step 2789, loss 0.00610257, acc 1
2020-02-08T02:19:08.210812: step 2790, loss 0.047462, acc 0.96875
2020-02-08T02:19:08.340694: step 2791, loss 0.0254967, acc 0.984375
2020-02-08T02:19:08.468701: step 2792, loss 0.0279292, acc 0.984375
2020-02-08T02:19:08.593250: step 2793, loss 0.0292276, acc 0.96875
2020-02-08T02:19:08.726628: step 2794, loss 0.0050013, acc 1
2020-02-08T02:19:08.853375: step 2795, loss 0.016267, acc 1
2020-02-08T02:19:08.982223: step 2796, loss 0.0484123, acc 0.984375
2020-02-08T02:19:09.106625: step 2797, loss 0.0394675, acc 0.984375
2020-02-08T02:19:09.240717: step 2798, loss 0.0627385, acc 0.984375
2020-02-08T02:19:09.372992: step 2799, loss 0.0193067, acc 1
2020-02-08T02:19:09.499038: step 2800, loss 0.0106379, acc 1

Evaluation:
2020-02-08T02:19:09.716500: step 2800, loss 1.0107, acc 0.73546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2800

2020-02-08T02:19:11.544974: step 2801, loss 0.00379262, acc 1
2020-02-08T02:19:11.675495: step 2802, loss 0.0101649, acc 1
2020-02-08T02:19:11.807959: step 2803, loss 0.0599418, acc 0.984375
2020-02-08T02:19:11.937636: step 2804, loss 0.0303773, acc 0.984375
2020-02-08T02:19:12.062573: step 2805, loss 0.0349188, acc 0.984375
2020-02-08T02:19:12.185500: step 2806, loss 0.0340153, acc 1
2020-02-08T02:19:12.318004: step 2807, loss 0.0154223, acc 1
2020-02-08T02:19:12.444936: step 2808, loss 0.0105215, acc 1
2020-02-08T02:19:12.576244: step 2809, loss 0.00319385, acc 1
2020-02-08T02:19:12.713229: step 2810, loss 0.0178892, acc 1
2020-02-08T02:19:12.837536: step 2811, loss 0.013056, acc 1
2020-02-08T02:19:12.965999: step 2812, loss 0.0508743, acc 0.984375
2020-02-08T02:19:13.087138: step 2813, loss 0.0124643, acc 1
2020-02-08T02:19:13.218475: step 2814, loss 0.0127893, acc 1
2020-02-08T02:19:13.341566: step 2815, loss 0.0136566, acc 1
2020-02-08T02:19:13.467510: step 2816, loss 0.00992422, acc 1
2020-02-08T02:19:13.596277: step 2817, loss 0.00722971, acc 1
2020-02-08T02:19:13.731789: step 2818, loss 0.0167655, acc 1
2020-02-08T02:19:13.860711: step 2819, loss 0.0622496, acc 0.96875
2020-02-08T02:19:13.991075: step 2820, loss 0.0294272, acc 0.96875
2020-02-08T02:19:14.117446: step 2821, loss 0.0394994, acc 0.984375
2020-02-08T02:19:14.243272: step 2822, loss 0.00958353, acc 1
2020-02-08T02:19:14.372133: step 2823, loss 0.0403192, acc 0.984375
2020-02-08T02:19:14.495433: step 2824, loss 0.0621127, acc 0.96875
2020-02-08T02:19:14.625678: step 2825, loss 0.0282212, acc 0.984375
2020-02-08T02:19:14.753672: step 2826, loss 0.012245, acc 1
2020-02-08T02:19:14.899319: step 2827, loss 0.0235539, acc 0.984375
2020-02-08T02:19:15.029297: step 2828, loss 0.0143879, acc 1
2020-02-08T02:19:15.151883: step 2829, loss 0.0171535, acc 1
2020-02-08T02:19:15.279121: step 2830, loss 0.0111427, acc 1
2020-02-08T02:19:15.411993: step 2831, loss 0.0148985, acc 1
2020-02-08T02:19:15.541016: step 2832, loss 0.00564262, acc 1
2020-02-08T02:19:15.673739: step 2833, loss 0.00600535, acc 1
2020-02-08T02:19:15.796019: step 2834, loss 0.00752466, acc 1
2020-02-08T02:19:15.921528: step 2835, loss 0.0127326, acc 1
2020-02-08T02:19:16.051341: step 2836, loss 0.0115018, acc 1
2020-02-08T02:19:16.180624: step 2837, loss 0.0250205, acc 0.984375
2020-02-08T02:19:16.304015: step 2838, loss 0.0234129, acc 0.984375
2020-02-08T02:19:16.437369: step 2839, loss 0.0125285, acc 1
2020-02-08T02:19:16.568576: step 2840, loss 0.00660237, acc 1
2020-02-08T02:19:16.702561: step 2841, loss 0.0444598, acc 0.984375
2020-02-08T02:19:16.831943: step 2842, loss 0.0156961, acc 1
2020-02-08T02:19:16.961464: step 2843, loss 0.00886917, acc 1
2020-02-08T02:19:17.085634: step 2844, loss 0.0466223, acc 0.984375
2020-02-08T02:19:17.212733: step 2845, loss 0.0103838, acc 1
2020-02-08T02:19:17.342666: step 2846, loss 0.0128805, acc 1
2020-02-08T02:19:17.467248: step 2847, loss 0.0106391, acc 1
2020-02-08T02:19:17.593448: step 2848, loss 0.0758147, acc 0.96875
2020-02-08T02:19:17.739454: step 2849, loss 0.00951869, acc 1
2020-02-08T02:19:17.862351: step 2850, loss 0.0239839, acc 1
2020-02-08T02:19:18.002924: step 2851, loss 0.0138066, acc 1
2020-02-08T02:19:18.121176: step 2852, loss 0.0357975, acc 0.984375
2020-02-08T02:19:18.239665: step 2853, loss 0.00758082, acc 1
2020-02-08T02:19:18.358186: step 2854, loss 0.037116, acc 0.984375
2020-02-08T02:19:18.473106: step 2855, loss 0.0109156, acc 1
2020-02-08T02:19:18.593295: step 2856, loss 0.0523846, acc 0.984375
2020-02-08T02:19:18.726552: step 2857, loss 0.0249393, acc 0.984375
2020-02-08T02:19:18.847563: step 2858, loss 0.00765718, acc 1
2020-02-08T02:19:18.973193: step 2859, loss 0.00574489, acc 1
2020-02-08T02:19:19.095887: step 2860, loss 0.00744789, acc 1
2020-02-08T02:19:19.228889: step 2861, loss 0.0065463, acc 1
2020-02-08T02:19:19.346573: step 2862, loss 0.00870597, acc 1
2020-02-08T02:19:19.479069: step 2863, loss 0.015662, acc 1
2020-02-08T02:19:19.600015: step 2864, loss 0.0151484, acc 1
2020-02-08T02:19:19.735350: step 2865, loss 0.0133758, acc 1
2020-02-08T02:19:19.858471: step 2866, loss 0.00609923, acc 1
2020-02-08T02:19:19.976760: step 2867, loss 0.010393, acc 1
2020-02-08T02:19:20.093718: step 2868, loss 0.00625099, acc 1
2020-02-08T02:19:20.225720: step 2869, loss 0.0108821, acc 1
2020-02-08T02:19:20.343879: step 2870, loss 0.0348945, acc 0.984375
2020-02-08T02:19:20.460487: step 2871, loss 0.00717655, acc 1
2020-02-08T02:19:20.585447: step 2872, loss 0.00504571, acc 1
2020-02-08T02:19:20.709123: step 2873, loss 0.0240576, acc 0.984375
2020-02-08T02:19:20.830931: step 2874, loss 0.0254661, acc 1
2020-02-08T02:19:20.948287: step 2875, loss 0.0180268, acc 1
2020-02-08T02:19:21.068776: step 2876, loss 0.0453224, acc 0.984375
2020-02-08T02:19:21.185622: step 2877, loss 0.00595919, acc 1
2020-02-08T02:19:21.419582: step 2878, loss 0.0339174, acc 0.984375
2020-02-08T02:19:21.540650: step 2879, loss 0.00564425, acc 1
2020-02-08T02:19:21.663329: step 2880, loss 0.029183, acc 0.984375
2020-02-08T02:19:21.786693: step 2881, loss 0.0313341, acc 1
2020-02-08T02:19:21.918007: step 2882, loss 0.00816232, acc 1
2020-02-08T02:19:22.036593: step 2883, loss 0.0163657, acc 1
2020-02-08T02:19:22.152570: step 2884, loss 0.0204368, acc 0.984375
2020-02-08T02:19:22.272749: step 2885, loss 0.0114997, acc 1
2020-02-08T02:19:22.387193: step 2886, loss 0.0421052, acc 0.984375
2020-02-08T02:19:22.503091: step 2887, loss 0.00476978, acc 1
2020-02-08T02:19:22.621581: step 2888, loss 0.0097744, acc 1
2020-02-08T02:19:22.741778: step 2889, loss 0.0136648, acc 1
2020-02-08T02:19:22.858700: step 2890, loss 0.0201691, acc 1
2020-02-08T02:19:22.976050: step 2891, loss 0.0107372, acc 1
2020-02-08T02:19:23.095934: step 2892, loss 0.00202704, acc 1
2020-02-08T02:19:23.212396: step 2893, loss 0.00678253, acc 1
2020-02-08T02:19:23.330254: step 2894, loss 0.0400664, acc 0.984375
2020-02-08T02:19:23.445488: step 2895, loss 0.0133025, acc 1
2020-02-08T02:19:23.565215: step 2896, loss 0.0331768, acc 0.984375
2020-02-08T02:19:23.686953: step 2897, loss 0.0106848, acc 1
2020-02-08T02:19:23.810986: step 2898, loss 0.014808, acc 1
2020-02-08T02:19:23.932597: step 2899, loss 0.0312845, acc 0.984375
2020-02-08T02:19:24.047604: step 2900, loss 0.0111118, acc 1

Evaluation:
2020-02-08T02:19:24.237155: step 2900, loss 1.04794, acc 0.739212

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-2900

2020-02-08T02:19:25.765236: step 2901, loss 0.00771293, acc 1
2020-02-08T02:19:25.884568: step 2902, loss 0.00638038, acc 1
2020-02-08T02:19:26.001173: step 2903, loss 0.0467127, acc 0.96875
2020-02-08T02:19:26.128924: step 2904, loss 0.00677737, acc 1
2020-02-08T02:19:26.245464: step 2905, loss 0.0516486, acc 0.984375
2020-02-08T02:19:26.362705: step 2906, loss 0.0523919, acc 0.96875
2020-02-08T02:19:26.476272: step 2907, loss 0.0131324, acc 1
2020-02-08T02:19:26.595139: step 2908, loss 0.0265042, acc 1
2020-02-08T02:19:26.716308: step 2909, loss 0.0661887, acc 0.96875
2020-02-08T02:19:26.834274: step 2910, loss 0.0243576, acc 1
2020-02-08T02:19:26.950132: step 2911, loss 0.0056818, acc 1
2020-02-08T02:19:27.069948: step 2912, loss 0.0134256, acc 1
2020-02-08T02:19:27.186529: step 2913, loss 0.0562623, acc 0.96875
2020-02-08T02:19:27.302531: step 2914, loss 0.00577324, acc 1
2020-02-08T02:19:27.420319: step 2915, loss 0.0349186, acc 0.984375
2020-02-08T02:19:27.536533: step 2916, loss 0.0132358, acc 1
2020-02-08T02:19:27.651031: step 2917, loss 0.0286782, acc 0.984375
2020-02-08T02:19:27.779109: step 2918, loss 0.00545572, acc 1
2020-02-08T02:19:27.893825: step 2919, loss 0.00786416, acc 1
2020-02-08T02:19:28.009086: step 2920, loss 0.0107603, acc 1
2020-02-08T02:19:28.123678: step 2921, loss 0.00593812, acc 1
2020-02-08T02:19:28.237413: step 2922, loss 0.0174818, acc 1
2020-02-08T02:19:28.351495: step 2923, loss 0.0263651, acc 0.984375
2020-02-08T02:19:28.469006: step 2924, loss 0.00996621, acc 1
2020-02-08T02:19:28.584328: step 2925, loss 0.0258965, acc 0.984375
2020-02-08T02:19:28.705848: step 2926, loss 0.029523, acc 0.984375
2020-02-08T02:19:28.827630: step 2927, loss 0.0162148, acc 1
2020-02-08T02:19:28.968576: step 2928, loss 0.0327816, acc 0.984375
2020-02-08T02:19:29.106151: step 2929, loss 0.0235828, acc 0.984375
2020-02-08T02:19:29.225853: step 2930, loss 0.00454481, acc 1
2020-02-08T02:19:29.340047: step 2931, loss 0.0371592, acc 1
2020-02-08T02:19:29.453247: step 2932, loss 0.0171737, acc 1
2020-02-08T02:19:29.570218: step 2933, loss 0.00648791, acc 1
2020-02-08T02:19:29.685272: step 2934, loss 0.00466985, acc 1
2020-02-08T02:19:29.805398: step 2935, loss 0.0305248, acc 0.984375
2020-02-08T02:19:29.921963: step 2936, loss 0.0344052, acc 0.984375
2020-02-08T02:19:30.040761: step 2937, loss 0.0550262, acc 0.96875
2020-02-08T02:19:30.156810: step 2938, loss 0.0130972, acc 1
2020-02-08T02:19:30.272352: step 2939, loss 0.00750573, acc 1
2020-02-08T02:19:30.391227: step 2940, loss 0.00668509, acc 1
2020-02-08T02:19:30.508619: step 2941, loss 0.0134875, acc 1
2020-02-08T02:19:30.627893: step 2942, loss 0.0112265, acc 1
2020-02-08T02:19:30.743615: step 2943, loss 0.0129522, acc 1
2020-02-08T02:19:30.862269: step 2944, loss 0.0161094, acc 1
2020-02-08T02:19:30.979005: step 2945, loss 0.0430718, acc 0.984375
2020-02-08T02:19:31.092484: step 2946, loss 0.027151, acc 1
2020-02-08T02:19:31.210042: step 2947, loss 0.0128383, acc 1
2020-02-08T02:19:31.326304: step 2948, loss 0.0277628, acc 0.984375
2020-02-08T02:19:31.442531: step 2949, loss 0.0217401, acc 1
2020-02-08T02:19:31.559730: step 2950, loss 0.00580194, acc 1
2020-02-08T02:19:31.678153: step 2951, loss 0.0361138, acc 0.984375
2020-02-08T02:19:31.799236: step 2952, loss 0.0115766, acc 1
2020-02-08T02:19:31.917935: step 2953, loss 0.0192825, acc 1
2020-02-08T02:19:32.032923: step 2954, loss 0.0124516, acc 1
2020-02-08T02:19:32.146387: step 2955, loss 0.0262372, acc 1
2020-02-08T02:19:32.262329: step 2956, loss 0.0564113, acc 0.984375
2020-02-08T02:19:32.377942: step 2957, loss 0.0149551, acc 1
2020-02-08T02:19:32.495867: step 2958, loss 0.0133451, acc 1
2020-02-08T02:19:32.612018: step 2959, loss 0.00791309, acc 1
2020-02-08T02:19:32.735659: step 2960, loss 0.0213791, acc 0.984375
2020-02-08T02:19:32.852613: step 2961, loss 0.00222828, acc 1
2020-02-08T02:19:32.970121: step 2962, loss 0.0675314, acc 0.96875
2020-02-08T02:19:33.085847: step 2963, loss 0.0100727, acc 1
2020-02-08T02:19:33.201795: step 2964, loss 0.00347466, acc 1
2020-02-08T02:19:33.322313: step 2965, loss 0.00142459, acc 1
2020-02-08T02:19:33.437137: step 2966, loss 0.00603726, acc 1
2020-02-08T02:19:33.553474: step 2967, loss 0.00512088, acc 1
2020-02-08T02:19:33.671412: step 2968, loss 0.0370802, acc 0.984375
2020-02-08T02:19:33.789657: step 2969, loss 0.0358479, acc 1
2020-02-08T02:19:33.905126: step 2970, loss 0.00606611, acc 1
2020-02-08T02:19:34.022476: step 2971, loss 0.0189855, acc 1
2020-02-08T02:19:34.138690: step 2972, loss 0.00805127, acc 1
2020-02-08T02:19:34.256134: step 2973, loss 0.0178214, acc 1
2020-02-08T02:19:34.374584: step 2974, loss 0.00893899, acc 1
2020-02-08T02:19:34.492539: step 2975, loss 0.00767772, acc 1
2020-02-08T02:19:34.610972: step 2976, loss 0.0135837, acc 1
2020-02-08T02:19:34.733732: step 2977, loss 0.00828392, acc 1
2020-02-08T02:19:34.851807: step 2978, loss 0.0437386, acc 0.984375
2020-02-08T02:19:34.970313: step 2979, loss 0.0156313, acc 1
2020-02-08T02:19:35.086787: step 2980, loss 0.024124, acc 1
2020-02-08T02:19:35.200723: step 2981, loss 0.00375211, acc 1
2020-02-08T02:19:35.317758: step 2982, loss 0.0241796, acc 1
2020-02-08T02:19:35.435190: step 2983, loss 0.00908484, acc 1
2020-02-08T02:19:35.551536: step 2984, loss 0.0137014, acc 0.984375
2020-02-08T02:19:35.670103: step 2985, loss 0.0158802, acc 1
2020-02-08T02:19:35.788007: step 2986, loss 0.0405962, acc 0.984375
2020-02-08T02:19:35.903704: step 2987, loss 0.0159158, acc 1
2020-02-08T02:19:36.018401: step 2988, loss 0.0343843, acc 0.96875
2020-02-08T02:19:36.136720: step 2989, loss 0.0322412, acc 0.984375
2020-02-08T02:19:36.256158: step 2990, loss 0.0374586, acc 0.984375
2020-02-08T02:19:36.374691: step 2991, loss 0.0420065, acc 0.96875
2020-02-08T02:19:36.493537: step 2992, loss 0.0245904, acc 0.984375
2020-02-08T02:19:36.612375: step 2993, loss 0.0181537, acc 0.984375
2020-02-08T02:19:36.732972: step 2994, loss 0.00822226, acc 1
2020-02-08T02:19:36.850797: step 2995, loss 0.0051375, acc 1
2020-02-08T02:19:36.968270: step 2996, loss 0.0209265, acc 1
2020-02-08T02:19:37.084974: step 2997, loss 0.00820753, acc 1
2020-02-08T02:19:37.201054: step 2998, loss 0.0184478, acc 1
2020-02-08T02:19:37.318979: step 2999, loss 0.019067, acc 1
2020-02-08T02:19:37.428554: step 3000, loss 0.024884, acc 0.983333

Evaluation:
2020-02-08T02:19:37.623464: step 3000, loss 1.09005, acc 0.734522

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581099119/checkpoints/model-3000

