WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:16:27.585211 4738497984 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:16:27.585465 4738497984 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:16:27.585573 4738497984 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 03:16:28.111930 4738497984 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 03:16:28.112173 4738497984 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 03:16:28.112392: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 03:16:28.125164: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7b17c3c90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 03:16:28.125229: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 03:16:28.125739 4738497984 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 03:16:28.130843 4738497984 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 03:16:28.144968 4738497984 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 03:16:28.154141 4738497984 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 03:16:28.181470 4738497984 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 03:16:28.193063 4738497984 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 03:16:28.193286 4738497984 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 03:16:28.204313 4738497984 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 03:16:28.206720 4738497984 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 03:16:28.238590 4738497984 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 03:16:28.477597 4738497984 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 03:16:28.477895 4738497984 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 03:16:28.486325 4738497984 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 03:16:28.504922 4738497984 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 03:16:28.506006 4738497984 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 03:16:28.521441 4738497984 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 03:16:28.522961 4738497984 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 03:16:28.544096 4738497984 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 03:16:28.545186 4738497984 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 03:16:28.559468 4738497984 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 03:16:28.560537 4738497984 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 03:16:28.577018 4738497984 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 03:16:28.578739 4738497984 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 03:16:28.597666 4738497984 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 03:16:28.598800 4738497984 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 03:16:28.613250 4738497984 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 03:16:28.614328 4738497984 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 03:16:28.633274 4738497984 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 03:16:28.635093 4738497984 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 03:16:28.651087 4738497984 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 03:16:28.652172 4738497984 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 03:16:28.655741 4738497984 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 03:16:28.983589 4738497984 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 03:16:28.983777 4738497984 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 03:16:29.088501 4738497984 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 03:16:29.636699 4738497984 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 03:17:49.862648 4738497984 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988

2020-02-08T03:16:29.636182: step 1, loss 3.51005, acc 0.515625
2020-02-08T03:16:29.768499: step 2, loss 2.13676, acc 0.546875
2020-02-08T03:16:29.887338: step 3, loss 1.99501, acc 0.5
2020-02-08T03:16:30.004831: step 4, loss 2.23833, acc 0.46875
2020-02-08T03:16:30.120425: step 5, loss 2.62064, acc 0.390625
2020-02-08T03:16:30.236624: step 6, loss 2.36822, acc 0.5
2020-02-08T03:16:30.354904: step 7, loss 2.33959, acc 0.484375
2020-02-08T03:16:30.470347: step 8, loss 1.84954, acc 0.578125
2020-02-08T03:16:30.588422: step 9, loss 1.64636, acc 0.546875
2020-02-08T03:16:30.703397: step 10, loss 2.12748, acc 0.53125
2020-02-08T03:16:30.816200: step 11, loss 1.38836, acc 0.640625
2020-02-08T03:16:30.934131: step 12, loss 2.43712, acc 0.4375
2020-02-08T03:16:31.049902: step 13, loss 2.32057, acc 0.53125
2020-02-08T03:16:31.164584: step 14, loss 1.73506, acc 0.671875
2020-02-08T03:16:31.280648: step 15, loss 1.93759, acc 0.46875
2020-02-08T03:16:31.396966: step 16, loss 1.91628, acc 0.515625
2020-02-08T03:16:31.512435: step 17, loss 1.82096, acc 0.5
2020-02-08T03:16:31.628354: step 18, loss 2.28305, acc 0.4375
2020-02-08T03:16:31.747321: step 19, loss 1.77709, acc 0.53125
2020-02-08T03:16:31.863150: step 20, loss 2.314, acc 0.46875
2020-02-08T03:16:31.978149: step 21, loss 1.77984, acc 0.5625
2020-02-08T03:16:32.094492: step 22, loss 2.39906, acc 0.453125
2020-02-08T03:16:32.209010: step 23, loss 1.8655, acc 0.5
2020-02-08T03:16:32.327926: step 24, loss 2.06035, acc 0.4375
2020-02-08T03:16:32.445444: step 25, loss 1.36131, acc 0.625
2020-02-08T03:16:32.560846: step 26, loss 1.87322, acc 0.46875
2020-02-08T03:16:32.676224: step 27, loss 1.90459, acc 0.484375
2020-02-08T03:16:32.791344: step 28, loss 2.27404, acc 0.484375
2020-02-08T03:16:32.910445: step 29, loss 1.63976, acc 0.484375
2020-02-08T03:16:33.027573: step 30, loss 2.83205, acc 0.34375
2020-02-08T03:16:33.146146: step 31, loss 1.41021, acc 0.53125
2020-02-08T03:16:33.260733: step 32, loss 1.94149, acc 0.46875
2020-02-08T03:16:33.377099: step 33, loss 1.58026, acc 0.453125
2020-02-08T03:16:33.492446: step 34, loss 1.87534, acc 0.4375
2020-02-08T03:16:33.608319: step 35, loss 1.84265, acc 0.4375
2020-02-08T03:16:33.723083: step 36, loss 2.31924, acc 0.375
2020-02-08T03:16:33.840860: step 37, loss 1.8564, acc 0.46875
2020-02-08T03:16:33.956986: step 38, loss 1.76632, acc 0.546875
2020-02-08T03:16:34.071421: step 39, loss 1.9245, acc 0.53125
2020-02-08T03:16:34.188753: step 40, loss 1.91132, acc 0.421875
2020-02-08T03:16:34.306678: step 41, loss 1.26257, acc 0.515625
2020-02-08T03:16:34.424203: step 42, loss 1.2154, acc 0.59375
2020-02-08T03:16:34.542826: step 43, loss 1.79338, acc 0.4375
2020-02-08T03:16:34.661365: step 44, loss 2.08006, acc 0.421875
2020-02-08T03:16:34.774881: step 45, loss 1.20851, acc 0.5625
2020-02-08T03:16:34.892928: step 46, loss 1.4436, acc 0.5625
2020-02-08T03:16:35.009898: step 47, loss 1.99705, acc 0.515625
2020-02-08T03:16:35.126295: step 48, loss 1.65358, acc 0.484375
2020-02-08T03:16:35.244256: step 49, loss 1.85996, acc 0.421875
2020-02-08T03:16:35.366534: step 50, loss 1.48768, acc 0.5625
2020-02-08T03:16:35.484537: step 51, loss 1.21027, acc 0.640625
2020-02-08T03:16:35.601881: step 52, loss 1.73478, acc 0.53125
2020-02-08T03:16:35.719792: step 53, loss 1.45102, acc 0.515625
2020-02-08T03:16:35.835752: step 54, loss 1.64347, acc 0.421875
2020-02-08T03:16:35.954773: step 55, loss 1.63264, acc 0.546875
2020-02-08T03:16:36.072751: step 56, loss 1.35872, acc 0.578125
2020-02-08T03:16:36.192761: step 57, loss 2.19898, acc 0.4375
2020-02-08T03:16:36.310413: step 58, loss 1.77787, acc 0.53125
2020-02-08T03:16:36.427999: step 59, loss 1.67678, acc 0.453125
2020-02-08T03:16:36.544737: step 60, loss 1.6346, acc 0.515625
2020-02-08T03:16:36.665170: step 61, loss 1.75477, acc 0.421875
2020-02-08T03:16:36.785880: step 62, loss 1.41808, acc 0.546875
2020-02-08T03:16:36.901792: step 63, loss 1.92911, acc 0.4375
2020-02-08T03:16:37.018355: step 64, loss 1.46485, acc 0.59375
2020-02-08T03:16:37.137216: step 65, loss 1.29291, acc 0.59375
2020-02-08T03:16:37.255534: step 66, loss 1.85831, acc 0.53125
2020-02-08T03:16:37.370922: step 67, loss 1.4465, acc 0.546875
2020-02-08T03:16:37.488567: step 68, loss 1.891, acc 0.59375
2020-02-08T03:16:37.605297: step 69, loss 1.73611, acc 0.5
2020-02-08T03:16:37.721798: step 70, loss 2.34225, acc 0.5
2020-02-08T03:16:37.840868: step 71, loss 1.13103, acc 0.609375
2020-02-08T03:16:37.957655: step 72, loss 1.57489, acc 0.609375
2020-02-08T03:16:38.076294: step 73, loss 1.50139, acc 0.5625
2020-02-08T03:16:38.193382: step 74, loss 2.21389, acc 0.40625
2020-02-08T03:16:38.310283: step 75, loss 1.88625, acc 0.484375
2020-02-08T03:16:38.426188: step 76, loss 1.40298, acc 0.53125
2020-02-08T03:16:38.545628: step 77, loss 1.43551, acc 0.53125
2020-02-08T03:16:38.661792: step 78, loss 1.25967, acc 0.59375
2020-02-08T03:16:38.784312: step 79, loss 1.24097, acc 0.609375
2020-02-08T03:16:38.902173: step 80, loss 1.65694, acc 0.4375
2020-02-08T03:16:39.016687: step 81, loss 1.17266, acc 0.640625
2020-02-08T03:16:39.133003: step 82, loss 1.56125, acc 0.5
2020-02-08T03:16:39.250577: step 83, loss 1.17008, acc 0.578125
2020-02-08T03:16:39.365842: step 84, loss 1.56301, acc 0.5
2020-02-08T03:16:39.482196: step 85, loss 1.5554, acc 0.546875
2020-02-08T03:16:39.600584: step 86, loss 1.91018, acc 0.40625
2020-02-08T03:16:39.717610: step 87, loss 1.35062, acc 0.5625
2020-02-08T03:16:39.837505: step 88, loss 1.61541, acc 0.484375
2020-02-08T03:16:39.952155: step 89, loss 1.87995, acc 0.4375
2020-02-08T03:16:40.067752: step 90, loss 1.35602, acc 0.53125
2020-02-08T03:16:40.186567: step 91, loss 1.39449, acc 0.453125
2020-02-08T03:16:40.306513: step 92, loss 1.48126, acc 0.546875
2020-02-08T03:16:40.423920: step 93, loss 1.13584, acc 0.546875
2020-02-08T03:16:40.539009: step 94, loss 1.71019, acc 0.484375
2020-02-08T03:16:40.653830: step 95, loss 1.70067, acc 0.546875
2020-02-08T03:16:40.770384: step 96, loss 1.33277, acc 0.59375
2020-02-08T03:16:40.887101: step 97, loss 1.36305, acc 0.5
2020-02-08T03:16:41.002704: step 98, loss 2.0972, acc 0.46875
2020-02-08T03:16:41.118657: step 99, loss 1.65311, acc 0.515625
2020-02-08T03:16:41.234315: step 100, loss 1.42065, acc 0.53125

Evaluation:
2020-02-08T03:16:41.471650: step 100, loss 0.796722, acc 0.58818

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-100

2020-02-08T03:16:43.590673: step 101, loss 1.24302, acc 0.53125
2020-02-08T03:16:43.707852: step 102, loss 1.45735, acc 0.46875
2020-02-08T03:16:43.823127: step 103, loss 1.63306, acc 0.515625
2020-02-08T03:16:43.943867: step 104, loss 1.70178, acc 0.46875
2020-02-08T03:16:44.060879: step 105, loss 1.30266, acc 0.5625
2020-02-08T03:16:44.178865: step 106, loss 1.57508, acc 0.53125
2020-02-08T03:16:44.296250: step 107, loss 1.59762, acc 0.515625
2020-02-08T03:16:44.409730: step 108, loss 1.70266, acc 0.4375
2020-02-08T03:16:44.525656: step 109, loss 1.33157, acc 0.578125
2020-02-08T03:16:44.645522: step 110, loss 1.6645, acc 0.53125
2020-02-08T03:16:44.760510: step 111, loss 1.22885, acc 0.609375
2020-02-08T03:16:44.877759: step 112, loss 1.09311, acc 0.59375
2020-02-08T03:16:44.996872: step 113, loss 1.30436, acc 0.53125
2020-02-08T03:16:45.114956: step 114, loss 1.48448, acc 0.5625
2020-02-08T03:16:45.233559: step 115, loss 1.56037, acc 0.53125
2020-02-08T03:16:45.352223: step 116, loss 1.44217, acc 0.53125
2020-02-08T03:16:45.465158: step 117, loss 1.37661, acc 0.59375
2020-02-08T03:16:45.586993: step 118, loss 1.63763, acc 0.46875
2020-02-08T03:16:45.706274: step 119, loss 1.69154, acc 0.53125
2020-02-08T03:16:45.824365: step 120, loss 2.52094, acc 0.34375
2020-02-08T03:16:45.943082: step 121, loss 1.16075, acc 0.625
2020-02-08T03:16:46.057748: step 122, loss 1.36644, acc 0.59375
2020-02-08T03:16:46.173924: step 123, loss 1.48811, acc 0.5
2020-02-08T03:16:46.290028: step 124, loss 1.33794, acc 0.609375
2020-02-08T03:16:46.408113: step 125, loss 1.48709, acc 0.578125
2020-02-08T03:16:46.523581: step 126, loss 1.83351, acc 0.40625
2020-02-08T03:16:46.641649: step 127, loss 1.62294, acc 0.5625
2020-02-08T03:16:46.757504: step 128, loss 1.51174, acc 0.609375
2020-02-08T03:16:46.872496: step 129, loss 1.36477, acc 0.546875
2020-02-08T03:16:46.992477: step 130, loss 1.4261, acc 0.484375
2020-02-08T03:16:47.108130: step 131, loss 1.38028, acc 0.546875
2020-02-08T03:16:47.226400: step 132, loss 1.64121, acc 0.40625
2020-02-08T03:16:47.343777: step 133, loss 1.57608, acc 0.53125
2020-02-08T03:16:47.457962: step 134, loss 1.58322, acc 0.53125
2020-02-08T03:16:47.575112: step 135, loss 1.03765, acc 0.625
2020-02-08T03:16:47.691530: step 136, loss 1.15193, acc 0.59375
2020-02-08T03:16:47.807143: step 137, loss 1.45058, acc 0.578125
2020-02-08T03:16:47.925918: step 138, loss 1.30389, acc 0.515625
2020-02-08T03:16:48.045475: step 139, loss 1.4192, acc 0.578125
2020-02-08T03:16:48.160390: step 140, loss 1.17175, acc 0.546875
2020-02-08T03:16:48.279068: step 141, loss 1.57834, acc 0.515625
2020-02-08T03:16:48.397358: step 142, loss 1.09148, acc 0.625
2020-02-08T03:16:48.512408: step 143, loss 1.46975, acc 0.53125
2020-02-08T03:16:48.628566: step 144, loss 1.2839, acc 0.5
2020-02-08T03:16:48.745594: step 145, loss 1.35469, acc 0.578125
2020-02-08T03:16:48.862242: step 146, loss 1.20926, acc 0.546875
2020-02-08T03:16:48.979726: step 147, loss 1.16375, acc 0.6875
2020-02-08T03:16:49.095937: step 148, loss 1.52587, acc 0.59375
2020-02-08T03:16:49.210725: step 149, loss 1.23953, acc 0.53125
2020-02-08T03:16:49.321237: step 150, loss 1.18957, acc 0.566667
2020-02-08T03:16:49.440064: step 151, loss 0.702304, acc 0.78125
2020-02-08T03:16:49.557235: step 152, loss 1.07841, acc 0.625
2020-02-08T03:16:49.671934: step 153, loss 1.10966, acc 0.640625
2020-02-08T03:16:49.791128: step 154, loss 1.10897, acc 0.609375
2020-02-08T03:16:49.906593: step 155, loss 0.679298, acc 0.75
2020-02-08T03:16:50.024912: step 156, loss 0.701589, acc 0.671875
2020-02-08T03:16:50.141592: step 157, loss 1.09249, acc 0.5625
2020-02-08T03:16:50.257892: step 158, loss 0.81756, acc 0.609375
2020-02-08T03:16:50.374942: step 159, loss 1.02314, acc 0.578125
2020-02-08T03:16:50.492728: step 160, loss 1.10679, acc 0.5625
2020-02-08T03:16:50.609120: step 161, loss 0.891771, acc 0.65625
2020-02-08T03:16:50.722925: step 162, loss 0.952743, acc 0.671875
2020-02-08T03:16:50.840837: step 163, loss 1.02079, acc 0.625
2020-02-08T03:16:50.957429: step 164, loss 0.968445, acc 0.6875
2020-02-08T03:16:51.072512: step 165, loss 1.16708, acc 0.546875
2020-02-08T03:16:51.191303: step 166, loss 1.42266, acc 0.515625
2020-02-08T03:16:51.306647: step 167, loss 1.12494, acc 0.578125
2020-02-08T03:16:51.515971: step 168, loss 0.991038, acc 0.609375
2020-02-08T03:16:51.637406: step 169, loss 0.848377, acc 0.625
2020-02-08T03:16:51.753905: step 170, loss 1.02342, acc 0.546875
2020-02-08T03:16:51.871389: step 171, loss 0.901006, acc 0.59375
2020-02-08T03:16:51.988102: step 172, loss 1.13959, acc 0.59375
2020-02-08T03:16:52.103064: step 173, loss 1.14299, acc 0.546875
2020-02-08T03:16:52.218896: step 174, loss 0.963619, acc 0.59375
2020-02-08T03:16:52.335458: step 175, loss 0.992995, acc 0.625
2020-02-08T03:16:52.453750: step 176, loss 1.12109, acc 0.65625
2020-02-08T03:16:52.569631: step 177, loss 1.34416, acc 0.484375
2020-02-08T03:16:52.688054: step 178, loss 0.798636, acc 0.671875
2020-02-08T03:16:52.808087: step 179, loss 1.1898, acc 0.578125
2020-02-08T03:16:52.926844: step 180, loss 0.716784, acc 0.625
2020-02-08T03:16:53.042791: step 181, loss 1.11342, acc 0.53125
2020-02-08T03:16:53.160404: step 182, loss 0.646663, acc 0.734375
2020-02-08T03:16:53.277397: step 183, loss 0.879473, acc 0.640625
2020-02-08T03:16:53.394289: step 184, loss 1.01062, acc 0.59375
2020-02-08T03:16:53.509546: step 185, loss 0.823522, acc 0.625
2020-02-08T03:16:53.625596: step 186, loss 1.24582, acc 0.578125
2020-02-08T03:16:53.745543: step 187, loss 0.978557, acc 0.53125
2020-02-08T03:16:53.865275: step 188, loss 1.24498, acc 0.515625
2020-02-08T03:16:53.980628: step 189, loss 0.920334, acc 0.546875
2020-02-08T03:16:54.099195: step 190, loss 1.00154, acc 0.546875
2020-02-08T03:16:54.217549: step 191, loss 0.972222, acc 0.625
2020-02-08T03:16:54.340215: step 192, loss 0.919593, acc 0.578125
2020-02-08T03:16:54.458232: step 193, loss 0.944553, acc 0.578125
2020-02-08T03:16:54.574323: step 194, loss 0.693262, acc 0.703125
2020-02-08T03:16:54.689823: step 195, loss 1.23264, acc 0.59375
2020-02-08T03:16:54.810449: step 196, loss 1.11352, acc 0.5625
2020-02-08T03:16:54.928017: step 197, loss 0.715905, acc 0.65625
2020-02-08T03:16:55.044423: step 198, loss 0.846871, acc 0.625
2020-02-08T03:16:55.160289: step 199, loss 0.99299, acc 0.625
2020-02-08T03:16:55.275758: step 200, loss 0.868878, acc 0.640625

Evaluation:
2020-02-08T03:16:55.465728: step 200, loss 0.685245, acc 0.615385

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-200

2020-02-08T03:16:57.016229: step 201, loss 0.971456, acc 0.65625
2020-02-08T03:16:57.133775: step 202, loss 1.27178, acc 0.5
2020-02-08T03:16:57.248852: step 203, loss 0.760681, acc 0.640625
2020-02-08T03:16:57.362191: step 204, loss 0.997309, acc 0.578125
2020-02-08T03:16:57.478339: step 205, loss 0.901838, acc 0.625
2020-02-08T03:16:57.594697: step 206, loss 1.11278, acc 0.59375
2020-02-08T03:16:57.710784: step 207, loss 0.755286, acc 0.703125
2020-02-08T03:16:57.827057: step 208, loss 0.964993, acc 0.53125
2020-02-08T03:16:57.945649: step 209, loss 1.05381, acc 0.609375
2020-02-08T03:16:58.062567: step 210, loss 1.31769, acc 0.546875
2020-02-08T03:16:58.180501: step 211, loss 0.955064, acc 0.640625
2020-02-08T03:16:58.298028: step 212, loss 0.937199, acc 0.609375
2020-02-08T03:16:58.416170: step 213, loss 0.739809, acc 0.75
2020-02-08T03:16:58.532507: step 214, loss 0.668671, acc 0.765625
2020-02-08T03:16:58.648484: step 215, loss 1.01395, acc 0.5625
2020-02-08T03:16:58.763528: step 216, loss 0.741485, acc 0.6875
2020-02-08T03:16:58.881478: step 217, loss 0.815016, acc 0.640625
2020-02-08T03:16:59.002583: step 218, loss 1.02138, acc 0.546875
2020-02-08T03:16:59.117710: step 219, loss 1.11921, acc 0.5625
2020-02-08T03:16:59.234435: step 220, loss 0.884075, acc 0.65625
2020-02-08T03:16:59.350848: step 221, loss 0.76161, acc 0.640625
2020-02-08T03:16:59.467685: step 222, loss 0.938958, acc 0.609375
2020-02-08T03:16:59.582900: step 223, loss 1.0628, acc 0.546875
2020-02-08T03:16:59.701315: step 224, loss 0.902453, acc 0.546875
2020-02-08T03:16:59.817448: step 225, loss 0.942903, acc 0.578125
2020-02-08T03:16:59.934848: step 226, loss 0.798826, acc 0.546875
2020-02-08T03:17:00.052520: step 227, loss 0.871427, acc 0.59375
2020-02-08T03:17:00.169644: step 228, loss 1.1078, acc 0.59375
2020-02-08T03:17:00.287740: step 229, loss 1.19085, acc 0.5625
2020-02-08T03:17:00.405974: step 230, loss 1.04547, acc 0.59375
2020-02-08T03:17:00.524890: step 231, loss 1.03411, acc 0.609375
2020-02-08T03:17:00.639919: step 232, loss 0.934333, acc 0.640625
2020-02-08T03:17:00.754678: step 233, loss 0.782587, acc 0.609375
2020-02-08T03:17:00.868236: step 234, loss 0.84829, acc 0.640625
2020-02-08T03:17:00.985683: step 235, loss 0.66121, acc 0.625
2020-02-08T03:17:01.101476: step 236, loss 1.19878, acc 0.46875
2020-02-08T03:17:01.219183: step 237, loss 1.00044, acc 0.578125
2020-02-08T03:17:01.335798: step 238, loss 0.919001, acc 0.609375
2020-02-08T03:17:01.449954: step 239, loss 0.955121, acc 0.5625
2020-02-08T03:17:01.567466: step 240, loss 0.805566, acc 0.640625
2020-02-08T03:17:01.686642: step 241, loss 0.814472, acc 0.609375
2020-02-08T03:17:01.804700: step 242, loss 0.753381, acc 0.609375
2020-02-08T03:17:01.919924: step 243, loss 0.813123, acc 0.625
2020-02-08T03:17:02.034981: step 244, loss 1.05368, acc 0.578125
2020-02-08T03:17:02.152881: step 245, loss 0.949185, acc 0.609375
2020-02-08T03:17:02.267121: step 246, loss 1.06003, acc 0.609375
2020-02-08T03:17:02.384019: step 247, loss 0.874805, acc 0.546875
2020-02-08T03:17:02.501605: step 248, loss 1.12223, acc 0.5625
2020-02-08T03:17:02.619235: step 249, loss 0.9898, acc 0.65625
2020-02-08T03:17:02.735275: step 250, loss 0.68948, acc 0.625
2020-02-08T03:17:02.851857: step 251, loss 0.648522, acc 0.75
2020-02-08T03:17:02.970939: step 252, loss 1.07404, acc 0.640625
2020-02-08T03:17:03.089574: step 253, loss 0.853654, acc 0.578125
2020-02-08T03:17:03.208075: step 254, loss 1.07422, acc 0.515625
2020-02-08T03:17:03.326798: step 255, loss 0.674824, acc 0.65625
2020-02-08T03:17:03.445065: step 256, loss 0.600857, acc 0.71875
2020-02-08T03:17:03.561233: step 257, loss 0.915644, acc 0.640625
2020-02-08T03:17:03.676133: step 258, loss 0.740273, acc 0.640625
2020-02-08T03:17:03.794217: step 259, loss 0.824224, acc 0.609375
2020-02-08T03:17:03.912700: step 260, loss 0.866807, acc 0.609375
2020-02-08T03:17:04.031393: step 261, loss 0.719281, acc 0.6875
2020-02-08T03:17:04.147939: step 262, loss 1.04833, acc 0.515625
2020-02-08T03:17:04.263357: step 263, loss 0.808824, acc 0.671875
2020-02-08T03:17:04.378671: step 264, loss 0.830883, acc 0.640625
2020-02-08T03:17:04.494576: step 265, loss 0.889208, acc 0.640625
2020-02-08T03:17:04.608526: step 266, loss 0.783754, acc 0.640625
2020-02-08T03:17:04.722215: step 267, loss 0.982066, acc 0.59375
2020-02-08T03:17:04.840285: step 268, loss 0.79059, acc 0.609375
2020-02-08T03:17:04.961700: step 269, loss 0.809846, acc 0.59375
2020-02-08T03:17:05.079719: step 270, loss 1.11424, acc 0.5625
2020-02-08T03:17:05.198194: step 271, loss 0.743861, acc 0.671875
2020-02-08T03:17:05.317684: step 272, loss 0.736074, acc 0.671875
2020-02-08T03:17:05.437677: step 273, loss 0.991632, acc 0.5
2020-02-08T03:17:05.553985: step 274, loss 0.868079, acc 0.609375
2020-02-08T03:17:05.673344: step 275, loss 1.02238, acc 0.578125
2020-02-08T03:17:05.791892: step 276, loss 0.834248, acc 0.59375
2020-02-08T03:17:05.909347: step 277, loss 0.705992, acc 0.6875
2020-02-08T03:17:06.023899: step 278, loss 0.753996, acc 0.640625
2020-02-08T03:17:06.140395: step 279, loss 0.7158, acc 0.65625
2020-02-08T03:17:06.256546: step 280, loss 1.16545, acc 0.46875
2020-02-08T03:17:06.372701: step 281, loss 0.79222, acc 0.640625
2020-02-08T03:17:06.489459: step 282, loss 0.954377, acc 0.5625
2020-02-08T03:17:06.607672: step 283, loss 1.02554, acc 0.578125
2020-02-08T03:17:06.727992: step 284, loss 0.798971, acc 0.671875
2020-02-08T03:17:06.843593: step 285, loss 0.935014, acc 0.578125
2020-02-08T03:17:06.960667: step 286, loss 0.916216, acc 0.59375
2020-02-08T03:17:07.078640: step 287, loss 0.796997, acc 0.734375
2020-02-08T03:17:07.198346: step 288, loss 0.730512, acc 0.65625
2020-02-08T03:17:07.316598: step 289, loss 0.804418, acc 0.65625
2020-02-08T03:17:07.431009: step 290, loss 1.10156, acc 0.515625
2020-02-08T03:17:07.547950: step 291, loss 1.06019, acc 0.5625
2020-02-08T03:17:07.665539: step 292, loss 0.887375, acc 0.578125
2020-02-08T03:17:07.778941: step 293, loss 0.779617, acc 0.609375
2020-02-08T03:17:07.897467: step 294, loss 0.654726, acc 0.671875
2020-02-08T03:17:08.013086: step 295, loss 0.747881, acc 0.640625
2020-02-08T03:17:08.130751: step 296, loss 0.589254, acc 0.6875
2020-02-08T03:17:08.248669: step 297, loss 0.751444, acc 0.5625
2020-02-08T03:17:08.366206: step 298, loss 1.0412, acc 0.5625
2020-02-08T03:17:08.484600: step 299, loss 0.674936, acc 0.71875
2020-02-08T03:17:08.597857: step 300, loss 1.0344, acc 0.55

Evaluation:
2020-02-08T03:17:08.788033: step 300, loss 0.639025, acc 0.633208

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-300

2020-02-08T03:17:10.253270: step 301, loss 0.760395, acc 0.734375
2020-02-08T03:17:10.371787: step 302, loss 0.852709, acc 0.65625
2020-02-08T03:17:10.490037: step 303, loss 0.898791, acc 0.5625
2020-02-08T03:17:10.605236: step 304, loss 0.679497, acc 0.640625
2020-02-08T03:17:10.721476: step 305, loss 0.89619, acc 0.546875
2020-02-08T03:17:10.840009: step 306, loss 0.741148, acc 0.65625
2020-02-08T03:17:10.955871: step 307, loss 0.467374, acc 0.796875
2020-02-08T03:17:11.070183: step 308, loss 0.847149, acc 0.65625
2020-02-08T03:17:11.187875: step 309, loss 0.50204, acc 0.78125
2020-02-08T03:17:11.307149: step 310, loss 0.81822, acc 0.609375
2020-02-08T03:17:11.422713: step 311, loss 0.860466, acc 0.59375
2020-02-08T03:17:11.540983: step 312, loss 0.770545, acc 0.65625
2020-02-08T03:17:11.658039: step 313, loss 0.697408, acc 0.640625
2020-02-08T03:17:11.773638: step 314, loss 0.723444, acc 0.65625
2020-02-08T03:17:11.893507: step 315, loss 0.511188, acc 0.828125
2020-02-08T03:17:12.010857: step 316, loss 0.677851, acc 0.703125
2020-02-08T03:17:12.126826: step 317, loss 1.05479, acc 0.515625
2020-02-08T03:17:12.246798: step 318, loss 0.562279, acc 0.734375
2020-02-08T03:17:12.364266: step 319, loss 0.709115, acc 0.640625
2020-02-08T03:17:12.482261: step 320, loss 0.880708, acc 0.59375
2020-02-08T03:17:12.598466: step 321, loss 0.707117, acc 0.640625
2020-02-08T03:17:12.714325: step 322, loss 0.746455, acc 0.671875
2020-02-08T03:17:12.829577: step 323, loss 0.636419, acc 0.6875
2020-02-08T03:17:12.945253: step 324, loss 0.771195, acc 0.65625
2020-02-08T03:17:13.061924: step 325, loss 0.691044, acc 0.625
2020-02-08T03:17:13.178261: step 326, loss 0.659376, acc 0.703125
2020-02-08T03:17:13.294244: step 327, loss 0.637862, acc 0.734375
2020-02-08T03:17:13.411841: step 328, loss 0.715957, acc 0.578125
2020-02-08T03:17:13.529942: step 329, loss 0.809894, acc 0.625
2020-02-08T03:17:13.647672: step 330, loss 0.835658, acc 0.609375
2020-02-08T03:17:13.764508: step 331, loss 0.556212, acc 0.734375
2020-02-08T03:17:13.882114: step 332, loss 0.842357, acc 0.625
2020-02-08T03:17:13.997618: step 333, loss 0.759924, acc 0.6875
2020-02-08T03:17:14.114139: step 334, loss 0.734923, acc 0.59375
2020-02-08T03:17:14.229288: step 335, loss 0.54474, acc 0.734375
2020-02-08T03:17:14.344110: step 336, loss 0.772286, acc 0.65625
2020-02-08T03:17:14.459218: step 337, loss 0.54991, acc 0.78125
2020-02-08T03:17:14.575596: step 338, loss 0.930018, acc 0.609375
2020-02-08T03:17:14.690831: step 339, loss 0.654503, acc 0.640625
2020-02-08T03:17:14.809199: step 340, loss 0.63506, acc 0.703125
2020-02-08T03:17:14.925592: step 341, loss 0.6695, acc 0.71875
2020-02-08T03:17:15.043006: step 342, loss 0.631232, acc 0.671875
2020-02-08T03:17:15.162258: step 343, loss 0.629408, acc 0.671875
2020-02-08T03:17:15.281672: step 344, loss 0.574132, acc 0.703125
2020-02-08T03:17:15.401230: step 345, loss 0.65816, acc 0.703125
2020-02-08T03:17:15.517305: step 346, loss 0.678381, acc 0.6875
2020-02-08T03:17:15.635790: step 347, loss 0.801805, acc 0.59375
2020-02-08T03:17:15.751082: step 348, loss 0.884804, acc 0.5625
2020-02-08T03:17:15.866119: step 349, loss 0.574581, acc 0.734375
2020-02-08T03:17:15.983341: step 350, loss 0.788284, acc 0.609375
2020-02-08T03:17:16.102472: step 351, loss 0.558281, acc 0.71875
2020-02-08T03:17:16.219700: step 352, loss 0.733477, acc 0.640625
2020-02-08T03:17:16.336932: step 353, loss 0.676153, acc 0.625
2020-02-08T03:17:16.452193: step 354, loss 0.718935, acc 0.625
2020-02-08T03:17:16.567823: step 355, loss 0.437417, acc 0.8125
2020-02-08T03:17:16.681711: step 356, loss 0.618971, acc 0.734375
2020-02-08T03:17:16.799389: step 357, loss 0.75077, acc 0.609375
2020-02-08T03:17:16.915372: step 358, loss 0.61086, acc 0.671875
2020-02-08T03:17:17.033261: step 359, loss 0.801193, acc 0.703125
2020-02-08T03:17:17.150963: step 360, loss 0.698218, acc 0.703125
2020-02-08T03:17:17.266936: step 361, loss 0.623444, acc 0.671875
2020-02-08T03:17:17.383716: step 362, loss 0.628289, acc 0.6875
2020-02-08T03:17:17.500343: step 363, loss 0.599292, acc 0.75
2020-02-08T03:17:17.616840: step 364, loss 0.811616, acc 0.65625
2020-02-08T03:17:17.731911: step 365, loss 0.892267, acc 0.65625
2020-02-08T03:17:17.845113: step 366, loss 0.555386, acc 0.75
2020-02-08T03:17:17.960185: step 367, loss 0.602223, acc 0.734375
2020-02-08T03:17:18.077697: step 368, loss 0.545217, acc 0.75
2020-02-08T03:17:18.195251: step 369, loss 0.615334, acc 0.65625
2020-02-08T03:17:18.310554: step 370, loss 0.519529, acc 0.703125
2020-02-08T03:17:18.428872: step 371, loss 0.568665, acc 0.734375
2020-02-08T03:17:18.543563: step 372, loss 0.605133, acc 0.671875
2020-02-08T03:17:18.662238: step 373, loss 0.624346, acc 0.65625
2020-02-08T03:17:18.779611: step 374, loss 0.652446, acc 0.640625
2020-02-08T03:17:18.898115: step 375, loss 0.68839, acc 0.625
2020-02-08T03:17:19.015045: step 376, loss 0.616669, acc 0.671875
2020-02-08T03:17:19.132300: step 377, loss 0.689325, acc 0.640625
2020-02-08T03:17:19.250557: step 378, loss 0.707477, acc 0.578125
2020-02-08T03:17:19.365850: step 379, loss 0.498089, acc 0.765625
2020-02-08T03:17:19.485336: step 380, loss 0.734386, acc 0.671875
2020-02-08T03:17:19.600677: step 381, loss 0.707733, acc 0.640625
2020-02-08T03:17:19.718878: step 382, loss 0.662366, acc 0.640625
2020-02-08T03:17:19.837942: step 383, loss 0.666938, acc 0.703125
2020-02-08T03:17:19.955814: step 384, loss 0.694441, acc 0.59375
2020-02-08T03:17:20.073480: step 385, loss 0.74551, acc 0.6875
2020-02-08T03:17:20.187732: step 386, loss 0.604891, acc 0.671875
2020-02-08T03:17:20.306182: step 387, loss 0.62189, acc 0.71875
2020-02-08T03:17:20.421743: step 388, loss 0.76964, acc 0.609375
2020-02-08T03:17:20.538930: step 389, loss 0.926145, acc 0.59375
2020-02-08T03:17:20.657970: step 390, loss 0.815473, acc 0.578125
2020-02-08T03:17:20.775333: step 391, loss 0.531585, acc 0.75
2020-02-08T03:17:20.890529: step 392, loss 0.552765, acc 0.78125
2020-02-08T03:17:21.009025: step 393, loss 0.660126, acc 0.671875
2020-02-08T03:17:21.124119: step 394, loss 0.609918, acc 0.6875
2020-02-08T03:17:21.243105: step 395, loss 0.524243, acc 0.75
2020-02-08T03:17:21.359703: step 396, loss 0.950036, acc 0.515625
2020-02-08T03:17:21.474323: step 397, loss 0.788029, acc 0.65625
2020-02-08T03:17:21.609359: step 398, loss 0.655162, acc 0.71875
2020-02-08T03:17:21.738728: step 399, loss 0.677876, acc 0.65625
2020-02-08T03:17:21.857066: step 400, loss 0.622536, acc 0.71875

Evaluation:
2020-02-08T03:17:22.044472: step 400, loss 0.630995, acc 0.637899

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-400

2020-02-08T03:17:23.565657: step 401, loss 0.599858, acc 0.71875
2020-02-08T03:17:23.680646: step 402, loss 0.541975, acc 0.75
2020-02-08T03:17:23.796692: step 403, loss 0.596593, acc 0.703125
2020-02-08T03:17:23.910719: step 404, loss 0.602481, acc 0.703125
2020-02-08T03:17:24.026693: step 405, loss 0.721719, acc 0.640625
2020-02-08T03:17:24.143988: step 406, loss 0.754008, acc 0.546875
2020-02-08T03:17:24.262366: step 407, loss 0.670555, acc 0.671875
2020-02-08T03:17:24.377696: step 408, loss 0.77325, acc 0.578125
2020-02-08T03:17:24.497411: step 409, loss 0.586459, acc 0.671875
2020-02-08T03:17:24.614478: step 410, loss 0.617152, acc 0.703125
2020-02-08T03:17:24.731999: step 411, loss 0.625797, acc 0.6875
2020-02-08T03:17:24.855030: step 412, loss 0.693146, acc 0.59375
2020-02-08T03:17:24.968592: step 413, loss 0.569913, acc 0.671875
2020-02-08T03:17:25.088699: step 414, loss 0.6957, acc 0.6875
2020-02-08T03:17:25.208084: step 415, loss 0.744552, acc 0.609375
2020-02-08T03:17:25.325812: step 416, loss 0.708061, acc 0.6875
2020-02-08T03:17:25.446735: step 417, loss 0.704222, acc 0.640625
2020-02-08T03:17:25.564420: step 418, loss 0.641231, acc 0.734375
2020-02-08T03:17:25.679439: step 419, loss 0.716906, acc 0.6875
2020-02-08T03:17:25.798355: step 420, loss 0.761095, acc 0.578125
2020-02-08T03:17:25.913615: step 421, loss 0.668157, acc 0.671875
2020-02-08T03:17:26.032035: step 422, loss 0.687748, acc 0.65625
2020-02-08T03:17:26.149930: step 423, loss 0.687368, acc 0.65625
2020-02-08T03:17:26.267577: step 424, loss 0.562665, acc 0.75
2020-02-08T03:17:26.385065: step 425, loss 0.642733, acc 0.65625
2020-02-08T03:17:26.505107: step 426, loss 0.746687, acc 0.6875
2020-02-08T03:17:26.622143: step 427, loss 0.667757, acc 0.625
2020-02-08T03:17:26.741279: step 428, loss 0.618768, acc 0.71875
2020-02-08T03:17:26.858551: step 429, loss 0.509066, acc 0.71875
2020-02-08T03:17:26.976079: step 430, loss 0.471619, acc 0.78125
2020-02-08T03:17:27.090533: step 431, loss 0.62694, acc 0.71875
2020-02-08T03:17:27.206764: step 432, loss 0.751457, acc 0.640625
2020-02-08T03:17:27.324373: step 433, loss 0.512057, acc 0.703125
2020-02-08T03:17:27.442761: step 434, loss 0.579808, acc 0.6875
2020-02-08T03:17:27.559858: step 435, loss 0.682167, acc 0.65625
2020-02-08T03:17:27.679291: step 436, loss 0.623821, acc 0.640625
2020-02-08T03:17:27.797686: step 437, loss 0.701377, acc 0.640625
2020-02-08T03:17:27.915432: step 438, loss 0.732222, acc 0.640625
2020-02-08T03:17:28.033297: step 439, loss 0.685349, acc 0.71875
2020-02-08T03:17:28.151134: step 440, loss 0.759677, acc 0.640625
2020-02-08T03:17:28.268399: step 441, loss 0.498891, acc 0.734375
2020-02-08T03:17:28.385556: step 442, loss 0.647835, acc 0.671875
2020-02-08T03:17:28.504365: step 443, loss 0.880934, acc 0.46875
2020-02-08T03:17:28.620815: step 444, loss 0.677987, acc 0.59375
2020-02-08T03:17:28.736252: step 445, loss 0.672644, acc 0.65625
2020-02-08T03:17:28.854579: step 446, loss 0.622208, acc 0.671875
2020-02-08T03:17:28.968136: step 447, loss 0.608826, acc 0.625
2020-02-08T03:17:29.087044: step 448, loss 0.702538, acc 0.703125
2020-02-08T03:17:29.205230: step 449, loss 0.606703, acc 0.6875
2020-02-08T03:17:29.317265: step 450, loss 0.708914, acc 0.666667
2020-02-08T03:17:29.436490: step 451, loss 0.607228, acc 0.734375
2020-02-08T03:17:29.555310: step 452, loss 0.431968, acc 0.8125
2020-02-08T03:17:29.674069: step 453, loss 0.487502, acc 0.71875
2020-02-08T03:17:29.795464: step 454, loss 0.375238, acc 0.875
2020-02-08T03:17:29.912045: step 455, loss 0.55321, acc 0.71875
2020-02-08T03:17:30.028573: step 456, loss 0.612664, acc 0.6875
2020-02-08T03:17:30.145541: step 457, loss 0.777291, acc 0.609375
2020-02-08T03:17:30.262031: step 458, loss 0.500251, acc 0.765625
2020-02-08T03:17:30.379866: step 459, loss 0.535463, acc 0.78125
2020-02-08T03:17:30.495963: step 460, loss 0.806846, acc 0.671875
2020-02-08T03:17:30.612747: step 461, loss 0.756947, acc 0.625
2020-02-08T03:17:30.727699: step 462, loss 0.553379, acc 0.6875
2020-02-08T03:17:30.845033: step 463, loss 0.532038, acc 0.71875
2020-02-08T03:17:30.962107: step 464, loss 0.565687, acc 0.6875
2020-02-08T03:17:31.076740: step 465, loss 0.442939, acc 0.8125
2020-02-08T03:17:31.199011: step 466, loss 0.667314, acc 0.6875
2020-02-08T03:17:31.316361: step 467, loss 0.505412, acc 0.734375
2020-02-08T03:17:31.433397: step 468, loss 0.601171, acc 0.6875
2020-02-08T03:17:31.550204: step 469, loss 0.517681, acc 0.796875
2020-02-08T03:17:31.666487: step 470, loss 0.535469, acc 0.765625
2020-02-08T03:17:31.780857: step 471, loss 0.64816, acc 0.671875
2020-02-08T03:17:31.897358: step 472, loss 0.691627, acc 0.625
2020-02-08T03:17:32.010192: step 473, loss 0.619658, acc 0.75
2020-02-08T03:17:32.129503: step 474, loss 0.518735, acc 0.765625
2020-02-08T03:17:32.246074: step 475, loss 0.580445, acc 0.71875
2020-02-08T03:17:32.361065: step 476, loss 0.478655, acc 0.8125
2020-02-08T03:17:32.476181: step 477, loss 0.488441, acc 0.734375
2020-02-08T03:17:32.594102: step 478, loss 0.641155, acc 0.71875
2020-02-08T03:17:32.710591: step 479, loss 0.51231, acc 0.765625
2020-02-08T03:17:32.827228: step 480, loss 0.508909, acc 0.765625
2020-02-08T03:17:32.946020: step 481, loss 0.575872, acc 0.703125
2020-02-08T03:17:33.062984: step 482, loss 0.539939, acc 0.71875
2020-02-08T03:17:33.180919: step 483, loss 0.722587, acc 0.625
2020-02-08T03:17:33.297922: step 484, loss 0.463127, acc 0.8125
2020-02-08T03:17:33.416447: step 485, loss 0.681979, acc 0.578125
2020-02-08T03:17:33.535962: step 486, loss 0.603829, acc 0.6875
2020-02-08T03:17:33.655163: step 487, loss 0.628302, acc 0.71875
2020-02-08T03:17:33.774199: step 488, loss 0.601446, acc 0.71875
2020-02-08T03:17:33.892362: step 489, loss 0.528626, acc 0.71875
2020-02-08T03:17:34.009850: step 490, loss 0.589064, acc 0.75
2020-02-08T03:17:34.127369: step 491, loss 0.489005, acc 0.765625
2020-02-08T03:17:34.244294: step 492, loss 0.793403, acc 0.609375
2020-02-08T03:17:34.361286: step 493, loss 0.606304, acc 0.703125
2020-02-08T03:17:34.476163: step 494, loss 0.47668, acc 0.78125
2020-02-08T03:17:34.592545: step 495, loss 0.585779, acc 0.71875
2020-02-08T03:17:34.710320: step 496, loss 0.580509, acc 0.671875
2020-02-08T03:17:34.827959: step 497, loss 0.658806, acc 0.640625
2020-02-08T03:17:34.946337: step 498, loss 0.511507, acc 0.78125
2020-02-08T03:17:35.062683: step 499, loss 0.607677, acc 0.734375
2020-02-08T03:17:35.176113: step 500, loss 0.568314, acc 0.65625

Evaluation:
2020-02-08T03:17:35.365908: step 500, loss 0.610159, acc 0.663227

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-500

2020-02-08T03:17:36.819953: step 501, loss 0.484824, acc 0.8125
2020-02-08T03:17:36.937370: step 502, loss 0.724742, acc 0.59375
2020-02-08T03:17:37.054446: step 503, loss 0.522808, acc 0.765625
2020-02-08T03:17:37.170434: step 504, loss 0.515976, acc 0.75
2020-02-08T03:17:37.288297: step 505, loss 0.586937, acc 0.71875
2020-02-08T03:17:37.406373: step 506, loss 0.708409, acc 0.640625
2020-02-08T03:17:37.525477: step 507, loss 0.615893, acc 0.6875
2020-02-08T03:17:37.643489: step 508, loss 0.532103, acc 0.734375
2020-02-08T03:17:37.760269: step 509, loss 0.574916, acc 0.71875
2020-02-08T03:17:37.873675: step 510, loss 0.709552, acc 0.5625
2020-02-08T03:17:37.988532: step 511, loss 0.646092, acc 0.609375
2020-02-08T03:17:38.107320: step 512, loss 0.593351, acc 0.71875
2020-02-08T03:17:38.225098: step 513, loss 0.619055, acc 0.671875
2020-02-08T03:17:38.342531: step 514, loss 0.607214, acc 0.75
2020-02-08T03:17:38.459967: step 515, loss 0.49009, acc 0.78125
2020-02-08T03:17:38.576507: step 516, loss 0.624095, acc 0.6875
2020-02-08T03:17:38.694619: step 517, loss 0.600016, acc 0.703125
2020-02-08T03:17:38.811054: step 518, loss 0.444691, acc 0.796875
2020-02-08T03:17:38.925561: step 519, loss 0.538742, acc 0.671875
2020-02-08T03:17:39.044490: step 520, loss 0.602458, acc 0.625
2020-02-08T03:17:39.162511: step 521, loss 0.586128, acc 0.75
2020-02-08T03:17:39.277916: step 522, loss 0.417866, acc 0.796875
2020-02-08T03:17:39.393714: step 523, loss 0.436475, acc 0.765625
2020-02-08T03:17:39.510666: step 524, loss 0.638549, acc 0.6875
2020-02-08T03:17:39.626040: step 525, loss 0.662003, acc 0.6875
2020-02-08T03:17:39.744063: step 526, loss 0.59734, acc 0.65625
2020-02-08T03:17:39.862219: step 527, loss 0.585083, acc 0.78125
2020-02-08T03:17:39.975795: step 528, loss 0.634821, acc 0.625
2020-02-08T03:17:40.097262: step 529, loss 0.482899, acc 0.765625
2020-02-08T03:17:40.215565: step 530, loss 0.548928, acc 0.75
2020-02-08T03:17:40.332351: step 531, loss 0.540051, acc 0.703125
2020-02-08T03:17:40.451458: step 532, loss 0.534637, acc 0.71875
2020-02-08T03:17:40.568038: step 533, loss 0.464277, acc 0.796875
2020-02-08T03:17:40.688556: step 534, loss 0.483731, acc 0.78125
2020-02-08T03:17:40.805240: step 535, loss 0.569366, acc 0.6875
2020-02-08T03:17:40.921821: step 536, loss 0.537655, acc 0.734375
2020-02-08T03:17:41.040396: step 537, loss 0.449396, acc 0.796875
2020-02-08T03:17:41.157977: step 538, loss 0.514925, acc 0.8125
2020-02-08T03:17:41.275309: step 539, loss 0.626876, acc 0.765625
2020-02-08T03:17:41.391291: step 540, loss 0.545567, acc 0.609375
2020-02-08T03:17:41.512147: step 541, loss 0.57036, acc 0.6875
2020-02-08T03:17:41.628393: step 542, loss 0.42998, acc 0.796875
2020-02-08T03:17:41.744302: step 543, loss 0.579016, acc 0.6875
2020-02-08T03:17:41.860848: step 544, loss 0.550515, acc 0.734375
2020-02-08T03:17:41.974071: step 545, loss 0.684664, acc 0.65625
2020-02-08T03:17:42.092414: step 546, loss 0.511151, acc 0.75
2020-02-08T03:17:42.209655: step 547, loss 0.60176, acc 0.765625
2020-02-08T03:17:42.325644: step 548, loss 0.424694, acc 0.828125
2020-02-08T03:17:42.441883: step 549, loss 0.62674, acc 0.640625
2020-02-08T03:17:42.556742: step 550, loss 0.575344, acc 0.703125
2020-02-08T03:17:42.669504: step 551, loss 0.500397, acc 0.71875
2020-02-08T03:17:42.787663: step 552, loss 0.600393, acc 0.71875
2020-02-08T03:17:42.902571: step 553, loss 0.483387, acc 0.71875
2020-02-08T03:17:43.019913: step 554, loss 0.460311, acc 0.796875
2020-02-08T03:17:43.138228: step 555, loss 0.509279, acc 0.765625
2020-02-08T03:17:43.255618: step 556, loss 0.523482, acc 0.734375
2020-02-08T03:17:43.370254: step 557, loss 0.476448, acc 0.78125
2020-02-08T03:17:43.487320: step 558, loss 0.576819, acc 0.734375
2020-02-08T03:17:43.602283: step 559, loss 0.471708, acc 0.796875
2020-02-08T03:17:43.716741: step 560, loss 0.480101, acc 0.796875
2020-02-08T03:17:43.832963: step 561, loss 0.551144, acc 0.703125
2020-02-08T03:17:43.950224: step 562, loss 0.531169, acc 0.75
2020-02-08T03:17:44.065465: step 563, loss 0.651833, acc 0.734375
2020-02-08T03:17:44.180878: step 564, loss 0.608433, acc 0.671875
2020-02-08T03:17:44.301321: step 565, loss 0.596356, acc 0.671875
2020-02-08T03:17:44.417795: step 566, loss 0.483042, acc 0.78125
2020-02-08T03:17:44.534939: step 567, loss 0.561941, acc 0.734375
2020-02-08T03:17:44.651692: step 568, loss 0.589688, acc 0.6875
2020-02-08T03:17:44.766751: step 569, loss 0.56225, acc 0.734375
2020-02-08T03:17:44.881971: step 570, loss 0.704488, acc 0.671875
2020-02-08T03:17:44.999759: step 571, loss 0.54157, acc 0.703125
2020-02-08T03:17:45.114821: step 572, loss 0.622346, acc 0.71875
2020-02-08T03:17:45.233056: step 573, loss 0.510691, acc 0.703125
2020-02-08T03:17:45.352002: step 574, loss 0.608852, acc 0.625
2020-02-08T03:17:45.469098: step 575, loss 0.499499, acc 0.734375
2020-02-08T03:17:45.588083: step 576, loss 0.620308, acc 0.703125
2020-02-08T03:17:45.705186: step 577, loss 0.533745, acc 0.71875
2020-02-08T03:17:45.821104: step 578, loss 0.579688, acc 0.703125
2020-02-08T03:17:45.937333: step 579, loss 0.516418, acc 0.734375
2020-02-08T03:17:46.053210: step 580, loss 0.485677, acc 0.765625
2020-02-08T03:17:46.168384: step 581, loss 0.637341, acc 0.703125
2020-02-08T03:17:46.283473: step 582, loss 0.67718, acc 0.65625
2020-02-08T03:17:46.400085: step 583, loss 0.584326, acc 0.640625
2020-02-08T03:17:46.516387: step 584, loss 0.56132, acc 0.71875
2020-02-08T03:17:46.631856: step 585, loss 0.540479, acc 0.71875
2020-02-08T03:17:46.750278: step 586, loss 0.543716, acc 0.734375
2020-02-08T03:17:46.868389: step 587, loss 0.44675, acc 0.734375
2020-02-08T03:17:46.987700: step 588, loss 0.686923, acc 0.625
2020-02-08T03:17:47.105221: step 589, loss 0.564848, acc 0.75
2020-02-08T03:17:47.220642: step 590, loss 0.575205, acc 0.703125
2020-02-08T03:17:47.337562: step 591, loss 0.610588, acc 0.703125
2020-02-08T03:17:47.455003: step 592, loss 0.496966, acc 0.75
2020-02-08T03:17:47.570137: step 593, loss 0.47086, acc 0.765625
2020-02-08T03:17:47.688080: step 594, loss 0.490428, acc 0.75
2020-02-08T03:17:47.806337: step 595, loss 0.513658, acc 0.75
2020-02-08T03:17:47.921854: step 596, loss 0.630522, acc 0.734375
2020-02-08T03:17:48.037304: step 597, loss 0.491213, acc 0.765625
2020-02-08T03:17:48.152399: step 598, loss 0.657922, acc 0.71875
2020-02-08T03:17:48.267595: step 599, loss 0.536217, acc 0.78125
2020-02-08T03:17:48.377914: step 600, loss 0.527461, acc 0.766667

Evaluation:
2020-02-08T03:17:48.563116: step 600, loss 0.699986, acc 0.589118

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-600

2020-02-08T03:17:50.057693: step 601, loss 0.587474, acc 0.703125
2020-02-08T03:17:50.172275: step 602, loss 0.572561, acc 0.703125
2020-02-08T03:17:50.289912: step 603, loss 0.62392, acc 0.671875
2020-02-08T03:17:50.405670: step 604, loss 0.526929, acc 0.765625
2020-02-08T03:17:50.521070: step 605, loss 0.520404, acc 0.75
2020-02-08T03:17:50.636475: step 606, loss 0.556542, acc 0.703125
2020-02-08T03:17:50.755821: step 607, loss 0.482224, acc 0.8125
2020-02-08T03:17:50.870264: step 608, loss 0.622465, acc 0.71875
2020-02-08T03:17:50.988884: step 609, loss 0.7312, acc 0.609375
2020-02-08T03:17:51.107438: step 610, loss 0.407606, acc 0.8125
2020-02-08T03:17:51.223015: step 611, loss 0.598577, acc 0.671875
2020-02-08T03:17:51.340132: step 612, loss 0.366861, acc 0.828125
2020-02-08T03:17:51.455264: step 613, loss 0.497298, acc 0.734375
2020-02-08T03:17:51.648079: step 614, loss 0.495364, acc 0.703125
2020-02-08T03:17:51.774424: step 615, loss 0.50098, acc 0.703125
2020-02-08T03:17:51.891373: step 616, loss 0.603857, acc 0.671875
2020-02-08T03:17:52.008886: step 617, loss 0.631457, acc 0.671875
2020-02-08T03:17:52.125936: step 618, loss 0.570099, acc 0.6875
2020-02-08T03:17:52.244794: step 619, loss 0.446561, acc 0.765625
2020-02-08T03:17:52.363323: step 620, loss 0.433432, acc 0.859375
2020-02-08T03:17:52.481077: step 621, loss 0.554478, acc 0.734375
2020-02-08T03:17:52.599683: step 622, loss 0.621581, acc 0.671875
2020-02-08T03:17:52.716641: step 623, loss 0.425068, acc 0.796875
2020-02-08T03:17:52.833022: step 624, loss 0.574874, acc 0.671875
2020-02-08T03:17:52.949752: step 625, loss 0.344227, acc 0.890625
2020-02-08T03:17:53.066130: step 626, loss 0.50606, acc 0.78125
2020-02-08T03:17:53.186462: step 627, loss 0.298249, acc 0.875
2020-02-08T03:17:53.305300: step 628, loss 0.590057, acc 0.734375
2020-02-08T03:17:53.419426: step 629, loss 0.601157, acc 0.65625
2020-02-08T03:17:53.538080: step 630, loss 0.626618, acc 0.71875
2020-02-08T03:17:53.656382: step 631, loss 0.385353, acc 0.859375
2020-02-08T03:17:53.773218: step 632, loss 0.517027, acc 0.703125
2020-02-08T03:17:53.895501: step 633, loss 0.52123, acc 0.734375
2020-02-08T03:17:54.012546: step 634, loss 0.429621, acc 0.8125
2020-02-08T03:17:54.128065: step 635, loss 0.471413, acc 0.71875
2020-02-08T03:17:54.242761: step 636, loss 0.486282, acc 0.765625
2020-02-08T03:17:54.356404: step 637, loss 0.68019, acc 0.65625
2020-02-08T03:17:54.472513: step 638, loss 0.464386, acc 0.78125
2020-02-08T03:17:54.588328: step 639, loss 0.477363, acc 0.765625
2020-02-08T03:17:54.706783: step 640, loss 0.551331, acc 0.65625
2020-02-08T03:17:54.823616: step 641, loss 0.480635, acc 0.765625
2020-02-08T03:17:54.939389: step 642, loss 0.461053, acc 0.8125
2020-02-08T03:17:55.057132: step 643, loss 0.494225, acc 0.796875
2020-02-08T03:17:55.172575: step 644, loss 0.566701, acc 0.71875
2020-02-08T03:17:55.288604: step 645, loss 0.454209, acc 0.765625
2020-02-08T03:17:55.407428: step 646, loss 0.396769, acc 0.875
2020-02-08T03:17:55.522111: step 647, loss 0.57378, acc 0.71875
2020-02-08T03:17:55.639259: step 648, loss 0.631761, acc 0.671875
2020-02-08T03:17:55.756733: step 649, loss 0.460038, acc 0.828125
2020-02-08T03:17:55.876495: step 650, loss 0.432525, acc 0.8125
2020-02-08T03:17:55.995696: step 651, loss 0.473414, acc 0.75
2020-02-08T03:17:56.113417: step 652, loss 0.437781, acc 0.8125
2020-02-08T03:17:56.231912: step 653, loss 0.511268, acc 0.75
2020-02-08T03:17:56.349898: step 654, loss 0.573391, acc 0.671875
2020-02-08T03:17:56.465714: step 655, loss 0.510966, acc 0.765625
2020-02-08T03:17:56.582559: step 656, loss 0.583912, acc 0.703125
2020-02-08T03:17:56.699957: step 657, loss 0.588094, acc 0.6875
2020-02-08T03:17:56.816402: step 658, loss 0.552613, acc 0.78125
2020-02-08T03:17:56.935766: step 659, loss 0.44409, acc 0.828125
2020-02-08T03:17:57.053686: step 660, loss 0.579237, acc 0.703125
2020-02-08T03:17:57.167920: step 661, loss 0.463254, acc 0.765625
2020-02-08T03:17:57.284434: step 662, loss 0.498596, acc 0.796875
2020-02-08T03:17:57.404631: step 663, loss 0.54108, acc 0.75
2020-02-08T03:17:57.519861: step 664, loss 0.413998, acc 0.765625
2020-02-08T03:17:57.637147: step 665, loss 0.730658, acc 0.671875
2020-02-08T03:17:57.753934: step 666, loss 0.47404, acc 0.84375
2020-02-08T03:17:57.870892: step 667, loss 0.615541, acc 0.6875
2020-02-08T03:17:57.990070: step 668, loss 0.512101, acc 0.734375
2020-02-08T03:17:58.105271: step 669, loss 0.50743, acc 0.734375
2020-02-08T03:17:58.220975: step 670, loss 0.34458, acc 0.84375
2020-02-08T03:17:58.335912: step 671, loss 0.467017, acc 0.796875
2020-02-08T03:17:58.455649: step 672, loss 0.475665, acc 0.78125
2020-02-08T03:17:58.573807: step 673, loss 0.41034, acc 0.734375
2020-02-08T03:17:58.692960: step 674, loss 0.506028, acc 0.734375
2020-02-08T03:17:58.810611: step 675, loss 0.475134, acc 0.78125
2020-02-08T03:17:58.927791: step 676, loss 0.504656, acc 0.734375
2020-02-08T03:17:59.045144: step 677, loss 0.415354, acc 0.8125
2020-02-08T03:17:59.160908: step 678, loss 0.56166, acc 0.703125
2020-02-08T03:17:59.273706: step 679, loss 0.572521, acc 0.625
2020-02-08T03:17:59.393038: step 680, loss 0.377075, acc 0.875
2020-02-08T03:17:59.508977: step 681, loss 0.449218, acc 0.8125
2020-02-08T03:17:59.622656: step 682, loss 0.54775, acc 0.703125
2020-02-08T03:17:59.738063: step 683, loss 0.476528, acc 0.828125
2020-02-08T03:17:59.859103: step 684, loss 0.706044, acc 0.640625
2020-02-08T03:17:59.973569: step 685, loss 0.519576, acc 0.734375
2020-02-08T03:18:00.093886: step 686, loss 0.615983, acc 0.734375
2020-02-08T03:18:00.210599: step 687, loss 0.409137, acc 0.84375
2020-02-08T03:18:00.326570: step 688, loss 0.556367, acc 0.75
2020-02-08T03:18:00.446977: step 689, loss 0.427597, acc 0.78125
2020-02-08T03:18:00.561583: step 690, loss 0.551921, acc 0.734375
2020-02-08T03:18:00.674003: step 691, loss 0.409539, acc 0.8125
2020-02-08T03:18:00.793156: step 692, loss 0.532244, acc 0.734375
2020-02-08T03:18:00.908714: step 693, loss 0.524175, acc 0.71875
2020-02-08T03:18:01.022205: step 694, loss 0.45599, acc 0.765625
2020-02-08T03:18:01.137869: step 695, loss 0.612974, acc 0.734375
2020-02-08T03:18:01.258807: step 696, loss 0.357865, acc 0.875
2020-02-08T03:18:01.373803: step 697, loss 0.415823, acc 0.78125
2020-02-08T03:18:01.489916: step 698, loss 0.60104, acc 0.65625
2020-02-08T03:18:01.607930: step 699, loss 0.496897, acc 0.734375
2020-02-08T03:18:01.720797: step 700, loss 0.444797, acc 0.8125

Evaluation:
2020-02-08T03:18:01.913218: step 700, loss 0.596365, acc 0.678236

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-700

2020-02-08T03:18:03.523026: step 701, loss 0.570073, acc 0.75
2020-02-08T03:18:03.641279: step 702, loss 0.572694, acc 0.75
2020-02-08T03:18:03.760910: step 703, loss 0.599967, acc 0.734375
2020-02-08T03:18:03.879931: step 704, loss 0.544484, acc 0.703125
2020-02-08T03:18:04.000694: step 705, loss 0.472022, acc 0.859375
2020-02-08T03:18:04.116173: step 706, loss 0.469284, acc 0.75
2020-02-08T03:18:04.231861: step 707, loss 0.624937, acc 0.6875
2020-02-08T03:18:04.352447: step 708, loss 0.441565, acc 0.796875
2020-02-08T03:18:04.469711: step 709, loss 0.582191, acc 0.65625
2020-02-08T03:18:04.587271: step 710, loss 0.516687, acc 0.828125
2020-02-08T03:18:04.705792: step 711, loss 0.509447, acc 0.765625
2020-02-08T03:18:04.825195: step 712, loss 0.529105, acc 0.703125
2020-02-08T03:18:04.943112: step 713, loss 0.501931, acc 0.765625
2020-02-08T03:18:05.061954: step 714, loss 0.45335, acc 0.78125
2020-02-08T03:18:05.177568: step 715, loss 0.540717, acc 0.765625
2020-02-08T03:18:05.298178: step 716, loss 0.704025, acc 0.671875
2020-02-08T03:18:05.416252: step 717, loss 0.490848, acc 0.734375
2020-02-08T03:18:05.532244: step 718, loss 0.607881, acc 0.734375
2020-02-08T03:18:05.649486: step 719, loss 0.453536, acc 0.796875
2020-02-08T03:18:05.765611: step 720, loss 0.566989, acc 0.765625
2020-02-08T03:18:05.889814: step 721, loss 0.59801, acc 0.734375
2020-02-08T03:18:06.011179: step 722, loss 0.481849, acc 0.765625
2020-02-08T03:18:06.127365: step 723, loss 0.554103, acc 0.734375
2020-02-08T03:18:06.245665: step 724, loss 0.462216, acc 0.78125
2020-02-08T03:18:06.366332: step 725, loss 0.623794, acc 0.6875
2020-02-08T03:18:06.486144: step 726, loss 0.515511, acc 0.734375
2020-02-08T03:18:06.605033: step 727, loss 0.542341, acc 0.734375
2020-02-08T03:18:06.721268: step 728, loss 0.403008, acc 0.828125
2020-02-08T03:18:06.845435: step 729, loss 0.493652, acc 0.78125
2020-02-08T03:18:06.963045: step 730, loss 0.482922, acc 0.75
2020-02-08T03:18:07.077036: step 731, loss 0.523661, acc 0.71875
2020-02-08T03:18:07.193163: step 732, loss 0.430772, acc 0.828125
2020-02-08T03:18:07.311155: step 733, loss 0.632518, acc 0.703125
2020-02-08T03:18:07.426139: step 734, loss 0.588566, acc 0.71875
2020-02-08T03:18:07.545319: step 735, loss 0.476199, acc 0.765625
2020-02-08T03:18:07.662322: step 736, loss 0.494576, acc 0.765625
2020-02-08T03:18:07.779595: step 737, loss 0.532617, acc 0.71875
2020-02-08T03:18:07.898085: step 738, loss 0.479381, acc 0.75
2020-02-08T03:18:08.014154: step 739, loss 0.505965, acc 0.796875
2020-02-08T03:18:08.132536: step 740, loss 0.403651, acc 0.8125
2020-02-08T03:18:08.248728: step 741, loss 0.503533, acc 0.71875
2020-02-08T03:18:08.365611: step 742, loss 0.447292, acc 0.765625
2020-02-08T03:18:08.480682: step 743, loss 0.536355, acc 0.734375
2020-02-08T03:18:08.600221: step 744, loss 0.529611, acc 0.734375
2020-02-08T03:18:08.714907: step 745, loss 0.576429, acc 0.71875
2020-02-08T03:18:08.836734: step 746, loss 0.385503, acc 0.859375
2020-02-08T03:18:08.955606: step 747, loss 0.49332, acc 0.78125
2020-02-08T03:18:09.073873: step 748, loss 0.571059, acc 0.6875
2020-02-08T03:18:09.192129: step 749, loss 0.507191, acc 0.75
2020-02-08T03:18:09.303668: step 750, loss 0.501841, acc 0.766667
2020-02-08T03:18:09.424690: step 751, loss 0.474481, acc 0.796875
2020-02-08T03:18:09.543545: step 752, loss 0.64448, acc 0.6875
2020-02-08T03:18:09.661353: step 753, loss 0.447009, acc 0.796875
2020-02-08T03:18:09.776783: step 754, loss 0.440078, acc 0.8125
2020-02-08T03:18:09.897730: step 755, loss 0.347675, acc 0.828125
2020-02-08T03:18:10.016136: step 756, loss 0.465373, acc 0.75
2020-02-08T03:18:10.135696: step 757, loss 0.434654, acc 0.8125
2020-02-08T03:18:10.250316: step 758, loss 0.546269, acc 0.734375
2020-02-08T03:18:10.367519: step 759, loss 0.420657, acc 0.765625
2020-02-08T03:18:10.487260: step 760, loss 0.512425, acc 0.78125
2020-02-08T03:18:10.605476: step 761, loss 0.460566, acc 0.796875
2020-02-08T03:18:10.724111: step 762, loss 0.42568, acc 0.84375
2020-02-08T03:18:10.844954: step 763, loss 0.384038, acc 0.8125
2020-02-08T03:18:10.962073: step 764, loss 0.435816, acc 0.734375
2020-02-08T03:18:11.077475: step 765, loss 0.503742, acc 0.71875
2020-02-08T03:18:11.191454: step 766, loss 0.443296, acc 0.8125
2020-02-08T03:18:11.309796: step 767, loss 0.484724, acc 0.703125
2020-02-08T03:18:11.429927: step 768, loss 0.450906, acc 0.8125
2020-02-08T03:18:11.546803: step 769, loss 0.329592, acc 0.875
2020-02-08T03:18:11.665538: step 770, loss 0.451057, acc 0.765625
2020-02-08T03:18:11.787023: step 771, loss 0.351917, acc 0.875
2020-02-08T03:18:11.902047: step 772, loss 0.325668, acc 0.859375
2020-02-08T03:18:12.019456: step 773, loss 0.464729, acc 0.796875
2020-02-08T03:18:12.135429: step 774, loss 0.295203, acc 0.859375
2020-02-08T03:18:12.254464: step 775, loss 0.412253, acc 0.828125
2020-02-08T03:18:12.369434: step 776, loss 0.27212, acc 0.90625
2020-02-08T03:18:12.484230: step 777, loss 0.350784, acc 0.78125
2020-02-08T03:18:12.600690: step 778, loss 0.337099, acc 0.828125
2020-02-08T03:18:12.720711: step 779, loss 0.393824, acc 0.859375
2020-02-08T03:18:12.840427: step 780, loss 0.481384, acc 0.765625
2020-02-08T03:18:12.958370: step 781, loss 0.630289, acc 0.65625
2020-02-08T03:18:13.076194: step 782, loss 0.442802, acc 0.78125
2020-02-08T03:18:13.193519: step 783, loss 0.462535, acc 0.78125
2020-02-08T03:18:13.309871: step 784, loss 0.445008, acc 0.796875
2020-02-08T03:18:13.428176: step 785, loss 0.492209, acc 0.765625
2020-02-08T03:18:13.547477: step 786, loss 0.498342, acc 0.78125
2020-02-08T03:18:13.665117: step 787, loss 0.437014, acc 0.796875
2020-02-08T03:18:13.786868: step 788, loss 0.414109, acc 0.8125
2020-02-08T03:18:13.906072: step 789, loss 0.485723, acc 0.734375
2020-02-08T03:18:14.024199: step 790, loss 0.366735, acc 0.875
2020-02-08T03:18:14.140521: step 791, loss 0.427467, acc 0.796875
2020-02-08T03:18:14.257997: step 792, loss 0.459914, acc 0.84375
2020-02-08T03:18:14.372749: step 793, loss 0.44647, acc 0.796875
2020-02-08T03:18:14.492732: step 794, loss 0.426201, acc 0.796875
2020-02-08T03:18:14.611086: step 795, loss 0.419492, acc 0.796875
2020-02-08T03:18:14.723423: step 796, loss 0.410668, acc 0.875
2020-02-08T03:18:14.846117: step 797, loss 0.399868, acc 0.796875
2020-02-08T03:18:14.960503: step 798, loss 0.50808, acc 0.765625
2020-02-08T03:18:15.076581: step 799, loss 0.419476, acc 0.78125
2020-02-08T03:18:15.197618: step 800, loss 0.416718, acc 0.828125

Evaluation:
2020-02-08T03:18:15.383367: step 800, loss 0.596018, acc 0.668856

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-800

2020-02-08T03:18:16.858167: step 801, loss 0.335457, acc 0.84375
2020-02-08T03:18:16.973688: step 802, loss 0.478029, acc 0.796875
2020-02-08T03:18:17.092662: step 803, loss 0.472223, acc 0.765625
2020-02-08T03:18:17.210456: step 804, loss 0.41905, acc 0.796875
2020-02-08T03:18:17.325001: step 805, loss 0.642764, acc 0.71875
2020-02-08T03:18:17.442976: step 806, loss 0.432429, acc 0.84375
2020-02-08T03:18:17.560401: step 807, loss 0.392999, acc 0.84375
2020-02-08T03:18:17.679733: step 808, loss 0.407166, acc 0.796875
2020-02-08T03:18:17.797944: step 809, loss 0.470816, acc 0.75
2020-02-08T03:18:17.917728: step 810, loss 0.433793, acc 0.828125
2020-02-08T03:18:18.033882: step 811, loss 0.456561, acc 0.78125
2020-02-08T03:18:18.151495: step 812, loss 0.465201, acc 0.765625
2020-02-08T03:18:18.266025: step 813, loss 0.375155, acc 0.875
2020-02-08T03:18:18.384016: step 814, loss 0.385717, acc 0.859375
2020-02-08T03:18:18.501240: step 815, loss 0.6141, acc 0.671875
2020-02-08T03:18:18.618411: step 816, loss 0.447354, acc 0.78125
2020-02-08T03:18:18.734172: step 817, loss 0.541744, acc 0.75
2020-02-08T03:18:18.856148: step 818, loss 0.488356, acc 0.765625
2020-02-08T03:18:18.970356: step 819, loss 0.370568, acc 0.890625
2020-02-08T03:18:19.090442: step 820, loss 0.556944, acc 0.65625
2020-02-08T03:18:19.208159: step 821, loss 0.469354, acc 0.765625
2020-02-08T03:18:19.346175: step 822, loss 0.407889, acc 0.828125
2020-02-08T03:18:19.551092: step 823, loss 0.476695, acc 0.78125
2020-02-08T03:18:19.679024: step 824, loss 0.369272, acc 0.8125
2020-02-08T03:18:19.811905: step 825, loss 0.457552, acc 0.859375
2020-02-08T03:18:19.955518: step 826, loss 0.372689, acc 0.765625
2020-02-08T03:18:20.093035: step 827, loss 0.452704, acc 0.84375
2020-02-08T03:18:20.225792: step 828, loss 0.481772, acc 0.78125
2020-02-08T03:18:20.358700: step 829, loss 0.301689, acc 0.875
2020-02-08T03:18:20.492629: step 830, loss 0.526782, acc 0.703125
2020-02-08T03:18:20.624234: step 831, loss 0.355518, acc 0.8125
2020-02-08T03:18:20.757797: step 832, loss 0.432439, acc 0.78125
2020-02-08T03:18:20.901155: step 833, loss 0.426906, acc 0.828125
2020-02-08T03:18:21.030299: step 834, loss 0.420318, acc 0.765625
2020-02-08T03:18:21.162011: step 835, loss 0.434767, acc 0.765625
2020-02-08T03:18:21.289566: step 836, loss 0.451718, acc 0.828125
2020-02-08T03:18:21.594713: step 837, loss 0.472216, acc 0.828125
2020-02-08T03:18:21.739928: step 838, loss 0.368778, acc 0.796875
2020-02-08T03:18:21.875671: step 839, loss 0.35987, acc 0.859375
2020-02-08T03:18:22.012208: step 840, loss 0.421571, acc 0.78125
2020-02-08T03:18:22.150995: step 841, loss 0.465468, acc 0.78125
2020-02-08T03:18:22.282517: step 842, loss 0.452985, acc 0.8125
2020-02-08T03:18:22.420824: step 843, loss 0.505488, acc 0.796875
2020-02-08T03:18:22.560403: step 844, loss 0.330334, acc 0.875
2020-02-08T03:18:22.701787: step 845, loss 0.479913, acc 0.75
2020-02-08T03:18:22.843422: step 846, loss 0.323274, acc 0.875
2020-02-08T03:18:22.995834: step 847, loss 0.483426, acc 0.75
2020-02-08T03:18:23.136167: step 848, loss 0.392338, acc 0.796875
2020-02-08T03:18:23.268155: step 849, loss 0.39303, acc 0.78125
2020-02-08T03:18:23.396383: step 850, loss 0.43513, acc 0.78125
2020-02-08T03:18:23.518849: step 851, loss 0.438659, acc 0.78125
2020-02-08T03:18:23.654517: step 852, loss 0.40711, acc 0.8125
2020-02-08T03:18:23.794484: step 853, loss 0.408716, acc 0.78125
2020-02-08T03:18:23.930817: step 854, loss 0.473741, acc 0.796875
2020-02-08T03:18:24.065720: step 855, loss 0.348213, acc 0.84375
2020-02-08T03:18:24.203579: step 856, loss 0.516667, acc 0.765625
2020-02-08T03:18:24.339845: step 857, loss 0.357359, acc 0.890625
2020-02-08T03:18:24.475382: step 858, loss 0.377765, acc 0.828125
2020-02-08T03:18:24.606198: step 859, loss 0.430829, acc 0.78125
2020-02-08T03:18:24.744901: step 860, loss 0.487656, acc 0.828125
2020-02-08T03:18:24.898002: step 861, loss 0.443357, acc 0.84375
2020-02-08T03:18:25.036096: step 862, loss 0.487959, acc 0.734375
2020-02-08T03:18:25.171905: step 863, loss 0.525365, acc 0.703125
2020-02-08T03:18:25.307659: step 864, loss 0.553723, acc 0.703125
2020-02-08T03:18:25.448967: step 865, loss 0.42496, acc 0.8125
2020-02-08T03:18:25.586787: step 866, loss 0.485607, acc 0.8125
2020-02-08T03:18:25.725238: step 867, loss 0.67309, acc 0.671875
2020-02-08T03:18:25.862888: step 868, loss 0.458246, acc 0.796875
2020-02-08T03:18:26.006025: step 869, loss 0.296296, acc 0.859375
2020-02-08T03:18:26.146683: step 870, loss 0.444017, acc 0.78125
2020-02-08T03:18:26.284034: step 871, loss 0.416761, acc 0.84375
2020-02-08T03:18:26.419975: step 872, loss 0.40543, acc 0.8125
2020-02-08T03:18:26.557195: step 873, loss 0.574293, acc 0.75
2020-02-08T03:18:26.688026: step 874, loss 0.414993, acc 0.765625
2020-02-08T03:18:26.820355: step 875, loss 0.393921, acc 0.828125
2020-02-08T03:18:26.956450: step 876, loss 0.404401, acc 0.828125
2020-02-08T03:18:27.088332: step 877, loss 0.460638, acc 0.8125
2020-02-08T03:18:27.211998: step 878, loss 0.464762, acc 0.828125
2020-02-08T03:18:27.341441: step 879, loss 0.704527, acc 0.671875
2020-02-08T03:18:27.467577: step 880, loss 0.501395, acc 0.828125
2020-02-08T03:18:27.594662: step 881, loss 0.414681, acc 0.75
2020-02-08T03:18:27.720137: step 882, loss 0.468746, acc 0.78125
2020-02-08T03:18:27.864662: step 883, loss 0.448697, acc 0.78125
2020-02-08T03:18:28.006547: step 884, loss 0.353874, acc 0.828125
2020-02-08T03:18:28.142977: step 885, loss 0.54665, acc 0.71875
2020-02-08T03:18:28.285860: step 886, loss 0.478598, acc 0.765625
2020-02-08T03:18:28.414194: step 887, loss 0.482236, acc 0.765625
2020-02-08T03:18:28.538218: step 888, loss 0.567174, acc 0.640625
2020-02-08T03:18:28.663731: step 889, loss 0.370056, acc 0.84375
2020-02-08T03:18:28.788112: step 890, loss 0.448544, acc 0.78125
2020-02-08T03:18:28.911370: step 891, loss 0.502429, acc 0.765625
2020-02-08T03:18:29.029799: step 892, loss 0.48654, acc 0.8125
2020-02-08T03:18:29.151603: step 893, loss 0.501616, acc 0.75
2020-02-08T03:18:29.273694: step 894, loss 0.513734, acc 0.734375
2020-02-08T03:18:29.392167: step 895, loss 0.3914, acc 0.8125
2020-02-08T03:18:29.508219: step 896, loss 0.32669, acc 0.84375
2020-02-08T03:18:29.640540: step 897, loss 0.499526, acc 0.765625
2020-02-08T03:18:29.757616: step 898, loss 0.40447, acc 0.8125
2020-02-08T03:18:29.877100: step 899, loss 0.380807, acc 0.8125
2020-02-08T03:18:29.992895: step 900, loss 0.503069, acc 0.783333

Evaluation:
2020-02-08T03:18:30.182454: step 900, loss 0.601384, acc 0.659475

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-900

2020-02-08T03:18:32.058488: step 901, loss 0.337277, acc 0.875
2020-02-08T03:18:32.173823: step 902, loss 0.466287, acc 0.75
2020-02-08T03:18:32.290078: step 903, loss 0.247172, acc 0.9375
2020-02-08T03:18:32.407566: step 904, loss 0.330693, acc 0.875
2020-02-08T03:18:32.522438: step 905, loss 0.42286, acc 0.84375
2020-02-08T03:18:32.640605: step 906, loss 0.383711, acc 0.796875
2020-02-08T03:18:32.757552: step 907, loss 0.340754, acc 0.828125
2020-02-08T03:18:32.874834: step 908, loss 0.458234, acc 0.78125
2020-02-08T03:18:32.994933: step 909, loss 0.428403, acc 0.796875
2020-02-08T03:18:33.112762: step 910, loss 0.401998, acc 0.859375
2020-02-08T03:18:33.228841: step 911, loss 0.364953, acc 0.84375
2020-02-08T03:18:33.347097: step 912, loss 0.356538, acc 0.84375
2020-02-08T03:18:33.463823: step 913, loss 0.315614, acc 0.859375
2020-02-08T03:18:33.582697: step 914, loss 0.3584, acc 0.828125
2020-02-08T03:18:33.701132: step 915, loss 0.364802, acc 0.796875
2020-02-08T03:18:33.819888: step 916, loss 0.377005, acc 0.765625
2020-02-08T03:18:33.937022: step 917, loss 0.39341, acc 0.796875
2020-02-08T03:18:34.055790: step 918, loss 0.461156, acc 0.78125
2020-02-08T03:18:34.169022: step 919, loss 0.346643, acc 0.84375
2020-02-08T03:18:34.285848: step 920, loss 0.3286, acc 0.90625
2020-02-08T03:18:34.403516: step 921, loss 0.343276, acc 0.859375
2020-02-08T03:18:34.522913: step 922, loss 0.336442, acc 0.890625
2020-02-08T03:18:34.641434: step 923, loss 0.404651, acc 0.8125
2020-02-08T03:18:34.764039: step 924, loss 0.46726, acc 0.734375
2020-02-08T03:18:34.884967: step 925, loss 0.392286, acc 0.8125
2020-02-08T03:18:35.002289: step 926, loss 0.621492, acc 0.671875
2020-02-08T03:18:35.117858: step 927, loss 0.461842, acc 0.75
2020-02-08T03:18:35.237875: step 928, loss 0.306755, acc 0.859375
2020-02-08T03:18:35.352920: step 929, loss 0.357306, acc 0.859375
2020-02-08T03:18:35.469331: step 930, loss 0.333049, acc 0.859375
2020-02-08T03:18:35.586034: step 931, loss 0.558928, acc 0.75
2020-02-08T03:18:35.703585: step 932, loss 0.528381, acc 0.734375
2020-02-08T03:18:35.820272: step 933, loss 0.280593, acc 0.921875
2020-02-08T03:18:35.939980: step 934, loss 0.341998, acc 0.828125
2020-02-08T03:18:36.057377: step 935, loss 0.375069, acc 0.8125
2020-02-08T03:18:36.169028: step 936, loss 0.289902, acc 0.890625
2020-02-08T03:18:36.287193: step 937, loss 0.395975, acc 0.8125
2020-02-08T03:18:36.403603: step 938, loss 0.372526, acc 0.84375
2020-02-08T03:18:36.519812: step 939, loss 0.256566, acc 0.90625
2020-02-08T03:18:36.639178: step 940, loss 0.433207, acc 0.8125
2020-02-08T03:18:36.755656: step 941, loss 0.301479, acc 0.859375
2020-02-08T03:18:36.874176: step 942, loss 0.460113, acc 0.78125
2020-02-08T03:18:36.990074: step 943, loss 0.322453, acc 0.828125
2020-02-08T03:18:37.106695: step 944, loss 0.292904, acc 0.890625
2020-02-08T03:18:37.219949: step 945, loss 0.407922, acc 0.890625
2020-02-08T03:18:37.334455: step 946, loss 0.342998, acc 0.859375
2020-02-08T03:18:37.450174: step 947, loss 0.284188, acc 0.890625
2020-02-08T03:18:37.563990: step 948, loss 0.475684, acc 0.78125
2020-02-08T03:18:37.677963: step 949, loss 0.299469, acc 0.875
2020-02-08T03:18:37.792327: step 950, loss 0.363688, acc 0.859375
2020-02-08T03:18:37.911577: step 951, loss 0.431971, acc 0.84375
2020-02-08T03:18:38.026300: step 952, loss 0.385478, acc 0.8125
2020-02-08T03:18:38.143933: step 953, loss 0.452728, acc 0.765625
2020-02-08T03:18:38.260236: step 954, loss 0.350329, acc 0.8125
2020-02-08T03:18:38.375785: step 955, loss 0.425681, acc 0.84375
2020-02-08T03:18:38.493430: step 956, loss 0.428654, acc 0.84375
2020-02-08T03:18:38.608324: step 957, loss 0.489794, acc 0.796875
2020-02-08T03:18:38.723597: step 958, loss 0.337957, acc 0.8125
2020-02-08T03:18:38.842623: step 959, loss 0.510354, acc 0.765625
2020-02-08T03:18:38.959028: step 960, loss 0.263294, acc 0.90625
2020-02-08T03:18:39.074787: step 961, loss 0.411818, acc 0.84375
2020-02-08T03:18:39.193167: step 962, loss 0.293692, acc 0.84375
2020-02-08T03:18:39.309193: step 963, loss 0.34861, acc 0.8125
2020-02-08T03:18:39.422149: step 964, loss 0.341016, acc 0.796875
2020-02-08T03:18:39.539921: step 965, loss 0.373111, acc 0.859375
2020-02-08T03:18:39.655633: step 966, loss 0.460943, acc 0.828125
2020-02-08T03:18:39.769958: step 967, loss 0.405371, acc 0.78125
2020-02-08T03:18:39.888324: step 968, loss 0.411552, acc 0.8125
2020-02-08T03:18:40.002426: step 969, loss 0.436932, acc 0.828125
2020-02-08T03:18:40.118750: step 970, loss 0.354218, acc 0.828125
2020-02-08T03:18:40.235712: step 971, loss 0.49247, acc 0.765625
2020-02-08T03:18:40.352231: step 972, loss 0.379797, acc 0.828125
2020-02-08T03:18:40.469130: step 973, loss 0.383455, acc 0.8125
2020-02-08T03:18:40.584719: step 974, loss 0.377056, acc 0.859375
2020-02-08T03:18:40.699749: step 975, loss 0.348381, acc 0.828125
2020-02-08T03:18:40.814492: step 976, loss 0.31377, acc 0.84375
2020-02-08T03:18:40.931003: step 977, loss 0.512356, acc 0.703125
2020-02-08T03:18:41.048154: step 978, loss 0.312227, acc 0.875
2020-02-08T03:18:41.164843: step 979, loss 0.383109, acc 0.890625
2020-02-08T03:18:41.281569: step 980, loss 0.315825, acc 0.875
2020-02-08T03:18:41.397305: step 981, loss 0.323076, acc 0.84375
2020-02-08T03:18:41.514742: step 982, loss 0.374793, acc 0.84375
2020-02-08T03:18:41.631817: step 983, loss 0.339028, acc 0.828125
2020-02-08T03:18:41.749655: step 984, loss 0.339597, acc 0.84375
2020-02-08T03:18:41.869274: step 985, loss 0.381009, acc 0.875
2020-02-08T03:18:41.986061: step 986, loss 0.34762, acc 0.828125
2020-02-08T03:18:42.103817: step 987, loss 0.347273, acc 0.875
2020-02-08T03:18:42.219226: step 988, loss 0.352772, acc 0.875
2020-02-08T03:18:42.341607: step 989, loss 0.358373, acc 0.8125
2020-02-08T03:18:42.457315: step 990, loss 0.328961, acc 0.84375
2020-02-08T03:18:42.574462: step 991, loss 0.279815, acc 0.84375
2020-02-08T03:18:42.691613: step 992, loss 0.428631, acc 0.78125
2020-02-08T03:18:42.808801: step 993, loss 0.335374, acc 0.8125
2020-02-08T03:18:42.923364: step 994, loss 0.429549, acc 0.796875
2020-02-08T03:18:43.038669: step 995, loss 0.297746, acc 0.890625
2020-02-08T03:18:43.155482: step 996, loss 0.36942, acc 0.8125
2020-02-08T03:18:43.267456: step 997, loss 0.351828, acc 0.828125
2020-02-08T03:18:43.381961: step 998, loss 0.368528, acc 0.8125
2020-02-08T03:18:43.501279: step 999, loss 0.267368, acc 0.921875
2020-02-08T03:18:43.616933: step 1000, loss 0.345356, acc 0.859375

Evaluation:
2020-02-08T03:18:43.804890: step 1000, loss 0.583132, acc 0.707317

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1000

2020-02-08T03:18:45.325855: step 1001, loss 0.358711, acc 0.78125
2020-02-08T03:18:45.442353: step 1002, loss 0.373448, acc 0.859375
2020-02-08T03:18:45.557395: step 1003, loss 0.52439, acc 0.75
2020-02-08T03:18:45.673021: step 1004, loss 0.383464, acc 0.84375
2020-02-08T03:18:45.791856: step 1005, loss 0.375449, acc 0.875
2020-02-08T03:18:45.909792: step 1006, loss 0.388196, acc 0.859375
2020-02-08T03:18:46.026978: step 1007, loss 0.367332, acc 0.84375
2020-02-08T03:18:46.144824: step 1008, loss 0.529211, acc 0.734375
2020-02-08T03:18:46.259305: step 1009, loss 0.39756, acc 0.796875
2020-02-08T03:18:46.371909: step 1010, loss 0.48659, acc 0.859375
2020-02-08T03:18:46.492282: step 1011, loss 0.362565, acc 0.8125
2020-02-08T03:18:46.611069: step 1012, loss 0.402315, acc 0.8125
2020-02-08T03:18:46.725303: step 1013, loss 0.36665, acc 0.84375
2020-02-08T03:18:46.848423: step 1014, loss 0.301617, acc 0.90625
2020-02-08T03:18:46.963605: step 1015, loss 0.536489, acc 0.8125
2020-02-08T03:18:47.081702: step 1016, loss 0.349213, acc 0.875
2020-02-08T03:18:47.201200: step 1017, loss 0.256388, acc 0.921875
2020-02-08T03:18:47.317302: step 1018, loss 0.573642, acc 0.765625
2020-02-08T03:18:47.434395: step 1019, loss 0.334013, acc 0.859375
2020-02-08T03:18:47.552915: step 1020, loss 0.360503, acc 0.828125
2020-02-08T03:18:47.669340: step 1021, loss 0.412633, acc 0.8125
2020-02-08T03:18:47.786665: step 1022, loss 0.274125, acc 0.875
2020-02-08T03:18:47.902587: step 1023, loss 0.369232, acc 0.859375
2020-02-08T03:18:48.018909: step 1024, loss 0.344707, acc 0.859375
2020-02-08T03:18:48.136766: step 1025, loss 0.46189, acc 0.765625
2020-02-08T03:18:48.252439: step 1026, loss 0.355809, acc 0.890625
2020-02-08T03:18:48.368181: step 1027, loss 0.432847, acc 0.8125
2020-02-08T03:18:48.483301: step 1028, loss 0.325519, acc 0.875
2020-02-08T03:18:48.601962: step 1029, loss 0.342499, acc 0.90625
2020-02-08T03:18:48.718434: step 1030, loss 0.336981, acc 0.828125
2020-02-08T03:18:48.836710: step 1031, loss 0.322836, acc 0.875
2020-02-08T03:18:48.951374: step 1032, loss 0.456624, acc 0.71875
2020-02-08T03:18:49.068200: step 1033, loss 0.370386, acc 0.828125
2020-02-08T03:18:49.181102: step 1034, loss 0.398968, acc 0.84375
2020-02-08T03:18:49.298327: step 1035, loss 0.453176, acc 0.8125
2020-02-08T03:18:49.413792: step 1036, loss 0.316522, acc 0.875
2020-02-08T03:18:49.529544: step 1037, loss 0.38442, acc 0.859375
2020-02-08T03:18:49.648830: step 1038, loss 0.341674, acc 0.84375
2020-02-08T03:18:49.764949: step 1039, loss 0.399638, acc 0.828125
2020-02-08T03:18:49.884115: step 1040, loss 0.47174, acc 0.828125
2020-02-08T03:18:50.001634: step 1041, loss 0.485916, acc 0.765625
2020-02-08T03:18:50.117773: step 1042, loss 0.326707, acc 0.875
2020-02-08T03:18:50.232713: step 1043, loss 0.394968, acc 0.859375
2020-02-08T03:18:50.349835: step 1044, loss 0.528606, acc 0.765625
2020-02-08T03:18:50.467275: step 1045, loss 0.32047, acc 0.84375
2020-02-08T03:18:50.582023: step 1046, loss 0.324282, acc 0.8125
2020-02-08T03:18:50.697760: step 1047, loss 0.418164, acc 0.8125
2020-02-08T03:18:50.815035: step 1048, loss 0.432127, acc 0.828125
2020-02-08T03:18:50.934669: step 1049, loss 0.332025, acc 0.859375
2020-02-08T03:18:51.048717: step 1050, loss 0.375761, acc 0.816667
2020-02-08T03:18:51.166749: step 1051, loss 0.301028, acc 0.84375
2020-02-08T03:18:51.280956: step 1052, loss 0.243261, acc 0.9375
2020-02-08T03:18:51.401499: step 1053, loss 0.245622, acc 0.921875
2020-02-08T03:18:51.516470: step 1054, loss 0.367635, acc 0.84375
2020-02-08T03:18:51.689013: step 1055, loss 0.367522, acc 0.828125
2020-02-08T03:18:51.812736: step 1056, loss 0.275523, acc 0.890625
2020-02-08T03:18:51.928861: step 1057, loss 0.193485, acc 0.953125
2020-02-08T03:18:52.047888: step 1058, loss 0.391807, acc 0.828125
2020-02-08T03:18:52.163867: step 1059, loss 0.299335, acc 0.828125
2020-02-08T03:18:52.279248: step 1060, loss 0.262775, acc 0.90625
2020-02-08T03:18:52.396541: step 1061, loss 0.338743, acc 0.84375
2020-02-08T03:18:52.512046: step 1062, loss 0.275945, acc 0.890625
2020-02-08T03:18:52.627113: step 1063, loss 0.311907, acc 0.875
2020-02-08T03:18:52.745714: step 1064, loss 0.259871, acc 0.90625
2020-02-08T03:18:52.864114: step 1065, loss 0.304433, acc 0.859375
2020-02-08T03:18:52.979485: step 1066, loss 0.21508, acc 0.9375
2020-02-08T03:18:53.095102: step 1067, loss 0.379972, acc 0.8125
2020-02-08T03:18:53.211516: step 1068, loss 0.178147, acc 0.9375
2020-02-08T03:18:53.328306: step 1069, loss 0.35281, acc 0.8125
2020-02-08T03:18:53.447617: step 1070, loss 0.295291, acc 0.90625
2020-02-08T03:18:53.564767: step 1071, loss 0.296735, acc 0.84375
2020-02-08T03:18:53.680790: step 1072, loss 0.438688, acc 0.8125
2020-02-08T03:18:53.798141: step 1073, loss 0.331506, acc 0.828125
2020-02-08T03:18:53.914900: step 1074, loss 0.351809, acc 0.84375
2020-02-08T03:18:54.030551: step 1075, loss 0.272941, acc 0.890625
2020-02-08T03:18:54.146278: step 1076, loss 0.386627, acc 0.8125
2020-02-08T03:18:54.263056: step 1077, loss 0.263999, acc 0.890625
2020-02-08T03:18:54.376254: step 1078, loss 0.230485, acc 0.890625
2020-02-08T03:18:54.494305: step 1079, loss 0.357909, acc 0.8125
2020-02-08T03:18:54.610691: step 1080, loss 0.308073, acc 0.859375
2020-02-08T03:18:54.728690: step 1081, loss 0.277973, acc 0.890625
2020-02-08T03:18:54.846724: step 1082, loss 0.5242, acc 0.8125
2020-02-08T03:18:54.964136: step 1083, loss 0.326355, acc 0.90625
2020-02-08T03:18:55.079714: step 1084, loss 0.357568, acc 0.84375
2020-02-08T03:18:55.196475: step 1085, loss 0.558956, acc 0.734375
2020-02-08T03:18:55.311904: step 1086, loss 0.265029, acc 0.9375
2020-02-08T03:18:55.426242: step 1087, loss 0.26265, acc 0.921875
2020-02-08T03:18:55.544186: step 1088, loss 0.341162, acc 0.90625
2020-02-08T03:18:55.657732: step 1089, loss 0.20492, acc 0.875
2020-02-08T03:18:55.772901: step 1090, loss 0.210726, acc 0.921875
2020-02-08T03:18:55.889826: step 1091, loss 0.34324, acc 0.859375
2020-02-08T03:18:56.007800: step 1092, loss 0.254912, acc 0.890625
2020-02-08T03:18:56.127622: step 1093, loss 0.345787, acc 0.875
2020-02-08T03:18:56.244314: step 1094, loss 0.254271, acc 0.90625
2020-02-08T03:18:56.361130: step 1095, loss 0.305447, acc 0.921875
2020-02-08T03:18:56.479926: step 1096, loss 0.361049, acc 0.796875
2020-02-08T03:18:56.595862: step 1097, loss 0.285534, acc 0.859375
2020-02-08T03:18:56.710665: step 1098, loss 0.38309, acc 0.84375
2020-02-08T03:18:56.830579: step 1099, loss 0.416565, acc 0.828125
2020-02-08T03:18:56.947438: step 1100, loss 0.267157, acc 0.890625

Evaluation:
2020-02-08T03:18:57.134939: step 1100, loss 0.588332, acc 0.694184

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1100

2020-02-08T03:18:58.648002: step 1101, loss 0.266844, acc 0.875
2020-02-08T03:18:58.765219: step 1102, loss 0.411767, acc 0.859375
2020-02-08T03:18:58.879989: step 1103, loss 0.291938, acc 0.84375
2020-02-08T03:18:58.998435: step 1104, loss 0.394382, acc 0.84375
2020-02-08T03:18:59.114724: step 1105, loss 0.288459, acc 0.875
2020-02-08T03:18:59.230764: step 1106, loss 0.268247, acc 0.90625
2020-02-08T03:18:59.348896: step 1107, loss 0.361093, acc 0.890625
2020-02-08T03:18:59.468951: step 1108, loss 0.290651, acc 0.9375
2020-02-08T03:18:59.588335: step 1109, loss 0.262661, acc 0.90625
2020-02-08T03:18:59.708621: step 1110, loss 0.489864, acc 0.78125
2020-02-08T03:18:59.827019: step 1111, loss 0.302355, acc 0.875
2020-02-08T03:18:59.942857: step 1112, loss 0.408162, acc 0.796875
2020-02-08T03:19:00.060889: step 1113, loss 0.348026, acc 0.84375
2020-02-08T03:19:00.175705: step 1114, loss 0.334492, acc 0.8125
2020-02-08T03:19:00.291120: step 1115, loss 0.320254, acc 0.84375
2020-02-08T03:19:00.405976: step 1116, loss 0.336309, acc 0.84375
2020-02-08T03:19:00.520908: step 1117, loss 0.309937, acc 0.859375
2020-02-08T03:19:00.635049: step 1118, loss 0.321956, acc 0.859375
2020-02-08T03:19:00.754908: step 1119, loss 0.240358, acc 0.859375
2020-02-08T03:19:00.874280: step 1120, loss 0.412213, acc 0.828125
2020-02-08T03:19:00.996508: step 1121, loss 0.340502, acc 0.890625
2020-02-08T03:19:01.113313: step 1122, loss 0.279217, acc 0.890625
2020-02-08T03:19:01.229280: step 1123, loss 0.414766, acc 0.765625
2020-02-08T03:19:01.347554: step 1124, loss 0.384918, acc 0.828125
2020-02-08T03:19:01.464604: step 1125, loss 0.293391, acc 0.890625
2020-02-08T03:19:01.579636: step 1126, loss 0.327669, acc 0.890625
2020-02-08T03:19:01.696316: step 1127, loss 0.324296, acc 0.859375
2020-02-08T03:19:01.813044: step 1128, loss 0.330766, acc 0.84375
2020-02-08T03:19:01.929759: step 1129, loss 0.416636, acc 0.8125
2020-02-08T03:19:02.046781: step 1130, loss 0.337472, acc 0.875
2020-02-08T03:19:02.163262: step 1131, loss 0.338872, acc 0.859375
2020-02-08T03:19:02.289466: step 1132, loss 0.318553, acc 0.875
2020-02-08T03:19:02.433242: step 1133, loss 0.304086, acc 0.875
2020-02-08T03:19:02.579072: step 1134, loss 0.381122, acc 0.84375
2020-02-08T03:19:02.707630: step 1135, loss 0.377164, acc 0.796875
2020-02-08T03:19:02.825732: step 1136, loss 0.293017, acc 0.875
2020-02-08T03:19:02.945084: step 1137, loss 0.271509, acc 0.890625
2020-02-08T03:19:03.066029: step 1138, loss 0.236967, acc 0.890625
2020-02-08T03:19:03.181381: step 1139, loss 0.350066, acc 0.84375
2020-02-08T03:19:03.306312: step 1140, loss 0.17939, acc 0.953125
2020-02-08T03:19:03.447504: step 1141, loss 0.219909, acc 0.921875
2020-02-08T03:19:03.568323: step 1142, loss 0.366059, acc 0.859375
2020-02-08T03:19:03.695705: step 1143, loss 0.251249, acc 0.875
2020-02-08T03:19:03.849197: step 1144, loss 0.376877, acc 0.828125
2020-02-08T03:19:03.967425: step 1145, loss 0.307823, acc 0.859375
2020-02-08T03:19:04.083271: step 1146, loss 0.317824, acc 0.828125
2020-02-08T03:19:04.201270: step 1147, loss 0.316605, acc 0.90625
2020-02-08T03:19:04.317383: step 1148, loss 0.271022, acc 0.859375
2020-02-08T03:19:04.433200: step 1149, loss 0.373763, acc 0.8125
2020-02-08T03:19:04.552348: step 1150, loss 0.397078, acc 0.828125
2020-02-08T03:19:04.669016: step 1151, loss 0.302584, acc 0.890625
2020-02-08T03:19:04.786624: step 1152, loss 0.356815, acc 0.8125
2020-02-08T03:19:04.905216: step 1153, loss 0.321787, acc 0.84375
2020-02-08T03:19:05.022823: step 1154, loss 0.221619, acc 0.90625
2020-02-08T03:19:05.135957: step 1155, loss 0.335947, acc 0.796875
2020-02-08T03:19:05.253073: step 1156, loss 0.344717, acc 0.890625
2020-02-08T03:19:05.370241: step 1157, loss 0.463074, acc 0.796875
2020-02-08T03:19:05.490448: step 1158, loss 0.382707, acc 0.828125
2020-02-08T03:19:05.608873: step 1159, loss 0.346968, acc 0.875
2020-02-08T03:19:05.723709: step 1160, loss 0.476832, acc 0.84375
2020-02-08T03:19:05.843578: step 1161, loss 0.233982, acc 0.890625
2020-02-08T03:19:05.960651: step 1162, loss 0.250298, acc 0.890625
2020-02-08T03:19:06.075372: step 1163, loss 0.284773, acc 0.90625
2020-02-08T03:19:06.193675: step 1164, loss 0.372398, acc 0.859375
2020-02-08T03:19:06.312582: step 1165, loss 0.242714, acc 0.875
2020-02-08T03:19:06.431567: step 1166, loss 0.183178, acc 0.9375
2020-02-08T03:19:06.549715: step 1167, loss 0.447285, acc 0.8125
2020-02-08T03:19:06.665884: step 1168, loss 0.381377, acc 0.828125
2020-02-08T03:19:06.784099: step 1169, loss 0.274218, acc 0.890625
2020-02-08T03:19:06.905461: step 1170, loss 0.371547, acc 0.84375
2020-02-08T03:19:07.022229: step 1171, loss 0.321374, acc 0.875
2020-02-08T03:19:07.142430: step 1172, loss 0.236543, acc 0.921875
2020-02-08T03:19:07.257692: step 1173, loss 0.464042, acc 0.796875
2020-02-08T03:19:07.372817: step 1174, loss 0.365695, acc 0.828125
2020-02-08T03:19:07.487038: step 1175, loss 0.332774, acc 0.859375
2020-02-08T03:19:07.602741: step 1176, loss 0.243458, acc 0.875
2020-02-08T03:19:07.716312: step 1177, loss 0.293361, acc 0.890625
2020-02-08T03:19:07.833501: step 1178, loss 0.42316, acc 0.828125
2020-02-08T03:19:07.951480: step 1179, loss 0.430582, acc 0.828125
2020-02-08T03:19:08.068362: step 1180, loss 0.434372, acc 0.8125
2020-02-08T03:19:08.184060: step 1181, loss 0.268778, acc 0.890625
2020-02-08T03:19:08.302210: step 1182, loss 0.352673, acc 0.859375
2020-02-08T03:19:08.417474: step 1183, loss 0.214996, acc 0.875
2020-02-08T03:19:08.535059: step 1184, loss 0.365151, acc 0.796875
2020-02-08T03:19:08.653863: step 1185, loss 0.33404, acc 0.84375
2020-02-08T03:19:08.773357: step 1186, loss 0.235695, acc 0.90625
2020-02-08T03:19:08.890189: step 1187, loss 0.341172, acc 0.875
2020-02-08T03:19:09.007826: step 1188, loss 0.30799, acc 0.859375
2020-02-08T03:19:09.127526: step 1189, loss 0.361587, acc 0.828125
2020-02-08T03:19:09.245773: step 1190, loss 0.28872, acc 0.90625
2020-02-08T03:19:09.362539: step 1191, loss 0.322933, acc 0.890625
2020-02-08T03:19:09.479684: step 1192, loss 0.253979, acc 0.890625
2020-02-08T03:19:09.596360: step 1193, loss 0.34833, acc 0.84375
2020-02-08T03:19:09.713455: step 1194, loss 0.308153, acc 0.875
2020-02-08T03:19:09.832878: step 1195, loss 0.283062, acc 0.875
2020-02-08T03:19:09.954633: step 1196, loss 0.365094, acc 0.875
2020-02-08T03:19:10.070918: step 1197, loss 0.325215, acc 0.90625
2020-02-08T03:19:10.186853: step 1198, loss 0.427401, acc 0.828125
2020-02-08T03:19:10.304013: step 1199, loss 0.390142, acc 0.84375
2020-02-08T03:19:10.416075: step 1200, loss 0.355165, acc 0.816667

Evaluation:
2020-02-08T03:19:10.604756: step 1200, loss 0.586414, acc 0.703565

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1200

2020-02-08T03:19:12.052254: step 1201, loss 0.225794, acc 0.890625
2020-02-08T03:19:12.170091: step 1202, loss 0.228944, acc 0.890625
2020-02-08T03:19:12.287138: step 1203, loss 0.280375, acc 0.890625
2020-02-08T03:19:12.405093: step 1204, loss 0.185808, acc 0.921875
2020-02-08T03:19:12.521765: step 1205, loss 0.313772, acc 0.875
2020-02-08T03:19:12.637552: step 1206, loss 0.205342, acc 0.921875
2020-02-08T03:19:12.756135: step 1207, loss 0.202115, acc 0.90625
2020-02-08T03:19:12.872584: step 1208, loss 0.253945, acc 0.875
2020-02-08T03:19:12.990429: step 1209, loss 0.26837, acc 0.90625
2020-02-08T03:19:13.108116: step 1210, loss 0.351377, acc 0.875
2020-02-08T03:19:13.221819: step 1211, loss 0.34086, acc 0.859375
2020-02-08T03:19:13.339685: step 1212, loss 0.288166, acc 0.890625
2020-02-08T03:19:13.456010: step 1213, loss 0.215371, acc 0.90625
2020-02-08T03:19:13.572433: step 1214, loss 0.180965, acc 0.890625
2020-02-08T03:19:13.690805: step 1215, loss 0.290502, acc 0.859375
2020-02-08T03:19:13.808275: step 1216, loss 0.392147, acc 0.8125
2020-02-08T03:19:13.924834: step 1217, loss 0.20667, acc 0.90625
2020-02-08T03:19:14.042477: step 1218, loss 0.21418, acc 0.9375
2020-02-08T03:19:14.160104: step 1219, loss 0.209152, acc 0.921875
2020-02-08T03:19:14.275730: step 1220, loss 0.172551, acc 0.953125
2020-02-08T03:19:14.394514: step 1221, loss 0.206634, acc 0.921875
2020-02-08T03:19:14.511662: step 1222, loss 0.275081, acc 0.921875
2020-02-08T03:19:14.625074: step 1223, loss 0.24498, acc 0.890625
2020-02-08T03:19:14.744708: step 1224, loss 0.264835, acc 0.875
2020-02-08T03:19:14.863335: step 1225, loss 0.225101, acc 0.90625
2020-02-08T03:19:14.976512: step 1226, loss 0.247866, acc 0.875
2020-02-08T03:19:15.093910: step 1227, loss 0.154219, acc 0.953125
2020-02-08T03:19:15.211596: step 1228, loss 0.250467, acc 0.890625
2020-02-08T03:19:15.326967: step 1229, loss 0.157481, acc 0.921875
2020-02-08T03:19:15.442571: step 1230, loss 0.252449, acc 0.859375
2020-02-08T03:19:15.557579: step 1231, loss 0.354031, acc 0.875
2020-02-08T03:19:15.673835: step 1232, loss 0.217445, acc 0.9375
2020-02-08T03:19:15.791776: step 1233, loss 0.242121, acc 0.90625
2020-02-08T03:19:15.909116: step 1234, loss 0.216061, acc 0.90625
2020-02-08T03:19:16.024309: step 1235, loss 0.296563, acc 0.890625
2020-02-08T03:19:16.139579: step 1236, loss 0.255427, acc 0.890625
2020-02-08T03:19:16.256022: step 1237, loss 0.267098, acc 0.875
2020-02-08T03:19:16.374342: step 1238, loss 0.188257, acc 0.953125
2020-02-08T03:19:16.491805: step 1239, loss 0.269113, acc 0.890625
2020-02-08T03:19:16.608332: step 1240, loss 0.249173, acc 0.90625
2020-02-08T03:19:16.723247: step 1241, loss 0.299932, acc 0.84375
2020-02-08T03:19:16.840878: step 1242, loss 0.239846, acc 0.90625
2020-02-08T03:19:16.960752: step 1243, loss 0.197459, acc 0.90625
2020-02-08T03:19:17.077918: step 1244, loss 0.247457, acc 0.890625
2020-02-08T03:19:17.192130: step 1245, loss 0.215994, acc 0.9375
2020-02-08T03:19:17.309034: step 1246, loss 0.299086, acc 0.875
2020-02-08T03:19:17.423024: step 1247, loss 0.292565, acc 0.890625
2020-02-08T03:19:17.542092: step 1248, loss 0.253673, acc 0.890625
2020-02-08T03:19:17.662269: step 1249, loss 0.328119, acc 0.828125
2020-02-08T03:19:17.779210: step 1250, loss 0.171374, acc 0.953125
2020-02-08T03:19:17.901926: step 1251, loss 0.149624, acc 0.9375
2020-02-08T03:19:18.018991: step 1252, loss 0.216306, acc 0.9375
2020-02-08T03:19:18.135946: step 1253, loss 0.22837, acc 0.9375
2020-02-08T03:19:18.252668: step 1254, loss 0.21369, acc 0.921875
2020-02-08T03:19:18.368595: step 1255, loss 0.223515, acc 0.890625
2020-02-08T03:19:18.484609: step 1256, loss 0.24103, acc 0.921875
2020-02-08T03:19:18.608095: step 1257, loss 0.125665, acc 0.984375
2020-02-08T03:19:18.724160: step 1258, loss 0.395241, acc 0.78125
2020-02-08T03:19:18.840701: step 1259, loss 0.30466, acc 0.859375
2020-02-08T03:19:18.961264: step 1260, loss 0.150769, acc 0.953125
2020-02-08T03:19:19.076241: step 1261, loss 0.197161, acc 0.90625
2020-02-08T03:19:19.194594: step 1262, loss 0.23181, acc 0.9375
2020-02-08T03:19:19.310511: step 1263, loss 0.336546, acc 0.859375
2020-02-08T03:19:19.428014: step 1264, loss 0.317737, acc 0.828125
2020-02-08T03:19:19.548065: step 1265, loss 0.404614, acc 0.84375
2020-02-08T03:19:19.665336: step 1266, loss 0.230819, acc 0.890625
2020-02-08T03:19:19.784183: step 1267, loss 0.405845, acc 0.8125
2020-02-08T03:19:19.903403: step 1268, loss 0.304366, acc 0.90625
2020-02-08T03:19:20.019987: step 1269, loss 0.279754, acc 0.890625
2020-02-08T03:19:20.137941: step 1270, loss 0.167523, acc 0.953125
2020-02-08T03:19:20.257675: step 1271, loss 0.41092, acc 0.796875
2020-02-08T03:19:20.372787: step 1272, loss 0.153254, acc 0.953125
2020-02-08T03:19:20.489131: step 1273, loss 0.246722, acc 0.890625
2020-02-08T03:19:20.606318: step 1274, loss 0.258672, acc 0.859375
2020-02-08T03:19:20.722117: step 1275, loss 0.265901, acc 0.890625
2020-02-08T03:19:20.842098: step 1276, loss 0.285496, acc 0.890625
2020-02-08T03:19:20.959168: step 1277, loss 0.317917, acc 0.921875
2020-02-08T03:19:21.076003: step 1278, loss 0.296377, acc 0.890625
2020-02-08T03:19:21.192643: step 1279, loss 0.3518, acc 0.859375
2020-02-08T03:19:21.308143: step 1280, loss 0.165105, acc 0.921875
2020-02-08T03:19:21.424658: step 1281, loss 0.277497, acc 0.875
2020-02-08T03:19:21.656325: step 1282, loss 0.228799, acc 0.9375
2020-02-08T03:19:21.783412: step 1283, loss 0.181456, acc 0.9375
2020-02-08T03:19:21.898576: step 1284, loss 0.179729, acc 0.9375
2020-02-08T03:19:22.014197: step 1285, loss 0.303342, acc 0.90625
2020-02-08T03:19:22.131619: step 1286, loss 0.160186, acc 0.921875
2020-02-08T03:19:22.249635: step 1287, loss 0.209028, acc 0.890625
2020-02-08T03:19:22.367175: step 1288, loss 0.188654, acc 0.921875
2020-02-08T03:19:22.484098: step 1289, loss 0.251711, acc 0.90625
2020-02-08T03:19:22.601064: step 1290, loss 0.248703, acc 0.84375
2020-02-08T03:19:22.717497: step 1291, loss 0.171682, acc 0.921875
2020-02-08T03:19:22.834667: step 1292, loss 0.244153, acc 0.890625
2020-02-08T03:19:22.951960: step 1293, loss 0.243555, acc 0.890625
2020-02-08T03:19:23.070334: step 1294, loss 0.277131, acc 0.90625
2020-02-08T03:19:23.189872: step 1295, loss 0.302414, acc 0.890625
2020-02-08T03:19:23.305092: step 1296, loss 0.265381, acc 0.90625
2020-02-08T03:19:23.419769: step 1297, loss 0.20774, acc 0.875
2020-02-08T03:19:23.539180: step 1298, loss 0.284633, acc 0.890625
2020-02-08T03:19:23.657638: step 1299, loss 0.244919, acc 0.90625
2020-02-08T03:19:23.773922: step 1300, loss 0.407848, acc 0.828125

Evaluation:
2020-02-08T03:19:23.961214: step 1300, loss 0.630256, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1300

2020-02-08T03:19:25.557658: step 1301, loss 0.348837, acc 0.875
2020-02-08T03:19:25.672053: step 1302, loss 0.345666, acc 0.828125
2020-02-08T03:19:25.792107: step 1303, loss 0.310322, acc 0.875
2020-02-08T03:19:25.906127: step 1304, loss 0.283992, acc 0.890625
2020-02-08T03:19:26.021632: step 1305, loss 0.159956, acc 0.9375
2020-02-08T03:19:26.135812: step 1306, loss 0.25662, acc 0.90625
2020-02-08T03:19:26.251989: step 1307, loss 0.325122, acc 0.875
2020-02-08T03:19:26.369439: step 1308, loss 0.261233, acc 0.84375
2020-02-08T03:19:26.484863: step 1309, loss 0.375449, acc 0.8125
2020-02-08T03:19:26.600721: step 1310, loss 0.163321, acc 0.9375
2020-02-08T03:19:26.716075: step 1311, loss 0.303605, acc 0.84375
2020-02-08T03:19:26.831415: step 1312, loss 0.316124, acc 0.875
2020-02-08T03:19:26.952128: step 1313, loss 0.270437, acc 0.890625
2020-02-08T03:19:27.067388: step 1314, loss 0.216645, acc 0.9375
2020-02-08T03:19:27.183341: step 1315, loss 0.361285, acc 0.859375
2020-02-08T03:19:27.301781: step 1316, loss 0.343122, acc 0.84375
2020-02-08T03:19:27.418172: step 1317, loss 0.371394, acc 0.875
2020-02-08T03:19:27.537885: step 1318, loss 0.166475, acc 0.90625
2020-02-08T03:19:27.655370: step 1319, loss 0.352591, acc 0.890625
2020-02-08T03:19:27.770327: step 1320, loss 0.282006, acc 0.921875
2020-02-08T03:19:27.887548: step 1321, loss 0.279683, acc 0.921875
2020-02-08T03:19:28.006207: step 1322, loss 0.333678, acc 0.90625
2020-02-08T03:19:28.123486: step 1323, loss 0.172995, acc 0.9375
2020-02-08T03:19:28.241481: step 1324, loss 0.420432, acc 0.796875
2020-02-08T03:19:28.359617: step 1325, loss 0.26404, acc 0.859375
2020-02-08T03:19:28.477113: step 1326, loss 0.343899, acc 0.859375
2020-02-08T03:19:28.594903: step 1327, loss 0.242684, acc 0.890625
2020-02-08T03:19:28.712191: step 1328, loss 0.230983, acc 0.90625
2020-02-08T03:19:28.829264: step 1329, loss 0.35641, acc 0.828125
2020-02-08T03:19:28.946226: step 1330, loss 0.359271, acc 0.796875
2020-02-08T03:19:29.060963: step 1331, loss 0.245739, acc 0.90625
2020-02-08T03:19:29.178009: step 1332, loss 0.245517, acc 0.90625
2020-02-08T03:19:29.296241: step 1333, loss 0.181482, acc 0.90625
2020-02-08T03:19:29.412990: step 1334, loss 0.273237, acc 0.90625
2020-02-08T03:19:29.529752: step 1335, loss 0.21721, acc 0.890625
2020-02-08T03:19:29.646761: step 1336, loss 0.264122, acc 0.90625
2020-02-08T03:19:29.765369: step 1337, loss 0.253823, acc 0.921875
2020-02-08T03:19:29.883906: step 1338, loss 0.319339, acc 0.90625
2020-02-08T03:19:30.003259: step 1339, loss 0.187699, acc 0.921875
2020-02-08T03:19:30.119019: step 1340, loss 0.273191, acc 0.890625
2020-02-08T03:19:30.233974: step 1341, loss 0.254024, acc 0.859375
2020-02-08T03:19:30.353312: step 1342, loss 0.245213, acc 0.90625
2020-02-08T03:19:30.469954: step 1343, loss 0.351882, acc 0.828125
2020-02-08T03:19:30.584401: step 1344, loss 0.298889, acc 0.84375
2020-02-08T03:19:30.703199: step 1345, loss 0.410374, acc 0.828125
2020-02-08T03:19:30.821103: step 1346, loss 0.237885, acc 0.90625
2020-02-08T03:19:30.937641: step 1347, loss 0.235865, acc 0.90625
2020-02-08T03:19:31.055574: step 1348, loss 0.3217, acc 0.859375
2020-02-08T03:19:31.170338: step 1349, loss 0.302543, acc 0.828125
2020-02-08T03:19:31.280412: step 1350, loss 0.179838, acc 0.916667
2020-02-08T03:19:31.401210: step 1351, loss 0.225996, acc 0.90625
2020-02-08T03:19:31.516313: step 1352, loss 0.188857, acc 0.9375
2020-02-08T03:19:31.632420: step 1353, loss 0.150452, acc 0.9375
2020-02-08T03:19:31.749365: step 1354, loss 0.206278, acc 0.90625
2020-02-08T03:19:31.866127: step 1355, loss 0.262746, acc 0.921875
2020-02-08T03:19:31.979066: step 1356, loss 0.227833, acc 0.921875
2020-02-08T03:19:32.097261: step 1357, loss 0.2708, acc 0.890625
2020-02-08T03:19:32.212731: step 1358, loss 0.309692, acc 0.859375
2020-02-08T03:19:32.330456: step 1359, loss 0.127448, acc 0.953125
2020-02-08T03:19:32.448760: step 1360, loss 0.231829, acc 0.84375
2020-02-08T03:19:32.566674: step 1361, loss 0.148636, acc 0.9375
2020-02-08T03:19:32.679382: step 1362, loss 0.270387, acc 0.9375
2020-02-08T03:19:32.797183: step 1363, loss 0.200281, acc 0.9375
2020-02-08T03:19:32.914723: step 1364, loss 0.243856, acc 0.875
2020-02-08T03:19:33.031269: step 1365, loss 0.215326, acc 0.90625
2020-02-08T03:19:33.150781: step 1366, loss 0.175176, acc 0.921875
2020-02-08T03:19:33.266000: step 1367, loss 0.161178, acc 0.96875
2020-02-08T03:19:33.380156: step 1368, loss 0.205828, acc 0.890625
2020-02-08T03:19:33.498468: step 1369, loss 0.175958, acc 0.90625
2020-02-08T03:19:33.615863: step 1370, loss 0.181367, acc 0.9375
2020-02-08T03:19:33.731646: step 1371, loss 0.231193, acc 0.90625
2020-02-08T03:19:33.851329: step 1372, loss 0.219522, acc 0.859375
2020-02-08T03:19:33.968526: step 1373, loss 0.205211, acc 0.953125
2020-02-08T03:19:34.084927: step 1374, loss 0.259413, acc 0.875
2020-02-08T03:19:34.202869: step 1375, loss 0.206899, acc 0.90625
2020-02-08T03:19:34.318264: step 1376, loss 0.294992, acc 0.875
2020-02-08T03:19:34.436683: step 1377, loss 0.187983, acc 0.921875
2020-02-08T03:19:34.553987: step 1378, loss 0.197544, acc 0.921875
2020-02-08T03:19:34.669829: step 1379, loss 0.153753, acc 0.953125
2020-02-08T03:19:34.786130: step 1380, loss 0.198343, acc 0.9375
2020-02-08T03:19:34.906976: step 1381, loss 0.30469, acc 0.875
2020-02-08T03:19:35.025052: step 1382, loss 0.208716, acc 0.90625
2020-02-08T03:19:35.139762: step 1383, loss 0.170531, acc 0.96875
2020-02-08T03:19:35.256219: step 1384, loss 0.177174, acc 0.90625
2020-02-08T03:19:35.373766: step 1385, loss 0.230991, acc 0.90625
2020-02-08T03:19:35.494858: step 1386, loss 0.189383, acc 0.90625
2020-02-08T03:19:35.610348: step 1387, loss 0.207948, acc 0.90625
2020-02-08T03:19:35.726739: step 1388, loss 0.211127, acc 0.90625
2020-02-08T03:19:35.845477: step 1389, loss 0.18122, acc 0.9375
2020-02-08T03:19:35.963027: step 1390, loss 0.288945, acc 0.859375
2020-02-08T03:19:36.079994: step 1391, loss 0.147446, acc 0.953125
2020-02-08T03:19:36.197361: step 1392, loss 0.257704, acc 0.859375
2020-02-08T03:19:36.313651: step 1393, loss 0.182531, acc 0.953125
2020-02-08T03:19:36.432063: step 1394, loss 0.152305, acc 0.9375
2020-02-08T03:19:36.549029: step 1395, loss 0.261201, acc 0.875
2020-02-08T03:19:36.667975: step 1396, loss 0.292023, acc 0.890625
2020-02-08T03:19:36.785028: step 1397, loss 0.220646, acc 0.921875
2020-02-08T03:19:36.900934: step 1398, loss 0.154366, acc 0.9375
2020-02-08T03:19:37.018418: step 1399, loss 0.208197, acc 0.890625
2020-02-08T03:19:37.139750: step 1400, loss 0.191573, acc 0.921875

Evaluation:
2020-02-08T03:19:37.326090: step 1400, loss 0.607758, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1400

2020-02-08T03:19:38.846440: step 1401, loss 0.186872, acc 0.9375
2020-02-08T03:19:38.964550: step 1402, loss 0.411386, acc 0.84375
2020-02-08T03:19:39.084130: step 1403, loss 0.188091, acc 0.921875
2020-02-08T03:19:39.202848: step 1404, loss 0.185892, acc 0.921875
2020-02-08T03:19:39.321005: step 1405, loss 0.10846, acc 0.953125
2020-02-08T03:19:39.436617: step 1406, loss 0.217029, acc 0.921875
2020-02-08T03:19:39.555657: step 1407, loss 0.268976, acc 0.890625
2020-02-08T03:19:39.672026: step 1408, loss 0.261936, acc 0.859375
2020-02-08T03:19:39.789416: step 1409, loss 0.210505, acc 0.9375
2020-02-08T03:19:39.906292: step 1410, loss 0.159313, acc 0.953125
2020-02-08T03:19:40.022483: step 1411, loss 0.25794, acc 0.875
2020-02-08T03:19:40.142406: step 1412, loss 0.241434, acc 0.890625
2020-02-08T03:19:40.258298: step 1413, loss 0.201291, acc 0.9375
2020-02-08T03:19:40.373280: step 1414, loss 0.169532, acc 0.9375
2020-02-08T03:19:40.491637: step 1415, loss 0.215572, acc 0.890625
2020-02-08T03:19:40.610489: step 1416, loss 0.120803, acc 0.96875
2020-02-08T03:19:40.727121: step 1417, loss 0.299197, acc 0.859375
2020-02-08T03:19:40.843716: step 1418, loss 0.173535, acc 0.953125
2020-02-08T03:19:40.959753: step 1419, loss 0.229846, acc 0.890625
2020-02-08T03:19:41.073464: step 1420, loss 0.149504, acc 0.9375
2020-02-08T03:19:41.190069: step 1421, loss 0.263012, acc 0.875
2020-02-08T03:19:41.305252: step 1422, loss 0.310142, acc 0.828125
2020-02-08T03:19:41.420835: step 1423, loss 0.244056, acc 0.90625
2020-02-08T03:19:41.536369: step 1424, loss 0.18879, acc 0.953125
2020-02-08T03:19:41.653612: step 1425, loss 0.247494, acc 0.90625
2020-02-08T03:19:41.769354: step 1426, loss 0.229184, acc 0.96875
2020-02-08T03:19:41.886170: step 1427, loss 0.221347, acc 0.90625
2020-02-08T03:19:42.003366: step 1428, loss 0.15081, acc 0.953125
2020-02-08T03:19:42.118511: step 1429, loss 0.266167, acc 0.90625
2020-02-08T03:19:42.232882: step 1430, loss 0.200926, acc 0.9375
2020-02-08T03:19:42.350400: step 1431, loss 0.237804, acc 0.84375
2020-02-08T03:19:42.466891: step 1432, loss 0.228833, acc 0.90625
2020-02-08T03:19:42.585408: step 1433, loss 0.234778, acc 0.921875
2020-02-08T03:19:42.702887: step 1434, loss 0.264507, acc 0.859375
2020-02-08T03:19:42.819564: step 1435, loss 0.115274, acc 0.96875
2020-02-08T03:19:42.938025: step 1436, loss 0.172677, acc 0.953125
2020-02-08T03:19:43.056179: step 1437, loss 0.174714, acc 0.921875
2020-02-08T03:19:43.169792: step 1438, loss 0.16203, acc 0.953125
2020-02-08T03:19:43.286113: step 1439, loss 0.226559, acc 0.9375
2020-02-08T03:19:43.404222: step 1440, loss 0.192732, acc 0.953125
2020-02-08T03:19:43.520157: step 1441, loss 0.224916, acc 0.875
2020-02-08T03:19:43.635146: step 1442, loss 0.184393, acc 0.921875
2020-02-08T03:19:43.755473: step 1443, loss 0.22201, acc 0.90625
2020-02-08T03:19:43.872525: step 1444, loss 0.167194, acc 0.90625
2020-02-08T03:19:43.989876: step 1445, loss 0.157511, acc 0.953125
2020-02-08T03:19:44.106693: step 1446, loss 0.117966, acc 0.9375
2020-02-08T03:19:44.224144: step 1447, loss 0.215534, acc 0.921875
2020-02-08T03:19:44.344730: step 1448, loss 0.226194, acc 0.90625
2020-02-08T03:19:44.460699: step 1449, loss 0.32552, acc 0.859375
2020-02-08T03:19:44.577513: step 1450, loss 0.133963, acc 0.9375
2020-02-08T03:19:44.691013: step 1451, loss 0.281957, acc 0.890625
2020-02-08T03:19:44.807377: step 1452, loss 0.210439, acc 0.90625
2020-02-08T03:19:44.922367: step 1453, loss 0.421158, acc 0.8125
2020-02-08T03:19:45.042005: step 1454, loss 0.207082, acc 0.9375
2020-02-08T03:19:45.158446: step 1455, loss 0.127957, acc 0.953125
2020-02-08T03:19:45.274340: step 1456, loss 0.206026, acc 0.921875
2020-02-08T03:19:45.390887: step 1457, loss 0.16846, acc 0.984375
2020-02-08T03:19:45.509619: step 1458, loss 0.235915, acc 0.875
2020-02-08T03:19:45.624706: step 1459, loss 0.16592, acc 0.90625
2020-02-08T03:19:45.742010: step 1460, loss 0.23719, acc 0.890625
2020-02-08T03:19:45.856316: step 1461, loss 0.109128, acc 0.96875
2020-02-08T03:19:45.974348: step 1462, loss 0.310634, acc 0.859375
2020-02-08T03:19:46.090331: step 1463, loss 0.209798, acc 0.90625
2020-02-08T03:19:46.208983: step 1464, loss 0.231832, acc 0.921875
2020-02-08T03:19:46.323771: step 1465, loss 0.217092, acc 0.921875
2020-02-08T03:19:46.440993: step 1466, loss 0.179927, acc 0.921875
2020-02-08T03:19:46.559942: step 1467, loss 0.193802, acc 0.921875
2020-02-08T03:19:46.675300: step 1468, loss 0.141267, acc 0.9375
2020-02-08T03:19:46.793265: step 1469, loss 0.201588, acc 0.921875
2020-02-08T03:19:46.911931: step 1470, loss 0.255146, acc 0.859375
2020-02-08T03:19:47.027369: step 1471, loss 0.168806, acc 0.9375
2020-02-08T03:19:47.145395: step 1472, loss 0.232445, acc 0.9375
2020-02-08T03:19:47.261922: step 1473, loss 0.190883, acc 0.90625
2020-02-08T03:19:47.376862: step 1474, loss 0.213742, acc 0.90625
2020-02-08T03:19:47.497654: step 1475, loss 0.215865, acc 0.90625
2020-02-08T03:19:47.615105: step 1476, loss 0.253898, acc 0.859375
2020-02-08T03:19:47.729039: step 1477, loss 0.159693, acc 0.9375
2020-02-08T03:19:47.847139: step 1478, loss 0.225783, acc 0.890625
2020-02-08T03:19:47.963250: step 1479, loss 0.280866, acc 0.890625
2020-02-08T03:19:48.080520: step 1480, loss 0.215477, acc 0.890625
2020-02-08T03:19:48.198466: step 1481, loss 0.181435, acc 0.921875
2020-02-08T03:19:48.314209: step 1482, loss 0.12269, acc 0.953125
2020-02-08T03:19:48.430575: step 1483, loss 0.269287, acc 0.875
2020-02-08T03:19:48.547401: step 1484, loss 0.168606, acc 0.953125
2020-02-08T03:19:48.663947: step 1485, loss 0.139929, acc 0.953125
2020-02-08T03:19:48.778811: step 1486, loss 0.158544, acc 0.9375
2020-02-08T03:19:48.896028: step 1487, loss 0.14104, acc 0.921875
2020-02-08T03:19:49.014931: step 1488, loss 0.336937, acc 0.875
2020-02-08T03:19:49.131142: step 1489, loss 0.181417, acc 0.921875
2020-02-08T03:19:49.251555: step 1490, loss 0.282497, acc 0.875
2020-02-08T03:19:49.368740: step 1491, loss 0.224891, acc 0.90625
2020-02-08T03:19:49.484148: step 1492, loss 0.164767, acc 0.921875
2020-02-08T03:19:49.606539: step 1493, loss 0.161211, acc 0.9375
2020-02-08T03:19:49.732931: step 1494, loss 0.174775, acc 0.921875
2020-02-08T03:19:49.858996: step 1495, loss 0.312373, acc 0.859375
2020-02-08T03:19:49.979591: step 1496, loss 0.119167, acc 0.953125
2020-02-08T03:19:50.106235: step 1497, loss 0.178443, acc 0.921875
2020-02-08T03:19:50.225635: step 1498, loss 0.174145, acc 0.953125
2020-02-08T03:19:50.347982: step 1499, loss 0.190855, acc 0.90625
2020-02-08T03:19:50.467629: step 1500, loss 0.24794, acc 0.883333

Evaluation:
2020-02-08T03:19:50.662691: step 1500, loss 0.628119, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1500

2020-02-08T03:19:52.118795: step 1501, loss 0.140768, acc 0.9375
2020-02-08T03:19:52.236169: step 1502, loss 0.202266, acc 0.90625
2020-02-08T03:19:52.366154: step 1503, loss 0.0899938, acc 0.984375
2020-02-08T03:19:52.494174: step 1504, loss 0.205957, acc 0.921875
2020-02-08T03:19:52.619195: step 1505, loss 0.197058, acc 0.9375
2020-02-08T03:19:52.733408: step 1506, loss 0.134081, acc 0.953125
2020-02-08T03:19:52.852425: step 1507, loss 0.125354, acc 0.921875
2020-02-08T03:19:52.972699: step 1508, loss 0.245278, acc 0.921875
2020-02-08T03:19:53.089663: step 1509, loss 0.271307, acc 0.875
2020-02-08T03:19:53.208279: step 1510, loss 0.176482, acc 0.921875
2020-02-08T03:19:53.324290: step 1511, loss 0.20032, acc 0.90625
2020-02-08T03:19:53.440464: step 1512, loss 0.199123, acc 0.890625
2020-02-08T03:19:53.559861: step 1513, loss 0.134035, acc 0.953125
2020-02-08T03:19:53.673762: step 1514, loss 0.205661, acc 0.90625
2020-02-08T03:19:53.796549: step 1515, loss 0.111374, acc 0.96875
2020-02-08T03:19:53.913573: step 1516, loss 0.12468, acc 0.953125
2020-02-08T03:19:54.027313: step 1517, loss 0.23532, acc 0.890625
2020-02-08T03:19:54.144209: step 1518, loss 0.125902, acc 0.9375
2020-02-08T03:19:54.262607: step 1519, loss 0.20606, acc 0.90625
2020-02-08T03:19:54.377227: step 1520, loss 0.213707, acc 0.921875
2020-02-08T03:19:54.491720: step 1521, loss 0.132146, acc 0.96875
2020-02-08T03:19:54.610331: step 1522, loss 0.175079, acc 0.9375
2020-02-08T03:19:54.725685: step 1523, loss 0.166623, acc 0.921875
2020-02-08T03:19:54.847033: step 1524, loss 0.152892, acc 0.9375
2020-02-08T03:19:54.962925: step 1525, loss 0.126371, acc 0.953125
2020-02-08T03:19:55.076705: step 1526, loss 0.169497, acc 0.953125
2020-02-08T03:19:55.194909: step 1527, loss 0.206791, acc 0.90625
2020-02-08T03:19:55.311600: step 1528, loss 0.180341, acc 0.921875
2020-02-08T03:19:55.431765: step 1529, loss 0.213311, acc 0.875
2020-02-08T03:19:55.549812: step 1530, loss 0.185791, acc 0.890625
2020-02-08T03:19:55.667247: step 1531, loss 0.147274, acc 0.921875
2020-02-08T03:19:55.785714: step 1532, loss 0.140722, acc 0.96875
2020-02-08T03:19:55.906390: step 1533, loss 0.161405, acc 0.9375
2020-02-08T03:19:56.023916: step 1534, loss 0.0909467, acc 0.984375
2020-02-08T03:19:56.144526: step 1535, loss 0.128378, acc 0.96875
2020-02-08T03:19:56.263018: step 1536, loss 0.379825, acc 0.84375
2020-02-08T03:19:56.378464: step 1537, loss 0.27193, acc 0.84375
2020-02-08T03:19:56.493791: step 1538, loss 0.11135, acc 0.953125
2020-02-08T03:19:56.611724: step 1539, loss 0.119865, acc 0.953125
2020-02-08T03:19:56.727649: step 1540, loss 0.155606, acc 0.96875
2020-02-08T03:19:56.842316: step 1541, loss 0.239701, acc 0.90625
2020-02-08T03:19:56.960452: step 1542, loss 0.190991, acc 0.90625
2020-02-08T03:19:57.076763: step 1543, loss 0.160238, acc 0.953125
2020-02-08T03:19:57.198093: step 1544, loss 0.143641, acc 0.953125
2020-02-08T03:19:57.317308: step 1545, loss 0.167666, acc 0.9375
2020-02-08T03:19:57.434717: step 1546, loss 0.160851, acc 0.9375
2020-02-08T03:19:57.553238: step 1547, loss 0.143953, acc 0.9375
2020-02-08T03:19:57.669136: step 1548, loss 0.10544, acc 0.96875
2020-02-08T03:19:57.782250: step 1549, loss 0.227595, acc 0.921875
2020-02-08T03:19:57.900306: step 1550, loss 0.149726, acc 0.953125
2020-02-08T03:19:58.016268: step 1551, loss 0.17287, acc 0.953125
2020-02-08T03:19:58.131716: step 1552, loss 0.175381, acc 0.9375
2020-02-08T03:19:58.249071: step 1553, loss 0.179025, acc 0.90625
2020-02-08T03:19:58.367829: step 1554, loss 0.112499, acc 0.96875
2020-02-08T03:19:58.488144: step 1555, loss 0.211656, acc 0.90625
2020-02-08T03:19:58.604716: step 1556, loss 0.139972, acc 0.9375
2020-02-08T03:19:58.720694: step 1557, loss 0.169531, acc 0.9375
2020-02-08T03:19:58.838612: step 1558, loss 0.218084, acc 0.921875
2020-02-08T03:19:58.955588: step 1559, loss 0.0855654, acc 0.96875
2020-02-08T03:19:59.071198: step 1560, loss 0.254659, acc 0.90625
2020-02-08T03:19:59.190581: step 1561, loss 0.1162, acc 0.953125
2020-02-08T03:19:59.306762: step 1562, loss 0.251921, acc 0.90625
2020-02-08T03:19:59.421701: step 1563, loss 0.177891, acc 0.9375
2020-02-08T03:19:59.540200: step 1564, loss 0.148448, acc 0.921875
2020-02-08T03:19:59.659279: step 1565, loss 0.219715, acc 0.890625
2020-02-08T03:19:59.776441: step 1566, loss 0.0960172, acc 0.984375
2020-02-08T03:19:59.919368: step 1567, loss 0.123966, acc 0.953125
2020-02-08T03:20:00.063652: step 1568, loss 0.198186, acc 0.9375
2020-02-08T03:20:00.182781: step 1569, loss 0.161764, acc 0.90625
2020-02-08T03:20:00.301058: step 1570, loss 0.11854, acc 0.953125
2020-02-08T03:20:00.419355: step 1571, loss 0.0806629, acc 1
2020-02-08T03:20:00.535266: step 1572, loss 0.246478, acc 0.890625
2020-02-08T03:20:00.653205: step 1573, loss 0.129439, acc 0.96875
2020-02-08T03:20:00.770392: step 1574, loss 0.147198, acc 0.9375
2020-02-08T03:20:00.893600: step 1575, loss 0.188002, acc 0.9375
2020-02-08T03:20:01.013189: step 1576, loss 0.18805, acc 0.921875
2020-02-08T03:20:01.130322: step 1577, loss 0.0610706, acc 0.984375
2020-02-08T03:20:01.246436: step 1578, loss 0.22751, acc 0.859375
2020-02-08T03:20:01.363964: step 1579, loss 0.205888, acc 0.921875
2020-02-08T03:20:01.483049: step 1580, loss 0.153722, acc 0.9375
2020-02-08T03:20:01.601292: step 1581, loss 0.173214, acc 0.953125
2020-02-08T03:20:01.716781: step 1582, loss 0.148051, acc 0.921875
2020-02-08T03:20:01.835180: step 1583, loss 0.196191, acc 0.90625
2020-02-08T03:20:01.955323: step 1584, loss 0.213457, acc 0.90625
2020-02-08T03:20:02.069064: step 1585, loss 0.159663, acc 0.953125
2020-02-08T03:20:02.187965: step 1586, loss 0.318697, acc 0.84375
2020-02-08T03:20:02.308843: step 1587, loss 0.234756, acc 0.9375
2020-02-08T03:20:02.428751: step 1588, loss 0.178848, acc 0.921875
2020-02-08T03:20:02.544779: step 1589, loss 0.162806, acc 0.953125
2020-02-08T03:20:02.665603: step 1590, loss 0.0761148, acc 0.984375
2020-02-08T03:20:02.782796: step 1591, loss 0.152647, acc 0.90625
2020-02-08T03:20:02.900246: step 1592, loss 0.243693, acc 0.921875
2020-02-08T03:20:03.017314: step 1593, loss 0.164678, acc 0.90625
2020-02-08T03:20:03.133634: step 1594, loss 0.165615, acc 0.953125
2020-02-08T03:20:03.250467: step 1595, loss 0.227518, acc 0.921875
2020-02-08T03:20:03.367866: step 1596, loss 0.0952208, acc 0.984375
2020-02-08T03:20:03.481632: step 1597, loss 0.20892, acc 0.921875
2020-02-08T03:20:03.598025: step 1598, loss 0.223301, acc 0.90625
2020-02-08T03:20:03.715042: step 1599, loss 0.240984, acc 0.890625
2020-02-08T03:20:03.830155: step 1600, loss 0.233723, acc 0.890625

Evaluation:
2020-02-08T03:20:04.017314: step 1600, loss 0.640022, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1600

2020-02-08T03:20:05.546205: step 1601, loss 0.147141, acc 0.9375
2020-02-08T03:20:05.672088: step 1602, loss 0.171348, acc 0.953125
2020-02-08T03:20:05.796132: step 1603, loss 0.148268, acc 0.921875
2020-02-08T03:20:05.918415: step 1604, loss 0.259251, acc 0.890625
2020-02-08T03:20:06.047008: step 1605, loss 0.0727701, acc 0.96875
2020-02-08T03:20:06.176220: step 1606, loss 0.229062, acc 0.875
2020-02-08T03:20:06.308598: step 1607, loss 0.244495, acc 0.90625
2020-02-08T03:20:06.428824: step 1608, loss 0.161457, acc 0.90625
2020-02-08T03:20:06.558479: step 1609, loss 0.0684497, acc 1
2020-02-08T03:20:06.677251: step 1610, loss 0.220792, acc 0.90625
2020-02-08T03:20:06.799221: step 1611, loss 0.151731, acc 0.953125
2020-02-08T03:20:06.922932: step 1612, loss 0.278105, acc 0.90625
2020-02-08T03:20:07.041970: step 1613, loss 0.341615, acc 0.828125
2020-02-08T03:20:07.160480: step 1614, loss 0.292916, acc 0.890625
2020-02-08T03:20:07.278447: step 1615, loss 0.132429, acc 0.953125
2020-02-08T03:20:07.393898: step 1616, loss 0.137102, acc 0.96875
2020-02-08T03:20:07.512234: step 1617, loss 0.139677, acc 0.9375
2020-02-08T03:20:07.639627: step 1618, loss 0.127169, acc 0.953125
2020-02-08T03:20:07.772850: step 1619, loss 0.231655, acc 0.921875
2020-02-08T03:20:07.900805: step 1620, loss 0.211743, acc 0.90625
2020-02-08T03:20:08.017290: step 1621, loss 0.161662, acc 0.953125
2020-02-08T03:20:08.135637: step 1622, loss 0.222265, acc 0.890625
2020-02-08T03:20:08.252916: step 1623, loss 0.152553, acc 0.890625
2020-02-08T03:20:08.372348: step 1624, loss 0.212785, acc 0.9375
2020-02-08T03:20:08.488506: step 1625, loss 0.179763, acc 0.875
2020-02-08T03:20:08.607367: step 1626, loss 0.0943648, acc 0.96875
2020-02-08T03:20:08.724235: step 1627, loss 0.187294, acc 0.9375
2020-02-08T03:20:08.843279: step 1628, loss 0.206551, acc 0.921875
2020-02-08T03:20:08.959007: step 1629, loss 0.202188, acc 0.921875
2020-02-08T03:20:09.075030: step 1630, loss 0.140174, acc 0.953125
2020-02-08T03:20:09.193226: step 1631, loss 0.167399, acc 0.9375
2020-02-08T03:20:09.311701: step 1632, loss 0.237627, acc 0.890625
2020-02-08T03:20:09.425309: step 1633, loss 0.240956, acc 0.921875
2020-02-08T03:20:09.543299: step 1634, loss 0.14794, acc 0.96875
2020-02-08T03:20:09.660819: step 1635, loss 0.129935, acc 0.96875
2020-02-08T03:20:09.775870: step 1636, loss 0.234595, acc 0.90625
2020-02-08T03:20:09.893435: step 1637, loss 0.190666, acc 0.921875
2020-02-08T03:20:10.011208: step 1638, loss 0.18444, acc 0.9375
2020-02-08T03:20:10.127541: step 1639, loss 0.175438, acc 0.9375
2020-02-08T03:20:10.250780: step 1640, loss 0.152951, acc 0.921875
2020-02-08T03:20:10.366196: step 1641, loss 0.139384, acc 0.96875
2020-02-08T03:20:10.478481: step 1642, loss 0.13036, acc 0.953125
2020-02-08T03:20:10.596277: step 1643, loss 0.118948, acc 0.96875
2020-02-08T03:20:10.715876: step 1644, loss 0.161292, acc 0.921875
2020-02-08T03:20:10.833775: step 1645, loss 0.151527, acc 0.9375
2020-02-08T03:20:10.950188: step 1646, loss 0.142698, acc 0.953125
2020-02-08T03:20:11.067842: step 1647, loss 0.118592, acc 0.96875
2020-02-08T03:20:11.186780: step 1648, loss 0.0988819, acc 0.984375
2020-02-08T03:20:11.305214: step 1649, loss 0.158929, acc 0.9375
2020-02-08T03:20:11.417989: step 1650, loss 0.243318, acc 0.883333
2020-02-08T03:20:11.535915: step 1651, loss 0.0874906, acc 0.96875
2020-02-08T03:20:11.650121: step 1652, loss 0.0822753, acc 0.96875
2020-02-08T03:20:11.767103: step 1653, loss 0.128815, acc 0.96875
2020-02-08T03:20:11.883302: step 1654, loss 0.17926, acc 0.90625
2020-02-08T03:20:11.999666: step 1655, loss 0.0883942, acc 0.96875
2020-02-08T03:20:12.114366: step 1656, loss 0.141568, acc 0.921875
2020-02-08T03:20:12.229766: step 1657, loss 0.141248, acc 0.96875
2020-02-08T03:20:12.343785: step 1658, loss 0.140624, acc 0.9375
2020-02-08T03:20:12.460663: step 1659, loss 0.088369, acc 0.9375
2020-02-08T03:20:12.578538: step 1660, loss 0.101687, acc 0.96875
2020-02-08T03:20:12.695495: step 1661, loss 0.0797399, acc 0.953125
2020-02-08T03:20:12.813066: step 1662, loss 0.144697, acc 0.9375
2020-02-08T03:20:12.932014: step 1663, loss 0.0844841, acc 0.984375
2020-02-08T03:20:13.048605: step 1664, loss 0.0639044, acc 1
2020-02-08T03:20:13.166254: step 1665, loss 0.137703, acc 0.9375
2020-02-08T03:20:13.283927: step 1666, loss 0.0881201, acc 0.96875
2020-02-08T03:20:13.402542: step 1667, loss 0.123317, acc 0.953125
2020-02-08T03:20:13.521453: step 1668, loss 0.113151, acc 0.953125
2020-02-08T03:20:13.638332: step 1669, loss 0.111245, acc 0.984375
2020-02-08T03:20:13.754324: step 1670, loss 0.176508, acc 0.953125
2020-02-08T03:20:13.875187: step 1671, loss 0.062086, acc 0.96875
2020-02-08T03:20:13.993636: step 1672, loss 0.165081, acc 0.953125
2020-02-08T03:20:14.110360: step 1673, loss 0.187575, acc 0.9375
2020-02-08T03:20:14.227040: step 1674, loss 0.11835, acc 0.96875
2020-02-08T03:20:14.344785: step 1675, loss 0.160576, acc 0.9375
2020-02-08T03:20:14.461411: step 1676, loss 0.131393, acc 0.953125
2020-02-08T03:20:14.580343: step 1677, loss 0.103873, acc 0.9375
2020-02-08T03:20:14.695957: step 1678, loss 0.123135, acc 0.96875
2020-02-08T03:20:14.813270: step 1679, loss 0.134307, acc 0.953125
2020-02-08T03:20:14.932607: step 1680, loss 0.246973, acc 0.921875
2020-02-08T03:20:15.050663: step 1681, loss 0.216231, acc 0.953125
2020-02-08T03:20:15.165746: step 1682, loss 0.0901984, acc 0.96875
2020-02-08T03:20:15.282443: step 1683, loss 0.157583, acc 0.921875
2020-02-08T03:20:15.398287: step 1684, loss 0.084113, acc 0.96875
2020-02-08T03:20:15.515642: step 1685, loss 0.179572, acc 0.90625
2020-02-08T03:20:15.631932: step 1686, loss 0.112875, acc 0.96875
2020-02-08T03:20:15.749909: step 1687, loss 0.0951769, acc 0.96875
2020-02-08T03:20:15.867915: step 1688, loss 0.11063, acc 0.921875
2020-02-08T03:20:15.982218: step 1689, loss 0.0692546, acc 1
2020-02-08T03:20:16.097435: step 1690, loss 0.11027, acc 0.984375
2020-02-08T03:20:16.215248: step 1691, loss 0.0718824, acc 0.984375
2020-02-08T03:20:16.330320: step 1692, loss 0.0765996, acc 0.953125
2020-02-08T03:20:16.447684: step 1693, loss 0.152207, acc 0.953125
2020-02-08T03:20:16.564929: step 1694, loss 0.075523, acc 0.984375
2020-02-08T03:20:16.679616: step 1695, loss 0.0942054, acc 0.96875
2020-02-08T03:20:16.795597: step 1696, loss 0.185426, acc 0.9375
2020-02-08T03:20:16.910235: step 1697, loss 0.105294, acc 0.984375
2020-02-08T03:20:17.024271: step 1698, loss 0.160182, acc 0.921875
2020-02-08T03:20:17.139360: step 1699, loss 0.098499, acc 0.96875
2020-02-08T03:20:17.255903: step 1700, loss 0.141821, acc 0.921875

Evaluation:
2020-02-08T03:20:17.448482: step 1700, loss 0.696893, acc 0.708255

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1700

2020-02-08T03:20:18.969055: step 1701, loss 0.155174, acc 0.921875
2020-02-08T03:20:19.088835: step 1702, loss 0.0988239, acc 0.96875
2020-02-08T03:20:19.204426: step 1703, loss 0.167641, acc 0.96875
2020-02-08T03:20:19.320451: step 1704, loss 0.115832, acc 0.953125
2020-02-08T03:20:19.438671: step 1705, loss 0.0841525, acc 0.96875
2020-02-08T03:20:19.554164: step 1706, loss 0.155523, acc 0.9375
2020-02-08T03:20:19.670007: step 1707, loss 0.135224, acc 0.953125
2020-02-08T03:20:19.786252: step 1708, loss 0.141562, acc 0.921875
2020-02-08T03:20:19.902606: step 1709, loss 0.139875, acc 0.96875
2020-02-08T03:20:20.019662: step 1710, loss 0.126099, acc 0.9375
2020-02-08T03:20:20.136180: step 1711, loss 0.113704, acc 0.96875
2020-02-08T03:20:20.251716: step 1712, loss 0.138146, acc 0.90625
2020-02-08T03:20:20.368458: step 1713, loss 0.171944, acc 0.921875
2020-02-08T03:20:20.486526: step 1714, loss 0.154653, acc 0.9375
2020-02-08T03:20:20.602045: step 1715, loss 0.113204, acc 0.96875
2020-02-08T03:20:20.717776: step 1716, loss 0.101557, acc 0.953125
2020-02-08T03:20:20.837812: step 1717, loss 0.138692, acc 0.9375
2020-02-08T03:20:20.956798: step 1718, loss 0.0745448, acc 0.984375
2020-02-08T03:20:21.073043: step 1719, loss 0.082204, acc 0.984375
2020-02-08T03:20:21.188948: step 1720, loss 0.0972054, acc 0.96875
2020-02-08T03:20:21.306218: step 1721, loss 0.0648324, acc 0.984375
2020-02-08T03:20:21.675083: step 1722, loss 0.139265, acc 0.96875
2020-02-08T03:20:21.801968: step 1723, loss 0.0965127, acc 0.984375
2020-02-08T03:20:21.917287: step 1724, loss 0.146013, acc 0.9375
2020-02-08T03:20:22.039858: step 1725, loss 0.171469, acc 0.9375
2020-02-08T03:20:22.157135: step 1726, loss 0.161946, acc 0.9375
2020-02-08T03:20:22.272789: step 1727, loss 0.0958083, acc 0.984375
2020-02-08T03:20:22.389535: step 1728, loss 0.147499, acc 0.9375
2020-02-08T03:20:22.506652: step 1729, loss 0.107486, acc 0.953125
2020-02-08T03:20:22.622454: step 1730, loss 0.090869, acc 0.984375
2020-02-08T03:20:22.739728: step 1731, loss 0.0987539, acc 0.984375
2020-02-08T03:20:22.857754: step 1732, loss 0.132294, acc 0.953125
2020-02-08T03:20:22.973394: step 1733, loss 0.121167, acc 0.984375
2020-02-08T03:20:23.088421: step 1734, loss 0.0844323, acc 0.96875
2020-02-08T03:20:23.206475: step 1735, loss 0.116057, acc 0.953125
2020-02-08T03:20:23.322182: step 1736, loss 0.118133, acc 0.9375
2020-02-08T03:20:23.439966: step 1737, loss 0.140061, acc 0.9375
2020-02-08T03:20:23.557482: step 1738, loss 0.111582, acc 0.96875
2020-02-08T03:20:23.672905: step 1739, loss 0.153577, acc 0.921875
2020-02-08T03:20:23.787917: step 1740, loss 0.135774, acc 0.921875
2020-02-08T03:20:23.907507: step 1741, loss 0.194324, acc 0.9375
2020-02-08T03:20:24.023092: step 1742, loss 0.220987, acc 0.921875
2020-02-08T03:20:24.142084: step 1743, loss 0.139899, acc 0.96875
2020-02-08T03:20:24.259462: step 1744, loss 0.128254, acc 0.9375
2020-02-08T03:20:24.377808: step 1745, loss 0.232816, acc 0.890625
2020-02-08T03:20:24.494452: step 1746, loss 0.120634, acc 0.953125
2020-02-08T03:20:24.613656: step 1747, loss 0.0862134, acc 0.96875
2020-02-08T03:20:24.729329: step 1748, loss 0.170894, acc 0.9375
2020-02-08T03:20:24.848041: step 1749, loss 0.171116, acc 0.921875
2020-02-08T03:20:24.965217: step 1750, loss 0.0983246, acc 0.96875
2020-02-08T03:20:25.081442: step 1751, loss 0.255777, acc 0.90625
2020-02-08T03:20:25.199778: step 1752, loss 0.169906, acc 0.921875
2020-02-08T03:20:25.316785: step 1753, loss 0.189273, acc 0.921875
2020-02-08T03:20:25.433733: step 1754, loss 0.0817231, acc 0.96875
2020-02-08T03:20:25.551611: step 1755, loss 0.125355, acc 0.953125
2020-02-08T03:20:25.668201: step 1756, loss 0.162379, acc 0.9375
2020-02-08T03:20:25.789020: step 1757, loss 0.151186, acc 0.9375
2020-02-08T03:20:25.907172: step 1758, loss 0.0945474, acc 0.984375
2020-02-08T03:20:26.023894: step 1759, loss 0.0689776, acc 0.96875
2020-02-08T03:20:26.138310: step 1760, loss 0.0892887, acc 0.96875
2020-02-08T03:20:26.255267: step 1761, loss 0.104748, acc 0.9375
2020-02-08T03:20:26.370990: step 1762, loss 0.155185, acc 0.9375
2020-02-08T03:20:26.488041: step 1763, loss 0.177907, acc 0.921875
2020-02-08T03:20:26.610196: step 1764, loss 0.231392, acc 0.90625
2020-02-08T03:20:26.725939: step 1765, loss 0.207193, acc 0.90625
2020-02-08T03:20:26.842195: step 1766, loss 0.126687, acc 0.9375
2020-02-08T03:20:26.958251: step 1767, loss 0.0593168, acc 1
2020-02-08T03:20:27.074666: step 1768, loss 0.0433464, acc 1
2020-02-08T03:20:27.193959: step 1769, loss 0.0783637, acc 0.984375
2020-02-08T03:20:27.310901: step 1770, loss 0.126245, acc 0.96875
2020-02-08T03:20:27.425241: step 1771, loss 0.160483, acc 0.953125
2020-02-08T03:20:27.544706: step 1772, loss 0.194795, acc 0.9375
2020-02-08T03:20:27.664719: step 1773, loss 0.142025, acc 0.96875
2020-02-08T03:20:27.779026: step 1774, loss 0.230661, acc 0.9375
2020-02-08T03:20:27.896105: step 1775, loss 0.11005, acc 0.953125
2020-02-08T03:20:28.012423: step 1776, loss 0.0899542, acc 0.984375
2020-02-08T03:20:28.130101: step 1777, loss 0.134734, acc 0.96875
2020-02-08T03:20:28.246678: step 1778, loss 0.147452, acc 0.9375
2020-02-08T03:20:28.361697: step 1779, loss 0.125362, acc 0.9375
2020-02-08T03:20:28.477795: step 1780, loss 0.231186, acc 0.875
2020-02-08T03:20:28.592521: step 1781, loss 0.0796932, acc 0.96875
2020-02-08T03:20:28.711521: step 1782, loss 0.177113, acc 0.921875
2020-02-08T03:20:28.828621: step 1783, loss 0.14595, acc 0.9375
2020-02-08T03:20:28.944783: step 1784, loss 0.118823, acc 0.953125
2020-02-08T03:20:29.061531: step 1785, loss 0.132711, acc 0.953125
2020-02-08T03:20:29.178480: step 1786, loss 0.0656245, acc 0.984375
2020-02-08T03:20:29.294399: step 1787, loss 0.167015, acc 0.953125
2020-02-08T03:20:29.414049: step 1788, loss 0.104848, acc 0.953125
2020-02-08T03:20:29.528602: step 1789, loss 0.1332, acc 0.96875
2020-02-08T03:20:29.643779: step 1790, loss 0.0935929, acc 0.953125
2020-02-08T03:20:29.763432: step 1791, loss 0.0699401, acc 1
2020-02-08T03:20:29.879638: step 1792, loss 0.248795, acc 0.890625
2020-02-08T03:20:29.994257: step 1793, loss 0.162547, acc 0.953125
2020-02-08T03:20:30.112809: step 1794, loss 0.0719913, acc 0.984375
2020-02-08T03:20:30.230717: step 1795, loss 0.17547, acc 0.921875
2020-02-08T03:20:30.346172: step 1796, loss 0.111295, acc 0.953125
2020-02-08T03:20:30.464764: step 1797, loss 0.18008, acc 0.9375
2020-02-08T03:20:30.581903: step 1798, loss 0.207364, acc 0.90625
2020-02-08T03:20:30.698907: step 1799, loss 0.109418, acc 0.9375
2020-02-08T03:20:30.811510: step 1800, loss 0.0896887, acc 0.966667

Evaluation:
2020-02-08T03:20:30.999110: step 1800, loss 0.709747, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1800

2020-02-08T03:20:32.530109: step 1801, loss 0.0727865, acc 0.984375
2020-02-08T03:20:32.646541: step 1802, loss 0.0830037, acc 0.96875
2020-02-08T03:20:32.761878: step 1803, loss 0.168361, acc 0.90625
2020-02-08T03:20:32.877084: step 1804, loss 0.0809135, acc 0.984375
2020-02-08T03:20:32.990998: step 1805, loss 0.109721, acc 0.953125
2020-02-08T03:20:33.105057: step 1806, loss 0.0742417, acc 0.984375
2020-02-08T03:20:33.220218: step 1807, loss 0.103282, acc 0.953125
2020-02-08T03:20:33.335131: step 1808, loss 0.0757354, acc 0.984375
2020-02-08T03:20:33.450117: step 1809, loss 0.102939, acc 0.96875
2020-02-08T03:20:33.565484: step 1810, loss 0.118529, acc 0.953125
2020-02-08T03:20:33.682502: step 1811, loss 0.154097, acc 0.90625
2020-02-08T03:20:33.799119: step 1812, loss 0.0305659, acc 1
2020-02-08T03:20:33.916783: step 1813, loss 0.131089, acc 0.953125
2020-02-08T03:20:34.035514: step 1814, loss 0.121838, acc 0.953125
2020-02-08T03:20:34.151208: step 1815, loss 0.0644675, acc 0.96875
2020-02-08T03:20:34.267357: step 1816, loss 0.0664932, acc 1
2020-02-08T03:20:34.385983: step 1817, loss 0.0469214, acc 1
2020-02-08T03:20:34.503715: step 1818, loss 0.150826, acc 0.9375
2020-02-08T03:20:34.620433: step 1819, loss 0.136677, acc 0.953125
2020-02-08T03:20:34.737244: step 1820, loss 0.0689775, acc 0.984375
2020-02-08T03:20:34.856471: step 1821, loss 0.0780223, acc 0.984375
2020-02-08T03:20:34.973000: step 1822, loss 0.0460087, acc 1
2020-02-08T03:20:35.090932: step 1823, loss 0.143513, acc 0.9375
2020-02-08T03:20:35.210316: step 1824, loss 0.0956117, acc 0.984375
2020-02-08T03:20:35.327058: step 1825, loss 0.101348, acc 0.9375
2020-02-08T03:20:35.443394: step 1826, loss 0.0922917, acc 0.953125
2020-02-08T03:20:35.557773: step 1827, loss 0.0655393, acc 0.96875
2020-02-08T03:20:35.672843: step 1828, loss 0.073117, acc 0.984375
2020-02-08T03:20:35.790333: step 1829, loss 0.182965, acc 0.921875
2020-02-08T03:20:35.909024: step 1830, loss 0.0453281, acc 0.984375
2020-02-08T03:20:36.025360: step 1831, loss 0.0604131, acc 1
2020-02-08T03:20:36.142700: step 1832, loss 0.0612565, acc 0.96875
2020-02-08T03:20:36.257721: step 1833, loss 0.0844355, acc 0.96875
2020-02-08T03:20:36.375574: step 1834, loss 0.215609, acc 0.875
2020-02-08T03:20:36.493952: step 1835, loss 0.0708799, acc 0.96875
2020-02-08T03:20:36.607459: step 1836, loss 0.0740831, acc 0.984375
2020-02-08T03:20:36.727060: step 1837, loss 0.066195, acc 1
2020-02-08T03:20:36.843085: step 1838, loss 0.0684965, acc 0.984375
2020-02-08T03:20:36.962154: step 1839, loss 0.0943672, acc 0.96875
2020-02-08T03:20:37.079488: step 1840, loss 0.194044, acc 0.9375
2020-02-08T03:20:37.196066: step 1841, loss 0.0412759, acc 1
2020-02-08T03:20:37.310903: step 1842, loss 0.224533, acc 0.96875
2020-02-08T03:20:37.429780: step 1843, loss 0.0763097, acc 0.96875
2020-02-08T03:20:37.546655: step 1844, loss 0.101341, acc 0.96875
2020-02-08T03:20:37.663370: step 1845, loss 0.151712, acc 0.921875
2020-02-08T03:20:37.778911: step 1846, loss 0.154129, acc 0.953125
2020-02-08T03:20:37.898620: step 1847, loss 0.0622072, acc 0.96875
2020-02-08T03:20:38.014376: step 1848, loss 0.0972725, acc 0.984375
2020-02-08T03:20:38.130206: step 1849, loss 0.160377, acc 0.953125
2020-02-08T03:20:38.246109: step 1850, loss 0.0546471, acc 1
2020-02-08T03:20:38.366745: step 1851, loss 0.142522, acc 0.953125
2020-02-08T03:20:38.484171: step 1852, loss 0.097763, acc 0.96875
2020-02-08T03:20:38.601756: step 1853, loss 0.138758, acc 0.921875
2020-02-08T03:20:38.726466: step 1854, loss 0.0935118, acc 0.96875
2020-02-08T03:20:38.853951: step 1855, loss 0.0711959, acc 0.96875
2020-02-08T03:20:38.971449: step 1856, loss 0.0653476, acc 0.96875
2020-02-08T03:20:39.094967: step 1857, loss 0.195742, acc 0.890625
2020-02-08T03:20:39.212373: step 1858, loss 0.082326, acc 0.953125
2020-02-08T03:20:39.327042: step 1859, loss 0.170653, acc 0.9375
2020-02-08T03:20:39.445923: step 1860, loss 0.110406, acc 0.921875
2020-02-08T03:20:39.563986: step 1861, loss 0.134874, acc 0.953125
2020-02-08T03:20:39.678444: step 1862, loss 0.078658, acc 0.984375
2020-02-08T03:20:39.797372: step 1863, loss 0.0960892, acc 0.953125
2020-02-08T03:20:39.915045: step 1864, loss 0.110192, acc 0.953125
2020-02-08T03:20:40.031891: step 1865, loss 0.111368, acc 0.953125
2020-02-08T03:20:40.150515: step 1866, loss 0.0612011, acc 1
2020-02-08T03:20:40.266274: step 1867, loss 0.0995108, acc 0.96875
2020-02-08T03:20:40.383497: step 1868, loss 0.0523146, acc 0.984375
2020-02-08T03:20:40.500250: step 1869, loss 0.0456014, acc 0.984375
2020-02-08T03:20:40.619542: step 1870, loss 0.0907059, acc 0.96875
2020-02-08T03:20:40.737998: step 1871, loss 0.0745174, acc 0.96875
2020-02-08T03:20:40.856069: step 1872, loss 0.125782, acc 0.96875
2020-02-08T03:20:40.973606: step 1873, loss 0.171353, acc 0.9375
2020-02-08T03:20:41.089755: step 1874, loss 0.14785, acc 0.953125
2020-02-08T03:20:41.204562: step 1875, loss 0.0595121, acc 0.984375
2020-02-08T03:20:41.321089: step 1876, loss 0.130051, acc 0.953125
2020-02-08T03:20:41.437755: step 1877, loss 0.0802282, acc 0.953125
2020-02-08T03:20:41.556051: step 1878, loss 0.131412, acc 0.9375
2020-02-08T03:20:41.672415: step 1879, loss 0.0480221, acc 0.984375
2020-02-08T03:20:41.788454: step 1880, loss 0.138043, acc 0.9375
2020-02-08T03:20:41.903895: step 1881, loss 0.0515148, acc 0.984375
2020-02-08T03:20:42.021190: step 1882, loss 0.156427, acc 0.9375
2020-02-08T03:20:42.135078: step 1883, loss 0.097688, acc 0.9375
2020-02-08T03:20:42.248186: step 1884, loss 0.174036, acc 0.953125
2020-02-08T03:20:42.366262: step 1885, loss 0.178985, acc 0.90625
2020-02-08T03:20:42.481866: step 1886, loss 0.0626108, acc 0.984375
2020-02-08T03:20:42.598796: step 1887, loss 0.0389135, acc 0.984375
2020-02-08T03:20:42.714279: step 1888, loss 0.0722995, acc 0.984375
2020-02-08T03:20:42.830580: step 1889, loss 0.166659, acc 0.953125
2020-02-08T03:20:42.949757: step 1890, loss 0.0884604, acc 0.953125
2020-02-08T03:20:43.067262: step 1891, loss 0.0837057, acc 0.984375
2020-02-08T03:20:43.182553: step 1892, loss 0.135636, acc 0.953125
2020-02-08T03:20:43.299576: step 1893, loss 0.174551, acc 0.9375
2020-02-08T03:20:43.417643: step 1894, loss 0.109237, acc 0.9375
2020-02-08T03:20:43.534135: step 1895, loss 0.107713, acc 0.96875
2020-02-08T03:20:43.649666: step 1896, loss 0.0699424, acc 0.96875
2020-02-08T03:20:43.770348: step 1897, loss 0.168337, acc 0.9375
2020-02-08T03:20:43.886855: step 1898, loss 0.0994444, acc 0.953125
2020-02-08T03:20:44.004959: step 1899, loss 0.0884288, acc 0.984375
2020-02-08T03:20:44.122238: step 1900, loss 0.101064, acc 0.96875

Evaluation:
2020-02-08T03:20:44.313054: step 1900, loss 0.735938, acc 0.712946

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-1900

2020-02-08T03:20:45.900037: step 1901, loss 0.0585534, acc 0.984375
2020-02-08T03:20:46.017524: step 1902, loss 0.0542858, acc 0.984375
2020-02-08T03:20:46.134049: step 1903, loss 0.0720824, acc 0.953125
2020-02-08T03:20:46.251582: step 1904, loss 0.146357, acc 0.9375
2020-02-08T03:20:46.366958: step 1905, loss 0.182967, acc 0.921875
2020-02-08T03:20:46.485391: step 1906, loss 0.113624, acc 0.9375
2020-02-08T03:20:46.602307: step 1907, loss 0.139003, acc 0.9375
2020-02-08T03:20:46.719922: step 1908, loss 0.160645, acc 0.90625
2020-02-08T03:20:46.834988: step 1909, loss 0.0921153, acc 0.96875
2020-02-08T03:20:46.955827: step 1910, loss 0.0605428, acc 0.96875
2020-02-08T03:20:47.071146: step 1911, loss 0.0975673, acc 0.953125
2020-02-08T03:20:47.187012: step 1912, loss 0.0928857, acc 0.9375
2020-02-08T03:20:47.305709: step 1913, loss 0.14547, acc 0.96875
2020-02-08T03:20:47.421647: step 1914, loss 0.078711, acc 0.96875
2020-02-08T03:20:47.538627: step 1915, loss 0.120055, acc 0.96875
2020-02-08T03:20:47.660532: step 1916, loss 0.0680505, acc 0.984375
2020-02-08T03:20:47.777873: step 1917, loss 0.214455, acc 0.9375
2020-02-08T03:20:47.899669: step 1918, loss 0.11233, acc 0.9375
2020-02-08T03:20:48.017312: step 1919, loss 0.0929582, acc 0.984375
2020-02-08T03:20:48.134948: step 1920, loss 0.129964, acc 0.953125
2020-02-08T03:20:48.253786: step 1921, loss 0.0799904, acc 0.96875
2020-02-08T03:20:48.371952: step 1922, loss 0.0494432, acc 0.984375
2020-02-08T03:20:48.486981: step 1923, loss 0.122442, acc 0.953125
2020-02-08T03:20:48.605436: step 1924, loss 0.164431, acc 0.9375
2020-02-08T03:20:48.720886: step 1925, loss 0.0560013, acc 0.984375
2020-02-08T03:20:48.834839: step 1926, loss 0.110369, acc 0.953125
2020-02-08T03:20:48.952571: step 1927, loss 0.106073, acc 0.984375
2020-02-08T03:20:49.070242: step 1928, loss 0.0726501, acc 0.984375
2020-02-08T03:20:49.189623: step 1929, loss 0.0973852, acc 0.96875
2020-02-08T03:20:49.308125: step 1930, loss 0.106793, acc 0.96875
2020-02-08T03:20:49.428446: step 1931, loss 0.118131, acc 0.96875
2020-02-08T03:20:49.548584: step 1932, loss 0.11851, acc 0.953125
2020-02-08T03:20:49.668718: step 1933, loss 0.0783893, acc 0.96875
2020-02-08T03:20:49.787459: step 1934, loss 0.121646, acc 0.921875
2020-02-08T03:20:49.907625: step 1935, loss 0.132814, acc 0.921875
2020-02-08T03:20:50.023297: step 1936, loss 0.204283, acc 0.921875
2020-02-08T03:20:50.137815: step 1937, loss 0.0709268, acc 0.96875
2020-02-08T03:20:50.255148: step 1938, loss 0.138531, acc 0.953125
2020-02-08T03:20:50.371867: step 1939, loss 0.050016, acc 1
2020-02-08T03:20:50.490223: step 1940, loss 0.094568, acc 0.953125
2020-02-08T03:20:50.607961: step 1941, loss 0.11148, acc 0.96875
2020-02-08T03:20:50.724896: step 1942, loss 0.0826065, acc 0.953125
2020-02-08T03:20:50.839974: step 1943, loss 0.0752935, acc 0.984375
2020-02-08T03:20:50.958468: step 1944, loss 0.0975071, acc 0.96875
2020-02-08T03:20:51.078312: step 1945, loss 0.0936723, acc 0.96875
2020-02-08T03:20:51.196133: step 1946, loss 0.125526, acc 0.953125
2020-02-08T03:20:51.310909: step 1947, loss 0.143983, acc 0.953125
2020-02-08T03:20:51.424715: step 1948, loss 0.0935077, acc 0.984375
2020-02-08T03:20:51.578063: step 1949, loss 0.107733, acc 0.953125
2020-02-08T03:20:51.695122: step 1950, loss 0.0950694, acc 0.966667
2020-02-08T03:20:51.815481: step 1951, loss 0.0489272, acc 1
2020-02-08T03:20:51.931051: step 1952, loss 0.0895089, acc 0.953125
2020-02-08T03:20:52.051778: step 1953, loss 0.0674167, acc 0.96875
2020-02-08T03:20:52.167956: step 1954, loss 0.0853434, acc 0.96875
2020-02-08T03:20:52.287717: step 1955, loss 0.0972573, acc 0.953125
2020-02-08T03:20:52.403907: step 1956, loss 0.123347, acc 0.953125
2020-02-08T03:20:52.518888: step 1957, loss 0.0932713, acc 0.953125
2020-02-08T03:20:52.636233: step 1958, loss 0.043142, acc 1
2020-02-08T03:20:52.752900: step 1959, loss 0.0485854, acc 0.984375
2020-02-08T03:20:52.871780: step 1960, loss 0.0586993, acc 0.984375
2020-02-08T03:20:52.989239: step 1961, loss 0.0195974, acc 1
2020-02-08T03:20:53.114824: step 1962, loss 0.06402, acc 0.96875
2020-02-08T03:20:53.231840: step 1963, loss 0.153317, acc 0.953125
2020-02-08T03:20:53.352810: step 1964, loss 0.0982398, acc 0.953125
2020-02-08T03:20:53.472192: step 1965, loss 0.0546494, acc 1
2020-02-08T03:20:53.588656: step 1966, loss 0.0924166, acc 0.953125
2020-02-08T03:20:53.708255: step 1967, loss 0.0879699, acc 0.9375
2020-02-08T03:20:53.826174: step 1968, loss 0.0510783, acc 0.984375
2020-02-08T03:20:53.944121: step 1969, loss 0.0345846, acc 1
2020-02-08T03:20:54.061958: step 1970, loss 0.112046, acc 0.953125
2020-02-08T03:20:54.176900: step 1971, loss 0.0606203, acc 0.984375
2020-02-08T03:20:54.296209: step 1972, loss 0.0510559, acc 0.96875
2020-02-08T03:20:54.413855: step 1973, loss 0.190501, acc 0.953125
2020-02-08T03:20:54.527743: step 1974, loss 0.120329, acc 0.953125
2020-02-08T03:20:54.645703: step 1975, loss 0.0541187, acc 0.96875
2020-02-08T03:20:54.763568: step 1976, loss 0.0720939, acc 0.96875
2020-02-08T03:20:54.883589: step 1977, loss 0.217571, acc 0.9375
2020-02-08T03:20:55.002699: step 1978, loss 0.0297576, acc 1
2020-02-08T03:20:55.117937: step 1979, loss 0.0503048, acc 1
2020-02-08T03:20:55.235006: step 1980, loss 0.0596696, acc 0.96875
2020-02-08T03:20:55.357039: step 1981, loss 0.0700226, acc 0.96875
2020-02-08T03:20:55.475159: step 1982, loss 0.0669894, acc 0.96875
2020-02-08T03:20:55.592921: step 1983, loss 0.0610084, acc 0.953125
2020-02-08T03:20:55.710196: step 1984, loss 0.0989941, acc 0.96875
2020-02-08T03:20:55.826040: step 1985, loss 0.148429, acc 0.921875
2020-02-08T03:20:55.944395: step 1986, loss 0.132409, acc 0.9375
2020-02-08T03:20:56.060593: step 1987, loss 0.0592256, acc 0.96875
2020-02-08T03:20:56.176060: step 1988, loss 0.0405377, acc 1
2020-02-08T03:20:56.292726: step 1989, loss 0.0461497, acc 0.984375
2020-02-08T03:20:56.409962: step 1990, loss 0.0537764, acc 0.984375
2020-02-08T03:20:56.526445: step 1991, loss 0.0587385, acc 0.984375
2020-02-08T03:20:56.647713: step 1992, loss 0.0520357, acc 0.984375
2020-02-08T03:20:56.764992: step 1993, loss 0.081758, acc 0.96875
2020-02-08T03:20:56.879577: step 1994, loss 0.0987763, acc 0.953125
2020-02-08T03:20:56.998359: step 1995, loss 0.059714, acc 0.984375
2020-02-08T03:20:57.115520: step 1996, loss 0.106474, acc 0.9375
2020-02-08T03:20:57.229863: step 1997, loss 0.054727, acc 0.984375
2020-02-08T03:20:57.347428: step 1998, loss 0.109996, acc 0.96875
2020-02-08T03:20:57.463171: step 1999, loss 0.0525946, acc 0.96875
2020-02-08T03:20:57.579593: step 2000, loss 0.162668, acc 0.9375

Evaluation:
2020-02-08T03:20:57.767795: step 2000, loss 0.753796, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2000

2020-02-08T03:20:59.283443: step 2001, loss 0.117787, acc 0.96875
2020-02-08T03:20:59.400320: step 2002, loss 0.111849, acc 0.96875
2020-02-08T03:20:59.517210: step 2003, loss 0.0940757, acc 0.984375
2020-02-08T03:20:59.632632: step 2004, loss 0.0516399, acc 0.96875
2020-02-08T03:20:59.749738: step 2005, loss 0.106587, acc 0.96875
2020-02-08T03:20:59.867589: step 2006, loss 0.0819778, acc 0.96875
2020-02-08T03:20:59.985639: step 2007, loss 0.0655714, acc 0.96875
2020-02-08T03:21:00.104463: step 2008, loss 0.0358202, acc 1
2020-02-08T03:21:00.219207: step 2009, loss 0.130378, acc 0.96875
2020-02-08T03:21:00.336952: step 2010, loss 0.0761727, acc 0.96875
2020-02-08T03:21:00.454945: step 2011, loss 0.0261982, acc 1
2020-02-08T03:21:00.571462: step 2012, loss 0.164571, acc 0.9375
2020-02-08T03:21:00.688459: step 2013, loss 0.0797529, acc 0.96875
2020-02-08T03:21:00.807441: step 2014, loss 0.141986, acc 0.9375
2020-02-08T03:21:00.923382: step 2015, loss 0.104685, acc 0.96875
2020-02-08T03:21:01.039825: step 2016, loss 0.0506405, acc 0.984375
2020-02-08T03:21:01.159906: step 2017, loss 0.0974364, acc 0.96875
2020-02-08T03:21:01.276089: step 2018, loss 0.0367496, acc 1
2020-02-08T03:21:01.391795: step 2019, loss 0.114435, acc 0.953125
2020-02-08T03:21:01.512215: step 2020, loss 0.107349, acc 0.96875
2020-02-08T03:21:01.626612: step 2021, loss 0.0346624, acc 1
2020-02-08T03:21:01.744027: step 2022, loss 0.0593016, acc 0.984375
2020-02-08T03:21:01.861876: step 2023, loss 0.0944174, acc 0.953125
2020-02-08T03:21:01.977467: step 2024, loss 0.124606, acc 0.96875
2020-02-08T03:21:02.092631: step 2025, loss 0.0662969, acc 0.984375
2020-02-08T03:21:02.208496: step 2026, loss 0.0911572, acc 0.953125
2020-02-08T03:21:02.322426: step 2027, loss 0.0525665, acc 0.96875
2020-02-08T03:21:02.441135: step 2028, loss 0.0843953, acc 0.96875
2020-02-08T03:21:02.558335: step 2029, loss 0.0693526, acc 0.953125
2020-02-08T03:21:02.674900: step 2030, loss 0.168759, acc 0.953125
2020-02-08T03:21:02.793187: step 2031, loss 0.0422869, acc 1
2020-02-08T03:21:02.911226: step 2032, loss 0.121145, acc 0.9375
2020-02-08T03:21:03.026732: step 2033, loss 0.0806953, acc 0.96875
2020-02-08T03:21:03.143790: step 2034, loss 0.0813565, acc 0.96875
2020-02-08T03:21:03.260837: step 2035, loss 0.140692, acc 0.9375
2020-02-08T03:21:03.373624: step 2036, loss 0.0769979, acc 0.96875
2020-02-08T03:21:03.488210: step 2037, loss 0.119784, acc 0.96875
2020-02-08T03:21:03.607893: step 2038, loss 0.10373, acc 0.953125
2020-02-08T03:21:03.724856: step 2039, loss 0.0475272, acc 1
2020-02-08T03:21:03.840348: step 2040, loss 0.0452968, acc 0.984375
2020-02-08T03:21:03.958003: step 2041, loss 0.0376456, acc 0.984375
2020-02-08T03:21:04.074877: step 2042, loss 0.0674578, acc 0.96875
2020-02-08T03:21:04.193128: step 2043, loss 0.120803, acc 0.96875
2020-02-08T03:21:04.311521: step 2044, loss 0.164355, acc 0.9375
2020-02-08T03:21:04.426746: step 2045, loss 0.0633757, acc 0.984375
2020-02-08T03:21:04.544570: step 2046, loss 0.0895105, acc 0.953125
2020-02-08T03:21:04.662200: step 2047, loss 0.0536776, acc 0.984375
2020-02-08T03:21:04.776644: step 2048, loss 0.0678601, acc 0.96875
2020-02-08T03:21:04.894608: step 2049, loss 0.115033, acc 0.9375
2020-02-08T03:21:05.014370: step 2050, loss 0.0783045, acc 0.96875
2020-02-08T03:21:05.129159: step 2051, loss 0.0250092, acc 1
2020-02-08T03:21:05.248288: step 2052, loss 0.0327329, acc 1
2020-02-08T03:21:05.363911: step 2053, loss 0.0896308, acc 0.953125
2020-02-08T03:21:05.479799: step 2054, loss 0.0337745, acc 1
2020-02-08T03:21:05.598110: step 2055, loss 0.0382603, acc 0.984375
2020-02-08T03:21:05.716346: step 2056, loss 0.0624461, acc 0.984375
2020-02-08T03:21:05.835748: step 2057, loss 0.0495466, acc 0.984375
2020-02-08T03:21:05.953848: step 2058, loss 0.119705, acc 0.9375
2020-02-08T03:21:06.069984: step 2059, loss 0.0552944, acc 0.984375
2020-02-08T03:21:06.186529: step 2060, loss 0.123716, acc 0.953125
2020-02-08T03:21:06.303904: step 2061, loss 0.0481423, acc 0.984375
2020-02-08T03:21:06.421283: step 2062, loss 0.0466382, acc 0.984375
2020-02-08T03:21:06.538030: step 2063, loss 0.221121, acc 0.921875
2020-02-08T03:21:06.655818: step 2064, loss 0.104128, acc 0.953125
2020-02-08T03:21:06.773318: step 2065, loss 0.0907836, acc 0.96875
2020-02-08T03:21:06.887451: step 2066, loss 0.0657182, acc 0.984375
2020-02-08T03:21:07.005867: step 2067, loss 0.106716, acc 0.953125
2020-02-08T03:21:07.121558: step 2068, loss 0.0778683, acc 0.96875
2020-02-08T03:21:07.238090: step 2069, loss 0.111086, acc 0.9375
2020-02-08T03:21:07.358644: step 2070, loss 0.127537, acc 0.953125
2020-02-08T03:21:07.475339: step 2071, loss 0.0990246, acc 0.984375
2020-02-08T03:21:07.591510: step 2072, loss 0.114948, acc 0.953125
2020-02-08T03:21:07.712985: step 2073, loss 0.138069, acc 0.921875
2020-02-08T03:21:07.829580: step 2074, loss 0.0504828, acc 0.984375
2020-02-08T03:21:07.947114: step 2075, loss 0.0934101, acc 0.96875
2020-02-08T03:21:08.064865: step 2076, loss 0.0200161, acc 1
2020-02-08T03:21:08.180847: step 2077, loss 0.0479066, acc 0.984375
2020-02-08T03:21:08.298749: step 2078, loss 0.0606059, acc 0.984375
2020-02-08T03:21:08.416925: step 2079, loss 0.207313, acc 0.921875
2020-02-08T03:21:08.531402: step 2080, loss 0.0926777, acc 0.96875
2020-02-08T03:21:08.647975: step 2081, loss 0.0970615, acc 0.984375
2020-02-08T03:21:08.764083: step 2082, loss 0.0746602, acc 0.96875
2020-02-08T03:21:08.889544: step 2083, loss 0.0565876, acc 0.984375
2020-02-08T03:21:09.008302: step 2084, loss 0.0437668, acc 1
2020-02-08T03:21:09.127354: step 2085, loss 0.0893538, acc 0.953125
2020-02-08T03:21:09.243416: step 2086, loss 0.11147, acc 0.96875
2020-02-08T03:21:09.362094: step 2087, loss 0.0675444, acc 0.984375
2020-02-08T03:21:09.476991: step 2088, loss 0.239522, acc 0.90625
2020-02-08T03:21:09.595676: step 2089, loss 0.0497825, acc 0.984375
2020-02-08T03:21:09.714676: step 2090, loss 0.0823788, acc 0.96875
2020-02-08T03:21:09.831076: step 2091, loss 0.0639366, acc 0.984375
2020-02-08T03:21:09.950828: step 2092, loss 0.0400725, acc 1
2020-02-08T03:21:10.067858: step 2093, loss 0.0722691, acc 0.953125
2020-02-08T03:21:10.182796: step 2094, loss 0.036562, acc 1
2020-02-08T03:21:10.299005: step 2095, loss 0.10872, acc 0.9375
2020-02-08T03:21:10.415703: step 2096, loss 0.0499778, acc 1
2020-02-08T03:21:10.531952: step 2097, loss 0.0928367, acc 0.953125
2020-02-08T03:21:10.649823: step 2098, loss 0.0682763, acc 0.984375
2020-02-08T03:21:10.767100: step 2099, loss 0.0259889, acc 1
2020-02-08T03:21:10.880539: step 2100, loss 0.0573219, acc 0.966667

Evaluation:
2020-02-08T03:21:11.066370: step 2100, loss 0.766093, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2100

2020-02-08T03:21:12.581799: step 2101, loss 0.0903644, acc 0.96875
2020-02-08T03:21:12.701455: step 2102, loss 0.0452724, acc 0.984375
2020-02-08T03:21:12.818850: step 2103, loss 0.0768624, acc 0.96875
2020-02-08T03:21:12.936498: step 2104, loss 0.0397552, acc 0.984375
2020-02-08T03:21:13.056320: step 2105, loss 0.0411299, acc 1
2020-02-08T03:21:13.172435: step 2106, loss 0.0652295, acc 0.96875
2020-02-08T03:21:13.289370: step 2107, loss 0.0753972, acc 0.96875
2020-02-08T03:21:13.407158: step 2108, loss 0.102528, acc 0.96875
2020-02-08T03:21:13.523852: step 2109, loss 0.0604581, acc 0.984375
2020-02-08T03:21:13.642927: step 2110, loss 0.0407195, acc 0.984375
2020-02-08T03:21:13.765254: step 2111, loss 0.0360805, acc 0.984375
2020-02-08T03:21:13.882341: step 2112, loss 0.0406045, acc 1
2020-02-08T03:21:14.001318: step 2113, loss 0.042853, acc 1
2020-02-08T03:21:14.120635: step 2114, loss 0.0234068, acc 1
2020-02-08T03:21:14.237855: step 2115, loss 0.0339628, acc 1
2020-02-08T03:21:14.354915: step 2116, loss 0.0871964, acc 0.96875
2020-02-08T03:21:14.470452: step 2117, loss 0.127302, acc 0.953125
2020-02-08T03:21:14.583033: step 2118, loss 0.0604725, acc 1
2020-02-08T03:21:14.698898: step 2119, loss 0.0696138, acc 0.96875
2020-02-08T03:21:14.816741: step 2120, loss 0.056245, acc 1
2020-02-08T03:21:14.930537: step 2121, loss 0.0475151, acc 0.984375
2020-02-08T03:21:15.052825: step 2122, loss 0.03763, acc 0.984375
2020-02-08T03:21:15.169882: step 2123, loss 0.0868549, acc 0.984375
2020-02-08T03:21:15.286749: step 2124, loss 0.0377048, acc 1
2020-02-08T03:21:15.409294: step 2125, loss 0.0462604, acc 0.984375
2020-02-08T03:21:15.528109: step 2126, loss 0.0661392, acc 0.984375
2020-02-08T03:21:15.646628: step 2127, loss 0.0909543, acc 0.96875
2020-02-08T03:21:15.763513: step 2128, loss 0.0177586, acc 1
2020-02-08T03:21:15.879096: step 2129, loss 0.0551381, acc 0.984375
2020-02-08T03:21:15.997144: step 2130, loss 0.101996, acc 0.953125
2020-02-08T03:21:16.113616: step 2131, loss 0.0571042, acc 0.984375
2020-02-08T03:21:16.228017: step 2132, loss 0.0541246, acc 0.984375
2020-02-08T03:21:16.347617: step 2133, loss 0.0139306, acc 1
2020-02-08T03:21:16.464008: step 2134, loss 0.0431302, acc 0.984375
2020-02-08T03:21:16.579688: step 2135, loss 0.0651405, acc 0.984375
2020-02-08T03:21:16.700693: step 2136, loss 0.0692827, acc 0.984375
2020-02-08T03:21:16.820924: step 2137, loss 0.0619424, acc 0.96875
2020-02-08T03:21:16.939530: step 2138, loss 0.0296061, acc 1
2020-02-08T03:21:17.056577: step 2139, loss 0.0759706, acc 0.984375
2020-02-08T03:21:17.173018: step 2140, loss 0.0306881, acc 0.984375
2020-02-08T03:21:17.292380: step 2141, loss 0.0334211, acc 1
2020-02-08T03:21:17.411695: step 2142, loss 0.045375, acc 0.96875
2020-02-08T03:21:17.526401: step 2143, loss 0.137103, acc 0.953125
2020-02-08T03:21:17.641964: step 2144, loss 0.0724699, acc 0.96875
2020-02-08T03:21:17.761170: step 2145, loss 0.0366092, acc 1
2020-02-08T03:21:17.875019: step 2146, loss 0.0423754, acc 1
2020-02-08T03:21:17.992160: step 2147, loss 0.0874561, acc 0.96875
2020-02-08T03:21:18.110298: step 2148, loss 0.0458367, acc 0.96875
2020-02-08T03:21:18.225235: step 2149, loss 0.0628527, acc 0.96875
2020-02-08T03:21:18.341492: step 2150, loss 0.0806796, acc 0.953125
2020-02-08T03:21:18.458862: step 2151, loss 0.0899688, acc 0.96875
2020-02-08T03:21:18.575287: step 2152, loss 0.0588254, acc 0.96875
2020-02-08T03:21:18.692106: step 2153, loss 0.0837844, acc 0.984375
2020-02-08T03:21:18.810369: step 2154, loss 0.0396862, acc 0.984375
2020-02-08T03:21:18.926632: step 2155, loss 0.0372333, acc 0.984375
2020-02-08T03:21:19.043761: step 2156, loss 0.0461455, acc 0.984375
2020-02-08T03:21:19.161462: step 2157, loss 0.0146137, acc 1
2020-02-08T03:21:19.276436: step 2158, loss 0.103689, acc 0.96875
2020-02-08T03:21:19.397359: step 2159, loss 0.0485537, acc 0.96875
2020-02-08T03:21:19.512363: step 2160, loss 0.0753956, acc 0.984375
2020-02-08T03:21:19.628758: step 2161, loss 0.115188, acc 0.953125
2020-02-08T03:21:19.746199: step 2162, loss 0.0348367, acc 1
2020-02-08T03:21:19.867654: step 2163, loss 0.0954085, acc 0.96875
2020-02-08T03:21:19.984965: step 2164, loss 0.0592215, acc 0.984375
2020-02-08T03:21:20.103049: step 2165, loss 0.0571125, acc 0.984375
2020-02-08T03:21:20.219351: step 2166, loss 0.0312541, acc 1
2020-02-08T03:21:20.334008: step 2167, loss 0.0461717, acc 0.984375
2020-02-08T03:21:20.451351: step 2168, loss 0.0812025, acc 0.953125
2020-02-08T03:21:20.568963: step 2169, loss 0.199198, acc 0.9375
2020-02-08T03:21:20.687127: step 2170, loss 0.0518936, acc 0.96875
2020-02-08T03:21:20.805710: step 2171, loss 0.0944013, acc 0.953125
2020-02-08T03:21:20.921359: step 2172, loss 0.209174, acc 0.90625
2020-02-08T03:21:21.039799: step 2173, loss 0.0783536, acc 0.984375
2020-02-08T03:21:21.157092: step 2174, loss 0.0459075, acc 0.984375
2020-02-08T03:21:21.270930: step 2175, loss 0.0540414, acc 0.984375
2020-02-08T03:21:21.389403: step 2176, loss 0.0944209, acc 0.96875
2020-02-08T03:21:21.782180: step 2177, loss 0.0369606, acc 1
2020-02-08T03:21:21.908092: step 2178, loss 0.0420724, acc 1
2020-02-08T03:21:22.024273: step 2179, loss 0.0269768, acc 1
2020-02-08T03:21:22.141764: step 2180, loss 0.0514758, acc 0.96875
2020-02-08T03:21:22.259322: step 2181, loss 0.0888499, acc 0.953125
2020-02-08T03:21:22.378181: step 2182, loss 0.0442428, acc 0.984375
2020-02-08T03:21:22.499265: step 2183, loss 0.0519802, acc 1
2020-02-08T03:21:22.615999: step 2184, loss 0.118045, acc 0.96875
2020-02-08T03:21:22.731938: step 2185, loss 0.0884115, acc 0.96875
2020-02-08T03:21:22.850959: step 2186, loss 0.0354963, acc 0.984375
2020-02-08T03:21:22.965427: step 2187, loss 0.0214031, acc 1
2020-02-08T03:21:23.082839: step 2188, loss 0.100069, acc 0.953125
2020-02-08T03:21:23.200393: step 2189, loss 0.0310316, acc 1
2020-02-08T03:21:23.318259: step 2190, loss 0.0343506, acc 0.984375
2020-02-08T03:21:23.435453: step 2191, loss 0.0613764, acc 0.953125
2020-02-08T03:21:23.550954: step 2192, loss 0.0399754, acc 1
2020-02-08T03:21:23.671816: step 2193, loss 0.0259759, acc 1
2020-02-08T03:21:23.790009: step 2194, loss 0.0213314, acc 1
2020-02-08T03:21:23.908326: step 2195, loss 0.155444, acc 0.921875
2020-02-08T03:21:24.022853: step 2196, loss 0.0487448, acc 0.984375
2020-02-08T03:21:24.141814: step 2197, loss 0.121793, acc 0.953125
2020-02-08T03:21:24.256853: step 2198, loss 0.0425989, acc 0.984375
2020-02-08T03:21:24.373675: step 2199, loss 0.0260365, acc 1
2020-02-08T03:21:24.490359: step 2200, loss 0.0592497, acc 0.984375

Evaluation:
2020-02-08T03:21:24.677645: step 2200, loss 0.786118, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2200

2020-02-08T03:21:26.214253: step 2201, loss 0.0254663, acc 1
2020-02-08T03:21:26.333509: step 2202, loss 0.0853866, acc 0.953125
2020-02-08T03:21:26.449608: step 2203, loss 0.0321671, acc 1
2020-02-08T03:21:26.566505: step 2204, loss 0.0542028, acc 0.984375
2020-02-08T03:21:26.684288: step 2205, loss 0.0471866, acc 0.96875
2020-02-08T03:21:26.798947: step 2206, loss 0.0544649, acc 0.984375
2020-02-08T03:21:26.916123: step 2207, loss 0.0519036, acc 0.984375
2020-02-08T03:21:27.032439: step 2208, loss 0.039842, acc 0.96875
2020-02-08T03:21:27.148075: step 2209, loss 0.0391944, acc 1
2020-02-08T03:21:27.266288: step 2210, loss 0.110092, acc 0.953125
2020-02-08T03:21:27.380669: step 2211, loss 0.0211143, acc 1
2020-02-08T03:21:27.496910: step 2212, loss 0.032656, acc 1
2020-02-08T03:21:27.613080: step 2213, loss 0.0913421, acc 0.953125
2020-02-08T03:21:27.729139: step 2214, loss 0.0460693, acc 1
2020-02-08T03:21:27.847071: step 2215, loss 0.0461674, acc 0.96875
2020-02-08T03:21:27.963784: step 2216, loss 0.0393357, acc 0.984375
2020-02-08T03:21:28.080936: step 2217, loss 0.052077, acc 0.984375
2020-02-08T03:21:28.198706: step 2218, loss 0.0213625, acc 1
2020-02-08T03:21:28.315551: step 2219, loss 0.0666604, acc 0.96875
2020-02-08T03:21:28.432072: step 2220, loss 0.081073, acc 0.96875
2020-02-08T03:21:28.549636: step 2221, loss 0.0701154, acc 0.984375
2020-02-08T03:21:28.665191: step 2222, loss 0.0616171, acc 1
2020-02-08T03:21:28.781058: step 2223, loss 0.067914, acc 0.984375
2020-02-08T03:21:28.896894: step 2224, loss 0.0664463, acc 0.96875
2020-02-08T03:21:29.015932: step 2225, loss 0.125578, acc 0.96875
2020-02-08T03:21:29.132963: step 2226, loss 0.0853716, acc 0.953125
2020-02-08T03:21:29.251394: step 2227, loss 0.11237, acc 0.96875
2020-02-08T03:21:29.372151: step 2228, loss 0.0463303, acc 0.984375
2020-02-08T03:21:29.488795: step 2229, loss 0.0609112, acc 0.96875
2020-02-08T03:21:29.605760: step 2230, loss 0.103157, acc 0.96875
2020-02-08T03:21:29.723298: step 2231, loss 0.0984577, acc 0.96875
2020-02-08T03:21:29.840680: step 2232, loss 0.109939, acc 0.96875
2020-02-08T03:21:29.956667: step 2233, loss 0.0557381, acc 0.984375
2020-02-08T03:21:30.074257: step 2234, loss 0.0264896, acc 1
2020-02-08T03:21:30.192636: step 2235, loss 0.0757299, acc 0.96875
2020-02-08T03:21:30.311521: step 2236, loss 0.0563745, acc 0.953125
2020-02-08T03:21:30.427360: step 2237, loss 0.0838547, acc 0.984375
2020-02-08T03:21:30.546522: step 2238, loss 0.0520107, acc 0.984375
2020-02-08T03:21:30.663731: step 2239, loss 0.0932376, acc 0.984375
2020-02-08T03:21:30.779425: step 2240, loss 0.0332046, acc 1
2020-02-08T03:21:30.895290: step 2241, loss 0.0835291, acc 0.96875
2020-02-08T03:21:31.011868: step 2242, loss 0.0348161, acc 0.984375
2020-02-08T03:21:31.127576: step 2243, loss 0.0623577, acc 0.96875
2020-02-08T03:21:31.246186: step 2244, loss 0.046389, acc 0.984375
2020-02-08T03:21:31.365535: step 2245, loss 0.0540893, acc 0.984375
2020-02-08T03:21:31.480945: step 2246, loss 0.1234, acc 0.96875
2020-02-08T03:21:31.596245: step 2247, loss 0.0473944, acc 0.953125
2020-02-08T03:21:31.712734: step 2248, loss 0.0370506, acc 0.984375
2020-02-08T03:21:31.829211: step 2249, loss 0.0852009, acc 0.96875
2020-02-08T03:21:31.944488: step 2250, loss 0.0588695, acc 0.966667
2020-02-08T03:21:32.067928: step 2251, loss 0.00972226, acc 1
2020-02-08T03:21:32.184828: step 2252, loss 0.041535, acc 0.984375
2020-02-08T03:21:32.304978: step 2253, loss 0.0282188, acc 0.984375
2020-02-08T03:21:32.421083: step 2254, loss 0.0153831, acc 1
2020-02-08T03:21:32.539729: step 2255, loss 0.118307, acc 0.9375
2020-02-08T03:21:32.657856: step 2256, loss 0.0842452, acc 0.953125
2020-02-08T03:21:32.774213: step 2257, loss 0.051813, acc 0.984375
2020-02-08T03:21:32.891201: step 2258, loss 0.054037, acc 0.984375
2020-02-08T03:21:33.014660: step 2259, loss 0.0201862, acc 1
2020-02-08T03:21:33.131079: step 2260, loss 0.0434177, acc 0.984375
2020-02-08T03:21:33.246424: step 2261, loss 0.0758609, acc 0.984375
2020-02-08T03:21:33.428264: step 2262, loss 0.0913837, acc 0.953125
2020-02-08T03:21:33.580015: step 2263, loss 0.0429086, acc 0.984375
2020-02-08T03:21:33.716992: step 2264, loss 0.0487013, acc 0.96875
2020-02-08T03:21:33.851896: step 2265, loss 0.0792249, acc 0.953125
2020-02-08T03:21:33.981445: step 2266, loss 0.0591254, acc 0.96875
2020-02-08T03:21:34.115642: step 2267, loss 0.135572, acc 0.9375
2020-02-08T03:21:34.253914: step 2268, loss 0.174713, acc 0.921875
2020-02-08T03:21:34.389111: step 2269, loss 0.0403722, acc 0.984375
2020-02-08T03:21:34.528305: step 2270, loss 0.105097, acc 0.96875
2020-02-08T03:21:34.664926: step 2271, loss 0.0149333, acc 1
2020-02-08T03:21:34.800035: step 2272, loss 0.0579844, acc 0.96875
2020-02-08T03:21:34.941903: step 2273, loss 0.0758922, acc 0.96875
2020-02-08T03:21:35.064367: step 2274, loss 0.0538701, acc 0.984375
2020-02-08T03:21:35.194190: step 2275, loss 0.0529348, acc 0.96875
2020-02-08T03:21:35.325081: step 2276, loss 0.0454557, acc 1
2020-02-08T03:21:35.457699: step 2277, loss 0.0236706, acc 1
2020-02-08T03:21:35.591109: step 2278, loss 0.102621, acc 0.9375
2020-02-08T03:21:35.721739: step 2279, loss 0.0363484, acc 1
2020-02-08T03:21:35.853408: step 2280, loss 0.024154, acc 1
2020-02-08T03:21:35.984595: step 2281, loss 0.0134988, acc 1
2020-02-08T03:21:36.116485: step 2282, loss 0.021524, acc 1
2020-02-08T03:21:36.249118: step 2283, loss 0.0569175, acc 0.984375
2020-02-08T03:21:36.376778: step 2284, loss 0.0205046, acc 1
2020-02-08T03:21:36.518490: step 2285, loss 0.0365509, acc 1
2020-02-08T03:21:36.663120: step 2286, loss 0.0915891, acc 0.984375
2020-02-08T03:21:36.822648: step 2287, loss 0.0369512, acc 0.984375
2020-02-08T03:21:36.980798: step 2288, loss 0.0527217, acc 0.984375
2020-02-08T03:21:37.123205: step 2289, loss 0.0445744, acc 1
2020-02-08T03:21:37.248576: step 2290, loss 0.0647331, acc 0.984375
2020-02-08T03:21:37.380710: step 2291, loss 0.0367816, acc 1
2020-02-08T03:21:37.518578: step 2292, loss 0.0447691, acc 1
2020-02-08T03:21:37.653867: step 2293, loss 0.00936291, acc 1
2020-02-08T03:21:37.793887: step 2294, loss 0.0345724, acc 0.984375
2020-02-08T03:21:37.935247: step 2295, loss 0.0338763, acc 1
2020-02-08T03:21:38.074058: step 2296, loss 0.0378575, acc 1
2020-02-08T03:21:38.213702: step 2297, loss 0.0266794, acc 1
2020-02-08T03:21:38.353015: step 2298, loss 0.0693816, acc 0.984375
2020-02-08T03:21:38.492462: step 2299, loss 0.122909, acc 0.96875
2020-02-08T03:21:38.630392: step 2300, loss 0.0131861, acc 1

Evaluation:
2020-02-08T03:21:38.859374: step 2300, loss 0.817988, acc 0.724203

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2300

2020-02-08T03:21:40.416473: step 2301, loss 0.036665, acc 0.984375
2020-02-08T03:21:40.553704: step 2302, loss 0.118453, acc 0.9375
2020-02-08T03:21:40.688793: step 2303, loss 0.0228096, acc 1
2020-02-08T03:21:40.827759: step 2304, loss 0.0521364, acc 0.984375
2020-02-08T03:21:40.965266: step 2305, loss 0.0536145, acc 0.96875
2020-02-08T03:21:41.102216: step 2306, loss 0.0571699, acc 0.984375
2020-02-08T03:21:41.238594: step 2307, loss 0.0476271, acc 0.984375
2020-02-08T03:21:41.373245: step 2308, loss 0.0443187, acc 0.984375
2020-02-08T03:21:41.515300: step 2309, loss 0.0202195, acc 1
2020-02-08T03:21:41.651375: step 2310, loss 0.0715186, acc 0.96875
2020-02-08T03:21:41.776565: step 2311, loss 0.0476777, acc 0.984375
2020-02-08T03:21:41.902316: step 2312, loss 0.014307, acc 1
2020-02-08T03:21:42.031813: step 2313, loss 0.072035, acc 0.96875
2020-02-08T03:21:42.158302: step 2314, loss 0.120977, acc 0.9375
2020-02-08T03:21:42.282472: step 2315, loss 0.0328662, acc 0.984375
2020-02-08T03:21:42.408809: step 2316, loss 0.0129953, acc 1
2020-02-08T03:21:42.533565: step 2317, loss 0.0647599, acc 0.984375
2020-02-08T03:21:42.658366: step 2318, loss 0.0584408, acc 0.984375
2020-02-08T03:21:42.782455: step 2319, loss 0.0394309, acc 0.984375
2020-02-08T03:21:42.909247: step 2320, loss 0.0320676, acc 0.984375
2020-02-08T03:21:43.034935: step 2321, loss 0.027484, acc 1
2020-02-08T03:21:43.163868: step 2322, loss 0.0348262, acc 0.984375
2020-02-08T03:21:43.292283: step 2323, loss 0.0876919, acc 0.96875
2020-02-08T03:21:43.435126: step 2324, loss 0.0551652, acc 0.984375
2020-02-08T03:21:43.579581: step 2325, loss 0.0600292, acc 0.984375
2020-02-08T03:21:43.715950: step 2326, loss 0.0436238, acc 1
2020-02-08T03:21:43.835847: step 2327, loss 0.106025, acc 0.96875
2020-02-08T03:21:43.959304: step 2328, loss 0.0307679, acc 0.984375
2020-02-08T03:21:44.083987: step 2329, loss 0.0675543, acc 0.96875
2020-02-08T03:21:44.212099: step 2330, loss 0.0195465, acc 1
2020-02-08T03:21:44.328307: step 2331, loss 0.0388873, acc 0.984375
2020-02-08T03:21:44.457902: step 2332, loss 0.0411545, acc 0.984375
2020-02-08T03:21:44.572980: step 2333, loss 0.0596569, acc 0.96875
2020-02-08T03:21:44.705137: step 2334, loss 0.0515352, acc 0.984375
2020-02-08T03:21:44.822621: step 2335, loss 0.0460776, acc 0.984375
2020-02-08T03:21:44.945046: step 2336, loss 0.0627803, acc 0.984375
2020-02-08T03:21:45.064502: step 2337, loss 0.0635924, acc 0.953125
2020-02-08T03:21:45.182760: step 2338, loss 0.0359993, acc 1
2020-02-08T03:21:45.306807: step 2339, loss 0.0648838, acc 0.96875
2020-02-08T03:21:45.423851: step 2340, loss 0.0249076, acc 1
2020-02-08T03:21:45.546875: step 2341, loss 0.0798373, acc 0.96875
2020-02-08T03:21:45.667384: step 2342, loss 0.064697, acc 0.984375
2020-02-08T03:21:45.788961: step 2343, loss 0.0332674, acc 0.984375
2020-02-08T03:21:45.909789: step 2344, loss 0.0430636, acc 0.984375
2020-02-08T03:21:46.027673: step 2345, loss 0.0408672, acc 0.96875
2020-02-08T03:21:46.149753: step 2346, loss 0.0336686, acc 0.984375
2020-02-08T03:21:46.274986: step 2347, loss 0.0448226, acc 0.984375
2020-02-08T03:21:46.399752: step 2348, loss 0.0560725, acc 0.984375
2020-02-08T03:21:46.518354: step 2349, loss 0.0454041, acc 0.984375
2020-02-08T03:21:46.636287: step 2350, loss 0.0620782, acc 0.96875
2020-02-08T03:21:46.755411: step 2351, loss 0.049032, acc 0.984375
2020-02-08T03:21:46.872873: step 2352, loss 0.0331144, acc 1
2020-02-08T03:21:47.000691: step 2353, loss 0.115609, acc 0.921875
2020-02-08T03:21:47.125608: step 2354, loss 0.0130193, acc 1
2020-02-08T03:21:47.245919: step 2355, loss 0.0773745, acc 0.96875
2020-02-08T03:21:47.363659: step 2356, loss 0.131936, acc 0.953125
2020-02-08T03:21:47.477532: step 2357, loss 0.0559596, acc 0.96875
2020-02-08T03:21:47.596310: step 2358, loss 0.0503145, acc 0.984375
2020-02-08T03:21:47.721303: step 2359, loss 0.0143992, acc 1
2020-02-08T03:21:47.841291: step 2360, loss 0.0196305, acc 1
2020-02-08T03:21:47.957947: step 2361, loss 0.0626336, acc 0.96875
2020-02-08T03:21:48.076103: step 2362, loss 0.0808388, acc 0.984375
2020-02-08T03:21:48.197792: step 2363, loss 0.0294281, acc 0.984375
2020-02-08T03:21:48.318337: step 2364, loss 0.010065, acc 1
2020-02-08T03:21:48.435745: step 2365, loss 0.060899, acc 0.96875
2020-02-08T03:21:48.553874: step 2366, loss 0.133798, acc 0.9375
2020-02-08T03:21:48.670098: step 2367, loss 0.0240274, acc 1
2020-02-08T03:21:48.786446: step 2368, loss 0.0817597, acc 0.96875
2020-02-08T03:21:48.903200: step 2369, loss 0.0569062, acc 0.96875
2020-02-08T03:21:49.020443: step 2370, loss 0.0172343, acc 1
2020-02-08T03:21:49.134991: step 2371, loss 0.030926, acc 0.984375
2020-02-08T03:21:49.250385: step 2372, loss 0.0546544, acc 0.984375
2020-02-08T03:21:49.371110: step 2373, loss 0.0311243, acc 0.984375
2020-02-08T03:21:49.486715: step 2374, loss 0.059272, acc 0.984375
2020-02-08T03:21:49.604034: step 2375, loss 0.026305, acc 1
2020-02-08T03:21:49.721323: step 2376, loss 0.0533149, acc 0.984375
2020-02-08T03:21:49.840074: step 2377, loss 0.0311615, acc 0.984375
2020-02-08T03:21:49.958561: step 2378, loss 0.0433787, acc 1
2020-02-08T03:21:50.073394: step 2379, loss 0.0262329, acc 1
2020-02-08T03:21:50.193580: step 2380, loss 0.0416684, acc 0.984375
2020-02-08T03:21:50.313812: step 2381, loss 0.0798134, acc 0.96875
2020-02-08T03:21:50.429671: step 2382, loss 0.0106367, acc 1
2020-02-08T03:21:50.545429: step 2383, loss 0.0355163, acc 0.984375
2020-02-08T03:21:50.662489: step 2384, loss 0.0871261, acc 0.984375
2020-02-08T03:21:50.778118: step 2385, loss 0.0411658, acc 0.984375
2020-02-08T03:21:50.896449: step 2386, loss 0.0350801, acc 0.984375
2020-02-08T03:21:51.014055: step 2387, loss 0.0236708, acc 1
2020-02-08T03:21:51.129070: step 2388, loss 0.0270883, acc 0.984375
2020-02-08T03:21:51.243442: step 2389, loss 0.0377144, acc 0.984375
2020-02-08T03:21:51.578490: step 2390, loss 0.0216108, acc 1
2020-02-08T03:21:51.700866: step 2391, loss 0.0408501, acc 0.984375
2020-02-08T03:21:51.817456: step 2392, loss 0.0818316, acc 0.953125
2020-02-08T03:21:51.932784: step 2393, loss 0.0457388, acc 1
2020-02-08T03:21:52.053539: step 2394, loss 0.0774066, acc 0.984375
2020-02-08T03:21:52.172071: step 2395, loss 0.0384933, acc 1
2020-02-08T03:21:52.289183: step 2396, loss 0.107276, acc 0.9375
2020-02-08T03:21:52.410886: step 2397, loss 0.0214156, acc 1
2020-02-08T03:21:52.526644: step 2398, loss 0.0198918, acc 1
2020-02-08T03:21:52.648510: step 2399, loss 0.01735, acc 1
2020-02-08T03:21:52.762185: step 2400, loss 0.0232788, acc 1

Evaluation:
2020-02-08T03:21:52.952666: step 2400, loss 0.848543, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2400

2020-02-08T03:21:54.480035: step 2401, loss 0.0202565, acc 1
2020-02-08T03:21:54.598048: step 2402, loss 0.0389842, acc 1
2020-02-08T03:21:54.716400: step 2403, loss 0.0725776, acc 0.96875
2020-02-08T03:21:54.831116: step 2404, loss 0.0251166, acc 1
2020-02-08T03:21:54.947124: step 2405, loss 0.0328856, acc 0.984375
2020-02-08T03:21:55.065393: step 2406, loss 0.0335767, acc 0.984375
2020-02-08T03:21:55.181435: step 2407, loss 0.0179536, acc 1
2020-02-08T03:21:55.301590: step 2408, loss 0.0566103, acc 0.96875
2020-02-08T03:21:55.418017: step 2409, loss 0.0730927, acc 0.953125
2020-02-08T03:21:55.533708: step 2410, loss 0.023438, acc 1
2020-02-08T03:21:55.650731: step 2411, loss 0.0713648, acc 0.96875
2020-02-08T03:21:55.766937: step 2412, loss 0.0226373, acc 0.984375
2020-02-08T03:21:55.885812: step 2413, loss 0.0204993, acc 1
2020-02-08T03:21:56.003056: step 2414, loss 0.013251, acc 1
2020-02-08T03:21:56.118540: step 2415, loss 0.0517348, acc 0.984375
2020-02-08T03:21:56.232544: step 2416, loss 0.0473793, acc 0.984375
2020-02-08T03:21:56.350568: step 2417, loss 0.0164007, acc 1
2020-02-08T03:21:56.465308: step 2418, loss 0.0336289, acc 0.984375
2020-02-08T03:21:56.578453: step 2419, loss 0.0394752, acc 0.984375
2020-02-08T03:21:56.695913: step 2420, loss 0.0367087, acc 0.984375
2020-02-08T03:21:56.814185: step 2421, loss 0.0673101, acc 0.96875
2020-02-08T03:21:56.928741: step 2422, loss 0.0330934, acc 1
2020-02-08T03:21:57.046116: step 2423, loss 0.0241184, acc 1
2020-02-08T03:21:57.163887: step 2424, loss 0.0326982, acc 0.984375
2020-02-08T03:21:57.278857: step 2425, loss 0.157187, acc 0.9375
2020-02-08T03:21:57.395313: step 2426, loss 0.0309258, acc 1
2020-02-08T03:21:57.513593: step 2427, loss 0.0144188, acc 1
2020-02-08T03:21:57.627863: step 2428, loss 0.0233539, acc 1
2020-02-08T03:21:57.744629: step 2429, loss 0.0624581, acc 0.96875
2020-02-08T03:21:57.861816: step 2430, loss 0.0164483, acc 1
2020-02-08T03:21:57.977784: step 2431, loss 0.0360411, acc 0.984375
2020-02-08T03:21:58.094502: step 2432, loss 0.100852, acc 0.96875
2020-02-08T03:21:58.216114: step 2433, loss 0.0144467, acc 1
2020-02-08T03:21:58.332032: step 2434, loss 0.0646222, acc 0.984375
2020-02-08T03:21:58.449569: step 2435, loss 0.0364723, acc 0.984375
2020-02-08T03:21:58.566010: step 2436, loss 0.031187, acc 0.984375
2020-02-08T03:21:58.680307: step 2437, loss 0.0466773, acc 0.984375
2020-02-08T03:21:58.796999: step 2438, loss 0.0441211, acc 0.984375
2020-02-08T03:21:58.914372: step 2439, loss 0.0235383, acc 1
2020-02-08T03:21:59.028628: step 2440, loss 0.0249904, acc 0.984375
2020-02-08T03:21:59.144958: step 2441, loss 0.0150188, acc 1
2020-02-08T03:21:59.260999: step 2442, loss 0.040976, acc 0.984375
2020-02-08T03:21:59.376467: step 2443, loss 0.0109826, acc 1
2020-02-08T03:21:59.493468: step 2444, loss 0.0208587, acc 1
2020-02-08T03:21:59.610418: step 2445, loss 0.0143183, acc 1
2020-02-08T03:21:59.725739: step 2446, loss 0.0256507, acc 0.984375
2020-02-08T03:21:59.843402: step 2447, loss 0.0168572, acc 1
2020-02-08T03:21:59.961989: step 2448, loss 0.0117125, acc 1
2020-02-08T03:22:00.077688: step 2449, loss 0.0169685, acc 1
2020-02-08T03:22:00.194861: step 2450, loss 0.034959, acc 1
2020-02-08T03:22:00.313287: step 2451, loss 0.0351653, acc 0.984375
2020-02-08T03:22:00.426877: step 2452, loss 0.0713144, acc 0.984375
2020-02-08T03:22:00.540878: step 2453, loss 0.0448569, acc 0.96875
2020-02-08T03:22:00.657681: step 2454, loss 0.0339499, acc 0.984375
2020-02-08T03:22:00.774016: step 2455, loss 0.0368644, acc 0.984375
2020-02-08T03:22:00.890311: step 2456, loss 0.0119395, acc 1
2020-02-08T03:22:01.007261: step 2457, loss 0.0476426, acc 0.984375
2020-02-08T03:22:01.123983: step 2458, loss 0.16299, acc 0.9375
2020-02-08T03:22:01.244687: step 2459, loss 0.0709887, acc 0.96875
2020-02-08T03:22:01.360794: step 2460, loss 0.0591536, acc 0.96875
2020-02-08T03:22:01.477851: step 2461, loss 0.0290239, acc 1
2020-02-08T03:22:01.594795: step 2462, loss 0.035015, acc 0.984375
2020-02-08T03:22:01.715120: step 2463, loss 0.0141877, acc 1
2020-02-08T03:22:01.832235: step 2464, loss 0.0427481, acc 0.984375
2020-02-08T03:22:01.948675: step 2465, loss 0.0495059, acc 0.984375
2020-02-08T03:22:02.062563: step 2466, loss 0.0479236, acc 0.984375
2020-02-08T03:22:02.177978: step 2467, loss 0.0739069, acc 0.96875
2020-02-08T03:22:02.297376: step 2468, loss 0.0281709, acc 1
2020-02-08T03:22:02.414520: step 2469, loss 0.0256602, acc 1
2020-02-08T03:22:02.530782: step 2470, loss 0.0338237, acc 0.984375
2020-02-08T03:22:02.648358: step 2471, loss 0.0489096, acc 0.984375
2020-02-08T03:22:02.767791: step 2472, loss 0.0278849, acc 1
2020-02-08T03:22:02.882171: step 2473, loss 0.0808764, acc 0.96875
2020-02-08T03:22:02.998932: step 2474, loss 0.0157284, acc 1
2020-02-08T03:22:03.112864: step 2475, loss 0.0622595, acc 0.96875
2020-02-08T03:22:03.227491: step 2476, loss 0.0250137, acc 1
2020-02-08T03:22:03.344764: step 2477, loss 0.0296832, acc 1
2020-02-08T03:22:03.462411: step 2478, loss 0.0552, acc 0.984375
2020-02-08T03:22:03.576025: step 2479, loss 0.0649446, acc 0.984375
2020-02-08T03:22:03.689440: step 2480, loss 0.0551659, acc 0.96875
2020-02-08T03:22:03.805471: step 2481, loss 0.0167891, acc 1
2020-02-08T03:22:03.921415: step 2482, loss 0.056844, acc 0.984375
2020-02-08T03:22:04.039251: step 2483, loss 0.0160811, acc 1
2020-02-08T03:22:04.156160: step 2484, loss 0.0728421, acc 0.96875
2020-02-08T03:22:04.271310: step 2485, loss 0.0290021, acc 0.984375
2020-02-08T03:22:04.385349: step 2486, loss 0.040335, acc 0.96875
2020-02-08T03:22:04.504716: step 2487, loss 0.0180866, acc 1
2020-02-08T03:22:04.618891: step 2488, loss 0.0339294, acc 1
2020-02-08T03:22:04.736066: step 2489, loss 0.09963, acc 0.96875
2020-02-08T03:22:04.852256: step 2490, loss 0.0409796, acc 0.984375
2020-02-08T03:22:04.968570: step 2491, loss 0.0218297, acc 1
2020-02-08T03:22:05.084473: step 2492, loss 0.0378268, acc 0.984375
2020-02-08T03:22:05.201769: step 2493, loss 0.0987714, acc 0.953125
2020-02-08T03:22:05.315946: step 2494, loss 0.0084396, acc 1
2020-02-08T03:22:05.433013: step 2495, loss 0.0461348, acc 0.984375
2020-02-08T03:22:05.551091: step 2496, loss 0.023743, acc 1
2020-02-08T03:22:05.666671: step 2497, loss 0.0236516, acc 1
2020-02-08T03:22:05.787703: step 2498, loss 0.0728568, acc 0.953125
2020-02-08T03:22:05.905025: step 2499, loss 0.026094, acc 0.984375
2020-02-08T03:22:06.021337: step 2500, loss 0.0474352, acc 0.984375

Evaluation:
2020-02-08T03:22:06.208266: step 2500, loss 0.872279, acc 0.724203

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2500

2020-02-08T03:22:07.798818: step 2501, loss 0.0161932, acc 1
2020-02-08T03:22:07.915553: step 2502, loss 0.0476745, acc 0.96875
2020-02-08T03:22:08.028859: step 2503, loss 0.00846454, acc 1
2020-02-08T03:22:08.145956: step 2504, loss 0.0284401, acc 1
2020-02-08T03:22:08.266605: step 2505, loss 0.0368451, acc 1
2020-02-08T03:22:08.380134: step 2506, loss 0.0190656, acc 1
2020-02-08T03:22:08.499952: step 2507, loss 0.0105303, acc 1
2020-02-08T03:22:08.616402: step 2508, loss 0.0475937, acc 0.96875
2020-02-08T03:22:08.730850: step 2509, loss 0.0214698, acc 1
2020-02-08T03:22:08.846421: step 2510, loss 0.0701226, acc 0.984375
2020-02-08T03:22:08.964106: step 2511, loss 0.0494288, acc 0.984375
2020-02-08T03:22:09.078889: step 2512, loss 0.0230685, acc 1
2020-02-08T03:22:09.195557: step 2513, loss 0.0195007, acc 1
2020-02-08T03:22:09.313339: step 2514, loss 0.0848812, acc 0.96875
2020-02-08T03:22:09.427851: step 2515, loss 0.00980349, acc 1
2020-02-08T03:22:09.546030: step 2516, loss 0.0481309, acc 1
2020-02-08T03:22:09.666614: step 2517, loss 0.065171, acc 0.96875
2020-02-08T03:22:09.781858: step 2518, loss 0.0501496, acc 0.96875
2020-02-08T03:22:09.898442: step 2519, loss 0.0383165, acc 0.984375
2020-02-08T03:22:10.015197: step 2520, loss 0.0412584, acc 0.96875
2020-02-08T03:22:10.132277: step 2521, loss 0.0283387, acc 0.984375
2020-02-08T03:22:10.247973: step 2522, loss 0.0306379, acc 0.984375
2020-02-08T03:22:10.364415: step 2523, loss 0.0424414, acc 0.96875
2020-02-08T03:22:10.477277: step 2524, loss 0.0247486, acc 0.984375
2020-02-08T03:22:10.590051: step 2525, loss 0.0170978, acc 1
2020-02-08T03:22:10.707167: step 2526, loss 0.069096, acc 0.96875
2020-02-08T03:22:10.823545: step 2527, loss 0.0287463, acc 0.984375
2020-02-08T03:22:10.939501: step 2528, loss 0.112845, acc 0.9375
2020-02-08T03:22:11.053513: step 2529, loss 0.097857, acc 0.953125
2020-02-08T03:22:11.170959: step 2530, loss 0.0317306, acc 1
2020-02-08T03:22:11.286516: step 2531, loss 0.0960354, acc 0.9375
2020-02-08T03:22:11.402675: step 2532, loss 0.014798, acc 1
2020-02-08T03:22:11.520564: step 2533, loss 0.0161266, acc 1
2020-02-08T03:22:11.636048: step 2534, loss 0.0608323, acc 0.96875
2020-02-08T03:22:11.749797: step 2535, loss 0.0685045, acc 0.984375
2020-02-08T03:22:11.867336: step 2536, loss 0.0335315, acc 0.984375
2020-02-08T03:22:11.984222: step 2537, loss 0.0229693, acc 1
2020-02-08T03:22:12.102347: step 2538, loss 0.0317772, acc 0.984375
2020-02-08T03:22:12.218744: step 2539, loss 0.0654182, acc 0.984375
2020-02-08T03:22:12.333576: step 2540, loss 0.052246, acc 0.96875
2020-02-08T03:22:12.451219: step 2541, loss 0.0509677, acc 0.984375
2020-02-08T03:22:12.569359: step 2542, loss 0.0316676, acc 1
2020-02-08T03:22:12.684180: step 2543, loss 0.0622704, acc 0.96875
2020-02-08T03:22:12.803227: step 2544, loss 0.0198613, acc 1
2020-02-08T03:22:12.920663: step 2545, loss 0.025215, acc 0.984375
2020-02-08T03:22:13.036754: step 2546, loss 0.0305301, acc 1
2020-02-08T03:22:13.156363: step 2547, loss 0.0596157, acc 0.96875
2020-02-08T03:22:13.274900: step 2548, loss 0.0248221, acc 1
2020-02-08T03:22:13.389174: step 2549, loss 0.0801749, acc 0.953125
2020-02-08T03:22:13.503338: step 2550, loss 0.024194, acc 1
2020-02-08T03:22:13.620280: step 2551, loss 0.0412283, acc 0.984375
2020-02-08T03:22:13.737542: step 2552, loss 0.0414309, acc 0.984375
2020-02-08T03:22:13.854231: step 2553, loss 0.0070789, acc 1
2020-02-08T03:22:13.971203: step 2554, loss 0.0184941, acc 1
2020-02-08T03:22:14.086881: step 2555, loss 0.036684, acc 0.984375
2020-02-08T03:22:14.202908: step 2556, loss 0.0660523, acc 0.984375
2020-02-08T03:22:14.318197: step 2557, loss 0.0681015, acc 0.96875
2020-02-08T03:22:14.434155: step 2558, loss 0.0340308, acc 0.984375
2020-02-08T03:22:14.550289: step 2559, loss 0.0116037, acc 1
2020-02-08T03:22:14.667275: step 2560, loss 0.00775159, acc 1
2020-02-08T03:22:14.781545: step 2561, loss 0.121707, acc 0.96875
2020-02-08T03:22:14.899693: step 2562, loss 0.0406103, acc 0.984375
2020-02-08T03:22:15.013417: step 2563, loss 0.0299959, acc 1
2020-02-08T03:22:15.129410: step 2564, loss 0.0233894, acc 0.984375
2020-02-08T03:22:15.248829: step 2565, loss 0.109493, acc 0.984375
2020-02-08T03:22:15.364854: step 2566, loss 0.0439088, acc 0.984375
2020-02-08T03:22:15.482423: step 2567, loss 0.0610187, acc 0.984375
2020-02-08T03:22:15.598474: step 2568, loss 0.0208916, acc 1
2020-02-08T03:22:15.717152: step 2569, loss 0.0288733, acc 1
2020-02-08T03:22:15.833857: step 2570, loss 0.0254294, acc 0.984375
2020-02-08T03:22:15.950959: step 2571, loss 0.0526857, acc 0.984375
2020-02-08T03:22:16.068598: step 2572, loss 0.100269, acc 0.953125
2020-02-08T03:22:16.184244: step 2573, loss 0.0190167, acc 1
2020-02-08T03:22:16.301677: step 2574, loss 0.0080474, acc 1
2020-02-08T03:22:16.418996: step 2575, loss 0.040046, acc 0.96875
2020-02-08T03:22:16.537023: step 2576, loss 0.045547, acc 0.984375
2020-02-08T03:22:16.653295: step 2577, loss 0.0173291, acc 1
2020-02-08T03:22:16.770607: step 2578, loss 0.030226, acc 1
2020-02-08T03:22:16.888023: step 2579, loss 0.0107875, acc 1
2020-02-08T03:22:17.004065: step 2580, loss 0.0166862, acc 1
2020-02-08T03:22:17.122407: step 2581, loss 0.0154529, acc 1
2020-02-08T03:22:17.239879: step 2582, loss 0.0180118, acc 1
2020-02-08T03:22:17.356652: step 2583, loss 0.0513159, acc 0.96875
2020-02-08T03:22:17.473169: step 2584, loss 0.0576243, acc 0.984375
2020-02-08T03:22:17.590782: step 2585, loss 0.0245439, acc 1
2020-02-08T03:22:17.706163: step 2586, loss 0.0234889, acc 1
2020-02-08T03:22:17.821903: step 2587, loss 0.0248129, acc 0.984375
2020-02-08T03:22:17.938307: step 2588, loss 0.0394633, acc 1
2020-02-08T03:22:18.055641: step 2589, loss 0.0181541, acc 1
2020-02-08T03:22:18.172054: step 2590, loss 0.0936601, acc 0.96875
2020-02-08T03:22:18.285355: step 2591, loss 0.0334305, acc 0.984375
2020-02-08T03:22:18.405570: step 2592, loss 0.0508388, acc 0.984375
2020-02-08T03:22:18.523851: step 2593, loss 0.0123244, acc 1
2020-02-08T03:22:18.638516: step 2594, loss 0.0277283, acc 1
2020-02-08T03:22:18.759792: step 2595, loss 0.0174297, acc 1
2020-02-08T03:22:18.875514: step 2596, loss 0.0633987, acc 0.984375
2020-02-08T03:22:18.991945: step 2597, loss 0.0676088, acc 0.953125
2020-02-08T03:22:19.109409: step 2598, loss 0.0108946, acc 1
2020-02-08T03:22:19.224506: step 2599, loss 0.0900581, acc 0.953125
2020-02-08T03:22:19.337267: step 2600, loss 0.0179155, acc 1

Evaluation:
2020-02-08T03:22:19.523721: step 2600, loss 0.906405, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2600

2020-02-08T03:22:21.335317: step 2601, loss 0.0713913, acc 0.984375
2020-02-08T03:22:21.552190: step 2602, loss 0.0624653, acc 0.984375
2020-02-08T03:22:21.681839: step 2603, loss 0.0314415, acc 1
2020-02-08T03:22:21.802601: step 2604, loss 0.0144033, acc 1
2020-02-08T03:22:21.918821: step 2605, loss 0.0158733, acc 1
2020-02-08T03:22:22.034457: step 2606, loss 0.0420181, acc 0.984375
2020-02-08T03:22:22.152216: step 2607, loss 0.0159165, acc 1
2020-02-08T03:22:22.267939: step 2608, loss 0.0562277, acc 0.953125
2020-02-08T03:22:22.382184: step 2609, loss 0.0253507, acc 1
2020-02-08T03:22:22.501076: step 2610, loss 0.0191969, acc 1
2020-02-08T03:22:22.618933: step 2611, loss 0.0585003, acc 0.96875
2020-02-08T03:22:22.732709: step 2612, loss 0.00753496, acc 1
2020-02-08T03:22:22.849362: step 2613, loss 0.0172893, acc 0.984375
2020-02-08T03:22:22.965740: step 2614, loss 0.00929862, acc 1
2020-02-08T03:22:23.080352: step 2615, loss 0.00912573, acc 1
2020-02-08T03:22:23.195191: step 2616, loss 0.0455729, acc 0.984375
2020-02-08T03:22:23.311421: step 2617, loss 0.0156463, acc 1
2020-02-08T03:22:23.427884: step 2618, loss 0.0419566, acc 0.984375
2020-02-08T03:22:23.545451: step 2619, loss 0.0161387, acc 1
2020-02-08T03:22:23.664879: step 2620, loss 0.0328125, acc 0.984375
2020-02-08T03:22:23.779887: step 2621, loss 0.0888862, acc 0.953125
2020-02-08T03:22:23.901233: step 2622, loss 0.0184788, acc 1
2020-02-08T03:22:24.016248: step 2623, loss 0.0170228, acc 0.984375
2020-02-08T03:22:24.132952: step 2624, loss 0.0672503, acc 0.984375
2020-02-08T03:22:24.251095: step 2625, loss 0.0629865, acc 0.96875
2020-02-08T03:22:24.367877: step 2626, loss 0.0193205, acc 1
2020-02-08T03:22:24.482253: step 2627, loss 0.0688908, acc 0.96875
2020-02-08T03:22:24.600810: step 2628, loss 0.0446651, acc 0.984375
2020-02-08T03:22:24.718081: step 2629, loss 0.0205823, acc 0.984375
2020-02-08T03:22:24.835959: step 2630, loss 0.0294457, acc 1
2020-02-08T03:22:24.954660: step 2631, loss 0.0340651, acc 0.984375
2020-02-08T03:22:25.070874: step 2632, loss 0.0270404, acc 1
2020-02-08T03:22:25.186516: step 2633, loss 0.046409, acc 0.984375
2020-02-08T03:22:25.304183: step 2634, loss 0.0625224, acc 0.96875
2020-02-08T03:22:25.421771: step 2635, loss 0.0105583, acc 1
2020-02-08T03:22:25.538426: step 2636, loss 0.0476423, acc 0.96875
2020-02-08T03:22:25.654686: step 2637, loss 0.0448668, acc 0.984375
2020-02-08T03:22:25.772805: step 2638, loss 0.0189362, acc 1
2020-02-08T03:22:25.890670: step 2639, loss 0.0787006, acc 0.984375
2020-02-08T03:22:26.007911: step 2640, loss 0.113324, acc 0.96875
2020-02-08T03:22:26.123394: step 2641, loss 0.114247, acc 0.953125
2020-02-08T03:22:26.241554: step 2642, loss 0.0181315, acc 0.984375
2020-02-08T03:22:26.358101: step 2643, loss 0.0170993, acc 1
2020-02-08T03:22:26.475186: step 2644, loss 0.0129744, acc 1
2020-02-08T03:22:26.592304: step 2645, loss 0.0118815, acc 1
2020-02-08T03:22:26.709609: step 2646, loss 0.0566787, acc 0.953125
2020-02-08T03:22:26.829464: step 2647, loss 0.0310767, acc 1
2020-02-08T03:22:26.949398: step 2648, loss 0.0500347, acc 0.984375
2020-02-08T03:22:27.067545: step 2649, loss 0.0518383, acc 0.984375
2020-02-08T03:22:27.184422: step 2650, loss 0.0219013, acc 1
2020-02-08T03:22:27.302864: step 2651, loss 0.0107278, acc 1
2020-02-08T03:22:27.418046: step 2652, loss 0.108837, acc 0.96875
2020-02-08T03:22:27.532687: step 2653, loss 0.0242321, acc 1
2020-02-08T03:22:27.650301: step 2654, loss 0.0137482, acc 1
2020-02-08T03:22:27.766363: step 2655, loss 0.0203925, acc 0.984375
2020-02-08T03:22:27.882272: step 2656, loss 0.027977, acc 0.984375
2020-02-08T03:22:27.999178: step 2657, loss 0.058245, acc 0.984375
2020-02-08T03:22:28.115805: step 2658, loss 0.0331808, acc 0.96875
2020-02-08T03:22:28.234059: step 2659, loss 0.041288, acc 0.96875
2020-02-08T03:22:28.350279: step 2660, loss 0.016826, acc 1
2020-02-08T03:22:28.465903: step 2661, loss 0.0449433, acc 0.96875
2020-02-08T03:22:28.581563: step 2662, loss 0.0528834, acc 0.984375
2020-02-08T03:22:28.698711: step 2663, loss 0.0210064, acc 1
2020-02-08T03:22:28.815976: step 2664, loss 0.024596, acc 1
2020-02-08T03:22:28.931163: step 2665, loss 0.0196621, acc 1
2020-02-08T03:22:29.045307: step 2666, loss 0.0348603, acc 1
2020-02-08T03:22:29.163723: step 2667, loss 0.0221805, acc 1
2020-02-08T03:22:29.277400: step 2668, loss 0.0118156, acc 1
2020-02-08T03:22:29.392586: step 2669, loss 0.0396314, acc 0.984375
2020-02-08T03:22:29.506870: step 2670, loss 0.0406584, acc 0.984375
2020-02-08T03:22:29.624653: step 2671, loss 0.0457103, acc 0.984375
2020-02-08T03:22:29.739534: step 2672, loss 0.0134817, acc 1
2020-02-08T03:22:29.861269: step 2673, loss 0.0192465, acc 1
2020-02-08T03:22:29.977841: step 2674, loss 0.179309, acc 0.921875
2020-02-08T03:22:30.098280: step 2675, loss 0.0217233, acc 1
2020-02-08T03:22:30.215395: step 2676, loss 0.00234035, acc 1
2020-02-08T03:22:30.331356: step 2677, loss 0.0154757, acc 1
2020-02-08T03:22:30.449915: step 2678, loss 0.0161735, acc 1
2020-02-08T03:22:30.568389: step 2679, loss 0.0138066, acc 1
2020-02-08T03:22:30.684380: step 2680, loss 0.0351384, acc 0.984375
2020-02-08T03:22:30.803713: step 2681, loss 0.026734, acc 1
2020-02-08T03:22:30.919333: step 2682, loss 0.00934345, acc 1
2020-02-08T03:22:31.034698: step 2683, loss 0.0433346, acc 0.984375
2020-02-08T03:22:31.151594: step 2684, loss 0.0556753, acc 0.953125
2020-02-08T03:22:31.270122: step 2685, loss 0.0151433, acc 1
2020-02-08T03:22:31.385018: step 2686, loss 0.0667746, acc 0.96875
2020-02-08T03:22:31.504480: step 2687, loss 0.00661414, acc 1
2020-02-08T03:22:31.621083: step 2688, loss 0.055898, acc 0.984375
2020-02-08T03:22:31.735060: step 2689, loss 0.0772459, acc 0.96875
2020-02-08T03:22:31.854799: step 2690, loss 0.0156284, acc 1
2020-02-08T03:22:31.971767: step 2691, loss 0.0704432, acc 0.96875
2020-02-08T03:22:32.088198: step 2692, loss 0.0625976, acc 0.984375
2020-02-08T03:22:32.207783: step 2693, loss 0.0692018, acc 0.984375
2020-02-08T03:22:32.323604: step 2694, loss 0.0484584, acc 0.984375
2020-02-08T03:22:32.441101: step 2695, loss 0.0351826, acc 0.984375
2020-02-08T03:22:32.561321: step 2696, loss 0.0365448, acc 1
2020-02-08T03:22:32.679886: step 2697, loss 0.0169788, acc 1
2020-02-08T03:22:32.796656: step 2698, loss 0.0226571, acc 1
2020-02-08T03:22:32.917173: step 2699, loss 0.0102891, acc 1
2020-02-08T03:22:33.029005: step 2700, loss 0.0181652, acc 1

Evaluation:
2020-02-08T03:22:33.219290: step 2700, loss 0.976811, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2700

2020-02-08T03:22:34.783778: step 2701, loss 0.0347844, acc 0.984375
2020-02-08T03:22:34.899805: step 2702, loss 0.0121037, acc 1
2020-02-08T03:22:35.020754: step 2703, loss 0.015204, acc 1
2020-02-08T03:22:35.138248: step 2704, loss 0.0347977, acc 0.984375
2020-02-08T03:22:35.254808: step 2705, loss 0.00868544, acc 1
2020-02-08T03:22:35.371816: step 2706, loss 0.0536598, acc 0.984375
2020-02-08T03:22:35.488477: step 2707, loss 0.0332807, acc 0.984375
2020-02-08T03:22:35.607168: step 2708, loss 0.0316215, acc 0.984375
2020-02-08T03:22:35.724803: step 2709, loss 0.0126219, acc 1
2020-02-08T03:22:35.843243: step 2710, loss 0.0104807, acc 1
2020-02-08T03:22:35.960685: step 2711, loss 0.0259722, acc 1
2020-02-08T03:22:36.078535: step 2712, loss 0.00361826, acc 1
2020-02-08T03:22:36.193319: step 2713, loss 0.0240023, acc 0.984375
2020-02-08T03:22:36.308796: step 2714, loss 0.0259287, acc 1
2020-02-08T03:22:36.424794: step 2715, loss 0.064199, acc 0.96875
2020-02-08T03:22:36.541193: step 2716, loss 0.02769, acc 1
2020-02-08T03:22:36.657449: step 2717, loss 0.0224576, acc 1
2020-02-08T03:22:36.774663: step 2718, loss 0.0137724, acc 1
2020-02-08T03:22:36.888753: step 2719, loss 0.00852993, acc 1
2020-02-08T03:22:37.008357: step 2720, loss 0.010753, acc 1
2020-02-08T03:22:37.125876: step 2721, loss 0.00825365, acc 1
2020-02-08T03:22:37.244119: step 2722, loss 0.053157, acc 0.984375
2020-02-08T03:22:37.361869: step 2723, loss 0.0175384, acc 1
2020-02-08T03:22:37.477270: step 2724, loss 0.0533765, acc 0.953125
2020-02-08T03:22:37.595128: step 2725, loss 0.0214867, acc 1
2020-02-08T03:22:37.711159: step 2726, loss 0.0356825, acc 0.96875
2020-02-08T03:22:37.828084: step 2727, loss 0.0394227, acc 0.984375
2020-02-08T03:22:37.945095: step 2728, loss 0.00688779, acc 1
2020-02-08T03:22:38.062410: step 2729, loss 0.0194957, acc 1
2020-02-08T03:22:38.180483: step 2730, loss 0.0170778, acc 0.984375
2020-02-08T03:22:38.298510: step 2731, loss 0.0111112, acc 1
2020-02-08T03:22:38.417112: step 2732, loss 0.0238233, acc 1
2020-02-08T03:22:38.535628: step 2733, loss 0.00817363, acc 1
2020-02-08T03:22:38.652824: step 2734, loss 0.0212547, acc 0.984375
2020-02-08T03:22:38.770883: step 2735, loss 0.013333, acc 1
2020-02-08T03:22:38.889310: step 2736, loss 0.0161754, acc 1
2020-02-08T03:22:39.008310: step 2737, loss 0.0277906, acc 0.984375
2020-02-08T03:22:39.125297: step 2738, loss 0.00758025, acc 1
2020-02-08T03:22:39.240056: step 2739, loss 0.0095754, acc 1
2020-02-08T03:22:39.357006: step 2740, loss 0.0114463, acc 1
2020-02-08T03:22:39.474493: step 2741, loss 0.0312068, acc 0.984375
2020-02-08T03:22:39.595189: step 2742, loss 0.00741217, acc 1
2020-02-08T03:22:39.712827: step 2743, loss 0.0642826, acc 0.96875
2020-02-08T03:22:39.831322: step 2744, loss 0.0477053, acc 0.984375
2020-02-08T03:22:39.950398: step 2745, loss 0.0132877, acc 1
2020-02-08T03:22:40.067069: step 2746, loss 0.114626, acc 0.96875
2020-02-08T03:22:40.183878: step 2747, loss 0.0156903, acc 1
2020-02-08T03:22:40.315480: step 2748, loss 0.0141994, acc 1
2020-02-08T03:22:40.431973: step 2749, loss 0.00600246, acc 1
2020-02-08T03:22:40.553191: step 2750, loss 0.0509022, acc 0.984375
2020-02-08T03:22:40.670834: step 2751, loss 0.0287845, acc 1
2020-02-08T03:22:40.786735: step 2752, loss 0.0737109, acc 0.984375
2020-02-08T03:22:40.905730: step 2753, loss 0.0127628, acc 1
2020-02-08T03:22:41.022280: step 2754, loss 0.0713949, acc 0.96875
2020-02-08T03:22:41.139366: step 2755, loss 0.0110829, acc 1
2020-02-08T03:22:41.258734: step 2756, loss 0.0416065, acc 1
2020-02-08T03:22:41.376845: step 2757, loss 0.0318143, acc 0.984375
2020-02-08T03:22:41.494444: step 2758, loss 0.00642258, acc 1
2020-02-08T03:22:41.613709: step 2759, loss 0.00934365, acc 1
2020-02-08T03:22:41.729519: step 2760, loss 0.017392, acc 1
2020-02-08T03:22:41.846765: step 2761, loss 0.0263004, acc 1
2020-02-08T03:22:41.962609: step 2762, loss 0.0415296, acc 0.984375
2020-02-08T03:22:42.077194: step 2763, loss 0.0168385, acc 1
2020-02-08T03:22:42.190739: step 2764, loss 0.00974563, acc 1
2020-02-08T03:22:42.308747: step 2765, loss 0.0132385, acc 1
2020-02-08T03:22:42.423734: step 2766, loss 0.0240441, acc 1
2020-02-08T03:22:42.540825: step 2767, loss 0.00582792, acc 1
2020-02-08T03:22:42.659985: step 2768, loss 0.0265859, acc 1
2020-02-08T03:22:42.777694: step 2769, loss 0.0049562, acc 1
2020-02-08T03:22:42.893928: step 2770, loss 0.0322584, acc 0.984375
2020-02-08T03:22:43.010547: step 2771, loss 0.0392738, acc 0.984375
2020-02-08T03:22:43.126537: step 2772, loss 0.0104153, acc 1
2020-02-08T03:22:43.250143: step 2773, loss 0.00919454, acc 1
2020-02-08T03:22:43.371331: step 2774, loss 0.0077454, acc 1
2020-02-08T03:22:43.486509: step 2775, loss 0.0771927, acc 0.96875
2020-02-08T03:22:43.605079: step 2776, loss 0.0672069, acc 0.984375
2020-02-08T03:22:43.722032: step 2777, loss 0.0218201, acc 0.984375
2020-02-08T03:22:43.842988: step 2778, loss 0.00999494, acc 1
2020-02-08T03:22:43.962524: step 2779, loss 0.0173965, acc 1
2020-02-08T03:22:44.077199: step 2780, loss 0.00620067, acc 1
2020-02-08T03:22:44.193836: step 2781, loss 0.0266171, acc 1
2020-02-08T03:22:44.308056: step 2782, loss 0.00504324, acc 1
2020-02-08T03:22:44.424119: step 2783, loss 0.0356511, acc 0.984375
2020-02-08T03:22:44.538281: step 2784, loss 0.0190561, acc 0.984375
2020-02-08T03:22:44.655888: step 2785, loss 0.0560743, acc 0.984375
2020-02-08T03:22:44.773614: step 2786, loss 0.00755906, acc 1
2020-02-08T03:22:44.893195: step 2787, loss 0.0110686, acc 1
2020-02-08T03:22:45.009964: step 2788, loss 0.047969, acc 0.984375
2020-02-08T03:22:45.125970: step 2789, loss 0.0424549, acc 0.984375
2020-02-08T03:22:45.244329: step 2790, loss 0.0736434, acc 0.984375
2020-02-08T03:22:45.362234: step 2791, loss 0.0219779, acc 1
2020-02-08T03:22:45.478046: step 2792, loss 0.0234026, acc 1
2020-02-08T03:22:45.593534: step 2793, loss 0.0240551, acc 1
2020-02-08T03:22:45.712162: step 2794, loss 0.0223241, acc 1
2020-02-08T03:22:45.828092: step 2795, loss 0.00731049, acc 1
2020-02-08T03:22:45.944492: step 2796, loss 0.0153888, acc 1
2020-02-08T03:22:46.060884: step 2797, loss 0.0141853, acc 1
2020-02-08T03:22:46.179447: step 2798, loss 0.0150705, acc 1
2020-02-08T03:22:46.297394: step 2799, loss 0.0201441, acc 1
2020-02-08T03:22:46.414027: step 2800, loss 0.00663225, acc 1

Evaluation:
2020-02-08T03:22:46.606793: step 2800, loss 0.972934, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2800

2020-02-08T03:22:48.140271: step 2801, loss 0.00378077, acc 1
2020-02-08T03:22:48.255476: step 2802, loss 0.0172864, acc 0.984375
2020-02-08T03:22:48.371764: step 2803, loss 0.015533, acc 1
2020-02-08T03:22:48.486588: step 2804, loss 0.023997, acc 0.984375
2020-02-08T03:22:48.606598: step 2805, loss 0.0118575, acc 1
2020-02-08T03:22:48.723829: step 2806, loss 0.0297881, acc 0.984375
2020-02-08T03:22:48.839844: step 2807, loss 0.0753917, acc 0.984375
2020-02-08T03:22:48.957497: step 2808, loss 0.0332995, acc 0.984375
2020-02-08T03:22:49.074013: step 2809, loss 0.0353653, acc 0.984375
2020-02-08T03:22:49.192906: step 2810, loss 0.0431488, acc 0.984375
2020-02-08T03:22:49.309256: step 2811, loss 0.0405557, acc 0.984375
2020-02-08T03:22:49.423730: step 2812, loss 0.0509783, acc 0.984375
2020-02-08T03:22:49.539409: step 2813, loss 0.0926361, acc 0.96875
2020-02-08T03:22:49.656487: step 2814, loss 0.013059, acc 1
2020-02-08T03:22:49.773062: step 2815, loss 0.0112381, acc 1
2020-02-08T03:22:49.888658: step 2816, loss 0.00950322, acc 1
2020-02-08T03:22:50.010941: step 2817, loss 0.0371054, acc 0.984375
2020-02-08T03:22:50.126945: step 2818, loss 0.0227298, acc 1
2020-02-08T03:22:50.245855: step 2819, loss 0.0205722, acc 1
2020-02-08T03:22:50.363372: step 2820, loss 0.0155599, acc 1
2020-02-08T03:22:50.477555: step 2821, loss 0.0261667, acc 1
2020-02-08T03:22:50.597410: step 2822, loss 0.0313887, acc 0.984375
2020-02-08T03:22:50.718079: step 2823, loss 0.102983, acc 0.953125
2020-02-08T03:22:50.832600: step 2824, loss 0.0117941, acc 1
2020-02-08T03:22:50.948805: step 2825, loss 0.0347705, acc 0.984375
2020-02-08T03:22:51.065356: step 2826, loss 0.00836835, acc 1
2020-02-08T03:22:51.183547: step 2827, loss 0.0302219, acc 0.984375
2020-02-08T03:22:51.300353: step 2828, loss 0.0243908, acc 1
2020-02-08T03:22:51.414893: step 2829, loss 0.0358595, acc 0.984375
2020-02-08T03:22:51.632445: step 2830, loss 0.0276581, acc 0.984375
2020-02-08T03:22:51.753021: step 2831, loss 0.0103659, acc 1
2020-02-08T03:22:51.869427: step 2832, loss 0.050226, acc 0.96875
2020-02-08T03:22:51.982511: step 2833, loss 0.00670391, acc 1
2020-02-08T03:22:52.097873: step 2834, loss 0.0172216, acc 1
2020-02-08T03:22:52.215150: step 2835, loss 0.0522674, acc 0.984375
2020-02-08T03:22:52.328103: step 2836, loss 0.00911885, acc 1
2020-02-08T03:22:52.445108: step 2837, loss 0.0181839, acc 1
2020-02-08T03:22:52.563414: step 2838, loss 0.0236758, acc 1
2020-02-08T03:22:52.677697: step 2839, loss 0.00526236, acc 1
2020-02-08T03:22:52.795345: step 2840, loss 0.00524598, acc 1
2020-02-08T03:22:52.917216: step 2841, loss 0.0230609, acc 0.984375
2020-02-08T03:22:53.035217: step 2842, loss 0.0163306, acc 0.984375
2020-02-08T03:22:53.152785: step 2843, loss 0.00496514, acc 1
2020-02-08T03:22:53.269154: step 2844, loss 0.03857, acc 0.984375
2020-02-08T03:22:53.383801: step 2845, loss 0.0319759, acc 0.96875
2020-02-08T03:22:53.502391: step 2846, loss 0.0305396, acc 0.984375
2020-02-08T03:22:53.618912: step 2847, loss 0.020548, acc 1
2020-02-08T03:22:53.737656: step 2848, loss 0.0121558, acc 1
2020-02-08T03:22:53.855039: step 2849, loss 0.0353008, acc 0.984375
2020-02-08T03:22:53.969134: step 2850, loss 0.0238414, acc 0.983333
2020-02-08T03:22:54.086249: step 2851, loss 0.00842346, acc 1
2020-02-08T03:22:54.203354: step 2852, loss 0.0494396, acc 0.984375
2020-02-08T03:22:54.321106: step 2853, loss 0.0123114, acc 1
2020-02-08T03:22:54.437435: step 2854, loss 0.019826, acc 0.984375
2020-02-08T03:22:54.554930: step 2855, loss 0.00689632, acc 1
2020-02-08T03:22:54.673355: step 2856, loss 0.0283126, acc 1
2020-02-08T03:22:54.791135: step 2857, loss 0.0288801, acc 0.984375
2020-02-08T03:22:54.907019: step 2858, loss 0.0329513, acc 0.984375
2020-02-08T03:22:55.021490: step 2859, loss 0.0289811, acc 0.984375
2020-02-08T03:22:55.135756: step 2860, loss 0.0369858, acc 0.984375
2020-02-08T03:22:55.253784: step 2861, loss 0.0113588, acc 1
2020-02-08T03:22:55.370276: step 2862, loss 0.0130941, acc 1
2020-02-08T03:22:55.485790: step 2863, loss 0.026546, acc 1
2020-02-08T03:22:55.602525: step 2864, loss 0.0607664, acc 0.984375
2020-02-08T03:22:55.717802: step 2865, loss 0.00997767, acc 1
2020-02-08T03:22:55.834070: step 2866, loss 0.0297036, acc 0.984375
2020-02-08T03:22:55.954515: step 2867, loss 0.0321414, acc 0.984375
2020-02-08T03:22:56.071358: step 2868, loss 0.0185187, acc 1
2020-02-08T03:22:56.187320: step 2869, loss 0.0387321, acc 0.96875
2020-02-08T03:22:56.304405: step 2870, loss 0.00677562, acc 1
2020-02-08T03:22:56.421457: step 2871, loss 0.0126929, acc 1
2020-02-08T03:22:56.538155: step 2872, loss 0.0301871, acc 0.984375
2020-02-08T03:22:56.654339: step 2873, loss 0.0532915, acc 0.96875
2020-02-08T03:22:56.768517: step 2874, loss 0.00902235, acc 1
2020-02-08T03:22:56.883308: step 2875, loss 0.0121835, acc 1
2020-02-08T03:22:56.998730: step 2876, loss 0.00698328, acc 1
2020-02-08T03:22:57.114491: step 2877, loss 0.0441279, acc 0.984375
2020-02-08T03:22:57.233028: step 2878, loss 0.0114853, acc 1
2020-02-08T03:22:57.353070: step 2879, loss 0.0248261, acc 0.984375
2020-02-08T03:22:57.472811: step 2880, loss 0.0117699, acc 1
2020-02-08T03:22:57.589092: step 2881, loss 0.0444658, acc 0.984375
2020-02-08T03:22:57.704734: step 2882, loss 0.0179716, acc 1
2020-02-08T03:22:57.822880: step 2883, loss 0.00580279, acc 1
2020-02-08T03:22:57.941319: step 2884, loss 0.0474972, acc 0.984375
2020-02-08T03:22:58.057656: step 2885, loss 0.0358586, acc 0.984375
2020-02-08T03:22:58.172448: step 2886, loss 0.011388, acc 1
2020-02-08T03:22:58.288163: step 2887, loss 0.0261, acc 0.984375
2020-02-08T03:22:58.405978: step 2888, loss 0.0110681, acc 1
2020-02-08T03:22:58.521270: step 2889, loss 0.0239523, acc 0.984375
2020-02-08T03:22:58.639194: step 2890, loss 0.00998266, acc 1
2020-02-08T03:22:58.759066: step 2891, loss 0.0770291, acc 0.96875
2020-02-08T03:22:58.873683: step 2892, loss 0.00797244, acc 1
2020-02-08T03:22:58.988903: step 2893, loss 0.0101993, acc 1
2020-02-08T03:22:59.106216: step 2894, loss 0.00736415, acc 1
2020-02-08T03:22:59.224116: step 2895, loss 0.0479322, acc 0.984375
2020-02-08T03:22:59.341614: step 2896, loss 0.0127204, acc 1
2020-02-08T03:22:59.461935: step 2897, loss 0.00879997, acc 1
2020-02-08T03:22:59.577616: step 2898, loss 0.0223577, acc 1
2020-02-08T03:22:59.695548: step 2899, loss 0.0341792, acc 0.984375
2020-02-08T03:22:59.815587: step 2900, loss 0.00733188, acc 1

Evaluation:
2020-02-08T03:23:00.005182: step 2900, loss 0.989171, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-2900

2020-02-08T03:23:01.531233: step 2901, loss 0.0089016, acc 1
2020-02-08T03:23:01.647986: step 2902, loss 0.0316235, acc 0.984375
2020-02-08T03:23:01.765995: step 2903, loss 0.0293778, acc 0.984375
2020-02-08T03:23:01.882496: step 2904, loss 0.0196291, acc 1
2020-02-08T03:23:01.999658: step 2905, loss 0.00772129, acc 1
2020-02-08T03:23:02.116693: step 2906, loss 0.0125034, acc 1
2020-02-08T03:23:02.233260: step 2907, loss 0.0435873, acc 0.96875
2020-02-08T03:23:02.350343: step 2908, loss 0.00858381, acc 1
2020-02-08T03:23:02.466903: step 2909, loss 0.0701393, acc 0.953125
2020-02-08T03:23:02.583470: step 2910, loss 0.0269713, acc 0.984375
2020-02-08T03:23:02.701741: step 2911, loss 0.0125229, acc 1
2020-02-08T03:23:02.816786: step 2912, loss 0.0120773, acc 1
2020-02-08T03:23:02.932225: step 2913, loss 0.0270329, acc 0.984375
2020-02-08T03:23:03.048474: step 2914, loss 0.00950236, acc 1
2020-02-08T03:23:03.167494: step 2915, loss 0.0318815, acc 0.984375
2020-02-08T03:23:03.282789: step 2916, loss 0.00840583, acc 1
2020-02-08T03:23:03.400956: step 2917, loss 0.0127656, acc 1
2020-02-08T03:23:03.518530: step 2918, loss 0.0161876, acc 1
2020-02-08T03:23:03.635511: step 2919, loss 0.00697731, acc 1
2020-02-08T03:23:03.753140: step 2920, loss 0.0210308, acc 0.984375
2020-02-08T03:23:03.871847: step 2921, loss 0.0398226, acc 0.984375
2020-02-08T03:23:03.990463: step 2922, loss 0.0216061, acc 1
2020-02-08T03:23:04.108567: step 2923, loss 0.0128221, acc 1
2020-02-08T03:23:04.224696: step 2924, loss 0.00614075, acc 1
2020-02-08T03:23:04.341963: step 2925, loss 0.0239603, acc 0.984375
2020-02-08T03:23:04.470458: step 2926, loss 0.00668896, acc 1
2020-02-08T03:23:04.587837: step 2927, loss 0.0170449, acc 1
2020-02-08T03:23:04.706990: step 2928, loss 0.0150133, acc 0.984375
2020-02-08T03:23:04.823755: step 2929, loss 0.104458, acc 0.96875
2020-02-08T03:23:04.941045: step 2930, loss 0.0796791, acc 0.984375
2020-02-08T03:23:05.057673: step 2931, loss 0.0144792, acc 1
2020-02-08T03:23:05.175268: step 2932, loss 0.0104506, acc 1
2020-02-08T03:23:05.292433: step 2933, loss 0.00344502, acc 1
2020-02-08T03:23:05.409554: step 2934, loss 0.0136064, acc 1
2020-02-08T03:23:05.525137: step 2935, loss 0.0112742, acc 1
2020-02-08T03:23:05.641179: step 2936, loss 0.0233876, acc 1
2020-02-08T03:23:05.760210: step 2937, loss 0.0139391, acc 1
2020-02-08T03:23:05.877942: step 2938, loss 0.0233368, acc 1
2020-02-08T03:23:05.997002: step 2939, loss 0.0235365, acc 0.984375
2020-02-08T03:23:06.116426: step 2940, loss 0.00905442, acc 1
2020-02-08T03:23:06.231874: step 2941, loss 0.00897285, acc 1
2020-02-08T03:23:06.348927: step 2942, loss 0.014103, acc 1
2020-02-08T03:23:06.468362: step 2943, loss 0.0512473, acc 0.96875
2020-02-08T03:23:06.583376: step 2944, loss 0.00610002, acc 1
2020-02-08T03:23:06.702758: step 2945, loss 0.0579295, acc 0.96875
2020-02-08T03:23:06.818793: step 2946, loss 0.0218503, acc 1
2020-02-08T03:23:06.935517: step 2947, loss 0.00942827, acc 1
2020-02-08T03:23:07.051812: step 2948, loss 0.0321842, acc 0.984375
2020-02-08T03:23:07.168495: step 2949, loss 0.0534974, acc 0.953125
2020-02-08T03:23:07.283289: step 2950, loss 0.00259291, acc 1
2020-02-08T03:23:07.399721: step 2951, loss 0.0190593, acc 0.984375
2020-02-08T03:23:07.517610: step 2952, loss 0.0321925, acc 0.984375
2020-02-08T03:23:07.632154: step 2953, loss 0.0163871, acc 1
2020-02-08T03:23:07.749042: step 2954, loss 0.0200886, acc 0.984375
2020-02-08T03:23:07.872790: step 2955, loss 0.0139337, acc 1
2020-02-08T03:23:07.989591: step 2956, loss 0.0142888, acc 1
2020-02-08T03:23:08.106624: step 2957, loss 0.0086539, acc 1
2020-02-08T03:23:08.225958: step 2958, loss 0.0298864, acc 0.984375
2020-02-08T03:23:08.342014: step 2959, loss 0.0277455, acc 0.984375
2020-02-08T03:23:08.459303: step 2960, loss 0.0100057, acc 1
2020-02-08T03:23:08.576188: step 2961, loss 0.00685042, acc 1
2020-02-08T03:23:08.694003: step 2962, loss 0.0308697, acc 0.984375
2020-02-08T03:23:08.811261: step 2963, loss 0.0260666, acc 1
2020-02-08T03:23:08.928241: step 2964, loss 0.0664558, acc 0.96875
2020-02-08T03:23:09.045316: step 2965, loss 0.00632696, acc 1
2020-02-08T03:23:09.161898: step 2966, loss 0.00765333, acc 1
2020-02-08T03:23:09.277229: step 2967, loss 0.0670777, acc 0.96875
2020-02-08T03:23:09.396202: step 2968, loss 0.0107141, acc 1
2020-02-08T03:23:09.512948: step 2969, loss 0.0203581, acc 1
2020-02-08T03:23:09.628116: step 2970, loss 0.0163391, acc 1
2020-02-08T03:23:09.742732: step 2971, loss 0.0118066, acc 1
2020-02-08T03:23:09.862302: step 2972, loss 0.00980643, acc 1
2020-02-08T03:23:09.979472: step 2973, loss 0.0119454, acc 1
2020-02-08T03:23:10.096122: step 2974, loss 0.0184519, acc 1
2020-02-08T03:23:10.214940: step 2975, loss 0.018805, acc 1
2020-02-08T03:23:10.329500: step 2976, loss 0.031358, acc 0.984375
2020-02-08T03:23:10.447346: step 2977, loss 0.0125341, acc 1
2020-02-08T03:23:10.563298: step 2978, loss 0.0163098, acc 1
2020-02-08T03:23:10.679270: step 2979, loss 0.00793797, acc 1
2020-02-08T03:23:10.798322: step 2980, loss 0.0302728, acc 0.984375
2020-02-08T03:23:10.915764: step 2981, loss 0.0444516, acc 0.96875
2020-02-08T03:23:11.029816: step 2982, loss 0.0167823, acc 1
2020-02-08T03:23:11.149690: step 2983, loss 0.0137994, acc 1
2020-02-08T03:23:11.266213: step 2984, loss 0.0108484, acc 1
2020-02-08T03:23:11.382598: step 2985, loss 0.012145, acc 1
2020-02-08T03:23:11.502516: step 2986, loss 0.0414517, acc 0.984375
2020-02-08T03:23:11.620201: step 2987, loss 0.0702722, acc 0.953125
2020-02-08T03:23:11.738188: step 2988, loss 0.00520878, acc 1
2020-02-08T03:23:11.859878: step 2989, loss 0.00420981, acc 1
2020-02-08T03:23:11.974873: step 2990, loss 0.0175745, acc 1
2020-02-08T03:23:12.089766: step 2991, loss 0.00486272, acc 1
2020-02-08T03:23:12.207623: step 2992, loss 0.00241212, acc 1
2020-02-08T03:23:12.322823: step 2993, loss 0.00787087, acc 1
2020-02-08T03:23:12.439280: step 2994, loss 0.021386, acc 0.984375
2020-02-08T03:23:12.555549: step 2995, loss 0.0152465, acc 1
2020-02-08T03:23:12.673248: step 2996, loss 0.0493233, acc 0.984375
2020-02-08T03:23:12.789048: step 2997, loss 0.00501807, acc 1
2020-02-08T03:23:12.904841: step 2998, loss 0.00692586, acc 1
2020-02-08T03:23:13.022235: step 2999, loss 0.0695958, acc 0.984375
2020-02-08T03:23:13.134776: step 3000, loss 0.0148163, acc 1

Evaluation:
2020-02-08T03:23:13.325252: step 3000, loss 1.01137, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581102988/checkpoints/model-3000

