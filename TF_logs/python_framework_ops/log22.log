WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:23:19.870733 4712328640 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:23:19.870985 4712328640 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 03:23:19.871124 4712328640 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 03:23:20.379846 4712328640 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 03:23:20.380084 4712328640 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 03:23:20.380287: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 03:23:20.394829: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9667fecab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 03:23:20.394851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 03:23:20.395205 4712328640 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 03:23:20.398439 4712328640 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 03:23:20.408856 4712328640 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 03:23:20.417825 4712328640 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 03:23:20.441123 4712328640 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 03:23:20.449190 4712328640 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 03:23:20.449413 4712328640 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 03:23:20.460022 4712328640 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 03:23:20.462375 4712328640 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 03:23:20.487405 4712328640 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 03:23:20.720649 4712328640 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 03:23:20.720888 4712328640 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 03:23:20.726093 4712328640 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 03:23:20.749171 4712328640 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 03:23:20.750800 4712328640 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 03:23:20.766499 4712328640 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 03:23:20.767567 4712328640 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 03:23:20.781743 4712328640 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 03:23:20.782796 4712328640 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 03:23:20.804154 4712328640 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 03:23:20.805238 4712328640 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 03:23:20.819456 4712328640 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 03:23:20.820518 4712328640 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 03:23:20.834801 4712328640 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 03:23:20.836621 4712328640 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 03:23:20.858530 4712328640 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 03:23:20.859611 4712328640 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 03:23:20.873670 4712328640 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 03:23:20.874717 4712328640 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 03:23:20.892081 4712328640 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 03:23:20.893764 4712328640 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 03:23:20.899331 4712328640 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 03:23:21.644819 4712328640 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 03:23:21.645009 4712328640 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 03:23:21.748934 4712328640 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 03:23:22.282430 4712328640 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 03:24:42.203697 4712328640 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400

2020-02-08T03:23:22.281996: step 1, loss 2.50938, acc 0.5625
2020-02-08T03:23:22.415838: step 2, loss 1.78121, acc 0.5625
2020-02-08T03:23:22.532436: step 3, loss 2.20264, acc 0.453125
2020-02-08T03:23:22.650860: step 4, loss 2.37836, acc 0.40625
2020-02-08T03:23:22.768976: step 5, loss 2.71284, acc 0.515625
2020-02-08T03:23:22.884810: step 6, loss 1.99426, acc 0.625
2020-02-08T03:23:23.003282: step 7, loss 2.13192, acc 0.5
2020-02-08T03:23:23.119856: step 8, loss 2.16648, acc 0.4375
2020-02-08T03:23:23.234652: step 9, loss 2.18701, acc 0.4375
2020-02-08T03:23:23.351573: step 10, loss 2.10272, acc 0.453125
2020-02-08T03:23:23.469501: step 11, loss 1.74668, acc 0.578125
2020-02-08T03:23:23.587304: step 12, loss 2.09186, acc 0.46875
2020-02-08T03:23:23.702645: step 13, loss 2.19343, acc 0.390625
2020-02-08T03:23:23.819127: step 14, loss 2.05715, acc 0.46875
2020-02-08T03:23:23.936487: step 15, loss 1.60721, acc 0.5625
2020-02-08T03:23:24.051283: step 16, loss 1.95961, acc 0.484375
2020-02-08T03:23:24.167509: step 17, loss 2.22389, acc 0.578125
2020-02-08T03:23:24.281762: step 18, loss 1.68915, acc 0.546875
2020-02-08T03:23:24.397447: step 19, loss 1.95775, acc 0.46875
2020-02-08T03:23:24.510151: step 20, loss 1.47858, acc 0.59375
2020-02-08T03:23:24.625799: step 21, loss 2.11259, acc 0.46875
2020-02-08T03:23:24.743501: step 22, loss 1.89858, acc 0.515625
2020-02-08T03:23:24.861377: step 23, loss 2.0012, acc 0.4375
2020-02-08T03:23:24.981309: step 24, loss 1.51147, acc 0.640625
2020-02-08T03:23:25.100818: step 25, loss 1.1763, acc 0.640625
2020-02-08T03:23:25.216909: step 26, loss 1.87338, acc 0.5
2020-02-08T03:23:25.334925: step 27, loss 2.1235, acc 0.5
2020-02-08T03:23:25.448786: step 28, loss 1.83843, acc 0.53125
2020-02-08T03:23:25.566901: step 29, loss 2.05832, acc 0.453125
2020-02-08T03:23:25.685061: step 30, loss 1.54996, acc 0.5625
2020-02-08T03:23:25.801739: step 31, loss 2.31664, acc 0.421875
2020-02-08T03:23:25.917714: step 32, loss 1.94134, acc 0.453125
2020-02-08T03:23:26.034269: step 33, loss 1.71525, acc 0.484375
2020-02-08T03:23:26.149976: step 34, loss 2.01349, acc 0.4375
2020-02-08T03:23:26.263337: step 35, loss 1.81806, acc 0.4375
2020-02-08T03:23:26.379132: step 36, loss 2.28211, acc 0.40625
2020-02-08T03:23:26.499721: step 37, loss 1.24827, acc 0.625
2020-02-08T03:23:26.618103: step 38, loss 1.94598, acc 0.40625
2020-02-08T03:23:26.738615: step 39, loss 1.43137, acc 0.59375
2020-02-08T03:23:26.857478: step 40, loss 1.70628, acc 0.5
2020-02-08T03:23:26.974649: step 41, loss 1.82972, acc 0.484375
2020-02-08T03:23:27.093895: step 42, loss 1.49413, acc 0.5
2020-02-08T03:23:27.208615: step 43, loss 1.74153, acc 0.515625
2020-02-08T03:23:27.325005: step 44, loss 2.29274, acc 0.46875
2020-02-08T03:23:27.441747: step 45, loss 1.68189, acc 0.515625
2020-02-08T03:23:27.560377: step 46, loss 1.53236, acc 0.46875
2020-02-08T03:23:27.678563: step 47, loss 1.48816, acc 0.515625
2020-02-08T03:23:27.794554: step 48, loss 1.73564, acc 0.53125
2020-02-08T03:23:27.916633: step 49, loss 2.14627, acc 0.421875
2020-02-08T03:23:28.035076: step 50, loss 1.58927, acc 0.53125
2020-02-08T03:23:28.150966: step 51, loss 1.69186, acc 0.453125
2020-02-08T03:23:28.268622: step 52, loss 1.19719, acc 0.59375
2020-02-08T03:23:28.384709: step 53, loss 1.1036, acc 0.6875
2020-02-08T03:23:28.501278: step 54, loss 2.18097, acc 0.453125
2020-02-08T03:23:28.619692: step 55, loss 1.95531, acc 0.484375
2020-02-08T03:23:28.734796: step 56, loss 1.31365, acc 0.53125
2020-02-08T03:23:28.851751: step 57, loss 1.60698, acc 0.40625
2020-02-08T03:23:28.968038: step 58, loss 1.36671, acc 0.546875
2020-02-08T03:23:29.083535: step 59, loss 1.74089, acc 0.5625
2020-02-08T03:23:29.200865: step 60, loss 1.76952, acc 0.421875
2020-02-08T03:23:29.316794: step 61, loss 1.725, acc 0.546875
2020-02-08T03:23:29.433449: step 62, loss 1.4324, acc 0.53125
2020-02-08T03:23:29.547468: step 63, loss 1.51366, acc 0.515625
2020-02-08T03:23:29.665775: step 64, loss 1.41957, acc 0.546875
2020-02-08T03:23:29.782811: step 65, loss 1.50936, acc 0.578125
2020-02-08T03:23:29.901784: step 66, loss 1.26881, acc 0.59375
2020-02-08T03:23:30.018048: step 67, loss 1.1638, acc 0.59375
2020-02-08T03:23:30.134868: step 68, loss 1.43955, acc 0.578125
2020-02-08T03:23:30.248320: step 69, loss 1.19524, acc 0.625
2020-02-08T03:23:30.364599: step 70, loss 1.15916, acc 0.609375
2020-02-08T03:23:30.482760: step 71, loss 2.12903, acc 0.453125
2020-02-08T03:23:30.599907: step 72, loss 1.56282, acc 0.5625
2020-02-08T03:23:30.717422: step 73, loss 1.79597, acc 0.46875
2020-02-08T03:23:30.833026: step 74, loss 1.35114, acc 0.546875
2020-02-08T03:23:30.948394: step 75, loss 1.28587, acc 0.515625
2020-02-08T03:23:31.065731: step 76, loss 1.28495, acc 0.5625
2020-02-08T03:23:31.181453: step 77, loss 1.58657, acc 0.484375
2020-02-08T03:23:31.301337: step 78, loss 1.79979, acc 0.453125
2020-02-08T03:23:31.417550: step 79, loss 1.74558, acc 0.453125
2020-02-08T03:23:31.532300: step 80, loss 1.57674, acc 0.5
2020-02-08T03:23:31.649029: step 81, loss 1.42019, acc 0.53125
2020-02-08T03:23:31.768224: step 82, loss 1.79575, acc 0.4375
2020-02-08T03:23:31.884442: step 83, loss 1.30702, acc 0.515625
2020-02-08T03:23:32.003049: step 84, loss 1.52221, acc 0.484375
2020-02-08T03:23:32.118810: step 85, loss 1.24382, acc 0.5625
2020-02-08T03:23:32.232317: step 86, loss 1.18349, acc 0.546875
2020-02-08T03:23:32.348792: step 87, loss 1.33958, acc 0.578125
2020-02-08T03:23:32.466058: step 88, loss 1.95836, acc 0.40625
2020-02-08T03:23:32.580601: step 89, loss 1.4563, acc 0.5625
2020-02-08T03:23:32.697533: step 90, loss 1.48454, acc 0.453125
2020-02-08T03:23:32.814000: step 91, loss 1.16804, acc 0.59375
2020-02-08T03:23:32.933250: step 92, loss 1.25304, acc 0.578125
2020-02-08T03:23:33.052373: step 93, loss 1.14913, acc 0.65625
2020-02-08T03:23:33.169493: step 94, loss 1.68899, acc 0.453125
2020-02-08T03:23:33.285835: step 95, loss 1.76723, acc 0.515625
2020-02-08T03:23:33.403920: step 96, loss 1.43577, acc 0.46875
2020-02-08T03:23:33.520354: step 97, loss 1.25374, acc 0.546875
2020-02-08T03:23:33.634722: step 98, loss 1.17771, acc 0.578125
2020-02-08T03:23:33.753021: step 99, loss 1.37471, acc 0.53125
2020-02-08T03:23:33.873493: step 100, loss 1.32753, acc 0.515625

Evaluation:
2020-02-08T03:23:34.112896: step 100, loss 0.776588, acc 0.580675

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-100

2020-02-08T03:23:35.740843: step 101, loss 0.86938, acc 0.6875
2020-02-08T03:23:35.862412: step 102, loss 1.43095, acc 0.53125
2020-02-08T03:23:35.978471: step 103, loss 1.02006, acc 0.5625
2020-02-08T03:23:36.096601: step 104, loss 1.5246, acc 0.4375
2020-02-08T03:23:36.213512: step 105, loss 1.08901, acc 0.578125
2020-02-08T03:23:36.329611: step 106, loss 1.28828, acc 0.59375
2020-02-08T03:23:36.445273: step 107, loss 1.91465, acc 0.453125
2020-02-08T03:23:36.560940: step 108, loss 1.30371, acc 0.59375
2020-02-08T03:23:36.677152: step 109, loss 1.40594, acc 0.546875
2020-02-08T03:23:36.792230: step 110, loss 1.46976, acc 0.59375
2020-02-08T03:23:36.909323: step 111, loss 1.54322, acc 0.53125
2020-02-08T03:23:37.024760: step 112, loss 1.06249, acc 0.59375
2020-02-08T03:23:37.139383: step 113, loss 1.19308, acc 0.5625
2020-02-08T03:23:37.257149: step 114, loss 1.14249, acc 0.5625
2020-02-08T03:23:37.372925: step 115, loss 1.14093, acc 0.578125
2020-02-08T03:23:37.489093: step 116, loss 1.31272, acc 0.546875
2020-02-08T03:23:37.605196: step 117, loss 1.26572, acc 0.546875
2020-02-08T03:23:37.723037: step 118, loss 1.43726, acc 0.5
2020-02-08T03:23:37.842600: step 119, loss 1.31008, acc 0.515625
2020-02-08T03:23:37.959294: step 120, loss 1.18435, acc 0.59375
2020-02-08T03:23:38.075942: step 121, loss 1.16378, acc 0.578125
2020-02-08T03:23:38.194077: step 122, loss 1.30711, acc 0.546875
2020-02-08T03:23:38.311195: step 123, loss 1.30657, acc 0.546875
2020-02-08T03:23:38.428355: step 124, loss 1.29813, acc 0.578125
2020-02-08T03:23:38.545196: step 125, loss 1.70101, acc 0.484375
2020-02-08T03:23:38.661229: step 126, loss 1.60015, acc 0.421875
2020-02-08T03:23:38.777341: step 127, loss 1.35833, acc 0.421875
2020-02-08T03:23:38.895246: step 128, loss 1.17805, acc 0.546875
2020-02-08T03:23:39.012858: step 129, loss 1.37756, acc 0.515625
2020-02-08T03:23:39.127791: step 130, loss 0.989973, acc 0.578125
2020-02-08T03:23:39.245205: step 131, loss 1.39591, acc 0.59375
2020-02-08T03:23:39.363037: step 132, loss 1.45074, acc 0.515625
2020-02-08T03:23:39.480501: step 133, loss 1.41864, acc 0.453125
2020-02-08T03:23:39.595096: step 134, loss 1.41396, acc 0.5
2020-02-08T03:23:39.711567: step 135, loss 1.12795, acc 0.53125
2020-02-08T03:23:39.826943: step 136, loss 1.06673, acc 0.59375
2020-02-08T03:23:39.943386: step 137, loss 1.46458, acc 0.484375
2020-02-08T03:23:40.059519: step 138, loss 1.31868, acc 0.484375
2020-02-08T03:23:40.175312: step 139, loss 1.3203, acc 0.453125
2020-02-08T03:23:40.292554: step 140, loss 1.26713, acc 0.5
2020-02-08T03:23:40.409179: step 141, loss 0.925721, acc 0.703125
2020-02-08T03:23:40.523750: step 142, loss 1.12941, acc 0.59375
2020-02-08T03:23:40.640777: step 143, loss 1.2315, acc 0.59375
2020-02-08T03:23:40.754496: step 144, loss 1.2609, acc 0.59375
2020-02-08T03:23:40.871439: step 145, loss 0.944934, acc 0.625
2020-02-08T03:23:40.987380: step 146, loss 1.49147, acc 0.484375
2020-02-08T03:23:41.104487: step 147, loss 1.11695, acc 0.609375
2020-02-08T03:23:41.219979: step 148, loss 1.1103, acc 0.578125
2020-02-08T03:23:41.336342: step 149, loss 0.968661, acc 0.609375
2020-02-08T03:23:41.450433: step 150, loss 1.31374, acc 0.6
2020-02-08T03:23:41.570409: step 151, loss 1.00011, acc 0.5625
2020-02-08T03:23:41.685411: step 152, loss 0.872223, acc 0.671875
2020-02-08T03:23:41.799855: step 153, loss 1.04494, acc 0.515625
2020-02-08T03:23:41.919283: step 154, loss 0.981737, acc 0.640625
2020-02-08T03:23:42.035292: step 155, loss 0.941818, acc 0.59375
2020-02-08T03:23:42.150059: step 156, loss 0.92494, acc 0.65625
2020-02-08T03:23:42.266069: step 157, loss 0.695244, acc 0.6875
2020-02-08T03:23:42.384699: step 158, loss 1.25661, acc 0.5
2020-02-08T03:23:42.499177: step 159, loss 1.03847, acc 0.53125
2020-02-08T03:23:42.613627: step 160, loss 1.06355, acc 0.546875
2020-02-08T03:23:42.730924: step 161, loss 0.925553, acc 0.59375
2020-02-08T03:23:42.845100: step 162, loss 1.04342, acc 0.609375
2020-02-08T03:23:42.962211: step 163, loss 0.85576, acc 0.625
2020-02-08T03:23:43.079182: step 164, loss 0.994376, acc 0.546875
2020-02-08T03:23:43.198572: step 165, loss 1.11583, acc 0.609375
2020-02-08T03:23:43.315283: step 166, loss 0.880895, acc 0.5625
2020-02-08T03:23:43.433201: step 167, loss 1.30274, acc 0.453125
2020-02-08T03:23:43.549636: step 168, loss 0.81363, acc 0.625
2020-02-08T03:23:43.665547: step 169, loss 0.775723, acc 0.703125
2020-02-08T03:23:43.782520: step 170, loss 0.961149, acc 0.578125
2020-02-08T03:23:43.900157: step 171, loss 0.696649, acc 0.75
2020-02-08T03:23:44.018487: step 172, loss 0.767758, acc 0.640625
2020-02-08T03:23:44.134556: step 173, loss 1.05264, acc 0.59375
2020-02-08T03:23:44.249603: step 174, loss 0.966803, acc 0.625
2020-02-08T03:23:44.366024: step 175, loss 0.915114, acc 0.609375
2020-02-08T03:23:44.483097: step 176, loss 0.70677, acc 0.65625
2020-02-08T03:23:44.596987: step 177, loss 1.37932, acc 0.46875
2020-02-08T03:23:44.711704: step 178, loss 0.878321, acc 0.703125
2020-02-08T03:23:44.827004: step 179, loss 0.723289, acc 0.671875
2020-02-08T03:23:44.942551: step 180, loss 0.943784, acc 0.578125
2020-02-08T03:23:45.059399: step 181, loss 0.93599, acc 0.5625
2020-02-08T03:23:45.175290: step 182, loss 1.04176, acc 0.53125
2020-02-08T03:23:45.289841: step 183, loss 1.02366, acc 0.5625
2020-02-08T03:23:45.405349: step 184, loss 1.0228, acc 0.546875
2020-02-08T03:23:45.521157: step 185, loss 0.944624, acc 0.59375
2020-02-08T03:23:45.635607: step 186, loss 1.03104, acc 0.46875
2020-02-08T03:23:45.753558: step 187, loss 0.785836, acc 0.671875
2020-02-08T03:23:45.868706: step 188, loss 1.08723, acc 0.5
2020-02-08T03:23:45.986476: step 189, loss 0.796658, acc 0.625
2020-02-08T03:23:46.101876: step 190, loss 1.10743, acc 0.515625
2020-02-08T03:23:46.219165: step 191, loss 0.845899, acc 0.625
2020-02-08T03:23:46.335665: step 192, loss 1.2559, acc 0.484375
2020-02-08T03:23:46.453388: step 193, loss 0.819055, acc 0.625
2020-02-08T03:23:46.567554: step 194, loss 0.983295, acc 0.59375
2020-02-08T03:23:46.685057: step 195, loss 0.783831, acc 0.671875
2020-02-08T03:23:46.800875: step 196, loss 0.645665, acc 0.6875
2020-02-08T03:23:46.917878: step 197, loss 0.793621, acc 0.640625
2020-02-08T03:23:47.033014: step 198, loss 1.1377, acc 0.609375
2020-02-08T03:23:47.149601: step 199, loss 1.21133, acc 0.59375
2020-02-08T03:23:47.264210: step 200, loss 1.01425, acc 0.640625

Evaluation:
2020-02-08T03:23:47.453965: step 200, loss 0.675809, acc 0.615385

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-200

2020-02-08T03:23:48.932795: step 201, loss 0.898415, acc 0.671875
2020-02-08T03:23:49.048990: step 202, loss 0.684101, acc 0.6875
2020-02-08T03:23:49.166035: step 203, loss 0.7589, acc 0.59375
2020-02-08T03:23:49.285186: step 204, loss 0.884962, acc 0.625
2020-02-08T03:23:49.403072: step 205, loss 1.03756, acc 0.578125
2020-02-08T03:23:49.521686: step 206, loss 0.68844, acc 0.6875
2020-02-08T03:23:49.635779: step 207, loss 0.857538, acc 0.625
2020-02-08T03:23:49.751674: step 208, loss 0.932843, acc 0.59375
2020-02-08T03:23:49.867469: step 209, loss 0.921599, acc 0.671875
2020-02-08T03:23:49.984057: step 210, loss 0.88711, acc 0.671875
2020-02-08T03:23:50.104038: step 211, loss 1.16244, acc 0.5
2020-02-08T03:23:50.222815: step 212, loss 0.884895, acc 0.5625
2020-02-08T03:23:50.340423: step 213, loss 1.00355, acc 0.578125
2020-02-08T03:23:50.458990: step 214, loss 1.02736, acc 0.5
2020-02-08T03:23:50.580056: step 215, loss 0.830532, acc 0.578125
2020-02-08T03:23:50.697064: step 216, loss 0.863676, acc 0.625
2020-02-08T03:23:50.818909: step 217, loss 1.05305, acc 0.609375
2020-02-08T03:23:50.934760: step 218, loss 1.14226, acc 0.4375
2020-02-08T03:23:51.052772: step 219, loss 0.863835, acc 0.578125
2020-02-08T03:23:51.171374: step 220, loss 0.872319, acc 0.625
2020-02-08T03:23:51.289084: step 221, loss 0.838546, acc 0.65625
2020-02-08T03:23:51.402748: step 222, loss 0.844282, acc 0.625
2020-02-08T03:23:51.624555: step 223, loss 0.9573, acc 0.578125
2020-02-08T03:23:51.753506: step 224, loss 0.792816, acc 0.640625
2020-02-08T03:23:51.871276: step 225, loss 0.877495, acc 0.625
2020-02-08T03:23:51.986059: step 226, loss 0.7852, acc 0.6875
2020-02-08T03:23:52.109090: step 227, loss 0.663638, acc 0.703125
2020-02-08T03:23:52.226959: step 228, loss 0.872264, acc 0.59375
2020-02-08T03:23:52.345343: step 229, loss 1.06097, acc 0.578125
2020-02-08T03:23:52.462711: step 230, loss 0.708967, acc 0.625
2020-02-08T03:23:52.580387: step 231, loss 0.772525, acc 0.640625
2020-02-08T03:23:52.698465: step 232, loss 0.931644, acc 0.59375
2020-02-08T03:23:52.814248: step 233, loss 0.948088, acc 0.625
2020-02-08T03:23:52.930260: step 234, loss 0.886593, acc 0.625
2020-02-08T03:23:53.048472: step 235, loss 0.795435, acc 0.6875
2020-02-08T03:23:53.164146: step 236, loss 1.25509, acc 0.5
2020-02-08T03:23:53.283179: step 237, loss 1.03593, acc 0.546875
2020-02-08T03:23:53.401186: step 238, loss 0.88931, acc 0.5625
2020-02-08T03:23:53.519924: step 239, loss 0.689086, acc 0.609375
2020-02-08T03:23:53.635395: step 240, loss 0.855433, acc 0.640625
2020-02-08T03:23:53.751220: step 241, loss 0.727815, acc 0.6875
2020-02-08T03:23:53.868270: step 242, loss 0.818603, acc 0.640625
2020-02-08T03:23:53.985650: step 243, loss 0.687823, acc 0.671875
2020-02-08T03:23:54.101240: step 244, loss 0.845677, acc 0.5625
2020-02-08T03:23:54.219059: step 245, loss 0.700899, acc 0.59375
2020-02-08T03:23:54.337282: step 246, loss 0.701557, acc 0.625
2020-02-08T03:23:54.452635: step 247, loss 0.78669, acc 0.640625
2020-02-08T03:23:54.569958: step 248, loss 0.968067, acc 0.53125
2020-02-08T03:23:54.686478: step 249, loss 0.998737, acc 0.515625
2020-02-08T03:23:54.803127: step 250, loss 0.747706, acc 0.671875
2020-02-08T03:23:54.920737: step 251, loss 0.809448, acc 0.546875
2020-02-08T03:23:55.040481: step 252, loss 0.946114, acc 0.546875
2020-02-08T03:23:55.159886: step 253, loss 1.10622, acc 0.515625
2020-02-08T03:23:55.275043: step 254, loss 0.875244, acc 0.59375
2020-02-08T03:23:55.388668: step 255, loss 0.979829, acc 0.640625
2020-02-08T03:23:55.511184: step 256, loss 0.788328, acc 0.609375
2020-02-08T03:23:55.627631: step 257, loss 1.02624, acc 0.59375
2020-02-08T03:23:55.747808: step 258, loss 0.691248, acc 0.65625
2020-02-08T03:23:55.867769: step 259, loss 0.856492, acc 0.625
2020-02-08T03:23:55.982707: step 260, loss 0.906616, acc 0.59375
2020-02-08T03:23:56.097961: step 261, loss 0.914208, acc 0.5625
2020-02-08T03:23:56.213534: step 262, loss 0.826069, acc 0.59375
2020-02-08T03:23:56.327779: step 263, loss 0.68685, acc 0.640625
2020-02-08T03:23:56.444594: step 264, loss 0.714356, acc 0.6875
2020-02-08T03:23:56.559408: step 265, loss 0.66065, acc 0.65625
2020-02-08T03:23:56.674900: step 266, loss 0.777546, acc 0.578125
2020-02-08T03:23:56.789209: step 267, loss 0.949877, acc 0.453125
2020-02-08T03:23:56.908270: step 268, loss 1.11903, acc 0.484375
2020-02-08T03:23:57.027218: step 269, loss 0.752939, acc 0.625
2020-02-08T03:23:57.144086: step 270, loss 0.652471, acc 0.734375
2020-02-08T03:23:57.259252: step 271, loss 0.845508, acc 0.640625
2020-02-08T03:23:57.375457: step 272, loss 0.941044, acc 0.515625
2020-02-08T03:23:57.492879: step 273, loss 0.987196, acc 0.578125
2020-02-08T03:23:57.609553: step 274, loss 0.90094, acc 0.59375
2020-02-08T03:23:57.724115: step 275, loss 0.876317, acc 0.59375
2020-02-08T03:23:57.843189: step 276, loss 0.719361, acc 0.75
2020-02-08T03:23:57.963166: step 277, loss 0.7445, acc 0.609375
2020-02-08T03:23:58.078214: step 278, loss 0.802596, acc 0.640625
2020-02-08T03:23:58.194003: step 279, loss 0.842369, acc 0.625
2020-02-08T03:23:58.310973: step 280, loss 0.77749, acc 0.640625
2020-02-08T03:23:58.424795: step 281, loss 0.820904, acc 0.59375
2020-02-08T03:23:58.544598: step 282, loss 0.932645, acc 0.5
2020-02-08T03:23:58.661647: step 283, loss 1.09326, acc 0.5
2020-02-08T03:23:58.776714: step 284, loss 1.07811, acc 0.578125
2020-02-08T03:23:58.894025: step 285, loss 0.793973, acc 0.671875
2020-02-08T03:23:59.010691: step 286, loss 0.645823, acc 0.640625
2020-02-08T03:23:59.126913: step 287, loss 0.940604, acc 0.5625
2020-02-08T03:23:59.244302: step 288, loss 0.892042, acc 0.59375
2020-02-08T03:23:59.360984: step 289, loss 0.778319, acc 0.578125
2020-02-08T03:23:59.476225: step 290, loss 0.883789, acc 0.578125
2020-02-08T03:23:59.593135: step 291, loss 0.847818, acc 0.625
2020-02-08T03:23:59.709630: step 292, loss 0.866784, acc 0.578125
2020-02-08T03:23:59.827787: step 293, loss 0.622419, acc 0.71875
2020-02-08T03:23:59.947547: step 294, loss 0.599883, acc 0.6875
2020-02-08T03:24:00.066473: step 295, loss 0.808889, acc 0.5625
2020-02-08T03:24:00.182679: step 296, loss 0.89678, acc 0.515625
2020-02-08T03:24:00.298294: step 297, loss 0.589084, acc 0.734375
2020-02-08T03:24:00.417253: step 298, loss 0.650142, acc 0.703125
2020-02-08T03:24:00.533196: step 299, loss 0.745574, acc 0.59375
2020-02-08T03:24:00.647971: step 300, loss 0.99618, acc 0.533333

Evaluation:
2020-02-08T03:24:00.834172: step 300, loss 0.642455, acc 0.621951

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-300

2020-02-08T03:24:02.355762: step 301, loss 0.71174, acc 0.65625
2020-02-08T03:24:02.473915: step 302, loss 0.660175, acc 0.6875
2020-02-08T03:24:02.588577: step 303, loss 0.859909, acc 0.546875
2020-02-08T03:24:02.707983: step 304, loss 0.597865, acc 0.65625
2020-02-08T03:24:02.823954: step 305, loss 0.734709, acc 0.609375
2020-02-08T03:24:02.939833: step 306, loss 0.825646, acc 0.609375
2020-02-08T03:24:03.054654: step 307, loss 0.519945, acc 0.75
2020-02-08T03:24:03.171451: step 308, loss 0.719331, acc 0.5625
2020-02-08T03:24:03.286240: step 309, loss 0.594635, acc 0.671875
2020-02-08T03:24:03.404443: step 310, loss 0.56691, acc 0.6875
2020-02-08T03:24:03.519347: step 311, loss 0.938503, acc 0.46875
2020-02-08T03:24:03.635723: step 312, loss 0.718053, acc 0.625
2020-02-08T03:24:03.755272: step 313, loss 0.796221, acc 0.609375
2020-02-08T03:24:03.874367: step 314, loss 0.624614, acc 0.671875
2020-02-08T03:24:03.991259: step 315, loss 0.762431, acc 0.546875
2020-02-08T03:24:04.119053: step 316, loss 0.798344, acc 0.5625
2020-02-08T03:24:04.237535: step 317, loss 0.588247, acc 0.703125
2020-02-08T03:24:04.358416: step 318, loss 0.735204, acc 0.65625
2020-02-08T03:24:04.474229: step 319, loss 0.632792, acc 0.6875
2020-02-08T03:24:04.592340: step 320, loss 0.773698, acc 0.625
2020-02-08T03:24:04.710275: step 321, loss 0.662164, acc 0.71875
2020-02-08T03:24:04.826454: step 322, loss 0.691491, acc 0.671875
2020-02-08T03:24:04.945193: step 323, loss 0.67375, acc 0.625
2020-02-08T03:24:05.066247: step 324, loss 0.624029, acc 0.703125
2020-02-08T03:24:05.181009: step 325, loss 0.605007, acc 0.703125
2020-02-08T03:24:05.297852: step 326, loss 0.557525, acc 0.734375
2020-02-08T03:24:05.416651: step 327, loss 0.645524, acc 0.734375
2020-02-08T03:24:05.534149: step 328, loss 0.624437, acc 0.6875
2020-02-08T03:24:05.651335: step 329, loss 0.616241, acc 0.640625
2020-02-08T03:24:05.768248: step 330, loss 0.58696, acc 0.671875
2020-02-08T03:24:05.884534: step 331, loss 0.648334, acc 0.609375
2020-02-08T03:24:06.003043: step 332, loss 0.769169, acc 0.59375
2020-02-08T03:24:06.119811: step 333, loss 0.803756, acc 0.59375
2020-02-08T03:24:06.233289: step 334, loss 0.685843, acc 0.578125
2020-02-08T03:24:06.350555: step 335, loss 0.684032, acc 0.640625
2020-02-08T03:24:06.468560: step 336, loss 0.534048, acc 0.734375
2020-02-08T03:24:06.581803: step 337, loss 0.535667, acc 0.6875
2020-02-08T03:24:06.697546: step 338, loss 0.796044, acc 0.546875
2020-02-08T03:24:06.812733: step 339, loss 0.672856, acc 0.65625
2020-02-08T03:24:06.927512: step 340, loss 0.635587, acc 0.640625
2020-02-08T03:24:07.045425: step 341, loss 0.527544, acc 0.75
2020-02-08T03:24:07.163197: step 342, loss 0.60888, acc 0.65625
2020-02-08T03:24:07.279496: step 343, loss 0.730245, acc 0.640625
2020-02-08T03:24:07.396702: step 344, loss 0.868045, acc 0.546875
2020-02-08T03:24:07.516499: step 345, loss 0.633615, acc 0.640625
2020-02-08T03:24:07.633255: step 346, loss 0.663951, acc 0.640625
2020-02-08T03:24:07.753573: step 347, loss 0.769187, acc 0.640625
2020-02-08T03:24:07.871233: step 348, loss 0.707616, acc 0.609375
2020-02-08T03:24:07.989733: step 349, loss 0.534247, acc 0.75
2020-02-08T03:24:08.107747: step 350, loss 0.629145, acc 0.65625
2020-02-08T03:24:08.222861: step 351, loss 0.558136, acc 0.75
2020-02-08T03:24:08.338991: step 352, loss 0.636397, acc 0.703125
2020-02-08T03:24:08.456369: step 353, loss 0.460413, acc 0.734375
2020-02-08T03:24:08.572727: step 354, loss 0.653479, acc 0.65625
2020-02-08T03:24:08.688990: step 355, loss 0.564936, acc 0.671875
2020-02-08T03:24:08.807500: step 356, loss 0.55525, acc 0.6875
2020-02-08T03:24:08.926931: step 357, loss 0.810336, acc 0.5625
2020-02-08T03:24:09.046458: step 358, loss 0.769346, acc 0.609375
2020-02-08T03:24:09.167094: step 359, loss 0.586331, acc 0.6875
2020-02-08T03:24:09.282210: step 360, loss 0.581366, acc 0.734375
2020-02-08T03:24:09.398249: step 361, loss 0.777912, acc 0.65625
2020-02-08T03:24:09.517476: step 362, loss 0.649283, acc 0.65625
2020-02-08T03:24:09.630955: step 363, loss 0.63636, acc 0.6875
2020-02-08T03:24:09.749005: step 364, loss 0.716323, acc 0.703125
2020-02-08T03:24:09.864793: step 365, loss 0.802826, acc 0.6875
2020-02-08T03:24:09.982180: step 366, loss 0.635736, acc 0.703125
2020-02-08T03:24:10.101387: step 367, loss 0.66833, acc 0.640625
2020-02-08T03:24:10.216754: step 368, loss 0.401898, acc 0.828125
2020-02-08T03:24:10.333402: step 369, loss 0.533391, acc 0.671875
2020-02-08T03:24:10.452510: step 370, loss 0.546097, acc 0.734375
2020-02-08T03:24:10.568557: step 371, loss 0.509708, acc 0.734375
2020-02-08T03:24:10.688164: step 372, loss 0.671282, acc 0.734375
2020-02-08T03:24:10.803350: step 373, loss 0.752122, acc 0.65625
2020-02-08T03:24:10.921142: step 374, loss 0.660708, acc 0.65625
2020-02-08T03:24:11.034739: step 375, loss 0.682127, acc 0.640625
2020-02-08T03:24:11.150037: step 376, loss 0.511563, acc 0.75
2020-02-08T03:24:11.266199: step 377, loss 0.594041, acc 0.671875
2020-02-08T03:24:11.381183: step 378, loss 0.620247, acc 0.765625
2020-02-08T03:24:11.499636: step 379, loss 0.56726, acc 0.71875
2020-02-08T03:24:11.616923: step 380, loss 0.65041, acc 0.703125
2020-02-08T03:24:11.733268: step 381, loss 0.668141, acc 0.625
2020-02-08T03:24:11.854398: step 382, loss 0.502718, acc 0.71875
2020-02-08T03:24:11.973762: step 383, loss 0.701437, acc 0.609375
2020-02-08T03:24:12.088413: step 384, loss 0.644305, acc 0.734375
2020-02-08T03:24:12.205650: step 385, loss 0.635078, acc 0.703125
2020-02-08T03:24:12.325112: step 386, loss 0.654426, acc 0.671875
2020-02-08T03:24:12.442029: step 387, loss 0.57449, acc 0.71875
2020-02-08T03:24:12.559941: step 388, loss 0.704719, acc 0.609375
2020-02-08T03:24:12.675804: step 389, loss 0.644064, acc 0.71875
2020-02-08T03:24:12.791319: step 390, loss 0.538627, acc 0.734375
2020-02-08T03:24:12.908275: step 391, loss 0.545888, acc 0.71875
2020-02-08T03:24:13.024978: step 392, loss 0.70016, acc 0.65625
2020-02-08T03:24:13.137022: step 393, loss 0.569401, acc 0.734375
2020-02-08T03:24:13.255809: step 394, loss 0.659343, acc 0.625
2020-02-08T03:24:13.372915: step 395, loss 0.761593, acc 0.625
2020-02-08T03:24:13.490866: step 396, loss 0.708027, acc 0.71875
2020-02-08T03:24:13.607865: step 397, loss 0.618287, acc 0.703125
2020-02-08T03:24:13.724302: step 398, loss 0.494163, acc 0.765625
2020-02-08T03:24:13.851477: step 399, loss 0.601082, acc 0.6875
2020-02-08T03:24:13.968220: step 400, loss 0.584998, acc 0.703125

Evaluation:
2020-02-08T03:24:14.157312: step 400, loss 0.723521, acc 0.560037

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-400

2020-02-08T03:24:15.613376: step 401, loss 0.67286, acc 0.671875
2020-02-08T03:24:15.729343: step 402, loss 0.679333, acc 0.609375
2020-02-08T03:24:15.843538: step 403, loss 0.617064, acc 0.640625
2020-02-08T03:24:15.958420: step 404, loss 0.565213, acc 0.71875
2020-02-08T03:24:16.073402: step 405, loss 0.586593, acc 0.71875
2020-02-08T03:24:16.187239: step 406, loss 0.6389, acc 0.734375
2020-02-08T03:24:16.307606: step 407, loss 0.690165, acc 0.578125
2020-02-08T03:24:16.424720: step 408, loss 0.754011, acc 0.625
2020-02-08T03:24:16.541907: step 409, loss 0.640675, acc 0.625
2020-02-08T03:24:16.660671: step 410, loss 0.917648, acc 0.5625
2020-02-08T03:24:16.778145: step 411, loss 0.790409, acc 0.5625
2020-02-08T03:24:16.895926: step 412, loss 0.690392, acc 0.65625
2020-02-08T03:24:17.011861: step 413, loss 0.53988, acc 0.765625
2020-02-08T03:24:17.128587: step 414, loss 0.577667, acc 0.671875
2020-02-08T03:24:17.244977: step 415, loss 0.769755, acc 0.59375
2020-02-08T03:24:17.363418: step 416, loss 0.67327, acc 0.640625
2020-02-08T03:24:17.481631: step 417, loss 0.612794, acc 0.6875
2020-02-08T03:24:17.598505: step 418, loss 0.553183, acc 0.765625
2020-02-08T03:24:17.715943: step 419, loss 0.762262, acc 0.625
2020-02-08T03:24:17.832739: step 420, loss 0.645953, acc 0.671875
2020-02-08T03:24:17.951538: step 421, loss 0.49975, acc 0.765625
2020-02-08T03:24:18.067749: step 422, loss 0.707454, acc 0.640625
2020-02-08T03:24:18.183556: step 423, loss 0.577449, acc 0.734375
2020-02-08T03:24:18.302036: step 424, loss 0.580768, acc 0.78125
2020-02-08T03:24:18.416348: step 425, loss 0.652783, acc 0.625
2020-02-08T03:24:18.533678: step 426, loss 0.719342, acc 0.578125
2020-02-08T03:24:18.654958: step 427, loss 0.774871, acc 0.5625
2020-02-08T03:24:18.773725: step 428, loss 0.657988, acc 0.671875
2020-02-08T03:24:18.890652: step 429, loss 0.574252, acc 0.65625
2020-02-08T03:24:19.008280: step 430, loss 0.562239, acc 0.65625
2020-02-08T03:24:19.124376: step 431, loss 0.592647, acc 0.71875
2020-02-08T03:24:19.240018: step 432, loss 0.653579, acc 0.578125
2020-02-08T03:24:19.358414: step 433, loss 0.714669, acc 0.640625
2020-02-08T03:24:19.472977: step 434, loss 0.790761, acc 0.578125
2020-02-08T03:24:19.586774: step 435, loss 0.683616, acc 0.65625
2020-02-08T03:24:19.703007: step 436, loss 0.605145, acc 0.71875
2020-02-08T03:24:19.820575: step 437, loss 0.667771, acc 0.578125
2020-02-08T03:24:19.936440: step 438, loss 0.63359, acc 0.65625
2020-02-08T03:24:20.053938: step 439, loss 0.720832, acc 0.59375
2020-02-08T03:24:20.171100: step 440, loss 0.624198, acc 0.65625
2020-02-08T03:24:20.286856: step 441, loss 0.666226, acc 0.640625
2020-02-08T03:24:20.404136: step 442, loss 0.689949, acc 0.65625
2020-02-08T03:24:20.519865: step 443, loss 0.644125, acc 0.671875
2020-02-08T03:24:20.634483: step 444, loss 0.757085, acc 0.625
2020-02-08T03:24:20.751897: step 445, loss 0.528054, acc 0.703125
2020-02-08T03:24:20.870384: step 446, loss 0.612019, acc 0.6875
2020-02-08T03:24:20.986388: step 447, loss 0.688001, acc 0.65625
2020-02-08T03:24:21.105494: step 448, loss 0.599489, acc 0.671875
2020-02-08T03:24:21.223014: step 449, loss 0.546809, acc 0.6875
2020-02-08T03:24:21.334258: step 450, loss 0.70109, acc 0.55
2020-02-08T03:24:21.454105: step 451, loss 0.549986, acc 0.703125
2020-02-08T03:24:21.758312: step 452, loss 0.542586, acc 0.703125
2020-02-08T03:24:21.882437: step 453, loss 0.565974, acc 0.734375
2020-02-08T03:24:22.001252: step 454, loss 0.6769, acc 0.625
2020-02-08T03:24:22.117566: step 455, loss 0.548186, acc 0.734375
2020-02-08T03:24:22.233050: step 456, loss 0.699709, acc 0.578125
2020-02-08T03:24:22.348561: step 457, loss 0.533289, acc 0.75
2020-02-08T03:24:22.469119: step 458, loss 0.503048, acc 0.734375
2020-02-08T03:24:22.584364: step 459, loss 0.509221, acc 0.8125
2020-02-08T03:24:22.700002: step 460, loss 0.530193, acc 0.703125
2020-02-08T03:24:22.815326: step 461, loss 0.598128, acc 0.6875
2020-02-08T03:24:22.930516: step 462, loss 0.580692, acc 0.6875
2020-02-08T03:24:23.047769: step 463, loss 0.604859, acc 0.6875
2020-02-08T03:24:23.164483: step 464, loss 0.527723, acc 0.796875
2020-02-08T03:24:23.280605: step 465, loss 0.563042, acc 0.65625
2020-02-08T03:24:23.400105: step 466, loss 0.536508, acc 0.78125
2020-02-08T03:24:23.518847: step 467, loss 0.626959, acc 0.671875
2020-02-08T03:24:23.634448: step 468, loss 0.557437, acc 0.71875
2020-02-08T03:24:23.752833: step 469, loss 0.517988, acc 0.75
2020-02-08T03:24:23.871819: step 470, loss 0.517626, acc 0.765625
2020-02-08T03:24:23.987872: step 471, loss 0.498492, acc 0.78125
2020-02-08T03:24:24.108464: step 472, loss 0.589988, acc 0.65625
2020-02-08T03:24:24.226316: step 473, loss 0.541705, acc 0.71875
2020-02-08T03:24:24.342515: step 474, loss 0.552705, acc 0.75
2020-02-08T03:24:24.462881: step 475, loss 0.581605, acc 0.703125
2020-02-08T03:24:24.578949: step 476, loss 0.545342, acc 0.703125
2020-02-08T03:24:24.699554: step 477, loss 0.630247, acc 0.65625
2020-02-08T03:24:24.816048: step 478, loss 0.465375, acc 0.78125
2020-02-08T03:24:24.932897: step 479, loss 0.573693, acc 0.671875
2020-02-08T03:24:25.047932: step 480, loss 0.59355, acc 0.734375
2020-02-08T03:24:25.163986: step 481, loss 0.578946, acc 0.71875
2020-02-08T03:24:25.279651: step 482, loss 0.543975, acc 0.75
2020-02-08T03:24:25.393409: step 483, loss 0.544063, acc 0.703125
2020-02-08T03:24:25.511289: step 484, loss 0.588474, acc 0.703125
2020-02-08T03:24:25.627924: step 485, loss 0.70951, acc 0.609375
2020-02-08T03:24:25.746727: step 486, loss 0.695801, acc 0.6875
2020-02-08T03:24:25.865554: step 487, loss 0.56386, acc 0.75
2020-02-08T03:24:25.985439: step 488, loss 0.555884, acc 0.75
2020-02-08T03:24:26.105519: step 489, loss 0.716286, acc 0.65625
2020-02-08T03:24:26.225091: step 490, loss 0.518438, acc 0.796875
2020-02-08T03:24:26.341930: step 491, loss 0.586872, acc 0.671875
2020-02-08T03:24:26.460320: step 492, loss 0.516288, acc 0.703125
2020-02-08T03:24:26.580082: step 493, loss 0.652089, acc 0.59375
2020-02-08T03:24:26.697625: step 494, loss 0.512116, acc 0.734375
2020-02-08T03:24:26.817207: step 495, loss 0.600926, acc 0.71875
2020-02-08T03:24:26.933270: step 496, loss 0.551978, acc 0.75
2020-02-08T03:24:27.050044: step 497, loss 0.392728, acc 0.859375
2020-02-08T03:24:27.168612: step 498, loss 0.570679, acc 0.703125
2020-02-08T03:24:27.283818: step 499, loss 0.495224, acc 0.734375
2020-02-08T03:24:27.400977: step 500, loss 0.624151, acc 0.625

Evaluation:
2020-02-08T03:24:27.589673: step 500, loss 0.627608, acc 0.652908

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-500

2020-02-08T03:24:29.075689: step 501, loss 0.681641, acc 0.671875
2020-02-08T03:24:29.192518: step 502, loss 0.605053, acc 0.671875
2020-02-08T03:24:29.309418: step 503, loss 0.533963, acc 0.703125
2020-02-08T03:24:29.426743: step 504, loss 0.583168, acc 0.765625
2020-02-08T03:24:29.546423: step 505, loss 0.573835, acc 0.71875
2020-02-08T03:24:29.666109: step 506, loss 0.600262, acc 0.703125
2020-02-08T03:24:29.785456: step 507, loss 0.62155, acc 0.734375
2020-02-08T03:24:29.906115: step 508, loss 0.569284, acc 0.75
2020-02-08T03:24:30.023058: step 509, loss 0.620603, acc 0.734375
2020-02-08T03:24:30.140257: step 510, loss 0.494632, acc 0.78125
2020-02-08T03:24:30.258234: step 511, loss 0.616142, acc 0.71875
2020-02-08T03:24:30.380527: step 512, loss 0.625026, acc 0.703125
2020-02-08T03:24:30.498818: step 513, loss 0.597555, acc 0.671875
2020-02-08T03:24:30.615873: step 514, loss 0.60012, acc 0.703125
2020-02-08T03:24:30.735354: step 515, loss 0.615683, acc 0.71875
2020-02-08T03:24:30.853145: step 516, loss 0.500561, acc 0.75
2020-02-08T03:24:30.971592: step 517, loss 0.592835, acc 0.6875
2020-02-08T03:24:31.085298: step 518, loss 0.688551, acc 0.625
2020-02-08T03:24:31.201350: step 519, loss 0.63992, acc 0.6875
2020-02-08T03:24:31.317933: step 520, loss 0.6499, acc 0.578125
2020-02-08T03:24:31.435601: step 521, loss 0.590762, acc 0.671875
2020-02-08T03:24:31.553065: step 522, loss 0.509654, acc 0.796875
2020-02-08T03:24:31.670647: step 523, loss 0.468244, acc 0.796875
2020-02-08T03:24:31.788029: step 524, loss 0.481874, acc 0.765625
2020-02-08T03:24:31.905437: step 525, loss 0.463867, acc 0.8125
2020-02-08T03:24:32.022046: step 526, loss 0.49175, acc 0.71875
2020-02-08T03:24:32.137482: step 527, loss 0.422126, acc 0.765625
2020-02-08T03:24:32.252956: step 528, loss 0.573704, acc 0.671875
2020-02-08T03:24:32.373646: step 529, loss 0.44133, acc 0.78125
2020-02-08T03:24:32.492256: step 530, loss 0.459411, acc 0.78125
2020-02-08T03:24:32.609096: step 531, loss 0.607756, acc 0.703125
2020-02-08T03:24:32.726872: step 532, loss 0.529389, acc 0.75
2020-02-08T03:24:32.845275: step 533, loss 0.649362, acc 0.71875
2020-02-08T03:24:32.962815: step 534, loss 0.522995, acc 0.71875
2020-02-08T03:24:33.080000: step 535, loss 0.474408, acc 0.796875
2020-02-08T03:24:33.199848: step 536, loss 0.611254, acc 0.671875
2020-02-08T03:24:33.316963: step 537, loss 0.452318, acc 0.84375
2020-02-08T03:24:33.435101: step 538, loss 0.55894, acc 0.6875
2020-02-08T03:24:33.553740: step 539, loss 0.609503, acc 0.71875
2020-02-08T03:24:33.671333: step 540, loss 0.604359, acc 0.671875
2020-02-08T03:24:33.787827: step 541, loss 0.494448, acc 0.75
2020-02-08T03:24:33.903159: step 542, loss 0.613528, acc 0.703125
2020-02-08T03:24:34.017717: step 543, loss 0.430704, acc 0.796875
2020-02-08T03:24:34.133581: step 544, loss 0.541116, acc 0.6875
2020-02-08T03:24:34.250642: step 545, loss 0.492192, acc 0.75
2020-02-08T03:24:34.366638: step 546, loss 0.566339, acc 0.71875
2020-02-08T03:24:34.482674: step 547, loss 0.561968, acc 0.625
2020-02-08T03:24:34.599651: step 548, loss 0.609047, acc 0.671875
2020-02-08T03:24:34.715356: step 549, loss 0.619209, acc 0.703125
2020-02-08T03:24:34.832927: step 550, loss 0.577565, acc 0.703125
2020-02-08T03:24:34.949938: step 551, loss 0.569576, acc 0.6875
2020-02-08T03:24:35.068643: step 552, loss 0.689224, acc 0.65625
2020-02-08T03:24:35.187027: step 553, loss 0.536557, acc 0.71875
2020-02-08T03:24:35.305196: step 554, loss 0.52823, acc 0.75
2020-02-08T03:24:35.422803: step 555, loss 0.482553, acc 0.78125
2020-02-08T03:24:35.539681: step 556, loss 0.664537, acc 0.640625
2020-02-08T03:24:35.656525: step 557, loss 0.591904, acc 0.640625
2020-02-08T03:24:35.773613: step 558, loss 0.497544, acc 0.703125
2020-02-08T03:24:35.894679: step 559, loss 0.578784, acc 0.703125
2020-02-08T03:24:36.012302: step 560, loss 0.547289, acc 0.6875
2020-02-08T03:24:36.130137: step 561, loss 0.515418, acc 0.765625
2020-02-08T03:24:36.246282: step 562, loss 0.582362, acc 0.640625
2020-02-08T03:24:36.364754: step 563, loss 0.598277, acc 0.640625
2020-02-08T03:24:36.481866: step 564, loss 0.53408, acc 0.8125
2020-02-08T03:24:36.600554: step 565, loss 0.60219, acc 0.703125
2020-02-08T03:24:36.718428: step 566, loss 0.540032, acc 0.671875
2020-02-08T03:24:36.838311: step 567, loss 0.555986, acc 0.75
2020-02-08T03:24:36.954148: step 568, loss 0.496636, acc 0.765625
2020-02-08T03:24:37.071309: step 569, loss 0.587053, acc 0.765625
2020-02-08T03:24:37.189773: step 570, loss 0.455553, acc 0.75
2020-02-08T03:24:37.307600: step 571, loss 0.57398, acc 0.671875
2020-02-08T03:24:37.422815: step 572, loss 0.505214, acc 0.734375
2020-02-08T03:24:37.540267: step 573, loss 0.525013, acc 0.671875
2020-02-08T03:24:37.656785: step 574, loss 0.479838, acc 0.765625
2020-02-08T03:24:37.775885: step 575, loss 0.590996, acc 0.71875
2020-02-08T03:24:37.893809: step 576, loss 0.575909, acc 0.71875
2020-02-08T03:24:38.011467: step 577, loss 0.510927, acc 0.671875
2020-02-08T03:24:38.130199: step 578, loss 0.627758, acc 0.71875
2020-02-08T03:24:38.249165: step 579, loss 0.596495, acc 0.703125
2020-02-08T03:24:38.366659: step 580, loss 0.562122, acc 0.703125
2020-02-08T03:24:38.484052: step 581, loss 0.596738, acc 0.703125
2020-02-08T03:24:38.601985: step 582, loss 0.606598, acc 0.703125
2020-02-08T03:24:38.717286: step 583, loss 0.684331, acc 0.65625
2020-02-08T03:24:38.832233: step 584, loss 0.620001, acc 0.703125
2020-02-08T03:24:38.950427: step 585, loss 0.415612, acc 0.8125
2020-02-08T03:24:39.066885: step 586, loss 0.572049, acc 0.703125
2020-02-08T03:24:39.181860: step 587, loss 0.656349, acc 0.65625
2020-02-08T03:24:39.300851: step 588, loss 0.534336, acc 0.765625
2020-02-08T03:24:39.415710: step 589, loss 0.631399, acc 0.578125
2020-02-08T03:24:39.530959: step 590, loss 0.634312, acc 0.703125
2020-02-08T03:24:39.651250: step 591, loss 0.521591, acc 0.796875
2020-02-08T03:24:39.769341: step 592, loss 0.366714, acc 0.84375
2020-02-08T03:24:39.888956: step 593, loss 0.46703, acc 0.78125
2020-02-08T03:24:40.009909: step 594, loss 0.520078, acc 0.796875
2020-02-08T03:24:40.129708: step 595, loss 0.542183, acc 0.78125
2020-02-08T03:24:40.245973: step 596, loss 0.665758, acc 0.640625
2020-02-08T03:24:40.363499: step 597, loss 0.524558, acc 0.75
2020-02-08T03:24:40.479719: step 598, loss 0.57499, acc 0.703125
2020-02-08T03:24:40.594378: step 599, loss 0.578477, acc 0.703125
2020-02-08T03:24:40.709432: step 600, loss 0.528314, acc 0.733333

Evaluation:
2020-02-08T03:24:40.896918: step 600, loss 0.644624, acc 0.634146

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-600

2020-02-08T03:24:42.391457: step 601, loss 0.477444, acc 0.75
2020-02-08T03:24:42.510643: step 602, loss 0.461371, acc 0.75
2020-02-08T03:24:42.626309: step 603, loss 0.498466, acc 0.734375
2020-02-08T03:24:42.741176: step 604, loss 0.443123, acc 0.828125
2020-02-08T03:24:42.857205: step 605, loss 0.403749, acc 0.8125
2020-02-08T03:24:42.975352: step 606, loss 0.535541, acc 0.796875
2020-02-08T03:24:43.094419: step 607, loss 0.46687, acc 0.765625
2020-02-08T03:24:43.210800: step 608, loss 0.616543, acc 0.625
2020-02-08T03:24:43.328449: step 609, loss 0.588113, acc 0.671875
2020-02-08T03:24:43.445815: step 610, loss 0.369322, acc 0.859375
2020-02-08T03:24:43.571262: step 611, loss 0.520478, acc 0.765625
2020-02-08T03:24:43.686819: step 612, loss 0.374457, acc 0.859375
2020-02-08T03:24:43.809725: step 613, loss 0.439591, acc 0.8125
2020-02-08T03:24:44.031585: step 614, loss 0.560212, acc 0.703125
2020-02-08T03:24:44.176612: step 615, loss 0.471229, acc 0.78125
2020-02-08T03:24:44.303987: step 616, loss 0.503115, acc 0.734375
2020-02-08T03:24:44.458409: step 617, loss 0.583681, acc 0.734375
2020-02-08T03:24:44.594478: step 618, loss 0.42526, acc 0.78125
2020-02-08T03:24:44.732293: step 619, loss 0.536955, acc 0.71875
2020-02-08T03:24:44.871052: step 620, loss 0.519322, acc 0.703125
2020-02-08T03:24:45.010623: step 621, loss 0.486655, acc 0.796875
2020-02-08T03:24:45.146553: step 622, loss 0.477114, acc 0.75
2020-02-08T03:24:45.275839: step 623, loss 0.454647, acc 0.84375
2020-02-08T03:24:45.414674: step 624, loss 0.555952, acc 0.703125
2020-02-08T03:24:45.550474: step 625, loss 0.438128, acc 0.828125
2020-02-08T03:24:45.682349: step 626, loss 0.576352, acc 0.734375
2020-02-08T03:24:45.809303: step 627, loss 0.525594, acc 0.71875
2020-02-08T03:24:45.943302: step 628, loss 0.444507, acc 0.78125
2020-02-08T03:24:46.076222: step 629, loss 0.554472, acc 0.703125
2020-02-08T03:24:46.207967: step 630, loss 0.615093, acc 0.75
2020-02-08T03:24:46.340613: step 631, loss 0.474605, acc 0.8125
2020-02-08T03:24:46.473110: step 632, loss 0.550073, acc 0.6875
2020-02-08T03:24:46.605304: step 633, loss 0.60904, acc 0.6875
2020-02-08T03:24:46.744697: step 634, loss 0.475323, acc 0.734375
2020-02-08T03:24:46.884630: step 635, loss 0.481108, acc 0.765625
2020-02-08T03:24:47.027481: step 636, loss 0.391766, acc 0.890625
2020-02-08T03:24:47.172132: step 637, loss 0.431509, acc 0.796875
2020-02-08T03:24:47.318720: step 638, loss 0.480275, acc 0.734375
2020-02-08T03:24:47.461343: step 639, loss 0.513873, acc 0.734375
2020-02-08T03:24:47.595655: step 640, loss 0.420815, acc 0.828125
2020-02-08T03:24:47.719308: step 641, loss 0.553048, acc 0.734375
2020-02-08T03:24:47.855530: step 642, loss 0.539071, acc 0.71875
2020-02-08T03:24:47.994915: step 643, loss 0.502043, acc 0.78125
2020-02-08T03:24:48.132430: step 644, loss 0.585944, acc 0.71875
2020-02-08T03:24:48.267462: step 645, loss 0.431361, acc 0.796875
2020-02-08T03:24:48.404383: step 646, loss 0.421188, acc 0.765625
2020-02-08T03:24:48.538342: step 647, loss 0.646696, acc 0.703125
2020-02-08T03:24:48.676336: step 648, loss 0.474922, acc 0.765625
2020-02-08T03:24:48.815833: step 649, loss 0.531987, acc 0.734375
2020-02-08T03:24:48.953431: step 650, loss 0.43892, acc 0.859375
2020-02-08T03:24:49.093264: step 651, loss 0.456964, acc 0.71875
2020-02-08T03:24:49.231120: step 652, loss 0.433376, acc 0.8125
2020-02-08T03:24:49.370337: step 653, loss 0.425471, acc 0.765625
2020-02-08T03:24:49.509166: step 654, loss 0.5088, acc 0.78125
2020-02-08T03:24:49.648349: step 655, loss 0.499922, acc 0.71875
2020-02-08T03:24:49.785387: step 656, loss 0.465446, acc 0.8125
2020-02-08T03:24:49.925552: step 657, loss 0.541918, acc 0.75
2020-02-08T03:24:50.063346: step 658, loss 0.409477, acc 0.84375
2020-02-08T03:24:50.201390: step 659, loss 0.392394, acc 0.84375
2020-02-08T03:24:50.344625: step 660, loss 0.476017, acc 0.78125
2020-02-08T03:24:50.482232: step 661, loss 0.525531, acc 0.765625
2020-02-08T03:24:50.616564: step 662, loss 0.369521, acc 0.890625
2020-02-08T03:24:50.754436: step 663, loss 0.431294, acc 0.796875
2020-02-08T03:24:50.886593: step 664, loss 0.460284, acc 0.765625
2020-02-08T03:24:51.014411: step 665, loss 0.599594, acc 0.703125
2020-02-08T03:24:51.151214: step 666, loss 0.534666, acc 0.71875
2020-02-08T03:24:51.288917: step 667, loss 0.459926, acc 0.765625
2020-02-08T03:24:51.404816: step 668, loss 0.438768, acc 0.78125
2020-02-08T03:24:51.648258: step 669, loss 0.459141, acc 0.796875
2020-02-08T03:24:51.802609: step 670, loss 0.524468, acc 0.84375
2020-02-08T03:24:51.938933: step 671, loss 0.540357, acc 0.671875
2020-02-08T03:24:52.076238: step 672, loss 0.509263, acc 0.734375
2020-02-08T03:24:52.211656: step 673, loss 0.551935, acc 0.734375
2020-02-08T03:24:52.342912: step 674, loss 0.479833, acc 0.703125
2020-02-08T03:24:52.474403: step 675, loss 0.605608, acc 0.6875
2020-02-08T03:24:52.594483: step 676, loss 0.526245, acc 0.734375
2020-02-08T03:24:52.720679: step 677, loss 0.429413, acc 0.796875
2020-02-08T03:24:52.848306: step 678, loss 0.548754, acc 0.703125
2020-02-08T03:24:52.974562: step 679, loss 0.48757, acc 0.828125
2020-02-08T03:24:53.095896: step 680, loss 0.470761, acc 0.765625
2020-02-08T03:24:53.227120: step 681, loss 0.459795, acc 0.8125
2020-02-08T03:24:53.347996: step 682, loss 0.400471, acc 0.796875
2020-02-08T03:24:53.477225: step 683, loss 0.443324, acc 0.796875
2020-02-08T03:24:53.597014: step 684, loss 0.435964, acc 0.75
2020-02-08T03:24:53.719054: step 685, loss 0.609524, acc 0.78125
2020-02-08T03:24:53.835084: step 686, loss 0.475435, acc 0.796875
2020-02-08T03:24:53.970372: step 687, loss 0.497945, acc 0.75
2020-02-08T03:24:54.088581: step 688, loss 0.619081, acc 0.671875
2020-02-08T03:24:54.209761: step 689, loss 0.420077, acc 0.8125
2020-02-08T03:24:54.330823: step 690, loss 0.527295, acc 0.703125
2020-02-08T03:24:54.452265: step 691, loss 0.423006, acc 0.828125
2020-02-08T03:24:54.573443: step 692, loss 0.602904, acc 0.734375
2020-02-08T03:24:54.690871: step 693, loss 0.457893, acc 0.78125
2020-02-08T03:24:54.810848: step 694, loss 0.477959, acc 0.765625
2020-02-08T03:24:54.929896: step 695, loss 0.471372, acc 0.765625
2020-02-08T03:24:55.047501: step 696, loss 0.534728, acc 0.6875
2020-02-08T03:24:55.165006: step 697, loss 0.420579, acc 0.828125
2020-02-08T03:24:55.282293: step 698, loss 0.452513, acc 0.78125
2020-02-08T03:24:55.399163: step 699, loss 0.470331, acc 0.796875
2020-02-08T03:24:55.519972: step 700, loss 0.534698, acc 0.734375

Evaluation:
2020-02-08T03:24:55.708251: step 700, loss 0.61343, acc 0.674484

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-700

2020-02-08T03:24:57.361379: step 701, loss 0.521678, acc 0.78125
2020-02-08T03:24:57.480447: step 702, loss 0.515198, acc 0.75
2020-02-08T03:24:57.601207: step 703, loss 0.50914, acc 0.75
2020-02-08T03:24:57.720260: step 704, loss 0.497552, acc 0.78125
2020-02-08T03:24:57.839082: step 705, loss 0.500206, acc 0.734375
2020-02-08T03:24:57.956460: step 706, loss 0.491767, acc 0.765625
2020-02-08T03:24:58.075537: step 707, loss 0.451148, acc 0.796875
2020-02-08T03:24:58.189869: step 708, loss 0.621244, acc 0.71875
2020-02-08T03:24:58.307018: step 709, loss 0.61237, acc 0.609375
2020-02-08T03:24:58.425940: step 710, loss 0.549242, acc 0.71875
2020-02-08T03:24:58.542454: step 711, loss 0.457731, acc 0.71875
2020-02-08T03:24:58.663034: step 712, loss 0.444033, acc 0.8125
2020-02-08T03:24:58.779647: step 713, loss 0.467464, acc 0.828125
2020-02-08T03:24:58.898109: step 714, loss 0.508037, acc 0.765625
2020-02-08T03:24:59.015953: step 715, loss 0.441662, acc 0.765625
2020-02-08T03:24:59.143773: step 716, loss 0.507512, acc 0.734375
2020-02-08T03:24:59.272821: step 717, loss 0.543464, acc 0.703125
2020-02-08T03:24:59.402513: step 718, loss 0.520723, acc 0.734375
2020-02-08T03:24:59.533680: step 719, loss 0.561726, acc 0.71875
2020-02-08T03:24:59.663114: step 720, loss 0.513637, acc 0.71875
2020-02-08T03:24:59.799048: step 721, loss 0.43654, acc 0.8125
2020-02-08T03:24:59.974396: step 722, loss 0.430324, acc 0.765625
2020-02-08T03:25:00.108706: step 723, loss 0.589449, acc 0.75
2020-02-08T03:25:00.224604: step 724, loss 0.446576, acc 0.765625
2020-02-08T03:25:00.344611: step 725, loss 0.543681, acc 0.734375
2020-02-08T03:25:00.464329: step 726, loss 0.466794, acc 0.78125
2020-02-08T03:25:00.584635: step 727, loss 0.46465, acc 0.78125
2020-02-08T03:25:00.707822: step 728, loss 0.497338, acc 0.75
2020-02-08T03:25:00.825440: step 729, loss 0.57621, acc 0.6875
2020-02-08T03:25:00.941137: step 730, loss 0.514852, acc 0.734375
2020-02-08T03:25:01.059687: step 731, loss 0.539749, acc 0.78125
2020-02-08T03:25:01.174711: step 732, loss 0.453931, acc 0.78125
2020-02-08T03:25:01.292747: step 733, loss 0.50616, acc 0.6875
2020-02-08T03:25:01.406786: step 734, loss 0.55759, acc 0.75
2020-02-08T03:25:01.525814: step 735, loss 0.528923, acc 0.71875
2020-02-08T03:25:01.639620: step 736, loss 0.533479, acc 0.71875
2020-02-08T03:25:01.756734: step 737, loss 0.622788, acc 0.640625
2020-02-08T03:25:01.878807: step 738, loss 0.401337, acc 0.78125
2020-02-08T03:25:01.995914: step 739, loss 0.49452, acc 0.71875
2020-02-08T03:25:02.113136: step 740, loss 0.42409, acc 0.78125
2020-02-08T03:25:02.229654: step 741, loss 0.470563, acc 0.75
2020-02-08T03:25:02.346918: step 742, loss 0.481696, acc 0.734375
2020-02-08T03:25:02.471836: step 743, loss 0.480728, acc 0.75
2020-02-08T03:25:02.589741: step 744, loss 0.498651, acc 0.75
2020-02-08T03:25:02.707842: step 745, loss 0.432943, acc 0.84375
2020-02-08T03:25:02.827247: step 746, loss 0.549926, acc 0.734375
2020-02-08T03:25:02.944068: step 747, loss 0.376152, acc 0.84375
2020-02-08T03:25:03.060156: step 748, loss 0.553922, acc 0.703125
2020-02-08T03:25:03.178881: step 749, loss 0.364029, acc 0.875
2020-02-08T03:25:03.290396: step 750, loss 0.42335, acc 0.733333
2020-02-08T03:25:03.409918: step 751, loss 0.43302, acc 0.8125
2020-02-08T03:25:03.528410: step 752, loss 0.569718, acc 0.71875
2020-02-08T03:25:03.644588: step 753, loss 0.42556, acc 0.8125
2020-02-08T03:25:03.763665: step 754, loss 0.464906, acc 0.765625
2020-02-08T03:25:03.885809: step 755, loss 0.324738, acc 0.859375
2020-02-08T03:25:04.004525: step 756, loss 0.420147, acc 0.828125
2020-02-08T03:25:04.123461: step 757, loss 0.419152, acc 0.796875
2020-02-08T03:25:04.238589: step 758, loss 0.442439, acc 0.796875
2020-02-08T03:25:04.357739: step 759, loss 0.613703, acc 0.703125
2020-02-08T03:25:04.474600: step 760, loss 0.341025, acc 0.875
2020-02-08T03:25:04.589494: step 761, loss 0.499606, acc 0.765625
2020-02-08T03:25:04.709467: step 762, loss 0.387052, acc 0.859375
2020-02-08T03:25:04.824426: step 763, loss 0.411693, acc 0.78125
2020-02-08T03:25:04.938757: step 764, loss 0.427079, acc 0.78125
2020-02-08T03:25:05.055901: step 765, loss 0.597141, acc 0.703125
2020-02-08T03:25:05.173412: step 766, loss 0.417621, acc 0.8125
2020-02-08T03:25:05.291012: step 767, loss 0.376777, acc 0.859375
2020-02-08T03:25:05.407207: step 768, loss 0.558568, acc 0.75
2020-02-08T03:25:05.523894: step 769, loss 0.282044, acc 0.859375
2020-02-08T03:25:05.641498: step 770, loss 0.459924, acc 0.796875
2020-02-08T03:25:05.758437: step 771, loss 0.386728, acc 0.859375
2020-02-08T03:25:05.878383: step 772, loss 0.367888, acc 0.859375
2020-02-08T03:25:06.001026: step 773, loss 0.495467, acc 0.734375
2020-02-08T03:25:06.118697: step 774, loss 0.412063, acc 0.875
2020-02-08T03:25:06.238649: step 775, loss 0.523534, acc 0.703125
2020-02-08T03:25:06.355527: step 776, loss 0.393359, acc 0.8125
2020-02-08T03:25:06.472938: step 777, loss 0.303091, acc 0.890625
2020-02-08T03:25:06.588405: step 778, loss 0.358403, acc 0.828125
2020-02-08T03:25:06.706070: step 779, loss 0.512448, acc 0.734375
2020-02-08T03:25:06.824340: step 780, loss 0.468404, acc 0.8125
2020-02-08T03:25:06.939250: step 781, loss 0.29005, acc 0.875
2020-02-08T03:25:07.058100: step 782, loss 0.452228, acc 0.796875
2020-02-08T03:25:07.175086: step 783, loss 0.463253, acc 0.78125
2020-02-08T03:25:07.293042: step 784, loss 0.436359, acc 0.765625
2020-02-08T03:25:07.410433: step 785, loss 0.478961, acc 0.765625
2020-02-08T03:25:07.529335: step 786, loss 0.375895, acc 0.796875
2020-02-08T03:25:07.646916: step 787, loss 0.430058, acc 0.78125
2020-02-08T03:25:07.767209: step 788, loss 0.32994, acc 0.890625
2020-02-08T03:25:07.885798: step 789, loss 0.466816, acc 0.765625
2020-02-08T03:25:08.002826: step 790, loss 0.361599, acc 0.84375
2020-02-08T03:25:08.119145: step 791, loss 0.387415, acc 0.8125
2020-02-08T03:25:08.233149: step 792, loss 0.464689, acc 0.734375
2020-02-08T03:25:08.349159: step 793, loss 0.408697, acc 0.78125
2020-02-08T03:25:08.466336: step 794, loss 0.511501, acc 0.78125
2020-02-08T03:25:08.581504: step 795, loss 0.448154, acc 0.78125
2020-02-08T03:25:08.697103: step 796, loss 0.487527, acc 0.765625
2020-02-08T03:25:08.816152: step 797, loss 0.47875, acc 0.765625
2020-02-08T03:25:08.932104: step 798, loss 0.412591, acc 0.796875
2020-02-08T03:25:09.047206: step 799, loss 0.449071, acc 0.796875
2020-02-08T03:25:09.161070: step 800, loss 0.457466, acc 0.828125

Evaluation:
2020-02-08T03:25:09.350153: step 800, loss 0.623168, acc 0.663227

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-800

2020-02-08T03:25:10.847761: step 801, loss 0.372388, acc 0.8125
2020-02-08T03:25:10.965719: step 802, loss 0.422592, acc 0.796875
2020-02-08T03:25:11.083668: step 803, loss 0.42236, acc 0.875
2020-02-08T03:25:11.201691: step 804, loss 0.368954, acc 0.8125
2020-02-08T03:25:11.321783: step 805, loss 0.556077, acc 0.71875
2020-02-08T03:25:11.439227: step 806, loss 0.413269, acc 0.765625
2020-02-08T03:25:11.558414: step 807, loss 0.450617, acc 0.8125
2020-02-08T03:25:11.673387: step 808, loss 0.485822, acc 0.78125
2020-02-08T03:25:11.788603: step 809, loss 0.374695, acc 0.859375
2020-02-08T03:25:11.909702: step 810, loss 0.480496, acc 0.78125
2020-02-08T03:25:12.028103: step 811, loss 0.385071, acc 0.84375
2020-02-08T03:25:12.145623: step 812, loss 0.360882, acc 0.859375
2020-02-08T03:25:12.262867: step 813, loss 0.390154, acc 0.796875
2020-02-08T03:25:12.379234: step 814, loss 0.386113, acc 0.875
2020-02-08T03:25:12.496350: step 815, loss 0.373125, acc 0.828125
2020-02-08T03:25:12.613985: step 816, loss 0.441972, acc 0.796875
2020-02-08T03:25:12.730220: step 817, loss 0.34346, acc 0.84375
2020-02-08T03:25:12.851705: step 818, loss 0.531101, acc 0.71875
2020-02-08T03:25:12.971673: step 819, loss 0.477135, acc 0.78125
2020-02-08T03:25:13.088380: step 820, loss 0.405328, acc 0.796875
2020-02-08T03:25:13.204806: step 821, loss 0.43779, acc 0.796875
2020-02-08T03:25:13.319850: step 822, loss 0.370845, acc 0.828125
2020-02-08T03:25:13.434697: step 823, loss 0.370701, acc 0.84375
2020-02-08T03:25:13.553189: step 824, loss 0.403921, acc 0.796875
2020-02-08T03:25:13.671646: step 825, loss 0.492384, acc 0.71875
2020-02-08T03:25:13.785934: step 826, loss 0.428382, acc 0.828125
2020-02-08T03:25:13.907472: step 827, loss 0.446483, acc 0.78125
2020-02-08T03:25:14.024748: step 828, loss 0.362556, acc 0.859375
2020-02-08T03:25:14.142177: step 829, loss 0.37302, acc 0.8125
2020-02-08T03:25:14.258375: step 830, loss 0.31381, acc 0.859375
2020-02-08T03:25:14.377953: step 831, loss 0.355251, acc 0.84375
2020-02-08T03:25:14.494701: step 832, loss 0.475466, acc 0.765625
2020-02-08T03:25:14.612079: step 833, loss 0.362607, acc 0.859375
2020-02-08T03:25:14.729098: step 834, loss 0.450629, acc 0.796875
2020-02-08T03:25:14.848557: step 835, loss 0.481679, acc 0.796875
2020-02-08T03:25:14.966530: step 836, loss 0.39997, acc 0.828125
2020-02-08T03:25:15.082269: step 837, loss 0.339726, acc 0.84375
2020-02-08T03:25:15.198027: step 838, loss 0.43609, acc 0.796875
2020-02-08T03:25:15.317431: step 839, loss 0.345721, acc 0.84375
2020-02-08T03:25:15.433102: step 840, loss 0.493511, acc 0.734375
2020-02-08T03:25:15.550696: step 841, loss 0.420233, acc 0.8125
2020-02-08T03:25:15.665503: step 842, loss 0.530969, acc 0.75
2020-02-08T03:25:15.784888: step 843, loss 0.404405, acc 0.828125
2020-02-08T03:25:15.907109: step 844, loss 0.374588, acc 0.828125
2020-02-08T03:25:16.023196: step 845, loss 0.483386, acc 0.8125
2020-02-08T03:25:16.140033: step 846, loss 0.295683, acc 0.890625
2020-02-08T03:25:16.258515: step 847, loss 0.326541, acc 0.90625
2020-02-08T03:25:16.372478: step 848, loss 0.31163, acc 0.875
2020-02-08T03:25:16.486442: step 849, loss 0.448082, acc 0.796875
2020-02-08T03:25:16.602883: step 850, loss 0.450079, acc 0.71875
2020-02-08T03:25:16.719410: step 851, loss 0.408264, acc 0.78125
2020-02-08T03:25:16.844211: step 852, loss 0.494695, acc 0.796875
2020-02-08T03:25:16.962719: step 853, loss 0.486248, acc 0.75
2020-02-08T03:25:17.075837: step 854, loss 0.515535, acc 0.78125
2020-02-08T03:25:17.192291: step 855, loss 0.397842, acc 0.8125
2020-02-08T03:25:17.312679: step 856, loss 0.51028, acc 0.734375
2020-02-08T03:25:17.428841: step 857, loss 0.406907, acc 0.8125
2020-02-08T03:25:17.545789: step 858, loss 0.525252, acc 0.734375
2020-02-08T03:25:17.663618: step 859, loss 0.417747, acc 0.828125
2020-02-08T03:25:17.778650: step 860, loss 0.246593, acc 0.921875
2020-02-08T03:25:17.900076: step 861, loss 0.498327, acc 0.8125
2020-02-08T03:25:18.019738: step 862, loss 0.423972, acc 0.8125
2020-02-08T03:25:18.134715: step 863, loss 0.642576, acc 0.703125
2020-02-08T03:25:18.251184: step 864, loss 0.662318, acc 0.734375
2020-02-08T03:25:18.368982: step 865, loss 0.432279, acc 0.734375
2020-02-08T03:25:18.483696: step 866, loss 0.458961, acc 0.75
2020-02-08T03:25:18.597843: step 867, loss 0.42627, acc 0.796875
2020-02-08T03:25:18.713886: step 868, loss 0.437241, acc 0.796875
2020-02-08T03:25:18.833798: step 869, loss 0.439115, acc 0.765625
2020-02-08T03:25:18.952744: step 870, loss 0.496431, acc 0.703125
2020-02-08T03:25:19.068937: step 871, loss 0.472161, acc 0.796875
2020-02-08T03:25:19.185794: step 872, loss 0.35143, acc 0.84375
2020-02-08T03:25:19.305225: step 873, loss 0.337039, acc 0.875
2020-02-08T03:25:19.424606: step 874, loss 0.480008, acc 0.78125
2020-02-08T03:25:19.542247: step 875, loss 0.31148, acc 0.859375
2020-02-08T03:25:19.661453: step 876, loss 0.42161, acc 0.78125
2020-02-08T03:25:19.777919: step 877, loss 0.35981, acc 0.828125
2020-02-08T03:25:19.902163: step 878, loss 0.394325, acc 0.84375
2020-02-08T03:25:20.023238: step 879, loss 0.685263, acc 0.71875
2020-02-08T03:25:20.136954: step 880, loss 0.423277, acc 0.796875
2020-02-08T03:25:20.253772: step 881, loss 0.563273, acc 0.703125
2020-02-08T03:25:20.372352: step 882, loss 0.405781, acc 0.828125
2020-02-08T03:25:20.488238: step 883, loss 0.482628, acc 0.78125
2020-02-08T03:25:20.601809: step 884, loss 0.286833, acc 0.890625
2020-02-08T03:25:20.720823: step 885, loss 0.316504, acc 0.859375
2020-02-08T03:25:20.845998: step 886, loss 0.540568, acc 0.78125
2020-02-08T03:25:20.963649: step 887, loss 0.464008, acc 0.8125
2020-02-08T03:25:21.081092: step 888, loss 0.755533, acc 0.6875
2020-02-08T03:25:21.201610: step 889, loss 0.326607, acc 0.84375
2020-02-08T03:25:21.319710: step 890, loss 0.417533, acc 0.78125
2020-02-08T03:25:21.587683: step 891, loss 0.303399, acc 0.828125
2020-02-08T03:25:21.713713: step 892, loss 0.52008, acc 0.71875
2020-02-08T03:25:21.832692: step 893, loss 0.337577, acc 0.84375
2020-02-08T03:25:21.948464: step 894, loss 0.518486, acc 0.734375
2020-02-08T03:25:22.066096: step 895, loss 0.439815, acc 0.8125
2020-02-08T03:25:22.181372: step 896, loss 0.313081, acc 0.875
2020-02-08T03:25:22.299883: step 897, loss 0.436575, acc 0.765625
2020-02-08T03:25:22.415191: step 898, loss 0.36353, acc 0.828125
2020-02-08T03:25:22.535148: step 899, loss 0.38472, acc 0.828125
2020-02-08T03:25:22.647063: step 900, loss 0.429697, acc 0.766667

Evaluation:
2020-02-08T03:25:22.844224: step 900, loss 0.608882, acc 0.686679

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-900

2020-02-08T03:25:24.378796: step 901, loss 0.33677, acc 0.890625
2020-02-08T03:25:24.499786: step 902, loss 0.332367, acc 0.828125
2020-02-08T03:25:24.618148: step 903, loss 0.287246, acc 0.875
2020-02-08T03:25:24.732339: step 904, loss 0.305028, acc 0.875
2020-02-08T03:25:24.853965: step 905, loss 0.282744, acc 0.890625
2020-02-08T03:25:24.973722: step 906, loss 0.305263, acc 0.84375
2020-02-08T03:25:25.089861: step 907, loss 0.42361, acc 0.765625
2020-02-08T03:25:25.209343: step 908, loss 0.235404, acc 0.9375
2020-02-08T03:25:25.326522: step 909, loss 0.37718, acc 0.859375
2020-02-08T03:25:25.443139: step 910, loss 0.476647, acc 0.828125
2020-02-08T03:25:25.559880: step 911, loss 0.349605, acc 0.859375
2020-02-08T03:25:25.675166: step 912, loss 0.411157, acc 0.8125
2020-02-08T03:25:25.793105: step 913, loss 0.342729, acc 0.828125
2020-02-08T03:25:25.912027: step 914, loss 0.297739, acc 0.890625
2020-02-08T03:25:26.029378: step 915, loss 0.304666, acc 0.890625
2020-02-08T03:25:26.144552: step 916, loss 0.355851, acc 0.828125
2020-02-08T03:25:26.260614: step 917, loss 0.349953, acc 0.828125
2020-02-08T03:25:26.376736: step 918, loss 0.402075, acc 0.828125
2020-02-08T03:25:26.493279: step 919, loss 0.245702, acc 0.953125
2020-02-08T03:25:26.609171: step 920, loss 0.328626, acc 0.859375
2020-02-08T03:25:26.725433: step 921, loss 0.345815, acc 0.84375
2020-02-08T03:25:26.847296: step 922, loss 0.361076, acc 0.84375
2020-02-08T03:25:26.964313: step 923, loss 0.278524, acc 0.875
2020-02-08T03:25:27.079533: step 924, loss 0.349303, acc 0.84375
2020-02-08T03:25:27.197263: step 925, loss 0.279065, acc 0.90625
2020-02-08T03:25:27.314815: step 926, loss 0.371356, acc 0.8125
2020-02-08T03:25:27.433033: step 927, loss 0.36581, acc 0.84375
2020-02-08T03:25:27.550222: step 928, loss 0.294085, acc 0.859375
2020-02-08T03:25:27.665853: step 929, loss 0.188097, acc 0.96875
2020-02-08T03:25:27.779747: step 930, loss 0.315507, acc 0.859375
2020-02-08T03:25:27.900884: step 931, loss 0.319292, acc 0.859375
2020-02-08T03:25:28.018691: step 932, loss 0.426996, acc 0.828125
2020-02-08T03:25:28.135496: step 933, loss 0.304674, acc 0.84375
2020-02-08T03:25:28.252032: step 934, loss 0.379975, acc 0.8125
2020-02-08T03:25:28.368497: step 935, loss 0.314568, acc 0.84375
2020-02-08T03:25:28.486237: step 936, loss 0.394208, acc 0.828125
2020-02-08T03:25:28.603200: step 937, loss 0.329239, acc 0.859375
2020-02-08T03:25:28.721199: step 938, loss 0.322602, acc 0.859375
2020-02-08T03:25:28.847973: step 939, loss 0.255775, acc 0.90625
2020-02-08T03:25:28.968916: step 940, loss 0.394369, acc 0.84375
2020-02-08T03:25:29.084038: step 941, loss 0.283852, acc 0.859375
2020-02-08T03:25:29.199042: step 942, loss 0.375081, acc 0.875
2020-02-08T03:25:29.315763: step 943, loss 0.258381, acc 0.921875
2020-02-08T03:25:29.433097: step 944, loss 0.355192, acc 0.84375
2020-02-08T03:25:29.549411: step 945, loss 0.333773, acc 0.859375
2020-02-08T03:25:29.666596: step 946, loss 0.296204, acc 0.84375
2020-02-08T03:25:29.783193: step 947, loss 0.322102, acc 0.875
2020-02-08T03:25:29.905003: step 948, loss 0.370447, acc 0.828125
2020-02-08T03:25:30.021696: step 949, loss 0.298227, acc 0.859375
2020-02-08T03:25:30.138245: step 950, loss 0.346924, acc 0.828125
2020-02-08T03:25:30.255841: step 951, loss 0.390976, acc 0.828125
2020-02-08T03:25:30.375698: step 952, loss 0.217033, acc 0.9375
2020-02-08T03:25:30.490481: step 953, loss 0.335621, acc 0.828125
2020-02-08T03:25:30.610873: step 954, loss 0.417675, acc 0.78125
2020-02-08T03:25:30.726995: step 955, loss 0.299765, acc 0.890625
2020-02-08T03:25:30.849779: step 956, loss 0.378774, acc 0.78125
2020-02-08T03:25:30.968250: step 957, loss 0.411027, acc 0.796875
2020-02-08T03:25:31.083957: step 958, loss 0.288679, acc 0.921875
2020-02-08T03:25:31.201440: step 959, loss 0.367873, acc 0.8125
2020-02-08T03:25:31.321376: step 960, loss 0.311788, acc 0.875
2020-02-08T03:25:31.435251: step 961, loss 0.346585, acc 0.859375
2020-02-08T03:25:31.556336: step 962, loss 0.230066, acc 0.953125
2020-02-08T03:25:31.672966: step 963, loss 0.368635, acc 0.859375
2020-02-08T03:25:31.788740: step 964, loss 0.241972, acc 0.890625
2020-02-08T03:25:31.909850: step 965, loss 0.518994, acc 0.78125
2020-02-08T03:25:32.025242: step 966, loss 0.39807, acc 0.796875
2020-02-08T03:25:32.140450: step 967, loss 0.446817, acc 0.78125
2020-02-08T03:25:32.258408: step 968, loss 0.470102, acc 0.765625
2020-02-08T03:25:32.373535: step 969, loss 0.384147, acc 0.859375
2020-02-08T03:25:32.491410: step 970, loss 0.432045, acc 0.859375
2020-02-08T03:25:32.608539: step 971, loss 0.414961, acc 0.78125
2020-02-08T03:25:32.725392: step 972, loss 0.392852, acc 0.828125
2020-02-08T03:25:32.844469: step 973, loss 0.247071, acc 0.90625
2020-02-08T03:25:32.964191: step 974, loss 0.402363, acc 0.828125
2020-02-08T03:25:33.080779: step 975, loss 0.354497, acc 0.875
2020-02-08T03:25:33.196401: step 976, loss 0.344757, acc 0.890625
2020-02-08T03:25:33.313330: step 977, loss 0.46688, acc 0.84375
2020-02-08T03:25:33.432914: step 978, loss 0.357979, acc 0.84375
2020-02-08T03:25:33.548969: step 979, loss 0.290391, acc 0.875
2020-02-08T03:25:33.668083: step 980, loss 0.388544, acc 0.859375
2020-02-08T03:25:33.782555: step 981, loss 0.346535, acc 0.8125
2020-02-08T03:25:33.903568: step 982, loss 0.377995, acc 0.8125
2020-02-08T03:25:34.023730: step 983, loss 0.350446, acc 0.859375
2020-02-08T03:25:34.137264: step 984, loss 0.310194, acc 0.875
2020-02-08T03:25:34.254621: step 985, loss 0.38412, acc 0.828125
2020-02-08T03:25:34.371166: step 986, loss 0.298509, acc 0.890625
2020-02-08T03:25:34.485999: step 987, loss 0.295401, acc 0.875
2020-02-08T03:25:34.611980: step 988, loss 0.296122, acc 0.828125
2020-02-08T03:25:34.726736: step 989, loss 0.500569, acc 0.78125
2020-02-08T03:25:34.849334: step 990, loss 0.261054, acc 0.875
2020-02-08T03:25:34.968194: step 991, loss 0.322369, acc 0.890625
2020-02-08T03:25:35.083639: step 992, loss 0.29791, acc 0.875
2020-02-08T03:25:35.200108: step 993, loss 0.322604, acc 0.875
2020-02-08T03:25:35.319522: step 994, loss 0.321958, acc 0.875
2020-02-08T03:25:35.437086: step 995, loss 0.340447, acc 0.859375
2020-02-08T03:25:35.556576: step 996, loss 0.458969, acc 0.796875
2020-02-08T03:25:35.675648: step 997, loss 0.255003, acc 0.921875
2020-02-08T03:25:35.793803: step 998, loss 0.365856, acc 0.8125
2020-02-08T03:25:35.911593: step 999, loss 0.3842, acc 0.828125
2020-02-08T03:25:36.028284: step 1000, loss 0.432627, acc 0.84375

Evaluation:
2020-02-08T03:25:36.218254: step 1000, loss 0.606653, acc 0.705441

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1000

2020-02-08T03:25:37.652939: step 1001, loss 0.241424, acc 0.890625
2020-02-08T03:25:37.770291: step 1002, loss 0.458724, acc 0.78125
2020-02-08T03:25:37.890739: step 1003, loss 0.357733, acc 0.859375
2020-02-08T03:25:38.008531: step 1004, loss 0.311303, acc 0.84375
2020-02-08T03:25:38.124036: step 1005, loss 0.459177, acc 0.796875
2020-02-08T03:25:38.238140: step 1006, loss 0.426833, acc 0.84375
2020-02-08T03:25:38.358238: step 1007, loss 0.326593, acc 0.84375
2020-02-08T03:25:38.473008: step 1008, loss 0.447166, acc 0.796875
2020-02-08T03:25:38.588222: step 1009, loss 0.441304, acc 0.765625
2020-02-08T03:25:38.706451: step 1010, loss 0.346441, acc 0.875
2020-02-08T03:25:38.826250: step 1011, loss 0.322729, acc 0.859375
2020-02-08T03:25:38.945472: step 1012, loss 0.239716, acc 0.90625
2020-02-08T03:25:39.067079: step 1013, loss 0.406198, acc 0.796875
2020-02-08T03:25:39.187767: step 1014, loss 0.293525, acc 0.875
2020-02-08T03:25:39.305561: step 1015, loss 0.416864, acc 0.765625
2020-02-08T03:25:39.422149: step 1016, loss 0.288012, acc 0.875
2020-02-08T03:25:39.542485: step 1017, loss 0.4069, acc 0.828125
2020-02-08T03:25:39.659655: step 1018, loss 0.566788, acc 0.734375
2020-02-08T03:25:39.775552: step 1019, loss 0.402747, acc 0.796875
2020-02-08T03:25:39.896867: step 1020, loss 0.336306, acc 0.859375
2020-02-08T03:25:40.014070: step 1021, loss 0.30207, acc 0.875
2020-02-08T03:25:40.130737: step 1022, loss 0.525595, acc 0.75
2020-02-08T03:25:40.245547: step 1023, loss 0.299991, acc 0.890625
2020-02-08T03:25:40.360873: step 1024, loss 0.477226, acc 0.765625
2020-02-08T03:25:40.477241: step 1025, loss 0.449259, acc 0.796875
2020-02-08T03:25:40.591453: step 1026, loss 0.383636, acc 0.859375
2020-02-08T03:25:40.707614: step 1027, loss 0.406815, acc 0.8125
2020-02-08T03:25:40.825041: step 1028, loss 0.329268, acc 0.84375
2020-02-08T03:25:40.942148: step 1029, loss 0.264379, acc 0.9375
2020-02-08T03:25:41.057802: step 1030, loss 0.281608, acc 0.90625
2020-02-08T03:25:41.177951: step 1031, loss 0.39872, acc 0.875
2020-02-08T03:25:41.293269: step 1032, loss 0.451555, acc 0.78125
2020-02-08T03:25:41.410926: step 1033, loss 0.371898, acc 0.828125
2020-02-08T03:25:41.526149: step 1034, loss 0.383351, acc 0.8125
2020-02-08T03:25:41.641508: step 1035, loss 0.298857, acc 0.859375
2020-02-08T03:25:41.759726: step 1036, loss 0.33958, acc 0.875
2020-02-08T03:25:41.880949: step 1037, loss 0.337337, acc 0.84375
2020-02-08T03:25:41.999062: step 1038, loss 0.43447, acc 0.828125
2020-02-08T03:25:42.115891: step 1039, loss 0.436838, acc 0.765625
2020-02-08T03:25:42.231121: step 1040, loss 0.34936, acc 0.859375
2020-02-08T03:25:42.348961: step 1041, loss 0.413313, acc 0.78125
2020-02-08T03:25:42.467921: step 1042, loss 0.24655, acc 0.921875
2020-02-08T03:25:42.583618: step 1043, loss 0.228983, acc 0.9375
2020-02-08T03:25:42.699794: step 1044, loss 0.392411, acc 0.828125
2020-02-08T03:25:42.819430: step 1045, loss 0.489366, acc 0.78125
2020-02-08T03:25:42.933917: step 1046, loss 0.352897, acc 0.84375
2020-02-08T03:25:43.053596: step 1047, loss 0.462195, acc 0.75
2020-02-08T03:25:43.170577: step 1048, loss 0.319025, acc 0.859375
2020-02-08T03:25:43.285316: step 1049, loss 0.315514, acc 0.859375
2020-02-08T03:25:43.401406: step 1050, loss 0.29514, acc 0.866667
2020-02-08T03:25:43.522095: step 1051, loss 0.201989, acc 0.9375
2020-02-08T03:25:43.639651: step 1052, loss 0.361453, acc 0.84375
2020-02-08T03:25:43.758796: step 1053, loss 0.263469, acc 0.875
2020-02-08T03:25:43.886778: step 1054, loss 0.332032, acc 0.859375
2020-02-08T03:25:44.008164: step 1055, loss 0.359389, acc 0.875
2020-02-08T03:25:44.124127: step 1056, loss 0.370997, acc 0.84375
2020-02-08T03:25:44.243659: step 1057, loss 0.243719, acc 0.90625
2020-02-08T03:25:44.363580: step 1058, loss 0.328266, acc 0.8125
2020-02-08T03:25:44.480130: step 1059, loss 0.1888, acc 0.921875
2020-02-08T03:25:44.597209: step 1060, loss 0.348121, acc 0.859375
2020-02-08T03:25:44.712574: step 1061, loss 0.305036, acc 0.84375
2020-02-08T03:25:44.831614: step 1062, loss 0.270672, acc 0.90625
2020-02-08T03:25:44.949485: step 1063, loss 0.267914, acc 0.875
2020-02-08T03:25:45.071526: step 1064, loss 0.312149, acc 0.8125
2020-02-08T03:25:45.187134: step 1065, loss 0.389087, acc 0.84375
2020-02-08T03:25:45.303704: step 1066, loss 0.197636, acc 0.90625
2020-02-08T03:25:45.420007: step 1067, loss 0.365077, acc 0.84375
2020-02-08T03:25:45.532796: step 1068, loss 0.261068, acc 0.921875
2020-02-08T03:25:45.649148: step 1069, loss 0.328807, acc 0.90625
2020-02-08T03:25:45.764872: step 1070, loss 0.266873, acc 0.90625
2020-02-08T03:25:45.886006: step 1071, loss 0.343364, acc 0.8125
2020-02-08T03:25:46.000945: step 1072, loss 0.260385, acc 0.890625
2020-02-08T03:25:46.118023: step 1073, loss 0.309891, acc 0.84375
2020-02-08T03:25:46.238082: step 1074, loss 0.45093, acc 0.78125
2020-02-08T03:25:46.353647: step 1075, loss 0.39152, acc 0.8125
2020-02-08T03:25:46.471434: step 1076, loss 0.413375, acc 0.75
2020-02-08T03:25:46.585026: step 1077, loss 0.375124, acc 0.8125
2020-02-08T03:25:46.699340: step 1078, loss 0.251305, acc 0.875
2020-02-08T03:25:46.816363: step 1079, loss 0.388475, acc 0.8125
2020-02-08T03:25:46.930553: step 1080, loss 0.270375, acc 0.890625
2020-02-08T03:25:47.047476: step 1081, loss 0.35005, acc 0.8125
2020-02-08T03:25:47.163827: step 1082, loss 0.301301, acc 0.875
2020-02-08T03:25:47.280519: step 1083, loss 0.311495, acc 0.890625
2020-02-08T03:25:47.398349: step 1084, loss 0.395231, acc 0.84375
2020-02-08T03:25:47.514367: step 1085, loss 0.371212, acc 0.84375
2020-02-08T03:25:47.630438: step 1086, loss 0.333946, acc 0.84375
2020-02-08T03:25:47.747797: step 1087, loss 0.314507, acc 0.890625
2020-02-08T03:25:47.870021: step 1088, loss 0.224468, acc 0.890625
2020-02-08T03:25:47.984477: step 1089, loss 0.304074, acc 0.90625
2020-02-08T03:25:48.103699: step 1090, loss 0.371383, acc 0.875
2020-02-08T03:25:48.220860: step 1091, loss 0.314848, acc 0.890625
2020-02-08T03:25:48.334011: step 1092, loss 0.288428, acc 0.875
2020-02-08T03:25:48.449024: step 1093, loss 0.238202, acc 0.859375
2020-02-08T03:25:48.565073: step 1094, loss 0.315035, acc 0.875
2020-02-08T03:25:48.680100: step 1095, loss 0.280555, acc 0.890625
2020-02-08T03:25:48.797747: step 1096, loss 0.35197, acc 0.921875
2020-02-08T03:25:48.916466: step 1097, loss 0.284497, acc 0.875
2020-02-08T03:25:49.032540: step 1098, loss 0.245009, acc 0.9375
2020-02-08T03:25:49.150886: step 1099, loss 0.176474, acc 0.9375
2020-02-08T03:25:49.266921: step 1100, loss 0.362792, acc 0.828125

Evaluation:
2020-02-08T03:25:49.453953: step 1100, loss 0.623776, acc 0.693246

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1100

2020-02-08T03:25:50.928513: step 1101, loss 0.273085, acc 0.828125
2020-02-08T03:25:51.045720: step 1102, loss 0.433563, acc 0.75
2020-02-08T03:25:51.162321: step 1103, loss 0.25697, acc 0.890625
2020-02-08T03:25:51.278587: step 1104, loss 0.339755, acc 0.859375
2020-02-08T03:25:51.641018: step 1105, loss 0.252075, acc 0.9375
2020-02-08T03:25:51.763716: step 1106, loss 0.274264, acc 0.890625
2020-02-08T03:25:51.885103: step 1107, loss 0.346579, acc 0.875
2020-02-08T03:25:52.003556: step 1108, loss 0.382296, acc 0.859375
2020-02-08T03:25:52.121578: step 1109, loss 0.424652, acc 0.765625
2020-02-08T03:25:52.239573: step 1110, loss 0.272443, acc 0.90625
2020-02-08T03:25:52.356619: step 1111, loss 0.257994, acc 0.9375
2020-02-08T03:25:52.472144: step 1112, loss 0.438368, acc 0.78125
2020-02-08T03:25:52.587813: step 1113, loss 0.345922, acc 0.8125
2020-02-08T03:25:52.707202: step 1114, loss 0.238797, acc 0.921875
2020-02-08T03:25:52.827131: step 1115, loss 0.348516, acc 0.875
2020-02-08T03:25:52.944972: step 1116, loss 0.32564, acc 0.90625
2020-02-08T03:25:53.062532: step 1117, loss 0.373599, acc 0.8125
2020-02-08T03:25:53.178410: step 1118, loss 0.40476, acc 0.8125
2020-02-08T03:25:53.290158: step 1119, loss 0.261262, acc 0.90625
2020-02-08T03:25:53.412698: step 1120, loss 0.222041, acc 0.90625
2020-02-08T03:25:53.529536: step 1121, loss 0.265375, acc 0.953125
2020-02-08T03:25:53.648419: step 1122, loss 0.306167, acc 0.84375
2020-02-08T03:25:53.764599: step 1123, loss 0.324476, acc 0.84375
2020-02-08T03:25:53.881368: step 1124, loss 0.297702, acc 0.890625
2020-02-08T03:25:53.996922: step 1125, loss 0.320318, acc 0.84375
2020-02-08T03:25:54.116065: step 1126, loss 0.266598, acc 0.875
2020-02-08T03:25:54.230986: step 1127, loss 0.28343, acc 0.90625
2020-02-08T03:25:54.345536: step 1128, loss 0.310099, acc 0.84375
2020-02-08T03:25:54.464535: step 1129, loss 0.317736, acc 0.796875
2020-02-08T03:25:54.579264: step 1130, loss 0.2413, acc 0.890625
2020-02-08T03:25:54.695937: step 1131, loss 0.265781, acc 0.890625
2020-02-08T03:25:54.815265: step 1132, loss 0.263631, acc 0.90625
2020-02-08T03:25:54.930462: step 1133, loss 0.341185, acc 0.875
2020-02-08T03:25:55.048026: step 1134, loss 0.302766, acc 0.890625
2020-02-08T03:25:55.163849: step 1135, loss 0.345575, acc 0.828125
2020-02-08T03:25:55.278741: step 1136, loss 0.298038, acc 0.875
2020-02-08T03:25:55.396732: step 1137, loss 0.279553, acc 0.90625
2020-02-08T03:25:55.515818: step 1138, loss 0.433962, acc 0.828125
2020-02-08T03:25:55.632420: step 1139, loss 0.298017, acc 0.84375
2020-02-08T03:25:55.746317: step 1140, loss 0.260229, acc 0.828125
2020-02-08T03:25:55.867114: step 1141, loss 0.274418, acc 0.890625
2020-02-08T03:25:55.981865: step 1142, loss 0.364071, acc 0.8125
2020-02-08T03:25:56.102062: step 1143, loss 0.219414, acc 0.890625
2020-02-08T03:25:56.219741: step 1144, loss 0.213292, acc 0.890625
2020-02-08T03:25:56.333731: step 1145, loss 0.213514, acc 0.90625
2020-02-08T03:25:56.449124: step 1146, loss 0.321514, acc 0.890625
2020-02-08T03:25:56.566817: step 1147, loss 0.165121, acc 0.953125
2020-02-08T03:25:56.683224: step 1148, loss 0.380571, acc 0.859375
2020-02-08T03:25:56.799153: step 1149, loss 0.16982, acc 0.96875
2020-02-08T03:25:56.918313: step 1150, loss 0.268198, acc 0.84375
2020-02-08T03:25:57.034712: step 1151, loss 0.266296, acc 0.875
2020-02-08T03:25:57.152543: step 1152, loss 0.421023, acc 0.828125
2020-02-08T03:25:57.266337: step 1153, loss 0.320796, acc 0.859375
2020-02-08T03:25:57.383264: step 1154, loss 0.282934, acc 0.890625
2020-02-08T03:25:57.502244: step 1155, loss 0.405884, acc 0.78125
2020-02-08T03:25:57.618588: step 1156, loss 0.328167, acc 0.84375
2020-02-08T03:25:57.733872: step 1157, loss 0.360314, acc 0.8125
2020-02-08T03:25:57.856378: step 1158, loss 0.236963, acc 0.875
2020-02-08T03:25:57.974167: step 1159, loss 0.342934, acc 0.890625
2020-02-08T03:25:58.090526: step 1160, loss 0.451555, acc 0.828125
2020-02-08T03:25:58.207728: step 1161, loss 0.301232, acc 0.796875
2020-02-08T03:25:58.324599: step 1162, loss 0.28019, acc 0.875
2020-02-08T03:25:58.440998: step 1163, loss 0.321795, acc 0.890625
2020-02-08T03:25:58.557810: step 1164, loss 0.38932, acc 0.828125
2020-02-08T03:25:58.673322: step 1165, loss 0.2986, acc 0.90625
2020-02-08T03:25:58.787227: step 1166, loss 0.335551, acc 0.859375
2020-02-08T03:25:58.907432: step 1167, loss 0.254761, acc 0.875
2020-02-08T03:25:59.024774: step 1168, loss 0.161788, acc 0.953125
2020-02-08T03:25:59.140460: step 1169, loss 0.187717, acc 0.953125
2020-02-08T03:25:59.258027: step 1170, loss 0.303076, acc 0.828125
2020-02-08T03:25:59.375558: step 1171, loss 0.248655, acc 0.96875
2020-02-08T03:25:59.492053: step 1172, loss 0.256555, acc 0.890625
2020-02-08T03:25:59.609002: step 1173, loss 0.312432, acc 0.875
2020-02-08T03:25:59.726044: step 1174, loss 0.283088, acc 0.890625
2020-02-08T03:25:59.843633: step 1175, loss 0.23794, acc 0.921875
2020-02-08T03:25:59.963604: step 1176, loss 0.234981, acc 0.90625
2020-02-08T03:26:00.080340: step 1177, loss 0.190781, acc 0.90625
2020-02-08T03:26:00.199586: step 1178, loss 0.248972, acc 0.875
2020-02-08T03:26:00.317093: step 1179, loss 0.284396, acc 0.859375
2020-02-08T03:26:00.431698: step 1180, loss 0.28118, acc 0.859375
2020-02-08T03:26:00.549487: step 1181, loss 0.44303, acc 0.765625
2020-02-08T03:26:00.664804: step 1182, loss 0.268815, acc 0.90625
2020-02-08T03:26:00.781224: step 1183, loss 0.245011, acc 0.890625
2020-02-08T03:26:00.901382: step 1184, loss 0.306694, acc 0.921875
2020-02-08T03:26:01.019722: step 1185, loss 0.280561, acc 0.890625
2020-02-08T03:26:01.136994: step 1186, loss 0.247369, acc 0.890625
2020-02-08T03:26:01.253101: step 1187, loss 0.310523, acc 0.859375
2020-02-08T03:26:01.371307: step 1188, loss 0.302429, acc 0.84375
2020-02-08T03:26:01.485528: step 1189, loss 0.376383, acc 0.875
2020-02-08T03:26:01.603903: step 1190, loss 0.266805, acc 0.9375
2020-02-08T03:26:01.720382: step 1191, loss 0.320624, acc 0.84375
2020-02-08T03:26:01.835932: step 1192, loss 0.391794, acc 0.828125
2020-02-08T03:26:01.953014: step 1193, loss 0.262754, acc 0.890625
2020-02-08T03:26:02.071521: step 1194, loss 0.349495, acc 0.875
2020-02-08T03:26:02.188196: step 1195, loss 0.311312, acc 0.875
2020-02-08T03:26:02.304754: step 1196, loss 0.203897, acc 0.921875
2020-02-08T03:26:02.422213: step 1197, loss 0.257284, acc 0.921875
2020-02-08T03:26:02.536684: step 1198, loss 0.330148, acc 0.875
2020-02-08T03:26:02.654436: step 1199, loss 0.264411, acc 0.890625
2020-02-08T03:26:02.765910: step 1200, loss 0.311035, acc 0.866667

Evaluation:
2020-02-08T03:26:02.960049: step 1200, loss 0.612282, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1200

2020-02-08T03:26:04.529922: step 1201, loss 0.149119, acc 0.9375
2020-02-08T03:26:04.647678: step 1202, loss 0.159311, acc 0.96875
2020-02-08T03:26:04.765990: step 1203, loss 0.195133, acc 0.9375
2020-02-08T03:26:04.885205: step 1204, loss 0.187317, acc 0.890625
2020-02-08T03:26:05.002794: step 1205, loss 0.361925, acc 0.84375
2020-02-08T03:26:05.122266: step 1206, loss 0.26498, acc 0.875
2020-02-08T03:26:05.238652: step 1207, loss 0.233198, acc 0.9375
2020-02-08T03:26:05.357328: step 1208, loss 0.274083, acc 0.90625
2020-02-08T03:26:05.473809: step 1209, loss 0.139369, acc 0.984375
2020-02-08T03:26:05.589387: step 1210, loss 0.221466, acc 0.9375
2020-02-08T03:26:05.708147: step 1211, loss 0.237826, acc 0.875
2020-02-08T03:26:05.822782: step 1212, loss 0.16755, acc 0.9375
2020-02-08T03:26:05.939894: step 1213, loss 0.168246, acc 0.953125
2020-02-08T03:26:06.057774: step 1214, loss 0.202343, acc 0.9375
2020-02-08T03:26:06.172766: step 1215, loss 0.135876, acc 0.953125
2020-02-08T03:26:06.288364: step 1216, loss 0.247382, acc 0.90625
2020-02-08T03:26:06.404282: step 1217, loss 0.188691, acc 0.9375
2020-02-08T03:26:06.522382: step 1218, loss 0.154744, acc 0.9375
2020-02-08T03:26:06.638044: step 1219, loss 0.287092, acc 0.890625
2020-02-08T03:26:06.754046: step 1220, loss 0.254563, acc 0.90625
2020-02-08T03:26:06.874067: step 1221, loss 0.263524, acc 0.859375
2020-02-08T03:26:06.993252: step 1222, loss 0.183495, acc 0.9375
2020-02-08T03:26:07.109750: step 1223, loss 0.242875, acc 0.921875
2020-02-08T03:26:07.228158: step 1224, loss 0.275421, acc 0.90625
2020-02-08T03:26:07.351179: step 1225, loss 0.20567, acc 0.921875
2020-02-08T03:26:07.466449: step 1226, loss 0.191935, acc 0.890625
2020-02-08T03:26:07.582118: step 1227, loss 0.280029, acc 0.875
2020-02-08T03:26:07.706031: step 1228, loss 0.20959, acc 0.90625
2020-02-08T03:26:07.823349: step 1229, loss 0.168929, acc 0.9375
2020-02-08T03:26:07.939897: step 1230, loss 0.118056, acc 0.96875
2020-02-08T03:26:08.058671: step 1231, loss 0.155837, acc 0.984375
2020-02-08T03:26:08.176585: step 1232, loss 0.255747, acc 0.875
2020-02-08T03:26:08.290701: step 1233, loss 0.311321, acc 0.890625
2020-02-08T03:26:08.407877: step 1234, loss 0.202863, acc 0.90625
2020-02-08T03:26:08.523736: step 1235, loss 0.107378, acc 0.953125
2020-02-08T03:26:08.638254: step 1236, loss 0.249346, acc 0.921875
2020-02-08T03:26:08.752266: step 1237, loss 0.189905, acc 0.90625
2020-02-08T03:26:08.871921: step 1238, loss 0.414997, acc 0.8125
2020-02-08T03:26:08.984097: step 1239, loss 0.310466, acc 0.875
2020-02-08T03:26:09.101689: step 1240, loss 0.310256, acc 0.859375
2020-02-08T03:26:09.219210: step 1241, loss 0.234414, acc 0.890625
2020-02-08T03:26:09.336563: step 1242, loss 0.223332, acc 0.90625
2020-02-08T03:26:09.455063: step 1243, loss 0.325998, acc 0.890625
2020-02-08T03:26:09.575633: step 1244, loss 0.238228, acc 0.890625
2020-02-08T03:26:09.690453: step 1245, loss 0.290754, acc 0.890625
2020-02-08T03:26:09.808869: step 1246, loss 0.267817, acc 0.890625
2020-02-08T03:26:09.926182: step 1247, loss 0.412511, acc 0.828125
2020-02-08T03:26:10.043580: step 1248, loss 0.295385, acc 0.859375
2020-02-08T03:26:10.161795: step 1249, loss 0.215524, acc 0.890625
2020-02-08T03:26:10.280530: step 1250, loss 0.200708, acc 0.890625
2020-02-08T03:26:10.400126: step 1251, loss 0.190105, acc 0.96875
2020-02-08T03:26:10.516986: step 1252, loss 0.151348, acc 0.96875
2020-02-08T03:26:10.635003: step 1253, loss 0.123772, acc 0.96875
2020-02-08T03:26:10.750044: step 1254, loss 0.221629, acc 0.875
2020-02-08T03:26:10.874104: step 1255, loss 0.272944, acc 0.890625
2020-02-08T03:26:10.989231: step 1256, loss 0.225083, acc 0.90625
2020-02-08T03:26:11.109503: step 1257, loss 0.195866, acc 0.921875
2020-02-08T03:26:11.228910: step 1258, loss 0.209884, acc 0.953125
2020-02-08T03:26:11.342767: step 1259, loss 0.16748, acc 0.953125
2020-02-08T03:26:11.458822: step 1260, loss 0.226566, acc 0.890625
2020-02-08T03:26:11.576926: step 1261, loss 0.122944, acc 0.96875
2020-02-08T03:26:11.694925: step 1262, loss 0.311616, acc 0.875
2020-02-08T03:26:11.814261: step 1263, loss 0.366027, acc 0.8125
2020-02-08T03:26:11.930724: step 1264, loss 0.210847, acc 0.9375
2020-02-08T03:26:12.047791: step 1265, loss 0.361313, acc 0.875
2020-02-08T03:26:12.165541: step 1266, loss 0.20771, acc 0.90625
2020-02-08T03:26:12.281656: step 1267, loss 0.218869, acc 0.9375
2020-02-08T03:26:12.398613: step 1268, loss 0.181357, acc 0.921875
2020-02-08T03:26:12.520963: step 1269, loss 0.234975, acc 0.90625
2020-02-08T03:26:12.636377: step 1270, loss 0.234718, acc 0.890625
2020-02-08T03:26:12.751045: step 1271, loss 0.178933, acc 0.953125
2020-02-08T03:26:12.872495: step 1272, loss 0.183073, acc 0.9375
2020-02-08T03:26:12.987070: step 1273, loss 0.264367, acc 0.890625
2020-02-08T03:26:13.110448: step 1274, loss 0.244794, acc 0.90625
2020-02-08T03:26:13.227141: step 1275, loss 0.225966, acc 0.90625
2020-02-08T03:26:13.346331: step 1276, loss 0.302488, acc 0.90625
2020-02-08T03:26:13.463384: step 1277, loss 0.232927, acc 0.90625
2020-02-08T03:26:13.579626: step 1278, loss 0.220725, acc 0.90625
2020-02-08T03:26:13.696713: step 1279, loss 0.223212, acc 0.953125
2020-02-08T03:26:13.818424: step 1280, loss 0.104575, acc 0.984375
2020-02-08T03:26:13.933328: step 1281, loss 0.256862, acc 0.859375
2020-02-08T03:26:14.054855: step 1282, loss 0.165772, acc 0.9375
2020-02-08T03:26:14.173250: step 1283, loss 0.251467, acc 0.890625
2020-02-08T03:26:14.287783: step 1284, loss 0.298569, acc 0.875
2020-02-08T03:26:14.401790: step 1285, loss 0.373793, acc 0.828125
2020-02-08T03:26:14.518008: step 1286, loss 0.216528, acc 0.890625
2020-02-08T03:26:14.632304: step 1287, loss 0.304499, acc 0.828125
2020-02-08T03:26:14.748093: step 1288, loss 0.316609, acc 0.875
2020-02-08T03:26:14.868735: step 1289, loss 0.181873, acc 0.9375
2020-02-08T03:26:14.983373: step 1290, loss 0.0965233, acc 0.984375
2020-02-08T03:26:15.100911: step 1291, loss 0.189657, acc 0.9375
2020-02-08T03:26:15.218655: step 1292, loss 0.248665, acc 0.890625
2020-02-08T03:26:15.334088: step 1293, loss 0.275478, acc 0.859375
2020-02-08T03:26:15.451910: step 1294, loss 0.282894, acc 0.859375
2020-02-08T03:26:15.573893: step 1295, loss 0.200117, acc 0.890625
2020-02-08T03:26:15.695700: step 1296, loss 0.155232, acc 0.953125
2020-02-08T03:26:15.817151: step 1297, loss 0.316821, acc 0.890625
2020-02-08T03:26:15.934093: step 1298, loss 0.223611, acc 0.921875
2020-02-08T03:26:16.049603: step 1299, loss 0.334317, acc 0.84375
2020-02-08T03:26:16.167534: step 1300, loss 0.238178, acc 0.875

Evaluation:
2020-02-08T03:26:16.355329: step 1300, loss 0.639784, acc 0.705441

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1300

2020-02-08T03:26:18.189909: step 1301, loss 0.174975, acc 0.921875
2020-02-08T03:26:18.308024: step 1302, loss 0.309526, acc 0.890625
2020-02-08T03:26:18.425519: step 1303, loss 0.284653, acc 0.90625
2020-02-08T03:26:18.541593: step 1304, loss 0.347793, acc 0.90625
2020-02-08T03:26:18.661671: step 1305, loss 0.338588, acc 0.859375
2020-02-08T03:26:18.777690: step 1306, loss 0.230229, acc 0.921875
2020-02-08T03:26:18.898201: step 1307, loss 0.244644, acc 0.90625
2020-02-08T03:26:19.014780: step 1308, loss 0.165197, acc 0.9375
2020-02-08T03:26:19.130239: step 1309, loss 0.25679, acc 0.921875
2020-02-08T03:26:19.245037: step 1310, loss 0.166582, acc 0.953125
2020-02-08T03:26:19.359362: step 1311, loss 0.409932, acc 0.828125
2020-02-08T03:26:19.475238: step 1312, loss 0.231898, acc 0.9375
2020-02-08T03:26:19.590629: step 1313, loss 0.246704, acc 0.890625
2020-02-08T03:26:19.707658: step 1314, loss 0.240859, acc 0.890625
2020-02-08T03:26:19.826220: step 1315, loss 0.251571, acc 0.90625
2020-02-08T03:26:19.943644: step 1316, loss 0.204412, acc 0.9375
2020-02-08T03:26:20.064494: step 1317, loss 0.22998, acc 0.921875
2020-02-08T03:26:20.180688: step 1318, loss 0.366986, acc 0.875
2020-02-08T03:26:20.306411: step 1319, loss 0.235444, acc 0.859375
2020-02-08T03:26:20.421421: step 1320, loss 0.301466, acc 0.8125
2020-02-08T03:26:20.537280: step 1321, loss 0.306286, acc 0.875
2020-02-08T03:26:20.655073: step 1322, loss 0.348442, acc 0.890625
2020-02-08T03:26:20.770649: step 1323, loss 0.215078, acc 0.953125
2020-02-08T03:26:20.888583: step 1324, loss 0.252741, acc 0.890625
2020-02-08T03:26:21.006517: step 1325, loss 0.324321, acc 0.875
2020-02-08T03:26:21.124423: step 1326, loss 0.338143, acc 0.828125
2020-02-08T03:26:21.239975: step 1327, loss 0.241387, acc 0.859375
2020-02-08T03:26:21.355245: step 1328, loss 0.153671, acc 0.96875
2020-02-08T03:26:21.471461: step 1329, loss 0.261732, acc 0.875
2020-02-08T03:26:21.702429: step 1330, loss 0.270379, acc 0.859375
2020-02-08T03:26:21.829970: step 1331, loss 0.267808, acc 0.890625
2020-02-08T03:26:21.947848: step 1332, loss 0.215884, acc 0.921875
2020-02-08T03:26:22.064729: step 1333, loss 0.150746, acc 0.9375
2020-02-08T03:26:22.180210: step 1334, loss 0.235635, acc 0.90625
2020-02-08T03:26:22.294980: step 1335, loss 0.246793, acc 0.875
2020-02-08T03:26:22.412018: step 1336, loss 0.263168, acc 0.90625
2020-02-08T03:26:22.528024: step 1337, loss 0.13478, acc 0.984375
2020-02-08T03:26:22.644445: step 1338, loss 0.232083, acc 0.921875
2020-02-08T03:26:22.761844: step 1339, loss 0.280247, acc 0.875
2020-02-08T03:26:22.880795: step 1340, loss 0.280271, acc 0.90625
2020-02-08T03:26:23.001610: step 1341, loss 0.234558, acc 0.921875
2020-02-08T03:26:23.118565: step 1342, loss 0.330966, acc 0.875
2020-02-08T03:26:23.236181: step 1343, loss 0.248826, acc 0.890625
2020-02-08T03:26:23.353674: step 1344, loss 0.180755, acc 0.9375
2020-02-08T03:26:23.470193: step 1345, loss 0.229528, acc 0.890625
2020-02-08T03:26:23.586919: step 1346, loss 0.196738, acc 0.9375
2020-02-08T03:26:23.706171: step 1347, loss 0.277783, acc 0.890625
2020-02-08T03:26:23.825858: step 1348, loss 0.286532, acc 0.890625
2020-02-08T03:26:23.939852: step 1349, loss 0.224677, acc 0.890625
2020-02-08T03:26:24.050934: step 1350, loss 0.21909, acc 0.9
2020-02-08T03:26:24.169946: step 1351, loss 0.290044, acc 0.859375
2020-02-08T03:26:24.286508: step 1352, loss 0.186131, acc 0.890625
2020-02-08T03:26:24.405632: step 1353, loss 0.244283, acc 0.921875
2020-02-08T03:26:24.523597: step 1354, loss 0.240214, acc 0.875
2020-02-08T03:26:24.637424: step 1355, loss 0.208228, acc 0.921875
2020-02-08T03:26:24.754972: step 1356, loss 0.214161, acc 0.890625
2020-02-08T03:26:24.875491: step 1357, loss 0.168943, acc 0.953125
2020-02-08T03:26:24.992920: step 1358, loss 0.246577, acc 0.859375
2020-02-08T03:26:25.114366: step 1359, loss 0.172945, acc 0.9375
2020-02-08T03:26:25.229426: step 1360, loss 0.155232, acc 0.90625
2020-02-08T03:26:25.347922: step 1361, loss 0.232296, acc 0.921875
2020-02-08T03:26:25.464424: step 1362, loss 0.356528, acc 0.8125
2020-02-08T03:26:25.580398: step 1363, loss 0.187012, acc 0.9375
2020-02-08T03:26:25.696656: step 1364, loss 0.284147, acc 0.921875
2020-02-08T03:26:25.811289: step 1365, loss 0.199139, acc 0.953125
2020-02-08T03:26:25.928299: step 1366, loss 0.165329, acc 0.921875
2020-02-08T03:26:26.045043: step 1367, loss 0.108206, acc 0.953125
2020-02-08T03:26:26.161756: step 1368, loss 0.204075, acc 0.921875
2020-02-08T03:26:26.278633: step 1369, loss 0.221373, acc 0.921875
2020-02-08T03:26:26.396094: step 1370, loss 0.103597, acc 0.953125
2020-02-08T03:26:26.516420: step 1371, loss 0.227274, acc 0.90625
2020-02-08T03:26:26.631282: step 1372, loss 0.118833, acc 0.953125
2020-02-08T03:26:26.746656: step 1373, loss 0.208528, acc 0.9375
2020-02-08T03:26:26.868549: step 1374, loss 0.164048, acc 0.9375
2020-02-08T03:26:26.985123: step 1375, loss 0.175081, acc 0.953125
2020-02-08T03:26:27.099975: step 1376, loss 0.369936, acc 0.859375
2020-02-08T03:26:27.215700: step 1377, loss 0.193768, acc 0.9375
2020-02-08T03:26:27.329336: step 1378, loss 0.154948, acc 0.953125
2020-02-08T03:26:27.445395: step 1379, loss 0.126428, acc 0.9375
2020-02-08T03:26:27.563314: step 1380, loss 0.0977997, acc 0.984375
2020-02-08T03:26:27.680263: step 1381, loss 0.120667, acc 0.953125
2020-02-08T03:26:27.802478: step 1382, loss 0.113474, acc 0.96875
2020-02-08T03:26:27.919946: step 1383, loss 0.24019, acc 0.90625
2020-02-08T03:26:28.035909: step 1384, loss 0.230334, acc 0.90625
2020-02-08T03:26:28.155307: step 1385, loss 0.209976, acc 0.859375
2020-02-08T03:26:28.272063: step 1386, loss 0.244492, acc 0.90625
2020-02-08T03:26:28.386941: step 1387, loss 0.177186, acc 0.890625
2020-02-08T03:26:28.503362: step 1388, loss 0.179742, acc 0.9375
2020-02-08T03:26:28.620405: step 1389, loss 0.125772, acc 0.96875
2020-02-08T03:26:28.736665: step 1390, loss 0.161474, acc 0.953125
2020-02-08T03:26:28.858782: step 1391, loss 0.217214, acc 0.890625
2020-02-08T03:26:28.975969: step 1392, loss 0.203446, acc 0.921875
2020-02-08T03:26:29.089707: step 1393, loss 0.158472, acc 0.953125
2020-02-08T03:26:29.208144: step 1394, loss 0.135992, acc 0.953125
2020-02-08T03:26:29.325133: step 1395, loss 0.21155, acc 0.890625
2020-02-08T03:26:29.440831: step 1396, loss 0.12926, acc 0.96875
2020-02-08T03:26:29.560555: step 1397, loss 0.175986, acc 0.953125
2020-02-08T03:26:29.678281: step 1398, loss 0.192302, acc 0.9375
2020-02-08T03:26:29.799907: step 1399, loss 0.328225, acc 0.875
2020-02-08T03:26:29.919938: step 1400, loss 0.329329, acc 0.875

Evaluation:
2020-02-08T03:26:30.109707: step 1400, loss 0.658413, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1400

2020-02-08T03:26:31.621495: step 1401, loss 0.177346, acc 0.96875
2020-02-08T03:26:31.739098: step 1402, loss 0.331609, acc 0.828125
2020-02-08T03:26:31.863151: step 1403, loss 0.191271, acc 0.9375
2020-02-08T03:26:31.980630: step 1404, loss 0.181244, acc 0.921875
2020-02-08T03:26:32.097896: step 1405, loss 0.185415, acc 0.9375
2020-02-08T03:26:32.219142: step 1406, loss 0.242123, acc 0.890625
2020-02-08T03:26:32.333314: step 1407, loss 0.162237, acc 0.953125
2020-02-08T03:26:32.446775: step 1408, loss 0.167849, acc 0.9375
2020-02-08T03:26:32.563392: step 1409, loss 0.155462, acc 0.921875
2020-02-08T03:26:32.680721: step 1410, loss 0.180534, acc 0.921875
2020-02-08T03:26:32.799042: step 1411, loss 0.139109, acc 0.953125
2020-02-08T03:26:32.917377: step 1412, loss 0.225412, acc 0.875
2020-02-08T03:26:33.036470: step 1413, loss 0.305397, acc 0.859375
2020-02-08T03:26:33.154100: step 1414, loss 0.14389, acc 0.96875
2020-02-08T03:26:33.274296: step 1415, loss 0.158531, acc 0.953125
2020-02-08T03:26:33.394064: step 1416, loss 0.136569, acc 0.96875
2020-02-08T03:26:33.511258: step 1417, loss 0.252542, acc 0.90625
2020-02-08T03:26:33.626349: step 1418, loss 0.206482, acc 0.921875
2020-02-08T03:26:33.743054: step 1419, loss 0.155705, acc 0.9375
2020-02-08T03:26:33.863081: step 1420, loss 0.14337, acc 0.953125
2020-02-08T03:26:33.979722: step 1421, loss 0.1528, acc 0.921875
2020-02-08T03:26:34.100549: step 1422, loss 0.214875, acc 0.875
2020-02-08T03:26:34.217688: step 1423, loss 0.162299, acc 0.96875
2020-02-08T03:26:34.334835: step 1424, loss 0.15666, acc 0.9375
2020-02-08T03:26:34.453546: step 1425, loss 0.262206, acc 0.875
2020-02-08T03:26:34.572035: step 1426, loss 0.173099, acc 0.9375
2020-02-08T03:26:34.685950: step 1427, loss 0.165052, acc 0.921875
2020-02-08T03:26:34.804664: step 1428, loss 0.0938703, acc 0.96875
2020-02-08T03:26:34.924290: step 1429, loss 0.167124, acc 0.96875
2020-02-08T03:26:35.040165: step 1430, loss 0.138759, acc 0.96875
2020-02-08T03:26:35.157007: step 1431, loss 0.111058, acc 0.953125
2020-02-08T03:26:35.273107: step 1432, loss 0.169989, acc 0.96875
2020-02-08T03:26:35.390398: step 1433, loss 0.0753544, acc 0.984375
2020-02-08T03:26:35.507996: step 1434, loss 0.166626, acc 0.9375
2020-02-08T03:26:35.625664: step 1435, loss 0.151195, acc 0.9375
2020-02-08T03:26:35.746554: step 1436, loss 0.219586, acc 0.9375
2020-02-08T03:26:35.867235: step 1437, loss 0.233818, acc 0.890625
2020-02-08T03:26:35.982373: step 1438, loss 0.173831, acc 0.921875
2020-02-08T03:26:36.100517: step 1439, loss 0.187331, acc 0.921875
2020-02-08T03:26:36.219041: step 1440, loss 0.162933, acc 0.953125
2020-02-08T03:26:36.335274: step 1441, loss 0.274263, acc 0.875
2020-02-08T03:26:36.452065: step 1442, loss 0.183947, acc 0.921875
2020-02-08T03:26:36.568597: step 1443, loss 0.124896, acc 0.953125
2020-02-08T03:26:36.685004: step 1444, loss 0.233884, acc 0.90625
2020-02-08T03:26:36.804006: step 1445, loss 0.157565, acc 0.921875
2020-02-08T03:26:36.919089: step 1446, loss 0.173419, acc 0.96875
2020-02-08T03:26:37.037777: step 1447, loss 0.182885, acc 0.90625
2020-02-08T03:26:37.154845: step 1448, loss 0.169379, acc 0.953125
2020-02-08T03:26:37.274543: step 1449, loss 0.159623, acc 0.921875
2020-02-08T03:26:37.392797: step 1450, loss 0.160808, acc 0.9375
2020-02-08T03:26:37.508877: step 1451, loss 0.286375, acc 0.859375
2020-02-08T03:26:37.624538: step 1452, loss 0.0829155, acc 0.96875
2020-02-08T03:26:37.739958: step 1453, loss 0.2456, acc 0.890625
2020-02-08T03:26:37.862567: step 1454, loss 0.204891, acc 0.96875
2020-02-08T03:26:37.983202: step 1455, loss 0.164914, acc 0.90625
2020-02-08T03:26:38.099362: step 1456, loss 0.119086, acc 0.96875
2020-02-08T03:26:38.216820: step 1457, loss 0.0878673, acc 0.953125
2020-02-08T03:26:38.335027: step 1458, loss 0.163934, acc 0.9375
2020-02-08T03:26:38.451230: step 1459, loss 0.140109, acc 0.953125
2020-02-08T03:26:38.567267: step 1460, loss 0.206446, acc 0.921875
2020-02-08T03:26:38.683474: step 1461, loss 0.275021, acc 0.921875
2020-02-08T03:26:38.802528: step 1462, loss 0.105814, acc 0.984375
2020-02-08T03:26:38.918280: step 1463, loss 0.14404, acc 0.96875
2020-02-08T03:26:39.036000: step 1464, loss 0.218203, acc 0.90625
2020-02-08T03:26:39.154762: step 1465, loss 0.307551, acc 0.828125
2020-02-08T03:26:39.271684: step 1466, loss 0.18775, acc 0.90625
2020-02-08T03:26:39.388824: step 1467, loss 0.174985, acc 0.96875
2020-02-08T03:26:39.507200: step 1468, loss 0.155393, acc 0.9375
2020-02-08T03:26:39.625744: step 1469, loss 0.171311, acc 0.921875
2020-02-08T03:26:39.746861: step 1470, loss 0.108274, acc 0.953125
2020-02-08T03:26:39.870060: step 1471, loss 0.243662, acc 0.90625
2020-02-08T03:26:39.987346: step 1472, loss 0.232058, acc 0.890625
2020-02-08T03:26:40.105546: step 1473, loss 0.182727, acc 0.9375
2020-02-08T03:26:40.224105: step 1474, loss 0.232308, acc 0.90625
2020-02-08T03:26:40.340527: step 1475, loss 0.330696, acc 0.890625
2020-02-08T03:26:40.458314: step 1476, loss 0.185144, acc 0.90625
2020-02-08T03:26:40.573913: step 1477, loss 0.125684, acc 0.953125
2020-02-08T03:26:40.691061: step 1478, loss 0.171625, acc 0.890625
2020-02-08T03:26:40.809067: step 1479, loss 0.190976, acc 0.9375
2020-02-08T03:26:40.926876: step 1480, loss 0.222511, acc 0.90625
2020-02-08T03:26:41.047499: step 1481, loss 0.194964, acc 0.953125
2020-02-08T03:26:41.162486: step 1482, loss 0.133733, acc 0.953125
2020-02-08T03:26:41.278255: step 1483, loss 0.19291, acc 0.953125
2020-02-08T03:26:41.396589: step 1484, loss 0.171266, acc 0.921875
2020-02-08T03:26:41.513464: step 1485, loss 0.17442, acc 0.9375
2020-02-08T03:26:41.629850: step 1486, loss 0.107592, acc 0.984375
2020-02-08T03:26:41.746998: step 1487, loss 0.312565, acc 0.859375
2020-02-08T03:26:41.867959: step 1488, loss 0.193666, acc 0.921875
2020-02-08T03:26:41.985012: step 1489, loss 0.171708, acc 0.9375
2020-02-08T03:26:42.106936: step 1490, loss 0.140957, acc 0.953125
2020-02-08T03:26:42.227415: step 1491, loss 0.143725, acc 0.9375
2020-02-08T03:26:42.344128: step 1492, loss 0.359022, acc 0.828125
2020-02-08T03:26:42.458279: step 1493, loss 0.195889, acc 0.90625
2020-02-08T03:26:42.576290: step 1494, loss 0.176201, acc 0.921875
2020-02-08T03:26:42.693196: step 1495, loss 0.170075, acc 0.953125
2020-02-08T03:26:42.810067: step 1496, loss 0.127757, acc 0.953125
2020-02-08T03:26:42.926430: step 1497, loss 0.290082, acc 0.84375
2020-02-08T03:26:43.048240: step 1498, loss 0.219768, acc 0.921875
2020-02-08T03:26:43.166742: step 1499, loss 0.196496, acc 0.90625
2020-02-08T03:26:43.279386: step 1500, loss 0.167981, acc 0.916667

Evaluation:
2020-02-08T03:26:43.469867: step 1500, loss 0.690107, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1500

2020-02-08T03:26:44.979413: step 1501, loss 0.0999022, acc 0.96875
2020-02-08T03:26:45.098534: step 1502, loss 0.090846, acc 0.96875
2020-02-08T03:26:45.217431: step 1503, loss 0.0769138, acc 0.96875
2020-02-08T03:26:45.333302: step 1504, loss 0.126961, acc 0.984375
2020-02-08T03:26:45.451031: step 1505, loss 0.207392, acc 0.90625
2020-02-08T03:26:45.572367: step 1506, loss 0.122653, acc 0.953125
2020-02-08T03:26:45.685318: step 1507, loss 0.109436, acc 0.953125
2020-02-08T03:26:45.803457: step 1508, loss 0.128451, acc 0.96875
2020-02-08T03:26:45.921530: step 1509, loss 0.115817, acc 0.96875
2020-02-08T03:26:46.036774: step 1510, loss 0.146096, acc 0.953125
2020-02-08T03:26:46.152102: step 1511, loss 0.0880288, acc 0.984375
2020-02-08T03:26:46.270934: step 1512, loss 0.147426, acc 0.9375
2020-02-08T03:26:46.386424: step 1513, loss 0.109558, acc 0.984375
2020-02-08T03:26:46.504038: step 1514, loss 0.137941, acc 0.921875
2020-02-08T03:26:46.621449: step 1515, loss 0.0696659, acc 0.96875
2020-02-08T03:26:46.736969: step 1516, loss 0.112564, acc 0.953125
2020-02-08T03:26:46.858464: step 1517, loss 0.132022, acc 0.96875
2020-02-08T03:26:46.975079: step 1518, loss 0.101065, acc 0.96875
2020-02-08T03:26:47.095727: step 1519, loss 0.134973, acc 0.953125
2020-02-08T03:26:47.212691: step 1520, loss 0.113725, acc 0.96875
2020-02-08T03:26:47.329561: step 1521, loss 0.0853556, acc 0.96875
2020-02-08T03:26:47.449470: step 1522, loss 0.0882623, acc 0.984375
2020-02-08T03:26:47.566418: step 1523, loss 0.261087, acc 0.90625
2020-02-08T03:26:47.681083: step 1524, loss 0.214573, acc 0.890625
2020-02-08T03:26:47.796892: step 1525, loss 0.142337, acc 0.96875
2020-02-08T03:26:47.917203: step 1526, loss 0.0792521, acc 0.984375
2020-02-08T03:26:48.033563: step 1527, loss 0.129601, acc 0.953125
2020-02-08T03:26:48.152009: step 1528, loss 0.1831, acc 0.9375
2020-02-08T03:26:48.268964: step 1529, loss 0.0824615, acc 0.984375
2020-02-08T03:26:48.388557: step 1530, loss 0.159909, acc 0.90625
2020-02-08T03:26:48.506325: step 1531, loss 0.134364, acc 0.953125
2020-02-08T03:26:48.623991: step 1532, loss 0.12399, acc 0.953125
2020-02-08T03:26:48.740465: step 1533, loss 0.188823, acc 0.9375
2020-02-08T03:26:48.864825: step 1534, loss 0.168305, acc 0.9375
2020-02-08T03:26:48.984966: step 1535, loss 0.134641, acc 0.9375
2020-02-08T03:26:49.101389: step 1536, loss 0.0983644, acc 0.953125
2020-02-08T03:26:49.219022: step 1537, loss 0.202787, acc 0.9375
2020-02-08T03:26:49.334954: step 1538, loss 0.14752, acc 0.953125
2020-02-08T03:26:49.451166: step 1539, loss 0.0981996, acc 0.984375
2020-02-08T03:26:49.567020: step 1540, loss 0.140881, acc 0.953125
2020-02-08T03:26:49.683229: step 1541, loss 0.192762, acc 0.921875
2020-02-08T03:26:49.800311: step 1542, loss 0.117686, acc 0.921875
2020-02-08T03:26:49.919466: step 1543, loss 0.127858, acc 0.96875
2020-02-08T03:26:50.035201: step 1544, loss 0.115586, acc 0.953125
2020-02-08T03:26:50.152650: step 1545, loss 0.206357, acc 0.921875
2020-02-08T03:26:50.267230: step 1546, loss 0.157901, acc 0.921875
2020-02-08T03:26:50.387512: step 1547, loss 0.233198, acc 0.90625
2020-02-08T03:26:50.507757: step 1548, loss 0.137356, acc 0.953125
2020-02-08T03:26:50.626156: step 1549, loss 0.111359, acc 0.953125
2020-02-08T03:26:50.741431: step 1550, loss 0.128191, acc 0.9375
2020-02-08T03:26:50.866395: step 1551, loss 0.124903, acc 0.96875
2020-02-08T03:26:50.983266: step 1552, loss 0.128202, acc 0.953125
2020-02-08T03:26:51.105246: step 1553, loss 0.250703, acc 0.890625
2020-02-08T03:26:51.220354: step 1554, loss 0.0738874, acc 1
2020-02-08T03:26:51.333364: step 1555, loss 0.14064, acc 0.953125
2020-02-08T03:26:51.542414: step 1556, loss 0.117782, acc 0.96875
2020-02-08T03:26:51.666828: step 1557, loss 0.137896, acc 0.921875
2020-02-08T03:26:51.781384: step 1558, loss 0.140195, acc 0.953125
2020-02-08T03:26:51.902128: step 1559, loss 0.0870952, acc 0.984375
2020-02-08T03:26:52.020729: step 1560, loss 0.131341, acc 0.921875
2020-02-08T03:26:52.137370: step 1561, loss 0.0639042, acc 1
2020-02-08T03:26:52.256909: step 1562, loss 0.0762896, acc 0.984375
2020-02-08T03:26:52.375477: step 1563, loss 0.163973, acc 0.921875
2020-02-08T03:26:52.492285: step 1564, loss 0.0959241, acc 0.953125
2020-02-08T03:26:52.611796: step 1565, loss 0.143711, acc 0.9375
2020-02-08T03:26:52.731683: step 1566, loss 0.125884, acc 0.953125
2020-02-08T03:26:52.851052: step 1567, loss 0.0735363, acc 0.984375
2020-02-08T03:26:52.967147: step 1568, loss 0.0847858, acc 0.984375
2020-02-08T03:26:53.083360: step 1569, loss 0.162029, acc 0.921875
2020-02-08T03:26:53.199183: step 1570, loss 0.221975, acc 0.9375
2020-02-08T03:26:53.316919: step 1571, loss 0.111015, acc 0.953125
2020-02-08T03:26:53.432227: step 1572, loss 0.20395, acc 0.921875
2020-02-08T03:26:53.552232: step 1573, loss 0.175916, acc 0.921875
2020-02-08T03:26:53.671252: step 1574, loss 0.130504, acc 0.953125
2020-02-08T03:26:53.788056: step 1575, loss 0.136571, acc 0.9375
2020-02-08T03:26:53.912198: step 1576, loss 0.15917, acc 0.96875
2020-02-08T03:26:54.028369: step 1577, loss 0.170453, acc 0.953125
2020-02-08T03:26:54.145902: step 1578, loss 0.201057, acc 0.90625
2020-02-08T03:26:54.262969: step 1579, loss 0.118553, acc 0.953125
2020-02-08T03:26:54.377066: step 1580, loss 0.213313, acc 0.921875
2020-02-08T03:26:54.491751: step 1581, loss 0.134414, acc 0.921875
2020-02-08T03:26:54.605829: step 1582, loss 0.0811824, acc 0.96875
2020-02-08T03:26:54.720618: step 1583, loss 0.234141, acc 0.890625
2020-02-08T03:26:54.838192: step 1584, loss 0.0801682, acc 1
2020-02-08T03:26:54.956255: step 1585, loss 0.161874, acc 0.921875
2020-02-08T03:26:55.071264: step 1586, loss 0.116102, acc 0.984375
2020-02-08T03:26:55.185759: step 1587, loss 0.101215, acc 0.96875
2020-02-08T03:26:55.302664: step 1588, loss 0.112976, acc 0.953125
2020-02-08T03:26:55.419232: step 1589, loss 0.166551, acc 0.921875
2020-02-08T03:26:55.537677: step 1590, loss 0.125407, acc 0.984375
2020-02-08T03:26:55.655190: step 1591, loss 0.141056, acc 0.9375
2020-02-08T03:26:55.772569: step 1592, loss 0.16947, acc 0.9375
2020-02-08T03:26:55.893777: step 1593, loss 0.219886, acc 0.90625
2020-02-08T03:26:56.011139: step 1594, loss 0.123898, acc 0.96875
2020-02-08T03:26:56.131731: step 1595, loss 0.127422, acc 0.9375
2020-02-08T03:26:56.248272: step 1596, loss 0.111149, acc 0.953125
2020-02-08T03:26:56.363807: step 1597, loss 0.170415, acc 0.890625
2020-02-08T03:26:56.479626: step 1598, loss 0.145065, acc 0.921875
2020-02-08T03:26:56.597543: step 1599, loss 0.114434, acc 0.953125
2020-02-08T03:26:56.710212: step 1600, loss 0.141183, acc 0.9375

Evaluation:
2020-02-08T03:26:56.906800: step 1600, loss 0.696733, acc 0.712946

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1600

2020-02-08T03:26:58.400372: step 1601, loss 0.223399, acc 0.859375
2020-02-08T03:26:58.515043: step 1602, loss 0.109389, acc 0.921875
2020-02-08T03:26:58.633409: step 1603, loss 0.0855859, acc 0.953125
2020-02-08T03:26:58.750172: step 1604, loss 0.224882, acc 0.921875
2020-02-08T03:26:58.876760: step 1605, loss 0.10653, acc 0.953125
2020-02-08T03:26:58.992043: step 1606, loss 0.146102, acc 0.921875
2020-02-08T03:26:59.109435: step 1607, loss 0.0773524, acc 0.984375
2020-02-08T03:26:59.226031: step 1608, loss 0.137527, acc 0.9375
2020-02-08T03:26:59.341411: step 1609, loss 0.107985, acc 0.953125
2020-02-08T03:26:59.457563: step 1610, loss 0.172629, acc 0.9375
2020-02-08T03:26:59.575623: step 1611, loss 0.197735, acc 0.890625
2020-02-08T03:26:59.691727: step 1612, loss 0.258071, acc 0.875
2020-02-08T03:26:59.808477: step 1613, loss 0.227505, acc 0.953125
2020-02-08T03:26:59.924570: step 1614, loss 0.253713, acc 0.921875
2020-02-08T03:27:00.037695: step 1615, loss 0.122825, acc 0.953125
2020-02-08T03:27:00.152501: step 1616, loss 0.120438, acc 0.9375
2020-02-08T03:27:00.271500: step 1617, loss 0.15342, acc 0.921875
2020-02-08T03:27:00.387509: step 1618, loss 0.227557, acc 0.90625
2020-02-08T03:27:00.504853: step 1619, loss 0.12866, acc 0.9375
2020-02-08T03:27:00.622416: step 1620, loss 0.146326, acc 0.953125
2020-02-08T03:27:00.737649: step 1621, loss 0.202729, acc 0.890625
2020-02-08T03:27:00.857911: step 1622, loss 0.12022, acc 0.9375
2020-02-08T03:27:00.975479: step 1623, loss 0.0766875, acc 0.984375
2020-02-08T03:27:01.093400: step 1624, loss 0.192167, acc 0.921875
2020-02-08T03:27:01.211018: step 1625, loss 0.0885566, acc 0.984375
2020-02-08T03:27:01.327393: step 1626, loss 0.145669, acc 0.890625
2020-02-08T03:27:01.443685: step 1627, loss 0.143977, acc 0.921875
2020-02-08T03:27:01.563461: step 1628, loss 0.208226, acc 0.875
2020-02-08T03:27:01.679957: step 1629, loss 0.140288, acc 0.9375
2020-02-08T03:27:01.803332: step 1630, loss 0.0966658, acc 0.984375
2020-02-08T03:27:01.920166: step 1631, loss 0.160996, acc 0.921875
2020-02-08T03:27:02.036913: step 1632, loss 0.261209, acc 0.859375
2020-02-08T03:27:02.155430: step 1633, loss 0.0984986, acc 0.953125
2020-02-08T03:27:02.273335: step 1634, loss 0.202983, acc 0.890625
2020-02-08T03:27:02.394583: step 1635, loss 0.164491, acc 0.921875
2020-02-08T03:27:02.509056: step 1636, loss 0.178946, acc 0.921875
2020-02-08T03:27:02.625385: step 1637, loss 0.166753, acc 0.9375
2020-02-08T03:27:02.741664: step 1638, loss 0.0620848, acc 0.984375
2020-02-08T03:27:02.863205: step 1639, loss 0.153555, acc 0.9375
2020-02-08T03:27:02.981037: step 1640, loss 0.144846, acc 0.953125
2020-02-08T03:27:03.097562: step 1641, loss 0.124376, acc 0.96875
2020-02-08T03:27:03.216225: step 1642, loss 0.143218, acc 0.953125
2020-02-08T03:27:03.334452: step 1643, loss 0.0433191, acc 1
2020-02-08T03:27:03.447935: step 1644, loss 0.194538, acc 0.875
2020-02-08T03:27:03.568220: step 1645, loss 0.159017, acc 0.9375
2020-02-08T03:27:03.683978: step 1646, loss 0.0897, acc 0.96875
2020-02-08T03:27:03.810600: step 1647, loss 0.0513388, acc 0.984375
2020-02-08T03:27:03.926531: step 1648, loss 0.106731, acc 0.96875
2020-02-08T03:27:04.044950: step 1649, loss 0.088321, acc 0.96875
2020-02-08T03:27:04.159220: step 1650, loss 0.0646562, acc 0.966667
2020-02-08T03:27:04.281280: step 1651, loss 0.103703, acc 0.953125
2020-02-08T03:27:04.396630: step 1652, loss 0.096362, acc 0.953125
2020-02-08T03:27:04.513504: step 1653, loss 0.0768663, acc 0.984375
2020-02-08T03:27:04.632072: step 1654, loss 0.104515, acc 0.9375
2020-02-08T03:27:04.747014: step 1655, loss 0.166948, acc 0.953125
2020-02-08T03:27:04.870188: step 1656, loss 0.0932202, acc 0.984375
2020-02-08T03:27:04.986733: step 1657, loss 0.121558, acc 0.96875
2020-02-08T03:27:05.104566: step 1658, loss 0.150732, acc 0.9375
2020-02-08T03:27:05.222604: step 1659, loss 0.0848329, acc 0.96875
2020-02-08T03:27:05.338011: step 1660, loss 0.09699, acc 0.96875
2020-02-08T03:27:05.455210: step 1661, loss 0.0958309, acc 0.96875
2020-02-08T03:27:05.572581: step 1662, loss 0.103309, acc 0.96875
2020-02-08T03:27:05.686630: step 1663, loss 0.0693556, acc 0.96875
2020-02-08T03:27:05.804074: step 1664, loss 0.0546583, acc 0.984375
2020-02-08T03:27:05.925203: step 1665, loss 0.107172, acc 0.9375
2020-02-08T03:27:06.041249: step 1666, loss 0.0915735, acc 0.953125
2020-02-08T03:27:06.163223: step 1667, loss 0.117091, acc 0.953125
2020-02-08T03:27:06.284602: step 1668, loss 0.0975091, acc 0.96875
2020-02-08T03:27:06.410317: step 1669, loss 0.0882159, acc 0.953125
2020-02-08T03:27:06.525254: step 1670, loss 0.199068, acc 0.90625
2020-02-08T03:27:06.641987: step 1671, loss 0.133638, acc 0.953125
2020-02-08T03:27:06.758704: step 1672, loss 0.0596472, acc 1
2020-02-08T03:27:06.881319: step 1673, loss 0.189452, acc 0.9375
2020-02-08T03:27:06.998765: step 1674, loss 0.123847, acc 0.984375
2020-02-08T03:27:07.117782: step 1675, loss 0.0665482, acc 0.96875
2020-02-08T03:27:07.238648: step 1676, loss 0.0347299, acc 0.984375
2020-02-08T03:27:07.356494: step 1677, loss 0.108316, acc 0.953125
2020-02-08T03:27:07.471789: step 1678, loss 0.0666833, acc 0.96875
2020-02-08T03:27:07.588891: step 1679, loss 0.0743392, acc 0.984375
2020-02-08T03:27:07.704513: step 1680, loss 0.0821837, acc 0.96875
2020-02-08T03:27:07.822475: step 1681, loss 0.0393037, acc 1
2020-02-08T03:27:07.938563: step 1682, loss 0.197747, acc 0.9375
2020-02-08T03:27:08.053820: step 1683, loss 0.0405737, acc 0.984375
2020-02-08T03:27:08.170484: step 1684, loss 0.0898394, acc 0.984375
2020-02-08T03:27:08.288704: step 1685, loss 0.170717, acc 0.953125
2020-02-08T03:27:08.407228: step 1686, loss 0.204138, acc 0.96875
2020-02-08T03:27:08.521820: step 1687, loss 0.0986577, acc 0.96875
2020-02-08T03:27:08.636893: step 1688, loss 0.128867, acc 0.96875
2020-02-08T03:27:08.758339: step 1689, loss 0.131571, acc 0.9375
2020-02-08T03:27:08.879226: step 1690, loss 0.0692656, acc 0.984375
2020-02-08T03:27:08.997560: step 1691, loss 0.042973, acc 0.984375
2020-02-08T03:27:09.116432: step 1692, loss 0.0527571, acc 0.984375
2020-02-08T03:27:09.235587: step 1693, loss 0.101026, acc 0.96875
2020-02-08T03:27:09.354425: step 1694, loss 0.119331, acc 0.9375
2020-02-08T03:27:09.470611: step 1695, loss 0.0975882, acc 0.953125
2020-02-08T03:27:09.586456: step 1696, loss 0.104095, acc 0.953125
2020-02-08T03:27:09.703684: step 1697, loss 0.0836718, acc 0.984375
2020-02-08T03:27:09.827298: step 1698, loss 0.0698637, acc 0.96875
2020-02-08T03:27:09.946130: step 1699, loss 0.127004, acc 0.96875
2020-02-08T03:27:10.063962: step 1700, loss 0.181908, acc 0.90625

Evaluation:
2020-02-08T03:27:10.253880: step 1700, loss 0.742841, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1700

2020-02-08T03:27:11.754314: step 1701, loss 0.0898333, acc 0.96875
2020-02-08T03:27:11.877307: step 1702, loss 0.11108, acc 0.96875
2020-02-08T03:27:11.994733: step 1703, loss 0.131602, acc 0.953125
2020-02-08T03:27:12.112131: step 1704, loss 0.124091, acc 0.953125
2020-02-08T03:27:12.229921: step 1705, loss 0.109234, acc 0.96875
2020-02-08T03:27:12.346437: step 1706, loss 0.0816323, acc 0.96875
2020-02-08T03:27:12.465151: step 1707, loss 0.106234, acc 0.953125
2020-02-08T03:27:12.581156: step 1708, loss 0.104686, acc 0.96875
2020-02-08T03:27:12.696074: step 1709, loss 0.123503, acc 0.953125
2020-02-08T03:27:12.812446: step 1710, loss 0.0746774, acc 0.953125
2020-02-08T03:27:12.933183: step 1711, loss 0.091793, acc 0.96875
2020-02-08T03:27:13.048317: step 1712, loss 0.0724858, acc 0.984375
2020-02-08T03:27:13.164062: step 1713, loss 0.128146, acc 0.96875
2020-02-08T03:27:13.280588: step 1714, loss 0.404631, acc 0.859375
2020-02-08T03:27:13.397545: step 1715, loss 0.0392219, acc 1
2020-02-08T03:27:13.513673: step 1716, loss 0.100321, acc 0.96875
2020-02-08T03:27:13.632061: step 1717, loss 0.189682, acc 0.9375
2020-02-08T03:27:13.747963: step 1718, loss 0.0606384, acc 0.96875
2020-02-08T03:27:13.866315: step 1719, loss 0.0777727, acc 0.96875
2020-02-08T03:27:13.983958: step 1720, loss 0.153738, acc 0.921875
2020-02-08T03:27:14.102026: step 1721, loss 0.0862914, acc 0.984375
2020-02-08T03:27:14.218374: step 1722, loss 0.103428, acc 0.96875
2020-02-08T03:27:14.333511: step 1723, loss 0.195251, acc 0.90625
2020-02-08T03:27:14.449872: step 1724, loss 0.0837423, acc 0.96875
2020-02-08T03:27:14.568949: step 1725, loss 0.0827057, acc 0.96875
2020-02-08T03:27:14.686891: step 1726, loss 0.0877933, acc 0.96875
2020-02-08T03:27:14.802116: step 1727, loss 0.220541, acc 0.921875
2020-02-08T03:27:14.929651: step 1728, loss 0.0833831, acc 0.984375
2020-02-08T03:27:15.045591: step 1729, loss 0.092621, acc 0.984375
2020-02-08T03:27:15.160132: step 1730, loss 0.130783, acc 0.9375
2020-02-08T03:27:15.277617: step 1731, loss 0.111934, acc 0.96875
2020-02-08T03:27:15.393013: step 1732, loss 0.109853, acc 0.9375
2020-02-08T03:27:15.511789: step 1733, loss 0.149426, acc 0.953125
2020-02-08T03:27:15.626371: step 1734, loss 0.0989257, acc 0.953125
2020-02-08T03:27:15.742634: step 1735, loss 0.124416, acc 0.9375
2020-02-08T03:27:15.862685: step 1736, loss 0.116869, acc 0.96875
2020-02-08T03:27:15.980474: step 1737, loss 0.114328, acc 0.953125
2020-02-08T03:27:16.094664: step 1738, loss 0.111985, acc 0.9375
2020-02-08T03:27:16.209660: step 1739, loss 0.0848588, acc 0.953125
2020-02-08T03:27:16.323955: step 1740, loss 0.0775209, acc 0.984375
2020-02-08T03:27:16.438864: step 1741, loss 0.169565, acc 0.921875
2020-02-08T03:27:16.556826: step 1742, loss 0.117804, acc 0.9375
2020-02-08T03:27:16.672861: step 1743, loss 0.242554, acc 0.921875
2020-02-08T03:27:16.788192: step 1744, loss 0.100172, acc 0.953125
2020-02-08T03:27:16.911774: step 1745, loss 0.0889487, acc 0.953125
2020-02-08T03:27:17.027915: step 1746, loss 0.118215, acc 0.953125
2020-02-08T03:27:17.145912: step 1747, loss 0.0589678, acc 0.984375
2020-02-08T03:27:17.268835: step 1748, loss 0.0425551, acc 1
2020-02-08T03:27:17.384479: step 1749, loss 0.23183, acc 0.921875
2020-02-08T03:27:17.500027: step 1750, loss 0.0898072, acc 0.953125
2020-02-08T03:27:17.619037: step 1751, loss 0.161527, acc 0.921875
2020-02-08T03:27:17.733456: step 1752, loss 0.217438, acc 0.921875
2020-02-08T03:27:17.857695: step 1753, loss 0.0346122, acc 1
2020-02-08T03:27:17.975690: step 1754, loss 0.098381, acc 0.953125
2020-02-08T03:27:18.091035: step 1755, loss 0.0770863, acc 0.96875
2020-02-08T03:27:18.212927: step 1756, loss 0.056673, acc 0.984375
2020-02-08T03:27:18.329468: step 1757, loss 0.0843151, acc 0.96875
2020-02-08T03:27:18.444832: step 1758, loss 0.1049, acc 0.9375
2020-02-08T03:27:18.564594: step 1759, loss 0.0874611, acc 0.96875
2020-02-08T03:27:18.680439: step 1760, loss 0.0855713, acc 0.984375
2020-02-08T03:27:18.793470: step 1761, loss 0.066304, acc 0.96875
2020-02-08T03:27:18.913713: step 1762, loss 0.205459, acc 0.90625
2020-02-08T03:27:19.029405: step 1763, loss 0.0754681, acc 0.984375
2020-02-08T03:27:19.144959: step 1764, loss 0.144348, acc 0.953125
2020-02-08T03:27:19.263285: step 1765, loss 0.146576, acc 0.953125
2020-02-08T03:27:19.379908: step 1766, loss 0.053683, acc 0.984375
2020-02-08T03:27:19.497783: step 1767, loss 0.0894382, acc 0.96875
2020-02-08T03:27:19.616614: step 1768, loss 0.0917215, acc 0.96875
2020-02-08T03:27:19.733289: step 1769, loss 0.161525, acc 0.921875
2020-02-08T03:27:19.852187: step 1770, loss 0.0521733, acc 0.984375
2020-02-08T03:27:19.970572: step 1771, loss 0.197143, acc 0.90625
2020-02-08T03:27:20.085486: step 1772, loss 0.185538, acc 0.953125
2020-02-08T03:27:20.206166: step 1773, loss 0.146135, acc 0.9375
2020-02-08T03:27:20.322394: step 1774, loss 0.0665194, acc 0.984375
2020-02-08T03:27:20.437501: step 1775, loss 0.114654, acc 0.96875
2020-02-08T03:27:20.554584: step 1776, loss 0.108792, acc 0.953125
2020-02-08T03:27:20.671955: step 1777, loss 0.132513, acc 0.9375
2020-02-08T03:27:20.787192: step 1778, loss 0.0968882, acc 0.953125
2020-02-08T03:27:20.909916: step 1779, loss 0.132006, acc 0.921875
2020-02-08T03:27:21.028077: step 1780, loss 0.0656366, acc 1
2020-02-08T03:27:21.142732: step 1781, loss 0.0393886, acc 1
2020-02-08T03:27:21.264296: step 1782, loss 0.157715, acc 0.953125
2020-02-08T03:27:21.381670: step 1783, loss 0.130101, acc 0.921875
2020-02-08T03:27:21.712891: step 1784, loss 0.174776, acc 0.921875
2020-02-08T03:27:21.837748: step 1785, loss 0.180059, acc 0.921875
2020-02-08T03:27:21.957578: step 1786, loss 0.146239, acc 0.9375
2020-02-08T03:27:22.073966: step 1787, loss 0.147459, acc 0.96875
2020-02-08T03:27:22.188042: step 1788, loss 0.088709, acc 0.96875
2020-02-08T03:27:22.305626: step 1789, loss 0.0661093, acc 0.96875
2020-02-08T03:27:22.423788: step 1790, loss 0.128001, acc 0.953125
2020-02-08T03:27:22.538066: step 1791, loss 0.0713161, acc 0.984375
2020-02-08T03:27:22.653101: step 1792, loss 0.10661, acc 0.953125
2020-02-08T03:27:22.771040: step 1793, loss 0.146734, acc 0.890625
2020-02-08T03:27:22.889937: step 1794, loss 0.125181, acc 0.921875
2020-02-08T03:27:23.012385: step 1795, loss 0.156964, acc 0.921875
2020-02-08T03:27:23.127678: step 1796, loss 0.0666536, acc 0.984375
2020-02-08T03:27:23.243074: step 1797, loss 0.152545, acc 0.96875
2020-02-08T03:27:23.361551: step 1798, loss 0.0905464, acc 0.953125
2020-02-08T03:27:23.477155: step 1799, loss 0.216671, acc 0.9375
2020-02-08T03:27:23.587506: step 1800, loss 0.161561, acc 0.966667

Evaluation:
2020-02-08T03:27:23.777278: step 1800, loss 0.772005, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1800

2020-02-08T03:27:25.516227: step 1801, loss 0.0408809, acc 1
2020-02-08T03:27:25.630617: step 1802, loss 0.0709915, acc 0.96875
2020-02-08T03:27:25.746805: step 1803, loss 0.0820212, acc 0.96875
2020-02-08T03:27:25.866218: step 1804, loss 0.0620208, acc 0.984375
2020-02-08T03:27:25.982721: step 1805, loss 0.0659251, acc 0.953125
2020-02-08T03:27:26.097789: step 1806, loss 0.104848, acc 0.953125
2020-02-08T03:27:26.215439: step 1807, loss 0.0384396, acc 1
2020-02-08T03:27:26.331498: step 1808, loss 0.0765516, acc 0.96875
2020-02-08T03:27:26.444456: step 1809, loss 0.13796, acc 0.9375
2020-02-08T03:27:26.562994: step 1810, loss 0.0624987, acc 1
2020-02-08T03:27:26.676045: step 1811, loss 0.0922339, acc 0.96875
2020-02-08T03:27:26.792138: step 1812, loss 0.108572, acc 0.953125
2020-02-08T03:27:26.911114: step 1813, loss 0.0482703, acc 1
2020-02-08T03:27:27.031666: step 1814, loss 0.0523896, acc 0.984375
2020-02-08T03:27:27.148942: step 1815, loss 0.114797, acc 0.96875
2020-02-08T03:27:27.266866: step 1816, loss 0.111595, acc 0.96875
2020-02-08T03:27:27.385157: step 1817, loss 0.0659875, acc 0.96875
2020-02-08T03:27:27.502196: step 1818, loss 0.0707245, acc 0.96875
2020-02-08T03:27:27.620183: step 1819, loss 0.0768218, acc 0.953125
2020-02-08T03:27:27.734862: step 1820, loss 0.065863, acc 0.96875
2020-02-08T03:27:27.855438: step 1821, loss 0.0621602, acc 1
2020-02-08T03:27:27.973074: step 1822, loss 0.0956738, acc 0.953125
2020-02-08T03:27:28.087834: step 1823, loss 0.0903958, acc 0.953125
2020-02-08T03:27:28.206415: step 1824, loss 0.0647596, acc 0.96875
2020-02-08T03:27:28.326816: step 1825, loss 0.0693505, acc 0.984375
2020-02-08T03:27:28.444041: step 1826, loss 0.0315784, acc 1
2020-02-08T03:27:28.560789: step 1827, loss 0.116248, acc 0.96875
2020-02-08T03:27:28.677267: step 1828, loss 0.0540933, acc 1
2020-02-08T03:27:28.796378: step 1829, loss 0.126333, acc 0.953125
2020-02-08T03:27:28.916246: step 1830, loss 0.0832542, acc 0.984375
2020-02-08T03:27:29.038629: step 1831, loss 0.0595758, acc 0.96875
2020-02-08T03:27:29.157008: step 1832, loss 0.106849, acc 0.953125
2020-02-08T03:27:29.274122: step 1833, loss 0.073375, acc 0.96875
2020-02-08T03:27:29.387374: step 1834, loss 0.0616289, acc 1
2020-02-08T03:27:29.504409: step 1835, loss 0.068701, acc 0.984375
2020-02-08T03:27:29.620299: step 1836, loss 0.139984, acc 0.9375
2020-02-08T03:27:29.735373: step 1837, loss 0.0921138, acc 0.984375
2020-02-08T03:27:29.855948: step 1838, loss 0.0569206, acc 0.984375
2020-02-08T03:27:29.974250: step 1839, loss 0.0885073, acc 0.953125
2020-02-08T03:27:30.089780: step 1840, loss 0.116616, acc 0.953125
2020-02-08T03:27:30.207180: step 1841, loss 0.0810997, acc 0.984375
2020-02-08T03:27:30.322663: step 1842, loss 0.0835885, acc 0.96875
2020-02-08T03:27:30.437871: step 1843, loss 0.0824048, acc 0.96875
2020-02-08T03:27:30.556758: step 1844, loss 0.0919077, acc 0.96875
2020-02-08T03:27:30.673528: step 1845, loss 0.149352, acc 0.9375
2020-02-08T03:27:30.791753: step 1846, loss 0.0712762, acc 0.96875
2020-02-08T03:27:30.911591: step 1847, loss 0.0305156, acc 0.984375
2020-02-08T03:27:31.028900: step 1848, loss 0.10286, acc 0.96875
2020-02-08T03:27:31.145861: step 1849, loss 0.180582, acc 0.90625
2020-02-08T03:27:31.262393: step 1850, loss 0.0884905, acc 0.96875
2020-02-08T03:27:31.378244: step 1851, loss 0.153875, acc 0.90625
2020-02-08T03:27:31.495365: step 1852, loss 0.0624245, acc 0.984375
2020-02-08T03:27:31.613474: step 1853, loss 0.172772, acc 0.9375
2020-02-08T03:27:31.731080: step 1854, loss 0.109528, acc 0.96875
2020-02-08T03:27:31.852442: step 1855, loss 0.100012, acc 0.9375
2020-02-08T03:27:31.970862: step 1856, loss 0.0735069, acc 0.984375
2020-02-08T03:27:32.086640: step 1857, loss 0.0690272, acc 0.984375
2020-02-08T03:27:32.205576: step 1858, loss 0.0692081, acc 0.984375
2020-02-08T03:27:32.320332: step 1859, loss 0.123755, acc 0.9375
2020-02-08T03:27:32.433701: step 1860, loss 0.0633661, acc 0.984375
2020-02-08T03:27:32.549432: step 1861, loss 0.0370351, acc 1
2020-02-08T03:27:32.666452: step 1862, loss 0.0809425, acc 0.984375
2020-02-08T03:27:32.780681: step 1863, loss 0.179317, acc 0.921875
2020-02-08T03:27:32.903339: step 1864, loss 0.0381236, acc 1
2020-02-08T03:27:33.018454: step 1865, loss 0.0639423, acc 0.984375
2020-02-08T03:27:33.132772: step 1866, loss 0.0992859, acc 0.96875
2020-02-08T03:27:33.247446: step 1867, loss 0.0332548, acc 1
2020-02-08T03:27:33.364992: step 1868, loss 0.0553102, acc 0.984375
2020-02-08T03:27:33.481070: step 1869, loss 0.0353291, acc 1
2020-02-08T03:27:33.596531: step 1870, loss 0.180319, acc 0.953125
2020-02-08T03:27:33.715353: step 1871, loss 0.111369, acc 0.953125
2020-02-08T03:27:33.837584: step 1872, loss 0.0955893, acc 0.984375
2020-02-08T03:27:33.952940: step 1873, loss 0.0807996, acc 0.96875
2020-02-08T03:27:34.069669: step 1874, loss 0.0800291, acc 0.984375
2020-02-08T03:27:34.183677: step 1875, loss 0.14259, acc 0.96875
2020-02-08T03:27:34.302802: step 1876, loss 0.0890422, acc 0.96875
2020-02-08T03:27:34.418018: step 1877, loss 0.0613236, acc 0.984375
2020-02-08T03:27:34.535325: step 1878, loss 0.144287, acc 0.96875
2020-02-08T03:27:34.651461: step 1879, loss 0.0862278, acc 0.96875
2020-02-08T03:27:34.770090: step 1880, loss 0.105379, acc 0.953125
2020-02-08T03:27:34.887087: step 1881, loss 0.118244, acc 0.953125
2020-02-08T03:27:35.008316: step 1882, loss 0.0868281, acc 0.96875
2020-02-08T03:27:35.126302: step 1883, loss 0.0269389, acc 1
2020-02-08T03:27:35.242613: step 1884, loss 0.14611, acc 0.953125
2020-02-08T03:27:35.359776: step 1885, loss 0.0989623, acc 0.96875
2020-02-08T03:27:35.477709: step 1886, loss 0.0359999, acc 0.984375
2020-02-08T03:27:35.592219: step 1887, loss 0.154537, acc 0.953125
2020-02-08T03:27:35.709519: step 1888, loss 0.0935903, acc 0.96875
2020-02-08T03:27:35.826456: step 1889, loss 0.176109, acc 0.953125
2020-02-08T03:27:35.944920: step 1890, loss 0.0781618, acc 0.96875
2020-02-08T03:27:36.061885: step 1891, loss 0.114303, acc 0.9375
2020-02-08T03:27:36.179315: step 1892, loss 0.0537548, acc 0.96875
2020-02-08T03:27:36.297249: step 1893, loss 0.08331, acc 0.953125
2020-02-08T03:27:36.416562: step 1894, loss 0.117538, acc 0.96875
2020-02-08T03:27:36.530223: step 1895, loss 0.170227, acc 0.96875
2020-02-08T03:27:36.644952: step 1896, loss 0.0527008, acc 0.984375
2020-02-08T03:27:36.762323: step 1897, loss 0.0764456, acc 0.96875
2020-02-08T03:27:36.881268: step 1898, loss 0.0680706, acc 0.953125
2020-02-08T03:27:36.999174: step 1899, loss 0.0813078, acc 0.984375
2020-02-08T03:27:37.116118: step 1900, loss 0.0793549, acc 0.984375

Evaluation:
2020-02-08T03:27:37.306782: step 1900, loss 0.765871, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-1900

2020-02-08T03:27:38.796942: step 1901, loss 0.0533532, acc 0.984375
2020-02-08T03:27:38.918486: step 1902, loss 0.188151, acc 0.96875
2020-02-08T03:27:39.036263: step 1903, loss 0.0916094, acc 0.953125
2020-02-08T03:27:39.153529: step 1904, loss 0.0896252, acc 0.984375
2020-02-08T03:27:39.268786: step 1905, loss 0.111644, acc 0.953125
2020-02-08T03:27:39.382413: step 1906, loss 0.0397235, acc 0.984375
2020-02-08T03:27:39.496850: step 1907, loss 0.0441665, acc 1
2020-02-08T03:27:39.614294: step 1908, loss 0.0916537, acc 0.96875
2020-02-08T03:27:39.730918: step 1909, loss 0.0426356, acc 0.984375
2020-02-08T03:27:39.849925: step 1910, loss 0.077086, acc 0.96875
2020-02-08T03:27:39.966771: step 1911, loss 0.0806124, acc 0.984375
2020-02-08T03:27:40.083970: step 1912, loss 0.066877, acc 0.96875
2020-02-08T03:27:40.203517: step 1913, loss 0.0910195, acc 0.96875
2020-02-08T03:27:40.319783: step 1914, loss 0.0478783, acc 0.984375
2020-02-08T03:27:40.436106: step 1915, loss 0.0509383, acc 0.984375
2020-02-08T03:27:40.553743: step 1916, loss 0.0349846, acc 0.984375
2020-02-08T03:27:40.670536: step 1917, loss 0.0643652, acc 0.953125
2020-02-08T03:27:40.783108: step 1918, loss 0.0369738, acc 1
2020-02-08T03:27:40.903419: step 1919, loss 0.0888391, acc 0.96875
2020-02-08T03:27:41.019063: step 1920, loss 0.0577231, acc 0.96875
2020-02-08T03:27:41.135550: step 1921, loss 0.0426502, acc 1
2020-02-08T03:27:41.250570: step 1922, loss 0.0673234, acc 0.96875
2020-02-08T03:27:41.366472: step 1923, loss 0.0952001, acc 0.9375
2020-02-08T03:27:41.481344: step 1924, loss 0.115261, acc 0.9375
2020-02-08T03:27:41.599629: step 1925, loss 0.0737361, acc 0.96875
2020-02-08T03:27:41.718939: step 1926, loss 0.0908403, acc 0.953125
2020-02-08T03:27:41.836324: step 1927, loss 0.0699666, acc 0.984375
2020-02-08T03:27:41.952264: step 1928, loss 0.0755705, acc 0.984375
2020-02-08T03:27:42.071459: step 1929, loss 0.0901099, acc 0.953125
2020-02-08T03:27:42.188091: step 1930, loss 0.163309, acc 0.9375
2020-02-08T03:27:42.307267: step 1931, loss 0.113943, acc 0.96875
2020-02-08T03:27:42.426483: step 1932, loss 0.0910879, acc 0.96875
2020-02-08T03:27:42.543730: step 1933, loss 0.142842, acc 0.9375
2020-02-08T03:27:42.666659: step 1934, loss 0.0893303, acc 0.96875
2020-02-08T03:27:42.785149: step 1935, loss 0.0993573, acc 0.984375
2020-02-08T03:27:42.906793: step 1936, loss 0.100296, acc 0.984375
2020-02-08T03:27:43.022138: step 1937, loss 0.110772, acc 0.9375
2020-02-08T03:27:43.140543: step 1938, loss 0.0388019, acc 1
2020-02-08T03:27:43.258164: step 1939, loss 0.0475574, acc 1
2020-02-08T03:27:43.374545: step 1940, loss 0.0916003, acc 0.9375
2020-02-08T03:27:43.486546: step 1941, loss 0.0616087, acc 0.984375
2020-02-08T03:27:43.604697: step 1942, loss 0.177638, acc 0.890625
2020-02-08T03:27:43.725775: step 1943, loss 0.0609295, acc 0.984375
2020-02-08T03:27:43.849251: step 1944, loss 0.117834, acc 0.96875
2020-02-08T03:27:43.968812: step 1945, loss 0.0785926, acc 0.953125
2020-02-08T03:27:44.085482: step 1946, loss 0.133068, acc 0.9375
2020-02-08T03:27:44.201492: step 1947, loss 0.042462, acc 1
2020-02-08T03:27:44.317002: step 1948, loss 0.0622292, acc 0.984375
2020-02-08T03:27:44.432170: step 1949, loss 0.204013, acc 0.921875
2020-02-08T03:27:44.544067: step 1950, loss 0.0416647, acc 0.983333
2020-02-08T03:27:44.662685: step 1951, loss 0.109545, acc 0.953125
2020-02-08T03:27:44.780616: step 1952, loss 0.0610615, acc 0.96875
2020-02-08T03:27:44.905769: step 1953, loss 0.0594404, acc 0.96875
2020-02-08T03:27:45.021689: step 1954, loss 0.0587716, acc 0.984375
2020-02-08T03:27:45.138507: step 1955, loss 0.0535262, acc 0.984375
2020-02-08T03:27:45.256026: step 1956, loss 0.0344397, acc 0.984375
2020-02-08T03:27:45.372225: step 1957, loss 0.027431, acc 1
2020-02-08T03:27:45.489536: step 1958, loss 0.034563, acc 1
2020-02-08T03:27:45.606472: step 1959, loss 0.0377376, acc 0.984375
2020-02-08T03:27:45.725339: step 1960, loss 0.0573191, acc 0.96875
2020-02-08T03:27:45.845167: step 1961, loss 0.0374508, acc 0.984375
2020-02-08T03:27:45.963112: step 1962, loss 0.0720666, acc 0.984375
2020-02-08T03:27:46.080846: step 1963, loss 0.0384, acc 1
2020-02-08T03:27:46.198428: step 1964, loss 0.0782263, acc 0.984375
2020-02-08T03:27:46.312915: step 1965, loss 0.130353, acc 0.96875
2020-02-08T03:27:46.430777: step 1966, loss 0.0914042, acc 0.96875
2020-02-08T03:27:46.544557: step 1967, loss 0.0546329, acc 0.984375
2020-02-08T03:27:46.664227: step 1968, loss 0.032388, acc 1
2020-02-08T03:27:46.782628: step 1969, loss 0.0373894, acc 1
2020-02-08T03:27:46.903493: step 1970, loss 0.0345969, acc 1
2020-02-08T03:27:47.018993: step 1971, loss 0.0519154, acc 0.984375
2020-02-08T03:27:47.134462: step 1972, loss 0.0394275, acc 0.984375
2020-02-08T03:27:47.250109: step 1973, loss 0.112075, acc 0.9375
2020-02-08T03:27:47.366409: step 1974, loss 0.0790554, acc 0.96875
2020-02-08T03:27:47.482045: step 1975, loss 0.0286514, acc 1
2020-02-08T03:27:47.598602: step 1976, loss 0.0415842, acc 0.984375
2020-02-08T03:27:47.714014: step 1977, loss 0.06694, acc 0.984375
2020-02-08T03:27:47.832313: step 1978, loss 0.0360873, acc 0.984375
2020-02-08T03:27:47.950274: step 1979, loss 0.0977429, acc 0.96875
2020-02-08T03:27:48.067239: step 1980, loss 0.11532, acc 0.953125
2020-02-08T03:27:48.184123: step 1981, loss 0.0457861, acc 0.984375
2020-02-08T03:27:48.301664: step 1982, loss 0.0584541, acc 0.984375
2020-02-08T03:27:48.418227: step 1983, loss 0.0522892, acc 0.96875
2020-02-08T03:27:48.535149: step 1984, loss 0.107691, acc 0.953125
2020-02-08T03:27:48.652106: step 1985, loss 0.0192136, acc 1
2020-02-08T03:27:48.770336: step 1986, loss 0.0455539, acc 0.984375
2020-02-08T03:27:48.890577: step 1987, loss 0.0612494, acc 0.953125
2020-02-08T03:27:49.007396: step 1988, loss 0.0323945, acc 1
2020-02-08T03:27:49.124159: step 1989, loss 0.054643, acc 0.96875
2020-02-08T03:27:49.241074: step 1990, loss 0.0418175, acc 0.984375
2020-02-08T03:27:49.359421: step 1991, loss 0.0794293, acc 0.96875
2020-02-08T03:27:49.474594: step 1992, loss 0.0346206, acc 1
2020-02-08T03:27:49.589775: step 1993, loss 0.0447549, acc 0.984375
2020-02-08T03:27:49.705674: step 1994, loss 0.0414444, acc 0.984375
2020-02-08T03:27:49.822166: step 1995, loss 0.0450888, acc 0.984375
2020-02-08T03:27:49.939619: step 1996, loss 0.038713, acc 0.984375
2020-02-08T03:27:50.056953: step 1997, loss 0.17899, acc 0.921875
2020-02-08T03:27:50.174049: step 1998, loss 0.0573415, acc 0.984375
2020-02-08T03:27:50.292462: step 1999, loss 0.0997985, acc 0.984375
2020-02-08T03:27:50.408885: step 2000, loss 0.0833204, acc 0.96875

Evaluation:
2020-02-08T03:27:50.598893: step 2000, loss 0.795937, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2000

2020-02-08T03:27:52.152798: step 2001, loss 0.065354, acc 0.953125
2020-02-08T03:27:52.386804: step 2002, loss 0.083294, acc 0.96875
2020-02-08T03:27:52.521063: step 2003, loss 0.0310621, acc 1
2020-02-08T03:27:52.637217: step 2004, loss 0.0636993, acc 0.96875
2020-02-08T03:27:52.753103: step 2005, loss 0.0391773, acc 0.984375
2020-02-08T03:27:52.876127: step 2006, loss 0.174418, acc 0.9375
2020-02-08T03:27:52.993402: step 2007, loss 0.0465473, acc 1
2020-02-08T03:27:53.107722: step 2008, loss 0.0392075, acc 1
2020-02-08T03:27:53.227199: step 2009, loss 0.0967233, acc 0.953125
2020-02-08T03:27:53.344652: step 2010, loss 0.0514409, acc 0.984375
2020-02-08T03:27:53.463861: step 2011, loss 0.0393284, acc 0.984375
2020-02-08T03:27:53.580493: step 2012, loss 0.0920491, acc 0.96875
2020-02-08T03:27:53.696797: step 2013, loss 0.0595683, acc 0.96875
2020-02-08T03:27:53.818052: step 2014, loss 0.0683692, acc 0.984375
2020-02-08T03:27:53.934185: step 2015, loss 0.055516, acc 1
2020-02-08T03:27:54.050940: step 2016, loss 0.0527979, acc 0.96875
2020-02-08T03:27:54.169172: step 2017, loss 0.0812486, acc 0.96875
2020-02-08T03:27:54.286182: step 2018, loss 0.0382607, acc 1
2020-02-08T03:27:54.403702: step 2019, loss 0.0487779, acc 1
2020-02-08T03:27:54.520606: step 2020, loss 0.114238, acc 0.953125
2020-02-08T03:27:54.639001: step 2021, loss 0.0896543, acc 0.9375
2020-02-08T03:27:54.754893: step 2022, loss 0.0524628, acc 1
2020-02-08T03:27:54.876537: step 2023, loss 0.0838003, acc 0.96875
2020-02-08T03:27:54.994433: step 2024, loss 0.0525023, acc 0.984375
2020-02-08T03:27:55.111447: step 2025, loss 0.0465618, acc 0.984375
2020-02-08T03:27:55.228260: step 2026, loss 0.0273453, acc 1
2020-02-08T03:27:55.344657: step 2027, loss 0.0288893, acc 1
2020-02-08T03:27:55.467098: step 2028, loss 0.06669, acc 0.984375
2020-02-08T03:27:55.582556: step 2029, loss 0.0313629, acc 1
2020-02-08T03:27:55.698203: step 2030, loss 0.0682077, acc 0.96875
2020-02-08T03:27:55.819756: step 2031, loss 0.0365828, acc 1
2020-02-08T03:27:55.934162: step 2032, loss 0.0156871, acc 1
2020-02-08T03:27:56.050567: step 2033, loss 0.0789785, acc 0.984375
2020-02-08T03:27:56.167839: step 2034, loss 0.0771954, acc 0.96875
2020-02-08T03:27:56.283139: step 2035, loss 0.169809, acc 0.953125
2020-02-08T03:27:56.399854: step 2036, loss 0.0370678, acc 0.984375
2020-02-08T03:27:56.517540: step 2037, loss 0.132906, acc 0.9375
2020-02-08T03:27:56.632324: step 2038, loss 0.0454131, acc 0.984375
2020-02-08T03:27:56.750871: step 2039, loss 0.0302478, acc 1
2020-02-08T03:27:56.871817: step 2040, loss 0.0980606, acc 0.96875
2020-02-08T03:27:56.987256: step 2041, loss 0.0278496, acc 1
2020-02-08T03:27:57.101635: step 2042, loss 0.0571707, acc 0.96875
2020-02-08T03:27:57.219043: step 2043, loss 0.132482, acc 0.96875
2020-02-08T03:27:57.333722: step 2044, loss 0.13642, acc 0.96875
2020-02-08T03:27:57.450387: step 2045, loss 0.0574748, acc 0.984375
2020-02-08T03:27:57.568170: step 2046, loss 0.133752, acc 0.953125
2020-02-08T03:27:57.689271: step 2047, loss 0.0578542, acc 0.984375
2020-02-08T03:27:57.810135: step 2048, loss 0.0735825, acc 0.96875
2020-02-08T03:27:57.928329: step 2049, loss 0.0962736, acc 0.953125
2020-02-08T03:27:58.043608: step 2050, loss 0.115468, acc 0.953125
2020-02-08T03:27:58.160555: step 2051, loss 0.0212447, acc 1
2020-02-08T03:27:58.276514: step 2052, loss 0.0789615, acc 0.953125
2020-02-08T03:27:58.392488: step 2053, loss 0.100367, acc 0.953125
2020-02-08T03:27:58.509594: step 2054, loss 0.053514, acc 0.984375
2020-02-08T03:27:58.627029: step 2055, loss 0.0912318, acc 0.96875
2020-02-08T03:27:58.742700: step 2056, loss 0.171329, acc 0.9375
2020-02-08T03:27:58.869465: step 2057, loss 0.0353929, acc 0.984375
2020-02-08T03:27:58.985660: step 2058, loss 0.051377, acc 1
2020-02-08T03:27:59.117949: step 2059, loss 0.0488327, acc 0.984375
2020-02-08T03:27:59.321553: step 2060, loss 0.0897455, acc 0.96875
2020-02-08T03:27:59.444516: step 2061, loss 0.0569854, acc 0.96875
2020-02-08T03:27:59.574353: step 2062, loss 0.0594194, acc 0.96875
2020-02-08T03:27:59.714155: step 2063, loss 0.0980837, acc 0.96875
2020-02-08T03:27:59.855180: step 2064, loss 0.0365708, acc 1
2020-02-08T03:27:59.993633: step 2065, loss 0.0125381, acc 1
2020-02-08T03:28:00.137233: step 2066, loss 0.0763259, acc 0.953125
2020-02-08T03:28:00.273987: step 2067, loss 0.120044, acc 0.96875
2020-02-08T03:28:00.415436: step 2068, loss 0.0340311, acc 1
2020-02-08T03:28:00.543544: step 2069, loss 0.0736627, acc 1
2020-02-08T03:28:00.685607: step 2070, loss 0.0734503, acc 0.984375
2020-02-08T03:28:00.826289: step 2071, loss 0.0592631, acc 0.96875
2020-02-08T03:28:00.962963: step 2072, loss 0.0345385, acc 1
2020-02-08T03:28:01.094814: step 2073, loss 0.113694, acc 0.953125
2020-02-08T03:28:01.225261: step 2074, loss 0.0436613, acc 1
2020-02-08T03:28:01.347485: step 2075, loss 0.0988063, acc 0.953125
2020-02-08T03:28:01.467484: step 2076, loss 0.02917, acc 0.984375
2020-02-08T03:28:01.598667: step 2077, loss 0.0536642, acc 0.984375
2020-02-08T03:28:01.723484: step 2078, loss 0.0884855, acc 0.984375
2020-02-08T03:28:01.853767: step 2079, loss 0.0575375, acc 0.96875
2020-02-08T03:28:01.978806: step 2080, loss 0.0924766, acc 0.96875
2020-02-08T03:28:02.110688: step 2081, loss 0.0406129, acc 1
2020-02-08T03:28:02.246418: step 2082, loss 0.0465378, acc 0.984375
2020-02-08T03:28:02.392578: step 2083, loss 0.023764, acc 1
2020-02-08T03:28:02.519872: step 2084, loss 0.0459545, acc 0.984375
2020-02-08T03:28:02.659038: step 2085, loss 0.0468976, acc 1
2020-02-08T03:28:02.808114: step 2086, loss 0.054481, acc 0.984375
2020-02-08T03:28:02.954777: step 2087, loss 0.0259291, acc 1
2020-02-08T03:28:03.089215: step 2088, loss 0.0249994, acc 1
2020-02-08T03:28:03.232299: step 2089, loss 0.103485, acc 0.96875
2020-02-08T03:28:03.356951: step 2090, loss 0.0525371, acc 0.984375
2020-02-08T03:28:03.481467: step 2091, loss 0.0620401, acc 0.96875
2020-02-08T03:28:03.606501: step 2092, loss 0.08601, acc 0.96875
2020-02-08T03:28:03.727527: step 2093, loss 0.0443977, acc 0.984375
2020-02-08T03:28:03.854545: step 2094, loss 0.0797408, acc 0.984375
2020-02-08T03:28:03.979938: step 2095, loss 0.108279, acc 0.96875
2020-02-08T03:28:04.117758: step 2096, loss 0.0316019, acc 1
2020-02-08T03:28:04.255197: step 2097, loss 0.0649061, acc 0.984375
2020-02-08T03:28:04.395748: step 2098, loss 0.065371, acc 0.96875
2020-02-08T03:28:04.539418: step 2099, loss 0.139503, acc 0.96875
2020-02-08T03:28:04.673979: step 2100, loss 0.0840241, acc 0.95

Evaluation:
2020-02-08T03:28:04.909092: step 2100, loss 0.839036, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2100

2020-02-08T03:28:06.518718: step 2101, loss 0.0368495, acc 0.984375
2020-02-08T03:28:06.661163: step 2102, loss 0.077409, acc 0.984375
2020-02-08T03:28:06.802870: step 2103, loss 0.0418207, acc 0.984375
2020-02-08T03:28:06.943337: step 2104, loss 0.0483947, acc 0.984375
2020-02-08T03:28:07.085657: step 2105, loss 0.0322859, acc 0.984375
2020-02-08T03:28:07.222561: step 2106, loss 0.0584632, acc 0.984375
2020-02-08T03:28:07.366297: step 2107, loss 0.0194487, acc 1
2020-02-08T03:28:07.503638: step 2108, loss 0.0411891, acc 0.984375
2020-02-08T03:28:07.637835: step 2109, loss 0.0157567, acc 1
2020-02-08T03:28:07.775885: step 2110, loss 0.039967, acc 0.984375
2020-02-08T03:28:07.914517: step 2111, loss 0.101905, acc 0.96875
2020-02-08T03:28:08.055181: step 2112, loss 0.0369205, acc 0.984375
2020-02-08T03:28:08.194602: step 2113, loss 0.0231756, acc 1
2020-02-08T03:28:08.331418: step 2114, loss 0.0368902, acc 0.984375
2020-02-08T03:28:08.471796: step 2115, loss 0.06615, acc 0.96875
2020-02-08T03:28:08.609963: step 2116, loss 0.0780197, acc 0.96875
2020-02-08T03:28:08.749960: step 2117, loss 0.0850098, acc 0.96875
2020-02-08T03:28:08.892973: step 2118, loss 0.0586826, acc 0.96875
2020-02-08T03:28:09.035900: step 2119, loss 0.0589608, acc 0.984375
2020-02-08T03:28:09.172944: step 2120, loss 0.0722874, acc 0.984375
2020-02-08T03:28:09.297578: step 2121, loss 0.0779747, acc 0.953125
2020-02-08T03:28:09.434913: step 2122, loss 0.0735721, acc 0.984375
2020-02-08T03:28:09.560093: step 2123, loss 0.0397762, acc 0.984375
2020-02-08T03:28:09.685639: step 2124, loss 0.0622506, acc 0.984375
2020-02-08T03:28:09.812612: step 2125, loss 0.03942, acc 1
2020-02-08T03:28:09.932675: step 2126, loss 0.0332082, acc 0.984375
2020-02-08T03:28:10.051175: step 2127, loss 0.0350082, acc 0.984375
2020-02-08T03:28:10.173075: step 2128, loss 0.0705636, acc 0.984375
2020-02-08T03:28:10.289725: step 2129, loss 0.0357135, acc 0.984375
2020-02-08T03:28:10.418315: step 2130, loss 0.0623322, acc 0.96875
2020-02-08T03:28:10.541518: step 2131, loss 0.0358202, acc 1
2020-02-08T03:28:10.661991: step 2132, loss 0.0418844, acc 0.984375
2020-02-08T03:28:10.783263: step 2133, loss 0.0775515, acc 0.953125
2020-02-08T03:28:10.910878: step 2134, loss 0.0417269, acc 0.984375
2020-02-08T03:28:11.029172: step 2135, loss 0.0591559, acc 0.953125
2020-02-08T03:28:11.147065: step 2136, loss 0.0343729, acc 1
2020-02-08T03:28:11.269749: step 2137, loss 0.0533729, acc 0.984375
2020-02-08T03:28:11.386434: step 2138, loss 0.145474, acc 0.9375
2020-02-08T03:28:11.509453: step 2139, loss 0.023385, acc 1
2020-02-08T03:28:11.638592: step 2140, loss 0.0342636, acc 0.984375
2020-02-08T03:28:11.764376: step 2141, loss 0.0700178, acc 0.984375
2020-02-08T03:28:11.888453: step 2142, loss 0.0463176, acc 0.984375
2020-02-08T03:28:12.016199: step 2143, loss 0.0677989, acc 0.953125
2020-02-08T03:28:12.133618: step 2144, loss 0.0783774, acc 0.984375
2020-02-08T03:28:12.255761: step 2145, loss 0.0305207, acc 1
2020-02-08T03:28:12.374563: step 2146, loss 0.0490873, acc 0.96875
2020-02-08T03:28:12.491135: step 2147, loss 0.120576, acc 0.921875
2020-02-08T03:28:12.611117: step 2148, loss 0.0117869, acc 1
2020-02-08T03:28:12.732187: step 2149, loss 0.0678866, acc 0.96875
2020-02-08T03:28:12.855289: step 2150, loss 0.0451922, acc 1
2020-02-08T03:28:12.973649: step 2151, loss 0.0877033, acc 0.953125
2020-02-08T03:28:13.090232: step 2152, loss 0.0264511, acc 1
2020-02-08T03:28:13.210673: step 2153, loss 0.133477, acc 0.96875
2020-02-08T03:28:13.325722: step 2154, loss 0.0269343, acc 0.984375
2020-02-08T03:28:13.443377: step 2155, loss 0.0611229, acc 0.984375
2020-02-08T03:28:13.561167: step 2156, loss 0.0955317, acc 0.953125
2020-02-08T03:28:13.678492: step 2157, loss 0.0339869, acc 0.984375
2020-02-08T03:28:13.807332: step 2158, loss 0.0551509, acc 0.96875
2020-02-08T03:28:13.925645: step 2159, loss 0.130129, acc 0.96875
2020-02-08T03:28:14.041173: step 2160, loss 0.0504628, acc 0.96875
2020-02-08T03:28:14.157818: step 2161, loss 0.0556106, acc 0.984375
2020-02-08T03:28:14.276220: step 2162, loss 0.106176, acc 0.984375
2020-02-08T03:28:14.393378: step 2163, loss 0.0219127, acc 1
2020-02-08T03:28:14.511665: step 2164, loss 0.0467516, acc 0.984375
2020-02-08T03:28:14.629853: step 2165, loss 0.049655, acc 0.984375
2020-02-08T03:28:14.747744: step 2166, loss 0.0540395, acc 0.984375
2020-02-08T03:28:14.872278: step 2167, loss 0.0316759, acc 1
2020-02-08T03:28:14.991092: step 2168, loss 0.117292, acc 0.9375
2020-02-08T03:28:15.108873: step 2169, loss 0.0189392, acc 1
2020-02-08T03:28:15.225112: step 2170, loss 0.0427968, acc 0.984375
2020-02-08T03:28:15.339543: step 2171, loss 0.0305695, acc 1
2020-02-08T03:28:15.455892: step 2172, loss 0.229021, acc 0.921875
2020-02-08T03:28:15.573589: step 2173, loss 0.0492133, acc 0.96875
2020-02-08T03:28:15.688340: step 2174, loss 0.0111768, acc 1
2020-02-08T03:28:15.804765: step 2175, loss 0.0460941, acc 0.984375
2020-02-08T03:28:15.922900: step 2176, loss 0.0394778, acc 0.984375
2020-02-08T03:28:16.042286: step 2177, loss 0.0404846, acc 0.984375
2020-02-08T03:28:16.162438: step 2178, loss 0.0444898, acc 0.984375
2020-02-08T03:28:16.281818: step 2179, loss 0.0272795, acc 0.984375
2020-02-08T03:28:16.398748: step 2180, loss 0.0423675, acc 0.984375
2020-02-08T03:28:16.519462: step 2181, loss 0.0775466, acc 0.96875
2020-02-08T03:28:16.635218: step 2182, loss 0.0564271, acc 0.96875
2020-02-08T03:28:16.756270: step 2183, loss 0.0580376, acc 0.984375
2020-02-08T03:28:16.880272: step 2184, loss 0.0621471, acc 0.984375
2020-02-08T03:28:17.002746: step 2185, loss 0.078382, acc 0.96875
2020-02-08T03:28:17.120133: step 2186, loss 0.0311272, acc 1
2020-02-08T03:28:17.235248: step 2187, loss 0.0435882, acc 0.984375
2020-02-08T03:28:17.354018: step 2188, loss 0.0636439, acc 0.96875
2020-02-08T03:28:17.472109: step 2189, loss 0.0137247, acc 1
2020-02-08T03:28:17.589282: step 2190, loss 0.0737773, acc 0.96875
2020-02-08T03:28:17.719117: step 2191, loss 0.0218593, acc 1
2020-02-08T03:28:17.836862: step 2192, loss 0.0521783, acc 1
2020-02-08T03:28:17.964557: step 2193, loss 0.0158158, acc 1
2020-02-08T03:28:18.084680: step 2194, loss 0.0756966, acc 0.96875
2020-02-08T03:28:18.200739: step 2195, loss 0.0755717, acc 0.984375
2020-02-08T03:28:18.322286: step 2196, loss 0.0587274, acc 0.984375
2020-02-08T03:28:18.439817: step 2197, loss 0.0346713, acc 0.984375
2020-02-08T03:28:18.559407: step 2198, loss 0.0359315, acc 0.984375
2020-02-08T03:28:18.676144: step 2199, loss 0.0461116, acc 0.984375
2020-02-08T03:28:18.792612: step 2200, loss 0.0967069, acc 0.953125

Evaluation:
2020-02-08T03:28:18.981010: step 2200, loss 0.857419, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2200

2020-02-08T03:28:20.475376: step 2201, loss 0.0680416, acc 0.96875
2020-02-08T03:28:20.594976: step 2202, loss 0.0489999, acc 0.984375
2020-02-08T03:28:20.714789: step 2203, loss 0.0269827, acc 0.984375
2020-02-08T03:28:20.833291: step 2204, loss 0.069773, acc 0.96875
2020-02-08T03:28:20.950722: step 2205, loss 0.0296407, acc 0.984375
2020-02-08T03:28:21.088813: step 2206, loss 0.0278911, acc 1
2020-02-08T03:28:21.233178: step 2207, loss 0.0911221, acc 0.96875
2020-02-08T03:28:21.348841: step 2208, loss 0.0542109, acc 0.96875
2020-02-08T03:28:21.471501: step 2209, loss 0.0457389, acc 0.984375
2020-02-08T03:28:21.586262: step 2210, loss 0.0237753, acc 1
2020-02-08T03:28:21.704447: step 2211, loss 0.0249709, acc 1
2020-02-08T03:28:21.925103: step 2212, loss 0.0475522, acc 0.984375
2020-02-08T03:28:22.047284: step 2213, loss 0.038725, acc 1
2020-02-08T03:28:22.162400: step 2214, loss 0.0538799, acc 0.984375
2020-02-08T03:28:22.279502: step 2215, loss 0.0166263, acc 1
2020-02-08T03:28:22.397201: step 2216, loss 0.0346436, acc 1
2020-02-08T03:28:22.513874: step 2217, loss 0.0526205, acc 0.984375
2020-02-08T03:28:22.632607: step 2218, loss 0.0561528, acc 0.984375
2020-02-08T03:28:22.750378: step 2219, loss 0.0223579, acc 1
2020-02-08T03:28:22.873190: step 2220, loss 0.0776726, acc 0.96875
2020-02-08T03:28:22.987591: step 2221, loss 0.0614655, acc 0.96875
2020-02-08T03:28:23.105163: step 2222, loss 0.142152, acc 0.96875
2020-02-08T03:28:23.222509: step 2223, loss 0.0494712, acc 1
2020-02-08T03:28:23.339702: step 2224, loss 0.0449706, acc 0.984375
2020-02-08T03:28:23.458160: step 2225, loss 0.0383864, acc 0.984375
2020-02-08T03:28:23.577719: step 2226, loss 0.129052, acc 0.9375
2020-02-08T03:28:23.694319: step 2227, loss 0.0670236, acc 0.96875
2020-02-08T03:28:23.813685: step 2228, loss 0.0414608, acc 0.984375
2020-02-08T03:28:23.928941: step 2229, loss 0.0240286, acc 1
2020-02-08T03:28:24.045846: step 2230, loss 0.103988, acc 0.96875
2020-02-08T03:28:24.166065: step 2231, loss 0.0289293, acc 0.984375
2020-02-08T03:28:24.283550: step 2232, loss 0.0681816, acc 0.984375
2020-02-08T03:28:24.400549: step 2233, loss 0.096948, acc 0.96875
2020-02-08T03:28:24.517695: step 2234, loss 0.0719072, acc 0.984375
2020-02-08T03:28:24.632533: step 2235, loss 0.104476, acc 0.96875
2020-02-08T03:28:24.753119: step 2236, loss 0.0492547, acc 0.984375
2020-02-08T03:28:24.878565: step 2237, loss 0.0965649, acc 0.96875
2020-02-08T03:28:24.995454: step 2238, loss 0.0424748, acc 0.984375
2020-02-08T03:28:25.114926: step 2239, loss 0.0558812, acc 0.96875
2020-02-08T03:28:25.233503: step 2240, loss 0.0281815, acc 1
2020-02-08T03:28:25.351218: step 2241, loss 0.0679579, acc 0.984375
2020-02-08T03:28:25.472690: step 2242, loss 0.0591245, acc 0.96875
2020-02-08T03:28:25.587387: step 2243, loss 0.0128784, acc 1
2020-02-08T03:28:25.704378: step 2244, loss 0.0263533, acc 1
2020-02-08T03:28:25.825227: step 2245, loss 0.0690811, acc 0.953125
2020-02-08T03:28:25.942895: step 2246, loss 0.0135051, acc 1
2020-02-08T03:28:26.059786: step 2247, loss 0.0331624, acc 1
2020-02-08T03:28:26.176132: step 2248, loss 0.0712152, acc 0.96875
2020-02-08T03:28:26.293707: step 2249, loss 0.0466294, acc 0.984375
2020-02-08T03:28:26.408110: step 2250, loss 0.0652299, acc 0.966667
2020-02-08T03:28:26.526505: step 2251, loss 0.0127368, acc 1
2020-02-08T03:28:26.640035: step 2252, loss 0.0810887, acc 0.984375
2020-02-08T03:28:26.760955: step 2253, loss 0.0433306, acc 0.984375
2020-02-08T03:28:26.882957: step 2254, loss 0.0689888, acc 0.984375
2020-02-08T03:28:26.997543: step 2255, loss 0.0289597, acc 1
2020-02-08T03:28:27.114211: step 2256, loss 0.0301676, acc 0.984375
2020-02-08T03:28:27.230641: step 2257, loss 0.0677777, acc 0.984375
2020-02-08T03:28:27.345834: step 2258, loss 0.0565629, acc 0.96875
2020-02-08T03:28:27.465342: step 2259, loss 0.0255523, acc 1
2020-02-08T03:28:27.580189: step 2260, loss 0.0309783, acc 0.984375
2020-02-08T03:28:27.698591: step 2261, loss 0.0416779, acc 0.984375
2020-02-08T03:28:27.817214: step 2262, loss 0.0698758, acc 0.96875
2020-02-08T03:28:27.936551: step 2263, loss 0.0338164, acc 1
2020-02-08T03:28:28.055748: step 2264, loss 0.0517292, acc 0.96875
2020-02-08T03:28:28.174402: step 2265, loss 0.044517, acc 0.984375
2020-02-08T03:28:28.291421: step 2266, loss 0.0525688, acc 0.984375
2020-02-08T03:28:28.410154: step 2267, loss 0.0406845, acc 0.984375
2020-02-08T03:28:28.527091: step 2268, loss 0.1008, acc 0.96875
2020-02-08T03:28:28.643261: step 2269, loss 0.0232769, acc 1
2020-02-08T03:28:28.763880: step 2270, loss 0.0394576, acc 1
2020-02-08T03:28:28.885175: step 2271, loss 0.0361792, acc 0.984375
2020-02-08T03:28:29.000781: step 2272, loss 0.0193729, acc 1
2020-02-08T03:28:29.120555: step 2273, loss 0.0469935, acc 0.984375
2020-02-08T03:28:29.236598: step 2274, loss 0.0452525, acc 0.96875
2020-02-08T03:28:29.353315: step 2275, loss 0.0756698, acc 0.96875
2020-02-08T03:28:29.473075: step 2276, loss 0.0144205, acc 1
2020-02-08T03:28:29.589031: step 2277, loss 0.0314394, acc 1
2020-02-08T03:28:29.707539: step 2278, loss 0.00891005, acc 1
2020-02-08T03:28:29.826513: step 2279, loss 0.0414843, acc 1
2020-02-08T03:28:29.946582: step 2280, loss 0.0381613, acc 0.96875
2020-02-08T03:28:30.067310: step 2281, loss 0.0258559, acc 1
2020-02-08T03:28:30.185635: step 2282, loss 0.0554198, acc 0.96875
2020-02-08T03:28:30.307565: step 2283, loss 0.0272829, acc 0.984375
2020-02-08T03:28:30.434122: step 2284, loss 0.00794303, acc 1
2020-02-08T03:28:30.556140: step 2285, loss 0.0217712, acc 1
2020-02-08T03:28:30.676703: step 2286, loss 0.0465759, acc 0.984375
2020-02-08T03:28:30.805277: step 2287, loss 0.0361187, acc 0.984375
2020-02-08T03:28:30.923823: step 2288, loss 0.0318279, acc 0.984375
2020-02-08T03:28:31.041182: step 2289, loss 0.0176773, acc 1
2020-02-08T03:28:31.159123: step 2290, loss 0.0405353, acc 0.984375
2020-02-08T03:28:31.279843: step 2291, loss 0.0311345, acc 0.984375
2020-02-08T03:28:31.400063: step 2292, loss 0.0213398, acc 0.984375
2020-02-08T03:28:31.520409: step 2293, loss 0.0360219, acc 0.984375
2020-02-08T03:28:31.637546: step 2294, loss 0.0260607, acc 1
2020-02-08T03:28:31.756693: step 2295, loss 0.0239811, acc 0.984375
2020-02-08T03:28:31.879906: step 2296, loss 0.0911989, acc 0.953125
2020-02-08T03:28:31.996521: step 2297, loss 0.107166, acc 0.953125
2020-02-08T03:28:32.115758: step 2298, loss 0.0547034, acc 0.984375
2020-02-08T03:28:32.233507: step 2299, loss 0.0103356, acc 1
2020-02-08T03:28:32.348671: step 2300, loss 0.0654957, acc 0.984375

Evaluation:
2020-02-08T03:28:32.540257: step 2300, loss 0.900316, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2300

2020-02-08T03:28:34.056928: step 2301, loss 0.0313815, acc 1
2020-02-08T03:28:34.173145: step 2302, loss 0.115859, acc 0.96875
2020-02-08T03:28:34.290277: step 2303, loss 0.0240946, acc 1
2020-02-08T03:28:34.411766: step 2304, loss 0.0159665, acc 1
2020-02-08T03:28:34.526197: step 2305, loss 0.0207966, acc 0.984375
2020-02-08T03:28:34.641975: step 2306, loss 0.0919014, acc 0.96875
2020-02-08T03:28:34.757721: step 2307, loss 0.0402075, acc 0.984375
2020-02-08T03:28:34.879491: step 2308, loss 0.0362901, acc 0.984375
2020-02-08T03:28:34.995531: step 2309, loss 0.0114351, acc 1
2020-02-08T03:28:35.112878: step 2310, loss 0.0239701, acc 1
2020-02-08T03:28:35.229714: step 2311, loss 0.0063432, acc 1
2020-02-08T03:28:35.346400: step 2312, loss 0.0745797, acc 0.953125
2020-02-08T03:28:35.462348: step 2313, loss 0.0482547, acc 0.96875
2020-02-08T03:28:35.579854: step 2314, loss 0.0526739, acc 0.96875
2020-02-08T03:28:35.694105: step 2315, loss 0.0227243, acc 1
2020-02-08T03:28:35.820092: step 2316, loss 0.0232373, acc 0.984375
2020-02-08T03:28:35.936729: step 2317, loss 0.0455596, acc 0.96875
2020-02-08T03:28:36.051020: step 2318, loss 0.046386, acc 0.96875
2020-02-08T03:28:36.171813: step 2319, loss 0.0381269, acc 1
2020-02-08T03:28:36.289326: step 2320, loss 0.0134518, acc 1
2020-02-08T03:28:36.406681: step 2321, loss 0.0572966, acc 0.984375
2020-02-08T03:28:36.521442: step 2322, loss 0.0112836, acc 1
2020-02-08T03:28:36.637877: step 2323, loss 0.0532535, acc 0.984375
2020-02-08T03:28:36.753106: step 2324, loss 0.0346907, acc 0.984375
2020-02-08T03:28:36.875284: step 2325, loss 0.0287078, acc 1
2020-02-08T03:28:36.991148: step 2326, loss 0.0262375, acc 1
2020-02-08T03:28:37.108413: step 2327, loss 0.0385946, acc 1
2020-02-08T03:28:37.226546: step 2328, loss 0.0287739, acc 1
2020-02-08T03:28:37.341811: step 2329, loss 0.0590811, acc 0.984375
2020-02-08T03:28:37.460582: step 2330, loss 0.111874, acc 0.953125
2020-02-08T03:28:37.577982: step 2331, loss 0.0784495, acc 0.96875
2020-02-08T03:28:37.692484: step 2332, loss 0.0180206, acc 1
2020-02-08T03:28:37.807055: step 2333, loss 0.0234896, acc 0.984375
2020-02-08T03:28:37.925389: step 2334, loss 0.0365592, acc 0.984375
2020-02-08T03:28:38.039094: step 2335, loss 0.019372, acc 1
2020-02-08T03:28:38.154820: step 2336, loss 0.115841, acc 0.9375
2020-02-08T03:28:38.273951: step 2337, loss 0.0760032, acc 0.96875
2020-02-08T03:28:38.391121: step 2338, loss 0.046784, acc 0.984375
2020-02-08T03:28:38.507547: step 2339, loss 0.0422116, acc 0.984375
2020-02-08T03:28:38.621972: step 2340, loss 0.0101994, acc 1
2020-02-08T03:28:38.735770: step 2341, loss 0.0323012, acc 1
2020-02-08T03:28:38.856085: step 2342, loss 0.0270052, acc 1
2020-02-08T03:28:38.974512: step 2343, loss 0.0161616, acc 1
2020-02-08T03:28:39.094349: step 2344, loss 0.00763518, acc 1
2020-02-08T03:28:39.209319: step 2345, loss 0.0195951, acc 1
2020-02-08T03:28:39.326503: step 2346, loss 0.0317531, acc 0.984375
2020-02-08T03:28:39.442585: step 2347, loss 0.00872312, acc 1
2020-02-08T03:28:39.558994: step 2348, loss 0.0334945, acc 0.984375
2020-02-08T03:28:39.674573: step 2349, loss 0.0386931, acc 0.984375
2020-02-08T03:28:39.790958: step 2350, loss 0.0552977, acc 0.96875
2020-02-08T03:28:39.909747: step 2351, loss 0.0589461, acc 0.984375
2020-02-08T03:28:40.025299: step 2352, loss 0.0209518, acc 1
2020-02-08T03:28:40.142113: step 2353, loss 0.0282475, acc 0.984375
2020-02-08T03:28:40.258282: step 2354, loss 0.0149892, acc 1
2020-02-08T03:28:40.377059: step 2355, loss 0.0419649, acc 0.984375
2020-02-08T03:28:40.493306: step 2356, loss 0.0245064, acc 1
2020-02-08T03:28:40.610737: step 2357, loss 0.023731, acc 1
2020-02-08T03:28:40.727837: step 2358, loss 0.0167355, acc 1
2020-02-08T03:28:40.849889: step 2359, loss 0.0196372, acc 1
2020-02-08T03:28:40.967317: step 2360, loss 0.00621764, acc 1
2020-02-08T03:28:41.082313: step 2361, loss 0.0517897, acc 0.984375
2020-02-08T03:28:41.201171: step 2362, loss 0.0508448, acc 0.984375
2020-02-08T03:28:41.317146: step 2363, loss 0.0195026, acc 1
2020-02-08T03:28:41.434868: step 2364, loss 0.0863406, acc 0.96875
2020-02-08T03:28:41.554787: step 2365, loss 0.066146, acc 0.96875
2020-02-08T03:28:41.673091: step 2366, loss 0.022435, acc 1
2020-02-08T03:28:41.794027: step 2367, loss 0.137438, acc 0.953125
2020-02-08T03:28:41.915733: step 2368, loss 0.0103584, acc 1
2020-02-08T03:28:42.033403: step 2369, loss 0.0874543, acc 0.96875
2020-02-08T03:28:42.154708: step 2370, loss 0.0700919, acc 0.984375
2020-02-08T03:28:42.270643: step 2371, loss 0.0533469, acc 0.984375
2020-02-08T03:28:42.387656: step 2372, loss 0.0493153, acc 0.984375
2020-02-08T03:28:42.505100: step 2373, loss 0.0273652, acc 1
2020-02-08T03:28:42.623470: step 2374, loss 0.0302979, acc 1
2020-02-08T03:28:42.740287: step 2375, loss 0.0372203, acc 1
2020-02-08T03:28:42.860981: step 2376, loss 0.0280296, acc 1
2020-02-08T03:28:42.978047: step 2377, loss 0.0442095, acc 0.96875
2020-02-08T03:28:43.094159: step 2378, loss 0.069785, acc 0.96875
2020-02-08T03:28:43.210510: step 2379, loss 0.0481765, acc 0.984375
2020-02-08T03:28:43.327704: step 2380, loss 0.0175538, acc 1
2020-02-08T03:28:43.444430: step 2381, loss 0.0317381, acc 0.984375
2020-02-08T03:28:43.560697: step 2382, loss 0.0169619, acc 1
2020-02-08T03:28:43.679042: step 2383, loss 0.0690475, acc 0.96875
2020-02-08T03:28:43.799646: step 2384, loss 0.0187487, acc 1
2020-02-08T03:28:43.917746: step 2385, loss 0.0173909, acc 1
2020-02-08T03:28:44.033939: step 2386, loss 0.0446618, acc 0.984375
2020-02-08T03:28:44.151791: step 2387, loss 0.0316246, acc 1
2020-02-08T03:28:44.266563: step 2388, loss 0.0529646, acc 0.984375
2020-02-08T03:28:44.381725: step 2389, loss 0.102134, acc 0.953125
2020-02-08T03:28:44.497768: step 2390, loss 0.0581807, acc 0.96875
2020-02-08T03:28:44.616119: step 2391, loss 0.0556277, acc 0.96875
2020-02-08T03:28:44.731671: step 2392, loss 0.0717286, acc 0.96875
2020-02-08T03:28:44.853827: step 2393, loss 0.071353, acc 1
2020-02-08T03:28:44.974087: step 2394, loss 0.0696907, acc 0.96875
2020-02-08T03:28:45.089351: step 2395, loss 0.0363687, acc 0.984375
2020-02-08T03:28:45.207795: step 2396, loss 0.0439656, acc 0.984375
2020-02-08T03:28:45.325442: step 2397, loss 0.0359347, acc 1
2020-02-08T03:28:45.442566: step 2398, loss 0.0682873, acc 0.96875
2020-02-08T03:28:45.559911: step 2399, loss 0.0305027, acc 1
2020-02-08T03:28:45.676317: step 2400, loss 0.0415097, acc 0.983333

Evaluation:
2020-02-08T03:28:45.870497: step 2400, loss 0.918813, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2400

2020-02-08T03:28:47.426472: step 2401, loss 0.08672, acc 0.984375
2020-02-08T03:28:47.545538: step 2402, loss 0.018438, acc 1
2020-02-08T03:28:47.663297: step 2403, loss 0.0222767, acc 0.984375
2020-02-08T03:28:47.778906: step 2404, loss 0.00504888, acc 1
2020-02-08T03:28:47.900590: step 2405, loss 0.0961609, acc 0.96875
2020-02-08T03:28:48.017107: step 2406, loss 0.103746, acc 0.96875
2020-02-08T03:28:48.132289: step 2407, loss 0.0215829, acc 1
2020-02-08T03:28:48.253676: step 2408, loss 0.00494021, acc 1
2020-02-08T03:28:48.374669: step 2409, loss 0.0885801, acc 0.96875
2020-02-08T03:28:48.491772: step 2410, loss 0.111609, acc 0.953125
2020-02-08T03:28:48.612069: step 2411, loss 0.0358973, acc 1
2020-02-08T03:28:48.728506: step 2412, loss 0.047139, acc 0.984375
2020-02-08T03:28:48.847853: step 2413, loss 0.0316159, acc 0.984375
2020-02-08T03:28:48.965103: step 2414, loss 0.00600465, acc 1
2020-02-08T03:28:49.083440: step 2415, loss 0.00737917, acc 1
2020-02-08T03:28:49.199677: step 2416, loss 0.0156506, acc 1
2020-02-08T03:28:49.322655: step 2417, loss 0.0134895, acc 1
2020-02-08T03:28:49.440070: step 2418, loss 0.0372286, acc 0.984375
2020-02-08T03:28:49.557139: step 2419, loss 0.0196824, acc 0.984375
2020-02-08T03:28:49.677467: step 2420, loss 0.114747, acc 0.96875
2020-02-08T03:28:49.801024: step 2421, loss 0.104272, acc 0.9375
2020-02-08T03:28:49.921027: step 2422, loss 0.00751904, acc 1
2020-02-08T03:28:50.035436: step 2423, loss 0.0593583, acc 0.96875
2020-02-08T03:28:50.154511: step 2424, loss 0.0598803, acc 0.984375
2020-02-08T03:28:50.271692: step 2425, loss 0.0571807, acc 0.96875
2020-02-08T03:28:50.388462: step 2426, loss 0.030057, acc 0.984375
2020-02-08T03:28:50.504621: step 2427, loss 0.0166573, acc 1
2020-02-08T03:28:50.621751: step 2428, loss 0.0535692, acc 0.96875
2020-02-08T03:28:50.737495: step 2429, loss 0.0197488, acc 1
2020-02-08T03:28:50.861071: step 2430, loss 0.00869022, acc 1
2020-02-08T03:28:50.979686: step 2431, loss 0.120908, acc 0.96875
2020-02-08T03:28:51.098029: step 2432, loss 0.128452, acc 0.96875
2020-02-08T03:28:51.216426: step 2433, loss 0.0115687, acc 1
2020-02-08T03:28:51.331940: step 2434, loss 0.0729559, acc 0.96875
2020-02-08T03:28:51.582391: step 2435, loss 0.0210227, acc 1
2020-02-08T03:28:51.716273: step 2436, loss 0.0138302, acc 1
2020-02-08T03:28:51.833715: step 2437, loss 0.0210639, acc 1
2020-02-08T03:28:51.947313: step 2438, loss 0.0436298, acc 0.984375
2020-02-08T03:28:52.064355: step 2439, loss 0.0179244, acc 1
2020-02-08T03:28:52.181985: step 2440, loss 0.0217358, acc 1
2020-02-08T03:28:52.298589: step 2441, loss 0.0148073, acc 1
2020-02-08T03:28:52.417567: step 2442, loss 0.0358915, acc 0.984375
2020-02-08T03:28:52.536089: step 2443, loss 0.013555, acc 1
2020-02-08T03:28:52.652637: step 2444, loss 0.016008, acc 1
2020-02-08T03:28:52.770693: step 2445, loss 0.0254782, acc 0.984375
2020-02-08T03:28:52.893090: step 2446, loss 0.0884832, acc 0.96875
2020-02-08T03:28:53.011317: step 2447, loss 0.0104679, acc 1
2020-02-08T03:28:53.129044: step 2448, loss 0.0259915, acc 1
2020-02-08T03:28:53.245443: step 2449, loss 0.0436279, acc 1
2020-02-08T03:28:53.363297: step 2450, loss 0.0677229, acc 0.96875
2020-02-08T03:28:53.479163: step 2451, loss 0.0126598, acc 1
2020-02-08T03:28:53.594995: step 2452, loss 0.00799257, acc 1
2020-02-08T03:28:53.712165: step 2453, loss 0.0255178, acc 1
2020-02-08T03:28:53.828878: step 2454, loss 0.00690572, acc 1
2020-02-08T03:28:53.942673: step 2455, loss 0.0254377, acc 0.984375
2020-02-08T03:28:54.057521: step 2456, loss 0.036445, acc 0.984375
2020-02-08T03:28:54.174813: step 2457, loss 0.0275954, acc 0.984375
2020-02-08T03:28:54.291629: step 2458, loss 0.0309471, acc 1
2020-02-08T03:28:54.412367: step 2459, loss 0.0164906, acc 1
2020-02-08T03:28:54.527031: step 2460, loss 0.0378707, acc 1
2020-02-08T03:28:54.646080: step 2461, loss 0.0107042, acc 1
2020-02-08T03:28:54.765745: step 2462, loss 0.0215858, acc 1
2020-02-08T03:28:54.886074: step 2463, loss 0.0194876, acc 1
2020-02-08T03:28:55.003626: step 2464, loss 0.0111255, acc 1
2020-02-08T03:28:55.123586: step 2465, loss 0.0214101, acc 1
2020-02-08T03:28:55.239377: step 2466, loss 0.052951, acc 0.984375
2020-02-08T03:28:55.356861: step 2467, loss 0.0661843, acc 0.96875
2020-02-08T03:28:55.476086: step 2468, loss 0.0342107, acc 0.984375
2020-02-08T03:28:55.590416: step 2469, loss 0.0198686, acc 1
2020-02-08T03:28:55.703704: step 2470, loss 0.0326622, acc 0.984375
2020-02-08T03:28:55.823337: step 2471, loss 0.0237477, acc 1
2020-02-08T03:28:55.937898: step 2472, loss 0.035902, acc 1
2020-02-08T03:28:56.059318: step 2473, loss 0.0190498, acc 0.984375
2020-02-08T03:28:56.178653: step 2474, loss 0.0064333, acc 1
2020-02-08T03:28:56.308377: step 2475, loss 0.021186, acc 0.984375
2020-02-08T03:28:56.426313: step 2476, loss 0.0122345, acc 1
2020-02-08T03:28:56.549395: step 2477, loss 0.022827, acc 1
2020-02-08T03:28:56.667668: step 2478, loss 0.0137596, acc 1
2020-02-08T03:28:56.784634: step 2479, loss 0.020819, acc 1
2020-02-08T03:28:56.905082: step 2480, loss 0.0737616, acc 0.953125
2020-02-08T03:28:57.026683: step 2481, loss 0.0360781, acc 0.984375
2020-02-08T03:28:57.144053: step 2482, loss 0.0246249, acc 0.984375
2020-02-08T03:28:57.259870: step 2483, loss 0.0158048, acc 1
2020-02-08T03:28:57.378647: step 2484, loss 0.0437925, acc 0.984375
2020-02-08T03:28:57.494088: step 2485, loss 0.0412447, acc 1
2020-02-08T03:28:57.609932: step 2486, loss 0.0197104, acc 1
2020-02-08T03:28:57.727324: step 2487, loss 0.0854007, acc 0.984375
2020-02-08T03:28:57.844271: step 2488, loss 0.0136527, acc 1
2020-02-08T03:28:57.966880: step 2489, loss 0.0357083, acc 0.984375
2020-02-08T03:28:58.083608: step 2490, loss 0.059521, acc 0.984375
2020-02-08T03:28:58.200624: step 2491, loss 0.0496689, acc 0.96875
2020-02-08T03:28:58.318357: step 2492, loss 0.0846339, acc 0.96875
2020-02-08T03:28:58.436205: step 2493, loss 0.0632658, acc 0.96875
2020-02-08T03:28:58.555096: step 2494, loss 0.0137866, acc 1
2020-02-08T03:28:58.670452: step 2495, loss 0.0404134, acc 0.984375
2020-02-08T03:28:58.788270: step 2496, loss 0.0235147, acc 1
2020-02-08T03:28:58.910503: step 2497, loss 0.0265606, acc 0.984375
2020-02-08T03:28:59.029229: step 2498, loss 0.0157207, acc 1
2020-02-08T03:28:59.142899: step 2499, loss 0.00930104, acc 1
2020-02-08T03:28:59.261024: step 2500, loss 0.0138679, acc 1

Evaluation:
2020-02-08T03:28:59.448436: step 2500, loss 0.940082, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2500

2020-02-08T03:29:01.014756: step 2501, loss 0.151364, acc 0.953125
2020-02-08T03:29:01.131738: step 2502, loss 0.147215, acc 0.953125
2020-02-08T03:29:01.247232: step 2503, loss 0.00691022, acc 1
2020-02-08T03:29:01.364158: step 2504, loss 0.0247087, acc 1
2020-02-08T03:29:01.482555: step 2505, loss 0.0236271, acc 1
2020-02-08T03:29:01.599606: step 2506, loss 0.0264746, acc 1
2020-02-08T03:29:01.718600: step 2507, loss 0.0416743, acc 1
2020-02-08T03:29:01.836428: step 2508, loss 0.0447242, acc 0.984375
2020-02-08T03:29:01.955807: step 2509, loss 0.0401042, acc 0.96875
2020-02-08T03:29:02.075522: step 2510, loss 0.0201045, acc 1
2020-02-08T03:29:02.193364: step 2511, loss 0.0726974, acc 0.984375
2020-02-08T03:29:02.312940: step 2512, loss 0.0123516, acc 1
2020-02-08T03:29:02.430662: step 2513, loss 0.00975616, acc 1
2020-02-08T03:29:02.547109: step 2514, loss 0.013026, acc 1
2020-02-08T03:29:02.672178: step 2515, loss 0.0407903, acc 0.984375
2020-02-08T03:29:02.790293: step 2516, loss 0.0117305, acc 1
2020-02-08T03:29:02.916936: step 2517, loss 0.0323853, acc 1
2020-02-08T03:29:03.033122: step 2518, loss 0.00792927, acc 1
2020-02-08T03:29:03.148744: step 2519, loss 0.0451853, acc 0.984375
2020-02-08T03:29:03.265965: step 2520, loss 0.0248106, acc 1
2020-02-08T03:29:03.383090: step 2521, loss 0.0520658, acc 0.984375
2020-02-08T03:29:03.499684: step 2522, loss 0.00608195, acc 1
2020-02-08T03:29:03.618620: step 2523, loss 0.0318837, acc 1
2020-02-08T03:29:03.736374: step 2524, loss 0.0219253, acc 1
2020-02-08T03:29:03.856852: step 2525, loss 0.0135464, acc 1
2020-02-08T03:29:03.973727: step 2526, loss 0.0199697, acc 1
2020-02-08T03:29:04.090882: step 2527, loss 0.0201521, acc 0.984375
2020-02-08T03:29:04.209480: step 2528, loss 0.0230081, acc 1
2020-02-08T03:29:04.326899: step 2529, loss 0.0229575, acc 1
2020-02-08T03:29:04.443685: step 2530, loss 0.0322558, acc 0.96875
2020-02-08T03:29:04.571439: step 2531, loss 0.0386858, acc 0.984375
2020-02-08T03:29:04.691958: step 2532, loss 0.0148997, acc 1
2020-02-08T03:29:04.810840: step 2533, loss 0.0243339, acc 1
2020-02-08T03:29:04.930813: step 2534, loss 0.0175164, acc 1
2020-02-08T03:29:05.047197: step 2535, loss 0.0232493, acc 1
2020-02-08T03:29:05.162849: step 2536, loss 0.0160788, acc 1
2020-02-08T03:29:05.278747: step 2537, loss 0.0122907, acc 1
2020-02-08T03:29:05.396354: step 2538, loss 0.0208541, acc 1
2020-02-08T03:29:05.514917: step 2539, loss 0.0450462, acc 0.96875
2020-02-08T03:29:05.631738: step 2540, loss 0.0220812, acc 1
2020-02-08T03:29:05.747999: step 2541, loss 0.0187698, acc 1
2020-02-08T03:29:05.869055: step 2542, loss 0.0377787, acc 1
2020-02-08T03:29:05.986991: step 2543, loss 0.044093, acc 0.96875
2020-02-08T03:29:06.107693: step 2544, loss 0.0237196, acc 1
2020-02-08T03:29:06.224957: step 2545, loss 0.0238695, acc 1
2020-02-08T03:29:06.344021: step 2546, loss 0.0136862, acc 1
2020-02-08T03:29:06.462444: step 2547, loss 0.0122327, acc 1
2020-02-08T03:29:06.583775: step 2548, loss 0.0214432, acc 1
2020-02-08T03:29:06.701904: step 2549, loss 0.021416, acc 0.984375
2020-02-08T03:29:06.819945: step 2550, loss 0.0197397, acc 1
2020-02-08T03:29:06.938563: step 2551, loss 0.00575493, acc 1
2020-02-08T03:29:07.057866: step 2552, loss 0.0169771, acc 1
2020-02-08T03:29:07.177606: step 2553, loss 0.0294405, acc 0.984375
2020-02-08T03:29:07.294271: step 2554, loss 0.0150789, acc 1
2020-02-08T03:29:07.411617: step 2555, loss 0.0239038, acc 1
2020-02-08T03:29:07.528550: step 2556, loss 0.0348907, acc 0.984375
2020-02-08T03:29:07.643082: step 2557, loss 0.0149048, acc 1
2020-02-08T03:29:07.761803: step 2558, loss 0.0103123, acc 1
2020-02-08T03:29:07.884555: step 2559, loss 0.0351926, acc 0.984375
2020-02-08T03:29:08.001996: step 2560, loss 0.00817249, acc 1
2020-02-08T03:29:08.118225: step 2561, loss 0.048903, acc 0.984375
2020-02-08T03:29:08.235995: step 2562, loss 0.0178797, acc 1
2020-02-08T03:29:08.354940: step 2563, loss 0.0269378, acc 1
2020-02-08T03:29:08.473600: step 2564, loss 0.0102668, acc 1
2020-02-08T03:29:08.588911: step 2565, loss 0.0251855, acc 0.984375
2020-02-08T03:29:08.707468: step 2566, loss 0.00386841, acc 1
2020-02-08T03:29:08.827450: step 2567, loss 0.0107915, acc 1
2020-02-08T03:29:08.943533: step 2568, loss 0.0088379, acc 1
2020-02-08T03:29:09.058858: step 2569, loss 0.00716627, acc 1
2020-02-08T03:29:09.176424: step 2570, loss 0.0109237, acc 1
2020-02-08T03:29:09.291514: step 2571, loss 0.00391162, acc 1
2020-02-08T03:29:09.411003: step 2572, loss 0.0146873, acc 1
2020-02-08T03:29:09.527955: step 2573, loss 0.0486857, acc 0.984375
2020-02-08T03:29:09.643056: step 2574, loss 0.0246537, acc 0.984375
2020-02-08T03:29:09.760672: step 2575, loss 0.124946, acc 0.96875
2020-02-08T03:29:09.883533: step 2576, loss 0.00686754, acc 1
2020-02-08T03:29:10.000646: step 2577, loss 0.00326338, acc 1
2020-02-08T03:29:10.119899: step 2578, loss 0.0115879, acc 1
2020-02-08T03:29:10.232387: step 2579, loss 0.0196656, acc 1
2020-02-08T03:29:10.346741: step 2580, loss 0.0169694, acc 1
2020-02-08T03:29:10.465941: step 2581, loss 0.0160781, acc 1
2020-02-08T03:29:10.591648: step 2582, loss 0.0741445, acc 0.96875
2020-02-08T03:29:10.707854: step 2583, loss 0.0137426, acc 1
2020-02-08T03:29:10.824238: step 2584, loss 0.0233672, acc 1
2020-02-08T03:29:10.941608: step 2585, loss 0.0458153, acc 0.984375
2020-02-08T03:29:11.057718: step 2586, loss 0.0253546, acc 0.984375
2020-02-08T03:29:11.175650: step 2587, loss 0.00900283, acc 1
2020-02-08T03:29:11.292077: step 2588, loss 0.02733, acc 0.984375
2020-02-08T03:29:11.410060: step 2589, loss 0.0275797, acc 0.984375
2020-02-08T03:29:11.526013: step 2590, loss 0.0261008, acc 0.984375
2020-02-08T03:29:11.642537: step 2591, loss 0.0246715, acc 1
2020-02-08T03:29:11.760952: step 2592, loss 0.0367351, acc 0.984375
2020-02-08T03:29:11.881383: step 2593, loss 0.014105, acc 1
2020-02-08T03:29:11.996969: step 2594, loss 0.0481445, acc 0.96875
2020-02-08T03:29:12.117954: step 2595, loss 0.0316812, acc 0.984375
2020-02-08T03:29:12.236229: step 2596, loss 0.0221406, acc 0.984375
2020-02-08T03:29:12.353464: step 2597, loss 0.0275955, acc 0.984375
2020-02-08T03:29:12.469111: step 2598, loss 0.0428474, acc 0.984375
2020-02-08T03:29:12.584890: step 2599, loss 0.00863206, acc 1
2020-02-08T03:29:12.700354: step 2600, loss 0.00533608, acc 1

Evaluation:
2020-02-08T03:29:12.894872: step 2600, loss 0.976509, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2600

2020-02-08T03:29:14.387662: step 2601, loss 0.0251832, acc 0.984375
2020-02-08T03:29:14.504835: step 2602, loss 0.00954569, acc 1
2020-02-08T03:29:14.622274: step 2603, loss 0.00964275, acc 1
2020-02-08T03:29:14.737435: step 2604, loss 0.0416117, acc 0.984375
2020-02-08T03:29:14.857595: step 2605, loss 0.0181734, acc 1
2020-02-08T03:29:14.981875: step 2606, loss 0.0237379, acc 1
2020-02-08T03:29:15.100185: step 2607, loss 0.0304951, acc 0.984375
2020-02-08T03:29:15.218965: step 2608, loss 0.021213, acc 0.984375
2020-02-08T03:29:15.335239: step 2609, loss 0.0029665, acc 1
2020-02-08T03:29:15.447666: step 2610, loss 0.00505873, acc 1
2020-02-08T03:29:15.563560: step 2611, loss 0.0328513, acc 0.984375
2020-02-08T03:29:15.678496: step 2612, loss 0.0409222, acc 0.984375
2020-02-08T03:29:15.792488: step 2613, loss 0.0614795, acc 0.96875
2020-02-08T03:29:15.914323: step 2614, loss 0.0556287, acc 0.96875
2020-02-08T03:29:16.033347: step 2615, loss 0.0231442, acc 0.984375
2020-02-08T03:29:16.153778: step 2616, loss 0.0454655, acc 0.96875
2020-02-08T03:29:16.271154: step 2617, loss 0.0332919, acc 0.984375
2020-02-08T03:29:16.387079: step 2618, loss 0.0199089, acc 1
2020-02-08T03:29:16.503168: step 2619, loss 0.0316809, acc 1
2020-02-08T03:29:16.622945: step 2620, loss 0.0369832, acc 0.984375
2020-02-08T03:29:16.743689: step 2621, loss 0.0319842, acc 1
2020-02-08T03:29:16.867515: step 2622, loss 0.0216602, acc 1
2020-02-08T03:29:16.984151: step 2623, loss 0.0159415, acc 1
2020-02-08T03:29:17.100149: step 2624, loss 0.0246188, acc 0.984375
2020-02-08T03:29:17.217262: step 2625, loss 0.010619, acc 1
2020-02-08T03:29:17.333142: step 2626, loss 0.0143362, acc 1
2020-02-08T03:29:17.448117: step 2627, loss 0.0818399, acc 0.96875
2020-02-08T03:29:17.564848: step 2628, loss 0.0192454, acc 1
2020-02-08T03:29:17.680963: step 2629, loss 0.0183278, acc 1
2020-02-08T03:29:17.799377: step 2630, loss 0.0380388, acc 0.984375
2020-02-08T03:29:17.920424: step 2631, loss 0.00657554, acc 1
2020-02-08T03:29:18.037035: step 2632, loss 0.00720588, acc 1
2020-02-08T03:29:18.156709: step 2633, loss 0.017218, acc 1
2020-02-08T03:29:18.276393: step 2634, loss 0.0122715, acc 1
2020-02-08T03:29:18.391524: step 2635, loss 0.0154146, acc 1
2020-02-08T03:29:18.508746: step 2636, loss 0.0197079, acc 1
2020-02-08T03:29:18.626584: step 2637, loss 0.0267875, acc 0.984375
2020-02-08T03:29:18.741157: step 2638, loss 0.0227603, acc 0.984375
2020-02-08T03:29:18.863862: step 2639, loss 0.00459425, acc 1
2020-02-08T03:29:18.981791: step 2640, loss 0.0413975, acc 0.96875
2020-02-08T03:29:19.097209: step 2641, loss 0.0530358, acc 0.96875
2020-02-08T03:29:19.217683: step 2642, loss 0.00852998, acc 1
2020-02-08T03:29:19.336382: step 2643, loss 0.0204715, acc 1
2020-02-08T03:29:19.454763: step 2644, loss 0.0476214, acc 0.96875
2020-02-08T03:29:19.574614: step 2645, loss 0.0216519, acc 1
2020-02-08T03:29:19.690272: step 2646, loss 0.0316065, acc 0.984375
2020-02-08T03:29:19.810382: step 2647, loss 0.0144296, acc 1
2020-02-08T03:29:19.933314: step 2648, loss 0.00802928, acc 1
2020-02-08T03:29:20.049880: step 2649, loss 0.017088, acc 1
2020-02-08T03:29:20.167994: step 2650, loss 0.00427236, acc 1
2020-02-08T03:29:20.285476: step 2651, loss 0.0275246, acc 1
2020-02-08T03:29:20.402765: step 2652, loss 0.0613266, acc 0.984375
2020-02-08T03:29:20.521803: step 2653, loss 0.085156, acc 0.984375
2020-02-08T03:29:20.637853: step 2654, loss 0.00642148, acc 1
2020-02-08T03:29:20.754431: step 2655, loss 0.0657947, acc 0.984375
2020-02-08T03:29:20.878057: step 2656, loss 0.0633233, acc 0.96875
2020-02-08T03:29:20.994789: step 2657, loss 0.0501243, acc 0.984375
2020-02-08T03:29:21.110364: step 2658, loss 0.0257384, acc 0.984375
2020-02-08T03:29:21.229435: step 2659, loss 0.145344, acc 0.96875
2020-02-08T03:29:21.348424: step 2660, loss 0.0510681, acc 0.96875
2020-02-08T03:29:21.464996: step 2661, loss 0.0165809, acc 1
2020-02-08T03:29:21.579052: step 2662, loss 0.0297388, acc 0.984375
2020-02-08T03:29:21.865864: step 2663, loss 0.0370688, acc 0.984375
2020-02-08T03:29:21.986881: step 2664, loss 0.021282, acc 0.984375
2020-02-08T03:29:22.103602: step 2665, loss 0.0267173, acc 0.984375
2020-02-08T03:29:22.221302: step 2666, loss 0.0067786, acc 1
2020-02-08T03:29:22.339131: step 2667, loss 0.0186909, acc 1
2020-02-08T03:29:22.456895: step 2668, loss 0.138342, acc 0.953125
2020-02-08T03:29:22.575611: step 2669, loss 0.0663776, acc 0.953125
2020-02-08T03:29:22.692148: step 2670, loss 0.117325, acc 0.953125
2020-02-08T03:29:22.809749: step 2671, loss 0.0247696, acc 1
2020-02-08T03:29:22.928425: step 2672, loss 0.00961292, acc 1
2020-02-08T03:29:23.041980: step 2673, loss 0.0174084, acc 1
2020-02-08T03:29:23.157556: step 2674, loss 0.0346077, acc 0.984375
2020-02-08T03:29:23.276019: step 2675, loss 0.0168394, acc 0.984375
2020-02-08T03:29:23.392712: step 2676, loss 0.0164114, acc 0.984375
2020-02-08T03:29:23.509569: step 2677, loss 0.0122131, acc 1
2020-02-08T03:29:23.626904: step 2678, loss 0.0333473, acc 0.984375
2020-02-08T03:29:23.744156: step 2679, loss 0.0118519, acc 1
2020-02-08T03:29:23.868919: step 2680, loss 0.0296986, acc 1
2020-02-08T03:29:23.988613: step 2681, loss 0.0396601, acc 0.984375
2020-02-08T03:29:24.105176: step 2682, loss 0.0863649, acc 0.984375
2020-02-08T03:29:24.220836: step 2683, loss 0.0159637, acc 1
2020-02-08T03:29:24.338119: step 2684, loss 0.0149247, acc 1
2020-02-08T03:29:24.452943: step 2685, loss 0.0474296, acc 0.984375
2020-02-08T03:29:24.570089: step 2686, loss 0.0895462, acc 0.96875
2020-02-08T03:29:24.684221: step 2687, loss 0.0235331, acc 1
2020-02-08T03:29:24.803713: step 2688, loss 0.00984817, acc 1
2020-02-08T03:29:24.919868: step 2689, loss 0.0290673, acc 1
2020-02-08T03:29:25.038461: step 2690, loss 0.00616511, acc 1
2020-02-08T03:29:25.157095: step 2691, loss 0.016178, acc 1
2020-02-08T03:29:25.273489: step 2692, loss 0.0516095, acc 0.984375
2020-02-08T03:29:25.389812: step 2693, loss 0.028092, acc 0.984375
2020-02-08T03:29:25.508257: step 2694, loss 0.0219689, acc 1
2020-02-08T03:29:25.626098: step 2695, loss 0.0422942, acc 0.984375
2020-02-08T03:29:25.743238: step 2696, loss 0.0360433, acc 0.984375
2020-02-08T03:29:25.867186: step 2697, loss 0.0173638, acc 1
2020-02-08T03:29:25.984047: step 2698, loss 0.0129021, acc 1
2020-02-08T03:29:26.099886: step 2699, loss 0.0561025, acc 0.984375
2020-02-08T03:29:26.212662: step 2700, loss 0.078176, acc 0.966667

Evaluation:
2020-02-08T03:29:26.399217: step 2700, loss 1.01556, acc 0.718574

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2700

2020-02-08T03:29:28.609669: step 2701, loss 0.00681207, acc 1
2020-02-08T03:29:28.727465: step 2702, loss 0.0231911, acc 1
2020-02-08T03:29:28.849836: step 2703, loss 0.0119101, acc 1
2020-02-08T03:29:28.968531: step 2704, loss 0.0301295, acc 0.984375
2020-02-08T03:29:29.085881: step 2705, loss 0.00766922, acc 1
2020-02-08T03:29:29.202622: step 2706, loss 0.00675099, acc 1
2020-02-08T03:29:29.322232: step 2707, loss 0.0269877, acc 0.984375
2020-02-08T03:29:29.437729: step 2708, loss 0.057511, acc 0.96875
2020-02-08T03:29:29.555188: step 2709, loss 0.0110961, acc 1
2020-02-08T03:29:29.672693: step 2710, loss 0.0067206, acc 1
2020-02-08T03:29:29.789166: step 2711, loss 0.0393175, acc 0.984375
2020-02-08T03:29:29.912029: step 2712, loss 0.00444917, acc 1
2020-02-08T03:29:30.028112: step 2713, loss 0.036785, acc 0.984375
2020-02-08T03:29:30.143069: step 2714, loss 0.0214999, acc 0.984375
2020-02-08T03:29:30.260576: step 2715, loss 0.0202786, acc 1
2020-02-08T03:29:30.379104: step 2716, loss 0.0110105, acc 1
2020-02-08T03:29:30.495372: step 2717, loss 0.0231303, acc 1
2020-02-08T03:29:30.612930: step 2718, loss 0.0278053, acc 1
2020-02-08T03:29:30.730953: step 2719, loss 0.00768855, acc 1
2020-02-08T03:29:30.852057: step 2720, loss 0.050432, acc 0.984375
2020-02-08T03:29:30.972644: step 2721, loss 0.0313761, acc 0.984375
2020-02-08T03:29:31.090119: step 2722, loss 0.00592275, acc 1
2020-02-08T03:29:31.206659: step 2723, loss 0.0259282, acc 0.984375
2020-02-08T03:29:31.325787: step 2724, loss 0.0109729, acc 1
2020-02-08T03:29:31.439964: step 2725, loss 0.0530229, acc 0.984375
2020-02-08T03:29:31.563124: step 2726, loss 0.00734576, acc 1
2020-02-08T03:29:31.677143: step 2727, loss 0.00473083, acc 1
2020-02-08T03:29:31.793928: step 2728, loss 0.00561802, acc 1
2020-02-08T03:29:31.915083: step 2729, loss 0.072845, acc 0.96875
2020-02-08T03:29:32.034192: step 2730, loss 0.0101594, acc 1
2020-02-08T03:29:32.152328: step 2731, loss 0.019975, acc 1
2020-02-08T03:29:32.270900: step 2732, loss 0.0218492, acc 1
2020-02-08T03:29:32.386038: step 2733, loss 0.00573382, acc 1
2020-02-08T03:29:32.503083: step 2734, loss 0.0191888, acc 1
2020-02-08T03:29:32.621307: step 2735, loss 0.0486965, acc 0.984375
2020-02-08T03:29:32.735700: step 2736, loss 0.0145567, acc 1
2020-02-08T03:29:32.855960: step 2737, loss 0.00424741, acc 1
2020-02-08T03:29:32.970020: step 2738, loss 0.010951, acc 1
2020-02-08T03:29:33.084914: step 2739, loss 0.0450268, acc 0.984375
2020-02-08T03:29:33.203126: step 2740, loss 0.00279537, acc 1
2020-02-08T03:29:33.322482: step 2741, loss 0.0233435, acc 1
2020-02-08T03:29:33.439327: step 2742, loss 0.0293013, acc 1
2020-02-08T03:29:33.555502: step 2743, loss 0.0580195, acc 0.984375
2020-02-08T03:29:33.672450: step 2744, loss 0.0119008, acc 1
2020-02-08T03:29:33.789012: step 2745, loss 0.0118578, acc 1
2020-02-08T03:29:33.911790: step 2746, loss 0.014391, acc 1
2020-02-08T03:29:34.028835: step 2747, loss 0.0100585, acc 1
2020-02-08T03:29:34.145947: step 2748, loss 0.0166984, acc 1
2020-02-08T03:29:34.263917: step 2749, loss 0.0348995, acc 0.96875
2020-02-08T03:29:34.381978: step 2750, loss 0.0141589, acc 1
2020-02-08T03:29:34.498363: step 2751, loss 0.0185428, acc 0.984375
2020-02-08T03:29:34.617840: step 2752, loss 0.00402887, acc 1
2020-02-08T03:29:34.733732: step 2753, loss 0.00772415, acc 1
2020-02-08T03:29:34.852903: step 2754, loss 0.0383691, acc 0.984375
2020-02-08T03:29:34.970423: step 2755, loss 0.0337212, acc 0.984375
2020-02-08T03:29:35.086165: step 2756, loss 0.0407038, acc 0.984375
2020-02-08T03:29:35.203218: step 2757, loss 0.0142501, acc 1
2020-02-08T03:29:35.321015: step 2758, loss 0.0545908, acc 0.96875
2020-02-08T03:29:35.436854: step 2759, loss 0.00930706, acc 1
2020-02-08T03:29:35.554468: step 2760, loss 0.0131693, acc 1
2020-02-08T03:29:35.673372: step 2761, loss 0.0219584, acc 1
2020-02-08T03:29:35.788867: step 2762, loss 0.0187721, acc 1
2020-02-08T03:29:35.906885: step 2763, loss 0.0498667, acc 0.984375
2020-02-08T03:29:36.023785: step 2764, loss 0.0352715, acc 0.96875
2020-02-08T03:29:36.139912: step 2765, loss 0.0253388, acc 1
2020-02-08T03:29:36.257653: step 2766, loss 0.00659609, acc 1
2020-02-08T03:29:36.377235: step 2767, loss 0.0253584, acc 0.984375
2020-02-08T03:29:36.492774: step 2768, loss 0.0388535, acc 0.984375
2020-02-08T03:29:36.612581: step 2769, loss 0.00455686, acc 1
2020-02-08T03:29:36.729885: step 2770, loss 0.0339923, acc 1
2020-02-08T03:29:36.847110: step 2771, loss 0.0323782, acc 0.984375
2020-02-08T03:29:36.964692: step 2772, loss 0.0293572, acc 0.984375
2020-02-08T03:29:37.081487: step 2773, loss 0.024512, acc 0.984375
2020-02-08T03:29:37.197971: step 2774, loss 0.0206279, acc 0.984375
2020-02-08T03:29:37.314786: step 2775, loss 0.0214085, acc 1
2020-02-08T03:29:37.430777: step 2776, loss 0.00473182, acc 1
2020-02-08T03:29:37.546578: step 2777, loss 0.0135801, acc 1
2020-02-08T03:29:37.662115: step 2778, loss 0.0105756, acc 1
2020-02-08T03:29:37.776008: step 2779, loss 0.0364448, acc 0.984375
2020-02-08T03:29:37.894877: step 2780, loss 0.0435193, acc 0.984375
2020-02-08T03:29:38.011879: step 2781, loss 0.0144303, acc 1
2020-02-08T03:29:38.126883: step 2782, loss 0.016485, acc 1
2020-02-08T03:29:38.240841: step 2783, loss 0.0558532, acc 0.984375
2020-02-08T03:29:38.357966: step 2784, loss 0.0171481, acc 1
2020-02-08T03:29:38.476944: step 2785, loss 0.00938988, acc 1
2020-02-08T03:29:38.593664: step 2786, loss 0.0280279, acc 0.984375
2020-02-08T03:29:38.716073: step 2787, loss 0.0247756, acc 1
2020-02-08T03:29:38.834694: step 2788, loss 0.00399739, acc 1
2020-02-08T03:29:38.952590: step 2789, loss 0.0778861, acc 0.984375
2020-02-08T03:29:39.074014: step 2790, loss 0.0291339, acc 0.984375
2020-02-08T03:29:39.188070: step 2791, loss 0.0320019, acc 1
2020-02-08T03:29:39.301634: step 2792, loss 0.021599, acc 1
2020-02-08T03:29:39.417897: step 2793, loss 0.0154134, acc 0.984375
2020-02-08T03:29:39.534239: step 2794, loss 0.0199483, acc 1
2020-02-08T03:29:39.650318: step 2795, loss 0.00370215, acc 1
2020-02-08T03:29:39.768669: step 2796, loss 0.00339159, acc 1
2020-02-08T03:29:39.888023: step 2797, loss 0.0246963, acc 0.984375
2020-02-08T03:29:40.006953: step 2798, loss 0.0496195, acc 0.96875
2020-02-08T03:29:40.127791: step 2799, loss 0.0194282, acc 1
2020-02-08T03:29:40.245420: step 2800, loss 0.0728713, acc 0.96875

Evaluation:
2020-02-08T03:29:40.432983: step 2800, loss 1.01847, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2800

2020-02-08T03:29:41.951617: step 2801, loss 0.016904, acc 1
2020-02-08T03:29:42.070160: step 2802, loss 0.0153346, acc 1
2020-02-08T03:29:42.186977: step 2803, loss 0.0106239, acc 1
2020-02-08T03:29:42.302968: step 2804, loss 0.0357706, acc 0.984375
2020-02-08T03:29:42.420582: step 2805, loss 0.0116279, acc 1
2020-02-08T03:29:42.536925: step 2806, loss 0.0161011, acc 1
2020-02-08T03:29:42.651338: step 2807, loss 0.0286181, acc 0.984375
2020-02-08T03:29:42.766071: step 2808, loss 0.0614157, acc 0.984375
2020-02-08T03:29:42.885377: step 2809, loss 0.0314261, acc 0.984375
2020-02-08T03:29:43.000358: step 2810, loss 0.00714624, acc 1
2020-02-08T03:29:43.117175: step 2811, loss 0.0326501, acc 0.984375
2020-02-08T03:29:43.232287: step 2812, loss 0.0271839, acc 0.984375
2020-02-08T03:29:43.348580: step 2813, loss 0.00434072, acc 1
2020-02-08T03:29:43.467753: step 2814, loss 0.0142219, acc 1
2020-02-08T03:29:43.582685: step 2815, loss 0.0228797, acc 0.984375
2020-02-08T03:29:43.696922: step 2816, loss 0.0115771, acc 1
2020-02-08T03:29:43.817964: step 2817, loss 0.0519435, acc 0.984375
2020-02-08T03:29:43.937241: step 2818, loss 0.0536568, acc 0.96875
2020-02-08T03:29:44.053053: step 2819, loss 0.027385, acc 0.984375
2020-02-08T03:29:44.171067: step 2820, loss 0.0333438, acc 1
2020-02-08T03:29:44.284254: step 2821, loss 0.0182518, acc 1
2020-02-08T03:29:44.403014: step 2822, loss 0.00982233, acc 1
2020-02-08T03:29:44.521635: step 2823, loss 0.0124846, acc 1
2020-02-08T03:29:44.636717: step 2824, loss 0.0436518, acc 0.96875
2020-02-08T03:29:44.755638: step 2825, loss 0.0305216, acc 0.984375
2020-02-08T03:29:44.875727: step 2826, loss 0.0295672, acc 0.984375
2020-02-08T03:29:44.990026: step 2827, loss 0.0225005, acc 1
2020-02-08T03:29:45.106468: step 2828, loss 0.0124931, acc 1
2020-02-08T03:29:45.225202: step 2829, loss 0.0128031, acc 1
2020-02-08T03:29:45.341967: step 2830, loss 0.0374513, acc 0.984375
2020-02-08T03:29:45.460338: step 2831, loss 0.0563451, acc 0.984375
2020-02-08T03:29:45.580085: step 2832, loss 0.0225993, acc 1
2020-02-08T03:29:45.695972: step 2833, loss 0.00545633, acc 1
2020-02-08T03:29:45.813220: step 2834, loss 0.0164669, acc 1
2020-02-08T03:29:45.930970: step 2835, loss 0.0463179, acc 0.984375
2020-02-08T03:29:46.048047: step 2836, loss 0.0143956, acc 1
2020-02-08T03:29:46.164478: step 2837, loss 0.016914, acc 1
2020-02-08T03:29:46.285152: step 2838, loss 0.0215105, acc 0.984375
2020-02-08T03:29:46.404677: step 2839, loss 0.0144887, acc 1
2020-02-08T03:29:46.525462: step 2840, loss 0.0281434, acc 0.984375
2020-02-08T03:29:46.641566: step 2841, loss 0.0686589, acc 0.96875
2020-02-08T03:29:46.761587: step 2842, loss 0.013347, acc 1
2020-02-08T03:29:46.885457: step 2843, loss 0.0544826, acc 0.984375
2020-02-08T03:29:47.002494: step 2844, loss 0.0479956, acc 0.984375
2020-02-08T03:29:47.118207: step 2845, loss 0.0116815, acc 1
2020-02-08T03:29:47.234209: step 2846, loss 0.00892334, acc 1
2020-02-08T03:29:47.352084: step 2847, loss 0.0292463, acc 0.984375
2020-02-08T03:29:47.470190: step 2848, loss 0.0245129, acc 1
2020-02-08T03:29:47.588022: step 2849, loss 0.00437856, acc 1
2020-02-08T03:29:47.701187: step 2850, loss 0.00356484, acc 1
2020-02-08T03:29:47.822592: step 2851, loss 0.0447864, acc 0.984375
2020-02-08T03:29:47.939071: step 2852, loss 0.00425833, acc 1
2020-02-08T03:29:48.055428: step 2853, loss 0.0169195, acc 1
2020-02-08T03:29:48.172340: step 2854, loss 0.0111755, acc 1
2020-02-08T03:29:48.288712: step 2855, loss 0.00542471, acc 1
2020-02-08T03:29:48.407314: step 2856, loss 0.0366022, acc 0.984375
2020-02-08T03:29:48.523899: step 2857, loss 0.0156119, acc 0.984375
2020-02-08T03:29:48.639311: step 2858, loss 0.0146586, acc 1
2020-02-08T03:29:48.763316: step 2859, loss 0.0333479, acc 0.984375
2020-02-08T03:29:48.886312: step 2860, loss 0.00836415, acc 1
2020-02-08T03:29:49.003078: step 2861, loss 0.0251351, acc 1
2020-02-08T03:29:49.120822: step 2862, loss 0.027139, acc 0.984375
2020-02-08T03:29:49.234814: step 2863, loss 0.0702015, acc 0.96875
2020-02-08T03:29:49.350073: step 2864, loss 0.00326316, acc 1
2020-02-08T03:29:49.467943: step 2865, loss 0.0286484, acc 0.984375
2020-02-08T03:29:49.590754: step 2866, loss 0.0460868, acc 0.96875
2020-02-08T03:29:49.715413: step 2867, loss 0.00517507, acc 1
2020-02-08T03:29:49.838906: step 2868, loss 0.0171792, acc 0.984375
2020-02-08T03:29:49.964720: step 2869, loss 0.00565628, acc 1
2020-02-08T03:29:50.089324: step 2870, loss 0.00387694, acc 1
2020-02-08T03:29:50.215221: step 2871, loss 0.0475605, acc 0.984375
2020-02-08T03:29:50.337736: step 2872, loss 0.0315926, acc 0.984375
2020-02-08T03:29:50.456808: step 2873, loss 0.00929238, acc 1
2020-02-08T03:29:50.579395: step 2874, loss 0.007205, acc 1
2020-02-08T03:29:50.699538: step 2875, loss 0.0382159, acc 0.984375
2020-02-08T03:29:50.824293: step 2876, loss 0.00286054, acc 1
2020-02-08T03:29:50.942583: step 2877, loss 0.00336065, acc 1
2020-02-08T03:29:51.066222: step 2878, loss 0.0159353, acc 1
2020-02-08T03:29:51.183682: step 2879, loss 0.00405326, acc 1
2020-02-08T03:29:51.305619: step 2880, loss 0.0080398, acc 1
2020-02-08T03:29:51.423100: step 2881, loss 0.00679083, acc 1
2020-02-08T03:29:51.539644: step 2882, loss 0.0126086, acc 1
2020-02-08T03:29:51.672181: step 2883, loss 0.00978861, acc 1
2020-02-08T03:29:51.791016: step 2884, loss 0.00882858, acc 1
2020-02-08T03:29:51.912983: step 2885, loss 0.040613, acc 0.984375
2020-02-08T03:29:52.031781: step 2886, loss 0.0170618, acc 1
2020-02-08T03:29:52.147836: step 2887, loss 0.0135193, acc 1
2020-02-08T03:29:52.265198: step 2888, loss 0.00958193, acc 1
2020-02-08T03:29:52.383584: step 2889, loss 0.0202002, acc 0.984375
2020-02-08T03:29:52.500071: step 2890, loss 0.0239619, acc 0.984375
2020-02-08T03:29:52.618802: step 2891, loss 0.00587433, acc 1
2020-02-08T03:29:52.735760: step 2892, loss 0.00649485, acc 1
2020-02-08T03:29:52.857642: step 2893, loss 0.0486962, acc 0.984375
2020-02-08T03:29:52.976749: step 2894, loss 0.0241245, acc 1
2020-02-08T03:29:53.093828: step 2895, loss 0.0112799, acc 1
2020-02-08T03:29:53.210860: step 2896, loss 0.0266557, acc 1
2020-02-08T03:29:53.331571: step 2897, loss 0.00537057, acc 1
2020-02-08T03:29:53.447749: step 2898, loss 0.0216752, acc 1
2020-02-08T03:29:53.565567: step 2899, loss 0.00500247, acc 1
2020-02-08T03:29:53.684681: step 2900, loss 0.0110539, acc 1

Evaluation:
2020-02-08T03:29:53.875571: step 2900, loss 1.05957, acc 0.716698

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-2900

2020-02-08T03:29:55.716933: step 2901, loss 0.0098063, acc 1
2020-02-08T03:29:55.834761: step 2902, loss 0.00323744, acc 1
2020-02-08T03:29:55.951217: step 2903, loss 0.00783623, acc 1
2020-02-08T03:29:56.066369: step 2904, loss 0.0505133, acc 0.984375
2020-02-08T03:29:56.184071: step 2905, loss 0.049969, acc 0.984375
2020-02-08T03:29:56.295757: step 2906, loss 0.0102066, acc 1
2020-02-08T03:29:56.414232: step 2907, loss 0.00761524, acc 1
2020-02-08T03:29:56.530247: step 2908, loss 0.0793976, acc 0.96875
2020-02-08T03:29:56.646883: step 2909, loss 0.00376765, acc 1
2020-02-08T03:29:56.763749: step 2910, loss 0.011582, acc 1
2020-02-08T03:29:56.885376: step 2911, loss 0.0290372, acc 0.984375
2020-02-08T03:29:57.001120: step 2912, loss 0.0214093, acc 1
2020-02-08T03:29:57.118443: step 2913, loss 0.0116612, acc 1
2020-02-08T03:29:57.235691: step 2914, loss 0.00655567, acc 1
2020-02-08T03:29:57.351557: step 2915, loss 0.0167186, acc 1
2020-02-08T03:29:57.466746: step 2916, loss 0.014031, acc 1
2020-02-08T03:29:57.585384: step 2917, loss 0.0254492, acc 0.984375
2020-02-08T03:29:57.700716: step 2918, loss 0.0106203, acc 1
2020-02-08T03:29:57.818151: step 2919, loss 0.00756085, acc 1
2020-02-08T03:29:57.934094: step 2920, loss 0.0288705, acc 0.984375
2020-02-08T03:29:58.049913: step 2921, loss 0.00580243, acc 1
2020-02-08T03:29:58.165711: step 2922, loss 0.0248409, acc 1
2020-02-08T03:29:58.281305: step 2923, loss 0.0446534, acc 0.984375
2020-02-08T03:29:58.398095: step 2924, loss 0.0121166, acc 1
2020-02-08T03:29:58.509422: step 2925, loss 0.0189067, acc 1
2020-02-08T03:29:58.626412: step 2926, loss 0.0219524, acc 0.984375
2020-02-08T03:29:58.745510: step 2927, loss 0.0117658, acc 1
2020-02-08T03:29:58.868668: step 2928, loss 0.0182143, acc 1
2020-02-08T03:29:58.985547: step 2929, loss 0.0136842, acc 1
2020-02-08T03:29:59.115376: step 2930, loss 0.0269178, acc 1
2020-02-08T03:29:59.247731: step 2931, loss 0.0213688, acc 1
2020-02-08T03:29:59.378547: step 2932, loss 0.00746378, acc 1
2020-02-08T03:29:59.505989: step 2933, loss 0.00687946, acc 1
2020-02-08T03:29:59.648574: step 2934, loss 0.0088794, acc 1
2020-02-08T03:29:59.792676: step 2935, loss 0.0162531, acc 1
2020-02-08T03:29:59.971301: step 2936, loss 0.0296596, acc 0.984375
2020-02-08T03:30:00.090039: step 2937, loss 0.00786187, acc 1
2020-02-08T03:30:00.205895: step 2938, loss 0.0605658, acc 0.984375
2020-02-08T03:30:00.323329: step 2939, loss 0.0506661, acc 0.96875
2020-02-08T03:30:00.438604: step 2940, loss 0.0323905, acc 0.984375
2020-02-08T03:30:00.555773: step 2941, loss 0.0635173, acc 0.953125
2020-02-08T03:30:00.671111: step 2942, loss 0.00289258, acc 1
2020-02-08T03:30:00.789833: step 2943, loss 0.00883874, acc 1
2020-02-08T03:30:00.913379: step 2944, loss 0.00942456, acc 1
2020-02-08T03:30:01.031396: step 2945, loss 0.0230511, acc 1
2020-02-08T03:30:01.151013: step 2946, loss 0.00639427, acc 1
2020-02-08T03:30:01.269650: step 2947, loss 0.00279117, acc 1
2020-02-08T03:30:01.388013: step 2948, loss 0.00873303, acc 1
2020-02-08T03:30:01.506500: step 2949, loss 0.00953494, acc 1
2020-02-08T03:30:01.622147: step 2950, loss 0.00393371, acc 1
2020-02-08T03:30:01.740696: step 2951, loss 0.0212486, acc 1
2020-02-08T03:30:01.861132: step 2952, loss 0.0125763, acc 1
2020-02-08T03:30:01.974884: step 2953, loss 0.00234957, acc 1
2020-02-08T03:30:02.091917: step 2954, loss 0.00520783, acc 1
2020-02-08T03:30:02.213436: step 2955, loss 0.00784775, acc 1
2020-02-08T03:30:02.330735: step 2956, loss 0.00709372, acc 1
2020-02-08T03:30:02.447264: step 2957, loss 0.034323, acc 0.984375
2020-02-08T03:30:02.565321: step 2958, loss 0.0180268, acc 1
2020-02-08T03:30:02.681166: step 2959, loss 0.00276164, acc 1
2020-02-08T03:30:02.799975: step 2960, loss 0.008718, acc 1
2020-02-08T03:30:02.920350: step 2961, loss 0.00741225, acc 1
2020-02-08T03:30:03.034771: step 2962, loss 0.0472481, acc 0.984375
2020-02-08T03:30:03.160758: step 2963, loss 0.00726765, acc 1
2020-02-08T03:30:03.277494: step 2964, loss 0.0581391, acc 0.984375
2020-02-08T03:30:03.394793: step 2965, loss 0.00789028, acc 1
2020-02-08T03:30:03.513219: step 2966, loss 0.0105684, acc 1
2020-02-08T03:30:03.630214: step 2967, loss 0.0508234, acc 0.984375
2020-02-08T03:30:03.749151: step 2968, loss 0.0124944, acc 1
2020-02-08T03:30:03.871769: step 2969, loss 0.0471681, acc 0.984375
2020-02-08T03:30:03.989667: step 2970, loss 0.00497395, acc 1
2020-02-08T03:30:04.107778: step 2971, loss 0.0288144, acc 0.984375
2020-02-08T03:30:04.226177: step 2972, loss 0.00609395, acc 1
2020-02-08T03:30:04.345806: step 2973, loss 0.0125284, acc 1
2020-02-08T03:30:04.464945: step 2974, loss 0.0394823, acc 0.96875
2020-02-08T03:30:04.583132: step 2975, loss 0.0080134, acc 1
2020-02-08T03:30:04.699350: step 2976, loss 0.00441424, acc 1
2020-02-08T03:30:04.817396: step 2977, loss 0.006973, acc 1
2020-02-08T03:30:04.934138: step 2978, loss 0.0096268, acc 1
2020-02-08T03:30:05.051825: step 2979, loss 0.00523691, acc 1
2020-02-08T03:30:05.170633: step 2980, loss 0.038844, acc 0.984375
2020-02-08T03:30:05.290495: step 2981, loss 0.0599554, acc 0.96875
2020-02-08T03:30:05.407345: step 2982, loss 0.0502608, acc 0.984375
2020-02-08T03:30:05.522781: step 2983, loss 0.0233257, acc 0.984375
2020-02-08T03:30:05.639697: step 2984, loss 0.0092881, acc 1
2020-02-08T03:30:05.756958: step 2985, loss 0.0061625, acc 1
2020-02-08T03:30:05.878957: step 2986, loss 0.0131568, acc 1
2020-02-08T03:30:05.993642: step 2987, loss 0.0372747, acc 0.984375
2020-02-08T03:30:06.113449: step 2988, loss 0.0289454, acc 1
2020-02-08T03:30:06.232496: step 2989, loss 0.00808081, acc 1
2020-02-08T03:30:06.353772: step 2990, loss 0.0298873, acc 0.984375
2020-02-08T03:30:06.474930: step 2991, loss 0.00742681, acc 1
2020-02-08T03:30:06.591538: step 2992, loss 0.0115515, acc 1
2020-02-08T03:30:06.707156: step 2993, loss 0.0271533, acc 0.984375
2020-02-08T03:30:06.828009: step 2994, loss 0.0877804, acc 0.953125
2020-02-08T03:30:06.943863: step 2995, loss 0.0116985, acc 1
2020-02-08T03:30:07.058589: step 2996, loss 0.0288597, acc 0.984375
2020-02-08T03:30:07.176311: step 2997, loss 0.00304165, acc 1
2020-02-08T03:30:07.292527: step 2998, loss 0.0142186, acc 1
2020-02-08T03:30:07.413097: step 2999, loss 0.0236898, acc 1
2020-02-08T03:30:07.524791: step 3000, loss 0.00690463, acc 1

Evaluation:
2020-02-08T03:30:07.710747: step 3000, loss 1.08846, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581103400/checkpoints/model-3000

