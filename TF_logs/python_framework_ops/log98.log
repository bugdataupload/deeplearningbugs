WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 16:01:12.903151 4628032960 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 16:01:12.903364 4628032960 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 16:01:12.903469 4628032960 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0216 16:01:13.432369 4628032960 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0216 16:01:13.432741 4628032960 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-16 16:01:13.433067: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-16 16:01:13.447240: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd60e961a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-16 16:01:13.447262: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0216 16:01:13.447647 4628032960 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0216 16:01:13.451138 4628032960 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0216 16:01:13.462045 4628032960 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0216 16:01:13.472672 4628032960 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0216 16:01:13.496442 4628032960 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0216 16:01:13.504624 4628032960 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0216 16:01:13.504828 4628032960 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0216 16:01:13.515290 4628032960 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0216 16:01:13.517690 4628032960 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0216 16:01:13.543345 4628032960 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0216 16:01:13.775792 4628032960 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0216 16:01:13.776406 4628032960 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0216 16:01:13.785630 4628032960 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0216 16:01:13.807296 4628032960 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0216 16:01:13.808397 4628032960 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0216 16:01:13.824158 4628032960 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0216 16:01:13.825726 4628032960 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0216 16:01:13.846246 4628032960 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0216 16:01:13.847317 4628032960 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0216 16:01:13.862279 4628032960 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0216 16:01:13.863320 4628032960 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0216 16:01:13.880317 4628032960 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0216 16:01:13.882083 4628032960 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0216 16:01:13.899856 4628032960 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0216 16:01:13.900938 4628032960 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0216 16:01:13.915539 4628032960 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0216 16:01:13.916592 4628032960 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0216 16:01:13.936679 4628032960 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0216 16:01:13.938308 4628032960 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0216 16:01:13.953078 4628032960 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0216 16:01:13.954138 4628032960 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0216 16:01:13.957657 4628032960 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0216 16:01:15.223863 4628032960 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0216 16:01:15.224065 4628032960 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0216 16:01:15.342820 4628032960 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0216 16:01:15.923340 4628032960 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0216 16:02:53.002311 4628032960 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073

2020-02-16T16:01:15.922883: step 1, loss 2.47897, acc 0.5
2020-02-16T16:01:16.061602: step 2, loss 1.88479, acc 0.53125
2020-02-16T16:01:16.178683: step 3, loss 1.50996, acc 0.5625
2020-02-16T16:01:16.296657: step 4, loss 1.83803, acc 0.453125
2020-02-16T16:01:16.417561: step 5, loss 1.66587, acc 0.53125
2020-02-16T16:01:16.538575: step 6, loss 1.76382, acc 0.546875
2020-02-16T16:01:16.655762: step 7, loss 2.19855, acc 0.484375
2020-02-16T16:01:16.783158: step 8, loss 1.88439, acc 0.578125
2020-02-16T16:01:16.908982: step 9, loss 1.85263, acc 0.53125
2020-02-16T16:01:17.024566: step 10, loss 2.06888, acc 0.421875
2020-02-16T16:01:17.142597: step 11, loss 1.85766, acc 0.421875
2020-02-16T16:01:17.263548: step 12, loss 1.83049, acc 0.5
2020-02-16T16:01:17.380948: step 13, loss 2.17958, acc 0.53125
2020-02-16T16:01:17.512505: step 14, loss 1.52917, acc 0.5625
2020-02-16T16:01:17.665789: step 15, loss 1.52567, acc 0.515625
2020-02-16T16:01:17.854433: step 16, loss 1.73238, acc 0.453125
2020-02-16T16:01:18.024454: step 17, loss 1.63749, acc 0.546875
2020-02-16T16:01:18.196181: step 18, loss 2.20446, acc 0.375
2020-02-16T16:01:18.359076: step 19, loss 1.73404, acc 0.546875
2020-02-16T16:01:18.500962: step 20, loss 1.80626, acc 0.5625
2020-02-16T16:01:18.642942: step 21, loss 2.20717, acc 0.46875
2020-02-16T16:01:18.852819: step 22, loss 1.24128, acc 0.640625
2020-02-16T16:01:18.988332: step 23, loss 1.35282, acc 0.671875
2020-02-16T16:01:19.157746: step 24, loss 2.04189, acc 0.46875
2020-02-16T16:01:19.295239: step 25, loss 1.57906, acc 0.546875
2020-02-16T16:01:19.414920: step 26, loss 1.68025, acc 0.53125
2020-02-16T16:01:19.535963: step 27, loss 1.78342, acc 0.453125
2020-02-16T16:01:19.653235: step 28, loss 1.93831, acc 0.4375
2020-02-16T16:01:19.794654: step 29, loss 2.22561, acc 0.46875
2020-02-16T16:01:19.923810: step 30, loss 1.65543, acc 0.46875
2020-02-16T16:01:20.044671: step 31, loss 2.08697, acc 0.53125
2020-02-16T16:01:20.162729: step 32, loss 1.50283, acc 0.515625
2020-02-16T16:01:20.282432: step 33, loss 1.76919, acc 0.5
2020-02-16T16:01:20.399793: step 34, loss 1.5792, acc 0.5
2020-02-16T16:01:20.515224: step 35, loss 1.76419, acc 0.453125
2020-02-16T16:01:20.636465: step 36, loss 1.77289, acc 0.609375
2020-02-16T16:01:20.760403: step 37, loss 2.43284, acc 0.421875
2020-02-16T16:01:20.878176: step 38, loss 1.51436, acc 0.484375
2020-02-16T16:01:20.996684: step 39, loss 1.37193, acc 0.546875
2020-02-16T16:01:21.114668: step 40, loss 1.37056, acc 0.515625
2020-02-16T16:01:21.238185: step 41, loss 1.67171, acc 0.484375
2020-02-16T16:01:21.358286: step 42, loss 1.60279, acc 0.609375
2020-02-16T16:01:21.483521: step 43, loss 1.60744, acc 0.546875
2020-02-16T16:01:21.664842: step 44, loss 1.70951, acc 0.578125
2020-02-16T16:01:21.826256: step 45, loss 1.90516, acc 0.46875
2020-02-16T16:01:21.960748: step 46, loss 1.54296, acc 0.5
2020-02-16T16:01:22.109515: step 47, loss 1.44102, acc 0.53125
2020-02-16T16:01:22.275253: step 48, loss 1.79492, acc 0.5625
2020-02-16T16:01:22.431361: step 49, loss 1.7756, acc 0.453125
2020-02-16T16:01:22.576029: step 50, loss 2.24589, acc 0.421875
2020-02-16T16:01:22.704495: step 51, loss 2.3075, acc 0.390625
2020-02-16T16:01:22.837895: step 52, loss 1.5335, acc 0.46875
2020-02-16T16:01:22.997799: step 53, loss 1.67296, acc 0.4375
2020-02-16T16:01:23.220179: step 54, loss 1.4378, acc 0.546875
2020-02-16T16:01:23.567684: step 55, loss 1.65373, acc 0.53125
2020-02-16T16:01:23.762443: step 56, loss 1.99008, acc 0.546875
2020-02-16T16:01:23.927506: step 57, loss 2.04764, acc 0.375
2020-02-16T16:01:24.089217: step 58, loss 1.42844, acc 0.515625
2020-02-16T16:01:24.219082: step 59, loss 1.44934, acc 0.515625
2020-02-16T16:01:24.382495: step 60, loss 1.94911, acc 0.5
2020-02-16T16:01:24.517930: step 61, loss 1.63545, acc 0.484375
2020-02-16T16:01:24.642108: step 62, loss 1.81881, acc 0.546875
2020-02-16T16:01:24.768919: step 63, loss 1.58811, acc 0.46875
2020-02-16T16:01:24.906047: step 64, loss 1.16561, acc 0.59375
2020-02-16T16:01:25.037058: step 65, loss 1.36575, acc 0.578125
2020-02-16T16:01:25.172009: step 66, loss 1.19191, acc 0.578125
2020-02-16T16:01:25.334579: step 67, loss 1.48788, acc 0.546875
2020-02-16T16:01:25.460206: step 68, loss 1.88093, acc 0.390625
2020-02-16T16:01:25.603242: step 69, loss 1.35841, acc 0.515625
2020-02-16T16:01:25.737465: step 70, loss 1.63217, acc 0.453125
2020-02-16T16:01:25.878006: step 71, loss 1.43108, acc 0.515625
2020-02-16T16:01:26.331717: step 72, loss 1.68359, acc 0.5
2020-02-16T16:01:26.513937: step 73, loss 1.20695, acc 0.59375
2020-02-16T16:01:26.658920: step 74, loss 1.26053, acc 0.53125
2020-02-16T16:01:26.867399: step 75, loss 1.2238, acc 0.546875
2020-02-16T16:01:26.994670: step 76, loss 1.70236, acc 0.46875
2020-02-16T16:01:27.189630: step 77, loss 1.55674, acc 0.546875
2020-02-16T16:01:27.316966: step 78, loss 1.44312, acc 0.609375
2020-02-16T16:01:27.452074: step 79, loss 1.75934, acc 0.46875
2020-02-16T16:01:27.609476: step 80, loss 1.25134, acc 0.53125
2020-02-16T16:01:27.761554: step 81, loss 1.20335, acc 0.53125
2020-02-16T16:01:27.895625: step 82, loss 1.23953, acc 0.578125
2020-02-16T16:01:28.019676: step 83, loss 1.67778, acc 0.46875
2020-02-16T16:01:28.144137: step 84, loss 1.5115, acc 0.515625
2020-02-16T16:01:28.270302: step 85, loss 1.20834, acc 0.609375
2020-02-16T16:01:28.394542: step 86, loss 1.24967, acc 0.5625
2020-02-16T16:01:28.519615: step 87, loss 1.4175, acc 0.578125
2020-02-16T16:01:28.648473: step 88, loss 1.15241, acc 0.609375
2020-02-16T16:01:28.783707: step 89, loss 1.39958, acc 0.5625
2020-02-16T16:01:28.911171: step 90, loss 1.50501, acc 0.515625
2020-02-16T16:01:29.038640: step 91, loss 1.30913, acc 0.578125
2020-02-16T16:01:29.167756: step 92, loss 1.5476, acc 0.515625
2020-02-16T16:01:29.294553: step 93, loss 1.39895, acc 0.578125
2020-02-16T16:01:29.417861: step 94, loss 1.29317, acc 0.484375
2020-02-16T16:01:29.548660: step 95, loss 1.52493, acc 0.5
2020-02-16T16:01:29.671030: step 96, loss 1.21293, acc 0.5625
2020-02-16T16:01:29.807312: step 97, loss 1.52611, acc 0.546875
2020-02-16T16:01:29.932207: step 98, loss 1.42504, acc 0.5
2020-02-16T16:01:30.055129: step 99, loss 1.17511, acc 0.609375
2020-02-16T16:01:30.174422: step 100, loss 1.53072, acc 0.5

Evaluation:
2020-02-16T16:01:30.436649: step 100, loss 1.01477, acc 0.54409

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-100

2020-02-16T16:01:32.082781: step 101, loss 1.25359, acc 0.59375
2020-02-16T16:01:32.208798: step 102, loss 1.41415, acc 0.609375
2020-02-16T16:01:32.333339: step 103, loss 1.91459, acc 0.484375
2020-02-16T16:01:32.461069: step 104, loss 1.50206, acc 0.53125
2020-02-16T16:01:32.584691: step 105, loss 1.47347, acc 0.4375
2020-02-16T16:01:32.762198: step 106, loss 1.27975, acc 0.59375
2020-02-16T16:01:32.888530: step 107, loss 0.97359, acc 0.546875
2020-02-16T16:01:33.014208: step 108, loss 1.31798, acc 0.515625
2020-02-16T16:01:33.140016: step 109, loss 1.3874, acc 0.546875
2020-02-16T16:01:33.264737: step 110, loss 1.25319, acc 0.53125
2020-02-16T16:01:33.393026: step 111, loss 1.19506, acc 0.609375
2020-02-16T16:01:33.518191: step 112, loss 1.18667, acc 0.453125
2020-02-16T16:01:33.649312: step 113, loss 1.27004, acc 0.59375
2020-02-16T16:01:33.779751: step 114, loss 1.39017, acc 0.53125
2020-02-16T16:01:33.908916: step 115, loss 1.23159, acc 0.53125
2020-02-16T16:01:34.035478: step 116, loss 1.54005, acc 0.578125
2020-02-16T16:01:34.161311: step 117, loss 1.27564, acc 0.546875
2020-02-16T16:01:34.286849: step 118, loss 1.12928, acc 0.5
2020-02-16T16:01:34.412497: step 119, loss 1.38939, acc 0.5625
2020-02-16T16:01:34.541894: step 120, loss 1.2302, acc 0.578125
2020-02-16T16:01:34.698056: step 121, loss 1.42751, acc 0.515625
2020-02-16T16:01:34.870245: step 122, loss 1.20362, acc 0.625
2020-02-16T16:01:35.032745: step 123, loss 1.04804, acc 0.671875
2020-02-16T16:01:35.169009: step 124, loss 1.15618, acc 0.46875
2020-02-16T16:01:35.306015: step 125, loss 1.32517, acc 0.53125
2020-02-16T16:01:35.449664: step 126, loss 1.46945, acc 0.5
2020-02-16T16:01:35.579545: step 127, loss 1.24316, acc 0.5625
2020-02-16T16:01:35.773680: step 128, loss 1.43715, acc 0.453125
2020-02-16T16:01:35.912807: step 129, loss 1.16949, acc 0.5625
2020-02-16T16:01:36.113100: step 130, loss 1.22949, acc 0.609375
2020-02-16T16:01:36.267965: step 131, loss 1.06473, acc 0.546875
2020-02-16T16:01:36.403168: step 132, loss 1.54431, acc 0.40625
2020-02-16T16:01:36.576047: step 133, loss 1.22812, acc 0.484375
2020-02-16T16:01:36.717269: step 134, loss 0.986214, acc 0.609375
2020-02-16T16:01:36.856026: step 135, loss 1.44339, acc 0.515625
2020-02-16T16:01:36.983890: step 136, loss 1.01278, acc 0.59375
2020-02-16T16:01:37.110866: step 137, loss 1.1965, acc 0.5
2020-02-16T16:01:37.245503: step 138, loss 1.32841, acc 0.453125
2020-02-16T16:01:37.412733: step 139, loss 0.885979, acc 0.65625
2020-02-16T16:01:37.579832: step 140, loss 1.09149, acc 0.59375
2020-02-16T16:01:37.742132: step 141, loss 1.28281, acc 0.53125
2020-02-16T16:01:37.898363: step 142, loss 1.27429, acc 0.484375
2020-02-16T16:01:38.024461: step 143, loss 1.4039, acc 0.453125
2020-02-16T16:01:38.162077: step 144, loss 1.21241, acc 0.53125
2020-02-16T16:01:38.296579: step 145, loss 1.57293, acc 0.453125
2020-02-16T16:01:38.447798: step 146, loss 1.54704, acc 0.4375
2020-02-16T16:01:38.579060: step 147, loss 1.24698, acc 0.546875
2020-02-16T16:01:38.710136: step 148, loss 1.42444, acc 0.5
2020-02-16T16:01:38.877427: step 149, loss 1.63471, acc 0.4375
2020-02-16T16:01:39.016383: step 150, loss 0.925827, acc 0.566667
2020-02-16T16:01:39.296663: step 151, loss 1.03079, acc 0.578125
2020-02-16T16:01:39.576520: step 152, loss 1.06807, acc 0.578125
2020-02-16T16:01:39.891963: step 153, loss 1.22287, acc 0.5
2020-02-16T16:01:40.302899: step 154, loss 0.862064, acc 0.65625
2020-02-16T16:01:40.492926: step 155, loss 0.963268, acc 0.671875
2020-02-16T16:01:40.765277: step 156, loss 0.872289, acc 0.65625
2020-02-16T16:01:40.890685: step 157, loss 1.32034, acc 0.546875
2020-02-16T16:01:41.011753: step 158, loss 0.82771, acc 0.71875
2020-02-16T16:01:41.135565: step 159, loss 0.847948, acc 0.59375
2020-02-16T16:01:41.330049: step 160, loss 0.985573, acc 0.546875
2020-02-16T16:01:41.455784: step 161, loss 1.04595, acc 0.546875
2020-02-16T16:01:41.573112: step 162, loss 1.01822, acc 0.609375
2020-02-16T16:01:41.703034: step 163, loss 1.07559, acc 0.53125
2020-02-16T16:01:41.898401: step 164, loss 0.976772, acc 0.640625
2020-02-16T16:01:42.023617: step 165, loss 0.822111, acc 0.625
2020-02-16T16:01:42.143260: step 166, loss 1.05036, acc 0.59375
2020-02-16T16:01:42.262751: step 167, loss 1.05863, acc 0.53125
2020-02-16T16:01:42.383570: step 168, loss 0.816761, acc 0.671875
2020-02-16T16:01:42.516412: step 169, loss 0.913726, acc 0.578125
2020-02-16T16:01:42.644003: step 170, loss 0.810977, acc 0.609375
2020-02-16T16:01:42.771859: step 171, loss 0.762398, acc 0.65625
2020-02-16T16:01:42.892597: step 172, loss 0.973686, acc 0.609375
2020-02-16T16:01:43.012115: step 173, loss 1.19846, acc 0.515625
2020-02-16T16:01:43.142604: step 174, loss 1.12029, acc 0.53125
2020-02-16T16:01:43.268026: step 175, loss 1.09829, acc 0.5
2020-02-16T16:01:43.388963: step 176, loss 0.898678, acc 0.640625
2020-02-16T16:01:43.524499: step 177, loss 1.14443, acc 0.4375
2020-02-16T16:01:43.643379: step 178, loss 1.03958, acc 0.578125
2020-02-16T16:01:43.789533: step 179, loss 0.869815, acc 0.59375
2020-02-16T16:01:43.924001: step 180, loss 0.809703, acc 0.59375
2020-02-16T16:01:44.056298: step 181, loss 0.84694, acc 0.625
2020-02-16T16:01:44.176890: step 182, loss 0.913029, acc 0.625
2020-02-16T16:01:44.303700: step 183, loss 0.828454, acc 0.609375
2020-02-16T16:01:44.434302: step 184, loss 0.907303, acc 0.6875
2020-02-16T16:01:44.557386: step 185, loss 0.882609, acc 0.59375
2020-02-16T16:01:44.708913: step 186, loss 0.955896, acc 0.609375
2020-02-16T16:01:44.848413: step 187, loss 0.924467, acc 0.53125
2020-02-16T16:01:44.975498: step 188, loss 1.06981, acc 0.5625
2020-02-16T16:01:45.108190: step 189, loss 0.824374, acc 0.65625
2020-02-16T16:01:45.246651: step 190, loss 1.37458, acc 0.484375
2020-02-16T16:01:45.667428: step 191, loss 0.655387, acc 0.71875
2020-02-16T16:01:45.814741: step 192, loss 0.879766, acc 0.625
2020-02-16T16:01:45.950278: step 193, loss 0.972534, acc 0.546875
2020-02-16T16:01:46.067463: step 194, loss 0.895685, acc 0.625
2020-02-16T16:01:46.231376: step 195, loss 0.84676, acc 0.671875
2020-02-16T16:01:46.367066: step 196, loss 1.09291, acc 0.546875
2020-02-16T16:01:46.523568: step 197, loss 1.12507, acc 0.46875
2020-02-16T16:01:46.693698: step 198, loss 0.861776, acc 0.625
2020-02-16T16:01:46.831171: step 199, loss 0.893736, acc 0.578125
2020-02-16T16:01:46.991123: step 200, loss 0.623316, acc 0.6875

Evaluation:
2020-02-16T16:01:47.316013: step 200, loss 0.684299, acc 0.587242

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-200

2020-02-16T16:01:48.926824: step 201, loss 0.677049, acc 0.71875
2020-02-16T16:01:49.127224: step 202, loss 0.976665, acc 0.53125
2020-02-16T16:01:49.497997: step 203, loss 0.729009, acc 0.671875
2020-02-16T16:01:49.644950: step 204, loss 0.799109, acc 0.640625
2020-02-16T16:01:49.860598: step 205, loss 0.814225, acc 0.59375
2020-02-16T16:01:50.019676: step 206, loss 0.844103, acc 0.59375
2020-02-16T16:01:50.168937: step 207, loss 0.655583, acc 0.671875
2020-02-16T16:01:50.293757: step 208, loss 0.862856, acc 0.625
2020-02-16T16:01:50.470632: step 209, loss 0.853786, acc 0.609375
2020-02-16T16:01:50.596812: step 210, loss 0.819988, acc 0.59375
2020-02-16T16:01:50.721103: step 211, loss 0.759406, acc 0.625
2020-02-16T16:01:50.867949: step 212, loss 0.847545, acc 0.578125
2020-02-16T16:01:51.012565: step 213, loss 1.1283, acc 0.453125
2020-02-16T16:01:51.155408: step 214, loss 0.943365, acc 0.5625
2020-02-16T16:01:51.295318: step 215, loss 0.823302, acc 0.5625
2020-02-16T16:01:51.419711: step 216, loss 1.01008, acc 0.625
2020-02-16T16:01:51.542720: step 217, loss 0.859587, acc 0.53125
2020-02-16T16:01:51.676640: step 218, loss 0.81153, acc 0.609375
2020-02-16T16:01:51.817998: step 219, loss 1.03517, acc 0.546875
2020-02-16T16:01:51.937048: step 220, loss 0.723698, acc 0.6875
2020-02-16T16:01:52.056987: step 221, loss 0.966248, acc 0.53125
2020-02-16T16:01:52.176491: step 222, loss 0.820346, acc 0.6875
2020-02-16T16:01:52.301544: step 223, loss 1.03206, acc 0.578125
2020-02-16T16:01:52.437952: step 224, loss 1.01815, acc 0.53125
2020-02-16T16:01:52.563850: step 225, loss 0.974622, acc 0.546875
2020-02-16T16:01:52.687220: step 226, loss 0.978056, acc 0.515625
2020-02-16T16:01:52.838506: step 227, loss 0.810983, acc 0.59375
2020-02-16T16:01:52.969632: step 228, loss 0.827304, acc 0.578125
2020-02-16T16:01:53.100863: step 229, loss 0.826653, acc 0.640625
2020-02-16T16:01:53.550213: step 230, loss 0.655653, acc 0.640625
2020-02-16T16:01:53.775767: step 231, loss 0.774479, acc 0.640625
2020-02-16T16:01:53.910901: step 232, loss 0.960227, acc 0.53125
2020-02-16T16:01:54.033689: step 233, loss 0.788374, acc 0.578125
2020-02-16T16:01:54.153889: step 234, loss 0.615873, acc 0.703125
2020-02-16T16:01:54.337038: step 235, loss 0.814726, acc 0.640625
2020-02-16T16:01:54.482708: step 236, loss 0.869506, acc 0.59375
2020-02-16T16:01:54.606116: step 237, loss 0.961218, acc 0.59375
2020-02-16T16:01:54.741257: step 238, loss 0.792752, acc 0.625
2020-02-16T16:01:54.913201: step 239, loss 0.760273, acc 0.609375
2020-02-16T16:01:55.050904: step 240, loss 1.031, acc 0.5
2020-02-16T16:01:55.183366: step 241, loss 0.904431, acc 0.484375
2020-02-16T16:01:55.356839: step 242, loss 1.07292, acc 0.59375
2020-02-16T16:01:55.480667: step 243, loss 0.788619, acc 0.640625
2020-02-16T16:01:55.611906: step 244, loss 0.832722, acc 0.5625
2020-02-16T16:01:55.744338: step 245, loss 0.710006, acc 0.65625
2020-02-16T16:01:55.875616: step 246, loss 0.835825, acc 0.515625
2020-02-16T16:01:56.016788: step 247, loss 0.732045, acc 0.59375
2020-02-16T16:01:56.143542: step 248, loss 0.927849, acc 0.578125
2020-02-16T16:01:56.264568: step 249, loss 1.08262, acc 0.484375
2020-02-16T16:01:56.383195: step 250, loss 0.849069, acc 0.53125
2020-02-16T16:01:56.523452: step 251, loss 0.744671, acc 0.609375
2020-02-16T16:01:56.670886: step 252, loss 0.838603, acc 0.609375
2020-02-16T16:01:56.810573: step 253, loss 0.750287, acc 0.6875
2020-02-16T16:01:56.932121: step 254, loss 0.787381, acc 0.59375
2020-02-16T16:01:57.096869: step 255, loss 0.797871, acc 0.609375
2020-02-16T16:01:57.233814: step 256, loss 1.05497, acc 0.515625
2020-02-16T16:01:57.363471: step 257, loss 1.04817, acc 0.46875
2020-02-16T16:01:57.488901: step 258, loss 0.981355, acc 0.453125
2020-02-16T16:01:57.615556: step 259, loss 0.923589, acc 0.5625
2020-02-16T16:01:57.750572: step 260, loss 1.07852, acc 0.5625
2020-02-16T16:01:57.887741: step 261, loss 1.03847, acc 0.59375
2020-02-16T16:01:58.009758: step 262, loss 1.01722, acc 0.53125
2020-02-16T16:01:58.140109: step 263, loss 0.652122, acc 0.65625
2020-02-16T16:01:58.335223: step 264, loss 0.934063, acc 0.609375
2020-02-16T16:01:58.469246: step 265, loss 1.02092, acc 0.59375
2020-02-16T16:01:58.588799: step 266, loss 0.835035, acc 0.5625
2020-02-16T16:01:58.707039: step 267, loss 0.820419, acc 0.5625
2020-02-16T16:01:58.837821: step 268, loss 0.806062, acc 0.59375
2020-02-16T16:01:58.979419: step 269, loss 0.766249, acc 0.59375
2020-02-16T16:01:59.172362: step 270, loss 0.766298, acc 0.625
2020-02-16T16:01:59.360876: step 271, loss 0.689816, acc 0.671875
2020-02-16T16:01:59.483095: step 272, loss 0.789864, acc 0.578125
2020-02-16T16:01:59.667433: step 273, loss 0.772824, acc 0.640625
2020-02-16T16:01:59.889544: step 274, loss 0.673703, acc 0.640625
2020-02-16T16:02:00.072791: step 275, loss 0.786566, acc 0.6875
2020-02-16T16:02:00.239358: step 276, loss 0.880168, acc 0.578125
2020-02-16T16:02:00.363819: step 277, loss 0.732095, acc 0.578125
2020-02-16T16:02:00.499835: step 278, loss 0.944528, acc 0.578125
2020-02-16T16:02:00.665944: step 279, loss 0.872728, acc 0.5625
2020-02-16T16:02:00.812915: step 280, loss 0.748134, acc 0.65625
2020-02-16T16:02:00.938561: step 281, loss 0.886377, acc 0.53125
2020-02-16T16:02:01.079807: step 282, loss 0.659415, acc 0.703125
2020-02-16T16:02:01.270552: step 283, loss 0.738166, acc 0.609375
2020-02-16T16:02:01.391488: step 284, loss 0.749595, acc 0.609375
2020-02-16T16:02:01.559919: step 285, loss 0.825198, acc 0.546875
2020-02-16T16:02:01.677001: step 286, loss 0.59838, acc 0.71875
2020-02-16T16:02:01.852126: step 287, loss 0.744996, acc 0.65625
2020-02-16T16:02:02.003163: step 288, loss 0.746352, acc 0.6875
2020-02-16T16:02:02.138825: step 289, loss 0.750041, acc 0.59375
2020-02-16T16:02:02.274269: step 290, loss 0.81537, acc 0.5625
2020-02-16T16:02:02.395908: step 291, loss 0.873643, acc 0.546875
2020-02-16T16:02:02.540282: step 292, loss 0.856216, acc 0.640625
2020-02-16T16:02:02.701420: step 293, loss 0.717579, acc 0.640625
2020-02-16T16:02:02.868619: step 294, loss 0.806981, acc 0.625
2020-02-16T16:02:02.997696: step 295, loss 0.872749, acc 0.640625
2020-02-16T16:02:03.114119: step 296, loss 0.731485, acc 0.703125
2020-02-16T16:02:03.237798: step 297, loss 0.7452, acc 0.59375
2020-02-16T16:02:03.363330: step 298, loss 0.809918, acc 0.59375
2020-02-16T16:02:03.492120: step 299, loss 0.740644, acc 0.625
2020-02-16T16:02:03.613617: step 300, loss 0.579557, acc 0.716667

Evaluation:
2020-02-16T16:02:03.824925: step 300, loss 0.646226, acc 0.616323

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-300

2020-02-16T16:02:05.387634: step 301, loss 0.690331, acc 0.625
2020-02-16T16:02:05.506851: step 302, loss 0.737527, acc 0.578125
2020-02-16T16:02:05.622563: step 303, loss 0.829827, acc 0.578125
2020-02-16T16:02:05.748010: step 304, loss 0.646752, acc 0.671875
2020-02-16T16:02:05.878240: step 305, loss 0.721681, acc 0.578125
2020-02-16T16:02:06.010345: step 306, loss 0.473201, acc 0.78125
2020-02-16T16:02:06.134990: step 307, loss 0.686703, acc 0.734375
2020-02-16T16:02:06.260123: step 308, loss 0.574602, acc 0.71875
2020-02-16T16:02:06.381479: step 309, loss 0.557438, acc 0.6875
2020-02-16T16:02:06.500110: step 310, loss 0.899451, acc 0.59375
2020-02-16T16:02:06.616871: step 311, loss 0.713974, acc 0.671875
2020-02-16T16:02:06.745396: step 312, loss 0.679718, acc 0.703125
2020-02-16T16:02:06.942598: step 313, loss 0.651902, acc 0.6875
2020-02-16T16:02:07.065712: step 314, loss 0.633724, acc 0.703125
2020-02-16T16:02:07.190228: step 315, loss 0.773259, acc 0.609375
2020-02-16T16:02:07.313197: step 316, loss 0.651435, acc 0.671875
2020-02-16T16:02:07.478228: step 317, loss 0.575368, acc 0.75
2020-02-16T16:02:07.617132: step 318, loss 0.485722, acc 0.765625
2020-02-16T16:02:07.746597: step 319, loss 0.754077, acc 0.609375
2020-02-16T16:02:07.869072: step 320, loss 0.741907, acc 0.59375
2020-02-16T16:02:07.990064: step 321, loss 0.600695, acc 0.734375
2020-02-16T16:02:08.125513: step 322, loss 0.679531, acc 0.703125
2020-02-16T16:02:08.301779: step 323, loss 0.742607, acc 0.609375
2020-02-16T16:02:08.468384: step 324, loss 0.685627, acc 0.578125
2020-02-16T16:02:08.596160: step 325, loss 0.590364, acc 0.671875
2020-02-16T16:02:08.719320: step 326, loss 0.573499, acc 0.734375
2020-02-16T16:02:08.848224: step 327, loss 0.59621, acc 0.6875
2020-02-16T16:02:08.965278: step 328, loss 0.843438, acc 0.59375
2020-02-16T16:02:09.093731: step 329, loss 0.723348, acc 0.640625
2020-02-16T16:02:09.218726: step 330, loss 0.732341, acc 0.59375
2020-02-16T16:02:09.342776: step 331, loss 0.708347, acc 0.671875
2020-02-16T16:02:09.462223: step 332, loss 0.633155, acc 0.65625
2020-02-16T16:02:09.579976: step 333, loss 0.665426, acc 0.609375
2020-02-16T16:02:09.699105: step 334, loss 0.697214, acc 0.703125
2020-02-16T16:02:09.824367: step 335, loss 0.612591, acc 0.703125
2020-02-16T16:02:09.939951: step 336, loss 0.58299, acc 0.734375
2020-02-16T16:02:10.061488: step 337, loss 0.671322, acc 0.640625
2020-02-16T16:02:10.183087: step 338, loss 0.792973, acc 0.640625
2020-02-16T16:02:10.302501: step 339, loss 0.5866, acc 0.71875
2020-02-16T16:02:10.419304: step 340, loss 0.68695, acc 0.71875
2020-02-16T16:02:10.539831: step 341, loss 0.578013, acc 0.65625
2020-02-16T16:02:10.658436: step 342, loss 0.613441, acc 0.6875
2020-02-16T16:02:10.794098: step 343, loss 0.619463, acc 0.6875
2020-02-16T16:02:10.913028: step 344, loss 0.720765, acc 0.609375
2020-02-16T16:02:11.042054: step 345, loss 0.612613, acc 0.609375
2020-02-16T16:02:11.209450: step 346, loss 0.671497, acc 0.6875
2020-02-16T16:02:11.338728: step 347, loss 0.578228, acc 0.734375
2020-02-16T16:02:11.462238: step 348, loss 0.572454, acc 0.671875
2020-02-16T16:02:11.592738: step 349, loss 0.579236, acc 0.6875
2020-02-16T16:02:11.782472: step 350, loss 0.644553, acc 0.703125
2020-02-16T16:02:11.909524: step 351, loss 0.631243, acc 0.75
2020-02-16T16:02:12.074261: step 352, loss 0.750403, acc 0.625
2020-02-16T16:02:12.223510: step 353, loss 0.684358, acc 0.671875
2020-02-16T16:02:12.346702: step 354, loss 0.634389, acc 0.703125
2020-02-16T16:02:12.523205: step 355, loss 0.560427, acc 0.703125
2020-02-16T16:02:12.645151: step 356, loss 0.560003, acc 0.6875
2020-02-16T16:02:12.770909: step 357, loss 0.66779, acc 0.59375
2020-02-16T16:02:12.894022: step 358, loss 0.598484, acc 0.71875
2020-02-16T16:02:13.013601: step 359, loss 0.772677, acc 0.625
2020-02-16T16:02:13.144668: step 360, loss 0.64846, acc 0.609375
2020-02-16T16:02:13.288355: step 361, loss 0.619664, acc 0.640625
2020-02-16T16:02:13.476728: step 362, loss 0.651068, acc 0.671875
2020-02-16T16:02:13.599552: step 363, loss 0.786862, acc 0.546875
2020-02-16T16:02:13.719923: step 364, loss 0.779019, acc 0.609375
2020-02-16T16:02:13.847307: step 365, loss 0.587286, acc 0.671875
2020-02-16T16:02:13.966118: step 366, loss 0.59023, acc 0.75
2020-02-16T16:02:14.100184: step 367, loss 0.51367, acc 0.78125
2020-02-16T16:02:14.229152: step 368, loss 0.672742, acc 0.6875
2020-02-16T16:02:14.392758: step 369, loss 0.627766, acc 0.671875
2020-02-16T16:02:14.547296: step 370, loss 0.554787, acc 0.671875
2020-02-16T16:02:14.671722: step 371, loss 0.75405, acc 0.703125
2020-02-16T16:02:14.903494: step 372, loss 0.585589, acc 0.609375
2020-02-16T16:02:15.025254: step 373, loss 0.568714, acc 0.703125
2020-02-16T16:02:15.144657: step 374, loss 0.882859, acc 0.53125
2020-02-16T16:02:15.265592: step 375, loss 0.59538, acc 0.765625
2020-02-16T16:02:15.390759: step 376, loss 0.599085, acc 0.71875
2020-02-16T16:02:15.518133: step 377, loss 0.677361, acc 0.671875
2020-02-16T16:02:15.646151: step 378, loss 0.61274, acc 0.703125
2020-02-16T16:02:15.772430: step 379, loss 0.679625, acc 0.578125
2020-02-16T16:02:15.891799: step 380, loss 0.555469, acc 0.671875
2020-02-16T16:02:16.009986: step 381, loss 0.895569, acc 0.609375
2020-02-16T16:02:16.125267: step 382, loss 0.651132, acc 0.6875
2020-02-16T16:02:16.246315: step 383, loss 0.5352, acc 0.8125
2020-02-16T16:02:16.390212: step 384, loss 0.744727, acc 0.640625
2020-02-16T16:02:16.548353: step 385, loss 0.850984, acc 0.546875
2020-02-16T16:02:16.666912: step 386, loss 0.81715, acc 0.578125
2020-02-16T16:02:16.803410: step 387, loss 0.523161, acc 0.78125
2020-02-16T16:02:16.987727: step 388, loss 0.668435, acc 0.671875
2020-02-16T16:02:17.116090: step 389, loss 0.659111, acc 0.640625
2020-02-16T16:02:17.253770: step 390, loss 0.651417, acc 0.6875
2020-02-16T16:02:17.392245: step 391, loss 0.670092, acc 0.671875
2020-02-16T16:02:17.518454: step 392, loss 0.631081, acc 0.65625
2020-02-16T16:02:17.654653: step 393, loss 0.719429, acc 0.625
2020-02-16T16:02:17.812548: step 394, loss 0.881632, acc 0.5625
2020-02-16T16:02:17.939066: step 395, loss 0.791845, acc 0.5625
2020-02-16T16:02:18.065088: step 396, loss 0.662745, acc 0.609375
2020-02-16T16:02:18.199972: step 397, loss 0.61278, acc 0.75
2020-02-16T16:02:18.352814: step 398, loss 0.577598, acc 0.734375
2020-02-16T16:02:18.517493: step 399, loss 0.662059, acc 0.640625
2020-02-16T16:02:18.658437: step 400, loss 0.626032, acc 0.71875

Evaluation:
2020-02-16T16:02:18.923640: step 400, loss 0.674279, acc 0.58349

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-400

2020-02-16T16:02:20.518313: step 401, loss 0.573685, acc 0.734375
2020-02-16T16:02:20.691201: step 402, loss 0.625512, acc 0.671875
2020-02-16T16:02:20.869867: step 403, loss 0.642515, acc 0.671875
2020-02-16T16:02:21.010504: step 404, loss 0.701354, acc 0.609375
2020-02-16T16:02:21.140016: step 405, loss 0.645189, acc 0.671875
2020-02-16T16:02:21.269233: step 406, loss 0.613775, acc 0.671875
2020-02-16T16:02:21.403593: step 407, loss 0.704751, acc 0.703125
2020-02-16T16:02:21.536410: step 408, loss 0.748761, acc 0.59375
2020-02-16T16:02:21.681805: step 409, loss 0.754209, acc 0.59375
2020-02-16T16:02:21.823290: step 410, loss 0.888873, acc 0.53125
2020-02-16T16:02:21.963647: step 411, loss 0.53112, acc 0.6875
2020-02-16T16:02:22.101092: step 412, loss 0.640111, acc 0.671875
2020-02-16T16:02:22.251291: step 413, loss 0.605741, acc 0.640625
2020-02-16T16:02:22.462763: step 414, loss 0.608074, acc 0.71875
2020-02-16T16:02:22.825816: step 415, loss 0.69535, acc 0.671875
2020-02-16T16:02:22.977480: step 416, loss 0.70399, acc 0.65625
2020-02-16T16:02:23.146045: step 417, loss 0.524293, acc 0.671875
2020-02-16T16:02:23.312393: step 418, loss 0.641212, acc 0.640625
2020-02-16T16:02:23.456195: step 419, loss 0.618626, acc 0.625
2020-02-16T16:02:23.579515: step 420, loss 0.662659, acc 0.625
2020-02-16T16:02:23.711550: step 421, loss 0.688381, acc 0.609375
2020-02-16T16:02:23.869015: step 422, loss 0.557442, acc 0.703125
2020-02-16T16:02:24.014646: step 423, loss 0.629216, acc 0.6875
2020-02-16T16:02:24.147824: step 424, loss 0.65911, acc 0.578125
2020-02-16T16:02:24.269375: step 425, loss 0.583802, acc 0.71875
2020-02-16T16:02:24.392203: step 426, loss 0.641052, acc 0.703125
2020-02-16T16:02:24.517636: step 427, loss 0.595797, acc 0.703125
2020-02-16T16:02:24.643523: step 428, loss 0.564644, acc 0.703125
2020-02-16T16:02:24.797508: step 429, loss 0.608977, acc 0.78125
2020-02-16T16:02:24.978348: step 430, loss 0.571143, acc 0.734375
2020-02-16T16:02:25.108032: step 431, loss 0.660722, acc 0.625
2020-02-16T16:02:25.232681: step 432, loss 0.537249, acc 0.78125
2020-02-16T16:02:25.357549: step 433, loss 0.690258, acc 0.65625
2020-02-16T16:02:25.487977: step 434, loss 0.688685, acc 0.578125
2020-02-16T16:02:25.660574: step 435, loss 0.700746, acc 0.71875
2020-02-16T16:02:25.856658: step 436, loss 0.573277, acc 0.71875
2020-02-16T16:02:25.979025: step 437, loss 0.745939, acc 0.578125
2020-02-16T16:02:26.100115: step 438, loss 0.508669, acc 0.796875
2020-02-16T16:02:26.217941: step 439, loss 0.620274, acc 0.640625
2020-02-16T16:02:26.367021: step 440, loss 0.690375, acc 0.640625
2020-02-16T16:02:26.519483: step 441, loss 0.652292, acc 0.625
2020-02-16T16:02:26.639294: step 442, loss 0.736792, acc 0.671875
2020-02-16T16:02:26.765471: step 443, loss 0.620555, acc 0.65625
2020-02-16T16:02:26.885745: step 444, loss 0.637302, acc 0.671875
2020-02-16T16:02:27.009027: step 445, loss 0.55688, acc 0.6875
2020-02-16T16:02:27.139958: step 446, loss 0.603245, acc 0.65625
2020-02-16T16:02:27.303016: step 447, loss 0.668622, acc 0.625
2020-02-16T16:02:27.469838: step 448, loss 0.855623, acc 0.5625
2020-02-16T16:02:27.596346: step 449, loss 0.729885, acc 0.578125
2020-02-16T16:02:27.713896: step 450, loss 0.690744, acc 0.6
2020-02-16T16:02:27.845221: step 451, loss 0.768493, acc 0.5625
2020-02-16T16:02:27.967667: step 452, loss 0.522496, acc 0.828125
2020-02-16T16:02:28.103731: step 453, loss 0.611683, acc 0.671875
2020-02-16T16:02:28.230065: step 454, loss 0.573833, acc 0.671875
2020-02-16T16:02:28.354265: step 455, loss 0.549216, acc 0.765625
2020-02-16T16:02:28.472249: step 456, loss 0.579301, acc 0.703125
2020-02-16T16:02:28.590161: step 457, loss 0.480331, acc 0.765625
2020-02-16T16:02:28.704815: step 458, loss 0.538154, acc 0.6875
2020-02-16T16:02:28.833015: step 459, loss 0.588708, acc 0.734375
2020-02-16T16:02:28.953474: step 460, loss 0.56747, acc 0.6875
2020-02-16T16:02:29.070970: step 461, loss 0.486129, acc 0.734375
2020-02-16T16:02:29.245814: step 462, loss 0.624325, acc 0.703125
2020-02-16T16:02:29.421657: step 463, loss 0.511289, acc 0.765625
2020-02-16T16:02:29.589347: step 464, loss 0.515645, acc 0.734375
2020-02-16T16:02:29.766980: step 465, loss 0.544436, acc 0.796875
2020-02-16T16:02:29.922239: step 466, loss 0.569419, acc 0.703125
2020-02-16T16:02:30.045914: step 467, loss 0.518131, acc 0.703125
2020-02-16T16:02:30.163057: step 468, loss 0.573695, acc 0.6875
2020-02-16T16:02:30.282134: step 469, loss 0.48411, acc 0.75
2020-02-16T16:02:30.402865: step 470, loss 0.572755, acc 0.71875
2020-02-16T16:02:30.532029: step 471, loss 0.525837, acc 0.703125
2020-02-16T16:02:30.821001: step 472, loss 0.619631, acc 0.71875
2020-02-16T16:02:30.950769: step 473, loss 0.664163, acc 0.609375
2020-02-16T16:02:31.067604: step 474, loss 0.578459, acc 0.703125
2020-02-16T16:02:31.184621: step 475, loss 0.651505, acc 0.671875
2020-02-16T16:02:31.308092: step 476, loss 0.6208, acc 0.734375
2020-02-16T16:02:31.481670: step 477, loss 0.627071, acc 0.671875
2020-02-16T16:02:31.621611: step 478, loss 0.608566, acc 0.65625
2020-02-16T16:02:31.742954: step 479, loss 0.452305, acc 0.84375
2020-02-16T16:02:31.864513: step 480, loss 0.570189, acc 0.671875
2020-02-16T16:02:31.983068: step 481, loss 0.60859, acc 0.6875
2020-02-16T16:02:32.110286: step 482, loss 0.48266, acc 0.75
2020-02-16T16:02:32.240173: step 483, loss 0.67344, acc 0.71875
2020-02-16T16:02:32.366815: step 484, loss 0.641398, acc 0.671875
2020-02-16T16:02:32.484135: step 485, loss 0.589491, acc 0.765625
2020-02-16T16:02:32.602087: step 486, loss 0.638625, acc 0.640625
2020-02-16T16:02:32.771479: step 487, loss 0.659101, acc 0.59375
2020-02-16T16:02:32.938546: step 488, loss 0.638798, acc 0.671875
2020-02-16T16:02:33.075186: step 489, loss 0.666838, acc 0.640625
2020-02-16T16:02:33.222792: step 490, loss 0.474899, acc 0.796875
2020-02-16T16:02:33.346482: step 491, loss 0.422402, acc 0.828125
2020-02-16T16:02:33.551794: step 492, loss 0.564778, acc 0.734375
2020-02-16T16:02:33.685826: step 493, loss 0.656594, acc 0.671875
2020-02-16T16:02:33.869652: step 494, loss 0.414011, acc 0.8125
2020-02-16T16:02:34.005832: step 495, loss 0.620585, acc 0.6875
2020-02-16T16:02:34.123834: step 496, loss 0.493932, acc 0.734375
2020-02-16T16:02:34.272408: step 497, loss 0.528209, acc 0.78125
2020-02-16T16:02:34.431854: step 498, loss 0.537906, acc 0.71875
2020-02-16T16:02:34.552705: step 499, loss 0.674958, acc 0.578125
2020-02-16T16:02:34.680947: step 500, loss 0.614799, acc 0.6875

Evaluation:
2020-02-16T16:02:35.027787: step 500, loss 0.623929, acc 0.630394

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-500

2020-02-16T16:02:36.651727: step 501, loss 0.536652, acc 0.734375
2020-02-16T16:02:37.072791: step 502, loss 0.669717, acc 0.6875
2020-02-16T16:02:37.212607: step 503, loss 0.60971, acc 0.6875
2020-02-16T16:02:37.342350: step 504, loss 0.553972, acc 0.703125
2020-02-16T16:02:37.520461: step 505, loss 0.607343, acc 0.609375
2020-02-16T16:02:37.649466: step 506, loss 0.709974, acc 0.625
2020-02-16T16:02:37.801537: step 507, loss 0.470184, acc 0.78125
2020-02-16T16:02:37.945881: step 508, loss 0.544859, acc 0.65625
2020-02-16T16:02:38.124986: step 509, loss 0.571155, acc 0.703125
2020-02-16T16:02:38.271536: step 510, loss 0.668181, acc 0.640625
2020-02-16T16:02:38.390644: step 511, loss 0.61903, acc 0.6875
2020-02-16T16:02:38.547136: step 512, loss 0.585211, acc 0.671875
2020-02-16T16:02:38.697734: step 513, loss 0.561076, acc 0.703125
2020-02-16T16:02:38.831230: step 514, loss 0.566261, acc 0.71875
2020-02-16T16:02:39.009812: step 515, loss 0.660447, acc 0.625
2020-02-16T16:02:39.135008: step 516, loss 0.470129, acc 0.75
2020-02-16T16:02:39.254014: step 517, loss 0.54541, acc 0.75
2020-02-16T16:02:39.371699: step 518, loss 0.439322, acc 0.765625
2020-02-16T16:02:39.493952: step 519, loss 0.579724, acc 0.6875
2020-02-16T16:02:39.632281: step 520, loss 0.656767, acc 0.640625
2020-02-16T16:02:39.781478: step 521, loss 0.61305, acc 0.671875
2020-02-16T16:02:39.916831: step 522, loss 0.491951, acc 0.75
2020-02-16T16:02:40.053318: step 523, loss 0.567295, acc 0.71875
2020-02-16T16:02:40.175066: step 524, loss 0.590818, acc 0.671875
2020-02-16T16:02:40.304107: step 525, loss 0.548169, acc 0.71875
2020-02-16T16:02:40.444026: step 526, loss 0.534668, acc 0.75
2020-02-16T16:02:40.564912: step 527, loss 0.450098, acc 0.8125
2020-02-16T16:02:40.682352: step 528, loss 0.525904, acc 0.796875
2020-02-16T16:02:40.809372: step 529, loss 0.549333, acc 0.71875
2020-02-16T16:02:40.928479: step 530, loss 0.530188, acc 0.71875
2020-02-16T16:02:41.045821: step 531, loss 0.560966, acc 0.75
2020-02-16T16:02:41.164411: step 532, loss 0.483657, acc 0.796875
2020-02-16T16:02:41.284418: step 533, loss 0.581055, acc 0.671875
2020-02-16T16:02:41.405230: step 534, loss 0.647351, acc 0.640625
2020-02-16T16:02:41.523714: step 535, loss 0.52031, acc 0.71875
2020-02-16T16:02:41.649624: step 536, loss 0.657143, acc 0.609375
2020-02-16T16:02:41.813789: step 537, loss 0.461033, acc 0.75
2020-02-16T16:02:41.967146: step 538, loss 0.560603, acc 0.734375
2020-02-16T16:02:42.121922: step 539, loss 0.643403, acc 0.609375
2020-02-16T16:02:42.273464: step 540, loss 0.629783, acc 0.671875
2020-02-16T16:02:42.401384: step 541, loss 0.55895, acc 0.71875
2020-02-16T16:02:42.561480: step 542, loss 0.522195, acc 0.734375
2020-02-16T16:02:42.686084: step 543, loss 0.546232, acc 0.734375
2020-02-16T16:02:42.818054: step 544, loss 0.595327, acc 0.71875
2020-02-16T16:02:42.948688: step 545, loss 0.556741, acc 0.71875
2020-02-16T16:02:43.076336: step 546, loss 0.6524, acc 0.640625
2020-02-16T16:02:43.202823: step 547, loss 0.603727, acc 0.65625
2020-02-16T16:02:43.336949: step 548, loss 0.501386, acc 0.8125
2020-02-16T16:02:43.468401: step 549, loss 0.566179, acc 0.734375
2020-02-16T16:02:43.602135: step 550, loss 0.451402, acc 0.8125
2020-02-16T16:02:43.781831: step 551, loss 0.670222, acc 0.546875
2020-02-16T16:02:43.952725: step 552, loss 0.596679, acc 0.703125
2020-02-16T16:02:44.097356: step 553, loss 0.568157, acc 0.78125
2020-02-16T16:02:44.215942: step 554, loss 0.460543, acc 0.78125
2020-02-16T16:02:44.516033: step 555, loss 0.679664, acc 0.65625
2020-02-16T16:02:44.804358: step 556, loss 0.6611, acc 0.6875
2020-02-16T16:02:44.930919: step 557, loss 0.490569, acc 0.734375
2020-02-16T16:02:45.075760: step 558, loss 0.631339, acc 0.734375
2020-02-16T16:02:45.208313: step 559, loss 0.585642, acc 0.703125
2020-02-16T16:02:45.346968: step 560, loss 0.650488, acc 0.640625
2020-02-16T16:02:45.518761: step 561, loss 0.613369, acc 0.671875
2020-02-16T16:02:45.663034: step 562, loss 0.591448, acc 0.71875
2020-02-16T16:02:45.858754: step 563, loss 0.561165, acc 0.703125
2020-02-16T16:02:46.019342: step 564, loss 0.631942, acc 0.640625
2020-02-16T16:02:46.160715: step 565, loss 0.521145, acc 0.734375
2020-02-16T16:02:46.287674: step 566, loss 0.436069, acc 0.78125
2020-02-16T16:02:46.410139: step 567, loss 0.658752, acc 0.609375
2020-02-16T16:02:46.530157: step 568, loss 0.552257, acc 0.75
2020-02-16T16:02:46.660651: step 569, loss 0.49842, acc 0.734375
2020-02-16T16:02:46.803448: step 570, loss 0.574521, acc 0.734375
2020-02-16T16:02:46.922773: step 571, loss 0.503991, acc 0.796875
2020-02-16T16:02:47.053261: step 572, loss 0.529777, acc 0.65625
2020-02-16T16:02:47.200848: step 573, loss 0.548829, acc 0.703125
2020-02-16T16:02:47.328273: step 574, loss 0.483925, acc 0.78125
2020-02-16T16:02:47.452328: step 575, loss 0.571362, acc 0.734375
2020-02-16T16:02:47.597349: step 576, loss 0.4379, acc 0.8125
2020-02-16T16:02:47.740964: step 577, loss 0.501206, acc 0.78125
2020-02-16T16:02:47.914734: step 578, loss 0.63996, acc 0.75
2020-02-16T16:02:48.307562: step 579, loss 0.493672, acc 0.75
2020-02-16T16:02:48.443564: step 580, loss 0.652864, acc 0.625
2020-02-16T16:02:48.637370: step 581, loss 0.55095, acc 0.75
2020-02-16T16:02:48.775098: step 582, loss 0.625461, acc 0.625
2020-02-16T16:02:48.900035: step 583, loss 0.43013, acc 0.78125
2020-02-16T16:02:49.064093: step 584, loss 0.501918, acc 0.78125
2020-02-16T16:02:49.187049: step 585, loss 0.497806, acc 0.71875
2020-02-16T16:02:49.357425: step 586, loss 0.611657, acc 0.71875
2020-02-16T16:02:49.529388: step 587, loss 0.513878, acc 0.75
2020-02-16T16:02:49.712050: step 588, loss 0.521698, acc 0.75
2020-02-16T16:02:49.877094: step 589, loss 0.692989, acc 0.609375
2020-02-16T16:02:50.009558: step 590, loss 0.59846, acc 0.6875
2020-02-16T16:02:50.134411: step 591, loss 0.692092, acc 0.6875
2020-02-16T16:02:50.261068: step 592, loss 0.551534, acc 0.71875
2020-02-16T16:02:50.396618: step 593, loss 0.565752, acc 0.6875
2020-02-16T16:02:50.542113: step 594, loss 0.498724, acc 0.75
2020-02-16T16:02:50.719751: step 595, loss 0.441716, acc 0.734375
2020-02-16T16:02:50.848906: step 596, loss 0.63973, acc 0.65625
2020-02-16T16:02:50.967752: step 597, loss 0.573601, acc 0.703125
2020-02-16T16:02:51.113874: step 598, loss 0.464069, acc 0.796875
2020-02-16T16:02:51.275531: step 599, loss 0.557381, acc 0.703125
2020-02-16T16:02:51.410729: step 600, loss 0.556124, acc 0.716667

Evaluation:
2020-02-16T16:02:51.690084: step 600, loss 0.682475, acc 0.590056

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-600

2020-02-16T16:02:53.230004: step 601, loss 0.53507, acc 0.78125
2020-02-16T16:02:53.395798: step 602, loss 0.594993, acc 0.671875
2020-02-16T16:02:53.546094: step 603, loss 0.551074, acc 0.6875
2020-02-16T16:02:53.683515: step 604, loss 0.486239, acc 0.734375
2020-02-16T16:02:53.882590: step 605, loss 0.592546, acc 0.71875
2020-02-16T16:02:54.045233: step 606, loss 0.488232, acc 0.765625
2020-02-16T16:02:54.204920: step 607, loss 0.569113, acc 0.71875
2020-02-16T16:02:54.338845: step 608, loss 0.56749, acc 0.6875
2020-02-16T16:02:54.478763: step 609, loss 0.54315, acc 0.734375
2020-02-16T16:02:54.674897: step 610, loss 0.427216, acc 0.796875
2020-02-16T16:02:55.014437: step 611, loss 0.447769, acc 0.8125
2020-02-16T16:02:55.194131: step 612, loss 0.471741, acc 0.84375
2020-02-16T16:02:55.311644: step 613, loss 0.506176, acc 0.796875
2020-02-16T16:02:55.486072: step 614, loss 0.560966, acc 0.6875
2020-02-16T16:02:55.675695: step 615, loss 0.724395, acc 0.6875
2020-02-16T16:02:55.820654: step 616, loss 0.51638, acc 0.71875
2020-02-16T16:02:55.947197: step 617, loss 0.489789, acc 0.8125
2020-02-16T16:02:56.072353: step 618, loss 0.493111, acc 0.765625
2020-02-16T16:02:56.257063: step 619, loss 0.582288, acc 0.703125
2020-02-16T16:02:56.418744: step 620, loss 0.569598, acc 0.71875
2020-02-16T16:02:56.588561: step 621, loss 0.509526, acc 0.75
2020-02-16T16:02:56.749666: step 622, loss 0.477125, acc 0.75
2020-02-16T16:02:56.867913: step 623, loss 0.512896, acc 0.734375
2020-02-16T16:02:56.983817: step 624, loss 0.557109, acc 0.71875
2020-02-16T16:02:57.110408: step 625, loss 0.515187, acc 0.75
2020-02-16T16:02:57.242452: step 626, loss 0.574788, acc 0.6875
2020-02-16T16:02:57.374517: step 627, loss 0.461604, acc 0.796875
2020-02-16T16:02:57.499867: step 628, loss 0.398467, acc 0.8125
2020-02-16T16:02:57.618141: step 629, loss 0.488045, acc 0.75
2020-02-16T16:02:57.738057: step 630, loss 0.529478, acc 0.71875
2020-02-16T16:02:57.858577: step 631, loss 0.508613, acc 0.796875
2020-02-16T16:02:57.979646: step 632, loss 0.585944, acc 0.734375
2020-02-16T16:02:58.138238: step 633, loss 0.539222, acc 0.734375
2020-02-16T16:02:58.294762: step 634, loss 0.545618, acc 0.765625
2020-02-16T16:02:58.415377: step 635, loss 0.531528, acc 0.734375
2020-02-16T16:02:58.533168: step 636, loss 0.549033, acc 0.6875
2020-02-16T16:02:58.652271: step 637, loss 0.592013, acc 0.703125
2020-02-16T16:02:58.783734: step 638, loss 0.476172, acc 0.765625
2020-02-16T16:02:58.916827: step 639, loss 0.493586, acc 0.796875
2020-02-16T16:02:59.114086: step 640, loss 0.442932, acc 0.796875
2020-02-16T16:02:59.258377: step 641, loss 0.490737, acc 0.796875
2020-02-16T16:02:59.402124: step 642, loss 0.57082, acc 0.71875
2020-02-16T16:02:59.555294: step 643, loss 0.532579, acc 0.734375
2020-02-16T16:02:59.702136: step 644, loss 0.676266, acc 0.578125
2020-02-16T16:02:59.864138: step 645, loss 0.583225, acc 0.6875
2020-02-16T16:03:00.013144: step 646, loss 0.388585, acc 0.828125
2020-02-16T16:03:00.264747: step 647, loss 0.539068, acc 0.734375
2020-02-16T16:03:00.609721: step 648, loss 0.480639, acc 0.78125
2020-02-16T16:03:00.866902: step 649, loss 0.540605, acc 0.703125
2020-02-16T16:03:01.073758: step 650, loss 0.466934, acc 0.78125
2020-02-16T16:03:01.247809: step 651, loss 0.565065, acc 0.75
2020-02-16T16:03:01.448332: step 652, loss 0.444595, acc 0.828125
2020-02-16T16:03:01.592728: step 653, loss 0.546428, acc 0.71875
2020-02-16T16:03:01.774180: step 654, loss 0.504354, acc 0.75
2020-02-16T16:03:01.899811: step 655, loss 0.544553, acc 0.6875
2020-02-16T16:03:02.021141: step 656, loss 0.491724, acc 0.734375
2020-02-16T16:03:02.156300: step 657, loss 0.597373, acc 0.75
2020-02-16T16:03:02.282516: step 658, loss 0.535786, acc 0.71875
2020-02-16T16:03:02.425186: step 659, loss 0.417716, acc 0.828125
2020-02-16T16:03:02.559324: step 660, loss 0.576344, acc 0.71875
2020-02-16T16:03:02.683834: step 661, loss 0.444309, acc 0.828125
2020-02-16T16:03:02.811026: step 662, loss 0.343175, acc 0.875
2020-02-16T16:03:02.943420: step 663, loss 0.652422, acc 0.609375
2020-02-16T16:03:03.073215: step 664, loss 0.470465, acc 0.8125
2020-02-16T16:03:03.218869: step 665, loss 0.546955, acc 0.78125
2020-02-16T16:03:03.396680: step 666, loss 0.473914, acc 0.796875
2020-02-16T16:03:03.565256: step 667, loss 0.47865, acc 0.765625
2020-02-16T16:03:03.743982: step 668, loss 0.495155, acc 0.75
2020-02-16T16:03:03.869071: step 669, loss 0.604117, acc 0.671875
2020-02-16T16:03:04.016487: step 670, loss 0.57891, acc 0.625
2020-02-16T16:03:04.168731: step 671, loss 0.500186, acc 0.75
2020-02-16T16:03:04.292928: step 672, loss 0.526624, acc 0.78125
2020-02-16T16:03:04.427193: step 673, loss 0.518676, acc 0.75
2020-02-16T16:03:04.558339: step 674, loss 0.503661, acc 0.796875
2020-02-16T16:03:04.694421: step 675, loss 0.450723, acc 0.75
2020-02-16T16:03:04.832732: step 676, loss 0.471111, acc 0.734375
2020-02-16T16:03:04.960810: step 677, loss 0.472705, acc 0.75
2020-02-16T16:03:05.083397: step 678, loss 0.467845, acc 0.765625
2020-02-16T16:03:05.213083: step 679, loss 0.488618, acc 0.71875
2020-02-16T16:03:05.336326: step 680, loss 0.562866, acc 0.734375
2020-02-16T16:03:05.455241: step 681, loss 0.408832, acc 0.796875
2020-02-16T16:03:05.574269: step 682, loss 0.558307, acc 0.71875
2020-02-16T16:03:05.695829: step 683, loss 0.415474, acc 0.796875
2020-02-16T16:03:05.822296: step 684, loss 0.510984, acc 0.75
2020-02-16T16:03:05.940804: step 685, loss 0.4895, acc 0.75
2020-02-16T16:03:06.063474: step 686, loss 0.564094, acc 0.703125
2020-02-16T16:03:06.183599: step 687, loss 0.510054, acc 0.75
2020-02-16T16:03:06.302523: step 688, loss 0.519346, acc 0.8125
2020-02-16T16:03:06.429335: step 689, loss 0.473823, acc 0.703125
2020-02-16T16:03:06.598209: step 690, loss 0.347944, acc 0.828125
2020-02-16T16:03:06.726592: step 691, loss 0.449775, acc 0.75
2020-02-16T16:03:06.855384: step 692, loss 0.688316, acc 0.65625
2020-02-16T16:03:06.973626: step 693, loss 0.484326, acc 0.828125
2020-02-16T16:03:07.143209: step 694, loss 0.455337, acc 0.71875
2020-02-16T16:03:07.287832: step 695, loss 0.55806, acc 0.734375
2020-02-16T16:03:07.410133: step 696, loss 0.412052, acc 0.78125
2020-02-16T16:03:07.532775: step 697, loss 0.582396, acc 0.703125
2020-02-16T16:03:07.711437: step 698, loss 0.606372, acc 0.75
2020-02-16T16:03:07.857807: step 699, loss 0.595416, acc 0.671875
2020-02-16T16:03:07.977869: step 700, loss 0.459691, acc 0.78125

Evaluation:
2020-02-16T16:03:08.258340: step 700, loss 0.628931, acc 0.636961

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-700

2020-02-16T16:03:09.904412: step 701, loss 0.610207, acc 0.671875
2020-02-16T16:03:10.062898: step 702, loss 0.530894, acc 0.75
2020-02-16T16:03:10.214515: step 703, loss 0.428822, acc 0.75
2020-02-16T16:03:10.357939: step 704, loss 0.4897, acc 0.796875
2020-02-16T16:03:10.508723: step 705, loss 0.541159, acc 0.71875
2020-02-16T16:03:10.625924: step 706, loss 0.527823, acc 0.734375
2020-02-16T16:03:10.751915: step 707, loss 0.519182, acc 0.734375
2020-02-16T16:03:10.873529: step 708, loss 0.429669, acc 0.765625
2020-02-16T16:03:11.002993: step 709, loss 0.568963, acc 0.75
2020-02-16T16:03:11.135810: step 710, loss 0.475325, acc 0.734375
2020-02-16T16:03:11.267922: step 711, loss 0.597435, acc 0.75
2020-02-16T16:03:11.391494: step 712, loss 0.473277, acc 0.8125
2020-02-16T16:03:11.513010: step 713, loss 0.407748, acc 0.78125
2020-02-16T16:03:11.630434: step 714, loss 0.502334, acc 0.734375
2020-02-16T16:03:11.753004: step 715, loss 0.524747, acc 0.734375
2020-02-16T16:03:11.873870: step 716, loss 0.541994, acc 0.734375
2020-02-16T16:03:11.998763: step 717, loss 0.346233, acc 0.84375
2020-02-16T16:03:12.124062: step 718, loss 0.531362, acc 0.6875
2020-02-16T16:03:12.261552: step 719, loss 0.547535, acc 0.75
2020-02-16T16:03:12.398606: step 720, loss 0.612536, acc 0.6875
2020-02-16T16:03:12.532783: step 721, loss 0.71163, acc 0.609375
2020-02-16T16:03:12.697108: step 722, loss 0.506455, acc 0.765625
2020-02-16T16:03:12.838827: step 723, loss 0.5303, acc 0.71875
2020-02-16T16:03:12.968953: step 724, loss 0.430155, acc 0.796875
2020-02-16T16:03:13.099935: step 725, loss 0.539681, acc 0.6875
2020-02-16T16:03:13.225002: step 726, loss 0.497598, acc 0.734375
2020-02-16T16:03:13.355793: step 727, loss 0.610127, acc 0.71875
2020-02-16T16:03:13.485234: step 728, loss 0.525873, acc 0.71875
2020-02-16T16:03:13.607852: step 729, loss 0.460857, acc 0.796875
2020-02-16T16:03:13.753455: step 730, loss 0.484324, acc 0.796875
2020-02-16T16:03:13.891245: step 731, loss 0.45758, acc 0.78125
2020-02-16T16:03:14.015799: step 732, loss 0.577942, acc 0.734375
2020-02-16T16:03:14.212569: step 733, loss 0.542721, acc 0.703125
2020-02-16T16:03:14.343966: step 734, loss 0.467371, acc 0.84375
2020-02-16T16:03:14.480900: step 735, loss 0.700266, acc 0.625
2020-02-16T16:03:14.613589: step 736, loss 0.480737, acc 0.84375
2020-02-16T16:03:14.744733: step 737, loss 0.650062, acc 0.6875
2020-02-16T16:03:14.925088: step 738, loss 0.507976, acc 0.75
2020-02-16T16:03:15.057657: step 739, loss 0.523124, acc 0.8125
2020-02-16T16:03:15.180611: step 740, loss 0.573342, acc 0.71875
2020-02-16T16:03:15.357244: step 741, loss 0.461982, acc 0.78125
2020-02-16T16:03:15.484769: step 742, loss 0.53661, acc 0.71875
2020-02-16T16:03:15.608371: step 743, loss 0.382918, acc 0.828125
2020-02-16T16:03:15.753051: step 744, loss 0.443117, acc 0.78125
2020-02-16T16:03:15.896154: step 745, loss 0.526531, acc 0.75
2020-02-16T16:03:16.043057: step 746, loss 0.399238, acc 0.8125
2020-02-16T16:03:16.178715: step 747, loss 0.44556, acc 0.8125
2020-02-16T16:03:16.338285: step 748, loss 0.560158, acc 0.65625
2020-02-16T16:03:16.471843: step 749, loss 0.420488, acc 0.828125
2020-02-16T16:03:16.591092: step 750, loss 0.513797, acc 0.75
2020-02-16T16:03:16.711985: step 751, loss 0.473372, acc 0.75
2020-02-16T16:03:16.863605: step 752, loss 0.436516, acc 0.796875
2020-02-16T16:03:16.995460: step 753, loss 0.519709, acc 0.75
2020-02-16T16:03:17.115095: step 754, loss 0.429676, acc 0.828125
2020-02-16T16:03:17.254765: step 755, loss 0.544617, acc 0.71875
2020-02-16T16:03:17.381491: step 756, loss 0.46692, acc 0.78125
2020-02-16T16:03:17.515876: step 757, loss 0.47478, acc 0.796875
2020-02-16T16:03:17.651406: step 758, loss 0.38607, acc 0.78125
2020-02-16T16:03:17.805595: step 759, loss 0.62728, acc 0.625
2020-02-16T16:03:17.947302: step 760, loss 0.503989, acc 0.734375
2020-02-16T16:03:18.328313: step 761, loss 0.489701, acc 0.671875
2020-02-16T16:03:18.699119: step 762, loss 0.345483, acc 0.84375
2020-02-16T16:03:18.972337: step 763, loss 0.367614, acc 0.84375
2020-02-16T16:03:19.158666: step 764, loss 0.415359, acc 0.75
2020-02-16T16:03:19.413485: step 765, loss 0.53408, acc 0.703125
2020-02-16T16:03:19.636512: step 766, loss 0.414097, acc 0.828125
2020-02-16T16:03:19.831124: step 767, loss 0.434355, acc 0.828125
2020-02-16T16:03:20.015487: step 768, loss 0.385368, acc 0.859375
2020-02-16T16:03:20.163418: step 769, loss 0.364334, acc 0.828125
2020-02-16T16:03:20.341022: step 770, loss 0.435764, acc 0.78125
2020-02-16T16:03:20.501807: step 771, loss 0.290516, acc 0.875
2020-02-16T16:03:20.654799: step 772, loss 0.461805, acc 0.75
2020-02-16T16:03:20.821433: step 773, loss 0.53911, acc 0.71875
2020-02-16T16:03:20.999502: step 774, loss 0.293087, acc 0.890625
2020-02-16T16:03:21.200599: step 775, loss 0.415417, acc 0.765625
2020-02-16T16:03:21.463296: step 776, loss 0.429499, acc 0.8125
2020-02-16T16:03:21.691946: step 777, loss 0.385196, acc 0.84375
2020-02-16T16:03:21.862210: step 778, loss 0.356183, acc 0.875
2020-02-16T16:03:22.058187: step 779, loss 0.395772, acc 0.796875
2020-02-16T16:03:22.351253: step 780, loss 0.466444, acc 0.78125
2020-02-16T16:03:22.564816: step 781, loss 0.460859, acc 0.796875
2020-02-16T16:03:22.789028: step 782, loss 0.327259, acc 0.90625
2020-02-16T16:03:22.984453: step 783, loss 0.436763, acc 0.78125
2020-02-16T16:03:23.194032: step 784, loss 0.528191, acc 0.71875
2020-02-16T16:03:23.368876: step 785, loss 0.401783, acc 0.875
2020-02-16T16:03:23.530130: step 786, loss 0.414076, acc 0.8125
2020-02-16T16:03:23.688066: step 787, loss 0.383289, acc 0.84375
2020-02-16T16:03:23.884324: step 788, loss 0.489275, acc 0.796875
2020-02-16T16:03:24.057002: step 789, loss 0.391289, acc 0.875
2020-02-16T16:03:24.345008: step 790, loss 0.372223, acc 0.84375
2020-02-16T16:03:24.568022: step 791, loss 0.397082, acc 0.796875
2020-02-16T16:03:24.867982: step 792, loss 0.523081, acc 0.78125
2020-02-16T16:03:25.015546: step 793, loss 0.447901, acc 0.796875
2020-02-16T16:03:25.222882: step 794, loss 0.338166, acc 0.859375
2020-02-16T16:03:25.406317: step 795, loss 0.449932, acc 0.796875
2020-02-16T16:03:25.576179: step 796, loss 0.446871, acc 0.8125
2020-02-16T16:03:25.788839: step 797, loss 0.488089, acc 0.78125
2020-02-16T16:03:25.967412: step 798, loss 0.518567, acc 0.8125
2020-02-16T16:03:26.155754: step 799, loss 0.391186, acc 0.796875
2020-02-16T16:03:26.294248: step 800, loss 0.478895, acc 0.734375

Evaluation:
2020-02-16T16:03:26.850590: step 800, loss 0.595294, acc 0.681989

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-800

2020-02-16T16:03:29.318913: step 801, loss 0.38154, acc 0.84375
2020-02-16T16:03:29.441407: step 802, loss 0.386959, acc 0.828125
2020-02-16T16:03:29.563268: step 803, loss 0.446906, acc 0.765625
2020-02-16T16:03:29.689367: step 804, loss 0.350341, acc 0.84375
2020-02-16T16:03:29.818228: step 805, loss 0.420332, acc 0.796875
2020-02-16T16:03:29.938831: step 806, loss 0.407395, acc 0.8125
2020-02-16T16:03:30.064962: step 807, loss 0.501468, acc 0.796875
2020-02-16T16:03:30.200019: step 808, loss 0.356593, acc 0.8125
2020-02-16T16:03:30.324881: step 809, loss 0.429647, acc 0.828125
2020-02-16T16:03:30.448073: step 810, loss 0.480794, acc 0.78125
2020-02-16T16:03:30.568841: step 811, loss 0.499562, acc 0.71875
2020-02-16T16:03:30.772530: step 812, loss 0.416017, acc 0.78125
2020-02-16T16:03:31.041870: step 813, loss 0.380311, acc 0.921875
2020-02-16T16:03:31.181577: step 814, loss 0.505722, acc 0.78125
2020-02-16T16:03:31.322191: step 815, loss 0.543779, acc 0.75
2020-02-16T16:03:31.444550: step 816, loss 0.43449, acc 0.828125
2020-02-16T16:03:31.585826: step 817, loss 0.325322, acc 0.875
2020-02-16T16:03:31.818782: step 818, loss 0.428117, acc 0.796875
2020-02-16T16:03:32.026529: step 819, loss 0.373597, acc 0.8125
2020-02-16T16:03:32.186169: step 820, loss 0.508809, acc 0.75
2020-02-16T16:03:32.323136: step 821, loss 0.421404, acc 0.765625
2020-02-16T16:03:32.531432: step 822, loss 0.547397, acc 0.734375
2020-02-16T16:03:32.678139: step 823, loss 0.411279, acc 0.828125
2020-02-16T16:03:32.906056: step 824, loss 0.319159, acc 0.875
2020-02-16T16:03:33.086156: step 825, loss 0.490839, acc 0.734375
2020-02-16T16:03:33.260125: step 826, loss 0.520641, acc 0.71875
2020-02-16T16:03:33.383670: step 827, loss 0.444057, acc 0.734375
2020-02-16T16:03:33.553399: step 828, loss 0.41314, acc 0.828125
2020-02-16T16:03:33.678136: step 829, loss 0.359291, acc 0.84375
2020-02-16T16:03:33.808907: step 830, loss 0.469331, acc 0.796875
2020-02-16T16:03:33.924741: step 831, loss 0.356824, acc 0.84375
2020-02-16T16:03:34.043019: step 832, loss 0.420514, acc 0.8125
2020-02-16T16:03:34.172728: step 833, loss 0.453325, acc 0.796875
2020-02-16T16:03:34.307007: step 834, loss 0.571158, acc 0.71875
2020-02-16T16:03:34.430252: step 835, loss 0.576964, acc 0.75
2020-02-16T16:03:34.554436: step 836, loss 0.485575, acc 0.75
2020-02-16T16:03:34.679382: step 837, loss 0.467574, acc 0.765625
2020-02-16T16:03:34.813189: step 838, loss 0.380057, acc 0.859375
2020-02-16T16:03:34.948677: step 839, loss 0.354465, acc 0.875
2020-02-16T16:03:35.066666: step 840, loss 0.417525, acc 0.859375
2020-02-16T16:03:35.190482: step 841, loss 0.609778, acc 0.703125
2020-02-16T16:03:35.314227: step 842, loss 0.462523, acc 0.734375
2020-02-16T16:03:35.436260: step 843, loss 0.552702, acc 0.796875
2020-02-16T16:03:35.557088: step 844, loss 0.337967, acc 0.90625
2020-02-16T16:03:35.676289: step 845, loss 0.50271, acc 0.71875
2020-02-16T16:03:35.807917: step 846, loss 0.409292, acc 0.84375
2020-02-16T16:03:36.008608: step 847, loss 0.367758, acc 0.8125
2020-02-16T16:03:36.160223: step 848, loss 0.437959, acc 0.84375
2020-02-16T16:03:36.284670: step 849, loss 0.504665, acc 0.75
2020-02-16T16:03:36.407341: step 850, loss 0.523903, acc 0.765625
2020-02-16T16:03:36.573364: step 851, loss 0.437542, acc 0.828125
2020-02-16T16:03:36.733772: step 852, loss 0.453573, acc 0.828125
2020-02-16T16:03:36.860815: step 853, loss 0.569138, acc 0.75
2020-02-16T16:03:37.000281: step 854, loss 0.418068, acc 0.78125
2020-02-16T16:03:37.119497: step 855, loss 0.471958, acc 0.703125
2020-02-16T16:03:37.240442: step 856, loss 0.570616, acc 0.71875
2020-02-16T16:03:37.376750: step 857, loss 0.329926, acc 0.890625
2020-02-16T16:03:37.506682: step 858, loss 0.527995, acc 0.78125
2020-02-16T16:03:37.628157: step 859, loss 0.537843, acc 0.75
2020-02-16T16:03:37.750627: step 860, loss 0.404916, acc 0.859375
2020-02-16T16:03:37.872329: step 861, loss 0.446327, acc 0.8125
2020-02-16T16:03:37.998985: step 862, loss 0.38668, acc 0.796875
2020-02-16T16:03:38.119718: step 863, loss 0.372429, acc 0.875
2020-02-16T16:03:38.240841: step 864, loss 0.442147, acc 0.75
2020-02-16T16:03:38.364783: step 865, loss 0.461807, acc 0.796875
2020-02-16T16:03:38.481841: step 866, loss 0.470335, acc 0.734375
2020-02-16T16:03:38.601672: step 867, loss 0.508102, acc 0.78125
2020-02-16T16:03:38.720635: step 868, loss 0.484439, acc 0.75
2020-02-16T16:03:38.848496: step 869, loss 0.531865, acc 0.796875
2020-02-16T16:03:38.966224: step 870, loss 0.4787, acc 0.75
2020-02-16T16:03:39.083973: step 871, loss 0.431212, acc 0.765625
2020-02-16T16:03:39.203286: step 872, loss 0.464144, acc 0.703125
2020-02-16T16:03:39.324035: step 873, loss 0.454526, acc 0.765625
2020-02-16T16:03:39.480629: step 874, loss 0.492262, acc 0.765625
2020-02-16T16:03:39.603906: step 875, loss 0.450279, acc 0.765625
2020-02-16T16:03:39.728851: step 876, loss 0.497223, acc 0.71875
2020-02-16T16:03:39.852838: step 877, loss 0.544853, acc 0.71875
2020-02-16T16:03:39.974285: step 878, loss 0.510605, acc 0.8125
2020-02-16T16:03:40.093070: step 879, loss 0.61545, acc 0.6875
2020-02-16T16:03:40.251273: step 880, loss 0.449382, acc 0.78125
2020-02-16T16:03:40.373366: step 881, loss 0.403904, acc 0.828125
2020-02-16T16:03:40.493268: step 882, loss 0.570221, acc 0.6875
2020-02-16T16:03:40.611230: step 883, loss 0.425465, acc 0.78125
2020-02-16T16:03:40.733406: step 884, loss 0.427562, acc 0.8125
2020-02-16T16:03:40.857574: step 885, loss 0.452109, acc 0.75
2020-02-16T16:03:40.978822: step 886, loss 0.500143, acc 0.765625
2020-02-16T16:03:41.097196: step 887, loss 0.499824, acc 0.75
2020-02-16T16:03:41.217026: step 888, loss 0.570213, acc 0.765625
2020-02-16T16:03:41.343396: step 889, loss 0.375253, acc 0.828125
2020-02-16T16:03:41.469829: step 890, loss 0.370756, acc 0.859375
2020-02-16T16:03:41.591334: step 891, loss 0.351447, acc 0.875
2020-02-16T16:03:41.711446: step 892, loss 0.551026, acc 0.703125
2020-02-16T16:03:41.840205: step 893, loss 0.470401, acc 0.765625
2020-02-16T16:03:41.962988: step 894, loss 0.588652, acc 0.703125
2020-02-16T16:03:42.079552: step 895, loss 0.483648, acc 0.734375
2020-02-16T16:03:42.197840: step 896, loss 0.334037, acc 0.859375
2020-02-16T16:03:42.318072: step 897, loss 0.355115, acc 0.90625
2020-02-16T16:03:42.436935: step 898, loss 0.264569, acc 0.90625
2020-02-16T16:03:42.555087: step 899, loss 0.479468, acc 0.78125
2020-02-16T16:03:42.669285: step 900, loss 0.321968, acc 0.883333

Evaluation:
2020-02-16T16:03:42.879905: step 900, loss 0.587209, acc 0.681989

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-900

2020-02-16T16:03:44.512102: step 901, loss 0.382258, acc 0.890625
2020-02-16T16:03:44.631681: step 902, loss 0.304369, acc 0.875
2020-02-16T16:03:44.760819: step 903, loss 0.351989, acc 0.875
2020-02-16T16:03:44.888265: step 904, loss 0.379856, acc 0.875
2020-02-16T16:03:45.013105: step 905, loss 0.349317, acc 0.8125
2020-02-16T16:03:45.136167: step 906, loss 0.366915, acc 0.890625
2020-02-16T16:03:45.275445: step 907, loss 0.397323, acc 0.84375
2020-02-16T16:03:45.414483: step 908, loss 0.321145, acc 0.875
2020-02-16T16:03:45.536500: step 909, loss 0.399075, acc 0.859375
2020-02-16T16:03:45.681235: step 910, loss 0.327042, acc 0.859375
2020-02-16T16:03:45.846058: step 911, loss 0.311184, acc 0.890625
2020-02-16T16:03:45.971107: step 912, loss 0.278915, acc 0.84375
2020-02-16T16:03:46.092373: step 913, loss 0.344724, acc 0.859375
2020-02-16T16:03:46.215661: step 914, loss 0.398252, acc 0.796875
2020-02-16T16:03:46.334320: step 915, loss 0.345871, acc 0.859375
2020-02-16T16:03:46.492653: step 916, loss 0.300371, acc 0.875
2020-02-16T16:03:46.640018: step 917, loss 0.339118, acc 0.84375
2020-02-16T16:03:46.761865: step 918, loss 0.409101, acc 0.8125
2020-02-16T16:03:46.883259: step 919, loss 0.29914, acc 0.875
2020-02-16T16:03:47.032378: step 920, loss 0.352685, acc 0.84375
2020-02-16T16:03:47.166736: step 921, loss 0.32931, acc 0.859375
2020-02-16T16:03:47.288862: step 922, loss 0.406037, acc 0.75
2020-02-16T16:03:47.415668: step 923, loss 0.292796, acc 0.875
2020-02-16T16:03:47.533702: step 924, loss 0.284373, acc 0.84375
2020-02-16T16:03:47.666016: step 925, loss 0.274731, acc 0.921875
2020-02-16T16:03:47.807384: step 926, loss 0.358524, acc 0.828125
2020-02-16T16:03:47.928473: step 927, loss 0.396417, acc 0.796875
2020-02-16T16:03:48.049865: step 928, loss 0.394461, acc 0.859375
2020-02-16T16:03:48.170042: step 929, loss 0.32879, acc 0.890625
2020-02-16T16:03:48.286478: step 930, loss 0.277589, acc 0.890625
2020-02-16T16:03:48.405090: step 931, loss 0.386737, acc 0.796875
2020-02-16T16:03:48.521174: step 932, loss 0.412865, acc 0.828125
2020-02-16T16:03:48.637897: step 933, loss 0.275887, acc 0.890625
2020-02-16T16:03:48.758235: step 934, loss 0.390244, acc 0.84375
2020-02-16T16:03:48.875748: step 935, loss 0.259598, acc 0.90625
2020-02-16T16:03:48.994958: step 936, loss 0.422211, acc 0.78125
2020-02-16T16:03:49.112876: step 937, loss 0.361405, acc 0.828125
2020-02-16T16:03:49.232949: step 938, loss 0.370103, acc 0.828125
2020-02-16T16:03:49.353565: step 939, loss 0.273292, acc 0.890625
2020-02-16T16:03:49.471661: step 940, loss 0.389918, acc 0.859375
2020-02-16T16:03:49.590961: step 941, loss 0.353981, acc 0.8125
2020-02-16T16:03:49.710237: step 942, loss 0.432731, acc 0.828125
2020-02-16T16:03:49.837941: step 943, loss 0.521803, acc 0.765625
2020-02-16T16:03:49.958636: step 944, loss 0.410075, acc 0.78125
2020-02-16T16:03:50.076369: step 945, loss 0.413081, acc 0.8125
2020-02-16T16:03:50.196057: step 946, loss 0.488298, acc 0.8125
2020-02-16T16:03:50.313157: step 947, loss 0.268768, acc 0.921875
2020-02-16T16:03:50.433160: step 948, loss 0.441943, acc 0.765625
2020-02-16T16:03:50.553187: step 949, loss 0.248976, acc 0.875
2020-02-16T16:03:50.669569: step 950, loss 0.263587, acc 0.90625
2020-02-16T16:03:50.796008: step 951, loss 0.345937, acc 0.90625
2020-02-16T16:03:50.916557: step 952, loss 0.469596, acc 0.765625
2020-02-16T16:03:51.033066: step 953, loss 0.302679, acc 0.90625
2020-02-16T16:03:51.152006: step 954, loss 0.379225, acc 0.765625
2020-02-16T16:03:51.267450: step 955, loss 0.377, acc 0.828125
2020-02-16T16:03:51.385566: step 956, loss 0.360004, acc 0.828125
2020-02-16T16:03:51.506006: step 957, loss 0.372803, acc 0.828125
2020-02-16T16:03:51.623682: step 958, loss 0.41404, acc 0.859375
2020-02-16T16:03:51.743973: step 959, loss 0.499099, acc 0.78125
2020-02-16T16:03:51.865349: step 960, loss 0.328485, acc 0.890625
2020-02-16T16:03:51.988801: step 961, loss 0.36341, acc 0.84375
2020-02-16T16:03:52.107310: step 962, loss 0.298672, acc 0.875
2020-02-16T16:03:52.225959: step 963, loss 0.368241, acc 0.859375
2020-02-16T16:03:52.345937: step 964, loss 0.401246, acc 0.828125
2020-02-16T16:03:52.467456: step 965, loss 0.356845, acc 0.828125
2020-02-16T16:03:52.584765: step 966, loss 0.428032, acc 0.78125
2020-02-16T16:03:52.703079: step 967, loss 0.313389, acc 0.890625
2020-02-16T16:03:52.827029: step 968, loss 0.398916, acc 0.796875
2020-02-16T16:03:52.946318: step 969, loss 0.390005, acc 0.75
2020-02-16T16:03:53.067594: step 970, loss 0.315979, acc 0.90625
2020-02-16T16:03:53.202886: step 971, loss 0.301564, acc 0.859375
2020-02-16T16:03:53.330350: step 972, loss 0.355226, acc 0.796875
2020-02-16T16:03:53.465180: step 973, loss 0.32775, acc 0.890625
2020-02-16T16:03:53.602044: step 974, loss 0.508318, acc 0.78125
2020-02-16T16:03:53.740467: step 975, loss 0.362308, acc 0.890625
2020-02-16T16:03:53.867317: step 976, loss 0.332336, acc 0.84375
2020-02-16T16:03:54.053974: step 977, loss 0.346435, acc 0.84375
2020-02-16T16:03:54.186412: step 978, loss 0.477987, acc 0.8125
2020-02-16T16:03:54.305351: step 979, loss 0.355844, acc 0.828125
2020-02-16T16:03:54.435153: step 980, loss 0.299006, acc 0.90625
2020-02-16T16:03:54.569731: step 981, loss 0.31207, acc 0.875
2020-02-16T16:03:54.698885: step 982, loss 0.406901, acc 0.8125
2020-02-16T16:03:54.835729: step 983, loss 0.329432, acc 0.875
2020-02-16T16:03:54.961449: step 984, loss 0.300118, acc 0.859375
2020-02-16T16:03:55.080603: step 985, loss 0.275943, acc 0.875
2020-02-16T16:03:55.202207: step 986, loss 0.375408, acc 0.859375
2020-02-16T16:03:55.318132: step 987, loss 0.41471, acc 0.78125
2020-02-16T16:03:55.439444: step 988, loss 0.355953, acc 0.859375
2020-02-16T16:03:55.559409: step 989, loss 0.389709, acc 0.859375
2020-02-16T16:03:55.678291: step 990, loss 0.317451, acc 0.828125
2020-02-16T16:03:55.804504: step 991, loss 0.386906, acc 0.84375
2020-02-16T16:03:55.923475: step 992, loss 0.463692, acc 0.75
2020-02-16T16:03:56.041046: step 993, loss 0.466691, acc 0.796875
2020-02-16T16:03:56.165324: step 994, loss 0.484191, acc 0.734375
2020-02-16T16:03:56.303063: step 995, loss 0.309007, acc 0.890625
2020-02-16T16:03:56.440351: step 996, loss 0.298372, acc 0.859375
2020-02-16T16:03:56.573333: step 997, loss 0.2238, acc 0.90625
2020-02-16T16:03:56.704719: step 998, loss 0.258932, acc 0.921875
2020-02-16T16:03:56.837965: step 999, loss 0.425912, acc 0.796875
2020-02-16T16:03:57.010056: step 1000, loss 0.284704, acc 0.90625

Evaluation:
2020-02-16T16:03:57.219890: step 1000, loss 0.581661, acc 0.70075

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1000

2020-02-16T16:03:58.802557: step 1001, loss 0.304613, acc 0.890625
2020-02-16T16:03:58.939423: step 1002, loss 0.329809, acc 0.84375
2020-02-16T16:03:59.099529: step 1003, loss 0.358015, acc 0.8125
2020-02-16T16:03:59.438729: step 1004, loss 0.303687, acc 0.875
2020-02-16T16:03:59.693134: step 1005, loss 0.430965, acc 0.796875
2020-02-16T16:03:59.891535: step 1006, loss 0.355772, acc 0.78125
2020-02-16T16:04:00.186755: step 1007, loss 0.262028, acc 0.90625
2020-02-16T16:04:00.415017: step 1008, loss 0.377745, acc 0.84375
2020-02-16T16:04:00.562548: step 1009, loss 0.329713, acc 0.890625
2020-02-16T16:04:00.729690: step 1010, loss 0.453644, acc 0.796875
2020-02-16T16:04:01.129759: step 1011, loss 0.348358, acc 0.875
2020-02-16T16:04:01.263097: step 1012, loss 0.426203, acc 0.8125
2020-02-16T16:04:01.381164: step 1013, loss 0.320211, acc 0.875
2020-02-16T16:04:01.498179: step 1014, loss 0.312304, acc 0.875
2020-02-16T16:04:01.617637: step 1015, loss 0.322219, acc 0.90625
2020-02-16T16:04:01.745084: step 1016, loss 0.315809, acc 0.875
2020-02-16T16:04:01.908719: step 1017, loss 0.371427, acc 0.84375
2020-02-16T16:04:02.036317: step 1018, loss 0.334126, acc 0.84375
2020-02-16T16:04:02.159342: step 1019, loss 0.425827, acc 0.8125
2020-02-16T16:04:02.282342: step 1020, loss 0.381551, acc 0.828125
2020-02-16T16:04:02.405677: step 1021, loss 0.295569, acc 0.890625
2020-02-16T16:04:02.525873: step 1022, loss 0.418152, acc 0.796875
2020-02-16T16:04:02.644298: step 1023, loss 0.446149, acc 0.78125
2020-02-16T16:04:02.781640: step 1024, loss 0.415187, acc 0.8125
2020-02-16T16:04:02.902820: step 1025, loss 0.456135, acc 0.796875
2020-02-16T16:04:03.018419: step 1026, loss 0.311905, acc 0.84375
2020-02-16T16:04:03.142599: step 1027, loss 0.356795, acc 0.8125
2020-02-16T16:04:03.265348: step 1028, loss 0.484047, acc 0.703125
2020-02-16T16:04:03.387308: step 1029, loss 0.378678, acc 0.796875
2020-02-16T16:04:03.525768: step 1030, loss 0.273521, acc 0.875
2020-02-16T16:04:03.658960: step 1031, loss 0.367825, acc 0.875
2020-02-16T16:04:03.799334: step 1032, loss 0.418528, acc 0.796875
2020-02-16T16:04:03.927650: step 1033, loss 0.461401, acc 0.78125
2020-02-16T16:04:04.051869: step 1034, loss 0.371343, acc 0.828125
2020-02-16T16:04:04.175979: step 1035, loss 0.358912, acc 0.84375
2020-02-16T16:04:04.296455: step 1036, loss 0.356651, acc 0.84375
2020-02-16T16:04:04.417725: step 1037, loss 0.368991, acc 0.828125
2020-02-16T16:04:04.561689: step 1038, loss 0.492139, acc 0.796875
2020-02-16T16:04:04.722472: step 1039, loss 0.393352, acc 0.84375
2020-02-16T16:04:04.855189: step 1040, loss 0.483904, acc 0.84375
2020-02-16T16:04:04.984830: step 1041, loss 0.493581, acc 0.75
2020-02-16T16:04:05.147839: step 1042, loss 0.230231, acc 0.9375
2020-02-16T16:04:05.293749: step 1043, loss 0.396647, acc 0.796875
2020-02-16T16:04:05.443159: step 1044, loss 0.432647, acc 0.78125
2020-02-16T16:04:05.609014: step 1045, loss 0.342459, acc 0.875
2020-02-16T16:04:05.774860: step 1046, loss 0.299866, acc 0.90625
2020-02-16T16:04:05.921694: step 1047, loss 0.425332, acc 0.78125
2020-02-16T16:04:06.070659: step 1048, loss 0.324754, acc 0.859375
2020-02-16T16:04:06.230370: step 1049, loss 0.309875, acc 0.859375
2020-02-16T16:04:06.384105: step 1050, loss 0.290422, acc 0.866667
2020-02-16T16:04:06.520552: step 1051, loss 0.291222, acc 0.90625
2020-02-16T16:04:06.642217: step 1052, loss 0.381881, acc 0.859375
2020-02-16T16:04:06.769000: step 1053, loss 0.265653, acc 0.890625
2020-02-16T16:04:06.891001: step 1054, loss 0.321719, acc 0.828125
2020-02-16T16:04:07.017652: step 1055, loss 0.42837, acc 0.8125
2020-02-16T16:04:07.151062: step 1056, loss 0.36602, acc 0.84375
2020-02-16T16:04:07.277999: step 1057, loss 0.301002, acc 0.859375
2020-02-16T16:04:07.401800: step 1058, loss 0.380584, acc 0.796875
2020-02-16T16:04:07.522623: step 1059, loss 0.308688, acc 0.828125
2020-02-16T16:04:07.645401: step 1060, loss 0.382589, acc 0.78125
2020-02-16T16:04:07.774938: step 1061, loss 0.339355, acc 0.875
2020-02-16T16:04:07.909884: step 1062, loss 0.436487, acc 0.78125
2020-02-16T16:04:08.026280: step 1063, loss 0.276449, acc 0.859375
2020-02-16T16:04:08.143417: step 1064, loss 0.223196, acc 0.921875
2020-02-16T16:04:08.268902: step 1065, loss 0.232378, acc 0.9375
2020-02-16T16:04:08.389820: step 1066, loss 0.363978, acc 0.828125
2020-02-16T16:04:08.508190: step 1067, loss 0.41848, acc 0.84375
2020-02-16T16:04:08.627663: step 1068, loss 0.266376, acc 0.875
2020-02-16T16:04:08.770820: step 1069, loss 0.384408, acc 0.796875
2020-02-16T16:04:08.891072: step 1070, loss 0.337744, acc 0.828125
2020-02-16T16:04:09.007454: step 1071, loss 0.278535, acc 0.875
2020-02-16T16:04:09.134823: step 1072, loss 0.372551, acc 0.84375
2020-02-16T16:04:09.304295: step 1073, loss 0.306565, acc 0.859375
2020-02-16T16:04:09.425540: step 1074, loss 0.241573, acc 0.890625
2020-02-16T16:04:09.552663: step 1075, loss 0.347431, acc 0.875
2020-02-16T16:04:09.723328: step 1076, loss 0.28911, acc 0.875
2020-02-16T16:04:09.852473: step 1077, loss 0.2886, acc 0.875
2020-02-16T16:04:09.973520: step 1078, loss 0.276147, acc 0.875
2020-02-16T16:04:10.127833: step 1079, loss 0.444897, acc 0.796875
2020-02-16T16:04:10.271752: step 1080, loss 0.285392, acc 0.84375
2020-02-16T16:04:10.393749: step 1081, loss 0.303501, acc 0.859375
2020-02-16T16:04:10.554761: step 1082, loss 0.306629, acc 0.859375
2020-02-16T16:04:10.690744: step 1083, loss 0.294117, acc 0.90625
2020-02-16T16:04:10.824085: step 1084, loss 0.288841, acc 0.859375
2020-02-16T16:04:10.984602: step 1085, loss 0.388499, acc 0.796875
2020-02-16T16:04:11.111379: step 1086, loss 0.311473, acc 0.84375
2020-02-16T16:04:11.231913: step 1087, loss 0.242508, acc 0.921875
2020-02-16T16:04:11.353584: step 1088, loss 0.276652, acc 0.90625
2020-02-16T16:04:11.470482: step 1089, loss 0.26182, acc 0.890625
2020-02-16T16:04:11.606066: step 1090, loss 0.346156, acc 0.875
2020-02-16T16:04:11.737198: step 1091, loss 0.399582, acc 0.875
2020-02-16T16:04:11.858966: step 1092, loss 0.261811, acc 0.84375
2020-02-16T16:04:11.975037: step 1093, loss 0.303919, acc 0.859375
2020-02-16T16:04:12.096445: step 1094, loss 0.250485, acc 0.859375
2020-02-16T16:04:12.263050: step 1095, loss 0.334726, acc 0.859375
2020-02-16T16:04:12.401689: step 1096, loss 0.374866, acc 0.828125
2020-02-16T16:04:12.520098: step 1097, loss 0.279072, acc 0.875
2020-02-16T16:04:12.639717: step 1098, loss 0.286662, acc 0.875
2020-02-16T16:04:12.764524: step 1099, loss 0.378345, acc 0.859375
2020-02-16T16:04:12.894343: step 1100, loss 0.300523, acc 0.890625

Evaluation:
2020-02-16T16:04:13.152876: step 1100, loss 0.612817, acc 0.682927

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1100

2020-02-16T16:04:15.483429: step 1101, loss 0.35938, acc 0.84375
2020-02-16T16:04:15.606414: step 1102, loss 0.228034, acc 0.9375
2020-02-16T16:04:15.729321: step 1103, loss 0.352345, acc 0.765625
2020-02-16T16:04:15.852280: step 1104, loss 0.268381, acc 0.921875
2020-02-16T16:04:15.972352: step 1105, loss 0.273991, acc 0.875
2020-02-16T16:04:16.090256: step 1106, loss 0.197049, acc 0.953125
2020-02-16T16:04:16.210052: step 1107, loss 0.308435, acc 0.875
2020-02-16T16:04:16.331144: step 1108, loss 0.298929, acc 0.921875
2020-02-16T16:04:16.450112: step 1109, loss 0.359743, acc 0.828125
2020-02-16T16:04:16.588799: step 1110, loss 0.289274, acc 0.890625
2020-02-16T16:04:16.728342: step 1111, loss 0.311425, acc 0.875
2020-02-16T16:04:16.851747: step 1112, loss 0.224951, acc 0.953125
2020-02-16T16:04:16.972528: step 1113, loss 0.311074, acc 0.859375
2020-02-16T16:04:17.093515: step 1114, loss 0.395454, acc 0.796875
2020-02-16T16:04:17.220135: step 1115, loss 0.415779, acc 0.75
2020-02-16T16:04:17.351871: step 1116, loss 0.263188, acc 0.890625
2020-02-16T16:04:17.475572: step 1117, loss 0.401767, acc 0.796875
2020-02-16T16:04:17.590770: step 1118, loss 0.397029, acc 0.828125
2020-02-16T16:04:17.710975: step 1119, loss 0.30494, acc 0.828125
2020-02-16T16:04:17.835903: step 1120, loss 0.475479, acc 0.765625
2020-02-16T16:04:17.957153: step 1121, loss 0.321892, acc 0.875
2020-02-16T16:04:18.074110: step 1122, loss 0.279257, acc 0.890625
2020-02-16T16:04:18.194060: step 1123, loss 0.232487, acc 0.9375
2020-02-16T16:04:18.358201: step 1124, loss 0.276503, acc 0.875
2020-02-16T16:04:18.534901: step 1125, loss 0.248962, acc 0.90625
2020-02-16T16:04:18.669998: step 1126, loss 0.2192, acc 0.90625
2020-02-16T16:04:18.840704: step 1127, loss 0.303741, acc 0.90625
2020-02-16T16:04:19.022594: step 1128, loss 0.405839, acc 0.78125
2020-02-16T16:04:19.151892: step 1129, loss 0.435932, acc 0.796875
2020-02-16T16:04:19.274864: step 1130, loss 0.351996, acc 0.828125
2020-02-16T16:04:19.398058: step 1131, loss 0.197972, acc 0.90625
2020-02-16T16:04:19.553705: step 1132, loss 0.321408, acc 0.859375
2020-02-16T16:04:19.718215: step 1133, loss 0.190232, acc 0.96875
2020-02-16T16:04:19.895174: step 1134, loss 0.281221, acc 0.859375
2020-02-16T16:04:20.043192: step 1135, loss 0.353635, acc 0.875
2020-02-16T16:04:20.163525: step 1136, loss 0.324735, acc 0.84375
2020-02-16T16:04:20.283116: step 1137, loss 0.286256, acc 0.875
2020-02-16T16:04:20.414990: step 1138, loss 0.298831, acc 0.890625
2020-02-16T16:04:20.552303: step 1139, loss 0.249672, acc 0.953125
2020-02-16T16:04:20.708460: step 1140, loss 0.214256, acc 0.921875
2020-02-16T16:04:20.874729: step 1141, loss 0.338707, acc 0.859375
2020-02-16T16:04:21.026176: step 1142, loss 0.42533, acc 0.8125
2020-02-16T16:04:21.175905: step 1143, loss 0.332675, acc 0.859375
2020-02-16T16:04:21.330959: step 1144, loss 0.287402, acc 0.859375
2020-02-16T16:04:21.489637: step 1145, loss 0.222546, acc 0.9375
2020-02-16T16:04:21.663542: step 1146, loss 0.407528, acc 0.828125
2020-02-16T16:04:21.827202: step 1147, loss 0.266522, acc 0.875
2020-02-16T16:04:21.975515: step 1148, loss 0.412123, acc 0.8125
2020-02-16T16:04:22.121549: step 1149, loss 0.404417, acc 0.828125
2020-02-16T16:04:22.268626: step 1150, loss 0.480484, acc 0.78125
2020-02-16T16:04:22.409645: step 1151, loss 0.267557, acc 0.921875
2020-02-16T16:04:22.596903: step 1152, loss 0.262627, acc 0.90625
2020-02-16T16:04:22.743260: step 1153, loss 0.296024, acc 0.890625
2020-02-16T16:04:22.930839: step 1154, loss 0.328147, acc 0.84375
2020-02-16T16:04:23.077793: step 1155, loss 0.340528, acc 0.8125
2020-02-16T16:04:23.215698: step 1156, loss 0.271562, acc 0.90625
2020-02-16T16:04:23.424924: step 1157, loss 0.295588, acc 0.84375
2020-02-16T16:04:23.664063: step 1158, loss 0.164937, acc 0.96875
2020-02-16T16:04:23.802740: step 1159, loss 0.215645, acc 0.90625
2020-02-16T16:04:24.001568: step 1160, loss 0.340239, acc 0.8125
2020-02-16T16:04:24.125033: step 1161, loss 0.334584, acc 0.859375
2020-02-16T16:04:24.315919: step 1162, loss 0.378997, acc 0.84375
2020-02-16T16:04:24.464223: step 1163, loss 0.198896, acc 0.921875
2020-02-16T16:04:24.637469: step 1164, loss 0.297796, acc 0.921875
2020-02-16T16:04:24.782037: step 1165, loss 0.374841, acc 0.84375
2020-02-16T16:04:24.906363: step 1166, loss 0.229322, acc 0.890625
2020-02-16T16:04:25.059288: step 1167, loss 0.297079, acc 0.90625
2020-02-16T16:04:25.206516: step 1168, loss 0.382561, acc 0.78125
2020-02-16T16:04:25.332618: step 1169, loss 0.3187, acc 0.859375
2020-02-16T16:04:25.455927: step 1170, loss 0.202296, acc 0.9375
2020-02-16T16:04:25.579027: step 1171, loss 0.454743, acc 0.78125
2020-02-16T16:04:25.765694: step 1172, loss 0.254794, acc 0.921875
2020-02-16T16:04:25.911175: step 1173, loss 0.423983, acc 0.8125
2020-02-16T16:04:26.031024: step 1174, loss 0.220393, acc 0.890625
2020-02-16T16:04:26.164964: step 1175, loss 0.335501, acc 0.859375
2020-02-16T16:04:26.287904: step 1176, loss 0.251968, acc 0.921875
2020-02-16T16:04:26.412358: step 1177, loss 0.265012, acc 0.921875
2020-02-16T16:04:26.544267: step 1178, loss 0.315033, acc 0.84375
2020-02-16T16:04:26.670886: step 1179, loss 0.320678, acc 0.859375
2020-02-16T16:04:26.800880: step 1180, loss 0.265606, acc 0.890625
2020-02-16T16:04:26.920120: step 1181, loss 0.250342, acc 0.890625
2020-02-16T16:04:27.038516: step 1182, loss 0.258955, acc 0.921875
2020-02-16T16:04:27.160511: step 1183, loss 0.454197, acc 0.828125
2020-02-16T16:04:27.281295: step 1184, loss 0.341466, acc 0.84375
2020-02-16T16:04:27.402400: step 1185, loss 0.189407, acc 0.9375
2020-02-16T16:04:27.519457: step 1186, loss 0.317566, acc 0.859375
2020-02-16T16:04:27.639101: step 1187, loss 0.373319, acc 0.875
2020-02-16T16:04:27.761288: step 1188, loss 0.313488, acc 0.796875
2020-02-16T16:04:27.881164: step 1189, loss 0.306298, acc 0.859375
2020-02-16T16:04:28.000612: step 1190, loss 0.235183, acc 0.875
2020-02-16T16:04:28.118052: step 1191, loss 0.230882, acc 0.90625
2020-02-16T16:04:28.235618: step 1192, loss 0.258752, acc 0.90625
2020-02-16T16:04:28.355941: step 1193, loss 0.348345, acc 0.859375
2020-02-16T16:04:28.475366: step 1194, loss 0.370594, acc 0.78125
2020-02-16T16:04:28.593869: step 1195, loss 0.369371, acc 0.921875
2020-02-16T16:04:28.717208: step 1196, loss 0.434785, acc 0.796875
2020-02-16T16:04:28.844314: step 1197, loss 0.23534, acc 0.90625
2020-02-16T16:04:28.966467: step 1198, loss 0.278975, acc 0.859375
2020-02-16T16:04:29.085743: step 1199, loss 0.273734, acc 0.921875
2020-02-16T16:04:29.209203: step 1200, loss 0.253665, acc 0.916667

Evaluation:
2020-02-16T16:04:29.417296: step 1200, loss 0.588164, acc 0.698874

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1200

2020-02-16T16:04:30.946948: step 1201, loss 0.23318, acc 0.90625
2020-02-16T16:04:31.070884: step 1202, loss 0.184979, acc 0.9375
2020-02-16T16:04:31.202633: step 1203, loss 0.242447, acc 0.90625
2020-02-16T16:04:31.322358: step 1204, loss 0.22287, acc 0.921875
2020-02-16T16:04:31.443659: step 1205, loss 0.212204, acc 0.890625
2020-02-16T16:04:31.565843: step 1206, loss 0.272101, acc 0.890625
2020-02-16T16:04:31.685228: step 1207, loss 0.267983, acc 0.90625
2020-02-16T16:04:31.818589: step 1208, loss 0.205244, acc 0.90625
2020-02-16T16:04:31.935714: step 1209, loss 0.232402, acc 0.90625
2020-02-16T16:04:32.053680: step 1210, loss 0.296605, acc 0.84375
2020-02-16T16:04:32.171563: step 1211, loss 0.362376, acc 0.8125
2020-02-16T16:04:32.289624: step 1212, loss 0.19771, acc 0.9375
2020-02-16T16:04:32.411287: step 1213, loss 0.223523, acc 0.90625
2020-02-16T16:04:32.527625: step 1214, loss 0.138939, acc 0.921875
2020-02-16T16:04:32.669372: step 1215, loss 0.215101, acc 0.9375
2020-02-16T16:04:32.820126: step 1216, loss 0.28257, acc 0.890625
2020-02-16T16:04:32.942035: step 1217, loss 0.168928, acc 0.9375
2020-02-16T16:04:33.061078: step 1218, loss 0.200057, acc 0.890625
2020-02-16T16:04:33.178070: step 1219, loss 0.254399, acc 0.890625
2020-02-16T16:04:33.300336: step 1220, loss 0.317304, acc 0.859375
2020-02-16T16:04:33.420801: step 1221, loss 0.269146, acc 0.890625
2020-02-16T16:04:33.536649: step 1222, loss 0.220038, acc 0.921875
2020-02-16T16:04:33.652461: step 1223, loss 0.226578, acc 0.90625
2020-02-16T16:04:33.776920: step 1224, loss 0.285242, acc 0.84375
2020-02-16T16:04:33.898079: step 1225, loss 0.245265, acc 0.921875
2020-02-16T16:04:34.013760: step 1226, loss 0.265482, acc 0.875
2020-02-16T16:04:34.140689: step 1227, loss 0.169374, acc 0.953125
2020-02-16T16:04:34.258065: step 1228, loss 0.167664, acc 0.9375
2020-02-16T16:04:34.391820: step 1229, loss 0.210982, acc 0.921875
2020-02-16T16:04:34.513317: step 1230, loss 0.209943, acc 0.953125
2020-02-16T16:04:34.633436: step 1231, loss 0.18265, acc 0.9375
2020-02-16T16:04:34.756779: step 1232, loss 0.329962, acc 0.890625
2020-02-16T16:04:34.883556: step 1233, loss 0.2459, acc 0.875
2020-02-16T16:04:35.005887: step 1234, loss 0.261397, acc 0.890625
2020-02-16T16:04:35.121828: step 1235, loss 0.254752, acc 0.890625
2020-02-16T16:04:35.239759: step 1236, loss 0.266492, acc 0.890625
2020-02-16T16:04:35.361875: step 1237, loss 0.255192, acc 0.90625
2020-02-16T16:04:35.477664: step 1238, loss 0.191663, acc 0.9375
2020-02-16T16:04:35.601071: step 1239, loss 0.229016, acc 0.890625
2020-02-16T16:04:35.722152: step 1240, loss 0.200889, acc 0.921875
2020-02-16T16:04:35.848752: step 1241, loss 0.291086, acc 0.890625
2020-02-16T16:04:35.969299: step 1242, loss 0.265872, acc 0.90625
2020-02-16T16:04:36.085675: step 1243, loss 0.303057, acc 0.875
2020-02-16T16:04:36.206603: step 1244, loss 0.353471, acc 0.828125
2020-02-16T16:04:36.325601: step 1245, loss 0.207161, acc 0.921875
2020-02-16T16:04:36.442965: step 1246, loss 0.201471, acc 0.90625
2020-02-16T16:04:36.560236: step 1247, loss 0.184617, acc 0.953125
2020-02-16T16:04:36.680335: step 1248, loss 0.247668, acc 0.90625
2020-02-16T16:04:36.810316: step 1249, loss 0.162734, acc 0.9375
2020-02-16T16:04:36.930446: step 1250, loss 0.298538, acc 0.859375
2020-02-16T16:04:37.051050: step 1251, loss 0.233478, acc 0.875
2020-02-16T16:04:37.169479: step 1252, loss 0.262645, acc 0.875
2020-02-16T16:04:37.288110: step 1253, loss 0.200877, acc 0.921875
2020-02-16T16:04:37.438620: step 1254, loss 0.208101, acc 0.921875
2020-02-16T16:04:37.587926: step 1255, loss 0.206486, acc 0.921875
2020-02-16T16:04:37.712774: step 1256, loss 0.251452, acc 0.890625
2020-02-16T16:04:37.873448: step 1257, loss 0.179021, acc 0.9375
2020-02-16T16:04:38.023396: step 1258, loss 0.258616, acc 0.890625
2020-02-16T16:04:38.140751: step 1259, loss 0.240991, acc 0.859375
2020-02-16T16:04:38.269701: step 1260, loss 0.23529, acc 0.90625
2020-02-16T16:04:38.460369: step 1261, loss 0.293375, acc 0.890625
2020-02-16T16:04:38.597579: step 1262, loss 0.212701, acc 0.890625
2020-02-16T16:04:38.738563: step 1263, loss 0.196672, acc 0.921875
2020-02-16T16:04:38.899355: step 1264, loss 0.260784, acc 0.90625
2020-02-16T16:04:39.019220: step 1265, loss 0.322031, acc 0.859375
2020-02-16T16:04:39.140454: step 1266, loss 0.280976, acc 0.921875
2020-02-16T16:04:39.260407: step 1267, loss 0.345954, acc 0.859375
2020-02-16T16:04:39.380422: step 1268, loss 0.140708, acc 0.9375
2020-02-16T16:04:39.512842: step 1269, loss 0.375776, acc 0.859375
2020-02-16T16:04:39.641842: step 1270, loss 0.259694, acc 0.875
2020-02-16T16:04:39.765258: step 1271, loss 0.278759, acc 0.8125
2020-02-16T16:04:39.883192: step 1272, loss 0.360744, acc 0.84375
2020-02-16T16:04:40.001475: step 1273, loss 0.337064, acc 0.859375
2020-02-16T16:04:40.116048: step 1274, loss 0.14125, acc 0.96875
2020-02-16T16:04:40.228575: step 1275, loss 0.266479, acc 0.828125
2020-02-16T16:04:40.346245: step 1276, loss 0.151143, acc 0.953125
2020-02-16T16:04:40.467148: step 1277, loss 0.269685, acc 0.890625
2020-02-16T16:04:40.581438: step 1278, loss 0.207526, acc 0.9375
2020-02-16T16:04:40.699798: step 1279, loss 0.340622, acc 0.859375
2020-02-16T16:04:40.824486: step 1280, loss 0.364564, acc 0.875
2020-02-16T16:04:40.944528: step 1281, loss 0.38225, acc 0.828125
2020-02-16T16:04:41.060536: step 1282, loss 0.185138, acc 0.9375
2020-02-16T16:04:41.177088: step 1283, loss 0.173819, acc 0.9375
2020-02-16T16:04:41.314089: step 1284, loss 0.266404, acc 0.875
2020-02-16T16:04:41.469978: step 1285, loss 0.261745, acc 0.921875
2020-02-16T16:04:41.621067: step 1286, loss 0.24608, acc 0.90625
2020-02-16T16:04:41.745356: step 1287, loss 0.249723, acc 0.875
2020-02-16T16:04:41.867206: step 1288, loss 0.237257, acc 0.921875
2020-02-16T16:04:41.987886: step 1289, loss 0.224534, acc 0.921875
2020-02-16T16:04:42.108213: step 1290, loss 0.22023, acc 0.921875
2020-02-16T16:04:42.238112: step 1291, loss 0.216798, acc 0.9375
2020-02-16T16:04:42.364403: step 1292, loss 0.239886, acc 0.890625
2020-02-16T16:04:42.482647: step 1293, loss 0.183713, acc 0.9375
2020-02-16T16:04:42.605045: step 1294, loss 0.37899, acc 0.8125
2020-02-16T16:04:42.723624: step 1295, loss 0.233633, acc 0.90625
2020-02-16T16:04:42.849204: step 1296, loss 0.15024, acc 0.90625
2020-02-16T16:04:43.017101: step 1297, loss 0.314014, acc 0.890625
2020-02-16T16:04:43.177459: step 1298, loss 0.163128, acc 0.9375
2020-02-16T16:04:43.312845: step 1299, loss 0.259903, acc 0.90625
2020-02-16T16:04:43.457758: step 1300, loss 0.19135, acc 0.9375

Evaluation:
2020-02-16T16:04:43.705334: step 1300, loss 0.605805, acc 0.709193

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1300

2020-02-16T16:04:45.297766: step 1301, loss 0.172473, acc 0.90625
2020-02-16T16:04:45.427288: step 1302, loss 0.425513, acc 0.84375
2020-02-16T16:04:45.578259: step 1303, loss 0.178135, acc 0.953125
2020-02-16T16:04:45.759085: step 1304, loss 0.271797, acc 0.890625
2020-02-16T16:04:45.879926: step 1305, loss 0.364683, acc 0.859375
2020-02-16T16:04:45.998533: step 1306, loss 0.297089, acc 0.84375
2020-02-16T16:04:46.116959: step 1307, loss 0.303647, acc 0.8125
2020-02-16T16:04:46.242066: step 1308, loss 0.293621, acc 0.875
2020-02-16T16:04:46.369067: step 1309, loss 0.362564, acc 0.859375
2020-02-16T16:04:46.496625: step 1310, loss 0.213454, acc 0.9375
2020-02-16T16:04:46.614989: step 1311, loss 0.217683, acc 0.875
2020-02-16T16:04:46.734071: step 1312, loss 0.211246, acc 0.90625
2020-02-16T16:04:46.855902: step 1313, loss 0.203512, acc 0.890625
2020-02-16T16:04:46.972299: step 1314, loss 0.234939, acc 0.90625
2020-02-16T16:04:47.090080: step 1315, loss 0.312345, acc 0.890625
2020-02-16T16:04:47.211410: step 1316, loss 0.25558, acc 0.859375
2020-02-16T16:04:47.328462: step 1317, loss 0.285248, acc 0.890625
2020-02-16T16:04:47.446362: step 1318, loss 0.13989, acc 0.96875
2020-02-16T16:04:47.563367: step 1319, loss 0.2824, acc 0.890625
2020-02-16T16:04:47.689336: step 1320, loss 0.311884, acc 0.859375
2020-02-16T16:04:47.859644: step 1321, loss 0.261661, acc 0.84375
2020-02-16T16:04:48.024138: step 1322, loss 0.132761, acc 0.96875
2020-02-16T16:04:48.146840: step 1323, loss 0.193268, acc 0.9375
2020-02-16T16:04:48.269644: step 1324, loss 0.320845, acc 0.921875
2020-02-16T16:04:48.447490: step 1325, loss 0.227348, acc 0.875
2020-02-16T16:04:48.575898: step 1326, loss 0.27753, acc 0.890625
2020-02-16T16:04:48.698020: step 1327, loss 0.361917, acc 0.84375
2020-02-16T16:04:48.823508: step 1328, loss 0.168658, acc 0.953125
2020-02-16T16:04:48.942367: step 1329, loss 0.114268, acc 0.96875
2020-02-16T16:04:49.072364: step 1330, loss 0.25144, acc 0.890625
2020-02-16T16:04:49.208963: step 1331, loss 0.29023, acc 0.890625
2020-02-16T16:04:49.328662: step 1332, loss 0.258004, acc 0.890625
2020-02-16T16:04:49.444613: step 1333, loss 0.308518, acc 0.859375
2020-02-16T16:04:49.565040: step 1334, loss 0.239158, acc 0.953125
2020-02-16T16:04:49.686039: step 1335, loss 0.310555, acc 0.859375
2020-02-16T16:04:49.814271: step 1336, loss 0.208597, acc 0.921875
2020-02-16T16:04:49.932314: step 1337, loss 0.226383, acc 0.90625
2020-02-16T16:04:50.050137: step 1338, loss 0.28036, acc 0.84375
2020-02-16T16:04:50.167224: step 1339, loss 0.308552, acc 0.8125
2020-02-16T16:04:50.286241: step 1340, loss 0.324545, acc 0.859375
2020-02-16T16:04:50.403691: step 1341, loss 0.234826, acc 0.890625
2020-02-16T16:04:50.521577: step 1342, loss 0.348696, acc 0.828125
2020-02-16T16:04:50.638547: step 1343, loss 0.295756, acc 0.84375
2020-02-16T16:04:50.765293: step 1344, loss 0.236784, acc 0.90625
2020-02-16T16:04:50.880698: step 1345, loss 0.281644, acc 0.90625
2020-02-16T16:04:50.997398: step 1346, loss 0.295981, acc 0.90625
2020-02-16T16:04:51.113737: step 1347, loss 0.212188, acc 0.9375
2020-02-16T16:04:51.229788: step 1348, loss 0.259355, acc 0.90625
2020-02-16T16:04:51.350445: step 1349, loss 0.202046, acc 0.9375
2020-02-16T16:04:51.467565: step 1350, loss 0.235874, acc 0.9
2020-02-16T16:04:51.592307: step 1351, loss 0.248867, acc 0.890625
2020-02-16T16:04:51.713253: step 1352, loss 0.111659, acc 0.96875
2020-02-16T16:04:51.840520: step 1353, loss 0.146004, acc 0.953125
2020-02-16T16:04:51.961179: step 1354, loss 0.165549, acc 0.953125
2020-02-16T16:04:52.078090: step 1355, loss 0.191965, acc 0.953125
2020-02-16T16:04:52.220858: step 1356, loss 0.179769, acc 0.9375
2020-02-16T16:04:52.383055: step 1357, loss 0.223109, acc 0.90625
2020-02-16T16:04:52.503766: step 1358, loss 0.17295, acc 0.96875
2020-02-16T16:04:52.621132: step 1359, loss 0.235376, acc 0.890625
2020-02-16T16:04:52.795713: step 1360, loss 0.185104, acc 0.921875
2020-02-16T16:04:52.943991: step 1361, loss 0.335268, acc 0.90625
2020-02-16T16:04:53.065566: step 1362, loss 0.141731, acc 0.953125
2020-02-16T16:04:53.215373: step 1363, loss 0.160264, acc 0.9375
2020-02-16T16:04:53.378127: step 1364, loss 0.248703, acc 0.859375
2020-02-16T16:04:53.500601: step 1365, loss 0.113338, acc 0.984375
2020-02-16T16:04:53.619744: step 1366, loss 0.260555, acc 0.875
2020-02-16T16:04:53.759498: step 1367, loss 0.205265, acc 0.90625
2020-02-16T16:04:53.889647: step 1368, loss 0.16551, acc 0.953125
2020-02-16T16:04:54.018904: step 1369, loss 0.205754, acc 0.890625
2020-02-16T16:04:54.143848: step 1370, loss 0.255886, acc 0.90625
2020-02-16T16:04:54.264636: step 1371, loss 0.209592, acc 0.9375
2020-02-16T16:04:54.379959: step 1372, loss 0.111008, acc 0.984375
2020-02-16T16:04:54.499917: step 1373, loss 0.153862, acc 0.953125
2020-02-16T16:04:54.619162: step 1374, loss 0.120647, acc 0.953125
2020-02-16T16:04:54.742949: step 1375, loss 0.212825, acc 0.9375
2020-02-16T16:04:54.865399: step 1376, loss 0.224653, acc 0.875
2020-02-16T16:04:54.986582: step 1377, loss 0.146134, acc 0.921875
2020-02-16T16:04:55.108853: step 1378, loss 0.236739, acc 0.9375
2020-02-16T16:04:55.228139: step 1379, loss 0.163062, acc 0.921875
2020-02-16T16:04:55.349303: step 1380, loss 0.128963, acc 0.96875
2020-02-16T16:04:55.467634: step 1381, loss 0.161249, acc 0.9375
2020-02-16T16:04:55.583481: step 1382, loss 0.176833, acc 0.9375
2020-02-16T16:04:55.704257: step 1383, loss 0.136909, acc 0.96875
2020-02-16T16:04:55.830914: step 1384, loss 0.224047, acc 0.90625
2020-02-16T16:04:55.949114: step 1385, loss 0.228936, acc 0.875
2020-02-16T16:04:56.070049: step 1386, loss 0.240106, acc 0.890625
2020-02-16T16:04:56.190735: step 1387, loss 0.162576, acc 0.96875
2020-02-16T16:04:56.308926: step 1388, loss 0.146926, acc 0.96875
2020-02-16T16:04:56.425495: step 1389, loss 0.199704, acc 0.890625
2020-02-16T16:04:56.547034: step 1390, loss 0.311002, acc 0.890625
2020-02-16T16:04:56.673073: step 1391, loss 0.238145, acc 0.9375
2020-02-16T16:04:56.835311: step 1392, loss 0.176105, acc 0.953125
2020-02-16T16:04:56.958222: step 1393, loss 0.174882, acc 0.9375
2020-02-16T16:04:57.075343: step 1394, loss 0.196267, acc 0.921875
2020-02-16T16:04:57.199390: step 1395, loss 0.190419, acc 0.90625
2020-02-16T16:04:57.318568: step 1396, loss 0.181573, acc 0.921875
2020-02-16T16:04:57.448192: step 1397, loss 0.107911, acc 1
2020-02-16T16:04:57.576482: step 1398, loss 0.150418, acc 0.953125
2020-02-16T16:04:57.697514: step 1399, loss 0.224001, acc 0.9375
2020-02-16T16:04:57.823300: step 1400, loss 0.126802, acc 0.9375

Evaluation:
2020-02-16T16:04:58.015300: step 1400, loss 0.626269, acc 0.702627

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1400

2020-02-16T16:04:59.583144: step 1401, loss 0.182126, acc 0.921875
2020-02-16T16:04:59.706494: step 1402, loss 0.233387, acc 0.90625
2020-02-16T16:04:59.844617: step 1403, loss 0.166561, acc 0.984375
2020-02-16T16:04:59.972713: step 1404, loss 0.195939, acc 0.9375
2020-02-16T16:05:00.100197: step 1405, loss 0.166697, acc 0.921875
2020-02-16T16:05:00.225780: step 1406, loss 0.200939, acc 0.953125
2020-02-16T16:05:00.349067: step 1407, loss 0.231075, acc 0.875
2020-02-16T16:05:00.486290: step 1408, loss 0.131649, acc 0.953125
2020-02-16T16:05:00.608831: step 1409, loss 0.210972, acc 0.875
2020-02-16T16:05:00.916325: step 1410, loss 0.277185, acc 0.90625
2020-02-16T16:05:01.065892: step 1411, loss 0.196427, acc 0.953125
2020-02-16T16:05:01.192683: step 1412, loss 0.251009, acc 0.921875
2020-02-16T16:05:01.336405: step 1413, loss 0.194982, acc 0.9375
2020-02-16T16:05:01.770202: step 1414, loss 0.107696, acc 0.953125
2020-02-16T16:05:01.964901: step 1415, loss 0.170095, acc 0.90625
2020-02-16T16:05:02.114610: step 1416, loss 0.152678, acc 0.9375
2020-02-16T16:05:02.307270: step 1417, loss 0.219573, acc 0.90625
2020-02-16T16:05:02.444364: step 1418, loss 0.214744, acc 0.921875
2020-02-16T16:05:02.570005: step 1419, loss 0.196397, acc 0.921875
2020-02-16T16:05:02.704110: step 1420, loss 0.19614, acc 0.921875
2020-02-16T16:05:02.864284: step 1421, loss 0.167637, acc 0.953125
2020-02-16T16:05:02.988268: step 1422, loss 0.169648, acc 0.9375
2020-02-16T16:05:03.110099: step 1423, loss 0.178649, acc 0.890625
2020-02-16T16:05:03.227679: step 1424, loss 0.119833, acc 0.96875
2020-02-16T16:05:03.359494: step 1425, loss 0.209847, acc 0.921875
2020-02-16T16:05:03.502715: step 1426, loss 0.151798, acc 0.921875
2020-02-16T16:05:03.667503: step 1427, loss 0.121766, acc 0.953125
2020-02-16T16:05:03.835693: step 1428, loss 0.139783, acc 0.984375
2020-02-16T16:05:03.959526: step 1429, loss 0.220023, acc 0.921875
2020-02-16T16:05:04.090145: step 1430, loss 0.211769, acc 0.890625
2020-02-16T16:05:04.259972: step 1431, loss 0.162292, acc 0.96875
2020-02-16T16:05:04.378162: step 1432, loss 0.202415, acc 0.90625
2020-02-16T16:05:04.520699: step 1433, loss 0.224856, acc 0.90625
2020-02-16T16:05:04.693770: step 1434, loss 0.153386, acc 0.953125
2020-02-16T16:05:04.860851: step 1435, loss 0.26144, acc 0.875
2020-02-16T16:05:05.068218: step 1436, loss 0.125599, acc 0.96875
2020-02-16T16:05:05.238232: step 1437, loss 0.173813, acc 0.921875
2020-02-16T16:05:05.420861: step 1438, loss 0.23865, acc 0.90625
2020-02-16T16:05:05.594263: step 1439, loss 0.249887, acc 0.890625
2020-02-16T16:05:05.761578: step 1440, loss 0.196452, acc 0.890625
2020-02-16T16:05:05.940892: step 1441, loss 0.236128, acc 0.921875
2020-02-16T16:05:06.099214: step 1442, loss 0.227697, acc 0.9375
2020-02-16T16:05:06.263717: step 1443, loss 0.260872, acc 0.875
2020-02-16T16:05:06.521805: step 1444, loss 0.314342, acc 0.875
2020-02-16T16:05:06.673629: step 1445, loss 0.156679, acc 0.953125
2020-02-16T16:05:06.876316: step 1446, loss 0.170576, acc 0.921875
2020-02-16T16:05:07.004173: step 1447, loss 0.162502, acc 0.90625
2020-02-16T16:05:07.246105: step 1448, loss 0.172995, acc 0.921875
2020-02-16T16:05:07.384464: step 1449, loss 0.247694, acc 0.875
2020-02-16T16:05:07.509901: step 1450, loss 0.151296, acc 0.921875
2020-02-16T16:05:07.637760: step 1451, loss 0.36276, acc 0.875
2020-02-16T16:05:07.762300: step 1452, loss 0.151346, acc 0.96875
2020-02-16T16:05:07.964077: step 1453, loss 0.220516, acc 0.90625
2020-02-16T16:05:08.140309: step 1454, loss 0.224595, acc 0.890625
2020-02-16T16:05:08.262149: step 1455, loss 0.191581, acc 0.9375
2020-02-16T16:05:08.392009: step 1456, loss 0.161246, acc 0.953125
2020-02-16T16:05:08.522342: step 1457, loss 0.132608, acc 0.953125
2020-02-16T16:05:08.687130: step 1458, loss 0.111264, acc 0.96875
2020-02-16T16:05:08.902753: step 1459, loss 0.252854, acc 0.90625
2020-02-16T16:05:09.079696: step 1460, loss 0.116418, acc 0.96875
2020-02-16T16:05:09.241220: step 1461, loss 0.228811, acc 0.90625
2020-02-16T16:05:09.381740: step 1462, loss 0.279473, acc 0.890625
2020-02-16T16:05:09.514372: step 1463, loss 0.228732, acc 0.953125
2020-02-16T16:05:09.703617: step 1464, loss 0.201355, acc 0.875
2020-02-16T16:05:09.908403: step 1465, loss 0.177996, acc 0.921875
2020-02-16T16:05:10.074591: step 1466, loss 0.149616, acc 0.9375
2020-02-16T16:05:10.285869: step 1467, loss 0.184915, acc 0.921875
2020-02-16T16:05:10.446514: step 1468, loss 0.205802, acc 0.890625
2020-02-16T16:05:10.577128: step 1469, loss 0.239961, acc 0.875
2020-02-16T16:05:10.753886: step 1470, loss 0.195008, acc 0.953125
2020-02-16T16:05:10.886983: step 1471, loss 0.308324, acc 0.84375
2020-02-16T16:05:11.014532: step 1472, loss 0.137242, acc 0.953125
2020-02-16T16:05:11.185332: step 1473, loss 0.205344, acc 0.921875
2020-02-16T16:05:11.354741: step 1474, loss 0.12337, acc 0.96875
2020-02-16T16:05:11.563354: step 1475, loss 0.323811, acc 0.84375
2020-02-16T16:05:11.839410: step 1476, loss 0.155616, acc 0.9375
2020-02-16T16:05:12.114747: step 1477, loss 0.158025, acc 0.953125
2020-02-16T16:05:12.313823: step 1478, loss 0.314411, acc 0.859375
2020-02-16T16:05:12.437015: step 1479, loss 0.219212, acc 0.90625
2020-02-16T16:05:12.573013: step 1480, loss 0.144657, acc 0.9375
2020-02-16T16:05:12.819986: step 1481, loss 0.140788, acc 0.953125
2020-02-16T16:05:13.020650: step 1482, loss 0.133082, acc 0.953125
2020-02-16T16:05:13.311329: step 1483, loss 0.259092, acc 0.90625
2020-02-16T16:05:13.477809: step 1484, loss 0.124568, acc 0.953125
2020-02-16T16:05:13.601655: step 1485, loss 0.172157, acc 0.9375
2020-02-16T16:05:13.729646: step 1486, loss 0.253159, acc 0.875
2020-02-16T16:05:13.879626: step 1487, loss 0.304356, acc 0.90625
2020-02-16T16:05:14.021539: step 1488, loss 0.144024, acc 0.9375
2020-02-16T16:05:14.144893: step 1489, loss 0.299995, acc 0.84375
2020-02-16T16:05:14.263903: step 1490, loss 0.245791, acc 0.875
2020-02-16T16:05:14.398533: step 1491, loss 0.164861, acc 0.921875
2020-02-16T16:05:14.610971: step 1492, loss 0.140624, acc 0.9375
2020-02-16T16:05:14.801349: step 1493, loss 0.258775, acc 0.875
2020-02-16T16:05:14.926137: step 1494, loss 0.157409, acc 0.9375
2020-02-16T16:05:15.051255: step 1495, loss 0.188318, acc 0.890625
2020-02-16T16:05:15.169185: step 1496, loss 0.163223, acc 0.9375
2020-02-16T16:05:15.288732: step 1497, loss 0.22116, acc 0.90625
2020-02-16T16:05:15.420148: step 1498, loss 0.209067, acc 0.890625
2020-02-16T16:05:15.553306: step 1499, loss 0.150653, acc 0.953125
2020-02-16T16:05:15.671299: step 1500, loss 0.153359, acc 0.916667

Evaluation:
2020-02-16T16:05:15.922830: step 1500, loss 0.624701, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1500

2020-02-16T16:05:17.673271: step 1501, loss 0.116175, acc 0.9375
2020-02-16T16:05:17.957634: step 1502, loss 0.216533, acc 0.90625
2020-02-16T16:05:18.233196: step 1503, loss 0.0801418, acc 0.984375
2020-02-16T16:05:18.552109: step 1504, loss 0.116254, acc 0.96875
2020-02-16T16:05:18.768275: step 1505, loss 0.11501, acc 0.96875
2020-02-16T16:05:19.055089: step 1506, loss 0.0993107, acc 0.96875
2020-02-16T16:05:19.283421: step 1507, loss 0.111652, acc 0.953125
2020-02-16T16:05:19.532408: step 1508, loss 0.204401, acc 0.921875
2020-02-16T16:05:19.688061: step 1509, loss 0.142904, acc 0.921875
2020-02-16T16:05:19.892579: step 1510, loss 0.104207, acc 0.96875
2020-02-16T16:05:20.056966: step 1511, loss 0.0946767, acc 0.96875
2020-02-16T16:05:20.200106: step 1512, loss 0.122187, acc 0.9375
2020-02-16T16:05:20.373468: step 1513, loss 0.201779, acc 0.90625
2020-02-16T16:05:20.510550: step 1514, loss 0.178363, acc 0.921875
2020-02-16T16:05:20.673025: step 1515, loss 0.154655, acc 0.9375
2020-02-16T16:05:20.868207: step 1516, loss 0.1534, acc 0.9375
2020-02-16T16:05:21.021938: step 1517, loss 0.237324, acc 0.890625
2020-02-16T16:05:21.196692: step 1518, loss 0.111606, acc 0.953125
2020-02-16T16:05:21.322508: step 1519, loss 0.123642, acc 0.953125
2020-02-16T16:05:21.475618: step 1520, loss 0.0686819, acc 0.96875
2020-02-16T16:05:21.615015: step 1521, loss 0.145972, acc 0.96875
2020-02-16T16:05:21.745283: step 1522, loss 0.253569, acc 0.859375
2020-02-16T16:05:21.884344: step 1523, loss 0.121969, acc 0.96875
2020-02-16T16:05:22.030312: step 1524, loss 0.21773, acc 0.9375
2020-02-16T16:05:22.164870: step 1525, loss 0.120088, acc 0.953125
2020-02-16T16:05:22.361039: step 1526, loss 0.177274, acc 0.9375
2020-02-16T16:05:22.629254: step 1527, loss 0.164436, acc 0.921875
2020-02-16T16:05:22.806571: step 1528, loss 0.154114, acc 0.90625
2020-02-16T16:05:22.956972: step 1529, loss 0.159269, acc 0.921875
2020-02-16T16:05:23.081137: step 1530, loss 0.226972, acc 0.921875
2020-02-16T16:05:23.218544: step 1531, loss 0.0981291, acc 0.96875
2020-02-16T16:05:23.367392: step 1532, loss 0.136951, acc 0.953125
2020-02-16T16:05:23.510761: step 1533, loss 0.142093, acc 0.96875
2020-02-16T16:05:23.757790: step 1534, loss 0.254348, acc 0.90625
2020-02-16T16:05:24.061794: step 1535, loss 0.140445, acc 0.96875
2020-02-16T16:05:24.243421: step 1536, loss 0.0904473, acc 0.984375
2020-02-16T16:05:24.433933: step 1537, loss 0.273138, acc 0.859375
2020-02-16T16:05:24.617989: step 1538, loss 0.141832, acc 0.921875
2020-02-16T16:05:24.776828: step 1539, loss 0.105893, acc 0.953125
2020-02-16T16:05:24.917404: step 1540, loss 0.134723, acc 0.953125
2020-02-16T16:05:25.094466: step 1541, loss 0.130564, acc 0.953125
2020-02-16T16:05:25.218249: step 1542, loss 0.109404, acc 0.984375
2020-02-16T16:05:25.347224: step 1543, loss 0.0887719, acc 0.96875
2020-02-16T16:05:25.471262: step 1544, loss 0.1078, acc 0.953125
2020-02-16T16:05:25.592858: step 1545, loss 0.141148, acc 0.953125
2020-02-16T16:05:25.718900: step 1546, loss 0.146416, acc 0.921875
2020-02-16T16:05:25.863283: step 1547, loss 0.177295, acc 0.921875
2020-02-16T16:05:25.999640: step 1548, loss 0.152841, acc 0.953125
2020-02-16T16:05:26.124607: step 1549, loss 0.153917, acc 0.9375
2020-02-16T16:05:26.248593: step 1550, loss 0.151834, acc 0.921875
2020-02-16T16:05:26.418173: step 1551, loss 0.0779415, acc 0.96875
2020-02-16T16:05:26.570691: step 1552, loss 0.100139, acc 0.96875
2020-02-16T16:05:26.738461: step 1553, loss 0.116678, acc 0.96875
2020-02-16T16:05:26.910816: step 1554, loss 0.13691, acc 0.921875
2020-02-16T16:05:27.057852: step 1555, loss 0.125497, acc 0.96875
2020-02-16T16:05:27.210824: step 1556, loss 0.17775, acc 0.921875
2020-02-16T16:05:27.348765: step 1557, loss 0.0863327, acc 0.96875
2020-02-16T16:05:27.482545: step 1558, loss 0.177822, acc 0.921875
2020-02-16T16:05:27.617818: step 1559, loss 0.137313, acc 0.9375
2020-02-16T16:05:27.760232: step 1560, loss 0.0981405, acc 0.984375
2020-02-16T16:05:27.898343: step 1561, loss 0.124835, acc 0.96875
2020-02-16T16:05:28.036479: step 1562, loss 0.215833, acc 0.9375
2020-02-16T16:05:28.169352: step 1563, loss 0.189563, acc 0.9375
2020-02-16T16:05:28.305924: step 1564, loss 0.166523, acc 0.921875
2020-02-16T16:05:28.441413: step 1565, loss 0.176873, acc 0.9375
2020-02-16T16:05:28.577954: step 1566, loss 0.0832983, acc 0.984375
2020-02-16T16:05:28.712847: step 1567, loss 0.122229, acc 0.96875
2020-02-16T16:05:28.857245: step 1568, loss 0.108907, acc 0.953125
2020-02-16T16:05:28.982864: step 1569, loss 0.148894, acc 0.953125
2020-02-16T16:05:29.109374: step 1570, loss 0.220803, acc 0.9375
2020-02-16T16:05:29.230475: step 1571, loss 0.136006, acc 0.953125
2020-02-16T16:05:29.366634: step 1572, loss 0.15696, acc 0.953125
2020-02-16T16:05:29.502445: step 1573, loss 0.154042, acc 0.953125
2020-02-16T16:05:29.625801: step 1574, loss 0.0977135, acc 0.96875
2020-02-16T16:05:29.770443: step 1575, loss 0.176141, acc 0.9375
2020-02-16T16:05:29.920021: step 1576, loss 0.224553, acc 0.9375
2020-02-16T16:05:30.070041: step 1577, loss 0.101625, acc 0.96875
2020-02-16T16:05:30.197277: step 1578, loss 0.17851, acc 0.953125
2020-02-16T16:05:30.329543: step 1579, loss 0.0988753, acc 0.96875
2020-02-16T16:05:30.464380: step 1580, loss 0.06411, acc 1
2020-02-16T16:05:30.593470: step 1581, loss 0.153453, acc 0.921875
2020-02-16T16:05:30.725574: step 1582, loss 0.164935, acc 0.90625
2020-02-16T16:05:30.985662: step 1583, loss 0.200985, acc 0.921875
2020-02-16T16:05:31.121489: step 1584, loss 0.142649, acc 0.953125
2020-02-16T16:05:31.269615: step 1585, loss 0.209468, acc 0.921875
2020-02-16T16:05:31.403982: step 1586, loss 0.0684327, acc 0.984375
2020-02-16T16:05:31.541791: step 1587, loss 0.0949146, acc 0.96875
2020-02-16T16:05:31.708380: step 1588, loss 0.128286, acc 0.9375
2020-02-16T16:05:31.977922: step 1589, loss 0.0934248, acc 0.984375
2020-02-16T16:05:32.113827: step 1590, loss 0.214616, acc 0.9375
2020-02-16T16:05:32.253574: step 1591, loss 0.234089, acc 0.890625
2020-02-16T16:05:32.423376: step 1592, loss 0.180797, acc 0.9375
2020-02-16T16:05:32.632024: step 1593, loss 0.154309, acc 0.9375
2020-02-16T16:05:33.156787: step 1594, loss 0.133355, acc 0.953125
2020-02-16T16:05:33.345565: step 1595, loss 0.175958, acc 0.921875
2020-02-16T16:05:33.555610: step 1596, loss 0.0610207, acc 0.984375
2020-02-16T16:05:33.753242: step 1597, loss 0.0977644, acc 0.96875
2020-02-16T16:05:33.890448: step 1598, loss 0.142948, acc 0.96875
2020-02-16T16:05:34.021631: step 1599, loss 0.114878, acc 0.953125
2020-02-16T16:05:34.176697: step 1600, loss 0.0890854, acc 0.96875

Evaluation:
2020-02-16T16:05:34.520608: step 1600, loss 0.646053, acc 0.71576

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1600

2020-02-16T16:05:36.379080: step 1601, loss 0.162301, acc 0.90625
2020-02-16T16:05:36.526974: step 1602, loss 0.129313, acc 0.9375
2020-02-16T16:05:36.663650: step 1603, loss 0.153055, acc 0.96875
2020-02-16T16:05:36.800068: step 1604, loss 0.1869, acc 0.953125
2020-02-16T16:05:36.973527: step 1605, loss 0.128251, acc 0.96875
2020-02-16T16:05:37.122054: step 1606, loss 0.178389, acc 0.9375
2020-02-16T16:05:37.257809: step 1607, loss 0.148545, acc 0.9375
2020-02-16T16:05:37.398126: step 1608, loss 0.231464, acc 0.890625
2020-02-16T16:05:37.524675: step 1609, loss 0.120472, acc 0.953125
2020-02-16T16:05:37.669199: step 1610, loss 0.137401, acc 0.953125
2020-02-16T16:05:37.828161: step 1611, loss 0.14254, acc 0.953125
2020-02-16T16:05:37.961831: step 1612, loss 0.126982, acc 0.953125
2020-02-16T16:05:38.106199: step 1613, loss 0.17608, acc 0.90625
2020-02-16T16:05:38.267747: step 1614, loss 0.228986, acc 0.890625
2020-02-16T16:05:38.402774: step 1615, loss 0.0688164, acc 0.984375
2020-02-16T16:05:38.543034: step 1616, loss 0.118237, acc 0.96875
2020-02-16T16:05:38.765171: step 1617, loss 0.108577, acc 0.96875
2020-02-16T16:05:38.959422: step 1618, loss 0.121726, acc 0.9375
2020-02-16T16:05:39.137438: step 1619, loss 0.088402, acc 0.96875
2020-02-16T16:05:39.305309: step 1620, loss 0.21162, acc 0.890625
2020-02-16T16:05:39.498152: step 1621, loss 0.0738505, acc 0.984375
2020-02-16T16:05:39.642615: step 1622, loss 0.136973, acc 0.953125
2020-02-16T16:05:39.809754: step 1623, loss 0.113371, acc 0.96875
2020-02-16T16:05:40.023539: step 1624, loss 0.0869138, acc 1
2020-02-16T16:05:40.221908: step 1625, loss 0.127268, acc 0.96875
2020-02-16T16:05:40.413767: step 1626, loss 0.0722428, acc 0.96875
2020-02-16T16:05:40.569885: step 1627, loss 0.116094, acc 0.9375
2020-02-16T16:05:40.734272: step 1628, loss 0.298429, acc 0.890625
2020-02-16T16:05:40.897775: step 1629, loss 0.16202, acc 0.921875
2020-02-16T16:05:41.044403: step 1630, loss 0.216369, acc 0.921875
2020-02-16T16:05:41.195266: step 1631, loss 0.22684, acc 0.890625
2020-02-16T16:05:41.357745: step 1632, loss 0.282644, acc 0.90625
2020-02-16T16:05:41.520149: step 1633, loss 0.0967067, acc 0.984375
2020-02-16T16:05:41.674115: step 1634, loss 0.117007, acc 0.9375
2020-02-16T16:05:41.840132: step 1635, loss 0.127943, acc 0.9375
2020-02-16T16:05:41.993850: step 1636, loss 0.257792, acc 0.921875
2020-02-16T16:05:42.162236: step 1637, loss 0.166333, acc 0.953125
2020-02-16T16:05:42.337303: step 1638, loss 0.169905, acc 0.890625
2020-02-16T16:05:42.521874: step 1639, loss 0.136324, acc 0.96875
2020-02-16T16:05:42.694196: step 1640, loss 0.168509, acc 0.953125
2020-02-16T16:05:42.850769: step 1641, loss 0.112237, acc 0.96875
2020-02-16T16:05:43.013180: step 1642, loss 0.20832, acc 0.90625
2020-02-16T16:05:43.236483: step 1643, loss 0.26954, acc 0.921875
2020-02-16T16:05:43.398063: step 1644, loss 0.101192, acc 0.96875
2020-02-16T16:05:43.531624: step 1645, loss 0.216909, acc 0.921875
2020-02-16T16:05:43.664254: step 1646, loss 0.182371, acc 0.90625
2020-02-16T16:05:43.833914: step 1647, loss 0.100002, acc 0.96875
2020-02-16T16:05:43.988418: step 1648, loss 0.120528, acc 0.953125
2020-02-16T16:05:44.125234: step 1649, loss 0.0691821, acc 0.984375
2020-02-16T16:05:44.265918: step 1650, loss 0.131031, acc 0.916667
2020-02-16T16:05:44.436313: step 1651, loss 0.113297, acc 0.984375
2020-02-16T16:05:44.570016: step 1652, loss 0.0809362, acc 0.953125
2020-02-16T16:05:44.703758: step 1653, loss 0.0883881, acc 0.96875
2020-02-16T16:05:44.853373: step 1654, loss 0.111134, acc 0.96875
2020-02-16T16:05:45.009498: step 1655, loss 0.130273, acc 0.9375
2020-02-16T16:05:45.165594: step 1656, loss 0.0743971, acc 0.96875
2020-02-16T16:05:45.305275: step 1657, loss 0.163648, acc 0.921875
2020-02-16T16:05:45.441469: step 1658, loss 0.123668, acc 0.953125
2020-02-16T16:05:45.580087: step 1659, loss 0.170739, acc 0.953125
2020-02-16T16:05:45.721451: step 1660, loss 0.0514548, acc 1
2020-02-16T16:05:45.871493: step 1661, loss 0.160102, acc 0.90625
2020-02-16T16:05:46.011629: step 1662, loss 0.091463, acc 0.96875
2020-02-16T16:05:46.151583: step 1663, loss 0.0886292, acc 0.984375
2020-02-16T16:05:46.292060: step 1664, loss 0.133655, acc 0.953125
2020-02-16T16:05:46.504711: step 1665, loss 0.0511385, acc 1
2020-02-16T16:05:46.659943: step 1666, loss 0.122927, acc 0.953125
2020-02-16T16:05:46.812255: step 1667, loss 0.126197, acc 0.953125
2020-02-16T16:05:47.001727: step 1668, loss 0.0857602, acc 0.96875
2020-02-16T16:05:47.162229: step 1669, loss 0.0855561, acc 0.953125
2020-02-16T16:05:47.305359: step 1670, loss 0.19539, acc 0.953125
2020-02-16T16:05:47.456978: step 1671, loss 0.126814, acc 0.921875
2020-02-16T16:05:47.659120: step 1672, loss 0.213611, acc 0.90625
2020-02-16T16:05:47.811108: step 1673, loss 0.112103, acc 0.984375
2020-02-16T16:05:47.962200: step 1674, loss 0.0875461, acc 0.984375
2020-02-16T16:05:48.106078: step 1675, loss 0.119854, acc 0.984375
2020-02-16T16:05:48.273908: step 1676, loss 0.160136, acc 0.921875
2020-02-16T16:05:48.420477: step 1677, loss 0.117602, acc 0.953125
2020-02-16T16:05:48.555319: step 1678, loss 0.126474, acc 0.953125
2020-02-16T16:05:48.702362: step 1679, loss 0.0924499, acc 0.984375
2020-02-16T16:05:48.881759: step 1680, loss 0.0945011, acc 0.96875
2020-02-16T16:05:49.023868: step 1681, loss 0.0775712, acc 0.953125
2020-02-16T16:05:49.157013: step 1682, loss 0.0992457, acc 0.953125
2020-02-16T16:05:49.286036: step 1683, loss 0.178733, acc 0.921875
2020-02-16T16:05:49.439085: step 1684, loss 0.10607, acc 0.953125
2020-02-16T16:05:49.590943: step 1685, loss 0.109332, acc 0.96875
2020-02-16T16:05:49.737184: step 1686, loss 0.111669, acc 0.96875
2020-02-16T16:05:49.948250: step 1687, loss 0.0804517, acc 0.96875
2020-02-16T16:05:50.090942: step 1688, loss 0.0952567, acc 0.96875
2020-02-16T16:05:50.230505: step 1689, loss 0.087695, acc 0.96875
2020-02-16T16:05:50.478572: step 1690, loss 0.0923729, acc 0.96875
2020-02-16T16:05:50.627113: step 1691, loss 0.107463, acc 0.96875
2020-02-16T16:05:50.771984: step 1692, loss 0.0769853, acc 0.984375
2020-02-16T16:05:50.973503: step 1693, loss 0.0761658, acc 0.984375
2020-02-16T16:05:51.159799: step 1694, loss 0.13229, acc 0.9375
2020-02-16T16:05:51.302070: step 1695, loss 0.0874743, acc 0.984375
2020-02-16T16:05:51.458659: step 1696, loss 0.142738, acc 0.96875
2020-02-16T16:05:51.633828: step 1697, loss 0.1394, acc 0.96875
2020-02-16T16:05:51.821909: step 1698, loss 0.224386, acc 0.90625
2020-02-16T16:05:51.973295: step 1699, loss 0.0816219, acc 0.984375
2020-02-16T16:05:52.163677: step 1700, loss 0.15903, acc 0.953125

Evaluation:
2020-02-16T16:05:52.529665: step 1700, loss 0.683844, acc 0.716698

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1700

2020-02-16T16:05:54.644117: step 1701, loss 0.149801, acc 0.921875
2020-02-16T16:05:54.808549: step 1702, loss 0.193911, acc 0.921875
2020-02-16T16:05:54.950910: step 1703, loss 0.118082, acc 0.96875
2020-02-16T16:05:55.135196: step 1704, loss 0.178298, acc 0.921875
2020-02-16T16:05:55.311586: step 1705, loss 0.0771843, acc 0.984375
2020-02-16T16:05:55.463183: step 1706, loss 0.0970416, acc 0.96875
2020-02-16T16:05:55.626238: step 1707, loss 0.0807586, acc 0.96875
2020-02-16T16:05:55.847046: step 1708, loss 0.14208, acc 0.921875
2020-02-16T16:05:55.997317: step 1709, loss 0.129287, acc 0.9375
2020-02-16T16:05:56.147170: step 1710, loss 0.111188, acc 0.96875
2020-02-16T16:05:56.320678: step 1711, loss 0.0618709, acc 1
2020-02-16T16:05:56.471092: step 1712, loss 0.198352, acc 0.90625
2020-02-16T16:05:56.630102: step 1713, loss 0.068523, acc 0.984375
2020-02-16T16:05:56.776965: step 1714, loss 0.191503, acc 0.9375
2020-02-16T16:05:56.922140: step 1715, loss 0.0711546, acc 1
2020-02-16T16:05:57.061803: step 1716, loss 0.16149, acc 0.921875
2020-02-16T16:05:57.200026: step 1717, loss 0.0512489, acc 1
2020-02-16T16:05:57.366385: step 1718, loss 0.108641, acc 0.984375
2020-02-16T16:05:57.501989: step 1719, loss 0.117851, acc 0.984375
2020-02-16T16:05:57.623376: step 1720, loss 0.0437264, acc 0.984375
2020-02-16T16:05:57.748468: step 1721, loss 0.0790562, acc 0.984375
2020-02-16T16:05:57.893033: step 1722, loss 0.100783, acc 0.96875
2020-02-16T16:05:58.069860: step 1723, loss 0.0669037, acc 0.984375
2020-02-16T16:05:58.212642: step 1724, loss 0.152949, acc 0.921875
2020-02-16T16:05:58.342828: step 1725, loss 0.1182, acc 0.953125
2020-02-16T16:05:58.508131: step 1726, loss 0.145423, acc 0.9375
2020-02-16T16:05:58.687572: step 1727, loss 0.0861649, acc 0.953125
2020-02-16T16:05:58.819015: step 1728, loss 0.159019, acc 0.953125
2020-02-16T16:05:58.950467: step 1729, loss 0.128033, acc 0.984375
2020-02-16T16:05:59.121907: step 1730, loss 0.184928, acc 0.9375
2020-02-16T16:05:59.246003: step 1731, loss 0.113861, acc 0.953125
2020-02-16T16:05:59.368620: step 1732, loss 0.0778774, acc 0.96875
2020-02-16T16:05:59.493446: step 1733, loss 0.113965, acc 0.96875
2020-02-16T16:05:59.614009: step 1734, loss 0.0911043, acc 0.96875
2020-02-16T16:05:59.758790: step 1735, loss 0.105545, acc 0.953125
2020-02-16T16:05:59.886992: step 1736, loss 0.159805, acc 0.90625
2020-02-16T16:06:00.008469: step 1737, loss 0.0779656, acc 0.96875
2020-02-16T16:06:00.130866: step 1738, loss 0.179151, acc 0.890625
2020-02-16T16:06:00.251121: step 1739, loss 0.094419, acc 0.953125
2020-02-16T16:06:00.378707: step 1740, loss 0.0584116, acc 0.984375
2020-02-16T16:06:00.531300: step 1741, loss 0.167583, acc 0.9375
2020-02-16T16:06:00.652527: step 1742, loss 0.0980002, acc 0.96875
2020-02-16T16:06:00.873109: step 1743, loss 0.0881989, acc 0.96875
2020-02-16T16:06:00.997398: step 1744, loss 0.104363, acc 0.9375
2020-02-16T16:06:01.116707: step 1745, loss 0.106273, acc 0.9375
2020-02-16T16:06:01.236225: step 1746, loss 0.1043, acc 0.96875
2020-02-16T16:06:01.356342: step 1747, loss 0.0529115, acc 1
2020-02-16T16:06:01.481965: step 1748, loss 0.0634941, acc 1
2020-02-16T16:06:01.645533: step 1749, loss 0.135137, acc 0.96875
2020-02-16T16:06:01.813197: step 1750, loss 0.143314, acc 0.9375
2020-02-16T16:06:01.935034: step 1751, loss 0.147464, acc 0.953125
2020-02-16T16:06:02.057895: step 1752, loss 0.231342, acc 0.890625
2020-02-16T16:06:02.217749: step 1753, loss 0.0921103, acc 0.984375
2020-02-16T16:06:02.381717: step 1754, loss 0.212878, acc 0.875
2020-02-16T16:06:02.513512: step 1755, loss 0.0916847, acc 0.9375
2020-02-16T16:06:02.632827: step 1756, loss 0.064204, acc 0.96875
2020-02-16T16:06:02.755187: step 1757, loss 0.0710414, acc 0.984375
2020-02-16T16:06:02.932994: step 1758, loss 0.10211, acc 0.96875
2020-02-16T16:06:03.089639: step 1759, loss 0.118873, acc 0.953125
2020-02-16T16:06:03.215498: step 1760, loss 0.157944, acc 0.921875
2020-02-16T16:06:03.336537: step 1761, loss 0.0491494, acc 1
2020-02-16T16:06:03.456500: step 1762, loss 0.157098, acc 0.9375
2020-02-16T16:06:03.594905: step 1763, loss 0.163823, acc 0.9375
2020-02-16T16:06:03.734723: step 1764, loss 0.108534, acc 0.984375
2020-02-16T16:06:03.866472: step 1765, loss 0.111308, acc 0.96875
2020-02-16T16:06:03.986430: step 1766, loss 0.124548, acc 0.953125
2020-02-16T16:06:04.104070: step 1767, loss 0.095536, acc 0.9375
2020-02-16T16:06:04.225728: step 1768, loss 0.164644, acc 0.90625
2020-02-16T16:06:04.355132: step 1769, loss 0.0522562, acc 0.984375
2020-02-16T16:06:04.472365: step 1770, loss 0.0709264, acc 0.96875
2020-02-16T16:06:04.587507: step 1771, loss 0.163262, acc 0.953125
2020-02-16T16:06:04.703662: step 1772, loss 0.144392, acc 0.9375
2020-02-16T16:06:04.827604: step 1773, loss 0.153133, acc 0.953125
2020-02-16T16:06:04.953242: step 1774, loss 0.111654, acc 0.953125
2020-02-16T16:06:05.076903: step 1775, loss 0.0972549, acc 0.953125
2020-02-16T16:06:05.199539: step 1776, loss 0.172479, acc 0.875
2020-02-16T16:06:05.317689: step 1777, loss 0.101267, acc 0.96875
2020-02-16T16:06:05.438315: step 1778, loss 0.077565, acc 0.984375
2020-02-16T16:06:05.560824: step 1779, loss 0.0926397, acc 0.953125
2020-02-16T16:06:05.676791: step 1780, loss 0.105475, acc 0.96875
2020-02-16T16:06:05.811349: step 1781, loss 0.0458494, acc 1
2020-02-16T16:06:05.930574: step 1782, loss 0.0746609, acc 0.984375
2020-02-16T16:06:06.051567: step 1783, loss 0.160996, acc 0.953125
2020-02-16T16:06:06.170928: step 1784, loss 0.114899, acc 0.953125
2020-02-16T16:06:06.290025: step 1785, loss 0.182608, acc 0.953125
2020-02-16T16:06:06.411825: step 1786, loss 0.0954005, acc 0.96875
2020-02-16T16:06:06.529300: step 1787, loss 0.283071, acc 0.90625
2020-02-16T16:06:06.648823: step 1788, loss 0.142104, acc 0.953125
2020-02-16T16:06:06.773550: step 1789, loss 0.19073, acc 0.90625
2020-02-16T16:06:06.898233: step 1790, loss 0.069089, acc 0.984375
2020-02-16T16:06:07.020346: step 1791, loss 0.101995, acc 0.984375
2020-02-16T16:06:07.139703: step 1792, loss 0.0890283, acc 0.953125
2020-02-16T16:06:07.258581: step 1793, loss 0.0934187, acc 0.96875
2020-02-16T16:06:07.378740: step 1794, loss 0.148163, acc 0.9375
2020-02-16T16:06:07.500161: step 1795, loss 0.167827, acc 0.90625
2020-02-16T16:06:07.620368: step 1796, loss 0.210003, acc 0.921875
2020-02-16T16:06:07.741703: step 1797, loss 0.174746, acc 0.90625
2020-02-16T16:06:07.863207: step 1798, loss 0.123785, acc 0.953125
2020-02-16T16:06:07.978942: step 1799, loss 0.13321, acc 0.9375
2020-02-16T16:06:08.094257: step 1800, loss 0.0913053, acc 0.95

Evaluation:
2020-02-16T16:06:08.290559: step 1800, loss 0.702641, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1800

2020-02-16T16:06:09.882801: step 1801, loss 0.0615249, acc 0.984375
2020-02-16T16:06:10.007783: step 1802, loss 0.0521204, acc 0.984375
2020-02-16T16:06:10.129906: step 1803, loss 0.0792543, acc 0.984375
2020-02-16T16:06:10.271320: step 1804, loss 0.10172, acc 0.953125
2020-02-16T16:06:10.413139: step 1805, loss 0.0622422, acc 0.96875
2020-02-16T16:06:10.578104: step 1806, loss 0.092819, acc 0.953125
2020-02-16T16:06:10.710441: step 1807, loss 0.143659, acc 0.9375
2020-02-16T16:06:10.868165: step 1808, loss 0.0643787, acc 1
2020-02-16T16:06:10.999696: step 1809, loss 0.100126, acc 0.9375
2020-02-16T16:06:11.125767: step 1810, loss 0.158321, acc 0.9375
2020-02-16T16:06:11.267785: step 1811, loss 0.0931369, acc 0.984375
2020-02-16T16:06:11.402294: step 1812, loss 0.114341, acc 0.953125
2020-02-16T16:06:11.543364: step 1813, loss 0.0795927, acc 0.96875
2020-02-16T16:06:11.986267: step 1814, loss 0.0865551, acc 0.96875
2020-02-16T16:06:12.122507: step 1815, loss 0.0431006, acc 1
2020-02-16T16:06:12.256934: step 1816, loss 0.0974658, acc 0.953125
2020-02-16T16:06:12.471679: step 1817, loss 0.169946, acc 0.921875
2020-02-16T16:06:12.650005: step 1818, loss 0.119178, acc 0.96875
2020-02-16T16:06:12.793070: step 1819, loss 0.149404, acc 0.953125
2020-02-16T16:06:12.959675: step 1820, loss 0.0767159, acc 0.96875
2020-02-16T16:06:13.106749: step 1821, loss 0.106098, acc 0.953125
2020-02-16T16:06:13.229540: step 1822, loss 0.0499299, acc 1
2020-02-16T16:06:13.361066: step 1823, loss 0.0838408, acc 0.96875
2020-02-16T16:06:13.515038: step 1824, loss 0.0611588, acc 0.96875
2020-02-16T16:06:13.654206: step 1825, loss 0.0907459, acc 0.96875
2020-02-16T16:06:13.797128: step 1826, loss 0.0441355, acc 1
2020-02-16T16:06:13.927101: step 1827, loss 0.0939978, acc 0.953125
2020-02-16T16:06:14.055117: step 1828, loss 0.046144, acc 0.984375
2020-02-16T16:06:14.174184: step 1829, loss 0.0709531, acc 0.96875
2020-02-16T16:06:14.319916: step 1830, loss 0.0687369, acc 0.984375
2020-02-16T16:06:14.462054: step 1831, loss 0.11425, acc 0.9375
2020-02-16T16:06:14.595847: step 1832, loss 0.0425466, acc 1
2020-02-16T16:06:14.715619: step 1833, loss 0.130829, acc 0.953125
2020-02-16T16:06:14.852393: step 1834, loss 0.0506118, acc 0.984375
2020-02-16T16:06:15.005046: step 1835, loss 0.0621742, acc 0.984375
2020-02-16T16:06:15.187641: step 1836, loss 0.0715946, acc 0.96875
2020-02-16T16:06:15.575171: step 1837, loss 0.103688, acc 0.953125
2020-02-16T16:06:15.694162: step 1838, loss 0.0883133, acc 0.953125
2020-02-16T16:06:15.897106: step 1839, loss 0.0793017, acc 0.953125
2020-02-16T16:06:16.037310: step 1840, loss 0.054109, acc 0.984375
2020-02-16T16:06:16.168121: step 1841, loss 0.0539012, acc 1
2020-02-16T16:06:16.326132: step 1842, loss 0.0908222, acc 0.953125
2020-02-16T16:06:16.465380: step 1843, loss 0.0806191, acc 0.96875
2020-02-16T16:06:16.613756: step 1844, loss 0.0964659, acc 0.96875
2020-02-16T16:06:16.766502: step 1845, loss 0.058565, acc 0.984375
2020-02-16T16:06:16.898569: step 1846, loss 0.0280957, acc 1
2020-02-16T16:06:17.025176: step 1847, loss 0.0492824, acc 1
2020-02-16T16:06:17.158850: step 1848, loss 0.0613517, acc 0.984375
2020-02-16T16:06:17.296184: step 1849, loss 0.228504, acc 0.9375
2020-02-16T16:06:17.430566: step 1850, loss 0.0969712, acc 0.9375
2020-02-16T16:06:17.563405: step 1851, loss 0.0600872, acc 0.984375
2020-02-16T16:06:17.690645: step 1852, loss 0.141353, acc 0.953125
2020-02-16T16:06:17.834176: step 1853, loss 0.14386, acc 0.953125
2020-02-16T16:06:17.969780: step 1854, loss 0.0658617, acc 1
2020-02-16T16:06:18.119781: step 1855, loss 0.116527, acc 0.953125
2020-02-16T16:06:18.255997: step 1856, loss 0.266556, acc 0.875
2020-02-16T16:06:18.392020: step 1857, loss 0.071, acc 1
2020-02-16T16:06:18.560146: step 1858, loss 0.0568447, acc 0.96875
2020-02-16T16:06:18.712514: step 1859, loss 0.175377, acc 0.953125
2020-02-16T16:06:18.890688: step 1860, loss 0.0688492, acc 0.984375
2020-02-16T16:06:19.039317: step 1861, loss 0.104791, acc 0.96875
2020-02-16T16:06:19.208788: step 1862, loss 0.0867036, acc 0.96875
2020-02-16T16:06:19.370808: step 1863, loss 0.106024, acc 0.953125
2020-02-16T16:06:19.794237: step 1864, loss 0.13218, acc 0.953125
2020-02-16T16:06:19.947083: step 1865, loss 0.0539146, acc 0.984375
2020-02-16T16:06:20.063633: step 1866, loss 0.0769456, acc 0.96875
2020-02-16T16:06:20.178487: step 1867, loss 0.0496913, acc 0.984375
2020-02-16T16:06:20.303828: step 1868, loss 0.0447262, acc 0.96875
2020-02-16T16:06:20.434262: step 1869, loss 0.111798, acc 0.984375
2020-02-16T16:06:20.562459: step 1870, loss 0.0489743, acc 0.984375
2020-02-16T16:06:20.679363: step 1871, loss 0.209641, acc 0.9375
2020-02-16T16:06:20.807671: step 1872, loss 0.121227, acc 0.953125
2020-02-16T16:06:20.928600: step 1873, loss 0.0753903, acc 1
2020-02-16T16:06:21.048237: step 1874, loss 0.105026, acc 0.953125
2020-02-16T16:06:21.174664: step 1875, loss 0.0842633, acc 0.96875
2020-02-16T16:06:21.319639: step 1876, loss 0.0547381, acc 1
2020-02-16T16:06:21.519699: step 1877, loss 0.0515922, acc 1
2020-02-16T16:06:21.660065: step 1878, loss 0.118843, acc 0.96875
2020-02-16T16:06:21.790797: step 1879, loss 0.1879, acc 0.9375
2020-02-16T16:06:21.915186: step 1880, loss 0.035467, acc 0.984375
2020-02-16T16:06:22.077214: step 1881, loss 0.115635, acc 0.984375
2020-02-16T16:06:22.215697: step 1882, loss 0.0890914, acc 0.96875
2020-02-16T16:06:22.335982: step 1883, loss 0.0352457, acc 1
2020-02-16T16:06:22.458208: step 1884, loss 0.147005, acc 0.9375
2020-02-16T16:06:22.574197: step 1885, loss 0.153774, acc 0.953125
2020-02-16T16:06:22.702923: step 1886, loss 0.119908, acc 0.9375
2020-02-16T16:06:22.849010: step 1887, loss 0.0273161, acc 1
2020-02-16T16:06:22.974060: step 1888, loss 0.150393, acc 0.9375
2020-02-16T16:06:23.092938: step 1889, loss 0.139283, acc 0.953125
2020-02-16T16:06:23.212875: step 1890, loss 0.0558142, acc 1
2020-02-16T16:06:23.334915: step 1891, loss 0.0585537, acc 0.984375
2020-02-16T16:06:23.455090: step 1892, loss 0.125611, acc 0.953125
2020-02-16T16:06:23.572921: step 1893, loss 0.110623, acc 0.953125
2020-02-16T16:06:23.692473: step 1894, loss 0.0983842, acc 0.953125
2020-02-16T16:06:23.821357: step 1895, loss 0.0741798, acc 0.96875
2020-02-16T16:06:23.944153: step 1896, loss 0.0359145, acc 1
2020-02-16T16:06:24.060410: step 1897, loss 0.0701793, acc 0.96875
2020-02-16T16:06:24.180069: step 1898, loss 0.0691685, acc 0.984375
2020-02-16T16:06:24.301189: step 1899, loss 0.174649, acc 0.9375
2020-02-16T16:06:24.422477: step 1900, loss 0.0820068, acc 0.96875

Evaluation:
2020-02-16T16:06:24.717118: step 1900, loss 0.726137, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-1900

2020-02-16T16:06:26.383645: step 1901, loss 0.0358925, acc 0.984375
2020-02-16T16:06:26.526885: step 1902, loss 0.0515396, acc 0.96875
2020-02-16T16:06:26.676341: step 1903, loss 0.130355, acc 0.96875
2020-02-16T16:06:26.807299: step 1904, loss 0.0951299, acc 0.984375
2020-02-16T16:06:26.925046: step 1905, loss 0.0687676, acc 0.984375
2020-02-16T16:06:27.040522: step 1906, loss 0.0468812, acc 0.984375
2020-02-16T16:06:27.169238: step 1907, loss 0.0964011, acc 0.96875
2020-02-16T16:06:27.299408: step 1908, loss 0.0584562, acc 0.984375
2020-02-16T16:06:27.421820: step 1909, loss 0.150604, acc 0.9375
2020-02-16T16:06:27.537473: step 1910, loss 0.0589963, acc 1
2020-02-16T16:06:27.661731: step 1911, loss 0.0666356, acc 0.984375
2020-02-16T16:06:27.792242: step 1912, loss 0.074042, acc 0.96875
2020-02-16T16:06:27.907482: step 1913, loss 0.0802789, acc 0.96875
2020-02-16T16:06:28.027597: step 1914, loss 0.0341405, acc 1
2020-02-16T16:06:28.148290: step 1915, loss 0.102776, acc 0.984375
2020-02-16T16:06:28.266920: step 1916, loss 0.112368, acc 0.953125
2020-02-16T16:06:28.383512: step 1917, loss 0.136587, acc 0.96875
2020-02-16T16:06:28.552585: step 1918, loss 0.0517886, acc 0.96875
2020-02-16T16:06:28.701274: step 1919, loss 0.175097, acc 0.953125
2020-02-16T16:06:28.830869: step 1920, loss 0.0727977, acc 0.96875
2020-02-16T16:06:28.950952: step 1921, loss 0.0785339, acc 0.984375
2020-02-16T16:06:29.073881: step 1922, loss 0.0312375, acc 1
2020-02-16T16:06:29.195679: step 1923, loss 0.0886675, acc 0.953125
2020-02-16T16:06:29.327167: step 1924, loss 0.123509, acc 0.90625
2020-02-16T16:06:29.449848: step 1925, loss 0.0270463, acc 1
2020-02-16T16:06:29.570924: step 1926, loss 0.0588688, acc 0.984375
2020-02-16T16:06:29.696549: step 1927, loss 0.0496078, acc 0.984375
2020-02-16T16:06:29.831676: step 1928, loss 0.0518848, acc 0.984375
2020-02-16T16:06:29.948819: step 1929, loss 0.0849802, acc 0.984375
2020-02-16T16:06:30.067071: step 1930, loss 0.106432, acc 0.953125
2020-02-16T16:06:30.188304: step 1931, loss 0.0857662, acc 0.96875
2020-02-16T16:06:30.318540: step 1932, loss 0.0772525, acc 0.96875
2020-02-16T16:06:30.449575: step 1933, loss 0.0721986, acc 0.984375
2020-02-16T16:06:30.571205: step 1934, loss 0.0637836, acc 0.984375
2020-02-16T16:06:30.957783: step 1935, loss 0.129437, acc 0.9375
2020-02-16T16:06:31.094537: step 1936, loss 0.0938797, acc 0.984375
2020-02-16T16:06:31.231167: step 1937, loss 0.0932592, acc 0.984375
2020-02-16T16:06:31.356375: step 1938, loss 0.0643242, acc 0.984375
2020-02-16T16:06:31.499337: step 1939, loss 0.0924249, acc 0.953125
2020-02-16T16:06:31.628135: step 1940, loss 0.21336, acc 0.890625
2020-02-16T16:06:31.771820: step 1941, loss 0.074933, acc 0.96875
2020-02-16T16:06:31.907822: step 1942, loss 0.0998014, acc 0.953125
2020-02-16T16:06:32.026031: step 1943, loss 0.105856, acc 0.953125
2020-02-16T16:06:32.145158: step 1944, loss 0.0837442, acc 0.96875
2020-02-16T16:06:32.263875: step 1945, loss 0.0922179, acc 0.96875
2020-02-16T16:06:32.379688: step 1946, loss 0.12425, acc 0.953125
2020-02-16T16:06:32.500846: step 1947, loss 0.115969, acc 0.9375
2020-02-16T16:06:32.633841: step 1948, loss 0.0896324, acc 0.953125
2020-02-16T16:06:32.821781: step 1949, loss 0.0912484, acc 0.953125
2020-02-16T16:06:32.950761: step 1950, loss 0.0612897, acc 0.983333
2020-02-16T16:06:33.118531: step 1951, loss 0.0555958, acc 1
2020-02-16T16:06:33.271749: step 1952, loss 0.0387515, acc 0.984375
2020-02-16T16:06:33.461384: step 1953, loss 0.108374, acc 0.96875
2020-02-16T16:06:33.605612: step 1954, loss 0.0521656, acc 0.984375
2020-02-16T16:06:33.798612: step 1955, loss 0.0392005, acc 1
2020-02-16T16:06:33.949702: step 1956, loss 0.115915, acc 0.9375
2020-02-16T16:06:34.092057: step 1957, loss 0.0252058, acc 1
2020-02-16T16:06:34.269132: step 1958, loss 0.0947967, acc 0.96875
2020-02-16T16:06:34.398508: step 1959, loss 0.0390587, acc 0.984375
2020-02-16T16:06:34.518888: step 1960, loss 0.0818176, acc 0.984375
2020-02-16T16:06:34.645879: step 1961, loss 0.0454842, acc 0.984375
2020-02-16T16:06:34.783706: step 1962, loss 0.044937, acc 1
2020-02-16T16:06:34.924024: step 1963, loss 0.0583751, acc 0.984375
2020-02-16T16:06:35.059788: step 1964, loss 0.0869865, acc 0.96875
2020-02-16T16:06:35.184105: step 1965, loss 0.0791061, acc 0.96875
2020-02-16T16:06:35.303808: step 1966, loss 0.144245, acc 0.953125
2020-02-16T16:06:35.423814: step 1967, loss 0.0853817, acc 0.96875
2020-02-16T16:06:35.542329: step 1968, loss 0.0345358, acc 0.984375
2020-02-16T16:06:35.682812: step 1969, loss 0.115116, acc 0.984375
2020-02-16T16:06:35.862872: step 1970, loss 0.0725114, acc 0.953125
2020-02-16T16:06:35.985347: step 1971, loss 0.0477676, acc 0.984375
2020-02-16T16:06:36.102077: step 1972, loss 0.0685509, acc 0.96875
2020-02-16T16:06:36.225408: step 1973, loss 0.0740385, acc 0.984375
2020-02-16T16:06:36.345738: step 1974, loss 0.0341148, acc 1
2020-02-16T16:06:36.475313: step 1975, loss 0.0197881, acc 1
2020-02-16T16:06:36.603708: step 1976, loss 0.0362388, acc 1
2020-02-16T16:06:36.724734: step 1977, loss 0.0553818, acc 0.984375
2020-02-16T16:06:36.859148: step 1978, loss 0.0449901, acc 0.984375
2020-02-16T16:06:36.986574: step 1979, loss 0.0972811, acc 0.953125
2020-02-16T16:06:37.106212: step 1980, loss 0.106418, acc 0.953125
2020-02-16T16:06:37.232096: step 1981, loss 0.0393273, acc 0.984375
2020-02-16T16:06:37.366032: step 1982, loss 0.110042, acc 0.953125
2020-02-16T16:06:37.517205: step 1983, loss 0.0923994, acc 0.984375
2020-02-16T16:06:37.641138: step 1984, loss 0.0539399, acc 0.96875
2020-02-16T16:06:37.766813: step 1985, loss 0.0835974, acc 0.96875
2020-02-16T16:06:37.884814: step 1986, loss 0.0623631, acc 0.984375
2020-02-16T16:06:38.003796: step 1987, loss 0.062755, acc 0.96875
2020-02-16T16:06:38.137474: step 1988, loss 0.0276691, acc 1
2020-02-16T16:06:38.270589: step 1989, loss 0.0837108, acc 0.984375
2020-02-16T16:06:38.392588: step 1990, loss 0.0635885, acc 0.953125
2020-02-16T16:06:38.512942: step 1991, loss 0.0468077, acc 0.984375
2020-02-16T16:06:38.634375: step 1992, loss 0.0597429, acc 0.984375
2020-02-16T16:06:38.757760: step 1993, loss 0.0860483, acc 0.96875
2020-02-16T16:06:38.877269: step 1994, loss 0.122874, acc 0.96875
2020-02-16T16:06:38.997443: step 1995, loss 0.140676, acc 0.953125
2020-02-16T16:06:39.116443: step 1996, loss 0.0507008, acc 0.984375
2020-02-16T16:06:39.236819: step 1997, loss 0.0259398, acc 1
2020-02-16T16:06:39.360010: step 1998, loss 0.0437732, acc 1
2020-02-16T16:06:39.518573: step 1999, loss 0.0232129, acc 1
2020-02-16T16:06:39.661119: step 2000, loss 0.0375651, acc 1

Evaluation:
2020-02-16T16:06:39.870644: step 2000, loss 0.770152, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2000

2020-02-16T16:06:41.446812: step 2001, loss 0.0970109, acc 0.96875
2020-02-16T16:06:41.565575: step 2002, loss 0.0680532, acc 0.96875
2020-02-16T16:06:41.682929: step 2003, loss 0.0555971, acc 0.96875
2020-02-16T16:06:41.815255: step 2004, loss 0.0586064, acc 0.984375
2020-02-16T16:06:41.933975: step 2005, loss 0.0604447, acc 0.96875
2020-02-16T16:06:42.050922: step 2006, loss 0.0549288, acc 0.984375
2020-02-16T16:06:42.170289: step 2007, loss 0.0284548, acc 1
2020-02-16T16:06:42.292802: step 2008, loss 0.0199441, acc 1
2020-02-16T16:06:42.411270: step 2009, loss 0.0608858, acc 0.96875
2020-02-16T16:06:42.526216: step 2010, loss 0.0616314, acc 0.984375
2020-02-16T16:06:42.647030: step 2011, loss 0.0541988, acc 0.96875
2020-02-16T16:06:42.804565: step 2012, loss 0.14904, acc 0.921875
2020-02-16T16:06:42.938938: step 2013, loss 0.146701, acc 0.953125
2020-02-16T16:06:43.072501: step 2014, loss 0.0442959, acc 0.96875
2020-02-16T16:06:43.198228: step 2015, loss 0.107692, acc 0.953125
2020-02-16T16:06:43.321840: step 2016, loss 0.0500865, acc 0.984375
2020-02-16T16:06:43.446696: step 2017, loss 0.10012, acc 0.96875
2020-02-16T16:06:43.565007: step 2018, loss 0.0942103, acc 0.96875
2020-02-16T16:06:43.705636: step 2019, loss 0.0826526, acc 0.96875
2020-02-16T16:06:43.841182: step 2020, loss 0.0375937, acc 1
2020-02-16T16:06:43.969537: step 2021, loss 0.107507, acc 0.984375
2020-02-16T16:06:44.103052: step 2022, loss 0.0505176, acc 0.984375
2020-02-16T16:06:44.222159: step 2023, loss 0.0890909, acc 0.96875
2020-02-16T16:06:44.345980: step 2024, loss 0.0378488, acc 1
2020-02-16T16:06:44.468437: step 2025, loss 0.03293, acc 1
2020-02-16T16:06:44.607827: step 2026, loss 0.0537578, acc 1
2020-02-16T16:06:44.732293: step 2027, loss 0.0690852, acc 0.953125
2020-02-16T16:06:44.915581: step 2028, loss 0.0478541, acc 0.96875
2020-02-16T16:06:45.358799: step 2029, loss 0.0539197, acc 0.984375
2020-02-16T16:06:45.482205: step 2030, loss 0.0300687, acc 1
2020-02-16T16:06:45.645319: step 2031, loss 0.035314, acc 0.984375
2020-02-16T16:06:45.821746: step 2032, loss 0.0777115, acc 0.96875
2020-02-16T16:06:45.942969: step 2033, loss 0.055728, acc 0.984375
2020-02-16T16:06:46.103165: step 2034, loss 0.08052, acc 0.96875
2020-02-16T16:06:46.226789: step 2035, loss 0.111691, acc 0.953125
2020-02-16T16:06:46.362994: step 2036, loss 0.149123, acc 0.953125
2020-02-16T16:06:46.497766: step 2037, loss 0.0716034, acc 0.96875
2020-02-16T16:06:46.627612: step 2038, loss 0.050713, acc 0.984375
2020-02-16T16:06:46.753306: step 2039, loss 0.0379842, acc 0.984375
2020-02-16T16:06:46.875737: step 2040, loss 0.070839, acc 0.96875
2020-02-16T16:06:47.008371: step 2041, loss 0.0454828, acc 0.96875
2020-02-16T16:06:47.131294: step 2042, loss 0.150402, acc 0.96875
2020-02-16T16:06:47.255484: step 2043, loss 0.134661, acc 0.96875
2020-02-16T16:06:47.380746: step 2044, loss 0.042453, acc 0.984375
2020-02-16T16:06:47.509049: step 2045, loss 0.0605923, acc 0.984375
2020-02-16T16:06:47.632759: step 2046, loss 0.103744, acc 0.9375
2020-02-16T16:06:47.764252: step 2047, loss 0.0516341, acc 0.984375
2020-02-16T16:06:47.889190: step 2048, loss 0.0482584, acc 1
2020-02-16T16:06:48.015890: step 2049, loss 0.0722028, acc 0.953125
2020-02-16T16:06:48.141457: step 2050, loss 0.108834, acc 0.9375
2020-02-16T16:06:48.266142: step 2051, loss 0.0519962, acc 0.96875
2020-02-16T16:06:48.396662: step 2052, loss 0.0598931, acc 0.96875
2020-02-16T16:06:48.521228: step 2053, loss 0.10936, acc 0.96875
2020-02-16T16:06:48.646012: step 2054, loss 0.087136, acc 0.953125
2020-02-16T16:06:48.771966: step 2055, loss 0.118639, acc 0.9375
2020-02-16T16:06:48.894248: step 2056, loss 0.176955, acc 0.921875
2020-02-16T16:06:49.019933: step 2057, loss 0.0707213, acc 0.96875
2020-02-16T16:06:49.145333: step 2058, loss 0.10581, acc 0.96875
2020-02-16T16:06:49.268639: step 2059, loss 0.0357489, acc 1
2020-02-16T16:06:49.396093: step 2060, loss 0.0783577, acc 0.96875
2020-02-16T16:06:49.519739: step 2061, loss 0.0789398, acc 0.96875
2020-02-16T16:06:49.647659: step 2062, loss 0.0557334, acc 0.984375
2020-02-16T16:06:49.779537: step 2063, loss 0.0287353, acc 1
2020-02-16T16:06:49.906811: step 2064, loss 0.0323486, acc 1
2020-02-16T16:06:50.034215: step 2065, loss 0.0291185, acc 1
2020-02-16T16:06:50.176114: step 2066, loss 0.106469, acc 0.9375
2020-02-16T16:06:50.320708: step 2067, loss 0.067612, acc 0.984375
2020-02-16T16:06:50.458148: step 2068, loss 0.060965, acc 0.984375
2020-02-16T16:06:50.608075: step 2069, loss 0.120893, acc 0.9375
2020-02-16T16:06:50.751517: step 2070, loss 0.0274031, acc 1
2020-02-16T16:06:50.904723: step 2071, loss 0.0538263, acc 0.984375
2020-02-16T16:06:51.066995: step 2072, loss 0.120909, acc 0.953125
2020-02-16T16:06:51.227883: step 2073, loss 0.204778, acc 0.9375
2020-02-16T16:06:51.379852: step 2074, loss 0.0557241, acc 0.96875
2020-02-16T16:06:51.596667: step 2075, loss 0.0375503, acc 0.984375
2020-02-16T16:06:51.743748: step 2076, loss 0.0432525, acc 0.984375
2020-02-16T16:06:51.888870: step 2077, loss 0.0519918, acc 0.96875
2020-02-16T16:06:52.021874: step 2078, loss 0.0761069, acc 0.953125
2020-02-16T16:06:52.157440: step 2079, loss 0.114366, acc 0.96875
2020-02-16T16:06:52.282214: step 2080, loss 0.0326536, acc 1
2020-02-16T16:06:52.428803: step 2081, loss 0.0448691, acc 0.984375
2020-02-16T16:06:52.590510: step 2082, loss 0.118542, acc 0.96875
2020-02-16T16:06:52.751358: step 2083, loss 0.210795, acc 0.921875
2020-02-16T16:06:52.913472: step 2084, loss 0.0794516, acc 0.96875
2020-02-16T16:06:53.037632: step 2085, loss 0.0918601, acc 0.96875
2020-02-16T16:06:53.165172: step 2086, loss 0.0396006, acc 1
2020-02-16T16:06:53.294117: step 2087, loss 0.0804559, acc 0.953125
2020-02-16T16:06:53.431879: step 2088, loss 0.0370421, acc 0.984375
2020-02-16T16:06:53.560799: step 2089, loss 0.0687456, acc 0.953125
2020-02-16T16:06:53.692907: step 2090, loss 0.0773811, acc 0.96875
2020-02-16T16:06:53.836082: step 2091, loss 0.0499508, acc 0.984375
2020-02-16T16:06:53.985817: step 2092, loss 0.0320479, acc 1
2020-02-16T16:06:54.123833: step 2093, loss 0.0320063, acc 1
2020-02-16T16:06:54.271458: step 2094, loss 0.144116, acc 0.96875
2020-02-16T16:06:54.497049: step 2095, loss 0.141007, acc 0.921875
2020-02-16T16:06:54.624279: step 2096, loss 0.0976357, acc 0.953125
2020-02-16T16:06:54.769223: step 2097, loss 0.0393971, acc 1
2020-02-16T16:06:54.907119: step 2098, loss 0.122608, acc 0.9375
2020-02-16T16:06:55.058035: step 2099, loss 0.032241, acc 1
2020-02-16T16:06:55.229064: step 2100, loss 0.0629813, acc 0.966667

Evaluation:
2020-02-16T16:06:55.447245: step 2100, loss 0.805535, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2100

2020-02-16T16:06:57.028325: step 2101, loss 0.0266357, acc 1
2020-02-16T16:06:57.154572: step 2102, loss 0.035638, acc 1
2020-02-16T16:06:57.277730: step 2103, loss 0.0236746, acc 1
2020-02-16T16:06:57.403951: step 2104, loss 0.0607367, acc 0.96875
2020-02-16T16:06:57.526905: step 2105, loss 0.0581287, acc 0.96875
2020-02-16T16:06:57.652253: step 2106, loss 0.0974998, acc 0.984375
2020-02-16T16:06:57.782024: step 2107, loss 0.0456962, acc 0.984375
2020-02-16T16:06:57.908816: step 2108, loss 0.117222, acc 0.96875
2020-02-16T16:06:58.032976: step 2109, loss 0.0259036, acc 1
2020-02-16T16:06:58.158116: step 2110, loss 0.0213281, acc 1
2020-02-16T16:06:58.278405: step 2111, loss 0.0799074, acc 0.96875
2020-02-16T16:06:58.409074: step 2112, loss 0.0189314, acc 1
2020-02-16T16:06:58.535809: step 2113, loss 0.0503341, acc 0.984375
2020-02-16T16:06:58.663894: step 2114, loss 0.024385, acc 1
2020-02-16T16:06:58.804908: step 2115, loss 0.0761899, acc 0.96875
2020-02-16T16:06:58.943217: step 2116, loss 0.0420011, acc 0.984375
2020-02-16T16:06:59.077612: step 2117, loss 0.0351108, acc 1
2020-02-16T16:06:59.250618: step 2118, loss 0.0485052, acc 0.984375
2020-02-16T16:06:59.385989: step 2119, loss 0.0241062, acc 1
2020-02-16T16:06:59.515964: step 2120, loss 0.0503075, acc 0.984375
2020-02-16T16:06:59.649580: step 2121, loss 0.038485, acc 1
2020-02-16T16:06:59.818638: step 2122, loss 0.0405818, acc 0.984375
2020-02-16T16:06:59.948621: step 2123, loss 0.0785146, acc 0.96875
2020-02-16T16:07:00.105360: step 2124, loss 0.039794, acc 1
2020-02-16T16:07:00.240562: step 2125, loss 0.0493325, acc 0.984375
2020-02-16T16:07:00.365808: step 2126, loss 0.0627936, acc 0.984375
2020-02-16T16:07:00.532997: step 2127, loss 0.0356612, acc 1
2020-02-16T16:07:00.954377: step 2128, loss 0.0340575, acc 0.984375
2020-02-16T16:07:01.081921: step 2129, loss 0.0366209, acc 1
2020-02-16T16:07:01.217015: step 2130, loss 0.0433034, acc 0.984375
2020-02-16T16:07:01.350169: step 2131, loss 0.0377165, acc 0.984375
2020-02-16T16:07:01.472414: step 2132, loss 0.0434602, acc 1
2020-02-16T16:07:01.590564: step 2133, loss 0.0984752, acc 0.96875
2020-02-16T16:07:01.712000: step 2134, loss 0.014284, acc 1
2020-02-16T16:07:01.844086: step 2135, loss 0.0223428, acc 1
2020-02-16T16:07:01.971440: step 2136, loss 0.0626682, acc 0.984375
2020-02-16T16:07:02.093507: step 2137, loss 0.0412596, acc 0.984375
2020-02-16T16:07:02.219672: step 2138, loss 0.0778611, acc 0.984375
2020-02-16T16:07:02.347214: step 2139, loss 0.0494205, acc 0.96875
2020-02-16T16:07:02.471522: step 2140, loss 0.0529049, acc 0.984375
2020-02-16T16:07:02.593198: step 2141, loss 0.0262176, acc 1
2020-02-16T16:07:02.715330: step 2142, loss 0.114062, acc 0.96875
2020-02-16T16:07:02.875027: step 2143, loss 0.0254809, acc 1
2020-02-16T16:07:03.014079: step 2144, loss 0.0467839, acc 0.984375
2020-02-16T16:07:03.132176: step 2145, loss 0.0248463, acc 1
2020-02-16T16:07:03.305908: step 2146, loss 0.0133049, acc 1
2020-02-16T16:07:03.430711: step 2147, loss 0.142299, acc 0.953125
2020-02-16T16:07:03.552581: step 2148, loss 0.0535924, acc 0.984375
2020-02-16T16:07:03.670991: step 2149, loss 0.0523352, acc 1
2020-02-16T16:07:03.799586: step 2150, loss 0.0396399, acc 0.984375
2020-02-16T16:07:03.932254: step 2151, loss 0.0576541, acc 0.984375
2020-02-16T16:07:04.065126: step 2152, loss 0.0584441, acc 0.96875
2020-02-16T16:07:04.183610: step 2153, loss 0.0533692, acc 0.984375
2020-02-16T16:07:04.304827: step 2154, loss 0.0312385, acc 0.984375
2020-02-16T16:07:04.431386: step 2155, loss 0.0426906, acc 1
2020-02-16T16:07:04.550964: step 2156, loss 0.0292298, acc 1
2020-02-16T16:07:04.666144: step 2157, loss 0.0769437, acc 0.96875
2020-02-16T16:07:04.794111: step 2158, loss 0.0274125, acc 1
2020-02-16T16:07:04.920971: step 2159, loss 0.0906485, acc 0.953125
2020-02-16T16:07:05.045435: step 2160, loss 0.013243, acc 1
2020-02-16T16:07:05.163226: step 2161, loss 0.0424425, acc 0.984375
2020-02-16T16:07:05.278913: step 2162, loss 0.0181475, acc 1
2020-02-16T16:07:05.397833: step 2163, loss 0.146501, acc 0.9375
2020-02-16T16:07:05.522005: step 2164, loss 0.0315613, acc 1
2020-02-16T16:07:05.639349: step 2165, loss 0.0693804, acc 0.96875
2020-02-16T16:07:05.762038: step 2166, loss 0.0787715, acc 0.953125
2020-02-16T16:07:05.880031: step 2167, loss 0.0665325, acc 0.984375
2020-02-16T16:07:06.003331: step 2168, loss 0.0706532, acc 0.96875
2020-02-16T16:07:06.122407: step 2169, loss 0.049156, acc 0.984375
2020-02-16T16:07:06.241263: step 2170, loss 0.0571126, acc 0.96875
2020-02-16T16:07:06.360534: step 2171, loss 0.0480173, acc 0.984375
2020-02-16T16:07:06.478822: step 2172, loss 0.0232938, acc 1
2020-02-16T16:07:06.596123: step 2173, loss 0.0656938, acc 0.984375
2020-02-16T16:07:06.723403: step 2174, loss 0.0157652, acc 1
2020-02-16T16:07:06.884857: step 2175, loss 0.0405862, acc 0.984375
2020-02-16T16:07:07.021553: step 2176, loss 0.0533605, acc 0.984375
2020-02-16T16:07:07.139323: step 2177, loss 0.0930327, acc 0.96875
2020-02-16T16:07:07.259553: step 2178, loss 0.0437284, acc 1
2020-02-16T16:07:07.375895: step 2179, loss 0.0288358, acc 1
2020-02-16T16:07:07.504578: step 2180, loss 0.0371521, acc 1
2020-02-16T16:07:07.630179: step 2181, loss 0.090975, acc 0.953125
2020-02-16T16:07:07.758364: step 2182, loss 0.11327, acc 0.96875
2020-02-16T16:07:07.879141: step 2183, loss 0.0722765, acc 0.984375
2020-02-16T16:07:07.999551: step 2184, loss 0.0225843, acc 1
2020-02-16T16:07:08.117644: step 2185, loss 0.0467048, acc 0.984375
2020-02-16T16:07:08.232859: step 2186, loss 0.0419836, acc 0.984375
2020-02-16T16:07:08.351260: step 2187, loss 0.0136449, acc 1
2020-02-16T16:07:08.469944: step 2188, loss 0.0770401, acc 0.984375
2020-02-16T16:07:08.586137: step 2189, loss 0.123599, acc 0.96875
2020-02-16T16:07:08.703261: step 2190, loss 0.0289715, acc 1
2020-02-16T16:07:08.830025: step 2191, loss 0.0569058, acc 0.984375
2020-02-16T16:07:08.950578: step 2192, loss 0.0457885, acc 0.984375
2020-02-16T16:07:09.068904: step 2193, loss 0.035494, acc 0.984375
2020-02-16T16:07:09.188292: step 2194, loss 0.0335995, acc 1
2020-02-16T16:07:09.304971: step 2195, loss 0.0914459, acc 0.96875
2020-02-16T16:07:09.423602: step 2196, loss 0.123103, acc 0.9375
2020-02-16T16:07:09.542248: step 2197, loss 0.0126483, acc 1
2020-02-16T16:07:09.661724: step 2198, loss 0.0198557, acc 1
2020-02-16T16:07:09.790737: step 2199, loss 0.0207453, acc 0.984375
2020-02-16T16:07:09.966249: step 2200, loss 0.0326099, acc 1

Evaluation:
2020-02-16T16:07:10.173736: step 2200, loss 0.807553, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2200

2020-02-16T16:07:12.491767: step 2201, loss 0.0190432, acc 1
2020-02-16T16:07:12.610328: step 2202, loss 0.0491535, acc 0.984375
2020-02-16T16:07:12.728748: step 2203, loss 0.0969681, acc 0.984375
2020-02-16T16:07:12.855027: step 2204, loss 0.131504, acc 0.96875
2020-02-16T16:07:12.974853: step 2205, loss 0.0172459, acc 1
2020-02-16T16:07:13.091625: step 2206, loss 0.0768831, acc 0.96875
2020-02-16T16:07:13.210272: step 2207, loss 0.0667623, acc 0.96875
2020-02-16T16:07:13.329608: step 2208, loss 0.0670726, acc 0.984375
2020-02-16T16:07:13.451352: step 2209, loss 0.0883145, acc 0.96875
2020-02-16T16:07:13.571212: step 2210, loss 0.0554012, acc 0.984375
2020-02-16T16:07:13.687402: step 2211, loss 0.0288104, acc 1
2020-02-16T16:07:13.812012: step 2212, loss 0.0502864, acc 0.96875
2020-02-16T16:07:13.935601: step 2213, loss 0.071654, acc 0.96875
2020-02-16T16:07:14.057693: step 2214, loss 0.123463, acc 0.9375
2020-02-16T16:07:14.175034: step 2215, loss 0.1438, acc 0.953125
2020-02-16T16:07:14.292979: step 2216, loss 0.021502, acc 1
2020-02-16T16:07:14.413822: step 2217, loss 0.145594, acc 0.921875
2020-02-16T16:07:14.531913: step 2218, loss 0.0307903, acc 0.984375
2020-02-16T16:07:14.649824: step 2219, loss 0.0253138, acc 1
2020-02-16T16:07:14.772357: step 2220, loss 0.0467107, acc 0.984375
2020-02-16T16:07:14.897746: step 2221, loss 0.0689004, acc 0.984375
2020-02-16T16:07:15.026722: step 2222, loss 0.0825164, acc 0.953125
2020-02-16T16:07:15.163503: step 2223, loss 0.0257272, acc 1
2020-02-16T16:07:15.284199: step 2224, loss 0.0275246, acc 1
2020-02-16T16:07:15.411419: step 2225, loss 0.0548127, acc 0.984375
2020-02-16T16:07:15.550091: step 2226, loss 0.030954, acc 0.984375
2020-02-16T16:07:15.670609: step 2227, loss 0.027075, acc 1
2020-02-16T16:07:15.795151: step 2228, loss 0.0573556, acc 0.984375
2020-02-16T16:07:15.917393: step 2229, loss 0.091061, acc 0.9375
2020-02-16T16:07:16.034707: step 2230, loss 0.0332511, acc 1
2020-02-16T16:07:16.152492: step 2231, loss 0.0753795, acc 0.96875
2020-02-16T16:07:16.272092: step 2232, loss 0.0379798, acc 0.984375
2020-02-16T16:07:16.397913: step 2233, loss 0.124288, acc 0.96875
2020-02-16T16:07:16.516092: step 2234, loss 0.0911636, acc 0.953125
2020-02-16T16:07:16.632198: step 2235, loss 0.0636355, acc 0.96875
2020-02-16T16:07:16.752981: step 2236, loss 0.120086, acc 0.96875
2020-02-16T16:07:16.872634: step 2237, loss 0.0457446, acc 0.984375
2020-02-16T16:07:16.996552: step 2238, loss 0.130623, acc 0.9375
2020-02-16T16:07:17.124732: step 2239, loss 0.218001, acc 0.9375
2020-02-16T16:07:17.246223: step 2240, loss 0.110888, acc 0.9375
2020-02-16T16:07:17.365492: step 2241, loss 0.0343834, acc 1
2020-02-16T16:07:17.528111: step 2242, loss 0.0397513, acc 0.984375
2020-02-16T16:07:17.722089: step 2243, loss 0.0309798, acc 0.984375
2020-02-16T16:07:17.880403: step 2244, loss 0.0195613, acc 1
2020-02-16T16:07:18.022275: step 2245, loss 0.103041, acc 0.96875
2020-02-16T16:07:18.167076: step 2246, loss 0.0600676, acc 0.984375
2020-02-16T16:07:18.330245: step 2247, loss 0.0172786, acc 1
2020-02-16T16:07:18.493271: step 2248, loss 0.0284634, acc 1
2020-02-16T16:07:18.641927: step 2249, loss 0.042529, acc 1
2020-02-16T16:07:18.798666: step 2250, loss 0.0871357, acc 0.983333
2020-02-16T16:07:18.983067: step 2251, loss 0.0172459, acc 1
2020-02-16T16:07:19.144041: step 2252, loss 0.0179966, acc 1
2020-02-16T16:07:19.362254: step 2253, loss 0.0191749, acc 1
2020-02-16T16:07:19.525836: step 2254, loss 0.0334868, acc 0.984375
2020-02-16T16:07:19.694955: step 2255, loss 0.0333359, acc 0.984375
2020-02-16T16:07:19.868672: step 2256, loss 0.0382401, acc 0.984375
2020-02-16T16:07:20.017125: step 2257, loss 0.0106264, acc 1
2020-02-16T16:07:20.154891: step 2258, loss 0.0416246, acc 1
2020-02-16T16:07:20.296315: step 2259, loss 0.0325726, acc 1
2020-02-16T16:07:20.455357: step 2260, loss 0.0340958, acc 1
2020-02-16T16:07:20.644466: step 2261, loss 0.0675448, acc 0.96875
2020-02-16T16:07:20.992047: step 2262, loss 0.0553582, acc 0.984375
2020-02-16T16:07:21.171841: step 2263, loss 0.0226749, acc 1
2020-02-16T16:07:21.354471: step 2264, loss 0.0285108, acc 0.984375
2020-02-16T16:07:21.519158: step 2265, loss 0.0196826, acc 1
2020-02-16T16:07:21.647972: step 2266, loss 0.0387554, acc 0.984375
2020-02-16T16:07:21.773665: step 2267, loss 0.0352414, acc 1
2020-02-16T16:07:21.899582: step 2268, loss 0.0543474, acc 0.96875
2020-02-16T16:07:22.026482: step 2269, loss 0.0453564, acc 1
2020-02-16T16:07:22.160556: step 2270, loss 0.0683615, acc 0.96875
2020-02-16T16:07:22.286584: step 2271, loss 0.0172255, acc 1
2020-02-16T16:07:22.419396: step 2272, loss 0.00790338, acc 1
2020-02-16T16:07:22.537763: step 2273, loss 0.0752414, acc 0.96875
2020-02-16T16:07:22.657965: step 2274, loss 0.139202, acc 0.96875
2020-02-16T16:07:22.790159: step 2275, loss 0.0529401, acc 0.984375
2020-02-16T16:07:22.927592: step 2276, loss 0.011351, acc 1
2020-02-16T16:07:23.051873: step 2277, loss 0.0137884, acc 1
2020-02-16T16:07:23.171012: step 2278, loss 0.0370162, acc 0.984375
2020-02-16T16:07:23.302525: step 2279, loss 0.0187418, acc 1
2020-02-16T16:07:23.438585: step 2280, loss 0.0184416, acc 1
2020-02-16T16:07:23.573125: step 2281, loss 0.0395026, acc 0.984375
2020-02-16T16:07:23.716729: step 2282, loss 0.025633, acc 1
2020-02-16T16:07:23.914608: step 2283, loss 0.0505348, acc 0.984375
2020-02-16T16:07:24.293240: step 2284, loss 0.0135768, acc 1
2020-02-16T16:07:24.528869: step 2285, loss 0.0284782, acc 1
2020-02-16T16:07:24.665603: step 2286, loss 0.0178886, acc 1
2020-02-16T16:07:24.821638: step 2287, loss 0.0142075, acc 1
2020-02-16T16:07:24.956764: step 2288, loss 0.0475913, acc 0.96875
2020-02-16T16:07:25.101971: step 2289, loss 0.0469368, acc 0.984375
2020-02-16T16:07:25.229763: step 2290, loss 0.0238, acc 0.984375
2020-02-16T16:07:25.372884: step 2291, loss 0.0123016, acc 1
2020-02-16T16:07:25.512019: step 2292, loss 0.0326376, acc 0.984375
2020-02-16T16:07:25.636512: step 2293, loss 0.0267318, acc 1
2020-02-16T16:07:25.801765: step 2294, loss 0.0214706, acc 1
2020-02-16T16:07:25.942794: step 2295, loss 0.0313509, acc 0.984375
2020-02-16T16:07:26.068563: step 2296, loss 0.0255257, acc 1
2020-02-16T16:07:26.196501: step 2297, loss 0.025255, acc 1
2020-02-16T16:07:26.321826: step 2298, loss 0.0290296, acc 1
2020-02-16T16:07:26.447392: step 2299, loss 0.0634493, acc 0.984375
2020-02-16T16:07:26.574273: step 2300, loss 0.0680777, acc 0.96875

Evaluation:
2020-02-16T16:07:26.789773: step 2300, loss 0.84245, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2300

2020-02-16T16:07:29.276716: step 2301, loss 0.0205039, acc 0.984375
2020-02-16T16:07:29.404322: step 2302, loss 0.0289064, acc 0.984375
2020-02-16T16:07:29.538863: step 2303, loss 0.057503, acc 0.96875
2020-02-16T16:07:29.667779: step 2304, loss 0.0385961, acc 0.984375
2020-02-16T16:07:29.807963: step 2305, loss 0.0322466, acc 0.984375
2020-02-16T16:07:29.931729: step 2306, loss 0.0511715, acc 0.96875
2020-02-16T16:07:30.058946: step 2307, loss 0.130947, acc 0.96875
2020-02-16T16:07:30.180260: step 2308, loss 0.0215564, acc 1
2020-02-16T16:07:30.303464: step 2309, loss 0.0507623, acc 0.96875
2020-02-16T16:07:30.428689: step 2310, loss 0.0355644, acc 1
2020-02-16T16:07:30.558693: step 2311, loss 0.0127162, acc 1
2020-02-16T16:07:31.079803: step 2312, loss 0.0312123, acc 0.984375
2020-02-16T16:07:31.210528: step 2313, loss 0.0291286, acc 1
2020-02-16T16:07:31.334600: step 2314, loss 0.0748611, acc 0.953125
2020-02-16T16:07:31.461441: step 2315, loss 0.0537179, acc 0.96875
2020-02-16T16:07:31.582266: step 2316, loss 0.161057, acc 0.953125
2020-02-16T16:07:31.711394: step 2317, loss 0.0669903, acc 0.96875
2020-02-16T16:07:31.857180: step 2318, loss 0.1298, acc 0.96875
2020-02-16T16:07:31.981373: step 2319, loss 0.091762, acc 0.96875
2020-02-16T16:07:32.107610: step 2320, loss 0.0146988, acc 1
2020-02-16T16:07:32.230899: step 2321, loss 0.0234431, acc 1
2020-02-16T16:07:32.356422: step 2322, loss 0.0183105, acc 1
2020-02-16T16:07:32.480677: step 2323, loss 0.0940432, acc 0.96875
2020-02-16T16:07:32.602112: step 2324, loss 0.0341853, acc 0.984375
2020-02-16T16:07:32.787422: step 2325, loss 0.0534625, acc 0.984375
2020-02-16T16:07:32.912123: step 2326, loss 0.0311984, acc 1
2020-02-16T16:07:33.035247: step 2327, loss 0.0463864, acc 0.96875
2020-02-16T16:07:33.163187: step 2328, loss 0.0328306, acc 1
2020-02-16T16:07:33.283161: step 2329, loss 0.0120753, acc 1
2020-02-16T16:07:33.407212: step 2330, loss 0.0765281, acc 0.984375
2020-02-16T16:07:33.530594: step 2331, loss 0.0384116, acc 0.984375
2020-02-16T16:07:33.663102: step 2332, loss 0.0896104, acc 0.9375
2020-02-16T16:07:33.792261: step 2333, loss 0.0654617, acc 0.984375
2020-02-16T16:07:33.924767: step 2334, loss 0.0111191, acc 1
2020-02-16T16:07:34.050177: step 2335, loss 0.0371714, acc 0.984375
2020-02-16T16:07:34.175825: step 2336, loss 0.0395339, acc 0.984375
2020-02-16T16:07:34.299323: step 2337, loss 0.0283246, acc 0.984375
2020-02-16T16:07:34.425248: step 2338, loss 0.0259467, acc 1
2020-02-16T16:07:34.549346: step 2339, loss 0.0442153, acc 0.984375
2020-02-16T16:07:34.675732: step 2340, loss 0.0345109, acc 0.984375
2020-02-16T16:07:34.811364: step 2341, loss 0.0772662, acc 0.96875
2020-02-16T16:07:34.946125: step 2342, loss 0.0290604, acc 1
2020-02-16T16:07:35.073547: step 2343, loss 0.0444439, acc 1
2020-02-16T16:07:35.201469: step 2344, loss 0.00738107, acc 1
2020-02-16T16:07:35.326482: step 2345, loss 0.0406423, acc 0.984375
2020-02-16T16:07:35.452097: step 2346, loss 0.0190986, acc 1
2020-02-16T16:07:35.575626: step 2347, loss 0.0541597, acc 0.984375
2020-02-16T16:07:35.704901: step 2348, loss 0.019475, acc 0.984375
2020-02-16T16:07:35.835048: step 2349, loss 0.0152232, acc 1
2020-02-16T16:07:35.968898: step 2350, loss 0.0457458, acc 1
2020-02-16T16:07:36.089221: step 2351, loss 0.0368931, acc 0.984375
2020-02-16T16:07:36.221313: step 2352, loss 0.0237318, acc 1
2020-02-16T16:07:36.346111: step 2353, loss 0.0925204, acc 0.953125
2020-02-16T16:07:36.470861: step 2354, loss 0.0695887, acc 0.96875
2020-02-16T16:07:36.596254: step 2355, loss 0.112526, acc 0.984375
2020-02-16T16:07:36.724283: step 2356, loss 0.0134481, acc 1
2020-02-16T16:07:36.860202: step 2357, loss 0.0793848, acc 0.984375
2020-02-16T16:07:36.979447: step 2358, loss 0.0429401, acc 0.984375
2020-02-16T16:07:37.106035: step 2359, loss 0.019847, acc 1
2020-02-16T16:07:37.232682: step 2360, loss 0.0130425, acc 1
2020-02-16T16:07:37.365145: step 2361, loss 0.0557742, acc 0.984375
2020-02-16T16:07:37.486960: step 2362, loss 0.0562397, acc 0.953125
2020-02-16T16:07:37.614450: step 2363, loss 0.0434757, acc 0.984375
2020-02-16T16:07:37.746598: step 2364, loss 0.0251896, acc 1
2020-02-16T16:07:37.873967: step 2365, loss 0.164751, acc 0.9375
2020-02-16T16:07:38.000802: step 2366, loss 0.036895, acc 0.984375
2020-02-16T16:07:38.125735: step 2367, loss 0.0492938, acc 0.984375
2020-02-16T16:07:38.256867: step 2368, loss 0.00763347, acc 1
2020-02-16T16:07:38.382253: step 2369, loss 0.0341822, acc 1
2020-02-16T16:07:38.507675: step 2370, loss 0.0315221, acc 1
2020-02-16T16:07:38.633430: step 2371, loss 0.0555242, acc 0.984375
2020-02-16T16:07:38.767212: step 2372, loss 0.0217851, acc 1
2020-02-16T16:07:38.889936: step 2373, loss 0.0408551, acc 0.984375
2020-02-16T16:07:39.017202: step 2374, loss 0.0274543, acc 1
2020-02-16T16:07:39.143503: step 2375, loss 0.0915843, acc 0.953125
2020-02-16T16:07:39.269657: step 2376, loss 0.0441154, acc 0.984375
2020-02-16T16:07:39.398397: step 2377, loss 0.0781983, acc 0.953125
2020-02-16T16:07:39.524414: step 2378, loss 0.0170809, acc 1
2020-02-16T16:07:39.654126: step 2379, loss 0.0262728, acc 0.984375
2020-02-16T16:07:39.782897: step 2380, loss 0.0262389, acc 1
2020-02-16T16:07:39.909340: step 2381, loss 0.0385398, acc 0.984375
2020-02-16T16:07:40.032673: step 2382, loss 0.0243476, acc 1
2020-02-16T16:07:40.158435: step 2383, loss 0.068258, acc 0.984375
2020-02-16T16:07:40.281807: step 2384, loss 0.0481704, acc 0.984375
2020-02-16T16:07:40.407029: step 2385, loss 0.0601941, acc 0.96875
2020-02-16T16:07:40.530249: step 2386, loss 0.0149469, acc 1
2020-02-16T16:07:40.658496: step 2387, loss 0.10859, acc 0.984375
2020-02-16T16:07:40.789766: step 2388, loss 0.0618652, acc 0.984375
2020-02-16T16:07:40.914815: step 2389, loss 0.0873127, acc 0.96875
2020-02-16T16:07:41.040293: step 2390, loss 0.0688167, acc 0.984375
2020-02-16T16:07:41.169440: step 2391, loss 0.057399, acc 0.984375
2020-02-16T16:07:41.295458: step 2392, loss 0.0798676, acc 0.96875
2020-02-16T16:07:41.422009: step 2393, loss 0.0617925, acc 0.984375
2020-02-16T16:07:41.546836: step 2394, loss 0.0695834, acc 0.96875
2020-02-16T16:07:41.673227: step 2395, loss 0.0234594, acc 1
2020-02-16T16:07:41.811090: step 2396, loss 0.0128717, acc 1
2020-02-16T16:07:41.936142: step 2397, loss 0.0530375, acc 1
2020-02-16T16:07:42.062301: step 2398, loss 0.02562, acc 1
2020-02-16T16:07:42.185229: step 2399, loss 0.012383, acc 1
2020-02-16T16:07:42.310587: step 2400, loss 0.0831172, acc 0.966667

Evaluation:
2020-02-16T16:07:42.512793: step 2400, loss 0.875842, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2400

2020-02-16T16:07:44.370027: step 2401, loss 0.0805615, acc 0.984375
2020-02-16T16:07:44.495705: step 2402, loss 0.0422292, acc 0.984375
2020-02-16T16:07:44.616448: step 2403, loss 0.0787222, acc 0.984375
2020-02-16T16:07:44.740489: step 2404, loss 0.0455297, acc 0.984375
2020-02-16T16:07:44.868290: step 2405, loss 0.0221238, acc 1
2020-02-16T16:07:44.995801: step 2406, loss 0.0463656, acc 0.96875
2020-02-16T16:07:45.123560: step 2407, loss 0.0647745, acc 0.96875
2020-02-16T16:07:45.249886: step 2408, loss 0.0181273, acc 1
2020-02-16T16:07:45.371360: step 2409, loss 0.0132805, acc 1
2020-02-16T16:07:45.499453: step 2410, loss 0.0890583, acc 0.9375
2020-02-16T16:07:45.629884: step 2411, loss 0.0823413, acc 0.984375
2020-02-16T16:07:45.755325: step 2412, loss 0.0726553, acc 0.96875
2020-02-16T16:07:45.877657: step 2413, loss 0.0355558, acc 1
2020-02-16T16:07:45.997996: step 2414, loss 0.0155661, acc 1
2020-02-16T16:07:46.115296: step 2415, loss 0.0174072, acc 1
2020-02-16T16:07:46.231524: step 2416, loss 0.0165321, acc 1
2020-02-16T16:07:46.348474: step 2417, loss 0.045358, acc 0.984375
2020-02-16T16:07:46.466052: step 2418, loss 0.0937287, acc 0.96875
2020-02-16T16:07:46.583958: step 2419, loss 0.0309066, acc 0.984375
2020-02-16T16:07:46.705839: step 2420, loss 0.0681947, acc 0.984375
2020-02-16T16:07:46.835156: step 2421, loss 0.064158, acc 0.96875
2020-02-16T16:07:46.951989: step 2422, loss 0.0511215, acc 0.984375
2020-02-16T16:07:47.070108: step 2423, loss 0.0157048, acc 1
2020-02-16T16:07:47.189691: step 2424, loss 0.0259961, acc 1
2020-02-16T16:07:47.308959: step 2425, loss 0.0661702, acc 0.984375
2020-02-16T16:07:47.426305: step 2426, loss 0.0192005, acc 1
2020-02-16T16:07:47.544289: step 2427, loss 0.027355, acc 1
2020-02-16T16:07:47.663525: step 2428, loss 0.0111551, acc 1
2020-02-16T16:07:47.787596: step 2429, loss 0.0242756, acc 1
2020-02-16T16:07:47.910787: step 2430, loss 0.0397583, acc 0.984375
2020-02-16T16:07:48.026884: step 2431, loss 0.0287735, acc 0.984375
2020-02-16T16:07:48.144101: step 2432, loss 0.0424814, acc 0.984375
2020-02-16T16:07:48.264862: step 2433, loss 0.0430502, acc 0.984375
2020-02-16T16:07:48.381810: step 2434, loss 0.107808, acc 0.96875
2020-02-16T16:07:48.500534: step 2435, loss 0.104123, acc 0.953125
2020-02-16T16:07:48.620632: step 2436, loss 0.0227052, acc 1
2020-02-16T16:07:48.741281: step 2437, loss 0.0184688, acc 1
2020-02-16T16:07:48.863898: step 2438, loss 0.0910674, acc 0.953125
2020-02-16T16:07:48.983351: step 2439, loss 0.0187813, acc 1
2020-02-16T16:07:49.103020: step 2440, loss 0.031384, acc 1
2020-02-16T16:07:49.223210: step 2441, loss 0.026321, acc 1
2020-02-16T16:07:49.343587: step 2442, loss 0.0800389, acc 0.96875
2020-02-16T16:07:49.463187: step 2443, loss 0.0140726, acc 1
2020-02-16T16:07:49.580249: step 2444, loss 0.0110205, acc 1
2020-02-16T16:07:49.702569: step 2445, loss 0.090471, acc 0.984375
2020-02-16T16:07:49.848066: step 2446, loss 0.020012, acc 0.984375
2020-02-16T16:07:50.015502: step 2447, loss 0.0156099, acc 1
2020-02-16T16:07:50.134234: step 2448, loss 0.0142675, acc 1
2020-02-16T16:07:50.255008: step 2449, loss 0.0474959, acc 0.984375
2020-02-16T16:07:50.421760: step 2450, loss 0.0338223, acc 1
2020-02-16T16:07:50.607839: step 2451, loss 0.0126425, acc 1
2020-02-16T16:07:50.803601: step 2452, loss 0.0110371, acc 1
2020-02-16T16:07:50.937406: step 2453, loss 0.0293146, acc 0.984375
2020-02-16T16:07:51.083165: step 2454, loss 0.0181641, acc 1
2020-02-16T16:07:51.267535: step 2455, loss 0.00991354, acc 1
2020-02-16T16:07:51.452842: step 2456, loss 0.0185659, acc 1
2020-02-16T16:07:51.600653: step 2457, loss 0.0412316, acc 0.984375
2020-02-16T16:07:51.723629: step 2458, loss 0.0320582, acc 0.984375
2020-02-16T16:07:51.853869: step 2459, loss 0.0123369, acc 1
2020-02-16T16:07:51.973837: step 2460, loss 0.0313566, acc 1
2020-02-16T16:07:52.097956: step 2461, loss 0.0134383, acc 1
2020-02-16T16:07:52.282759: step 2462, loss 0.0510259, acc 0.984375
2020-02-16T16:07:52.417106: step 2463, loss 0.0161569, acc 1
2020-02-16T16:07:52.540643: step 2464, loss 0.0452492, acc 0.984375
2020-02-16T16:07:52.672651: step 2465, loss 0.0201729, acc 1
2020-02-16T16:07:52.799784: step 2466, loss 0.0350503, acc 0.984375
2020-02-16T16:07:52.928237: step 2467, loss 0.0248443, acc 1
2020-02-16T16:07:53.055279: step 2468, loss 0.0219622, acc 1
2020-02-16T16:07:53.175386: step 2469, loss 0.0154705, acc 1
2020-02-16T16:07:53.293546: step 2470, loss 0.0317832, acc 1
2020-02-16T16:07:53.410714: step 2471, loss 0.0209775, acc 1
2020-02-16T16:07:53.527390: step 2472, loss 0.0299314, acc 1
2020-02-16T16:07:53.643929: step 2473, loss 0.00762101, acc 1
2020-02-16T16:07:53.767238: step 2474, loss 0.0239753, acc 0.984375
2020-02-16T16:07:53.884004: step 2475, loss 0.00593375, acc 1
2020-02-16T16:07:54.001619: step 2476, loss 0.029365, acc 0.984375
2020-02-16T16:07:54.120379: step 2477, loss 0.0324969, acc 0.984375
2020-02-16T16:07:54.238529: step 2478, loss 0.0245722, acc 1
2020-02-16T16:07:54.357467: step 2479, loss 0.0242063, acc 0.984375
2020-02-16T16:07:54.474525: step 2480, loss 0.0611932, acc 0.96875
2020-02-16T16:07:54.591728: step 2481, loss 0.0647099, acc 0.9375
2020-02-16T16:07:54.711357: step 2482, loss 0.0164635, acc 1
2020-02-16T16:07:54.846494: step 2483, loss 0.022029, acc 1
2020-02-16T16:07:54.967931: step 2484, loss 0.0414228, acc 0.984375
2020-02-16T16:07:55.084780: step 2485, loss 0.0558956, acc 0.96875
2020-02-16T16:07:55.204715: step 2486, loss 0.0321299, acc 1
2020-02-16T16:07:55.323246: step 2487, loss 0.00733896, acc 1
2020-02-16T16:07:55.438491: step 2488, loss 0.00796423, acc 1
2020-02-16T16:07:55.586667: step 2489, loss 0.0603611, acc 0.984375
2020-02-16T16:07:55.778888: step 2490, loss 0.0292154, acc 1
2020-02-16T16:07:55.940243: step 2491, loss 0.0189014, acc 1
2020-02-16T16:07:56.085946: step 2492, loss 0.0288294, acc 1
2020-02-16T16:07:56.212541: step 2493, loss 0.0173885, acc 1
2020-02-16T16:07:56.336959: step 2494, loss 0.0444412, acc 0.984375
2020-02-16T16:07:56.458354: step 2495, loss 0.0507759, acc 0.984375
2020-02-16T16:07:56.581180: step 2496, loss 0.0181508, acc 0.984375
2020-02-16T16:07:56.720064: step 2497, loss 0.017026, acc 1
2020-02-16T16:07:56.854831: step 2498, loss 0.0367415, acc 0.984375
2020-02-16T16:07:56.975705: step 2499, loss 0.0189847, acc 1
2020-02-16T16:07:57.103830: step 2500, loss 0.0810974, acc 0.9375

Evaluation:
2020-02-16T16:07:57.401803: step 2500, loss 0.896892, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2500

2020-02-16T16:07:59.010154: step 2501, loss 0.0270994, acc 1
2020-02-16T16:07:59.134291: step 2502, loss 0.0739935, acc 0.984375
2020-02-16T16:07:59.263336: step 2503, loss 0.00612277, acc 1
2020-02-16T16:07:59.402164: step 2504, loss 0.0633105, acc 0.96875
2020-02-16T16:07:59.558860: step 2505, loss 0.0138704, acc 1
2020-02-16T16:07:59.693693: step 2506, loss 0.0227839, acc 1
2020-02-16T16:07:59.854605: step 2507, loss 0.0130334, acc 1
2020-02-16T16:07:59.999924: step 2508, loss 0.0339729, acc 0.984375
2020-02-16T16:08:00.166891: step 2509, loss 0.0355118, acc 1
2020-02-16T16:08:00.490575: step 2510, loss 0.0500758, acc 0.984375
2020-02-16T16:08:00.712430: step 2511, loss 0.0166526, acc 1
2020-02-16T16:08:01.082910: step 2512, loss 0.0323943, acc 1
2020-02-16T16:08:01.231636: step 2513, loss 0.0231331, acc 1
2020-02-16T16:08:01.401713: step 2514, loss 0.0172537, acc 1
2020-02-16T16:08:01.528996: step 2515, loss 0.0465582, acc 0.984375
2020-02-16T16:08:01.651098: step 2516, loss 0.00618724, acc 1
2020-02-16T16:08:01.780477: step 2517, loss 0.0362718, acc 0.984375
2020-02-16T16:08:01.947656: step 2518, loss 0.0111121, acc 1
2020-02-16T16:08:02.089012: step 2519, loss 0.0161878, acc 1
2020-02-16T16:08:02.241276: step 2520, loss 0.0220943, acc 1
2020-02-16T16:08:02.403319: step 2521, loss 0.0325024, acc 1
2020-02-16T16:08:02.568656: step 2522, loss 0.0300127, acc 0.984375
2020-02-16T16:08:02.712629: step 2523, loss 0.0152647, acc 1
2020-02-16T16:08:02.841803: step 2524, loss 0.0525703, acc 0.984375
2020-02-16T16:08:02.960714: step 2525, loss 0.025634, acc 0.984375
2020-02-16T16:08:03.077082: step 2526, loss 0.042045, acc 0.984375
2020-02-16T16:08:03.216973: step 2527, loss 0.0291623, acc 0.984375
2020-02-16T16:08:03.398114: step 2528, loss 0.0153773, acc 1
2020-02-16T16:08:03.521175: step 2529, loss 0.0357351, acc 1
2020-02-16T16:08:03.643447: step 2530, loss 0.019795, acc 1
2020-02-16T16:08:03.767351: step 2531, loss 0.0303059, acc 1
2020-02-16T16:08:03.896318: step 2532, loss 0.0304932, acc 0.984375
2020-02-16T16:08:04.055941: step 2533, loss 0.0184594, acc 1
2020-02-16T16:08:04.202692: step 2534, loss 0.0996853, acc 0.984375
2020-02-16T16:08:04.332991: step 2535, loss 0.0377796, acc 0.96875
2020-02-16T16:08:04.459462: step 2536, loss 0.0298419, acc 1
2020-02-16T16:08:04.587113: step 2537, loss 0.0303384, acc 0.984375
2020-02-16T16:08:04.734851: step 2538, loss 0.0240198, acc 0.984375
2020-02-16T16:08:04.878202: step 2539, loss 0.0744069, acc 0.96875
2020-02-16T16:08:05.036555: step 2540, loss 0.0112212, acc 1
2020-02-16T16:08:05.171577: step 2541, loss 0.0328666, acc 1
2020-02-16T16:08:05.317481: step 2542, loss 0.0459801, acc 0.96875
2020-02-16T16:08:05.470589: step 2543, loss 0.0349342, acc 0.984375
2020-02-16T16:08:05.814299: step 2544, loss 0.0352631, acc 0.984375
2020-02-16T16:08:06.035203: step 2545, loss 0.021512, acc 1
2020-02-16T16:08:06.210984: step 2546, loss 0.0568304, acc 0.96875
2020-02-16T16:08:06.397245: step 2547, loss 0.0430875, acc 0.984375
2020-02-16T16:08:06.571685: step 2548, loss 0.018961, acc 1
2020-02-16T16:08:06.695194: step 2549, loss 0.0275036, acc 0.984375
2020-02-16T16:08:06.839908: step 2550, loss 0.027041, acc 1
2020-02-16T16:08:07.003887: step 2551, loss 0.0350977, acc 0.984375
2020-02-16T16:08:07.124583: step 2552, loss 0.0080189, acc 1
2020-02-16T16:08:07.243359: step 2553, loss 0.0560033, acc 0.96875
2020-02-16T16:08:07.364877: step 2554, loss 0.0154894, acc 1
2020-02-16T16:08:07.522728: step 2555, loss 0.0128754, acc 1
2020-02-16T16:08:07.670488: step 2556, loss 0.0151361, acc 1
2020-02-16T16:08:07.805096: step 2557, loss 0.0303801, acc 1
2020-02-16T16:08:07.941426: step 2558, loss 0.0191197, acc 1
2020-02-16T16:08:08.062454: step 2559, loss 0.0207078, acc 1
2020-02-16T16:08:08.197539: step 2560, loss 0.00909122, acc 1
2020-02-16T16:08:08.335990: step 2561, loss 0.028695, acc 1
2020-02-16T16:08:08.464353: step 2562, loss 0.0213343, acc 1
2020-02-16T16:08:08.594897: step 2563, loss 0.0325272, acc 0.984375
2020-02-16T16:08:08.734653: step 2564, loss 0.0211755, acc 1
2020-02-16T16:08:08.859816: step 2565, loss 0.0833526, acc 0.96875
2020-02-16T16:08:08.981942: step 2566, loss 0.0751698, acc 0.96875
2020-02-16T16:08:09.101069: step 2567, loss 0.0265959, acc 0.984375
2020-02-16T16:08:09.222955: step 2568, loss 0.0400188, acc 0.984375
2020-02-16T16:08:09.343778: step 2569, loss 0.0175178, acc 1
2020-02-16T16:08:09.466227: step 2570, loss 0.0114668, acc 1
2020-02-16T16:08:09.585349: step 2571, loss 0.0319741, acc 0.984375
2020-02-16T16:08:09.707011: step 2572, loss 0.0293872, acc 0.984375
2020-02-16T16:08:09.842970: step 2573, loss 0.0448606, acc 0.984375
2020-02-16T16:08:09.968424: step 2574, loss 0.0212883, acc 1
2020-02-16T16:08:10.087204: step 2575, loss 0.0126252, acc 1
2020-02-16T16:08:10.210687: step 2576, loss 0.0229451, acc 1
2020-02-16T16:08:10.330377: step 2577, loss 0.0106414, acc 1
2020-02-16T16:08:10.453957: step 2578, loss 0.0186488, acc 1
2020-02-16T16:08:10.571872: step 2579, loss 0.0622044, acc 0.984375
2020-02-16T16:08:10.693163: step 2580, loss 0.0348004, acc 0.984375
2020-02-16T16:08:10.851550: step 2581, loss 0.0226, acc 1
2020-02-16T16:08:10.992800: step 2582, loss 0.0314655, acc 1
2020-02-16T16:08:11.126499: step 2583, loss 0.0651933, acc 0.984375
2020-02-16T16:08:11.259053: step 2584, loss 0.0144476, acc 1
2020-02-16T16:08:11.410075: step 2585, loss 0.0350729, acc 0.984375
2020-02-16T16:08:11.767698: step 2586, loss 0.0155738, acc 1
2020-02-16T16:08:12.017255: step 2587, loss 0.00905336, acc 1
2020-02-16T16:08:12.159039: step 2588, loss 0.0198935, acc 1
2020-02-16T16:08:12.296932: step 2589, loss 0.0125229, acc 1
2020-02-16T16:08:12.427398: step 2590, loss 0.0637761, acc 0.96875
2020-02-16T16:08:12.566815: step 2591, loss 0.0581197, acc 0.96875
2020-02-16T16:08:12.735026: step 2592, loss 0.0209177, acc 1
2020-02-16T16:08:12.875218: step 2593, loss 0.0503278, acc 0.96875
2020-02-16T16:08:13.066174: step 2594, loss 0.048903, acc 0.984375
2020-02-16T16:08:13.449662: step 2595, loss 0.0276348, acc 0.984375
2020-02-16T16:08:13.580909: step 2596, loss 0.0749961, acc 0.984375
2020-02-16T16:08:13.796553: step 2597, loss 0.0463192, acc 0.96875
2020-02-16T16:08:13.978262: step 2598, loss 0.0190619, acc 0.984375
2020-02-16T16:08:14.141542: step 2599, loss 0.00855698, acc 1
2020-02-16T16:08:14.332632: step 2600, loss 0.011126, acc 1

Evaluation:
2020-02-16T16:08:14.572954: step 2600, loss 0.935046, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2600

2020-02-16T16:08:16.131386: step 2601, loss 0.0354057, acc 0.984375
2020-02-16T16:08:16.255969: step 2602, loss 0.0240618, acc 1
2020-02-16T16:08:16.379225: step 2603, loss 0.0349224, acc 1
2020-02-16T16:08:16.509648: step 2604, loss 0.0192363, acc 1
2020-02-16T16:08:16.631627: step 2605, loss 0.0132436, acc 1
2020-02-16T16:08:16.756837: step 2606, loss 0.0200202, acc 1
2020-02-16T16:08:16.882910: step 2607, loss 0.0889594, acc 0.96875
2020-02-16T16:08:17.005627: step 2608, loss 0.0268669, acc 0.984375
2020-02-16T16:08:17.129959: step 2609, loss 0.0109003, acc 1
2020-02-16T16:08:17.254907: step 2610, loss 0.0213366, acc 0.984375
2020-02-16T16:08:17.378946: step 2611, loss 0.0860523, acc 0.953125
2020-02-16T16:08:17.507052: step 2612, loss 0.00974073, acc 1
2020-02-16T16:08:17.636945: step 2613, loss 0.00913813, acc 1
2020-02-16T16:08:17.769870: step 2614, loss 0.0125436, acc 1
2020-02-16T16:08:17.898887: step 2615, loss 0.0542872, acc 1
2020-02-16T16:08:18.035091: step 2616, loss 0.0480602, acc 0.984375
2020-02-16T16:08:18.185582: step 2617, loss 0.0247641, acc 1
2020-02-16T16:08:18.328092: step 2618, loss 0.0231701, acc 0.984375
2020-02-16T16:08:18.475741: step 2619, loss 0.0324515, acc 0.984375
2020-02-16T16:08:18.733490: step 2620, loss 0.0250003, acc 1
2020-02-16T16:08:19.075762: step 2621, loss 0.00996129, acc 1
2020-02-16T16:08:19.239656: step 2622, loss 0.050385, acc 0.96875
2020-02-16T16:08:19.458478: step 2623, loss 0.0122891, acc 1
2020-02-16T16:08:19.659174: step 2624, loss 0.00901218, acc 1
2020-02-16T16:08:19.809547: step 2625, loss 0.0258582, acc 0.984375
2020-02-16T16:08:19.979865: step 2626, loss 0.0176747, acc 1
2020-02-16T16:08:20.199663: step 2627, loss 0.00770393, acc 1
2020-02-16T16:08:20.320574: step 2628, loss 0.0204981, acc 1
2020-02-16T16:08:20.441462: step 2629, loss 0.0172847, acc 1
2020-02-16T16:08:20.564065: step 2630, loss 0.0695483, acc 0.984375
2020-02-16T16:08:20.705575: step 2631, loss 0.0403289, acc 0.984375
2020-02-16T16:08:20.883623: step 2632, loss 0.0094006, acc 1
2020-02-16T16:08:21.049523: step 2633, loss 0.0784083, acc 0.96875
2020-02-16T16:08:21.209661: step 2634, loss 0.0875416, acc 0.953125
2020-02-16T16:08:21.380320: step 2635, loss 0.00745523, acc 1
2020-02-16T16:08:21.557707: step 2636, loss 0.0391368, acc 0.984375
2020-02-16T16:08:21.710610: step 2637, loss 0.00791061, acc 1
2020-02-16T16:08:21.871066: step 2638, loss 0.0546061, acc 0.96875
2020-02-16T16:08:21.991308: step 2639, loss 0.0091223, acc 1
2020-02-16T16:08:22.120543: step 2640, loss 0.0257394, acc 1
2020-02-16T16:08:22.301962: step 2641, loss 0.0738824, acc 0.96875
2020-02-16T16:08:22.448537: step 2642, loss 0.0410145, acc 0.96875
2020-02-16T16:08:22.614727: step 2643, loss 0.0497276, acc 0.96875
2020-02-16T16:08:22.776907: step 2644, loss 0.0698577, acc 0.984375
2020-02-16T16:08:22.934590: step 2645, loss 0.0201594, acc 1
2020-02-16T16:08:23.104406: step 2646, loss 0.038119, acc 0.984375
2020-02-16T16:08:23.282838: step 2647, loss 0.0145519, acc 1
2020-02-16T16:08:23.411810: step 2648, loss 0.0256662, acc 0.984375
2020-02-16T16:08:23.543565: step 2649, loss 0.0145639, acc 1
2020-02-16T16:08:23.720775: step 2650, loss 0.029985, acc 0.984375
2020-02-16T16:08:23.877020: step 2651, loss 0.0242851, acc 1
2020-02-16T16:08:24.065553: step 2652, loss 0.0216172, acc 1
2020-02-16T16:08:24.231352: step 2653, loss 0.0347838, acc 0.984375
2020-02-16T16:08:24.421029: step 2654, loss 0.0233789, acc 1
2020-02-16T16:08:24.570612: step 2655, loss 0.0107235, acc 1
2020-02-16T16:08:24.711276: step 2656, loss 0.0141179, acc 1
2020-02-16T16:08:24.856354: step 2657, loss 0.016984, acc 1
2020-02-16T16:08:25.064737: step 2658, loss 0.0635821, acc 0.96875
2020-02-16T16:08:25.207996: step 2659, loss 0.0102432, acc 1
2020-02-16T16:08:25.337783: step 2660, loss 0.135286, acc 0.953125
2020-02-16T16:08:25.471878: step 2661, loss 0.00886154, acc 1
2020-02-16T16:08:25.596963: step 2662, loss 0.038347, acc 0.984375
2020-02-16T16:08:25.775486: step 2663, loss 0.0174204, acc 1
2020-02-16T16:08:25.916613: step 2664, loss 0.0304565, acc 0.984375
2020-02-16T16:08:26.041460: step 2665, loss 0.0110366, acc 1
2020-02-16T16:08:26.164626: step 2666, loss 0.142676, acc 0.9375
2020-02-16T16:08:26.286790: step 2667, loss 0.0249183, acc 0.984375
2020-02-16T16:08:26.448230: step 2668, loss 0.0262652, acc 0.984375
2020-02-16T16:08:26.610249: step 2669, loss 0.0242634, acc 0.984375
2020-02-16T16:08:26.732361: step 2670, loss 0.0625286, acc 0.984375
2020-02-16T16:08:26.883037: step 2671, loss 0.00810603, acc 1
2020-02-16T16:08:27.066033: step 2672, loss 0.00762739, acc 1
2020-02-16T16:08:27.187596: step 2673, loss 0.0173115, acc 1
2020-02-16T16:08:27.308882: step 2674, loss 0.0258349, acc 0.984375
2020-02-16T16:08:27.426646: step 2675, loss 0.00684458, acc 1
2020-02-16T16:08:27.554418: step 2676, loss 0.00542315, acc 1
2020-02-16T16:08:27.681778: step 2677, loss 0.0224811, acc 1
2020-02-16T16:08:27.821021: step 2678, loss 0.00828567, acc 1
2020-02-16T16:08:27.941940: step 2679, loss 0.0127454, acc 1
2020-02-16T16:08:28.068106: step 2680, loss 0.0774922, acc 0.96875
2020-02-16T16:08:28.199030: step 2681, loss 0.0144832, acc 1
2020-02-16T16:08:28.323553: step 2682, loss 0.0238699, acc 1
2020-02-16T16:08:28.441642: step 2683, loss 0.0150167, acc 1
2020-02-16T16:08:28.567263: step 2684, loss 0.0432767, acc 0.984375
2020-02-16T16:08:28.685761: step 2685, loss 0.0488689, acc 0.984375
2020-02-16T16:08:28.817778: step 2686, loss 0.00356777, acc 1
2020-02-16T16:08:28.934953: step 2687, loss 0.0167691, acc 1
2020-02-16T16:08:29.056656: step 2688, loss 0.0325894, acc 0.984375
2020-02-16T16:08:29.173447: step 2689, loss 0.026879, acc 0.984375
2020-02-16T16:08:29.290714: step 2690, loss 0.029457, acc 1
2020-02-16T16:08:29.407729: step 2691, loss 0.0111691, acc 1
2020-02-16T16:08:29.528919: step 2692, loss 0.062476, acc 0.96875
2020-02-16T16:08:29.648994: step 2693, loss 0.0314629, acc 0.984375
2020-02-16T16:08:29.774560: step 2694, loss 0.0525015, acc 0.984375
2020-02-16T16:08:29.892373: step 2695, loss 0.00968476, acc 1
2020-02-16T16:08:30.010797: step 2696, loss 0.0191484, acc 1
2020-02-16T16:08:30.127965: step 2697, loss 0.0172167, acc 1
2020-02-16T16:08:30.246180: step 2698, loss 0.0464839, acc 0.984375
2020-02-16T16:08:30.364428: step 2699, loss 0.0178379, acc 1
2020-02-16T16:08:30.477443: step 2700, loss 0.00549012, acc 1

Evaluation:
2020-02-16T16:08:30.673190: step 2700, loss 0.940584, acc 0.73546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2700

2020-02-16T16:08:32.436947: step 2701, loss 0.00925121, acc 1
2020-02-16T16:08:32.588055: step 2702, loss 0.0203314, acc 1
2020-02-16T16:08:32.804370: step 2703, loss 0.0138863, acc 1
2020-02-16T16:08:32.950382: step 2704, loss 0.00883155, acc 1
2020-02-16T16:08:33.114128: step 2705, loss 0.0615083, acc 0.953125
2020-02-16T16:08:33.284437: step 2706, loss 0.0107847, acc 1
2020-02-16T16:08:33.409613: step 2707, loss 0.00792047, acc 1
2020-02-16T16:08:33.528480: step 2708, loss 0.0163836, acc 1
2020-02-16T16:08:33.647944: step 2709, loss 0.0238881, acc 0.984375
2020-02-16T16:08:33.823052: step 2710, loss 0.0156202, acc 1
2020-02-16T16:08:33.971553: step 2711, loss 0.0170607, acc 1
2020-02-16T16:08:34.092091: step 2712, loss 0.0108126, acc 1
2020-02-16T16:08:34.210509: step 2713, loss 0.0264734, acc 1
2020-02-16T16:08:34.366003: step 2714, loss 0.0179731, acc 1
2020-02-16T16:08:34.521601: step 2715, loss 0.0330559, acc 0.984375
2020-02-16T16:08:34.642537: step 2716, loss 0.0144417, acc 1
2020-02-16T16:08:34.767267: step 2717, loss 0.0232647, acc 1
2020-02-16T16:08:34.886521: step 2718, loss 0.0123853, acc 1
2020-02-16T16:08:35.015195: step 2719, loss 0.0126842, acc 1
2020-02-16T16:08:35.144913: step 2720, loss 0.0134651, acc 1
2020-02-16T16:08:35.271911: step 2721, loss 0.0192896, acc 1
2020-02-16T16:08:35.390517: step 2722, loss 0.00868368, acc 1
2020-02-16T16:08:35.510210: step 2723, loss 0.0484363, acc 0.984375
2020-02-16T16:08:35.627219: step 2724, loss 0.0236355, acc 1
2020-02-16T16:08:35.754799: step 2725, loss 0.0628149, acc 0.984375
2020-02-16T16:08:35.877058: step 2726, loss 0.0185512, acc 0.984375
2020-02-16T16:08:35.991549: step 2727, loss 0.0221943, acc 1
2020-02-16T16:08:36.111974: step 2728, loss 0.0365972, acc 0.984375
2020-02-16T16:08:36.229345: step 2729, loss 0.0215149, acc 1
2020-02-16T16:08:36.353358: step 2730, loss 0.0332887, acc 0.984375
2020-02-16T16:08:36.532383: step 2731, loss 0.0152131, acc 1
2020-02-16T16:08:36.704077: step 2732, loss 0.0242367, acc 0.984375
2020-02-16T16:08:36.893390: step 2733, loss 0.0199183, acc 1
2020-02-16T16:08:37.056105: step 2734, loss 0.017008, acc 1
2020-02-16T16:08:37.219602: step 2735, loss 0.0730838, acc 0.984375
2020-02-16T16:08:37.346768: step 2736, loss 0.0123473, acc 1
2020-02-16T16:08:37.510693: step 2737, loss 0.00858036, acc 1
2020-02-16T16:08:37.701153: step 2738, loss 0.012833, acc 1
2020-02-16T16:08:37.834662: step 2739, loss 0.0223621, acc 1
2020-02-16T16:08:37.957202: step 2740, loss 0.00857401, acc 1
2020-02-16T16:08:38.140026: step 2741, loss 0.019947, acc 1
2020-02-16T16:08:38.277329: step 2742, loss 0.00768496, acc 1
2020-02-16T16:08:38.400316: step 2743, loss 0.0453795, acc 0.984375
2020-02-16T16:08:38.522450: step 2744, loss 0.0196848, acc 1
2020-02-16T16:08:38.643501: step 2745, loss 0.0961023, acc 0.96875
2020-02-16T16:08:38.784328: step 2746, loss 0.0121382, acc 1
2020-02-16T16:08:38.914265: step 2747, loss 0.0163222, acc 1
2020-02-16T16:08:39.033033: step 2748, loss 0.0352478, acc 0.984375
2020-02-16T16:08:39.154113: step 2749, loss 0.0367977, acc 0.984375
2020-02-16T16:08:39.270880: step 2750, loss 0.0217664, acc 1
2020-02-16T16:08:39.392411: step 2751, loss 0.0123868, acc 1
2020-02-16T16:08:39.571585: step 2752, loss 0.0157138, acc 1
2020-02-16T16:08:39.701237: step 2753, loss 0.0161388, acc 1
2020-02-16T16:08:39.850101: step 2754, loss 0.0318531, acc 0.984375
2020-02-16T16:08:39.983190: step 2755, loss 0.00647449, acc 1
2020-02-16T16:08:40.121421: step 2756, loss 0.0464024, acc 0.96875
2020-02-16T16:08:40.263392: step 2757, loss 0.0158469, acc 1
2020-02-16T16:08:40.394817: step 2758, loss 0.00832634, acc 1
2020-02-16T16:08:40.512519: step 2759, loss 0.015185, acc 1
2020-02-16T16:08:40.630594: step 2760, loss 0.00464742, acc 1
2020-02-16T16:08:40.749517: step 2761, loss 0.025444, acc 0.984375
2020-02-16T16:08:40.869520: step 2762, loss 0.00545937, acc 1
2020-02-16T16:08:40.989545: step 2763, loss 0.0117035, acc 1
2020-02-16T16:08:41.106139: step 2764, loss 0.0140166, acc 1
2020-02-16T16:08:41.224301: step 2765, loss 0.00440062, acc 1
2020-02-16T16:08:41.345055: step 2766, loss 0.0664318, acc 0.984375
2020-02-16T16:08:41.462432: step 2767, loss 0.00491282, acc 1
2020-02-16T16:08:41.581885: step 2768, loss 0.00607578, acc 1
2020-02-16T16:08:41.699299: step 2769, loss 0.00642948, acc 1
2020-02-16T16:08:41.829728: step 2770, loss 0.0357377, acc 0.96875
2020-02-16T16:08:41.947264: step 2771, loss 0.0222141, acc 0.984375
2020-02-16T16:08:42.063069: step 2772, loss 0.00609316, acc 1
2020-02-16T16:08:42.180287: step 2773, loss 0.0104246, acc 1
2020-02-16T16:08:42.302173: step 2774, loss 0.00285933, acc 1
2020-02-16T16:08:42.419056: step 2775, loss 0.0294761, acc 0.984375
2020-02-16T16:08:42.556726: step 2776, loss 0.00682565, acc 1
2020-02-16T16:08:42.711650: step 2777, loss 0.0212055, acc 0.984375
2020-02-16T16:08:42.844987: step 2778, loss 0.0390211, acc 0.984375
2020-02-16T16:08:42.962973: step 2779, loss 0.0620263, acc 0.984375
2020-02-16T16:08:43.084269: step 2780, loss 0.0561927, acc 0.96875
2020-02-16T16:08:43.211333: step 2781, loss 0.0111236, acc 1
2020-02-16T16:08:43.345628: step 2782, loss 0.0151958, acc 1
2020-02-16T16:08:43.472000: step 2783, loss 0.0085577, acc 1
2020-02-16T16:08:43.606547: step 2784, loss 0.0158411, acc 1
2020-02-16T16:08:43.782256: step 2785, loss 0.0659399, acc 0.9375
2020-02-16T16:08:43.931008: step 2786, loss 0.01933, acc 1
2020-02-16T16:08:44.056065: step 2787, loss 0.0131437, acc 1
2020-02-16T16:08:44.175189: step 2788, loss 0.0210928, acc 0.984375
2020-02-16T16:08:44.301607: step 2789, loss 0.00686068, acc 1
2020-02-16T16:08:44.433159: step 2790, loss 0.0156613, acc 1
2020-02-16T16:08:44.569746: step 2791, loss 0.0145956, acc 1
2020-02-16T16:08:44.697824: step 2792, loss 0.0143982, acc 1
2020-02-16T16:08:44.828320: step 2793, loss 0.0966476, acc 0.953125
2020-02-16T16:08:44.958998: step 2794, loss 0.00139453, acc 1
2020-02-16T16:08:45.079457: step 2795, loss 0.0159566, acc 1
2020-02-16T16:08:45.203717: step 2796, loss 0.00918606, acc 1
2020-02-16T16:08:45.339307: step 2797, loss 0.0204901, acc 1
2020-02-16T16:08:45.467534: step 2798, loss 0.0719953, acc 0.96875
2020-02-16T16:08:45.588795: step 2799, loss 0.0237864, acc 1
2020-02-16T16:08:45.714215: step 2800, loss 0.0790663, acc 0.953125

Evaluation:
2020-02-16T16:08:45.925481: step 2800, loss 0.97526, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2800

2020-02-16T16:08:48.202329: step 2801, loss 0.00646361, acc 1
2020-02-16T16:08:48.340658: step 2802, loss 0.02327, acc 0.984375
2020-02-16T16:08:48.465565: step 2803, loss 0.0214823, acc 0.984375
2020-02-16T16:08:48.599132: step 2804, loss 0.00901884, acc 1
2020-02-16T16:08:48.735665: step 2805, loss 0.0235762, acc 0.984375
2020-02-16T16:08:48.870964: step 2806, loss 0.024344, acc 0.984375
2020-02-16T16:08:49.009253: step 2807, loss 0.0160267, acc 1
2020-02-16T16:08:49.130927: step 2808, loss 0.042229, acc 0.96875
2020-02-16T16:08:49.252871: step 2809, loss 0.00482809, acc 1
2020-02-16T16:08:49.380453: step 2810, loss 0.0109911, acc 1
2020-02-16T16:08:49.530720: step 2811, loss 0.0503373, acc 0.984375
2020-02-16T16:08:49.655555: step 2812, loss 0.0913389, acc 0.984375
2020-02-16T16:08:49.835694: step 2813, loss 0.0101888, acc 1
2020-02-16T16:08:49.965056: step 2814, loss 0.0241468, acc 1
2020-02-16T16:08:50.099086: step 2815, loss 0.0259004, acc 0.984375
2020-02-16T16:08:50.257417: step 2816, loss 0.0691629, acc 0.984375
2020-02-16T16:08:50.425052: step 2817, loss 0.00954605, acc 1
2020-02-16T16:08:50.580140: step 2818, loss 0.0528656, acc 0.984375
2020-02-16T16:08:50.716704: step 2819, loss 0.00820848, acc 1
2020-02-16T16:08:50.930893: step 2820, loss 0.0349804, acc 0.984375
2020-02-16T16:08:51.309326: step 2821, loss 0.0229223, acc 1
2020-02-16T16:08:51.452305: step 2822, loss 0.0144391, acc 1
2020-02-16T16:08:51.609415: step 2823, loss 0.0579938, acc 0.984375
2020-02-16T16:08:51.805479: step 2824, loss 0.00903672, acc 1
2020-02-16T16:08:51.930136: step 2825, loss 0.0372713, acc 0.984375
2020-02-16T16:08:52.054298: step 2826, loss 0.0047963, acc 1
2020-02-16T16:08:52.177074: step 2827, loss 0.0214112, acc 0.984375
2020-02-16T16:08:52.306582: step 2828, loss 0.0468877, acc 0.96875
2020-02-16T16:08:52.479214: step 2829, loss 0.0204289, acc 1
2020-02-16T16:08:52.650014: step 2830, loss 0.0266015, acc 1
2020-02-16T16:08:52.781871: step 2831, loss 0.0590191, acc 0.984375
2020-02-16T16:08:52.913093: step 2832, loss 0.00495494, acc 1
2020-02-16T16:08:53.044015: step 2833, loss 0.0275761, acc 1
2020-02-16T16:08:53.210046: step 2834, loss 0.0312669, acc 0.984375
2020-02-16T16:08:53.366702: step 2835, loss 0.0419419, acc 0.984375
2020-02-16T16:08:53.498759: step 2836, loss 0.0101335, acc 1
2020-02-16T16:08:53.628284: step 2837, loss 0.00931725, acc 1
2020-02-16T16:08:53.750404: step 2838, loss 0.00614152, acc 1
2020-02-16T16:08:53.873632: step 2839, loss 0.0204999, acc 0.984375
2020-02-16T16:08:53.993107: step 2840, loss 0.116615, acc 0.953125
2020-02-16T16:08:54.117254: step 2841, loss 0.0102056, acc 1
2020-02-16T16:08:54.240253: step 2842, loss 0.0234157, acc 0.984375
2020-02-16T16:08:54.360059: step 2843, loss 0.00923917, acc 1
2020-02-16T16:08:54.528265: step 2844, loss 0.0180565, acc 1
2020-02-16T16:08:54.991887: step 2845, loss 0.0317208, acc 1
2020-02-16T16:08:55.127248: step 2846, loss 0.0783001, acc 0.96875
2020-02-16T16:08:55.288333: step 2847, loss 0.0150839, acc 1
2020-02-16T16:08:55.467219: step 2848, loss 0.0305152, acc 0.984375
2020-02-16T16:08:55.591956: step 2849, loss 0.0181085, acc 1
2020-02-16T16:08:55.754539: step 2850, loss 0.00616495, acc 1
2020-02-16T16:08:55.923073: step 2851, loss 0.00179637, acc 1
2020-02-16T16:08:56.050981: step 2852, loss 0.0213865, acc 1
2020-02-16T16:08:56.174028: step 2853, loss 0.0156945, acc 1
2020-02-16T16:08:56.345774: step 2854, loss 0.0304602, acc 0.984375
2020-02-16T16:08:56.494839: step 2855, loss 0.0106233, acc 1
2020-02-16T16:08:56.620783: step 2856, loss 0.00571873, acc 1
2020-02-16T16:08:56.771374: step 2857, loss 0.0127553, acc 1
2020-02-16T16:08:56.932204: step 2858, loss 0.00381528, acc 1
2020-02-16T16:08:57.064065: step 2859, loss 0.0135228, acc 1
2020-02-16T16:08:57.189232: step 2860, loss 0.0362838, acc 0.984375
2020-02-16T16:08:57.361218: step 2861, loss 0.0535201, acc 0.984375
2020-02-16T16:08:57.500285: step 2862, loss 0.0124498, acc 1
2020-02-16T16:08:57.624716: step 2863, loss 0.022429, acc 1
2020-02-16T16:08:57.780000: step 2864, loss 0.00687378, acc 1
2020-02-16T16:08:57.931736: step 2865, loss 0.0308009, acc 1
2020-02-16T16:08:58.054248: step 2866, loss 0.0342238, acc 0.984375
2020-02-16T16:08:58.219894: step 2867, loss 0.0125241, acc 1
2020-02-16T16:08:58.362106: step 2868, loss 0.0215734, acc 0.984375
2020-02-16T16:08:58.483258: step 2869, loss 0.00645487, acc 1
2020-02-16T16:08:58.606792: step 2870, loss 0.0214665, acc 0.984375
2020-02-16T16:08:58.806233: step 2871, loss 0.0143167, acc 1
2020-02-16T16:08:58.935587: step 2872, loss 0.0148264, acc 1
2020-02-16T16:08:59.059726: step 2873, loss 0.0369479, acc 0.984375
2020-02-16T16:08:59.236412: step 2874, loss 0.0144329, acc 1
2020-02-16T16:08:59.363390: step 2875, loss 0.017378, acc 1
2020-02-16T16:08:59.527123: step 2876, loss 0.0158259, acc 1
2020-02-16T16:08:59.661922: step 2877, loss 0.00636018, acc 1
2020-02-16T16:08:59.792107: step 2878, loss 0.00422721, acc 1
2020-02-16T16:08:59.956839: step 2879, loss 0.0117761, acc 1
2020-02-16T16:09:00.122149: step 2880, loss 0.00975535, acc 1
2020-02-16T16:09:00.249214: step 2881, loss 0.00584432, acc 1
2020-02-16T16:09:00.373892: step 2882, loss 0.0134586, acc 1
2020-02-16T16:09:00.493043: step 2883, loss 0.0135259, acc 1
2020-02-16T16:09:00.625561: step 2884, loss 0.0198068, acc 1
2020-02-16T16:09:00.820932: step 2885, loss 0.0240235, acc 1
2020-02-16T16:09:00.959698: step 2886, loss 0.0390138, acc 0.984375
2020-02-16T16:09:01.304634: step 2887, loss 0.00623871, acc 1
2020-02-16T16:09:01.486396: step 2888, loss 0.00933955, acc 1
2020-02-16T16:09:01.615738: step 2889, loss 0.0158719, acc 1
2020-02-16T16:09:01.736955: step 2890, loss 0.0238642, acc 0.984375
2020-02-16T16:09:01.904547: step 2891, loss 0.00513406, acc 1
2020-02-16T16:09:02.059883: step 2892, loss 0.0507017, acc 0.984375
2020-02-16T16:09:02.179903: step 2893, loss 0.0361282, acc 0.984375
2020-02-16T16:09:02.303057: step 2894, loss 0.0190922, acc 1
2020-02-16T16:09:02.488860: step 2895, loss 0.0391479, acc 0.984375
2020-02-16T16:09:02.636650: step 2896, loss 0.00998722, acc 1
2020-02-16T16:09:02.778108: step 2897, loss 0.0179458, acc 1
2020-02-16T16:09:02.970652: step 2898, loss 0.0206009, acc 1
2020-02-16T16:09:03.102124: step 2899, loss 0.00534841, acc 1
2020-02-16T16:09:03.226149: step 2900, loss 0.0260786, acc 0.984375

Evaluation:
2020-02-16T16:09:03.476411: step 2900, loss 1.00337, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-2900

2020-02-16T16:09:05.584508: step 2901, loss 0.00421621, acc 1
2020-02-16T16:09:05.707362: step 2902, loss 0.00330132, acc 1
2020-02-16T16:09:05.833000: step 2903, loss 0.0349522, acc 0.984375
2020-02-16T16:09:05.957382: step 2904, loss 0.0226134, acc 0.984375
2020-02-16T16:09:06.075715: step 2905, loss 0.00451469, acc 1
2020-02-16T16:09:06.193900: step 2906, loss 0.00703967, acc 1
2020-02-16T16:09:06.313459: step 2907, loss 0.00440106, acc 1
2020-02-16T16:09:06.433284: step 2908, loss 0.0181579, acc 1
2020-02-16T16:09:06.556977: step 2909, loss 0.00667887, acc 1
2020-02-16T16:09:06.678396: step 2910, loss 0.00408345, acc 1
2020-02-16T16:09:06.818885: step 2911, loss 0.0297177, acc 1
2020-02-16T16:09:06.940972: step 2912, loss 0.00784469, acc 1
2020-02-16T16:09:07.061842: step 2913, loss 0.00474475, acc 1
2020-02-16T16:09:07.178269: step 2914, loss 0.00886617, acc 1
2020-02-16T16:09:07.298198: step 2915, loss 0.0149184, acc 1
2020-02-16T16:09:07.418155: step 2916, loss 0.00525018, acc 1
2020-02-16T16:09:07.535841: step 2917, loss 0.00779634, acc 1
2020-02-16T16:09:07.655913: step 2918, loss 0.0256069, acc 1
2020-02-16T16:09:07.777977: step 2919, loss 0.00484924, acc 1
2020-02-16T16:09:07.904892: step 2920, loss 0.032205, acc 0.984375
2020-02-16T16:09:08.036501: step 2921, loss 0.00700471, acc 1
2020-02-16T16:09:08.181750: step 2922, loss 0.0205073, acc 0.984375
2020-02-16T16:09:08.307993: step 2923, loss 0.0296248, acc 0.984375
2020-02-16T16:09:08.444105: step 2924, loss 0.00835695, acc 1
2020-02-16T16:09:08.591360: step 2925, loss 0.0122354, acc 1
2020-02-16T16:09:08.730413: step 2926, loss 0.0172918, acc 0.984375
2020-02-16T16:09:08.881408: step 2927, loss 0.0290637, acc 0.984375
2020-02-16T16:09:09.024553: step 2928, loss 0.0285242, acc 0.984375
2020-02-16T16:09:09.147244: step 2929, loss 0.0923624, acc 0.953125
2020-02-16T16:09:09.267741: step 2930, loss 0.0167398, acc 1
2020-02-16T16:09:09.435974: step 2931, loss 0.0110437, acc 1
2020-02-16T16:09:09.563763: step 2932, loss 0.0318942, acc 0.984375
2020-02-16T16:09:09.693023: step 2933, loss 0.0123127, acc 1
2020-02-16T16:09:09.857750: step 2934, loss 0.00190041, acc 1
2020-02-16T16:09:09.983583: step 2935, loss 0.0230581, acc 0.984375
2020-02-16T16:09:10.106099: step 2936, loss 0.0438488, acc 0.96875
2020-02-16T16:09:10.248901: step 2937, loss 0.00947088, acc 1
2020-02-16T16:09:10.396010: step 2938, loss 0.0170504, acc 1
2020-02-16T16:09:10.528549: step 2939, loss 0.004805, acc 1
2020-02-16T16:09:10.675070: step 2940, loss 0.00664374, acc 1
2020-02-16T16:09:10.845406: step 2941, loss 0.00793637, acc 1
2020-02-16T16:09:10.977555: step 2942, loss 0.00802618, acc 1
2020-02-16T16:09:11.098654: step 2943, loss 0.0406225, acc 0.984375
2020-02-16T16:09:11.224908: step 2944, loss 0.00967532, acc 1
2020-02-16T16:09:11.354544: step 2945, loss 0.0443944, acc 0.96875
2020-02-16T16:09:11.489010: step 2946, loss 0.0156536, acc 0.984375
2020-02-16T16:09:11.627369: step 2947, loss 0.00475173, acc 1
2020-02-16T16:09:11.810029: step 2948, loss 0.00653118, acc 1
2020-02-16T16:09:11.946637: step 2949, loss 0.0331689, acc 0.984375
2020-02-16T16:09:12.086443: step 2950, loss 0.0181281, acc 1
2020-02-16T16:09:12.250873: step 2951, loss 0.0379724, acc 0.96875
2020-02-16T16:09:12.381565: step 2952, loss 0.0285689, acc 0.984375
2020-02-16T16:09:12.508655: step 2953, loss 0.0223807, acc 0.984375
2020-02-16T16:09:12.678234: step 2954, loss 0.0219029, acc 1
2020-02-16T16:09:12.815858: step 2955, loss 0.00516608, acc 1
2020-02-16T16:09:12.956102: step 2956, loss 0.0179942, acc 0.984375
2020-02-16T16:09:13.102240: step 2957, loss 0.0128641, acc 1
2020-02-16T16:09:13.231419: step 2958, loss 0.0155088, acc 1
2020-02-16T16:09:13.375411: step 2959, loss 0.00489087, acc 1
2020-02-16T16:09:13.524046: step 2960, loss 0.0096195, acc 1
2020-02-16T16:09:13.657473: step 2961, loss 0.0321852, acc 0.984375
2020-02-16T16:09:13.807522: step 2962, loss 0.0115843, acc 1
2020-02-16T16:09:13.966704: step 2963, loss 0.0047492, acc 1
2020-02-16T16:09:14.416240: step 2964, loss 0.00987322, acc 1
2020-02-16T16:09:14.567512: step 2965, loss 0.00521226, acc 1
2020-02-16T16:09:14.705036: step 2966, loss 0.027643, acc 0.984375
2020-02-16T16:09:14.857401: step 2967, loss 0.0131868, acc 1
2020-02-16T16:09:15.077516: step 2968, loss 0.0333491, acc 0.984375
2020-02-16T16:09:15.237862: step 2969, loss 0.0151085, acc 1
2020-02-16T16:09:15.416145: step 2970, loss 0.0545871, acc 0.96875
2020-02-16T16:09:15.548690: step 2971, loss 0.0235126, acc 0.984375
2020-02-16T16:09:15.708145: step 2972, loss 0.00343775, acc 1
2020-02-16T16:09:15.884422: step 2973, loss 0.0134386, acc 1
2020-02-16T16:09:16.028056: step 2974, loss 0.00235112, acc 1
2020-02-16T16:09:16.201145: step 2975, loss 0.00721735, acc 1
2020-02-16T16:09:16.385996: step 2976, loss 0.0129264, acc 1
2020-02-16T16:09:16.553671: step 2977, loss 0.0154888, acc 1
2020-02-16T16:09:16.708455: step 2978, loss 0.00701417, acc 1
2020-02-16T16:09:16.856961: step 2979, loss 0.050287, acc 0.984375
2020-02-16T16:09:17.032878: step 2980, loss 0.0116267, acc 1
2020-02-16T16:09:17.432752: step 2981, loss 0.00969424, acc 1
2020-02-16T16:09:17.564849: step 2982, loss 0.011454, acc 1
2020-02-16T16:09:17.741646: step 2983, loss 0.00755785, acc 1
2020-02-16T16:09:17.933585: step 2984, loss 0.0295659, acc 0.984375
2020-02-16T16:09:18.099740: step 2985, loss 0.0106012, acc 1
2020-02-16T16:09:18.227893: step 2986, loss 0.0161475, acc 1
2020-02-16T16:09:18.406317: step 2987, loss 0.0351373, acc 0.984375
2020-02-16T16:09:18.540791: step 2988, loss 0.0141778, acc 1
2020-02-16T16:09:18.663136: step 2989, loss 0.0481508, acc 0.984375
2020-02-16T16:09:18.809098: step 2990, loss 0.0123382, acc 1
2020-02-16T16:09:18.942332: step 2991, loss 0.0222039, acc 1
2020-02-16T16:09:19.081045: step 2992, loss 0.0307696, acc 0.984375
2020-02-16T16:09:19.213144: step 2993, loss 0.0258333, acc 0.984375
2020-02-16T16:09:19.332925: step 2994, loss 0.0140398, acc 1
2020-02-16T16:09:19.451605: step 2995, loss 0.0115719, acc 1
2020-02-16T16:09:19.574649: step 2996, loss 0.0135025, acc 1
2020-02-16T16:09:19.702630: step 2997, loss 0.0177291, acc 1
2020-02-16T16:09:19.872537: step 2998, loss 0.0160131, acc 1
2020-02-16T16:09:20.011380: step 2999, loss 0.00844435, acc 1
2020-02-16T16:09:20.143883: step 3000, loss 0.0175514, acc 0.983333

Evaluation:
2020-02-16T16:09:20.381107: step 3000, loss 1.02643, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581840073/checkpoints/model-3000

