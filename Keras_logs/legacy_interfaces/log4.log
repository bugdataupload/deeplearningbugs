Using TensorFlow backend.
Load data...
Adjusting sequence length for actual size
x_train shape: (9595, 56)
x_test shape: (1067, 56)
Vocabulary Size: 18779
Model type is CNN-non-static
Load existing Word2Vec model '50features_1minwords_10context'
Traceback (most recent call last):
  File "sentiment_cnn.py", line 135, in <module>
    z = Embedding(len(vocabulary_inv), embedding_dim, input_length=sequence_length, name="embedding")(model_input)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 34, in wrapper
    args, kwargs, converted = preprocessor(args, kwargs)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 127, in embedding_kwargs_preprocessor
    kwargs.pop('dropout')
KeyError: 'dropout'
