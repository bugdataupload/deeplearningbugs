Using TensorFlow backend.
Load data...
Adjusting sequence length for actual size
x_train shape: (9595, 56)
x_test shape: (1067, 56)
Vocabulary Size: 18779
Model type is CNN-non-static
Load existing Word2Vec model '50features_1minwords_10context'
Traceback (most recent call last):
  File "sentiment_cnn.py", line 135, in <module>
    z = Embedding(len(vocabulary_inv), embedding_dim, input_length=sequence_length, name="embedding")(model_input)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/layers/embeddings.py", line 100, in __init__
    self.embeddings_constraint = constraints.get(embeddings_constraint)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/constraints.py", line 183, in get
    str(identifier))
ValueError: Could not interpret constraint identifier: None
