Using TensorFlow backend.
Load data...
Adjusting sequence length for actual size
x_train shape: (9595, 56)
x_test shape: (1067, 56)
Vocabulary Size: 18779
Model type is CNN-non-static
Load existing Word2Vec model '50features_1minwords_10context'
Traceback (most recent call last):
  File "sentiment_cnn.py", line 135, in <module>
    z = Embedding(len(vocabulary_inv), embedding_dim, input_length=sequence_length, name="embedding")(model_input)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/engine/base_layer.py", line 463, in __call__
    self.build(unpack_singleton(input_shapes))
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/layers/embeddings.py", line 112, in build
    dtype=self.dtype)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/engine/base_layer.py", line 279, in add_weight
    weight = K.variable(initializer(shape, dtype=dtype),
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/initializers.py", line 117, in __call__
    self.seed += 1
TypeError: unsupported operand type(s) for +=: 'NoneType' and 'int'
