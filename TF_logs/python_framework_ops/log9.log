WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:27:03.941632 4795833792 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:27:03.941846 4795833792 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:27:03.941951 4795833792 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:27:04.457614 4795833792 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:27:04.457857 4795833792 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:27:04.458062: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:27:04.472487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd620c5080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:27:04.472509: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:27:04.472924 4795833792 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:27:04.477905 4795833792 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:27:04.488615 4795833792 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:27:04.497704 4795833792 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:27:04.524547 4795833792 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:27:04.534860 4795833792 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:27:04.535094 4795833792 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:27:04.547847 4795833792 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:27:04.550654 4795833792 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:27:04.582568 4795833792 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:27:04.832111 4795833792 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:27:04.832486 4795833792 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:27:04.838202 4795833792 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:27:04.856036 4795833792 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:27:04.857175 4795833792 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:27:04.877818 4795833792 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:27:04.878953 4795833792 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:27:04.893576 4795833792 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:27:04.894624 4795833792 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:27:04.909669 4795833792 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:27:04.910727 4795833792 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:27:04.928573 4795833792 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:27:04.929829 4795833792 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:27:04.946301 4795833792 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:27:04.947425 4795833792 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:27:04.961899 4795833792 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:27:04.963604 4795833792 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:27:04.987683 4795833792 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:27:04.989158 4795833792 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:27:05.008699 4795833792 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:27:05.009787 4795833792 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:27:05.014420 4795833792 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:27:05.839909 4795833792 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:27:05.840381 4795833792 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:27:05.936779 4795833792 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:27:06.495390 4795833792 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:28:28.811311 4795833792 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025

2020-02-08T02:27:06.494889: step 1, loss 2.6676, acc 0.453125
2020-02-08T02:27:06.628570: step 2, loss 1.71612, acc 0.484375
2020-02-08T02:27:06.748769: step 3, loss 2.2909, acc 0.53125
2020-02-08T02:27:06.865571: step 4, loss 2.3234, acc 0.484375
2020-02-08T02:27:06.984629: step 5, loss 1.97719, acc 0.53125
2020-02-08T02:27:07.101445: step 6, loss 1.8264, acc 0.484375
2020-02-08T02:27:07.220605: step 7, loss 2.18146, acc 0.546875
2020-02-08T02:27:07.337678: step 8, loss 1.60702, acc 0.59375
2020-02-08T02:27:07.455115: step 9, loss 1.74515, acc 0.515625
2020-02-08T02:27:07.573299: step 10, loss 2.11146, acc 0.5
2020-02-08T02:27:07.690222: step 11, loss 2.43851, acc 0.390625
2020-02-08T02:27:07.804504: step 12, loss 1.949, acc 0.515625
2020-02-08T02:27:07.921544: step 13, loss 1.23744, acc 0.65625
2020-02-08T02:27:08.041647: step 14, loss 2.01072, acc 0.484375
2020-02-08T02:27:08.155505: step 15, loss 1.8465, acc 0.59375
2020-02-08T02:27:08.272033: step 16, loss 2.0995, acc 0.546875
2020-02-08T02:27:08.388323: step 17, loss 1.69374, acc 0.5
2020-02-08T02:27:08.505474: step 18, loss 1.60847, acc 0.53125
2020-02-08T02:27:08.627857: step 19, loss 1.54564, acc 0.5
2020-02-08T02:27:08.750818: step 20, loss 2.2042, acc 0.53125
2020-02-08T02:27:08.865066: step 21, loss 2.04934, acc 0.53125
2020-02-08T02:27:08.983973: step 22, loss 1.87429, acc 0.578125
2020-02-08T02:27:09.100129: step 23, loss 1.89762, acc 0.484375
2020-02-08T02:27:09.217251: step 24, loss 2.03338, acc 0.5
2020-02-08T02:27:09.335956: step 25, loss 1.92701, acc 0.53125
2020-02-08T02:27:09.451976: step 26, loss 1.56369, acc 0.515625
2020-02-08T02:27:09.568800: step 27, loss 1.47487, acc 0.5
2020-02-08T02:27:09.690314: step 28, loss 1.50971, acc 0.546875
2020-02-08T02:27:09.806547: step 29, loss 1.28355, acc 0.609375
2020-02-08T02:27:09.927431: step 30, loss 1.29413, acc 0.609375
2020-02-08T02:27:10.046324: step 31, loss 1.96107, acc 0.46875
2020-02-08T02:27:10.161551: step 32, loss 1.66098, acc 0.609375
2020-02-08T02:27:10.279678: step 33, loss 1.72807, acc 0.421875
2020-02-08T02:27:10.397426: step 34, loss 1.63788, acc 0.5625
2020-02-08T02:27:10.513701: step 35, loss 1.86541, acc 0.5
2020-02-08T02:27:10.631358: step 36, loss 1.95058, acc 0.46875
2020-02-08T02:27:10.752307: step 37, loss 1.64976, acc 0.5
2020-02-08T02:27:10.871999: step 38, loss 1.99971, acc 0.421875
2020-02-08T02:27:10.994017: step 39, loss 2.43714, acc 0.484375
2020-02-08T02:27:11.111285: step 40, loss 2.02863, acc 0.453125
2020-02-08T02:27:11.226426: step 41, loss 1.49192, acc 0.625
2020-02-08T02:27:11.344762: step 42, loss 1.90143, acc 0.484375
2020-02-08T02:27:11.460830: step 43, loss 1.29768, acc 0.65625
2020-02-08T02:27:11.578905: step 44, loss 1.79316, acc 0.5
2020-02-08T02:27:11.701027: step 45, loss 1.44378, acc 0.59375
2020-02-08T02:27:11.816388: step 46, loss 1.89367, acc 0.53125
2020-02-08T02:27:11.936423: step 47, loss 1.32165, acc 0.5625
2020-02-08T02:27:12.053725: step 48, loss 1.80205, acc 0.484375
2020-02-08T02:27:12.171004: step 49, loss 1.53606, acc 0.59375
2020-02-08T02:27:12.288856: step 50, loss 1.47559, acc 0.5
2020-02-08T02:27:12.405458: step 51, loss 1.66873, acc 0.546875
2020-02-08T02:27:12.525185: step 52, loss 1.51739, acc 0.5625
2020-02-08T02:27:12.644595: step 53, loss 1.84039, acc 0.421875
2020-02-08T02:27:12.771504: step 54, loss 1.89351, acc 0.5
2020-02-08T02:27:12.890056: step 55, loss 1.37697, acc 0.59375
2020-02-08T02:27:13.005428: step 56, loss 1.52488, acc 0.578125
2020-02-08T02:27:13.126696: step 57, loss 1.77297, acc 0.453125
2020-02-08T02:27:13.244338: step 58, loss 1.46557, acc 0.5625
2020-02-08T02:27:13.363256: step 59, loss 1.51636, acc 0.515625
2020-02-08T02:27:13.482162: step 60, loss 1.51065, acc 0.515625
2020-02-08T02:27:13.601930: step 61, loss 1.49697, acc 0.515625
2020-02-08T02:27:13.725835: step 62, loss 1.70125, acc 0.515625
2020-02-08T02:27:13.844285: step 63, loss 1.62684, acc 0.5625
2020-02-08T02:27:13.960878: step 64, loss 1.99901, acc 0.5
2020-02-08T02:27:14.078581: step 65, loss 1.39165, acc 0.5625
2020-02-08T02:27:14.193251: step 66, loss 1.51928, acc 0.453125
2020-02-08T02:27:14.308337: step 67, loss 1.36417, acc 0.53125
2020-02-08T02:27:14.425027: step 68, loss 1.63956, acc 0.515625
2020-02-08T02:27:14.543774: step 69, loss 1.4063, acc 0.5625
2020-02-08T02:27:14.659369: step 70, loss 1.71369, acc 0.5
2020-02-08T02:27:14.782041: step 71, loss 1.30548, acc 0.5625
2020-02-08T02:27:14.897816: step 72, loss 1.43741, acc 0.5625
2020-02-08T02:27:15.013860: step 73, loss 1.21182, acc 0.578125
2020-02-08T02:27:15.133706: step 74, loss 1.60317, acc 0.4375
2020-02-08T02:27:15.250477: step 75, loss 1.71741, acc 0.53125
2020-02-08T02:27:15.367955: step 76, loss 1.68191, acc 0.546875
2020-02-08T02:27:15.489946: step 77, loss 1.52177, acc 0.46875
2020-02-08T02:27:15.607745: step 78, loss 1.75359, acc 0.46875
2020-02-08T02:27:15.730509: step 79, loss 1.82714, acc 0.5
2020-02-08T02:27:15.846678: step 80, loss 1.51896, acc 0.546875
2020-02-08T02:27:15.967534: step 81, loss 1.5788, acc 0.5625
2020-02-08T02:27:16.084990: step 82, loss 1.49313, acc 0.484375
2020-02-08T02:27:16.201487: step 83, loss 1.95535, acc 0.515625
2020-02-08T02:27:16.316531: step 84, loss 1.19819, acc 0.546875
2020-02-08T02:27:16.432714: step 85, loss 1.61121, acc 0.515625
2020-02-08T02:27:16.550520: step 86, loss 1.63682, acc 0.515625
2020-02-08T02:27:16.669322: step 87, loss 1.73973, acc 0.59375
2020-02-08T02:27:16.785285: step 88, loss 1.71574, acc 0.546875
2020-02-08T02:27:16.901288: step 89, loss 1.28846, acc 0.59375
2020-02-08T02:27:17.015789: step 90, loss 1.42595, acc 0.625
2020-02-08T02:27:17.133148: step 91, loss 1.45225, acc 0.5625
2020-02-08T02:27:17.251345: step 92, loss 1.67922, acc 0.515625
2020-02-08T02:27:17.366770: step 93, loss 1.10186, acc 0.609375
2020-02-08T02:27:17.483444: step 94, loss 1.38173, acc 0.625
2020-02-08T02:27:17.600080: step 95, loss 1.81316, acc 0.515625
2020-02-08T02:27:17.724137: step 96, loss 1.63217, acc 0.53125
2020-02-08T02:27:17.848408: step 97, loss 2.03457, acc 0.390625
2020-02-08T02:27:17.971874: step 98, loss 1.23721, acc 0.5625
2020-02-08T02:27:18.089838: step 99, loss 1.57309, acc 0.5
2020-02-08T02:27:18.203710: step 100, loss 1.28396, acc 0.625

Evaluation:
2020-02-08T02:27:18.439780: step 100, loss 1.17468, acc 0.534709

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-100

2020-02-08T02:27:20.082302: step 101, loss 1.11988, acc 0.65625
2020-02-08T02:27:20.199504: step 102, loss 1.65389, acc 0.484375
2020-02-08T02:27:20.315463: step 103, loss 1.56208, acc 0.546875
2020-02-08T02:27:20.432731: step 104, loss 1.54902, acc 0.578125
2020-02-08T02:27:20.548398: step 105, loss 1.29776, acc 0.5625
2020-02-08T02:27:20.668514: step 106, loss 1.29156, acc 0.515625
2020-02-08T02:27:20.788990: step 107, loss 1.52192, acc 0.5
2020-02-08T02:27:20.906374: step 108, loss 1.59373, acc 0.5
2020-02-08T02:27:21.023539: step 109, loss 1.38256, acc 0.515625
2020-02-08T02:27:21.139828: step 110, loss 1.03093, acc 0.5625
2020-02-08T02:27:21.406377: step 111, loss 1.17428, acc 0.59375
2020-02-08T02:27:21.533362: step 112, loss 1.18196, acc 0.578125
2020-02-08T02:27:21.649321: step 113, loss 1.27749, acc 0.578125
2020-02-08T02:27:21.771501: step 114, loss 1.14251, acc 0.546875
2020-02-08T02:27:21.887986: step 115, loss 1.60183, acc 0.4375
2020-02-08T02:27:22.002397: step 116, loss 1.23853, acc 0.5625
2020-02-08T02:27:22.115609: step 117, loss 1.32786, acc 0.578125
2020-02-08T02:27:22.231793: step 118, loss 1.26122, acc 0.578125
2020-02-08T02:27:22.349458: step 119, loss 1.69933, acc 0.484375
2020-02-08T02:27:22.464270: step 120, loss 1.25211, acc 0.609375
2020-02-08T02:27:22.583075: step 121, loss 1.26905, acc 0.5
2020-02-08T02:27:22.704849: step 122, loss 1.12513, acc 0.546875
2020-02-08T02:27:22.821220: step 123, loss 1.47997, acc 0.5625
2020-02-08T02:27:22.936991: step 124, loss 1.29981, acc 0.53125
2020-02-08T02:27:23.050926: step 125, loss 1.24501, acc 0.53125
2020-02-08T02:27:23.166545: step 126, loss 1.46429, acc 0.46875
2020-02-08T02:27:23.286222: step 127, loss 1.49496, acc 0.53125
2020-02-08T02:27:23.402862: step 128, loss 1.3763, acc 0.53125
2020-02-08T02:27:23.518028: step 129, loss 1.23306, acc 0.53125
2020-02-08T02:27:23.635071: step 130, loss 1.22044, acc 0.546875
2020-02-08T02:27:23.756564: step 131, loss 1.3735, acc 0.640625
2020-02-08T02:27:23.873791: step 132, loss 1.44346, acc 0.53125
2020-02-08T02:27:23.989365: step 133, loss 1.49322, acc 0.578125
2020-02-08T02:27:24.103863: step 134, loss 1.21077, acc 0.59375
2020-02-08T02:27:24.221761: step 135, loss 1.10127, acc 0.546875
2020-02-08T02:27:24.342058: step 136, loss 1.1186, acc 0.609375
2020-02-08T02:27:24.460786: step 137, loss 1.4773, acc 0.5625
2020-02-08T02:27:24.579440: step 138, loss 1.11362, acc 0.578125
2020-02-08T02:27:24.695830: step 139, loss 1.08088, acc 0.609375
2020-02-08T02:27:24.810195: step 140, loss 1.18612, acc 0.546875
2020-02-08T02:27:24.924263: step 141, loss 1.25163, acc 0.59375
2020-02-08T02:27:25.040046: step 142, loss 1.5101, acc 0.453125
2020-02-08T02:27:25.155521: step 143, loss 0.8245, acc 0.640625
2020-02-08T02:27:25.271236: step 144, loss 1.20471, acc 0.46875
2020-02-08T02:27:25.388105: step 145, loss 1.06851, acc 0.578125
2020-02-08T02:27:25.504651: step 146, loss 1.35303, acc 0.515625
2020-02-08T02:27:25.621776: step 147, loss 1.08818, acc 0.578125
2020-02-08T02:27:25.743833: step 148, loss 1.32729, acc 0.5
2020-02-08T02:27:25.859733: step 149, loss 1.13806, acc 0.609375
2020-02-08T02:27:25.974936: step 150, loss 1.04314, acc 0.6
2020-02-08T02:27:26.096505: step 151, loss 0.975074, acc 0.5625
2020-02-08T02:27:26.212779: step 152, loss 1.11216, acc 0.625
2020-02-08T02:27:26.332460: step 153, loss 0.931104, acc 0.625
2020-02-08T02:27:26.448254: step 154, loss 1.08507, acc 0.546875
2020-02-08T02:27:26.562263: step 155, loss 0.768582, acc 0.703125
2020-02-08T02:27:26.681559: step 156, loss 1.12156, acc 0.53125
2020-02-08T02:27:26.800252: step 157, loss 0.857345, acc 0.640625
2020-02-08T02:27:26.918087: step 158, loss 1.08299, acc 0.625
2020-02-08T02:27:27.038817: step 159, loss 1.06726, acc 0.515625
2020-02-08T02:27:27.158073: step 160, loss 1.22382, acc 0.53125
2020-02-08T02:27:27.272176: step 161, loss 0.808565, acc 0.609375
2020-02-08T02:27:27.387087: step 162, loss 0.713205, acc 0.6875
2020-02-08T02:27:27.504302: step 163, loss 0.951253, acc 0.625
2020-02-08T02:27:27.619705: step 164, loss 0.946327, acc 0.578125
2020-02-08T02:27:27.741051: step 165, loss 1.25651, acc 0.515625
2020-02-08T02:27:27.858357: step 166, loss 1.13123, acc 0.59375
2020-02-08T02:27:27.973664: step 167, loss 0.830283, acc 0.609375
2020-02-08T02:27:28.089937: step 168, loss 1.12882, acc 0.640625
2020-02-08T02:27:28.206220: step 169, loss 0.774307, acc 0.609375
2020-02-08T02:27:28.324635: step 170, loss 0.812124, acc 0.734375
2020-02-08T02:27:28.443925: step 171, loss 1.12595, acc 0.640625
2020-02-08T02:27:28.561398: step 172, loss 1.00772, acc 0.578125
2020-02-08T02:27:28.679320: step 173, loss 0.86103, acc 0.640625
2020-02-08T02:27:28.794533: step 174, loss 1.15057, acc 0.640625
2020-02-08T02:27:28.910615: step 175, loss 1.31555, acc 0.5
2020-02-08T02:27:29.025887: step 176, loss 1.03099, acc 0.5625
2020-02-08T02:27:29.143419: step 177, loss 0.856347, acc 0.65625
2020-02-08T02:27:29.259741: step 178, loss 0.917145, acc 0.609375
2020-02-08T02:27:29.378584: step 179, loss 0.862334, acc 0.671875
2020-02-08T02:27:29.496545: step 180, loss 1.07837, acc 0.59375
2020-02-08T02:27:29.612455: step 181, loss 0.822977, acc 0.6875
2020-02-08T02:27:29.732437: step 182, loss 0.922132, acc 0.65625
2020-02-08T02:27:29.847646: step 183, loss 0.805541, acc 0.671875
2020-02-08T02:27:29.962514: step 184, loss 1.01073, acc 0.5625
2020-02-08T02:27:30.079525: step 185, loss 0.79982, acc 0.640625
2020-02-08T02:27:30.196518: step 186, loss 1.06319, acc 0.546875
2020-02-08T02:27:30.312924: step 187, loss 0.676643, acc 0.609375
2020-02-08T02:27:30.429823: step 188, loss 0.960672, acc 0.578125
2020-02-08T02:27:30.546110: step 189, loss 0.942236, acc 0.59375
2020-02-08T02:27:30.664231: step 190, loss 1.01215, acc 0.609375
2020-02-08T02:27:30.786192: step 191, loss 0.970373, acc 0.609375
2020-02-08T02:27:30.903925: step 192, loss 0.730868, acc 0.6875
2020-02-08T02:27:31.023864: step 193, loss 1.10648, acc 0.578125
2020-02-08T02:27:31.144311: step 194, loss 0.683182, acc 0.625
2020-02-08T02:27:31.261928: step 195, loss 0.926955, acc 0.625
2020-02-08T02:27:31.378558: step 196, loss 1.02084, acc 0.625
2020-02-08T02:27:31.498194: step 197, loss 1.19216, acc 0.546875
2020-02-08T02:27:31.613663: step 198, loss 0.971343, acc 0.578125
2020-02-08T02:27:31.735208: step 199, loss 0.740321, acc 0.65625
2020-02-08T02:27:31.850514: step 200, loss 1.03993, acc 0.578125

Evaluation:
2020-02-08T02:27:32.041455: step 200, loss 0.700038, acc 0.595685

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-200

2020-02-08T02:27:34.024105: step 201, loss 0.756024, acc 0.625
2020-02-08T02:27:34.143233: step 202, loss 0.662716, acc 0.703125
2020-02-08T02:27:34.260614: step 203, loss 1.04883, acc 0.515625
2020-02-08T02:27:34.380860: step 204, loss 1.04532, acc 0.53125
2020-02-08T02:27:34.500951: step 205, loss 1.02498, acc 0.5625
2020-02-08T02:27:34.623104: step 206, loss 0.861005, acc 0.671875
2020-02-08T02:27:34.744170: step 207, loss 0.675003, acc 0.640625
2020-02-08T02:27:34.860219: step 208, loss 0.705709, acc 0.71875
2020-02-08T02:27:34.978486: step 209, loss 0.929893, acc 0.578125
2020-02-08T02:27:35.095653: step 210, loss 0.827403, acc 0.578125
2020-02-08T02:27:35.211319: step 211, loss 1.01856, acc 0.53125
2020-02-08T02:27:35.328886: step 212, loss 0.820736, acc 0.734375
2020-02-08T02:27:35.446044: step 213, loss 0.882241, acc 0.578125
2020-02-08T02:27:35.561733: step 214, loss 0.916247, acc 0.5625
2020-02-08T02:27:35.680271: step 215, loss 0.635754, acc 0.671875
2020-02-08T02:27:35.798217: step 216, loss 0.775383, acc 0.65625
2020-02-08T02:27:35.915738: step 217, loss 0.979179, acc 0.578125
2020-02-08T02:27:36.035216: step 218, loss 0.937949, acc 0.578125
2020-02-08T02:27:36.150827: step 219, loss 1.12057, acc 0.515625
2020-02-08T02:27:36.266615: step 220, loss 1.10791, acc 0.53125
2020-02-08T02:27:36.383207: step 221, loss 0.844883, acc 0.65625
2020-02-08T02:27:36.500550: step 222, loss 0.91272, acc 0.609375
2020-02-08T02:27:36.617452: step 223, loss 0.995319, acc 0.671875
2020-02-08T02:27:36.742718: step 224, loss 0.799021, acc 0.65625
2020-02-08T02:27:36.858696: step 225, loss 0.893761, acc 0.59375
2020-02-08T02:27:36.975430: step 226, loss 0.797551, acc 0.640625
2020-02-08T02:27:37.094732: step 227, loss 0.816164, acc 0.671875
2020-02-08T02:27:37.213350: step 228, loss 0.953348, acc 0.578125
2020-02-08T02:27:37.331504: step 229, loss 0.730811, acc 0.6875
2020-02-08T02:27:37.448836: step 230, loss 0.636322, acc 0.65625
2020-02-08T02:27:37.567433: step 231, loss 1.04927, acc 0.546875
2020-02-08T02:27:37.686017: step 232, loss 1.00455, acc 0.515625
2020-02-08T02:27:37.802641: step 233, loss 0.880029, acc 0.625
2020-02-08T02:27:37.919636: step 234, loss 0.819696, acc 0.625
2020-02-08T02:27:38.037644: step 235, loss 0.988111, acc 0.59375
2020-02-08T02:27:38.154731: step 236, loss 0.748986, acc 0.640625
2020-02-08T02:27:38.272291: step 237, loss 1.04464, acc 0.5625
2020-02-08T02:27:38.391361: step 238, loss 0.7387, acc 0.59375
2020-02-08T02:27:38.507750: step 239, loss 0.956395, acc 0.5625
2020-02-08T02:27:38.624187: step 240, loss 0.753927, acc 0.65625
2020-02-08T02:27:38.747115: step 241, loss 1.01373, acc 0.53125
2020-02-08T02:27:38.863785: step 242, loss 0.781642, acc 0.625
2020-02-08T02:27:38.981782: step 243, loss 0.866591, acc 0.625
2020-02-08T02:27:39.099799: step 244, loss 0.844885, acc 0.609375
2020-02-08T02:27:39.217745: step 245, loss 0.710671, acc 0.59375
2020-02-08T02:27:39.335036: step 246, loss 0.627064, acc 0.71875
2020-02-08T02:27:39.451316: step 247, loss 0.712663, acc 0.765625
2020-02-08T02:27:39.568582: step 248, loss 0.620558, acc 0.75
2020-02-08T02:27:39.690710: step 249, loss 0.842388, acc 0.578125
2020-02-08T02:27:39.806104: step 250, loss 0.827356, acc 0.609375
2020-02-08T02:27:39.922654: step 251, loss 0.820016, acc 0.703125
2020-02-08T02:27:40.039323: step 252, loss 0.658092, acc 0.671875
2020-02-08T02:27:40.155546: step 253, loss 0.983271, acc 0.515625
2020-02-08T02:27:40.271960: step 254, loss 0.952412, acc 0.578125
2020-02-08T02:27:40.392520: step 255, loss 0.753001, acc 0.625
2020-02-08T02:27:40.509764: step 256, loss 0.762025, acc 0.65625
2020-02-08T02:27:40.626809: step 257, loss 1.00566, acc 0.546875
2020-02-08T02:27:40.749160: step 258, loss 1.074, acc 0.4375
2020-02-08T02:27:40.862792: step 259, loss 0.848971, acc 0.578125
2020-02-08T02:27:40.979720: step 260, loss 0.829997, acc 0.640625
2020-02-08T02:27:41.097062: step 261, loss 0.990427, acc 0.5
2020-02-08T02:27:41.213949: step 262, loss 0.985382, acc 0.546875
2020-02-08T02:27:41.332953: step 263, loss 0.683209, acc 0.6875
2020-02-08T02:27:41.451704: step 264, loss 0.861123, acc 0.578125
2020-02-08T02:27:41.570427: step 265, loss 0.80409, acc 0.578125
2020-02-08T02:27:41.688214: step 266, loss 0.804841, acc 0.578125
2020-02-08T02:27:41.803387: step 267, loss 0.995087, acc 0.578125
2020-02-08T02:27:41.920650: step 268, loss 0.715068, acc 0.6875
2020-02-08T02:27:42.038178: step 269, loss 0.746521, acc 0.640625
2020-02-08T02:27:42.153716: step 270, loss 0.549128, acc 0.734375
2020-02-08T02:27:42.269312: step 271, loss 0.80502, acc 0.609375
2020-02-08T02:27:42.383998: step 272, loss 1.04628, acc 0.484375
2020-02-08T02:27:42.497637: step 273, loss 0.999625, acc 0.5625
2020-02-08T02:27:42.614934: step 274, loss 0.596943, acc 0.671875
2020-02-08T02:27:42.735631: step 275, loss 0.836364, acc 0.609375
2020-02-08T02:27:42.850294: step 276, loss 0.493519, acc 0.78125
2020-02-08T02:27:42.965696: step 277, loss 0.839599, acc 0.640625
2020-02-08T02:27:43.083630: step 278, loss 0.676783, acc 0.71875
2020-02-08T02:27:43.202559: step 279, loss 0.914298, acc 0.53125
2020-02-08T02:27:43.318145: step 280, loss 0.619474, acc 0.75
2020-02-08T02:27:43.434905: step 281, loss 0.75214, acc 0.671875
2020-02-08T02:27:43.550875: step 282, loss 0.773515, acc 0.59375
2020-02-08T02:27:43.668182: step 283, loss 0.568539, acc 0.703125
2020-02-08T02:27:43.790289: step 284, loss 1.05416, acc 0.5
2020-02-08T02:27:43.906477: step 285, loss 0.740446, acc 0.625
2020-02-08T02:27:44.024751: step 286, loss 1.02511, acc 0.59375
2020-02-08T02:27:44.142800: step 287, loss 0.818725, acc 0.6875
2020-02-08T02:27:44.258351: step 288, loss 1.16004, acc 0.5
2020-02-08T02:27:44.378338: step 289, loss 0.740931, acc 0.59375
2020-02-08T02:27:44.494985: step 290, loss 0.705799, acc 0.703125
2020-02-08T02:27:44.612518: step 291, loss 0.747113, acc 0.671875
2020-02-08T02:27:44.734756: step 292, loss 0.994352, acc 0.578125
2020-02-08T02:27:44.854032: step 293, loss 0.802992, acc 0.5625
2020-02-08T02:27:44.970948: step 294, loss 0.829779, acc 0.65625
2020-02-08T02:27:45.090322: step 295, loss 0.752498, acc 0.671875
2020-02-08T02:27:45.211812: step 296, loss 1.05042, acc 0.515625
2020-02-08T02:27:45.330213: step 297, loss 0.903831, acc 0.578125
2020-02-08T02:27:45.447824: step 298, loss 0.714627, acc 0.765625
2020-02-08T02:27:45.565004: step 299, loss 0.947673, acc 0.546875
2020-02-08T02:27:45.679919: step 300, loss 1.1257, acc 0.55

Evaluation:
2020-02-08T02:27:45.869428: step 300, loss 0.645584, acc 0.633208

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-300

2020-02-08T02:27:47.352587: step 301, loss 0.624926, acc 0.703125
2020-02-08T02:27:47.472729: step 302, loss 0.685067, acc 0.6875
2020-02-08T02:27:47.590379: step 303, loss 0.616793, acc 0.75
2020-02-08T02:27:47.710921: step 304, loss 0.681854, acc 0.671875
2020-02-08T02:27:47.826356: step 305, loss 0.829363, acc 0.65625
2020-02-08T02:27:47.942842: step 306, loss 0.560265, acc 0.703125
2020-02-08T02:27:48.057808: step 307, loss 0.925203, acc 0.609375
2020-02-08T02:27:48.174944: step 308, loss 0.718713, acc 0.671875
2020-02-08T02:27:48.292274: step 309, loss 0.582422, acc 0.71875
2020-02-08T02:27:48.405841: step 310, loss 1.04677, acc 0.484375
2020-02-08T02:27:48.523832: step 311, loss 0.70498, acc 0.65625
2020-02-08T02:27:48.639550: step 312, loss 0.862994, acc 0.609375
2020-02-08T02:27:48.761882: step 313, loss 0.799501, acc 0.671875
2020-02-08T02:27:48.880065: step 314, loss 0.672373, acc 0.65625
2020-02-08T02:27:48.998124: step 315, loss 0.746659, acc 0.6875
2020-02-08T02:27:49.118270: step 316, loss 0.677348, acc 0.65625
2020-02-08T02:27:49.239736: step 317, loss 0.810073, acc 0.625
2020-02-08T02:27:49.356774: step 318, loss 0.707117, acc 0.625
2020-02-08T02:27:49.472970: step 319, loss 0.597012, acc 0.71875
2020-02-08T02:27:49.589667: step 320, loss 0.663944, acc 0.734375
2020-02-08T02:27:49.710148: step 321, loss 0.740705, acc 0.65625
2020-02-08T02:27:49.826884: step 322, loss 0.667886, acc 0.6875
2020-02-08T02:27:49.943273: step 323, loss 0.766811, acc 0.65625
2020-02-08T02:27:50.061723: step 324, loss 0.612093, acc 0.703125
2020-02-08T02:27:50.180033: step 325, loss 0.643818, acc 0.71875
2020-02-08T02:27:50.297505: step 326, loss 0.543876, acc 0.6875
2020-02-08T02:27:50.413853: step 327, loss 0.592776, acc 0.65625
2020-02-08T02:27:50.530493: step 328, loss 0.71282, acc 0.625
2020-02-08T02:27:50.647803: step 329, loss 0.717115, acc 0.609375
2020-02-08T02:27:50.770343: step 330, loss 0.574138, acc 0.703125
2020-02-08T02:27:50.889794: step 331, loss 0.684417, acc 0.71875
2020-02-08T02:27:51.005024: step 332, loss 0.61747, acc 0.734375
2020-02-08T02:27:51.121543: step 333, loss 0.777654, acc 0.578125
2020-02-08T02:27:51.237546: step 334, loss 0.552123, acc 0.6875
2020-02-08T02:27:51.353571: step 335, loss 0.688258, acc 0.703125
2020-02-08T02:27:51.487400: step 336, loss 0.724703, acc 0.640625
2020-02-08T02:27:51.603015: step 337, loss 0.556296, acc 0.703125
2020-02-08T02:27:51.724760: step 338, loss 0.744091, acc 0.609375
2020-02-08T02:27:51.841398: step 339, loss 0.733647, acc 0.609375
2020-02-08T02:27:51.958407: step 340, loss 0.611857, acc 0.734375
2020-02-08T02:27:52.075969: step 341, loss 0.764577, acc 0.6875
2020-02-08T02:27:52.194776: step 342, loss 0.526159, acc 0.71875
2020-02-08T02:27:52.311040: step 343, loss 0.659057, acc 0.625
2020-02-08T02:27:52.429816: step 344, loss 0.53906, acc 0.78125
2020-02-08T02:27:52.548966: step 345, loss 0.628901, acc 0.625
2020-02-08T02:27:52.669211: step 346, loss 0.77331, acc 0.578125
2020-02-08T02:27:52.790168: step 347, loss 0.90191, acc 0.484375
2020-02-08T02:27:52.908015: step 348, loss 0.770016, acc 0.640625
2020-02-08T02:27:53.024703: step 349, loss 0.604781, acc 0.6875
2020-02-08T02:27:53.148006: step 350, loss 0.631697, acc 0.6875
2020-02-08T02:27:53.266221: step 351, loss 0.496831, acc 0.734375
2020-02-08T02:27:53.383401: step 352, loss 0.672596, acc 0.640625
2020-02-08T02:27:53.499824: step 353, loss 0.522988, acc 0.78125
2020-02-08T02:27:53.616334: step 354, loss 0.606353, acc 0.640625
2020-02-08T02:27:53.741743: step 355, loss 0.678338, acc 0.6875
2020-02-08T02:27:53.858961: step 356, loss 0.722466, acc 0.546875
2020-02-08T02:27:53.978259: step 357, loss 0.580578, acc 0.671875
2020-02-08T02:27:54.096245: step 358, loss 0.520697, acc 0.75
2020-02-08T02:27:54.210927: step 359, loss 0.672961, acc 0.625
2020-02-08T02:27:54.327573: step 360, loss 0.611471, acc 0.703125
2020-02-08T02:27:54.446759: step 361, loss 0.821912, acc 0.59375
2020-02-08T02:27:54.563358: step 362, loss 0.806677, acc 0.671875
2020-02-08T02:27:54.682953: step 363, loss 0.689046, acc 0.71875
2020-02-08T02:27:54.798097: step 364, loss 0.676405, acc 0.703125
2020-02-08T02:27:54.915673: step 365, loss 0.600105, acc 0.6875
2020-02-08T02:27:55.031934: step 366, loss 0.593298, acc 0.671875
2020-02-08T02:27:55.147781: step 367, loss 0.616076, acc 0.6875
2020-02-08T02:27:55.265366: step 368, loss 0.580805, acc 0.640625
2020-02-08T02:27:55.382521: step 369, loss 0.642642, acc 0.75
2020-02-08T02:27:55.500859: step 370, loss 0.542572, acc 0.8125
2020-02-08T02:27:55.617613: step 371, loss 0.904214, acc 0.53125
2020-02-08T02:27:55.738082: step 372, loss 0.632766, acc 0.6875
2020-02-08T02:27:55.853841: step 373, loss 0.520959, acc 0.71875
2020-02-08T02:27:55.971750: step 374, loss 0.585499, acc 0.71875
2020-02-08T02:27:56.089432: step 375, loss 0.555696, acc 0.703125
2020-02-08T02:27:56.208824: step 376, loss 0.597777, acc 0.640625
2020-02-08T02:27:56.325075: step 377, loss 0.59737, acc 0.640625
2020-02-08T02:27:56.442981: step 378, loss 0.647906, acc 0.6875
2020-02-08T02:27:56.559863: step 379, loss 0.713774, acc 0.65625
2020-02-08T02:27:56.677712: step 380, loss 0.657786, acc 0.625
2020-02-08T02:27:56.797231: step 381, loss 0.538115, acc 0.765625
2020-02-08T02:27:56.912929: step 382, loss 0.718306, acc 0.625
2020-02-08T02:27:57.029647: step 383, loss 0.718893, acc 0.640625
2020-02-08T02:27:57.145964: step 384, loss 0.674725, acc 0.578125
2020-02-08T02:27:57.263301: step 385, loss 0.687084, acc 0.625
2020-02-08T02:27:57.381892: step 386, loss 0.595995, acc 0.734375
2020-02-08T02:27:57.497684: step 387, loss 0.736437, acc 0.609375
2020-02-08T02:27:57.614294: step 388, loss 0.689231, acc 0.640625
2020-02-08T02:27:57.737162: step 389, loss 0.758742, acc 0.609375
2020-02-08T02:27:57.854201: step 390, loss 0.570035, acc 0.640625
2020-02-08T02:27:57.972865: step 391, loss 0.554727, acc 0.71875
2020-02-08T02:27:58.095136: step 392, loss 0.763568, acc 0.71875
2020-02-08T02:27:58.210419: step 393, loss 0.657865, acc 0.640625
2020-02-08T02:27:58.334481: step 394, loss 0.704927, acc 0.65625
2020-02-08T02:27:58.450724: step 395, loss 0.657641, acc 0.640625
2020-02-08T02:27:58.568880: step 396, loss 0.562431, acc 0.671875
2020-02-08T02:27:58.690451: step 397, loss 0.585802, acc 0.71875
2020-02-08T02:27:58.806857: step 398, loss 0.5513, acc 0.75
2020-02-08T02:27:58.924453: step 399, loss 0.548492, acc 0.71875
2020-02-08T02:27:59.044776: step 400, loss 0.550809, acc 0.6875

Evaluation:
2020-02-08T02:27:59.234816: step 400, loss 0.673048, acc 0.599437

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-400

2020-02-08T02:28:01.543490: step 401, loss 0.793586, acc 0.59375
2020-02-08T02:28:01.657899: step 402, loss 0.688319, acc 0.65625
2020-02-08T02:28:01.779669: step 403, loss 0.717659, acc 0.625
2020-02-08T02:28:01.896229: step 404, loss 0.6999, acc 0.625
2020-02-08T02:28:02.011618: step 405, loss 0.733942, acc 0.65625
2020-02-08T02:28:02.128604: step 406, loss 0.620421, acc 0.609375
2020-02-08T02:28:02.246705: step 407, loss 0.637945, acc 0.703125
2020-02-08T02:28:02.364241: step 408, loss 0.67948, acc 0.640625
2020-02-08T02:28:02.480124: step 409, loss 0.636129, acc 0.703125
2020-02-08T02:28:02.597937: step 410, loss 0.744624, acc 0.609375
2020-02-08T02:28:02.718312: step 411, loss 0.949374, acc 0.5
2020-02-08T02:28:02.837006: step 412, loss 0.577266, acc 0.71875
2020-02-08T02:28:02.952592: step 413, loss 0.482435, acc 0.71875
2020-02-08T02:28:03.071184: step 414, loss 0.509621, acc 0.75
2020-02-08T02:28:03.190006: step 415, loss 0.637286, acc 0.640625
2020-02-08T02:28:03.305727: step 416, loss 0.763034, acc 0.5625
2020-02-08T02:28:03.426097: step 417, loss 0.451187, acc 0.765625
2020-02-08T02:28:03.544539: step 418, loss 0.587303, acc 0.703125
2020-02-08T02:28:03.660411: step 419, loss 0.731098, acc 0.609375
2020-02-08T02:28:03.785328: step 420, loss 0.605204, acc 0.671875
2020-02-08T02:28:03.902523: step 421, loss 0.707869, acc 0.65625
2020-02-08T02:28:04.025727: step 422, loss 0.566645, acc 0.703125
2020-02-08T02:28:04.144279: step 423, loss 0.767268, acc 0.59375
2020-02-08T02:28:04.260860: step 424, loss 0.52214, acc 0.734375
2020-02-08T02:28:04.378163: step 425, loss 0.695681, acc 0.609375
2020-02-08T02:28:04.496243: step 426, loss 0.606721, acc 0.734375
2020-02-08T02:28:04.617430: step 427, loss 0.586722, acc 0.671875
2020-02-08T02:28:04.741402: step 428, loss 0.627131, acc 0.65625
2020-02-08T02:28:04.856259: step 429, loss 0.656736, acc 0.6875
2020-02-08T02:28:04.975233: step 430, loss 0.648353, acc 0.609375
2020-02-08T02:28:05.091833: step 431, loss 0.654135, acc 0.6875
2020-02-08T02:28:05.208580: step 432, loss 0.571293, acc 0.75
2020-02-08T02:28:05.326205: step 433, loss 0.657738, acc 0.671875
2020-02-08T02:28:05.444806: step 434, loss 0.608931, acc 0.6875
2020-02-08T02:28:05.560657: step 435, loss 0.66558, acc 0.671875
2020-02-08T02:28:05.682260: step 436, loss 0.657803, acc 0.703125
2020-02-08T02:28:05.798952: step 437, loss 0.743916, acc 0.625
2020-02-08T02:28:05.913642: step 438, loss 0.664291, acc 0.6875
2020-02-08T02:28:06.034117: step 439, loss 0.590672, acc 0.6875
2020-02-08T02:28:06.152264: step 440, loss 0.645682, acc 0.671875
2020-02-08T02:28:06.267229: step 441, loss 0.654208, acc 0.65625
2020-02-08T02:28:06.383998: step 442, loss 0.605333, acc 0.609375
2020-02-08T02:28:06.500398: step 443, loss 0.616137, acc 0.6875
2020-02-08T02:28:06.616969: step 444, loss 0.626866, acc 0.671875
2020-02-08T02:28:06.740005: step 445, loss 0.601185, acc 0.71875
2020-02-08T02:28:06.856917: step 446, loss 0.88531, acc 0.609375
2020-02-08T02:28:06.975279: step 447, loss 0.790179, acc 0.5625
2020-02-08T02:28:07.091878: step 448, loss 0.52274, acc 0.6875
2020-02-08T02:28:07.210509: step 449, loss 0.703699, acc 0.625
2020-02-08T02:28:07.323549: step 450, loss 0.600402, acc 0.666667
2020-02-08T02:28:07.450317: step 451, loss 0.761833, acc 0.640625
2020-02-08T02:28:07.563736: step 452, loss 0.588319, acc 0.703125
2020-02-08T02:28:07.684098: step 453, loss 0.636908, acc 0.671875
2020-02-08T02:28:07.801691: step 454, loss 0.511448, acc 0.75
2020-02-08T02:28:07.918940: step 455, loss 0.58164, acc 0.6875
2020-02-08T02:28:08.038409: step 456, loss 0.615496, acc 0.71875
2020-02-08T02:28:08.155729: step 457, loss 0.597532, acc 0.71875
2020-02-08T02:28:08.274213: step 458, loss 0.549748, acc 0.75
2020-02-08T02:28:08.393400: step 459, loss 0.621981, acc 0.734375
2020-02-08T02:28:08.508437: step 460, loss 0.527707, acc 0.734375
2020-02-08T02:28:08.627030: step 461, loss 0.546052, acc 0.75
2020-02-08T02:28:08.750598: step 462, loss 0.535414, acc 0.671875
2020-02-08T02:28:08.872043: step 463, loss 0.384788, acc 0.875
2020-02-08T02:28:08.992604: step 464, loss 0.555153, acc 0.6875
2020-02-08T02:28:09.110834: step 465, loss 0.568094, acc 0.734375
2020-02-08T02:28:09.235191: step 466, loss 0.550635, acc 0.71875
2020-02-08T02:28:09.352648: step 467, loss 0.645794, acc 0.640625
2020-02-08T02:28:09.469766: step 468, loss 0.553554, acc 0.6875
2020-02-08T02:28:09.591221: step 469, loss 0.465224, acc 0.765625
2020-02-08T02:28:09.709046: step 470, loss 0.475872, acc 0.78125
2020-02-08T02:28:09.829507: step 471, loss 0.525532, acc 0.703125
2020-02-08T02:28:09.948435: step 472, loss 0.629224, acc 0.65625
2020-02-08T02:28:10.067451: step 473, loss 0.785497, acc 0.5625
2020-02-08T02:28:10.185902: step 474, loss 0.593616, acc 0.734375
2020-02-08T02:28:10.300530: step 475, loss 0.570597, acc 0.65625
2020-02-08T02:28:10.417589: step 476, loss 0.617312, acc 0.734375
2020-02-08T02:28:10.535938: step 477, loss 0.514693, acc 0.734375
2020-02-08T02:28:10.652566: step 478, loss 0.557755, acc 0.765625
2020-02-08T02:28:10.773650: step 479, loss 0.464304, acc 0.828125
2020-02-08T02:28:10.894351: step 480, loss 0.478657, acc 0.796875
2020-02-08T02:28:11.009665: step 481, loss 0.567335, acc 0.734375
2020-02-08T02:28:11.126877: step 482, loss 0.563197, acc 0.75
2020-02-08T02:28:11.246453: step 483, loss 0.485671, acc 0.796875
2020-02-08T02:28:11.365103: step 484, loss 0.618196, acc 0.703125
2020-02-08T02:28:11.481996: step 485, loss 0.577518, acc 0.765625
2020-02-08T02:28:11.601747: step 486, loss 0.624814, acc 0.609375
2020-02-08T02:28:11.724753: step 487, loss 0.426965, acc 0.8125
2020-02-08T02:28:11.843765: step 488, loss 0.505302, acc 0.75
2020-02-08T02:28:11.962155: step 489, loss 0.610198, acc 0.625
2020-02-08T02:28:12.080083: step 490, loss 0.596574, acc 0.640625
2020-02-08T02:28:12.200195: step 491, loss 0.525935, acc 0.6875
2020-02-08T02:28:12.313448: step 492, loss 0.514681, acc 0.71875
2020-02-08T02:28:12.431661: step 493, loss 0.55359, acc 0.75
2020-02-08T02:28:12.548883: step 494, loss 0.660617, acc 0.671875
2020-02-08T02:28:12.664933: step 495, loss 0.616505, acc 0.703125
2020-02-08T02:28:12.786935: step 496, loss 0.494665, acc 0.78125
2020-02-08T02:28:12.902161: step 497, loss 0.447255, acc 0.78125
2020-02-08T02:28:13.019247: step 498, loss 0.468876, acc 0.796875
2020-02-08T02:28:13.135668: step 499, loss 0.651377, acc 0.71875
2020-02-08T02:28:13.251613: step 500, loss 0.533799, acc 0.734375

Evaluation:
2020-02-08T02:28:13.439479: step 500, loss 0.614899, acc 0.652908

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-500

2020-02-08T02:28:15.522504: step 501, loss 0.584653, acc 0.6875
2020-02-08T02:28:15.640208: step 502, loss 0.586513, acc 0.734375
2020-02-08T02:28:15.765501: step 503, loss 0.505507, acc 0.734375
2020-02-08T02:28:15.884802: step 504, loss 0.532554, acc 0.734375
2020-02-08T02:28:16.001767: step 505, loss 0.596986, acc 0.65625
2020-02-08T02:28:16.118105: step 506, loss 0.652147, acc 0.6875
2020-02-08T02:28:16.236572: step 507, loss 0.523375, acc 0.765625
2020-02-08T02:28:16.355078: step 508, loss 0.571583, acc 0.6875
2020-02-08T02:28:16.472164: step 509, loss 0.690911, acc 0.65625
2020-02-08T02:28:16.592404: step 510, loss 0.547475, acc 0.734375
2020-02-08T02:28:16.710972: step 511, loss 0.55169, acc 0.765625
2020-02-08T02:28:16.829523: step 512, loss 0.507052, acc 0.734375
2020-02-08T02:28:16.949473: step 513, loss 0.574322, acc 0.734375
2020-02-08T02:28:17.063919: step 514, loss 0.608515, acc 0.625
2020-02-08T02:28:17.181021: step 515, loss 0.473795, acc 0.78125
2020-02-08T02:28:17.296747: step 516, loss 0.435073, acc 0.84375
2020-02-08T02:28:17.412217: step 517, loss 0.54324, acc 0.671875
2020-02-08T02:28:17.529448: step 518, loss 0.659497, acc 0.65625
2020-02-08T02:28:17.645883: step 519, loss 0.640118, acc 0.71875
2020-02-08T02:28:17.764930: step 520, loss 0.769673, acc 0.59375
2020-02-08T02:28:17.884497: step 521, loss 0.531177, acc 0.75
2020-02-08T02:28:17.999533: step 522, loss 0.617556, acc 0.671875
2020-02-08T02:28:18.116714: step 523, loss 0.456455, acc 0.78125
2020-02-08T02:28:18.234586: step 524, loss 0.564545, acc 0.71875
2020-02-08T02:28:18.350616: step 525, loss 0.605309, acc 0.6875
2020-02-08T02:28:18.468163: step 526, loss 0.593959, acc 0.71875
2020-02-08T02:28:18.590962: step 527, loss 0.475304, acc 0.8125
2020-02-08T02:28:18.706600: step 528, loss 0.734062, acc 0.59375
2020-02-08T02:28:18.826557: step 529, loss 0.495446, acc 0.75
2020-02-08T02:28:18.942877: step 530, loss 0.545099, acc 0.703125
2020-02-08T02:28:19.056538: step 531, loss 0.577493, acc 0.6875
2020-02-08T02:28:19.172740: step 532, loss 0.492227, acc 0.765625
2020-02-08T02:28:19.287797: step 533, loss 0.630635, acc 0.71875
2020-02-08T02:28:19.402708: step 534, loss 0.512417, acc 0.78125
2020-02-08T02:28:19.517059: step 535, loss 0.424815, acc 0.8125
2020-02-08T02:28:19.633897: step 536, loss 0.66801, acc 0.671875
2020-02-08T02:28:19.755077: step 537, loss 0.382365, acc 0.828125
2020-02-08T02:28:19.874866: step 538, loss 0.518275, acc 0.78125
2020-02-08T02:28:19.995639: step 539, loss 0.576767, acc 0.734375
2020-02-08T02:28:20.111052: step 540, loss 0.513061, acc 0.78125
2020-02-08T02:28:20.237733: step 541, loss 0.606798, acc 0.6875
2020-02-08T02:28:20.354478: step 542, loss 0.524065, acc 0.75
2020-02-08T02:28:20.473753: step 543, loss 0.58664, acc 0.6875
2020-02-08T02:28:20.590953: step 544, loss 0.523306, acc 0.71875
2020-02-08T02:28:20.707793: step 545, loss 0.500121, acc 0.75
2020-02-08T02:28:20.827738: step 546, loss 0.680687, acc 0.609375
2020-02-08T02:28:20.946410: step 547, loss 0.607348, acc 0.640625
2020-02-08T02:28:21.059226: step 548, loss 0.530599, acc 0.765625
2020-02-08T02:28:21.177950: step 549, loss 0.545022, acc 0.6875
2020-02-08T02:28:21.295954: step 550, loss 0.502941, acc 0.71875
2020-02-08T02:28:21.556393: step 551, loss 0.523333, acc 0.765625
2020-02-08T02:28:21.675844: step 552, loss 0.588442, acc 0.625
2020-02-08T02:28:21.792442: step 553, loss 0.633032, acc 0.734375
2020-02-08T02:28:21.905761: step 554, loss 0.55496, acc 0.71875
2020-02-08T02:28:22.022598: step 555, loss 0.482322, acc 0.765625
2020-02-08T02:28:22.143516: step 556, loss 0.596375, acc 0.75
2020-02-08T02:28:22.259427: step 557, loss 0.500559, acc 0.75
2020-02-08T02:28:22.377116: step 558, loss 0.542508, acc 0.796875
2020-02-08T02:28:22.498536: step 559, loss 0.468019, acc 0.71875
2020-02-08T02:28:22.614602: step 560, loss 0.482676, acc 0.734375
2020-02-08T02:28:22.735651: step 561, loss 0.500321, acc 0.78125
2020-02-08T02:28:22.853260: step 562, loss 0.504111, acc 0.8125
2020-02-08T02:28:22.970225: step 563, loss 0.523382, acc 0.734375
2020-02-08T02:28:23.089101: step 564, loss 0.455286, acc 0.828125
2020-02-08T02:28:23.208341: step 565, loss 0.435526, acc 0.8125
2020-02-08T02:28:23.327004: step 566, loss 0.560188, acc 0.75
2020-02-08T02:28:23.445825: step 567, loss 0.560077, acc 0.75
2020-02-08T02:28:23.565289: step 568, loss 0.590215, acc 0.71875
2020-02-08T02:28:23.683133: step 569, loss 0.454793, acc 0.8125
2020-02-08T02:28:23.802500: step 570, loss 0.57238, acc 0.671875
2020-02-08T02:28:23.919471: step 571, loss 0.594184, acc 0.71875
2020-02-08T02:28:24.038702: step 572, loss 0.519996, acc 0.75
2020-02-08T02:28:24.154089: step 573, loss 0.500193, acc 0.75
2020-02-08T02:28:24.266965: step 574, loss 0.543794, acc 0.703125
2020-02-08T02:28:24.384658: step 575, loss 0.558756, acc 0.6875
2020-02-08T02:28:24.500604: step 576, loss 0.47102, acc 0.78125
2020-02-08T02:28:24.615055: step 577, loss 0.564453, acc 0.734375
2020-02-08T02:28:24.738978: step 578, loss 0.659496, acc 0.6875
2020-02-08T02:28:24.856303: step 579, loss 0.469177, acc 0.796875
2020-02-08T02:28:24.972426: step 580, loss 0.730789, acc 0.640625
2020-02-08T02:28:25.088586: step 581, loss 0.522119, acc 0.75
2020-02-08T02:28:25.204674: step 582, loss 0.604924, acc 0.671875
2020-02-08T02:28:25.322586: step 583, loss 0.495225, acc 0.75
2020-02-08T02:28:25.441227: step 584, loss 0.492302, acc 0.765625
2020-02-08T02:28:25.555700: step 585, loss 0.54394, acc 0.6875
2020-02-08T02:28:25.675181: step 586, loss 0.431612, acc 0.84375
2020-02-08T02:28:25.793097: step 587, loss 0.463996, acc 0.84375
2020-02-08T02:28:25.907019: step 588, loss 0.503197, acc 0.765625
2020-02-08T02:28:26.023785: step 589, loss 0.562414, acc 0.71875
2020-02-08T02:28:26.139232: step 590, loss 0.56158, acc 0.703125
2020-02-08T02:28:26.256858: step 591, loss 0.638046, acc 0.671875
2020-02-08T02:28:26.375198: step 592, loss 0.451702, acc 0.8125
2020-02-08T02:28:26.493919: step 593, loss 0.569292, acc 0.734375
2020-02-08T02:28:26.609072: step 594, loss 0.489113, acc 0.78125
2020-02-08T02:28:26.732540: step 595, loss 0.54837, acc 0.71875
2020-02-08T02:28:26.851724: step 596, loss 0.638861, acc 0.640625
2020-02-08T02:28:26.966667: step 597, loss 0.482936, acc 0.734375
2020-02-08T02:28:27.085244: step 598, loss 0.446355, acc 0.75
2020-02-08T02:28:27.204258: step 599, loss 0.63257, acc 0.6875
2020-02-08T02:28:27.317080: step 600, loss 0.546911, acc 0.7

Evaluation:
2020-02-08T02:28:27.507823: step 600, loss 0.613013, acc 0.659475

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-600

2020-02-08T02:28:28.997961: step 601, loss 0.511881, acc 0.75
2020-02-08T02:28:29.114285: step 602, loss 0.548244, acc 0.703125
2020-02-08T02:28:29.234289: step 603, loss 0.424494, acc 0.796875
2020-02-08T02:28:29.350962: step 604, loss 0.535767, acc 0.703125
2020-02-08T02:28:29.466819: step 605, loss 0.478924, acc 0.765625
2020-02-08T02:28:29.583449: step 606, loss 0.582988, acc 0.703125
2020-02-08T02:28:29.701412: step 607, loss 0.496084, acc 0.75
2020-02-08T02:28:29.819671: step 608, loss 0.432193, acc 0.828125
2020-02-08T02:28:29.938314: step 609, loss 0.450217, acc 0.796875
2020-02-08T02:28:30.055879: step 610, loss 0.401231, acc 0.8125
2020-02-08T02:28:30.172971: step 611, loss 0.473835, acc 0.765625
2020-02-08T02:28:30.293893: step 612, loss 0.450624, acc 0.828125
2020-02-08T02:28:30.410546: step 613, loss 0.399884, acc 0.84375
2020-02-08T02:28:30.530679: step 614, loss 0.429789, acc 0.765625
2020-02-08T02:28:30.647428: step 615, loss 0.545433, acc 0.6875
2020-02-08T02:28:30.765177: step 616, loss 0.546974, acc 0.734375
2020-02-08T02:28:30.882611: step 617, loss 0.605219, acc 0.734375
2020-02-08T02:28:31.001541: step 618, loss 0.478083, acc 0.75
2020-02-08T02:28:31.116791: step 619, loss 0.451322, acc 0.78125
2020-02-08T02:28:31.234342: step 620, loss 0.582608, acc 0.6875
2020-02-08T02:28:31.350332: step 621, loss 0.573931, acc 0.6875
2020-02-08T02:28:31.467896: step 622, loss 0.432909, acc 0.765625
2020-02-08T02:28:31.584652: step 623, loss 0.545749, acc 0.6875
2020-02-08T02:28:31.700507: step 624, loss 0.477321, acc 0.796875
2020-02-08T02:28:31.815689: step 625, loss 0.434781, acc 0.78125
2020-02-08T02:28:31.936490: step 626, loss 0.513142, acc 0.6875
2020-02-08T02:28:32.053409: step 627, loss 0.427876, acc 0.828125
2020-02-08T02:28:32.169583: step 628, loss 0.536005, acc 0.796875
2020-02-08T02:28:32.289127: step 629, loss 0.619806, acc 0.671875
2020-02-08T02:28:32.405354: step 630, loss 0.651332, acc 0.703125
2020-02-08T02:28:32.523960: step 631, loss 0.53229, acc 0.765625
2020-02-08T02:28:32.640860: step 632, loss 0.532506, acc 0.765625
2020-02-08T02:28:32.761419: step 633, loss 0.427826, acc 0.765625
2020-02-08T02:28:32.884905: step 634, loss 0.488922, acc 0.796875
2020-02-08T02:28:33.006794: step 635, loss 0.597957, acc 0.65625
2020-02-08T02:28:33.122867: step 636, loss 0.450569, acc 0.8125
2020-02-08T02:28:33.239469: step 637, loss 0.588506, acc 0.734375
2020-02-08T02:28:33.355633: step 638, loss 0.368778, acc 0.828125
2020-02-08T02:28:33.474318: step 639, loss 0.462054, acc 0.84375
2020-02-08T02:28:33.592057: step 640, loss 0.362131, acc 0.875
2020-02-08T02:28:33.709463: step 641, loss 0.494333, acc 0.765625
2020-02-08T02:28:33.828675: step 642, loss 0.543278, acc 0.78125
2020-02-08T02:28:33.948433: step 643, loss 0.455632, acc 0.796875
2020-02-08T02:28:34.067072: step 644, loss 0.554744, acc 0.765625
2020-02-08T02:28:34.187036: step 645, loss 0.499671, acc 0.734375
2020-02-08T02:28:34.303499: step 646, loss 0.617658, acc 0.734375
2020-02-08T02:28:34.416205: step 647, loss 0.557032, acc 0.703125
2020-02-08T02:28:34.535100: step 648, loss 0.610167, acc 0.78125
2020-02-08T02:28:34.649479: step 649, loss 0.388208, acc 0.8125
2020-02-08T02:28:34.769934: step 650, loss 0.417814, acc 0.8125
2020-02-08T02:28:34.887667: step 651, loss 0.494978, acc 0.765625
2020-02-08T02:28:35.004829: step 652, loss 0.44553, acc 0.859375
2020-02-08T02:28:35.123028: step 653, loss 0.565195, acc 0.703125
2020-02-08T02:28:35.240297: step 654, loss 0.35939, acc 0.8125
2020-02-08T02:28:35.359493: step 655, loss 0.384236, acc 0.890625
2020-02-08T02:28:35.475270: step 656, loss 0.508956, acc 0.75
2020-02-08T02:28:35.594624: step 657, loss 0.48781, acc 0.71875
2020-02-08T02:28:35.712302: step 658, loss 0.607737, acc 0.6875
2020-02-08T02:28:35.830769: step 659, loss 0.398508, acc 0.828125
2020-02-08T02:28:35.953206: step 660, loss 0.47362, acc 0.75
2020-02-08T02:28:36.071899: step 661, loss 0.537962, acc 0.703125
2020-02-08T02:28:36.187080: step 662, loss 0.409672, acc 0.828125
2020-02-08T02:28:36.305088: step 663, loss 0.581133, acc 0.65625
2020-02-08T02:28:36.421100: step 664, loss 0.429278, acc 0.8125
2020-02-08T02:28:36.539981: step 665, loss 0.473415, acc 0.71875
2020-02-08T02:28:36.657697: step 666, loss 0.44463, acc 0.8125
2020-02-08T02:28:36.780354: step 667, loss 0.508823, acc 0.71875
2020-02-08T02:28:36.896010: step 668, loss 0.339111, acc 0.828125
2020-02-08T02:28:37.011944: step 669, loss 0.476579, acc 0.75
2020-02-08T02:28:37.130579: step 670, loss 0.444415, acc 0.765625
2020-02-08T02:28:37.247840: step 671, loss 0.479579, acc 0.734375
2020-02-08T02:28:37.364260: step 672, loss 0.436646, acc 0.796875
2020-02-08T02:28:37.482361: step 673, loss 0.411581, acc 0.78125
2020-02-08T02:28:37.599760: step 674, loss 0.517127, acc 0.734375
2020-02-08T02:28:37.718215: step 675, loss 0.542758, acc 0.765625
2020-02-08T02:28:37.836638: step 676, loss 0.600739, acc 0.78125
2020-02-08T02:28:37.954894: step 677, loss 0.545794, acc 0.65625
2020-02-08T02:28:38.070203: step 678, loss 0.612586, acc 0.734375
2020-02-08T02:28:38.185317: step 679, loss 0.408587, acc 0.796875
2020-02-08T02:28:38.302881: step 680, loss 0.435998, acc 0.8125
2020-02-08T02:28:38.421542: step 681, loss 0.451228, acc 0.78125
2020-02-08T02:28:38.538360: step 682, loss 0.437538, acc 0.765625
2020-02-08T02:28:38.654558: step 683, loss 0.383777, acc 0.78125
2020-02-08T02:28:38.777355: step 684, loss 0.523486, acc 0.703125
2020-02-08T02:28:38.894621: step 685, loss 0.488136, acc 0.78125
2020-02-08T02:28:39.015232: step 686, loss 0.572896, acc 0.71875
2020-02-08T02:28:39.137404: step 687, loss 0.530087, acc 0.75
2020-02-08T02:28:39.256975: step 688, loss 0.553988, acc 0.75
2020-02-08T02:28:39.375205: step 689, loss 0.40469, acc 0.84375
2020-02-08T02:28:39.489514: step 690, loss 0.49255, acc 0.8125
2020-02-08T02:28:39.608912: step 691, loss 0.346591, acc 0.890625
2020-02-08T02:28:39.731125: step 692, loss 0.563342, acc 0.71875
2020-02-08T02:28:39.847863: step 693, loss 0.399251, acc 0.859375
2020-02-08T02:28:39.964839: step 694, loss 0.397568, acc 0.859375
2020-02-08T02:28:40.079165: step 695, loss 0.473786, acc 0.796875
2020-02-08T02:28:40.197219: step 696, loss 0.449239, acc 0.78125
2020-02-08T02:28:40.311030: step 697, loss 0.463397, acc 0.796875
2020-02-08T02:28:40.430581: step 698, loss 0.455055, acc 0.765625
2020-02-08T02:28:40.547704: step 699, loss 0.490268, acc 0.78125
2020-02-08T02:28:40.664048: step 700, loss 0.520834, acc 0.75

Evaluation:
2020-02-08T02:28:40.858716: step 700, loss 0.600427, acc 0.672608

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-700

2020-02-08T02:28:42.444138: step 701, loss 0.586771, acc 0.734375
2020-02-08T02:28:42.563853: step 702, loss 0.467689, acc 0.765625
2020-02-08T02:28:42.683473: step 703, loss 0.510175, acc 0.703125
2020-02-08T02:28:42.800535: step 704, loss 0.427917, acc 0.8125
2020-02-08T02:28:42.916808: step 705, loss 0.564656, acc 0.671875
2020-02-08T02:28:43.036680: step 706, loss 0.408202, acc 0.8125
2020-02-08T02:28:43.153441: step 707, loss 0.49943, acc 0.71875
2020-02-08T02:28:43.273239: step 708, loss 0.373135, acc 0.84375
2020-02-08T02:28:43.390771: step 709, loss 0.691525, acc 0.65625
2020-02-08T02:28:43.507473: step 710, loss 0.485395, acc 0.8125
2020-02-08T02:28:43.625137: step 711, loss 0.473216, acc 0.71875
2020-02-08T02:28:43.754108: step 712, loss 0.553169, acc 0.6875
2020-02-08T02:28:43.869119: step 713, loss 0.531061, acc 0.765625
2020-02-08T02:28:43.986705: step 714, loss 0.495783, acc 0.765625
2020-02-08T02:28:44.105033: step 715, loss 0.439476, acc 0.796875
2020-02-08T02:28:44.220030: step 716, loss 0.503407, acc 0.765625
2020-02-08T02:28:44.338971: step 717, loss 0.566997, acc 0.71875
2020-02-08T02:28:44.456638: step 718, loss 0.495091, acc 0.734375
2020-02-08T02:28:44.573812: step 719, loss 0.508155, acc 0.765625
2020-02-08T02:28:44.691041: step 720, loss 0.445527, acc 0.796875
2020-02-08T02:28:44.808329: step 721, loss 0.513111, acc 0.734375
2020-02-08T02:28:44.925405: step 722, loss 0.427385, acc 0.828125
2020-02-08T02:28:45.041629: step 723, loss 0.549199, acc 0.71875
2020-02-08T02:28:45.158138: step 724, loss 0.56651, acc 0.75
2020-02-08T02:28:45.278026: step 725, loss 0.648152, acc 0.640625
2020-02-08T02:28:45.399210: step 726, loss 0.529653, acc 0.671875
2020-02-08T02:28:45.516345: step 727, loss 0.521926, acc 0.765625
2020-02-08T02:28:45.633747: step 728, loss 0.493797, acc 0.765625
2020-02-08T02:28:45.758996: step 729, loss 0.429358, acc 0.765625
2020-02-08T02:28:45.874734: step 730, loss 0.511221, acc 0.6875
2020-02-08T02:28:45.992850: step 731, loss 0.428928, acc 0.8125
2020-02-08T02:28:46.111290: step 732, loss 0.460767, acc 0.765625
2020-02-08T02:28:46.225992: step 733, loss 0.473919, acc 0.8125
2020-02-08T02:28:46.345129: step 734, loss 0.483818, acc 0.75
2020-02-08T02:28:46.461761: step 735, loss 0.506956, acc 0.75
2020-02-08T02:28:46.581013: step 736, loss 0.547546, acc 0.734375
2020-02-08T02:28:46.702828: step 737, loss 0.517692, acc 0.71875
2020-02-08T02:28:46.820571: step 738, loss 0.355412, acc 0.8125
2020-02-08T02:28:46.940693: step 739, loss 0.42656, acc 0.828125
2020-02-08T02:28:47.056042: step 740, loss 0.46059, acc 0.75
2020-02-08T02:28:47.171081: step 741, loss 0.527394, acc 0.671875
2020-02-08T02:28:47.286518: step 742, loss 0.699189, acc 0.65625
2020-02-08T02:28:47.402348: step 743, loss 0.590596, acc 0.703125
2020-02-08T02:28:47.517309: step 744, loss 0.549727, acc 0.75
2020-02-08T02:28:47.636592: step 745, loss 0.564526, acc 0.71875
2020-02-08T02:28:47.758692: step 746, loss 0.477366, acc 0.734375
2020-02-08T02:28:47.876201: step 747, loss 0.46332, acc 0.796875
2020-02-08T02:28:47.994277: step 748, loss 0.510861, acc 0.734375
2020-02-08T02:28:48.108257: step 749, loss 0.420369, acc 0.765625
2020-02-08T02:28:48.221092: step 750, loss 0.412906, acc 0.85
2020-02-08T02:28:48.341005: step 751, loss 0.374714, acc 0.84375
2020-02-08T02:28:48.461198: step 752, loss 0.45383, acc 0.765625
2020-02-08T02:28:48.578351: step 753, loss 0.437934, acc 0.84375
2020-02-08T02:28:48.741063: step 754, loss 0.510459, acc 0.765625
2020-02-08T02:28:48.928641: step 755, loss 0.499332, acc 0.765625
2020-02-08T02:28:49.055763: step 756, loss 0.386189, acc 0.796875
2020-02-08T02:28:49.193731: step 757, loss 0.453316, acc 0.796875
2020-02-08T02:28:49.334335: step 758, loss 0.393175, acc 0.78125
2020-02-08T02:28:49.467011: step 759, loss 0.537464, acc 0.65625
2020-02-08T02:28:49.601909: step 760, loss 0.350002, acc 0.84375
2020-02-08T02:28:49.737829: step 761, loss 0.375893, acc 0.859375
2020-02-08T02:28:49.871205: step 762, loss 0.440092, acc 0.796875
2020-02-08T02:28:50.003497: step 763, loss 0.329997, acc 0.921875
2020-02-08T02:28:50.142732: step 764, loss 0.37881, acc 0.859375
2020-02-08T02:28:50.276655: step 765, loss 0.45903, acc 0.765625
2020-02-08T02:28:50.406517: step 766, loss 0.326416, acc 0.875
2020-02-08T02:28:50.528650: step 767, loss 0.354668, acc 0.875
2020-02-08T02:28:50.659034: step 768, loss 0.422814, acc 0.796875
2020-02-08T02:28:50.787702: step 769, loss 0.352522, acc 0.859375
2020-02-08T02:28:50.918767: step 770, loss 0.48431, acc 0.765625
2020-02-08T02:28:51.047711: step 771, loss 0.284039, acc 0.890625
2020-02-08T02:28:51.180138: step 772, loss 0.397924, acc 0.828125
2020-02-08T02:28:51.300342: step 773, loss 0.40858, acc 0.828125
2020-02-08T02:28:51.416745: step 774, loss 0.306816, acc 0.84375
2020-02-08T02:28:51.645052: step 775, loss 0.41086, acc 0.8125
2020-02-08T02:28:51.801351: step 776, loss 0.326134, acc 0.84375
2020-02-08T02:28:51.929045: step 777, loss 0.522367, acc 0.6875
2020-02-08T02:28:52.060892: step 778, loss 0.349311, acc 0.84375
2020-02-08T02:28:52.200505: step 779, loss 0.2449, acc 0.9375
2020-02-08T02:28:52.342496: step 780, loss 0.424747, acc 0.84375
2020-02-08T02:28:52.487405: step 781, loss 0.418785, acc 0.8125
2020-02-08T02:28:52.640526: step 782, loss 0.377878, acc 0.8125
2020-02-08T02:28:52.789221: step 783, loss 0.39395, acc 0.796875
2020-02-08T02:28:52.916223: step 784, loss 0.350826, acc 0.84375
2020-02-08T02:28:53.050020: step 785, loss 0.432496, acc 0.84375
2020-02-08T02:28:53.188722: step 786, loss 0.510651, acc 0.6875
2020-02-08T02:28:53.327546: step 787, loss 0.34152, acc 0.84375
2020-02-08T02:28:53.466969: step 788, loss 0.490539, acc 0.75
2020-02-08T02:28:53.609922: step 789, loss 0.460398, acc 0.78125
2020-02-08T02:28:53.761229: step 790, loss 0.357615, acc 0.8125
2020-02-08T02:28:53.893239: step 791, loss 0.411258, acc 0.796875
2020-02-08T02:28:54.036019: step 792, loss 0.438275, acc 0.796875
2020-02-08T02:28:54.165246: step 793, loss 0.495728, acc 0.6875
2020-02-08T02:28:54.310193: step 794, loss 0.48071, acc 0.75
2020-02-08T02:28:54.452774: step 795, loss 0.383475, acc 0.84375
2020-02-08T02:28:54.592487: step 796, loss 0.420027, acc 0.78125
2020-02-08T02:28:54.740171: step 797, loss 0.476284, acc 0.75
2020-02-08T02:28:54.879046: step 798, loss 0.477055, acc 0.734375
2020-02-08T02:28:55.011816: step 799, loss 0.395521, acc 0.828125
2020-02-08T02:28:55.154319: step 800, loss 0.484235, acc 0.796875

Evaluation:
2020-02-08T02:28:55.380946: step 800, loss 0.608475, acc 0.673546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-800

2020-02-08T02:28:56.906822: step 801, loss 0.424962, acc 0.8125
2020-02-08T02:28:57.042813: step 802, loss 0.41955, acc 0.78125
2020-02-08T02:28:57.184144: step 803, loss 0.425031, acc 0.78125
2020-02-08T02:28:57.322548: step 804, loss 0.313561, acc 0.875
2020-02-08T02:28:57.450564: step 805, loss 0.364588, acc 0.84375
2020-02-08T02:28:57.588874: step 806, loss 0.473997, acc 0.78125
2020-02-08T02:28:57.715395: step 807, loss 0.420734, acc 0.8125
2020-02-08T02:28:57.855925: step 808, loss 0.376928, acc 0.859375
2020-02-08T02:28:57.996598: step 809, loss 0.397009, acc 0.796875
2020-02-08T02:28:58.136688: step 810, loss 0.520346, acc 0.75
2020-02-08T02:28:58.275389: step 811, loss 0.332185, acc 0.90625
2020-02-08T02:28:58.411871: step 812, loss 0.538471, acc 0.765625
2020-02-08T02:28:58.549898: step 813, loss 0.447003, acc 0.78125
2020-02-08T02:28:58.690359: step 814, loss 0.318123, acc 0.859375
2020-02-08T02:28:58.817201: step 815, loss 0.388303, acc 0.84375
2020-02-08T02:28:58.946765: step 816, loss 0.497405, acc 0.71875
2020-02-08T02:28:59.075217: step 817, loss 0.350406, acc 0.84375
2020-02-08T02:28:59.199814: step 818, loss 0.349994, acc 0.875
2020-02-08T02:28:59.314934: step 819, loss 0.384511, acc 0.78125
2020-02-08T02:28:59.432609: step 820, loss 0.400842, acc 0.796875
2020-02-08T02:28:59.555117: step 821, loss 0.365838, acc 0.828125
2020-02-08T02:28:59.693525: step 822, loss 0.298711, acc 0.890625
2020-02-08T02:28:59.810490: step 823, loss 0.387756, acc 0.828125
2020-02-08T02:28:59.932126: step 824, loss 0.360541, acc 0.84375
2020-02-08T02:29:00.051863: step 825, loss 0.427519, acc 0.796875
2020-02-08T02:29:00.168373: step 826, loss 0.407846, acc 0.71875
2020-02-08T02:29:00.289523: step 827, loss 0.542107, acc 0.71875
2020-02-08T02:29:00.408451: step 828, loss 0.365202, acc 0.828125
2020-02-08T02:29:00.527353: step 829, loss 0.438161, acc 0.8125
2020-02-08T02:29:00.656798: step 830, loss 0.442947, acc 0.75
2020-02-08T02:29:00.782652: step 831, loss 0.525368, acc 0.8125
2020-02-08T02:29:00.907248: step 832, loss 0.554839, acc 0.75
2020-02-08T02:29:01.025374: step 833, loss 0.370181, acc 0.84375
2020-02-08T02:29:01.145791: step 834, loss 0.328952, acc 0.8125
2020-02-08T02:29:01.261339: step 835, loss 0.490296, acc 0.75
2020-02-08T02:29:01.385397: step 836, loss 0.508521, acc 0.765625
2020-02-08T02:29:01.506958: step 837, loss 0.479874, acc 0.765625
2020-02-08T02:29:01.623311: step 838, loss 0.371491, acc 0.796875
2020-02-08T02:29:01.754213: step 839, loss 0.436856, acc 0.8125
2020-02-08T02:29:01.872074: step 840, loss 0.476386, acc 0.765625
2020-02-08T02:29:01.995740: step 841, loss 0.5382, acc 0.734375
2020-02-08T02:29:02.113673: step 842, loss 0.505767, acc 0.796875
2020-02-08T02:29:02.232341: step 843, loss 0.393653, acc 0.796875
2020-02-08T02:29:02.351385: step 844, loss 0.375328, acc 0.796875
2020-02-08T02:29:02.468914: step 845, loss 0.333568, acc 0.828125
2020-02-08T02:29:02.584466: step 846, loss 0.339298, acc 0.796875
2020-02-08T02:29:02.702909: step 847, loss 0.431187, acc 0.828125
2020-02-08T02:29:02.818098: step 848, loss 0.322776, acc 0.859375
2020-02-08T02:29:02.938338: step 849, loss 0.354591, acc 0.8125
2020-02-08T02:29:03.054664: step 850, loss 0.456748, acc 0.734375
2020-02-08T02:29:03.170134: step 851, loss 0.399391, acc 0.84375
2020-02-08T02:29:03.288105: step 852, loss 0.485668, acc 0.8125
2020-02-08T02:29:03.405746: step 853, loss 0.573482, acc 0.703125
2020-02-08T02:29:03.522304: step 854, loss 0.432481, acc 0.84375
2020-02-08T02:29:03.643603: step 855, loss 0.505459, acc 0.78125
2020-02-08T02:29:03.766242: step 856, loss 0.57019, acc 0.703125
2020-02-08T02:29:03.890703: step 857, loss 0.508473, acc 0.75
2020-02-08T02:29:04.006568: step 858, loss 0.510591, acc 0.703125
2020-02-08T02:29:04.121186: step 859, loss 0.449119, acc 0.796875
2020-02-08T02:29:04.239697: step 860, loss 0.317304, acc 0.859375
2020-02-08T02:29:04.358201: step 861, loss 0.536795, acc 0.71875
2020-02-08T02:29:04.477327: step 862, loss 0.41792, acc 0.796875
2020-02-08T02:29:04.594610: step 863, loss 0.375399, acc 0.796875
2020-02-08T02:29:04.715877: step 864, loss 0.53152, acc 0.78125
2020-02-08T02:29:04.832340: step 865, loss 0.372576, acc 0.796875
2020-02-08T02:29:04.949670: step 866, loss 0.336985, acc 0.859375
2020-02-08T02:29:05.064344: step 867, loss 0.391613, acc 0.828125
2020-02-08T02:29:05.183341: step 868, loss 0.415092, acc 0.78125
2020-02-08T02:29:05.303649: step 869, loss 0.355465, acc 0.84375
2020-02-08T02:29:05.419271: step 870, loss 0.402213, acc 0.796875
2020-02-08T02:29:05.537034: step 871, loss 0.388909, acc 0.8125
2020-02-08T02:29:05.653352: step 872, loss 0.352516, acc 0.875
2020-02-08T02:29:05.773538: step 873, loss 0.496038, acc 0.75
2020-02-08T02:29:05.892676: step 874, loss 0.488145, acc 0.765625
2020-02-08T02:29:06.010178: step 875, loss 0.402672, acc 0.84375
2020-02-08T02:29:06.130346: step 876, loss 0.376675, acc 0.828125
2020-02-08T02:29:06.266676: step 877, loss 0.468487, acc 0.75
2020-02-08T02:29:06.403307: step 878, loss 0.480729, acc 0.78125
2020-02-08T02:29:06.524088: step 879, loss 0.439034, acc 0.84375
2020-02-08T02:29:06.642491: step 880, loss 0.328375, acc 0.90625
2020-02-08T02:29:06.760877: step 881, loss 0.4017, acc 0.796875
2020-02-08T02:29:06.875084: step 882, loss 0.45614, acc 0.796875
2020-02-08T02:29:06.994250: step 883, loss 0.457088, acc 0.78125
2020-02-08T02:29:07.108033: step 884, loss 0.304429, acc 0.84375
2020-02-08T02:29:07.225906: step 885, loss 0.453099, acc 0.796875
2020-02-08T02:29:07.346168: step 886, loss 0.586397, acc 0.75
2020-02-08T02:29:07.462848: step 887, loss 0.416268, acc 0.8125
2020-02-08T02:29:07.580495: step 888, loss 0.405866, acc 0.796875
2020-02-08T02:29:07.699924: step 889, loss 0.320127, acc 0.890625
2020-02-08T02:29:07.818073: step 890, loss 0.327919, acc 0.875
2020-02-08T02:29:07.934692: step 891, loss 0.403191, acc 0.828125
2020-02-08T02:29:08.051668: step 892, loss 0.389578, acc 0.765625
2020-02-08T02:29:08.166829: step 893, loss 0.510714, acc 0.71875
2020-02-08T02:29:08.281541: step 894, loss 0.505884, acc 0.734375
2020-02-08T02:29:08.398103: step 895, loss 0.320773, acc 0.875
2020-02-08T02:29:08.515750: step 896, loss 0.389722, acc 0.75
2020-02-08T02:29:08.636031: step 897, loss 0.466118, acc 0.71875
2020-02-08T02:29:08.758337: step 898, loss 0.291439, acc 0.890625
2020-02-08T02:29:08.874248: step 899, loss 0.401956, acc 0.859375
2020-02-08T02:29:08.989632: step 900, loss 0.475741, acc 0.8

Evaluation:
2020-02-08T02:29:09.177525: step 900, loss 0.584235, acc 0.688555

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-900

2020-02-08T02:29:10.657916: step 901, loss 0.356442, acc 0.875
2020-02-08T02:29:10.776236: step 902, loss 0.337665, acc 0.890625
2020-02-08T02:29:10.894837: step 903, loss 0.35622, acc 0.875
2020-02-08T02:29:11.010078: step 904, loss 0.302693, acc 0.84375
2020-02-08T02:29:11.124013: step 905, loss 0.315773, acc 0.921875
2020-02-08T02:29:11.246047: step 906, loss 0.488731, acc 0.78125
2020-02-08T02:29:11.361168: step 907, loss 0.34288, acc 0.875
2020-02-08T02:29:11.478446: step 908, loss 0.302386, acc 0.859375
2020-02-08T02:29:11.596229: step 909, loss 0.407038, acc 0.828125
2020-02-08T02:29:11.713881: step 910, loss 0.436718, acc 0.78125
2020-02-08T02:29:11.829287: step 911, loss 0.374372, acc 0.890625
2020-02-08T02:29:11.947887: step 912, loss 0.282562, acc 0.890625
2020-02-08T02:29:12.064420: step 913, loss 0.342842, acc 0.84375
2020-02-08T02:29:12.181490: step 914, loss 0.480761, acc 0.78125
2020-02-08T02:29:12.298804: step 915, loss 0.386047, acc 0.828125
2020-02-08T02:29:12.415685: step 916, loss 0.296532, acc 0.875
2020-02-08T02:29:12.533321: step 917, loss 0.308915, acc 0.90625
2020-02-08T02:29:12.650338: step 918, loss 0.407506, acc 0.78125
2020-02-08T02:29:12.767670: step 919, loss 0.351509, acc 0.84375
2020-02-08T02:29:12.888423: step 920, loss 0.303471, acc 0.890625
2020-02-08T02:29:13.006127: step 921, loss 0.3833, acc 0.8125
2020-02-08T02:29:13.121042: step 922, loss 0.359279, acc 0.890625
2020-02-08T02:29:13.236166: step 923, loss 0.439671, acc 0.8125
2020-02-08T02:29:13.351857: step 924, loss 0.307444, acc 0.890625
2020-02-08T02:29:13.467825: step 925, loss 0.297529, acc 0.921875
2020-02-08T02:29:13.584584: step 926, loss 0.33644, acc 0.859375
2020-02-08T02:29:13.706932: step 927, loss 0.373711, acc 0.8125
2020-02-08T02:29:13.825013: step 928, loss 0.328189, acc 0.859375
2020-02-08T02:29:13.943008: step 929, loss 0.279249, acc 0.90625
2020-02-08T02:29:14.061151: step 930, loss 0.385903, acc 0.828125
2020-02-08T02:29:14.177922: step 931, loss 0.353328, acc 0.84375
2020-02-08T02:29:14.301387: step 932, loss 0.455043, acc 0.796875
2020-02-08T02:29:14.416557: step 933, loss 0.253847, acc 0.953125
2020-02-08T02:29:14.536191: step 934, loss 0.306021, acc 0.859375
2020-02-08T02:29:14.654243: step 935, loss 0.324933, acc 0.859375
2020-02-08T02:29:14.775325: step 936, loss 0.439787, acc 0.828125
2020-02-08T02:29:14.893938: step 937, loss 0.331638, acc 0.90625
2020-02-08T02:29:15.009535: step 938, loss 0.326177, acc 0.859375
2020-02-08T02:29:15.125841: step 939, loss 0.19976, acc 0.953125
2020-02-08T02:29:15.242386: step 940, loss 0.234759, acc 0.90625
2020-02-08T02:29:15.359274: step 941, loss 0.2917, acc 0.8125
2020-02-08T02:29:15.471685: step 942, loss 0.365566, acc 0.875
2020-02-08T02:29:15.587825: step 943, loss 0.392808, acc 0.8125
2020-02-08T02:29:15.707588: step 944, loss 0.287789, acc 0.90625
2020-02-08T02:29:15.823284: step 945, loss 0.374027, acc 0.875
2020-02-08T02:29:15.942040: step 946, loss 0.399266, acc 0.84375
2020-02-08T02:29:16.061632: step 947, loss 0.291158, acc 0.859375
2020-02-08T02:29:16.180197: step 948, loss 0.375865, acc 0.84375
2020-02-08T02:29:16.295605: step 949, loss 0.314701, acc 0.890625
2020-02-08T02:29:16.410663: step 950, loss 0.248654, acc 0.859375
2020-02-08T02:29:16.525661: step 951, loss 0.358853, acc 0.828125
2020-02-08T02:29:16.644731: step 952, loss 0.290546, acc 0.90625
2020-02-08T02:29:16.765969: step 953, loss 0.390682, acc 0.796875
2020-02-08T02:29:16.882455: step 954, loss 0.35799, acc 0.78125
2020-02-08T02:29:17.000209: step 955, loss 0.387429, acc 0.84375
2020-02-08T02:29:17.115817: step 956, loss 0.452569, acc 0.796875
2020-02-08T02:29:17.232309: step 957, loss 0.279199, acc 0.90625
2020-02-08T02:29:17.350812: step 958, loss 0.399121, acc 0.8125
2020-02-08T02:29:17.467548: step 959, loss 0.542578, acc 0.71875
2020-02-08T02:29:17.583235: step 960, loss 0.432886, acc 0.8125
2020-02-08T02:29:17.699794: step 961, loss 0.347904, acc 0.8125
2020-02-08T02:29:17.817876: step 962, loss 0.266147, acc 0.921875
2020-02-08T02:29:17.933496: step 963, loss 0.221687, acc 0.921875
2020-02-08T02:29:18.051429: step 964, loss 0.407427, acc 0.84375
2020-02-08T02:29:18.164598: step 965, loss 0.341132, acc 0.84375
2020-02-08T02:29:18.283298: step 966, loss 0.311613, acc 0.828125
2020-02-08T02:29:18.401556: step 967, loss 0.468212, acc 0.765625
2020-02-08T02:29:18.517126: step 968, loss 0.380855, acc 0.828125
2020-02-08T02:29:18.633377: step 969, loss 0.450617, acc 0.8125
2020-02-08T02:29:18.759848: step 970, loss 0.472897, acc 0.75
2020-02-08T02:29:18.883211: step 971, loss 0.366932, acc 0.8125
2020-02-08T02:29:19.008933: step 972, loss 0.364853, acc 0.875
2020-02-08T02:29:19.128676: step 973, loss 0.254721, acc 0.875
2020-02-08T02:29:19.253690: step 974, loss 0.578619, acc 0.703125
2020-02-08T02:29:19.373823: step 975, loss 0.409786, acc 0.8125
2020-02-08T02:29:19.503533: step 976, loss 0.323818, acc 0.859375
2020-02-08T02:29:19.623467: step 977, loss 0.360362, acc 0.828125
2020-02-08T02:29:19.747376: step 978, loss 0.288042, acc 0.875
2020-02-08T02:29:19.865055: step 979, loss 0.275343, acc 0.859375
2020-02-08T02:29:19.986182: step 980, loss 0.338116, acc 0.84375
2020-02-08T02:29:20.107542: step 981, loss 0.387496, acc 0.78125
2020-02-08T02:29:20.226349: step 982, loss 0.414212, acc 0.796875
2020-02-08T02:29:20.347355: step 983, loss 0.374062, acc 0.8125
2020-02-08T02:29:20.461316: step 984, loss 0.271733, acc 0.90625
2020-02-08T02:29:20.577187: step 985, loss 0.338994, acc 0.84375
2020-02-08T02:29:20.698421: step 986, loss 0.292812, acc 0.875
2020-02-08T02:29:20.814290: step 987, loss 0.370907, acc 0.8125
2020-02-08T02:29:20.929847: step 988, loss 0.386647, acc 0.796875
2020-02-08T02:29:21.046555: step 989, loss 0.379323, acc 0.828125
2020-02-08T02:29:21.162838: step 990, loss 0.374447, acc 0.875
2020-02-08T02:29:21.506474: step 991, loss 0.362422, acc 0.875
2020-02-08T02:29:21.625710: step 992, loss 0.349349, acc 0.859375
2020-02-08T02:29:21.747254: step 993, loss 0.374153, acc 0.796875
2020-02-08T02:29:21.864303: step 994, loss 0.354242, acc 0.859375
2020-02-08T02:29:21.979464: step 995, loss 0.32941, acc 0.796875
2020-02-08T02:29:22.095133: step 996, loss 0.339195, acc 0.84375
2020-02-08T02:29:22.211077: step 997, loss 0.35105, acc 0.859375
2020-02-08T02:29:22.329624: step 998, loss 0.282902, acc 0.84375
2020-02-08T02:29:22.446275: step 999, loss 0.474321, acc 0.796875
2020-02-08T02:29:22.561564: step 1000, loss 0.335253, acc 0.84375

Evaluation:
2020-02-08T02:29:22.756244: step 1000, loss 0.590311, acc 0.702627

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1000

2020-02-08T02:29:25.687358: step 1001, loss 0.311862, acc 0.875
2020-02-08T02:29:25.806083: step 1002, loss 0.270827, acc 0.90625
2020-02-08T02:29:25.920651: step 1003, loss 0.293479, acc 0.890625
2020-02-08T02:29:26.037760: step 1004, loss 0.339721, acc 0.859375
2020-02-08T02:29:26.153335: step 1005, loss 0.320507, acc 0.90625
2020-02-08T02:29:26.268859: step 1006, loss 0.345354, acc 0.828125
2020-02-08T02:29:26.384529: step 1007, loss 0.249392, acc 0.890625
2020-02-08T02:29:26.502448: step 1008, loss 0.385244, acc 0.8125
2020-02-08T02:29:26.618132: step 1009, loss 0.423848, acc 0.734375
2020-02-08T02:29:26.742581: step 1010, loss 0.397151, acc 0.859375
2020-02-08T02:29:26.858245: step 1011, loss 0.285178, acc 0.828125
2020-02-08T02:29:26.974967: step 1012, loss 0.304623, acc 0.90625
2020-02-08T02:29:27.092188: step 1013, loss 0.374029, acc 0.828125
2020-02-08T02:29:27.207526: step 1014, loss 0.272525, acc 0.859375
2020-02-08T02:29:27.320514: step 1015, loss 0.489016, acc 0.796875
2020-02-08T02:29:27.435732: step 1016, loss 0.366218, acc 0.828125
2020-02-08T02:29:27.552269: step 1017, loss 0.418226, acc 0.796875
2020-02-08T02:29:27.667700: step 1018, loss 0.444382, acc 0.75
2020-02-08T02:29:27.789272: step 1019, loss 0.236464, acc 0.921875
2020-02-08T02:29:27.905599: step 1020, loss 0.403217, acc 0.796875
2020-02-08T02:29:28.019973: step 1021, loss 0.385523, acc 0.875
2020-02-08T02:29:28.137361: step 1022, loss 0.396859, acc 0.796875
2020-02-08T02:29:28.254895: step 1023, loss 0.33201, acc 0.84375
2020-02-08T02:29:28.373284: step 1024, loss 0.463169, acc 0.8125
2020-02-08T02:29:28.492958: step 1025, loss 0.314865, acc 0.890625
2020-02-08T02:29:28.608001: step 1026, loss 0.322546, acc 0.828125
2020-02-08T02:29:28.726760: step 1027, loss 0.263336, acc 0.921875
2020-02-08T02:29:28.844799: step 1028, loss 0.330288, acc 0.859375
2020-02-08T02:29:28.975007: step 1029, loss 0.372422, acc 0.8125
2020-02-08T02:29:29.118412: step 1030, loss 0.274759, acc 0.90625
2020-02-08T02:29:29.233625: step 1031, loss 0.372021, acc 0.828125
2020-02-08T02:29:29.348003: step 1032, loss 0.31562, acc 0.875
2020-02-08T02:29:29.464041: step 1033, loss 0.353424, acc 0.875
2020-02-08T02:29:29.578386: step 1034, loss 0.36115, acc 0.84375
2020-02-08T02:29:29.696178: step 1035, loss 0.257987, acc 0.953125
2020-02-08T02:29:29.811162: step 1036, loss 0.331008, acc 0.796875
2020-02-08T02:29:29.926776: step 1037, loss 0.460525, acc 0.828125
2020-02-08T02:29:30.043067: step 1038, loss 0.492595, acc 0.796875
2020-02-08T02:29:30.160422: step 1039, loss 0.417707, acc 0.796875
2020-02-08T02:29:30.278842: step 1040, loss 0.400591, acc 0.828125
2020-02-08T02:29:30.396490: step 1041, loss 0.324457, acc 0.84375
2020-02-08T02:29:30.512324: step 1042, loss 0.271039, acc 0.890625
2020-02-08T02:29:30.629551: step 1043, loss 0.242218, acc 0.890625
2020-02-08T02:29:30.748543: step 1044, loss 0.380445, acc 0.796875
2020-02-08T02:29:30.862194: step 1045, loss 0.30623, acc 0.890625
2020-02-08T02:29:30.978079: step 1046, loss 0.405901, acc 0.890625
2020-02-08T02:29:31.095388: step 1047, loss 0.398705, acc 0.8125
2020-02-08T02:29:31.209362: step 1048, loss 0.326672, acc 0.859375
2020-02-08T02:29:31.329281: step 1049, loss 0.246815, acc 0.875
2020-02-08T02:29:31.445386: step 1050, loss 0.294056, acc 0.883333
2020-02-08T02:29:31.565143: step 1051, loss 0.213221, acc 0.9375
2020-02-08T02:29:31.684542: step 1052, loss 0.239199, acc 0.875
2020-02-08T02:29:31.800157: step 1053, loss 0.2872, acc 0.890625
2020-02-08T02:29:31.919106: step 1054, loss 0.311914, acc 0.875
2020-02-08T02:29:32.031424: step 1055, loss 0.366706, acc 0.84375
2020-02-08T02:29:32.147807: step 1056, loss 0.336201, acc 0.84375
2020-02-08T02:29:32.263866: step 1057, loss 0.168877, acc 0.9375
2020-02-08T02:29:32.381191: step 1058, loss 0.270316, acc 0.890625
2020-02-08T02:29:32.494709: step 1059, loss 0.263277, acc 0.84375
2020-02-08T02:29:32.611234: step 1060, loss 0.304548, acc 0.90625
2020-02-08T02:29:32.732311: step 1061, loss 0.35453, acc 0.875
2020-02-08T02:29:32.849532: step 1062, loss 0.319566, acc 0.84375
2020-02-08T02:29:32.965783: step 1063, loss 0.228606, acc 0.921875
2020-02-08T02:29:33.080802: step 1064, loss 0.234441, acc 0.890625
2020-02-08T02:29:33.193535: step 1065, loss 0.246921, acc 0.90625
2020-02-08T02:29:33.309774: step 1066, loss 0.28532, acc 0.890625
2020-02-08T02:29:33.426787: step 1067, loss 0.330012, acc 0.875
2020-02-08T02:29:33.544765: step 1068, loss 0.264244, acc 0.90625
2020-02-08T02:29:33.663633: step 1069, loss 0.356448, acc 0.890625
2020-02-08T02:29:33.786642: step 1070, loss 0.405461, acc 0.84375
2020-02-08T02:29:33.898708: step 1071, loss 0.190338, acc 0.921875
2020-02-08T02:29:34.015976: step 1072, loss 0.295178, acc 0.859375
2020-02-08T02:29:34.135819: step 1073, loss 0.234722, acc 0.921875
2020-02-08T02:29:34.253727: step 1074, loss 0.283852, acc 0.875
2020-02-08T02:29:34.370540: step 1075, loss 0.25929, acc 0.90625
2020-02-08T02:29:34.489045: step 1076, loss 0.353496, acc 0.828125
2020-02-08T02:29:34.606887: step 1077, loss 0.280816, acc 0.890625
2020-02-08T02:29:34.729543: step 1078, loss 0.251768, acc 0.890625
2020-02-08T02:29:34.846469: step 1079, loss 0.240332, acc 0.9375
2020-02-08T02:29:34.965610: step 1080, loss 0.256083, acc 0.921875
2020-02-08T02:29:35.083751: step 1081, loss 0.305681, acc 0.875
2020-02-08T02:29:35.202681: step 1082, loss 0.305768, acc 0.90625
2020-02-08T02:29:35.320113: step 1083, loss 0.319644, acc 0.890625
2020-02-08T02:29:35.435408: step 1084, loss 0.311995, acc 0.875
2020-02-08T02:29:35.555826: step 1085, loss 0.347228, acc 0.875
2020-02-08T02:29:35.672719: step 1086, loss 0.302836, acc 0.84375
2020-02-08T02:29:35.792995: step 1087, loss 0.293325, acc 0.90625
2020-02-08T02:29:35.913059: step 1088, loss 0.239747, acc 0.90625
2020-02-08T02:29:36.030004: step 1089, loss 0.181019, acc 0.921875
2020-02-08T02:29:36.147278: step 1090, loss 0.253171, acc 0.9375
2020-02-08T02:29:36.265077: step 1091, loss 0.296057, acc 0.890625
2020-02-08T02:29:36.382808: step 1092, loss 0.268541, acc 0.875
2020-02-08T02:29:36.499243: step 1093, loss 0.189726, acc 0.9375
2020-02-08T02:29:36.618629: step 1094, loss 0.272023, acc 0.859375
2020-02-08T02:29:36.744017: step 1095, loss 0.306698, acc 0.875
2020-02-08T02:29:36.863072: step 1096, loss 0.249905, acc 0.890625
2020-02-08T02:29:36.982665: step 1097, loss 0.244265, acc 0.921875
2020-02-08T02:29:37.099852: step 1098, loss 0.342341, acc 0.859375
2020-02-08T02:29:37.216863: step 1099, loss 0.2141, acc 0.953125
2020-02-08T02:29:37.335833: step 1100, loss 0.266106, acc 0.875

Evaluation:
2020-02-08T02:29:37.522287: step 1100, loss 0.587286, acc 0.70075

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1100

2020-02-08T02:29:40.328048: step 1101, loss 0.187789, acc 0.9375
2020-02-08T02:29:40.447606: step 1102, loss 0.327114, acc 0.84375
2020-02-08T02:29:40.566659: step 1103, loss 0.309926, acc 0.875
2020-02-08T02:29:40.681786: step 1104, loss 0.394174, acc 0.8125
2020-02-08T02:29:40.798371: step 1105, loss 0.182144, acc 0.9375
2020-02-08T02:29:40.912229: step 1106, loss 0.23575, acc 0.921875
2020-02-08T02:29:41.032958: step 1107, loss 0.276248, acc 0.890625
2020-02-08T02:29:41.155577: step 1108, loss 0.369985, acc 0.84375
2020-02-08T02:29:41.272196: step 1109, loss 0.253304, acc 0.875
2020-02-08T02:29:41.391840: step 1110, loss 0.205389, acc 0.90625
2020-02-08T02:29:41.508670: step 1111, loss 0.20626, acc 0.9375
2020-02-08T02:29:41.623643: step 1112, loss 0.20159, acc 0.921875
2020-02-08T02:29:41.750329: step 1113, loss 0.319065, acc 0.828125
2020-02-08T02:29:41.866702: step 1114, loss 0.234949, acc 0.90625
2020-02-08T02:29:41.983537: step 1115, loss 0.285548, acc 0.828125
2020-02-08T02:29:42.101795: step 1116, loss 0.318224, acc 0.875
2020-02-08T02:29:42.217640: step 1117, loss 0.387396, acc 0.859375
2020-02-08T02:29:42.333435: step 1118, loss 0.305222, acc 0.875
2020-02-08T02:29:42.450769: step 1119, loss 0.203966, acc 0.9375
2020-02-08T02:29:42.568585: step 1120, loss 0.235929, acc 0.921875
2020-02-08T02:29:42.688189: step 1121, loss 0.290036, acc 0.875
2020-02-08T02:29:42.806004: step 1122, loss 0.269961, acc 0.921875
2020-02-08T02:29:42.921246: step 1123, loss 0.237084, acc 0.90625
2020-02-08T02:29:43.038668: step 1124, loss 0.35694, acc 0.84375
2020-02-08T02:29:43.153497: step 1125, loss 0.347969, acc 0.859375
2020-02-08T02:29:43.271871: step 1126, loss 0.315202, acc 0.8125
2020-02-08T02:29:43.389925: step 1127, loss 0.258383, acc 0.859375
2020-02-08T02:29:43.507840: step 1128, loss 0.497017, acc 0.765625
2020-02-08T02:29:43.624864: step 1129, loss 0.411264, acc 0.828125
2020-02-08T02:29:43.748199: step 1130, loss 0.295478, acc 0.890625
2020-02-08T02:29:43.865227: step 1131, loss 0.248311, acc 0.90625
2020-02-08T02:29:43.982553: step 1132, loss 0.433368, acc 0.8125
2020-02-08T02:29:44.096857: step 1133, loss 0.194297, acc 0.921875
2020-02-08T02:29:44.212388: step 1134, loss 0.287374, acc 0.921875
2020-02-08T02:29:44.331011: step 1135, loss 0.216454, acc 0.90625
2020-02-08T02:29:44.450342: step 1136, loss 0.312781, acc 0.84375
2020-02-08T02:29:44.567249: step 1137, loss 0.26093, acc 0.953125
2020-02-08T02:29:44.689429: step 1138, loss 0.365215, acc 0.828125
2020-02-08T02:29:44.810342: step 1139, loss 0.214587, acc 0.96875
2020-02-08T02:29:44.927403: step 1140, loss 0.237832, acc 0.890625
2020-02-08T02:29:45.048149: step 1141, loss 0.359356, acc 0.859375
2020-02-08T02:29:45.164428: step 1142, loss 0.374497, acc 0.875
2020-02-08T02:29:45.285858: step 1143, loss 0.238864, acc 0.890625
2020-02-08T02:29:45.404023: step 1144, loss 0.309983, acc 0.859375
2020-02-08T02:29:45.519664: step 1145, loss 0.319058, acc 0.875
2020-02-08T02:29:45.639991: step 1146, loss 0.193442, acc 0.9375
2020-02-08T02:29:45.762048: step 1147, loss 0.305258, acc 0.890625
2020-02-08T02:29:45.879059: step 1148, loss 0.297051, acc 0.890625
2020-02-08T02:29:46.000926: step 1149, loss 0.357744, acc 0.875
2020-02-08T02:29:46.117923: step 1150, loss 0.31661, acc 0.859375
2020-02-08T02:29:46.235687: step 1151, loss 0.380331, acc 0.84375
2020-02-08T02:29:46.353617: step 1152, loss 0.216328, acc 0.90625
2020-02-08T02:29:46.469975: step 1153, loss 0.253647, acc 0.90625
2020-02-08T02:29:46.588711: step 1154, loss 0.348098, acc 0.859375
2020-02-08T02:29:46.704869: step 1155, loss 0.297768, acc 0.890625
2020-02-08T02:29:46.822600: step 1156, loss 0.200361, acc 0.953125
2020-02-08T02:29:46.937639: step 1157, loss 0.243524, acc 0.90625
2020-02-08T02:29:47.057520: step 1158, loss 0.244932, acc 0.875
2020-02-08T02:29:47.173643: step 1159, loss 0.245644, acc 0.90625
2020-02-08T02:29:47.290553: step 1160, loss 0.326152, acc 0.84375
2020-02-08T02:29:47.407559: step 1161, loss 0.362454, acc 0.796875
2020-02-08T02:29:47.523663: step 1162, loss 0.281188, acc 0.890625
2020-02-08T02:29:47.642334: step 1163, loss 0.246151, acc 0.859375
2020-02-08T02:29:47.760520: step 1164, loss 0.446466, acc 0.828125
2020-02-08T02:29:47.876878: step 1165, loss 0.284384, acc 0.859375
2020-02-08T02:29:47.994628: step 1166, loss 0.32165, acc 0.859375
2020-02-08T02:29:48.111055: step 1167, loss 0.262071, acc 0.890625
2020-02-08T02:29:48.226530: step 1168, loss 0.271641, acc 0.84375
2020-02-08T02:29:48.342703: step 1169, loss 0.378588, acc 0.84375
2020-02-08T02:29:48.461485: step 1170, loss 0.336072, acc 0.875
2020-02-08T02:29:48.578480: step 1171, loss 0.264273, acc 0.90625
2020-02-08T02:29:48.700567: step 1172, loss 0.284657, acc 0.859375
2020-02-08T02:29:48.819725: step 1173, loss 0.418841, acc 0.765625
2020-02-08T02:29:48.936109: step 1174, loss 0.178589, acc 0.953125
2020-02-08T02:29:49.052848: step 1175, loss 0.388558, acc 0.796875
2020-02-08T02:29:49.170506: step 1176, loss 0.244823, acc 0.90625
2020-02-08T02:29:49.286900: step 1177, loss 0.275429, acc 0.890625
2020-02-08T02:29:49.404625: step 1178, loss 0.341518, acc 0.875
2020-02-08T02:29:49.521034: step 1179, loss 0.246638, acc 0.921875
2020-02-08T02:29:49.641773: step 1180, loss 0.312318, acc 0.859375
2020-02-08T02:29:49.761917: step 1181, loss 0.483308, acc 0.796875
2020-02-08T02:29:49.879060: step 1182, loss 0.163314, acc 0.984375
2020-02-08T02:29:49.998011: step 1183, loss 0.237816, acc 0.890625
2020-02-08T02:29:50.115228: step 1184, loss 0.246227, acc 0.890625
2020-02-08T02:29:50.234765: step 1185, loss 0.303591, acc 0.90625
2020-02-08T02:29:50.355032: step 1186, loss 0.250458, acc 0.90625
2020-02-08T02:29:50.470632: step 1187, loss 0.227527, acc 0.90625
2020-02-08T02:29:50.587102: step 1188, loss 0.203219, acc 0.9375
2020-02-08T02:29:50.708503: step 1189, loss 0.347255, acc 0.859375
2020-02-08T02:29:50.827557: step 1190, loss 0.278209, acc 0.875
2020-02-08T02:29:50.946832: step 1191, loss 0.252497, acc 0.9375
2020-02-08T02:29:51.065053: step 1192, loss 0.293266, acc 0.890625
2020-02-08T02:29:51.182884: step 1193, loss 0.245869, acc 0.90625
2020-02-08T02:29:51.421879: step 1194, loss 0.441881, acc 0.78125
2020-02-08T02:29:51.540464: step 1195, loss 0.311466, acc 0.90625
2020-02-08T02:29:51.658119: step 1196, loss 0.414084, acc 0.828125
2020-02-08T02:29:51.780377: step 1197, loss 0.251719, acc 0.890625
2020-02-08T02:29:51.900031: step 1198, loss 0.298259, acc 0.875
2020-02-08T02:29:52.018125: step 1199, loss 0.297331, acc 0.875
2020-02-08T02:29:52.132698: step 1200, loss 0.268208, acc 0.9

Evaluation:
2020-02-08T02:29:52.325693: step 1200, loss 0.590016, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1200

2020-02-08T02:29:53.881589: step 1201, loss 0.174363, acc 0.9375
2020-02-08T02:29:53.997501: step 1202, loss 0.156097, acc 0.96875
2020-02-08T02:29:54.112300: step 1203, loss 0.207564, acc 0.96875
2020-02-08T02:29:54.230014: step 1204, loss 0.226547, acc 0.875
2020-02-08T02:29:54.348899: step 1205, loss 0.224808, acc 0.9375
2020-02-08T02:29:54.465030: step 1206, loss 0.266567, acc 0.90625
2020-02-08T02:29:54.581553: step 1207, loss 0.165812, acc 0.953125
2020-02-08T02:29:54.707906: step 1208, loss 0.16708, acc 0.953125
2020-02-08T02:29:54.824672: step 1209, loss 0.245954, acc 0.890625
2020-02-08T02:29:54.945200: step 1210, loss 0.266585, acc 0.890625
2020-02-08T02:29:55.063462: step 1211, loss 0.271534, acc 0.84375
2020-02-08T02:29:55.178046: step 1212, loss 0.208931, acc 0.921875
2020-02-08T02:29:55.298537: step 1213, loss 0.154291, acc 0.953125
2020-02-08T02:29:55.413909: step 1214, loss 0.146962, acc 0.96875
2020-02-08T02:29:55.531496: step 1215, loss 0.195865, acc 0.90625
2020-02-08T02:29:55.650727: step 1216, loss 0.221545, acc 0.875
2020-02-08T02:29:55.770320: step 1217, loss 0.234983, acc 0.921875
2020-02-08T02:29:55.889369: step 1218, loss 0.267748, acc 0.890625
2020-02-08T02:29:56.008204: step 1219, loss 0.22122, acc 0.875
2020-02-08T02:29:56.125665: step 1220, loss 0.239753, acc 0.90625
2020-02-08T02:29:56.246881: step 1221, loss 0.182644, acc 0.921875
2020-02-08T02:29:56.363441: step 1222, loss 0.203403, acc 0.890625
2020-02-08T02:29:56.482913: step 1223, loss 0.243997, acc 0.90625
2020-02-08T02:29:56.605145: step 1224, loss 0.286948, acc 0.921875
2020-02-08T02:29:56.723957: step 1225, loss 0.280628, acc 0.875
2020-02-08T02:29:56.845708: step 1226, loss 0.237896, acc 0.875
2020-02-08T02:29:56.963630: step 1227, loss 0.202246, acc 0.890625
2020-02-08T02:29:57.080359: step 1228, loss 0.190337, acc 0.921875
2020-02-08T02:29:57.196664: step 1229, loss 0.266127, acc 0.9375
2020-02-08T02:29:57.315562: step 1230, loss 0.135621, acc 0.9375
2020-02-08T02:29:57.432867: step 1231, loss 0.286053, acc 0.828125
2020-02-08T02:29:57.550027: step 1232, loss 0.193197, acc 0.921875
2020-02-08T02:29:57.665478: step 1233, loss 0.271347, acc 0.921875
2020-02-08T02:29:57.787175: step 1234, loss 0.13265, acc 0.953125
2020-02-08T02:29:57.902756: step 1235, loss 0.213138, acc 0.90625
2020-02-08T02:29:58.018089: step 1236, loss 0.217387, acc 0.9375
2020-02-08T02:29:58.134739: step 1237, loss 0.164817, acc 0.90625
2020-02-08T02:29:58.253439: step 1238, loss 0.411851, acc 0.765625
2020-02-08T02:29:58.369254: step 1239, loss 0.282414, acc 0.890625
2020-02-08T02:29:58.486596: step 1240, loss 0.220509, acc 0.9375
2020-02-08T02:29:58.605189: step 1241, loss 0.190053, acc 0.890625
2020-02-08T02:29:58.725074: step 1242, loss 0.174692, acc 0.96875
2020-02-08T02:29:58.845800: step 1243, loss 0.30664, acc 0.875
2020-02-08T02:29:58.963857: step 1244, loss 0.285106, acc 0.859375
2020-02-08T02:29:59.083064: step 1245, loss 0.20378, acc 0.921875
2020-02-08T02:29:59.212096: step 1246, loss 0.331429, acc 0.875
2020-02-08T02:29:59.343766: step 1247, loss 0.20759, acc 0.9375
2020-02-08T02:29:59.471834: step 1248, loss 0.202128, acc 0.921875
2020-02-08T02:29:59.603813: step 1249, loss 0.149841, acc 0.96875
2020-02-08T02:29:59.735027: step 1250, loss 0.193183, acc 0.921875
2020-02-08T02:29:59.865648: step 1251, loss 0.236658, acc 0.90625
2020-02-08T02:29:59.996902: step 1252, loss 0.261017, acc 0.859375
2020-02-08T02:30:00.116576: step 1253, loss 0.260869, acc 0.90625
2020-02-08T02:30:00.237254: step 1254, loss 0.303598, acc 0.8125
2020-02-08T02:30:00.351441: step 1255, loss 0.195248, acc 0.9375
2020-02-08T02:30:00.467292: step 1256, loss 0.194467, acc 0.921875
2020-02-08T02:30:00.582586: step 1257, loss 0.18756, acc 0.921875
2020-02-08T02:30:00.700637: step 1258, loss 0.292184, acc 0.828125
2020-02-08T02:30:00.816371: step 1259, loss 0.251804, acc 0.875
2020-02-08T02:30:00.933439: step 1260, loss 0.202579, acc 0.9375
2020-02-08T02:30:01.051443: step 1261, loss 0.250731, acc 0.921875
2020-02-08T02:30:01.166588: step 1262, loss 0.182315, acc 0.921875
2020-02-08T02:30:01.281732: step 1263, loss 0.30402, acc 0.859375
2020-02-08T02:30:01.398909: step 1264, loss 0.21256, acc 0.921875
2020-02-08T02:30:01.514549: step 1265, loss 0.26303, acc 0.890625
2020-02-08T02:30:01.631099: step 1266, loss 0.249362, acc 0.890625
2020-02-08T02:30:01.753979: step 1267, loss 0.251007, acc 0.875
2020-02-08T02:30:01.869636: step 1268, loss 0.257387, acc 0.90625
2020-02-08T02:30:01.985713: step 1269, loss 0.268939, acc 0.875
2020-02-08T02:30:02.102277: step 1270, loss 0.219077, acc 0.90625
2020-02-08T02:30:02.216096: step 1271, loss 0.224837, acc 0.9375
2020-02-08T02:30:02.332810: step 1272, loss 0.147952, acc 0.9375
2020-02-08T02:30:02.450310: step 1273, loss 0.247605, acc 0.890625
2020-02-08T02:30:02.564139: step 1274, loss 0.1858, acc 0.890625
2020-02-08T02:30:02.686004: step 1275, loss 0.183395, acc 0.9375
2020-02-08T02:30:02.803486: step 1276, loss 0.229595, acc 0.9375
2020-02-08T02:30:02.918980: step 1277, loss 0.228358, acc 0.890625
2020-02-08T02:30:03.033531: step 1278, loss 0.206178, acc 0.890625
2020-02-08T02:30:03.153263: step 1279, loss 0.224244, acc 0.921875
2020-02-08T02:30:03.268160: step 1280, loss 0.182137, acc 0.921875
2020-02-08T02:30:03.387607: step 1281, loss 0.295287, acc 0.859375
2020-02-08T02:30:03.504248: step 1282, loss 0.238965, acc 0.9375
2020-02-08T02:30:03.618542: step 1283, loss 0.235815, acc 0.875
2020-02-08T02:30:03.742274: step 1284, loss 0.241142, acc 0.9375
2020-02-08T02:30:03.861818: step 1285, loss 0.290244, acc 0.859375
2020-02-08T02:30:03.977519: step 1286, loss 0.137806, acc 0.96875
2020-02-08T02:30:04.095751: step 1287, loss 0.322343, acc 0.8125
2020-02-08T02:30:04.211987: step 1288, loss 0.185033, acc 0.921875
2020-02-08T02:30:04.328478: step 1289, loss 0.309358, acc 0.90625
2020-02-08T02:30:04.449301: step 1290, loss 0.187697, acc 0.90625
2020-02-08T02:30:04.565832: step 1291, loss 0.184485, acc 0.9375
2020-02-08T02:30:04.682399: step 1292, loss 0.114057, acc 0.96875
2020-02-08T02:30:04.799168: step 1293, loss 0.242661, acc 0.921875
2020-02-08T02:30:04.914873: step 1294, loss 0.21029, acc 0.890625
2020-02-08T02:30:05.033067: step 1295, loss 0.245815, acc 0.875
2020-02-08T02:30:05.151900: step 1296, loss 0.173188, acc 0.9375
2020-02-08T02:30:05.268157: step 1297, loss 0.216504, acc 0.90625
2020-02-08T02:30:05.383975: step 1298, loss 0.292582, acc 0.875
2020-02-08T02:30:05.503263: step 1299, loss 0.175934, acc 0.9375
2020-02-08T02:30:05.619723: step 1300, loss 0.272186, acc 0.875

Evaluation:
2020-02-08T02:30:05.812568: step 1300, loss 0.605128, acc 0.708255

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1300

2020-02-08T02:30:07.407095: step 1301, loss 0.287616, acc 0.84375
2020-02-08T02:30:07.521994: step 1302, loss 0.26689, acc 0.890625
2020-02-08T02:30:07.640616: step 1303, loss 0.167806, acc 0.921875
2020-02-08T02:30:07.762158: step 1304, loss 0.279552, acc 0.875
2020-02-08T02:30:07.878632: step 1305, loss 0.30267, acc 0.90625
2020-02-08T02:30:07.995070: step 1306, loss 0.275468, acc 0.90625
2020-02-08T02:30:08.109343: step 1307, loss 0.267218, acc 0.90625
2020-02-08T02:30:08.226268: step 1308, loss 0.177123, acc 0.9375
2020-02-08T02:30:08.343402: step 1309, loss 0.371177, acc 0.84375
2020-02-08T02:30:08.459626: step 1310, loss 0.205392, acc 0.921875
2020-02-08T02:30:08.572650: step 1311, loss 0.237845, acc 0.890625
2020-02-08T02:30:08.689579: step 1312, loss 0.179175, acc 0.921875
2020-02-08T02:30:08.806424: step 1313, loss 0.359059, acc 0.828125
2020-02-08T02:30:08.920159: step 1314, loss 0.226888, acc 0.921875
2020-02-08T02:30:09.037188: step 1315, loss 0.156363, acc 0.9375
2020-02-08T02:30:09.153003: step 1316, loss 0.286487, acc 0.875
2020-02-08T02:30:09.267940: step 1317, loss 0.187883, acc 0.953125
2020-02-08T02:30:09.382040: step 1318, loss 0.193409, acc 0.875
2020-02-08T02:30:09.497515: step 1319, loss 0.214687, acc 0.90625
2020-02-08T02:30:09.612989: step 1320, loss 0.21738, acc 0.90625
2020-02-08T02:30:09.737878: step 1321, loss 0.372774, acc 0.828125
2020-02-08T02:30:09.854546: step 1322, loss 0.285107, acc 0.90625
2020-02-08T02:30:09.970372: step 1323, loss 0.341193, acc 0.90625
2020-02-08T02:30:10.088291: step 1324, loss 0.297398, acc 0.84375
2020-02-08T02:30:10.202267: step 1325, loss 0.261512, acc 0.890625
2020-02-08T02:30:10.317852: step 1326, loss 0.230967, acc 0.921875
2020-02-08T02:30:10.434748: step 1327, loss 0.334415, acc 0.8125
2020-02-08T02:30:10.552667: step 1328, loss 0.276414, acc 0.875
2020-02-08T02:30:10.667094: step 1329, loss 0.260822, acc 0.875
2020-02-08T02:30:10.790300: step 1330, loss 0.262533, acc 0.859375
2020-02-08T02:30:10.906781: step 1331, loss 0.198383, acc 0.90625
2020-02-08T02:30:11.022554: step 1332, loss 0.292115, acc 0.859375
2020-02-08T02:30:11.137573: step 1333, loss 0.245651, acc 0.90625
2020-02-08T02:30:11.253772: step 1334, loss 0.22555, acc 0.890625
2020-02-08T02:30:11.370306: step 1335, loss 0.21056, acc 0.9375
2020-02-08T02:30:11.487011: step 1336, loss 0.195592, acc 0.953125
2020-02-08T02:30:11.603075: step 1337, loss 0.279292, acc 0.921875
2020-02-08T02:30:11.719932: step 1338, loss 0.215402, acc 0.90625
2020-02-08T02:30:11.837640: step 1339, loss 0.297556, acc 0.828125
2020-02-08T02:30:11.955993: step 1340, loss 0.232238, acc 0.890625
2020-02-08T02:30:12.070893: step 1341, loss 0.228654, acc 0.859375
2020-02-08T02:30:12.186734: step 1342, loss 0.235151, acc 0.890625
2020-02-08T02:30:12.304319: step 1343, loss 0.230838, acc 0.90625
2020-02-08T02:30:12.422660: step 1344, loss 0.146549, acc 0.953125
2020-02-08T02:30:12.539610: step 1345, loss 0.23674, acc 0.890625
2020-02-08T02:30:12.657625: step 1346, loss 0.1869, acc 0.90625
2020-02-08T02:30:12.777033: step 1347, loss 0.178118, acc 0.953125
2020-02-08T02:30:12.897531: step 1348, loss 0.208297, acc 0.9375
2020-02-08T02:30:13.011407: step 1349, loss 0.169662, acc 0.9375
2020-02-08T02:30:13.121629: step 1350, loss 0.200175, acc 0.883333
2020-02-08T02:30:13.239963: step 1351, loss 0.247877, acc 0.890625
2020-02-08T02:30:13.357396: step 1352, loss 0.145218, acc 0.953125
2020-02-08T02:30:13.473512: step 1353, loss 0.216041, acc 0.890625
2020-02-08T02:30:13.593891: step 1354, loss 0.125947, acc 0.96875
2020-02-08T02:30:13.712318: step 1355, loss 0.225969, acc 0.90625
2020-02-08T02:30:13.828889: step 1356, loss 0.111774, acc 0.953125
2020-02-08T02:30:13.946286: step 1357, loss 0.215096, acc 0.921875
2020-02-08T02:30:14.064065: step 1358, loss 0.200209, acc 0.921875
2020-02-08T02:30:14.178540: step 1359, loss 0.204953, acc 0.9375
2020-02-08T02:30:14.295658: step 1360, loss 0.23582, acc 0.890625
2020-02-08T02:30:14.412272: step 1361, loss 0.166021, acc 0.9375
2020-02-08T02:30:14.530876: step 1362, loss 0.143231, acc 0.984375
2020-02-08T02:30:14.648252: step 1363, loss 0.180995, acc 0.9375
2020-02-08T02:30:14.766997: step 1364, loss 0.215445, acc 0.953125
2020-02-08T02:30:14.884152: step 1365, loss 0.116567, acc 0.984375
2020-02-08T02:30:15.002673: step 1366, loss 0.203315, acc 0.953125
2020-02-08T02:30:15.118205: step 1367, loss 0.12141, acc 0.9375
2020-02-08T02:30:15.236390: step 1368, loss 0.144979, acc 0.953125
2020-02-08T02:30:15.352310: step 1369, loss 0.298802, acc 0.890625
2020-02-08T02:30:15.468598: step 1370, loss 0.207553, acc 0.921875
2020-02-08T02:30:15.586217: step 1371, loss 0.148023, acc 0.953125
2020-02-08T02:30:15.705472: step 1372, loss 0.0986535, acc 0.984375
2020-02-08T02:30:15.823282: step 1373, loss 0.230394, acc 0.90625
2020-02-08T02:30:15.940958: step 1374, loss 0.173999, acc 0.953125
2020-02-08T02:30:16.056858: step 1375, loss 0.152766, acc 0.9375
2020-02-08T02:30:16.171564: step 1376, loss 0.223594, acc 0.890625
2020-02-08T02:30:16.288810: step 1377, loss 0.159951, acc 0.96875
2020-02-08T02:30:16.404967: step 1378, loss 0.116208, acc 0.953125
2020-02-08T02:30:16.518714: step 1379, loss 0.102058, acc 0.96875
2020-02-08T02:30:16.634276: step 1380, loss 0.176059, acc 0.921875
2020-02-08T02:30:16.755710: step 1381, loss 0.161439, acc 0.953125
2020-02-08T02:30:16.869178: step 1382, loss 0.148611, acc 0.953125
2020-02-08T02:30:16.986324: step 1383, loss 0.164109, acc 0.984375
2020-02-08T02:30:17.103078: step 1384, loss 0.248721, acc 0.90625
2020-02-08T02:30:17.218865: step 1385, loss 0.164969, acc 0.953125
2020-02-08T02:30:17.335013: step 1386, loss 0.239075, acc 0.890625
2020-02-08T02:30:17.450117: step 1387, loss 0.204732, acc 0.921875
2020-02-08T02:30:17.569932: step 1388, loss 0.208952, acc 0.921875
2020-02-08T02:30:17.687794: step 1389, loss 0.152652, acc 0.9375
2020-02-08T02:30:17.805971: step 1390, loss 0.262526, acc 0.921875
2020-02-08T02:30:17.921593: step 1391, loss 0.209087, acc 0.953125
2020-02-08T02:30:18.039070: step 1392, loss 0.188195, acc 0.90625
2020-02-08T02:30:18.157709: step 1393, loss 0.148496, acc 0.953125
2020-02-08T02:30:18.274438: step 1394, loss 0.146874, acc 0.96875
2020-02-08T02:30:18.390732: step 1395, loss 0.223112, acc 0.90625
2020-02-08T02:30:18.510616: step 1396, loss 0.194205, acc 0.9375
2020-02-08T02:30:18.625074: step 1397, loss 0.149288, acc 0.9375
2020-02-08T02:30:18.746853: step 1398, loss 0.16165, acc 0.921875
2020-02-08T02:30:18.864914: step 1399, loss 0.226716, acc 0.875
2020-02-08T02:30:18.983010: step 1400, loss 0.250159, acc 0.9375

Evaluation:
2020-02-08T02:30:19.173585: step 1400, loss 0.63328, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1400

2020-02-08T02:30:20.687430: step 1401, loss 0.23222, acc 0.90625
2020-02-08T02:30:20.803677: step 1402, loss 0.167772, acc 0.96875
2020-02-08T02:30:20.922142: step 1403, loss 0.190904, acc 0.921875
2020-02-08T02:30:21.038408: step 1404, loss 0.265435, acc 0.921875
2020-02-08T02:30:21.159621: step 1405, loss 0.140217, acc 0.90625
2020-02-08T02:30:21.275732: step 1406, loss 0.18597, acc 0.953125
2020-02-08T02:30:21.387627: step 1407, loss 0.188006, acc 0.90625
2020-02-08T02:30:21.699742: step 1408, loss 0.169529, acc 0.921875
2020-02-08T02:30:21.816923: step 1409, loss 0.267885, acc 0.890625
2020-02-08T02:30:21.935008: step 1410, loss 0.21091, acc 0.921875
2020-02-08T02:30:22.053174: step 1411, loss 0.0745513, acc 0.984375
2020-02-08T02:30:22.170839: step 1412, loss 0.26826, acc 0.890625
2020-02-08T02:30:22.284358: step 1413, loss 0.164807, acc 0.9375
2020-02-08T02:30:22.403507: step 1414, loss 0.188454, acc 0.921875
2020-02-08T02:30:22.520131: step 1415, loss 0.217632, acc 0.90625
2020-02-08T02:30:22.639138: step 1416, loss 0.141434, acc 0.96875
2020-02-08T02:30:22.759884: step 1417, loss 0.235133, acc 0.875
2020-02-08T02:30:22.873460: step 1418, loss 0.19354, acc 0.9375
2020-02-08T02:30:22.988747: step 1419, loss 0.181117, acc 0.9375
2020-02-08T02:30:23.108978: step 1420, loss 0.170397, acc 0.875
2020-02-08T02:30:23.223515: step 1421, loss 0.275034, acc 0.828125
2020-02-08T02:30:23.338980: step 1422, loss 0.182756, acc 0.90625
2020-02-08T02:30:23.453482: step 1423, loss 0.107097, acc 0.96875
2020-02-08T02:30:23.566928: step 1424, loss 0.103519, acc 0.953125
2020-02-08T02:30:23.683663: step 1425, loss 0.208645, acc 0.875
2020-02-08T02:30:23.801408: step 1426, loss 0.10794, acc 0.953125
2020-02-08T02:30:23.919748: step 1427, loss 0.148184, acc 0.953125
2020-02-08T02:30:24.037667: step 1428, loss 0.16968, acc 0.9375
2020-02-08T02:30:24.156619: step 1429, loss 0.224976, acc 0.921875
2020-02-08T02:30:24.271503: step 1430, loss 0.151583, acc 0.9375
2020-02-08T02:30:24.388712: step 1431, loss 0.185511, acc 0.921875
2020-02-08T02:30:24.505484: step 1432, loss 0.20517, acc 0.9375
2020-02-08T02:30:24.620884: step 1433, loss 0.11633, acc 0.96875
2020-02-08T02:30:24.743995: step 1434, loss 0.148492, acc 0.90625
2020-02-08T02:30:24.860484: step 1435, loss 0.122631, acc 0.96875
2020-02-08T02:30:24.977514: step 1436, loss 0.189992, acc 0.9375
2020-02-08T02:30:25.093208: step 1437, loss 0.169824, acc 0.953125
2020-02-08T02:30:25.209425: step 1438, loss 0.190353, acc 0.9375
2020-02-08T02:30:25.324372: step 1439, loss 0.286955, acc 0.90625
2020-02-08T02:30:25.441596: step 1440, loss 0.269546, acc 0.90625
2020-02-08T02:30:25.558233: step 1441, loss 0.201542, acc 0.9375
2020-02-08T02:30:25.674234: step 1442, loss 0.173908, acc 0.9375
2020-02-08T02:30:25.801339: step 1443, loss 0.282274, acc 0.875
2020-02-08T02:30:25.916722: step 1444, loss 0.23046, acc 0.921875
2020-02-08T02:30:26.034336: step 1445, loss 0.186969, acc 0.953125
2020-02-08T02:30:26.152222: step 1446, loss 0.17499, acc 0.921875
2020-02-08T02:30:26.268454: step 1447, loss 0.163598, acc 0.96875
2020-02-08T02:30:26.383468: step 1448, loss 0.299971, acc 0.875
2020-02-08T02:30:26.502365: step 1449, loss 0.21411, acc 0.90625
2020-02-08T02:30:26.618875: step 1450, loss 0.175101, acc 0.953125
2020-02-08T02:30:26.741339: step 1451, loss 0.248776, acc 0.875
2020-02-08T02:30:26.856992: step 1452, loss 0.203386, acc 0.921875
2020-02-08T02:30:26.975014: step 1453, loss 0.142829, acc 0.9375
2020-02-08T02:30:27.095546: step 1454, loss 0.157344, acc 0.90625
2020-02-08T02:30:27.214045: step 1455, loss 0.232258, acc 0.875
2020-02-08T02:30:27.332902: step 1456, loss 0.227563, acc 0.953125
2020-02-08T02:30:27.452313: step 1457, loss 0.186659, acc 0.90625
2020-02-08T02:30:27.567095: step 1458, loss 0.132501, acc 0.96875
2020-02-08T02:30:27.689384: step 1459, loss 0.130776, acc 0.96875
2020-02-08T02:30:27.809806: step 1460, loss 0.216955, acc 0.890625
2020-02-08T02:30:27.923137: step 1461, loss 0.225374, acc 0.890625
2020-02-08T02:30:28.040350: step 1462, loss 0.193235, acc 0.921875
2020-02-08T02:30:28.158319: step 1463, loss 0.202979, acc 0.953125
2020-02-08T02:30:28.276147: step 1464, loss 0.115232, acc 0.96875
2020-02-08T02:30:28.393736: step 1465, loss 0.159434, acc 0.9375
2020-02-08T02:30:28.510836: step 1466, loss 0.0929935, acc 0.984375
2020-02-08T02:30:28.627019: step 1467, loss 0.172151, acc 0.921875
2020-02-08T02:30:28.750088: step 1468, loss 0.119157, acc 0.953125
2020-02-08T02:30:28.866445: step 1469, loss 0.199523, acc 0.90625
2020-02-08T02:30:28.982746: step 1470, loss 0.144919, acc 0.9375
2020-02-08T02:30:29.100391: step 1471, loss 0.216975, acc 0.921875
2020-02-08T02:30:29.217704: step 1472, loss 0.14733, acc 0.9375
2020-02-08T02:30:29.336026: step 1473, loss 0.213478, acc 0.90625
2020-02-08T02:30:29.452549: step 1474, loss 0.180034, acc 0.9375
2020-02-08T02:30:29.570526: step 1475, loss 0.256791, acc 0.875
2020-02-08T02:30:29.691325: step 1476, loss 0.229991, acc 0.890625
2020-02-08T02:30:29.808224: step 1477, loss 0.159347, acc 0.9375
2020-02-08T02:30:29.923257: step 1478, loss 0.0836266, acc 0.96875
2020-02-08T02:30:30.041861: step 1479, loss 0.167054, acc 0.9375
2020-02-08T02:30:30.159137: step 1480, loss 0.178042, acc 0.953125
2020-02-08T02:30:30.279040: step 1481, loss 0.197612, acc 0.875
2020-02-08T02:30:30.397471: step 1482, loss 0.158669, acc 0.953125
2020-02-08T02:30:30.514647: step 1483, loss 0.181122, acc 0.921875
2020-02-08T02:30:30.633266: step 1484, loss 0.121352, acc 0.953125
2020-02-08T02:30:30.754877: step 1485, loss 0.08611, acc 0.984375
2020-02-08T02:30:30.869187: step 1486, loss 0.101828, acc 0.984375
2020-02-08T02:30:30.987820: step 1487, loss 0.259969, acc 0.90625
2020-02-08T02:30:31.105234: step 1488, loss 0.199471, acc 0.96875
2020-02-08T02:30:31.221465: step 1489, loss 0.175701, acc 0.921875
2020-02-08T02:30:31.336858: step 1490, loss 0.241184, acc 0.875
2020-02-08T02:30:31.457629: step 1491, loss 0.0767985, acc 1
2020-02-08T02:30:31.571259: step 1492, loss 0.323589, acc 0.828125
2020-02-08T02:30:31.691914: step 1493, loss 0.345971, acc 0.90625
2020-02-08T02:30:31.810641: step 1494, loss 0.124109, acc 0.953125
2020-02-08T02:30:31.926932: step 1495, loss 0.237207, acc 0.890625
2020-02-08T02:30:32.044694: step 1496, loss 0.139942, acc 0.953125
2020-02-08T02:30:32.162988: step 1497, loss 0.203538, acc 0.921875
2020-02-08T02:30:32.279717: step 1498, loss 0.178699, acc 0.921875
2020-02-08T02:30:32.400445: step 1499, loss 0.230473, acc 0.875
2020-02-08T02:30:32.516915: step 1500, loss 0.162419, acc 0.916667

Evaluation:
2020-02-08T02:30:32.714495: step 1500, loss 0.642819, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1500

2020-02-08T02:30:34.969775: step 1501, loss 0.118343, acc 0.96875
2020-02-08T02:30:35.088022: step 1502, loss 0.268823, acc 0.890625
2020-02-08T02:30:35.205161: step 1503, loss 0.0538859, acc 1
2020-02-08T02:30:35.319873: step 1504, loss 0.16531, acc 0.96875
2020-02-08T02:30:35.437666: step 1505, loss 0.137073, acc 0.9375
2020-02-08T02:30:35.554742: step 1506, loss 0.079809, acc 0.96875
2020-02-08T02:30:35.669657: step 1507, loss 0.103939, acc 0.953125
2020-02-08T02:30:35.790652: step 1508, loss 0.148864, acc 0.9375
2020-02-08T02:30:35.908781: step 1509, loss 0.0877068, acc 0.96875
2020-02-08T02:30:36.026524: step 1510, loss 0.154113, acc 0.953125
2020-02-08T02:30:36.141840: step 1511, loss 0.167849, acc 0.921875
2020-02-08T02:30:36.259606: step 1512, loss 0.173935, acc 0.9375
2020-02-08T02:30:36.376742: step 1513, loss 0.052915, acc 1
2020-02-08T02:30:36.494417: step 1514, loss 0.172269, acc 0.921875
2020-02-08T02:30:36.613087: step 1515, loss 0.097673, acc 0.96875
2020-02-08T02:30:36.730829: step 1516, loss 0.116829, acc 0.9375
2020-02-08T02:30:36.848326: step 1517, loss 0.113317, acc 0.96875
2020-02-08T02:30:36.964800: step 1518, loss 0.199052, acc 0.921875
2020-02-08T02:30:37.077863: step 1519, loss 0.131559, acc 0.96875
2020-02-08T02:30:37.194784: step 1520, loss 0.138607, acc 0.953125
2020-02-08T02:30:37.309284: step 1521, loss 0.0930215, acc 0.984375
2020-02-08T02:30:37.423257: step 1522, loss 0.178631, acc 0.953125
2020-02-08T02:30:37.542444: step 1523, loss 0.169451, acc 0.921875
2020-02-08T02:30:37.657647: step 1524, loss 0.154102, acc 0.921875
2020-02-08T02:30:37.781805: step 1525, loss 0.142034, acc 0.953125
2020-02-08T02:30:37.897996: step 1526, loss 0.119542, acc 0.953125
2020-02-08T02:30:38.016392: step 1527, loss 0.0749773, acc 0.96875
2020-02-08T02:30:38.132520: step 1528, loss 0.169621, acc 0.9375
2020-02-08T02:30:38.249092: step 1529, loss 0.119457, acc 0.96875
2020-02-08T02:30:38.364933: step 1530, loss 0.167784, acc 0.921875
2020-02-08T02:30:38.480308: step 1531, loss 0.160398, acc 0.953125
2020-02-08T02:30:38.599042: step 1532, loss 0.089164, acc 0.984375
2020-02-08T02:30:38.717083: step 1533, loss 0.136345, acc 0.953125
2020-02-08T02:30:38.834119: step 1534, loss 0.0981391, acc 0.953125
2020-02-08T02:30:38.950749: step 1535, loss 0.1442, acc 0.96875
2020-02-08T02:30:39.068861: step 1536, loss 0.23264, acc 0.890625
2020-02-08T02:30:39.181733: step 1537, loss 0.169662, acc 0.90625
2020-02-08T02:30:39.298351: step 1538, loss 0.0979701, acc 0.984375
2020-02-08T02:30:39.413924: step 1539, loss 0.215621, acc 0.921875
2020-02-08T02:30:39.530474: step 1540, loss 0.177998, acc 0.90625
2020-02-08T02:30:39.645691: step 1541, loss 0.139846, acc 0.984375
2020-02-08T02:30:39.765982: step 1542, loss 0.0568404, acc 0.984375
2020-02-08T02:30:39.883687: step 1543, loss 0.142245, acc 0.953125
2020-02-08T02:30:40.001604: step 1544, loss 0.107569, acc 0.953125
2020-02-08T02:30:40.118736: step 1545, loss 0.187592, acc 0.9375
2020-02-08T02:30:40.238104: step 1546, loss 0.156726, acc 0.9375
2020-02-08T02:30:40.356747: step 1547, loss 0.158149, acc 0.953125
2020-02-08T02:30:40.472184: step 1548, loss 0.145098, acc 0.9375
2020-02-08T02:30:40.590830: step 1549, loss 0.125498, acc 0.921875
2020-02-08T02:30:40.708418: step 1550, loss 0.233355, acc 0.90625
2020-02-08T02:30:40.823787: step 1551, loss 0.185447, acc 0.90625
2020-02-08T02:30:40.940137: step 1552, loss 0.081873, acc 0.96875
2020-02-08T02:30:41.056855: step 1553, loss 0.106387, acc 0.9375
2020-02-08T02:30:41.173864: step 1554, loss 0.10961, acc 0.96875
2020-02-08T02:30:41.292733: step 1555, loss 0.0959193, acc 0.953125
2020-02-08T02:30:41.409976: step 1556, loss 0.0949454, acc 0.984375
2020-02-08T02:30:41.523977: step 1557, loss 0.129334, acc 0.9375
2020-02-08T02:30:41.644013: step 1558, loss 0.133033, acc 0.921875
2020-02-08T02:30:41.765753: step 1559, loss 0.120714, acc 0.9375
2020-02-08T02:30:41.882310: step 1560, loss 0.104251, acc 0.96875
2020-02-08T02:30:41.998791: step 1561, loss 0.141301, acc 0.90625
2020-02-08T02:30:42.114386: step 1562, loss 0.141786, acc 0.953125
2020-02-08T02:30:42.230122: step 1563, loss 0.159367, acc 0.953125
2020-02-08T02:30:42.349204: step 1564, loss 0.0864549, acc 0.984375
2020-02-08T02:30:42.467809: step 1565, loss 0.169049, acc 0.921875
2020-02-08T02:30:42.586185: step 1566, loss 0.0790282, acc 0.96875
2020-02-08T02:30:42.705952: step 1567, loss 0.0964712, acc 0.953125
2020-02-08T02:30:42.821929: step 1568, loss 0.0987402, acc 0.96875
2020-02-08T02:30:42.939284: step 1569, loss 0.201282, acc 0.890625
2020-02-08T02:30:43.057600: step 1570, loss 0.0757531, acc 1
2020-02-08T02:30:43.171375: step 1571, loss 0.192673, acc 0.921875
2020-02-08T02:30:43.290667: step 1572, loss 0.0947171, acc 0.96875
2020-02-08T02:30:43.409192: step 1573, loss 0.0831803, acc 0.984375
2020-02-08T02:30:43.523537: step 1574, loss 0.19248, acc 0.921875
2020-02-08T02:30:43.639642: step 1575, loss 0.11035, acc 0.96875
2020-02-08T02:30:43.760936: step 1576, loss 0.108634, acc 0.984375
2020-02-08T02:30:43.878258: step 1577, loss 0.0762409, acc 0.984375
2020-02-08T02:30:43.995162: step 1578, loss 0.213553, acc 0.9375
2020-02-08T02:30:44.110304: step 1579, loss 0.135987, acc 0.953125
2020-02-08T02:30:44.228411: step 1580, loss 0.171481, acc 0.96875
2020-02-08T02:30:44.346109: step 1581, loss 0.0762071, acc 0.96875
2020-02-08T02:30:44.462380: step 1582, loss 0.0658489, acc 0.984375
2020-02-08T02:30:44.580106: step 1583, loss 0.081356, acc 0.984375
2020-02-08T02:30:44.698102: step 1584, loss 0.181046, acc 0.921875
2020-02-08T02:30:44.815239: step 1585, loss 0.104511, acc 0.953125
2020-02-08T02:30:44.932964: step 1586, loss 0.100393, acc 0.96875
2020-02-08T02:30:45.051856: step 1587, loss 0.142532, acc 0.953125
2020-02-08T02:30:45.166408: step 1588, loss 0.0748854, acc 0.96875
2020-02-08T02:30:45.280633: step 1589, loss 0.184983, acc 0.96875
2020-02-08T02:30:45.397694: step 1590, loss 0.137181, acc 0.921875
2020-02-08T02:30:45.513172: step 1591, loss 0.168989, acc 0.90625
2020-02-08T02:30:45.629325: step 1592, loss 0.192563, acc 0.90625
2020-02-08T02:30:45.753598: step 1593, loss 0.180185, acc 0.921875
2020-02-08T02:30:45.870408: step 1594, loss 0.121728, acc 0.953125
2020-02-08T02:30:45.989808: step 1595, loss 0.131376, acc 0.96875
2020-02-08T02:30:46.109322: step 1596, loss 0.0243915, acc 1
2020-02-08T02:30:46.225032: step 1597, loss 0.0826364, acc 0.96875
2020-02-08T02:30:46.341146: step 1598, loss 0.139623, acc 0.953125
2020-02-08T02:30:46.459337: step 1599, loss 0.180868, acc 0.9375
2020-02-08T02:30:46.576067: step 1600, loss 0.159708, acc 0.90625

Evaluation:
2020-02-08T02:30:46.768834: step 1600, loss 0.649155, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1600

2020-02-08T02:30:49.059273: step 1601, loss 0.114978, acc 0.96875
2020-02-08T02:30:49.175237: step 1602, loss 0.169087, acc 0.90625
2020-02-08T02:30:49.293325: step 1603, loss 0.172351, acc 0.9375
2020-02-08T02:30:49.410941: step 1604, loss 0.155323, acc 0.953125
2020-02-08T02:30:49.524184: step 1605, loss 0.176855, acc 0.890625
2020-02-08T02:30:49.641211: step 1606, loss 0.0934375, acc 0.984375
2020-02-08T02:30:49.762955: step 1607, loss 0.0822467, acc 0.96875
2020-02-08T02:30:49.886356: step 1608, loss 0.281362, acc 0.875
2020-02-08T02:30:50.002221: step 1609, loss 0.072066, acc 0.984375
2020-02-08T02:30:50.125356: step 1610, loss 0.167491, acc 0.90625
2020-02-08T02:30:50.244731: step 1611, loss 0.183901, acc 0.9375
2020-02-08T02:30:50.363194: step 1612, loss 0.138279, acc 0.9375
2020-02-08T02:30:50.483003: step 1613, loss 0.193283, acc 0.90625
2020-02-08T02:30:50.598088: step 1614, loss 0.14658, acc 0.96875
2020-02-08T02:30:50.717226: step 1615, loss 0.144557, acc 0.921875
2020-02-08T02:30:50.834280: step 1616, loss 0.228602, acc 0.9375
2020-02-08T02:30:50.948839: step 1617, loss 0.238632, acc 0.859375
2020-02-08T02:30:51.065807: step 1618, loss 0.128247, acc 0.953125
2020-02-08T02:30:51.180304: step 1619, loss 0.184253, acc 0.921875
2020-02-08T02:30:51.300556: step 1620, loss 0.142606, acc 0.96875
2020-02-08T02:30:51.418317: step 1621, loss 0.129283, acc 0.96875
2020-02-08T02:30:51.654507: step 1622, loss 0.183441, acc 0.921875
2020-02-08T02:30:51.786660: step 1623, loss 0.0988528, acc 0.96875
2020-02-08T02:30:51.902252: step 1624, loss 0.0826071, acc 0.96875
2020-02-08T02:30:52.019765: step 1625, loss 0.180978, acc 0.90625
2020-02-08T02:30:52.137116: step 1626, loss 0.0568494, acc 0.984375
2020-02-08T02:30:52.253655: step 1627, loss 0.162704, acc 0.953125
2020-02-08T02:30:52.370245: step 1628, loss 0.181246, acc 0.9375
2020-02-08T02:30:52.487447: step 1629, loss 0.2075, acc 0.9375
2020-02-08T02:30:52.603877: step 1630, loss 0.110527, acc 0.9375
2020-02-08T02:30:52.723441: step 1631, loss 0.160145, acc 0.953125
2020-02-08T02:30:52.837255: step 1632, loss 0.112081, acc 0.953125
2020-02-08T02:30:52.953824: step 1633, loss 0.0758726, acc 0.96875
2020-02-08T02:30:53.070343: step 1634, loss 0.118482, acc 0.96875
2020-02-08T02:30:53.187159: step 1635, loss 0.194137, acc 0.953125
2020-02-08T02:30:53.304018: step 1636, loss 0.184997, acc 0.921875
2020-02-08T02:30:53.419652: step 1637, loss 0.156492, acc 0.921875
2020-02-08T02:30:53.535700: step 1638, loss 0.0684967, acc 0.96875
2020-02-08T02:30:53.654441: step 1639, loss 0.205706, acc 0.890625
2020-02-08T02:30:53.776459: step 1640, loss 0.0905191, acc 0.953125
2020-02-08T02:30:53.892766: step 1641, loss 0.172319, acc 0.96875
2020-02-08T02:30:54.010709: step 1642, loss 0.233888, acc 0.875
2020-02-08T02:30:54.127703: step 1643, loss 0.144444, acc 0.921875
2020-02-08T02:30:54.247219: step 1644, loss 0.217771, acc 0.9375
2020-02-08T02:30:54.365474: step 1645, loss 0.150996, acc 0.9375
2020-02-08T02:30:54.481452: step 1646, loss 0.160641, acc 0.890625
2020-02-08T02:30:54.597645: step 1647, loss 0.142875, acc 0.96875
2020-02-08T02:30:54.716039: step 1648, loss 0.111573, acc 0.984375
2020-02-08T02:30:54.835038: step 1649, loss 0.127519, acc 0.953125
2020-02-08T02:30:54.947232: step 1650, loss 0.205806, acc 0.933333
2020-02-08T02:30:55.069607: step 1651, loss 0.0594905, acc 0.984375
2020-02-08T02:30:55.187531: step 1652, loss 0.18175, acc 0.921875
2020-02-08T02:30:55.305844: step 1653, loss 0.119728, acc 0.96875
2020-02-08T02:30:55.422600: step 1654, loss 0.134712, acc 0.9375
2020-02-08T02:30:55.539381: step 1655, loss 0.192841, acc 0.921875
2020-02-08T02:30:55.656424: step 1656, loss 0.0949561, acc 0.984375
2020-02-08T02:30:55.780020: step 1657, loss 0.15647, acc 0.9375
2020-02-08T02:30:55.899541: step 1658, loss 0.0547502, acc 0.984375
2020-02-08T02:30:56.014850: step 1659, loss 0.16054, acc 0.953125
2020-02-08T02:30:56.132027: step 1660, loss 0.0997479, acc 0.96875
2020-02-08T02:30:56.250072: step 1661, loss 0.19995, acc 0.953125
2020-02-08T02:30:56.366586: step 1662, loss 0.100434, acc 0.96875
2020-02-08T02:30:56.482607: step 1663, loss 0.0589542, acc 1
2020-02-08T02:30:56.599425: step 1664, loss 0.111679, acc 0.9375
2020-02-08T02:30:56.718847: step 1665, loss 0.121839, acc 0.953125
2020-02-08T02:30:56.836797: step 1666, loss 0.0808019, acc 0.984375
2020-02-08T02:30:56.951841: step 1667, loss 0.150783, acc 0.96875
2020-02-08T02:30:57.069697: step 1668, loss 0.0918451, acc 0.96875
2020-02-08T02:30:57.188125: step 1669, loss 0.0500761, acc 0.96875
2020-02-08T02:30:57.305633: step 1670, loss 0.134247, acc 0.953125
2020-02-08T02:30:57.420215: step 1671, loss 0.159706, acc 0.953125
2020-02-08T02:30:57.539841: step 1672, loss 0.0985837, acc 0.953125
2020-02-08T02:30:57.655346: step 1673, loss 0.08875, acc 0.984375
2020-02-08T02:30:57.776181: step 1674, loss 0.0892689, acc 0.953125
2020-02-08T02:30:57.894552: step 1675, loss 0.175611, acc 0.9375
2020-02-08T02:30:58.013377: step 1676, loss 0.0981976, acc 0.96875
2020-02-08T02:30:58.129218: step 1677, loss 0.188071, acc 0.890625
2020-02-08T02:30:58.245052: step 1678, loss 0.0714489, acc 0.984375
2020-02-08T02:30:58.361587: step 1679, loss 0.168198, acc 0.921875
2020-02-08T02:30:58.480481: step 1680, loss 0.200972, acc 0.90625
2020-02-08T02:30:58.595684: step 1681, loss 0.100465, acc 0.96875
2020-02-08T02:30:58.714526: step 1682, loss 0.164256, acc 0.9375
2020-02-08T02:30:58.830920: step 1683, loss 0.0981725, acc 0.984375
2020-02-08T02:30:58.950630: step 1684, loss 0.115379, acc 0.9375
2020-02-08T02:30:59.068495: step 1685, loss 0.119578, acc 0.9375
2020-02-08T02:30:59.190663: step 1686, loss 0.102295, acc 0.953125
2020-02-08T02:30:59.309106: step 1687, loss 0.0413514, acc 1
2020-02-08T02:30:59.426790: step 1688, loss 0.113114, acc 0.9375
2020-02-08T02:30:59.549521: step 1689, loss 0.0629602, acc 0.984375
2020-02-08T02:30:59.664426: step 1690, loss 0.0966352, acc 0.96875
2020-02-08T02:30:59.788268: step 1691, loss 0.0880798, acc 0.96875
2020-02-08T02:30:59.905773: step 1692, loss 0.116224, acc 0.953125
2020-02-08T02:31:00.020263: step 1693, loss 0.117365, acc 0.984375
2020-02-08T02:31:00.137831: step 1694, loss 0.124662, acc 0.953125
2020-02-08T02:31:00.254107: step 1695, loss 0.176017, acc 0.921875
2020-02-08T02:31:00.370545: step 1696, loss 0.234364, acc 0.90625
2020-02-08T02:31:00.487221: step 1697, loss 0.144995, acc 0.90625
2020-02-08T02:31:00.603276: step 1698, loss 0.106953, acc 0.953125
2020-02-08T02:31:00.720767: step 1699, loss 0.144582, acc 0.9375
2020-02-08T02:31:00.837900: step 1700, loss 0.124845, acc 0.96875

Evaluation:
2020-02-08T02:31:01.029940: step 1700, loss 0.689039, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1700

2020-02-08T02:31:02.538961: step 1701, loss 0.0690164, acc 0.96875
2020-02-08T02:31:02.657133: step 1702, loss 0.0594676, acc 0.984375
2020-02-08T02:31:02.777070: step 1703, loss 0.0911946, acc 0.953125
2020-02-08T02:31:02.893260: step 1704, loss 0.122075, acc 0.953125
2020-02-08T02:31:03.013587: step 1705, loss 0.142285, acc 0.921875
2020-02-08T02:31:03.128406: step 1706, loss 0.0435253, acc 1
2020-02-08T02:31:03.246362: step 1707, loss 0.108334, acc 0.953125
2020-02-08T02:31:03.362012: step 1708, loss 0.074367, acc 0.96875
2020-02-08T02:31:03.477548: step 1709, loss 0.16877, acc 0.921875
2020-02-08T02:31:03.594451: step 1710, loss 0.113642, acc 0.96875
2020-02-08T02:31:03.716236: step 1711, loss 0.103383, acc 0.96875
2020-02-08T02:31:03.834044: step 1712, loss 0.08136, acc 0.96875
2020-02-08T02:31:03.951481: step 1713, loss 0.0774362, acc 0.96875
2020-02-08T02:31:04.066998: step 1714, loss 0.132893, acc 0.921875
2020-02-08T02:31:04.181758: step 1715, loss 0.0573357, acc 0.984375
2020-02-08T02:31:04.300223: step 1716, loss 0.161197, acc 0.9375
2020-02-08T02:31:04.417007: step 1717, loss 0.123418, acc 0.953125
2020-02-08T02:31:04.535128: step 1718, loss 0.080752, acc 0.953125
2020-02-08T02:31:04.653299: step 1719, loss 0.0530449, acc 1
2020-02-08T02:31:04.774665: step 1720, loss 0.111385, acc 0.96875
2020-02-08T02:31:04.891802: step 1721, loss 0.118667, acc 0.9375
2020-02-08T02:31:05.009308: step 1722, loss 0.108146, acc 0.9375
2020-02-08T02:31:05.127422: step 1723, loss 0.158812, acc 0.9375
2020-02-08T02:31:05.248344: step 1724, loss 0.200767, acc 0.921875
2020-02-08T02:31:05.367799: step 1725, loss 0.153767, acc 0.9375
2020-02-08T02:31:05.487996: step 1726, loss 0.236155, acc 0.9375
2020-02-08T02:31:05.605985: step 1727, loss 0.189709, acc 0.921875
2020-02-08T02:31:05.722925: step 1728, loss 0.171819, acc 0.953125
2020-02-08T02:31:05.839947: step 1729, loss 0.0988304, acc 0.96875
2020-02-08T02:31:05.957846: step 1730, loss 0.0812514, acc 0.96875
2020-02-08T02:31:06.073603: step 1731, loss 0.0669153, acc 0.984375
2020-02-08T02:31:06.192325: step 1732, loss 0.0605997, acc 1
2020-02-08T02:31:06.307557: step 1733, loss 0.0728688, acc 1
2020-02-08T02:31:06.422987: step 1734, loss 0.110549, acc 0.96875
2020-02-08T02:31:06.542570: step 1735, loss 0.181835, acc 0.921875
2020-02-08T02:31:06.660530: step 1736, loss 0.192135, acc 0.953125
2020-02-08T02:31:06.778733: step 1737, loss 0.127001, acc 0.9375
2020-02-08T02:31:06.897683: step 1738, loss 0.166641, acc 0.9375
2020-02-08T02:31:07.013580: step 1739, loss 0.140253, acc 0.96875
2020-02-08T02:31:07.130778: step 1740, loss 0.0883326, acc 0.953125
2020-02-08T02:31:07.251374: step 1741, loss 0.114145, acc 0.96875
2020-02-08T02:31:07.368267: step 1742, loss 0.0889395, acc 0.96875
2020-02-08T02:31:07.483789: step 1743, loss 0.146511, acc 0.9375
2020-02-08T02:31:07.600186: step 1744, loss 0.186677, acc 0.96875
2020-02-08T02:31:07.718523: step 1745, loss 0.143519, acc 0.90625
2020-02-08T02:31:07.834620: step 1746, loss 0.109399, acc 0.984375
2020-02-08T02:31:07.953493: step 1747, loss 0.114723, acc 0.953125
2020-02-08T02:31:08.070354: step 1748, loss 0.0636145, acc 0.984375
2020-02-08T02:31:08.190956: step 1749, loss 0.171622, acc 0.921875
2020-02-08T02:31:08.310857: step 1750, loss 0.0552337, acc 0.984375
2020-02-08T02:31:08.429743: step 1751, loss 0.129495, acc 0.9375
2020-02-08T02:31:08.546090: step 1752, loss 0.113621, acc 0.9375
2020-02-08T02:31:08.662768: step 1753, loss 0.0829246, acc 0.984375
2020-02-08T02:31:08.782163: step 1754, loss 0.0460166, acc 1
2020-02-08T02:31:08.899079: step 1755, loss 0.0991178, acc 0.96875
2020-02-08T02:31:09.016623: step 1756, loss 0.075077, acc 0.984375
2020-02-08T02:31:09.135129: step 1757, loss 0.0929993, acc 0.9375
2020-02-08T02:31:09.253717: step 1758, loss 0.116196, acc 0.9375
2020-02-08T02:31:09.370835: step 1759, loss 0.192269, acc 0.9375
2020-02-08T02:31:09.486798: step 1760, loss 0.0925312, acc 0.953125
2020-02-08T02:31:09.603333: step 1761, loss 0.0542185, acc 0.984375
2020-02-08T02:31:09.722282: step 1762, loss 0.110934, acc 0.953125
2020-02-08T02:31:09.838436: step 1763, loss 0.127115, acc 0.953125
2020-02-08T02:31:09.956479: step 1764, loss 0.0776879, acc 0.984375
2020-02-08T02:31:10.072298: step 1765, loss 0.147567, acc 0.9375
2020-02-08T02:31:10.190788: step 1766, loss 0.160801, acc 0.9375
2020-02-08T02:31:10.307671: step 1767, loss 0.155365, acc 0.96875
2020-02-08T02:31:10.424779: step 1768, loss 0.115645, acc 0.9375
2020-02-08T02:31:10.543623: step 1769, loss 0.0444512, acc 0.984375
2020-02-08T02:31:10.660024: step 1770, loss 0.0551218, acc 0.984375
2020-02-08T02:31:10.780828: step 1771, loss 0.0784004, acc 0.96875
2020-02-08T02:31:10.898425: step 1772, loss 0.182505, acc 0.921875
2020-02-08T02:31:11.016053: step 1773, loss 0.0739432, acc 0.96875
2020-02-08T02:31:11.132620: step 1774, loss 0.160078, acc 0.921875
2020-02-08T02:31:11.249900: step 1775, loss 0.116691, acc 0.96875
2020-02-08T02:31:11.365634: step 1776, loss 0.073727, acc 0.984375
2020-02-08T02:31:11.485523: step 1777, loss 0.088502, acc 0.984375
2020-02-08T02:31:11.603939: step 1778, loss 0.104121, acc 0.953125
2020-02-08T02:31:11.725066: step 1779, loss 0.21491, acc 0.921875
2020-02-08T02:31:11.842497: step 1780, loss 0.0873914, acc 0.984375
2020-02-08T02:31:11.961257: step 1781, loss 0.0892009, acc 0.96875
2020-02-08T02:31:12.077505: step 1782, loss 0.105975, acc 0.953125
2020-02-08T02:31:12.194642: step 1783, loss 0.0995196, acc 0.953125
2020-02-08T02:31:12.312790: step 1784, loss 0.0581352, acc 0.984375
2020-02-08T02:31:12.430046: step 1785, loss 0.10874, acc 0.953125
2020-02-08T02:31:12.547543: step 1786, loss 0.0985733, acc 0.953125
2020-02-08T02:31:12.664909: step 1787, loss 0.152369, acc 0.9375
2020-02-08T02:31:12.784451: step 1788, loss 0.129179, acc 0.953125
2020-02-08T02:31:12.903303: step 1789, loss 0.103994, acc 0.96875
2020-02-08T02:31:13.022138: step 1790, loss 0.056755, acc 0.984375
2020-02-08T02:31:13.140024: step 1791, loss 0.122842, acc 0.953125
2020-02-08T02:31:13.260354: step 1792, loss 0.137041, acc 0.9375
2020-02-08T02:31:13.378638: step 1793, loss 0.145499, acc 0.953125
2020-02-08T02:31:13.497282: step 1794, loss 0.0848986, acc 0.96875
2020-02-08T02:31:13.616692: step 1795, loss 0.120581, acc 0.953125
2020-02-08T02:31:13.738128: step 1796, loss 0.070723, acc 1
2020-02-08T02:31:13.858038: step 1797, loss 0.0579241, acc 0.96875
2020-02-08T02:31:13.974210: step 1798, loss 0.0969986, acc 0.96875
2020-02-08T02:31:14.091844: step 1799, loss 0.200359, acc 0.9375
2020-02-08T02:31:14.206651: step 1800, loss 0.116368, acc 0.983333

Evaluation:
2020-02-08T02:31:14.395657: step 1800, loss 0.69642, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1800

2020-02-08T02:31:16.990555: step 1801, loss 0.0375462, acc 0.984375
2020-02-08T02:31:17.110666: step 1802, loss 0.0748144, acc 0.96875
2020-02-08T02:31:17.228964: step 1803, loss 0.0865675, acc 0.96875
2020-02-08T02:31:17.345432: step 1804, loss 0.092195, acc 0.984375
2020-02-08T02:31:17.462950: step 1805, loss 0.0526449, acc 0.984375
2020-02-08T02:31:17.580209: step 1806, loss 0.0559338, acc 0.96875
2020-02-08T02:31:17.698351: step 1807, loss 0.0480807, acc 1
2020-02-08T02:31:17.815825: step 1808, loss 0.0856416, acc 0.96875
2020-02-08T02:31:17.937196: step 1809, loss 0.15388, acc 0.921875
2020-02-08T02:31:18.054774: step 1810, loss 0.0840896, acc 0.9375
2020-02-08T02:31:18.169584: step 1811, loss 0.0523675, acc 0.984375
2020-02-08T02:31:18.286175: step 1812, loss 0.07887, acc 0.96875
2020-02-08T02:31:18.408433: step 1813, loss 0.0481083, acc 0.984375
2020-02-08T02:31:18.522954: step 1814, loss 0.130378, acc 0.9375
2020-02-08T02:31:18.641712: step 1815, loss 0.0496423, acc 0.984375
2020-02-08T02:31:18.764085: step 1816, loss 0.128809, acc 0.953125
2020-02-08T02:31:18.879780: step 1817, loss 0.0619077, acc 0.96875
2020-02-08T02:31:18.997211: step 1818, loss 0.0690031, acc 0.953125
2020-02-08T02:31:19.115541: step 1819, loss 0.120776, acc 0.9375
2020-02-08T02:31:19.231671: step 1820, loss 0.220326, acc 0.921875
2020-02-08T02:31:19.348780: step 1821, loss 0.0435078, acc 1
2020-02-08T02:31:19.465138: step 1822, loss 0.0533861, acc 0.984375
2020-02-08T02:31:19.582186: step 1823, loss 0.138176, acc 0.921875
2020-02-08T02:31:19.706387: step 1824, loss 0.0501248, acc 0.984375
2020-02-08T02:31:19.826112: step 1825, loss 0.0599308, acc 0.96875
2020-02-08T02:31:19.944216: step 1826, loss 0.105728, acc 0.953125
2020-02-08T02:31:20.060824: step 1827, loss 0.0695422, acc 0.984375
2020-02-08T02:31:20.181842: step 1828, loss 0.0354964, acc 0.984375
2020-02-08T02:31:20.303100: step 1829, loss 0.0968987, acc 0.96875
2020-02-08T02:31:20.421573: step 1830, loss 0.097415, acc 0.953125
2020-02-08T02:31:20.544682: step 1831, loss 0.0784489, acc 0.984375
2020-02-08T02:31:20.662638: step 1832, loss 0.0498813, acc 0.96875
2020-02-08T02:31:20.785604: step 1833, loss 0.118229, acc 0.921875
2020-02-08T02:31:20.908550: step 1834, loss 0.0292957, acc 1
2020-02-08T02:31:21.023030: step 1835, loss 0.0332069, acc 1
2020-02-08T02:31:21.138434: step 1836, loss 0.0617859, acc 0.984375
2020-02-08T02:31:21.252010: step 1837, loss 0.0826958, acc 0.96875
2020-02-08T02:31:21.368626: step 1838, loss 0.110671, acc 0.921875
2020-02-08T02:31:21.642954: step 1839, loss 0.0522737, acc 1
2020-02-08T02:31:21.769362: step 1840, loss 0.0968367, acc 0.96875
2020-02-08T02:31:21.889470: step 1841, loss 0.0875402, acc 0.96875
2020-02-08T02:31:22.007640: step 1842, loss 0.0538276, acc 1
2020-02-08T02:31:22.127934: step 1843, loss 0.0701498, acc 0.984375
2020-02-08T02:31:22.249819: step 1844, loss 0.0865774, acc 0.96875
2020-02-08T02:31:22.366952: step 1845, loss 0.105365, acc 0.96875
2020-02-08T02:31:22.484157: step 1846, loss 0.078209, acc 0.9375
2020-02-08T02:31:22.601854: step 1847, loss 0.130712, acc 0.96875
2020-02-08T02:31:22.724553: step 1848, loss 0.0880159, acc 0.96875
2020-02-08T02:31:22.841842: step 1849, loss 0.0819242, acc 0.984375
2020-02-08T02:31:22.962126: step 1850, loss 0.0594836, acc 0.984375
2020-02-08T02:31:23.079633: step 1851, loss 0.139026, acc 0.96875
2020-02-08T02:31:23.197938: step 1852, loss 0.0682864, acc 0.984375
2020-02-08T02:31:23.315464: step 1853, loss 0.0586642, acc 0.984375
2020-02-08T02:31:23.431172: step 1854, loss 0.0422077, acc 1
2020-02-08T02:31:23.546613: step 1855, loss 0.0726986, acc 0.96875
2020-02-08T02:31:23.664926: step 1856, loss 0.0679631, acc 0.96875
2020-02-08T02:31:23.786672: step 1857, loss 0.107404, acc 0.953125
2020-02-08T02:31:23.906102: step 1858, loss 0.115819, acc 0.96875
2020-02-08T02:31:24.021624: step 1859, loss 0.0319031, acc 1
2020-02-08T02:31:24.134802: step 1860, loss 0.0548081, acc 0.96875
2020-02-08T02:31:24.254035: step 1861, loss 0.0742952, acc 0.984375
2020-02-08T02:31:24.368858: step 1862, loss 0.0575029, acc 0.96875
2020-02-08T02:31:24.487551: step 1863, loss 0.01949, acc 1
2020-02-08T02:31:24.607102: step 1864, loss 0.147706, acc 0.953125
2020-02-08T02:31:24.722624: step 1865, loss 0.0558986, acc 0.984375
2020-02-08T02:31:24.839523: step 1866, loss 0.109961, acc 0.9375
2020-02-08T02:31:24.958167: step 1867, loss 0.0484323, acc 1
2020-02-08T02:31:25.073881: step 1868, loss 0.0901368, acc 0.984375
2020-02-08T02:31:25.191802: step 1869, loss 0.0347404, acc 0.984375
2020-02-08T02:31:25.313697: step 1870, loss 0.0550101, acc 0.984375
2020-02-08T02:31:25.431315: step 1871, loss 0.080538, acc 0.953125
2020-02-08T02:31:25.547711: step 1872, loss 0.099239, acc 0.953125
2020-02-08T02:31:25.664283: step 1873, loss 0.175024, acc 0.9375
2020-02-08T02:31:25.785520: step 1874, loss 0.0845288, acc 0.96875
2020-02-08T02:31:25.903587: step 1875, loss 0.06228, acc 0.984375
2020-02-08T02:31:26.018111: step 1876, loss 0.135834, acc 0.953125
2020-02-08T02:31:26.140422: step 1877, loss 0.134339, acc 0.9375
2020-02-08T02:31:26.260627: step 1878, loss 0.0731461, acc 0.953125
2020-02-08T02:31:26.377666: step 1879, loss 0.087193, acc 0.953125
2020-02-08T02:31:26.499517: step 1880, loss 0.0589086, acc 0.984375
2020-02-08T02:31:26.618276: step 1881, loss 0.0302059, acc 1
2020-02-08T02:31:26.739349: step 1882, loss 0.0872528, acc 0.96875
2020-02-08T02:31:26.859844: step 1883, loss 0.0597976, acc 0.984375
2020-02-08T02:31:26.976540: step 1884, loss 0.120519, acc 0.953125
2020-02-08T02:31:27.100872: step 1885, loss 0.0554579, acc 0.984375
2020-02-08T02:31:27.219165: step 1886, loss 0.0772109, acc 0.96875
2020-02-08T02:31:27.339100: step 1887, loss 0.068359, acc 0.96875
2020-02-08T02:31:27.455740: step 1888, loss 0.119133, acc 0.953125
2020-02-08T02:31:27.570841: step 1889, loss 0.14345, acc 0.9375
2020-02-08T02:31:27.689763: step 1890, loss 0.0267274, acc 1
2020-02-08T02:31:27.808768: step 1891, loss 0.0686752, acc 0.96875
2020-02-08T02:31:27.929097: step 1892, loss 0.0578587, acc 0.984375
2020-02-08T02:31:28.047436: step 1893, loss 0.046499, acc 0.984375
2020-02-08T02:31:28.164268: step 1894, loss 0.15891, acc 0.984375
2020-02-08T02:31:28.279588: step 1895, loss 0.106467, acc 0.953125
2020-02-08T02:31:28.398534: step 1896, loss 0.0238748, acc 1
2020-02-08T02:31:28.517819: step 1897, loss 0.123427, acc 0.953125
2020-02-08T02:31:28.641641: step 1898, loss 0.0780999, acc 0.96875
2020-02-08T02:31:28.764621: step 1899, loss 0.0759457, acc 0.984375
2020-02-08T02:31:28.881474: step 1900, loss 0.103003, acc 0.9375

Evaluation:
2020-02-08T02:31:29.073121: step 1900, loss 0.723488, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-1900

2020-02-08T02:31:31.630013: step 1901, loss 0.0677502, acc 0.96875
2020-02-08T02:31:31.759554: step 1902, loss 0.136177, acc 0.9375
2020-02-08T02:31:31.872950: step 1903, loss 0.0834083, acc 0.9375
2020-02-08T02:31:31.993576: step 1904, loss 0.0549379, acc 0.984375
2020-02-08T02:31:32.110173: step 1905, loss 0.0649602, acc 0.96875
2020-02-08T02:31:32.227871: step 1906, loss 0.0486822, acc 0.984375
2020-02-08T02:31:32.346383: step 1907, loss 0.0552363, acc 0.984375
2020-02-08T02:31:32.464019: step 1908, loss 0.0545532, acc 0.984375
2020-02-08T02:31:32.582469: step 1909, loss 0.0701013, acc 0.96875
2020-02-08T02:31:32.704127: step 1910, loss 0.105219, acc 0.953125
2020-02-08T02:31:32.821745: step 1911, loss 0.0797164, acc 0.96875
2020-02-08T02:31:32.939506: step 1912, loss 0.0604481, acc 1
2020-02-08T02:31:33.061571: step 1913, loss 0.0865375, acc 0.96875
2020-02-08T02:31:33.176936: step 1914, loss 0.0841793, acc 0.96875
2020-02-08T02:31:33.293341: step 1915, loss 0.0278967, acc 1
2020-02-08T02:31:33.412105: step 1916, loss 0.038516, acc 1
2020-02-08T02:31:33.526579: step 1917, loss 0.118471, acc 0.953125
2020-02-08T02:31:33.642642: step 1918, loss 0.0593997, acc 0.953125
2020-02-08T02:31:33.763011: step 1919, loss 0.0575314, acc 0.984375
2020-02-08T02:31:33.876795: step 1920, loss 0.0465926, acc 0.984375
2020-02-08T02:31:33.993922: step 1921, loss 0.09936, acc 0.96875
2020-02-08T02:31:34.110383: step 1922, loss 0.0428598, acc 0.984375
2020-02-08T02:31:34.227460: step 1923, loss 0.080397, acc 0.96875
2020-02-08T02:31:34.342444: step 1924, loss 0.105923, acc 0.953125
2020-02-08T02:31:34.459784: step 1925, loss 0.0826316, acc 0.96875
2020-02-08T02:31:34.575629: step 1926, loss 0.139064, acc 0.921875
2020-02-08T02:31:34.691621: step 1927, loss 0.154203, acc 0.953125
2020-02-08T02:31:34.811333: step 1928, loss 0.158944, acc 0.96875
2020-02-08T02:31:34.924936: step 1929, loss 0.0774396, acc 0.96875
2020-02-08T02:31:35.043057: step 1930, loss 0.122978, acc 0.96875
2020-02-08T02:31:35.159850: step 1931, loss 0.063386, acc 0.984375
2020-02-08T02:31:35.278167: step 1932, loss 0.0509349, acc 0.984375
2020-02-08T02:31:35.395938: step 1933, loss 0.0676212, acc 0.984375
2020-02-08T02:31:35.516146: step 1934, loss 0.0663345, acc 0.96875
2020-02-08T02:31:35.634236: step 1935, loss 0.106453, acc 0.953125
2020-02-08T02:31:35.761382: step 1936, loss 0.144128, acc 0.953125
2020-02-08T02:31:35.879584: step 1937, loss 0.154336, acc 0.9375
2020-02-08T02:31:35.997470: step 1938, loss 0.0374412, acc 1
2020-02-08T02:31:36.116279: step 1939, loss 0.100711, acc 0.953125
2020-02-08T02:31:36.232107: step 1940, loss 0.0245735, acc 1
2020-02-08T02:31:36.346575: step 1941, loss 0.0717826, acc 0.96875
2020-02-08T02:31:36.461868: step 1942, loss 0.137715, acc 0.921875
2020-02-08T02:31:36.577058: step 1943, loss 0.091101, acc 0.96875
2020-02-08T02:31:36.696412: step 1944, loss 0.0195007, acc 1
2020-02-08T02:31:36.813279: step 1945, loss 0.0596911, acc 0.984375
2020-02-08T02:31:36.929391: step 1946, loss 0.0440465, acc 1
2020-02-08T02:31:37.049316: step 1947, loss 0.0839606, acc 0.96875
2020-02-08T02:31:37.165387: step 1948, loss 0.0677844, acc 0.984375
2020-02-08T02:31:37.282739: step 1949, loss 0.0945651, acc 0.96875
2020-02-08T02:31:37.396649: step 1950, loss 0.0675711, acc 0.966667
2020-02-08T02:31:37.515954: step 1951, loss 0.055284, acc 1
2020-02-08T02:31:37.633616: step 1952, loss 0.10846, acc 0.9375
2020-02-08T02:31:37.755782: step 1953, loss 0.0498097, acc 0.96875
2020-02-08T02:31:37.871857: step 1954, loss 0.0973069, acc 0.96875
2020-02-08T02:31:37.989649: step 1955, loss 0.0377447, acc 1
2020-02-08T02:31:38.108475: step 1956, loss 0.119612, acc 0.96875
2020-02-08T02:31:38.222927: step 1957, loss 0.0518006, acc 0.984375
2020-02-08T02:31:38.341395: step 1958, loss 0.0611412, acc 0.96875
2020-02-08T02:31:38.460193: step 1959, loss 0.0631566, acc 0.984375
2020-02-08T02:31:38.578806: step 1960, loss 0.0806295, acc 0.96875
2020-02-08T02:31:38.696344: step 1961, loss 0.0705308, acc 0.953125
2020-02-08T02:31:38.814586: step 1962, loss 0.0405686, acc 1
2020-02-08T02:31:38.928941: step 1963, loss 0.0823177, acc 0.96875
2020-02-08T02:31:39.049252: step 1964, loss 0.030083, acc 1
2020-02-08T02:31:39.165978: step 1965, loss 0.106816, acc 0.96875
2020-02-08T02:31:39.281597: step 1966, loss 0.0760976, acc 0.953125
2020-02-08T02:31:39.398812: step 1967, loss 0.0839868, acc 0.984375
2020-02-08T02:31:39.516679: step 1968, loss 0.0585449, acc 0.984375
2020-02-08T02:31:39.631478: step 1969, loss 0.0263538, acc 1
2020-02-08T02:31:39.754665: step 1970, loss 0.0717188, acc 0.96875
2020-02-08T02:31:39.871906: step 1971, loss 0.0366542, acc 1
2020-02-08T02:31:39.990286: step 1972, loss 0.0532135, acc 0.96875
2020-02-08T02:31:40.108250: step 1973, loss 0.0618115, acc 0.96875
2020-02-08T02:31:40.222959: step 1974, loss 0.0807592, acc 0.953125
2020-02-08T02:31:40.343909: step 1975, loss 0.0580745, acc 0.96875
2020-02-08T02:31:40.458819: step 1976, loss 0.0364542, acc 0.984375
2020-02-08T02:31:40.577721: step 1977, loss 0.0696382, acc 0.953125
2020-02-08T02:31:40.695925: step 1978, loss 0.0987723, acc 0.953125
2020-02-08T02:31:40.814193: step 1979, loss 0.107105, acc 0.9375
2020-02-08T02:31:40.929412: step 1980, loss 0.041183, acc 0.984375
2020-02-08T02:31:41.047681: step 1981, loss 0.0106908, acc 1
2020-02-08T02:31:41.165348: step 1982, loss 0.0622271, acc 0.96875
2020-02-08T02:31:41.283704: step 1983, loss 0.0654992, acc 0.96875
2020-02-08T02:31:41.401101: step 1984, loss 0.0404378, acc 0.984375
2020-02-08T02:31:41.517440: step 1985, loss 0.0988564, acc 0.9375
2020-02-08T02:31:41.632447: step 1986, loss 0.0385041, acc 1
2020-02-08T02:31:41.758454: step 1987, loss 0.0439352, acc 0.984375
2020-02-08T02:31:41.877607: step 1988, loss 0.0711259, acc 0.953125
2020-02-08T02:31:41.998980: step 1989, loss 0.119745, acc 0.96875
2020-02-08T02:31:42.114148: step 1990, loss 0.0793314, acc 0.953125
2020-02-08T02:31:42.228329: step 1991, loss 0.0553948, acc 0.96875
2020-02-08T02:31:42.347627: step 1992, loss 0.109214, acc 0.96875
2020-02-08T02:31:42.464256: step 1993, loss 0.069313, acc 0.96875
2020-02-08T02:31:42.578867: step 1994, loss 0.0488158, acc 0.984375
2020-02-08T02:31:42.699144: step 1995, loss 0.0483995, acc 0.96875
2020-02-08T02:31:42.817428: step 1996, loss 0.0707849, acc 0.96875
2020-02-08T02:31:42.933330: step 1997, loss 0.053387, acc 0.96875
2020-02-08T02:31:43.052928: step 1998, loss 0.0540692, acc 0.984375
2020-02-08T02:31:43.168421: step 1999, loss 0.0528509, acc 1
2020-02-08T02:31:43.283631: step 2000, loss 0.0666002, acc 0.984375

Evaluation:
2020-02-08T02:31:43.471516: step 2000, loss 0.757523, acc 0.724203

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2000

2020-02-08T02:31:45.245403: step 2001, loss 0.128949, acc 0.953125
2020-02-08T02:31:45.362383: step 2002, loss 0.0592634, acc 1
2020-02-08T02:31:45.481008: step 2003, loss 0.0952834, acc 0.984375
2020-02-08T02:31:45.600844: step 2004, loss 0.0488316, acc 0.984375
2020-02-08T02:31:45.720267: step 2005, loss 0.0932244, acc 0.9375
2020-02-08T02:31:45.840820: step 2006, loss 0.0697056, acc 0.96875
2020-02-08T02:31:45.961895: step 2007, loss 0.0286051, acc 1
2020-02-08T02:31:46.080811: step 2008, loss 0.0758785, acc 0.96875
2020-02-08T02:31:46.198213: step 2009, loss 0.0912399, acc 0.984375
2020-02-08T02:31:46.314141: step 2010, loss 0.0420943, acc 0.984375
2020-02-08T02:31:46.429015: step 2011, loss 0.0138338, acc 1
2020-02-08T02:31:46.548364: step 2012, loss 0.0178595, acc 1
2020-02-08T02:31:46.664888: step 2013, loss 0.114862, acc 0.984375
2020-02-08T02:31:46.784918: step 2014, loss 0.0357077, acc 1
2020-02-08T02:31:46.900113: step 2015, loss 0.0502046, acc 1
2020-02-08T02:31:47.017221: step 2016, loss 0.0285997, acc 1
2020-02-08T02:31:47.133468: step 2017, loss 0.10589, acc 0.984375
2020-02-08T02:31:47.250827: step 2018, loss 0.0745767, acc 0.96875
2020-02-08T02:31:47.367178: step 2019, loss 0.0996415, acc 0.953125
2020-02-08T02:31:47.485009: step 2020, loss 0.0715581, acc 0.984375
2020-02-08T02:31:47.602982: step 2021, loss 0.0538397, acc 1
2020-02-08T02:31:47.721010: step 2022, loss 0.0511305, acc 1
2020-02-08T02:31:47.838295: step 2023, loss 0.11046, acc 0.984375
2020-02-08T02:31:47.957635: step 2024, loss 0.0596108, acc 0.96875
2020-02-08T02:31:48.074364: step 2025, loss 0.0567435, acc 0.984375
2020-02-08T02:31:48.193918: step 2026, loss 0.0740384, acc 0.96875
2020-02-08T02:31:48.309081: step 2027, loss 0.0565541, acc 0.96875
2020-02-08T02:31:48.424783: step 2028, loss 0.0641483, acc 1
2020-02-08T02:31:48.540236: step 2029, loss 0.0372534, acc 1
2020-02-08T02:31:48.658438: step 2030, loss 0.0608341, acc 0.984375
2020-02-08T02:31:48.776791: step 2031, loss 0.124676, acc 0.9375
2020-02-08T02:31:48.896261: step 2032, loss 0.0701178, acc 0.984375
2020-02-08T02:31:49.016236: step 2033, loss 0.0348013, acc 0.984375
2020-02-08T02:31:49.129727: step 2034, loss 0.0583201, acc 0.984375
2020-02-08T02:31:49.247546: step 2035, loss 0.0962992, acc 0.96875
2020-02-08T02:31:49.363266: step 2036, loss 0.10365, acc 0.953125
2020-02-08T02:31:49.481614: step 2037, loss 0.0809052, acc 0.96875
2020-02-08T02:31:49.601673: step 2038, loss 0.0753483, acc 0.953125
2020-02-08T02:31:49.720859: step 2039, loss 0.0441546, acc 0.984375
2020-02-08T02:31:49.837830: step 2040, loss 0.0193201, acc 1
2020-02-08T02:31:49.956956: step 2041, loss 0.0492302, acc 0.984375
2020-02-08T02:31:50.070470: step 2042, loss 0.0718635, acc 0.96875
2020-02-08T02:31:50.189866: step 2043, loss 0.150325, acc 0.953125
2020-02-08T02:31:50.307784: step 2044, loss 0.0893058, acc 0.984375
2020-02-08T02:31:50.422194: step 2045, loss 0.0513728, acc 0.984375
2020-02-08T02:31:50.540378: step 2046, loss 0.0306424, acc 1
2020-02-08T02:31:50.657057: step 2047, loss 0.120086, acc 0.953125
2020-02-08T02:31:50.775203: step 2048, loss 0.0273867, acc 1
2020-02-08T02:31:50.895648: step 2049, loss 0.143813, acc 0.9375
2020-02-08T02:31:51.011917: step 2050, loss 0.13487, acc 0.921875
2020-02-08T02:31:51.132004: step 2051, loss 0.0993696, acc 0.953125
2020-02-08T02:31:51.246051: step 2052, loss 0.103364, acc 0.96875
2020-02-08T02:31:51.360389: step 2053, loss 0.0285626, acc 1
2020-02-08T02:31:51.487125: step 2054, loss 0.0473638, acc 0.96875
2020-02-08T02:31:51.605132: step 2055, loss 0.033459, acc 1
2020-02-08T02:31:51.725478: step 2056, loss 0.0683884, acc 0.984375
2020-02-08T02:31:51.845438: step 2057, loss 0.0426333, acc 0.984375
2020-02-08T02:31:51.959263: step 2058, loss 0.104793, acc 0.953125
2020-02-08T02:31:52.073722: step 2059, loss 0.0548588, acc 0.984375
2020-02-08T02:31:52.190071: step 2060, loss 0.0595573, acc 0.984375
2020-02-08T02:31:52.306504: step 2061, loss 0.134222, acc 0.96875
2020-02-08T02:31:52.421626: step 2062, loss 0.0309788, acc 1
2020-02-08T02:31:52.536181: step 2063, loss 0.122432, acc 0.953125
2020-02-08T02:31:52.653284: step 2064, loss 0.0663841, acc 0.96875
2020-02-08T02:31:52.774986: step 2065, loss 0.0481329, acc 0.96875
2020-02-08T02:31:52.895341: step 2066, loss 0.0273491, acc 1
2020-02-08T02:31:53.011584: step 2067, loss 0.0477841, acc 0.984375
2020-02-08T02:31:53.127699: step 2068, loss 0.110822, acc 0.984375
2020-02-08T02:31:53.247209: step 2069, loss 0.11383, acc 0.953125
2020-02-08T02:31:53.363364: step 2070, loss 0.0400159, acc 0.984375
2020-02-08T02:31:53.481206: step 2071, loss 0.0479737, acc 0.984375
2020-02-08T02:31:53.600165: step 2072, loss 0.0725452, acc 0.96875
2020-02-08T02:31:53.719314: step 2073, loss 0.0843387, acc 0.953125
2020-02-08T02:31:53.836177: step 2074, loss 0.0219814, acc 1
2020-02-08T02:31:53.955537: step 2075, loss 0.0703442, acc 0.96875
2020-02-08T02:31:54.072534: step 2076, loss 0.0716484, acc 0.96875
2020-02-08T02:31:54.191567: step 2077, loss 0.139871, acc 0.953125
2020-02-08T02:31:54.310498: step 2078, loss 0.128283, acc 0.953125
2020-02-08T02:31:54.428051: step 2079, loss 0.149448, acc 0.921875
2020-02-08T02:31:54.547254: step 2080, loss 0.079824, acc 0.953125
2020-02-08T02:31:54.667742: step 2081, loss 0.0532771, acc 0.96875
2020-02-08T02:31:54.792706: step 2082, loss 0.0261355, acc 1
2020-02-08T02:31:54.911251: step 2083, loss 0.0994649, acc 0.96875
2020-02-08T02:31:55.026568: step 2084, loss 0.0392313, acc 1
2020-02-08T02:31:55.146235: step 2085, loss 0.0718234, acc 0.96875
2020-02-08T02:31:55.263526: step 2086, loss 0.04429, acc 0.984375
2020-02-08T02:31:55.380720: step 2087, loss 0.0359144, acc 1
2020-02-08T02:31:55.499066: step 2088, loss 0.0764386, acc 0.96875
2020-02-08T02:31:55.613882: step 2089, loss 0.0483278, acc 0.984375
2020-02-08T02:31:55.738240: step 2090, loss 0.0871958, acc 0.96875
2020-02-08T02:31:55.856548: step 2091, loss 0.0935392, acc 0.96875
2020-02-08T02:31:55.974694: step 2092, loss 0.0295935, acc 0.984375
2020-02-08T02:31:56.093308: step 2093, loss 0.0435254, acc 0.984375
2020-02-08T02:31:56.211718: step 2094, loss 0.0584638, acc 0.984375
2020-02-08T02:31:56.327422: step 2095, loss 0.0414695, acc 0.984375
2020-02-08T02:31:56.446453: step 2096, loss 0.0488266, acc 0.984375
2020-02-08T02:31:56.565469: step 2097, loss 0.0178035, acc 1
2020-02-08T02:31:56.685682: step 2098, loss 0.159209, acc 0.953125
2020-02-08T02:31:56.805478: step 2099, loss 0.0667828, acc 0.984375
2020-02-08T02:31:56.918420: step 2100, loss 0.0543039, acc 0.983333

Evaluation:
2020-02-08T02:31:57.111598: step 2100, loss 0.778664, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2100

2020-02-08T02:31:58.714801: step 2101, loss 0.050752, acc 0.984375
2020-02-08T02:31:58.829133: step 2102, loss 0.10272, acc 0.9375
2020-02-08T02:31:58.946254: step 2103, loss 0.0795194, acc 0.96875
2020-02-08T02:31:59.065070: step 2104, loss 0.0102264, acc 1
2020-02-08T02:31:59.182754: step 2105, loss 0.0324916, acc 0.984375
2020-02-08T02:31:59.301047: step 2106, loss 0.0513103, acc 0.984375
2020-02-08T02:31:59.419401: step 2107, loss 0.0478628, acc 0.984375
2020-02-08T02:31:59.537404: step 2108, loss 0.0885127, acc 0.96875
2020-02-08T02:31:59.652724: step 2109, loss 0.0480323, acc 0.984375
2020-02-08T02:31:59.773134: step 2110, loss 0.0332493, acc 0.984375
2020-02-08T02:31:59.888616: step 2111, loss 0.0602248, acc 0.96875
2020-02-08T02:32:00.006546: step 2112, loss 0.0594856, acc 0.984375
2020-02-08T02:32:00.123164: step 2113, loss 0.0181475, acc 1
2020-02-08T02:32:00.243639: step 2114, loss 0.0382832, acc 0.984375
2020-02-08T02:32:00.361258: step 2115, loss 0.0343929, acc 0.984375
2020-02-08T02:32:00.478768: step 2116, loss 0.0553625, acc 0.984375
2020-02-08T02:32:00.600837: step 2117, loss 0.0283436, acc 1
2020-02-08T02:32:00.719282: step 2118, loss 0.0298389, acc 1
2020-02-08T02:32:00.836479: step 2119, loss 0.07863, acc 0.96875
2020-02-08T02:32:00.956786: step 2120, loss 0.0477352, acc 0.984375
2020-02-08T02:32:01.071457: step 2121, loss 0.0616885, acc 0.984375
2020-02-08T02:32:01.190374: step 2122, loss 0.0829194, acc 0.96875
2020-02-08T02:32:01.313045: step 2123, loss 0.0295338, acc 0.984375
2020-02-08T02:32:01.430452: step 2124, loss 0.0284187, acc 1
2020-02-08T02:32:01.548609: step 2125, loss 0.0119856, acc 1
2020-02-08T02:32:01.666013: step 2126, loss 0.0433254, acc 0.984375
2020-02-08T02:32:01.789178: step 2127, loss 0.0762521, acc 0.96875
2020-02-08T02:32:01.907765: step 2128, loss 0.0475157, acc 0.96875
2020-02-08T02:32:02.023031: step 2129, loss 0.0333645, acc 1
2020-02-08T02:32:02.142303: step 2130, loss 0.0913898, acc 0.96875
2020-02-08T02:32:02.260488: step 2131, loss 0.0390824, acc 0.984375
2020-02-08T02:32:02.375316: step 2132, loss 0.0509278, acc 0.96875
2020-02-08T02:32:02.497162: step 2133, loss 0.0534473, acc 0.96875
2020-02-08T02:32:02.614056: step 2134, loss 0.0953178, acc 0.953125
2020-02-08T02:32:02.735731: step 2135, loss 0.0226991, acc 1
2020-02-08T02:32:02.852610: step 2136, loss 0.0497171, acc 0.984375
2020-02-08T02:32:02.967631: step 2137, loss 0.0928175, acc 0.953125
2020-02-08T02:32:03.083253: step 2138, loss 0.0425147, acc 0.96875
2020-02-08T02:32:03.201075: step 2139, loss 0.0418022, acc 0.984375
2020-02-08T02:32:03.316035: step 2140, loss 0.0239871, acc 0.984375
2020-02-08T02:32:03.430507: step 2141, loss 0.0289828, acc 0.984375
2020-02-08T02:32:03.550796: step 2142, loss 0.0203504, acc 1
2020-02-08T02:32:03.667986: step 2143, loss 0.121882, acc 0.96875
2020-02-08T02:32:03.789554: step 2144, loss 0.0555342, acc 0.984375
2020-02-08T02:32:03.909174: step 2145, loss 0.0357219, acc 1
2020-02-08T02:32:04.027729: step 2146, loss 0.0421224, acc 0.984375
2020-02-08T02:32:04.144659: step 2147, loss 0.0338923, acc 1
2020-02-08T02:32:04.265867: step 2148, loss 0.100072, acc 0.953125
2020-02-08T02:32:04.384229: step 2149, loss 0.0723634, acc 0.984375
2020-02-08T02:32:04.502188: step 2150, loss 0.013174, acc 1
2020-02-08T02:32:04.618386: step 2151, loss 0.0638308, acc 0.96875
2020-02-08T02:32:04.742267: step 2152, loss 0.0558261, acc 0.984375
2020-02-08T02:32:04.860236: step 2153, loss 0.0535523, acc 0.984375
2020-02-08T02:32:04.975703: step 2154, loss 0.0749915, acc 0.984375
2020-02-08T02:32:05.091470: step 2155, loss 0.0720279, acc 0.984375
2020-02-08T02:32:05.210334: step 2156, loss 0.029027, acc 1
2020-02-08T02:32:05.324792: step 2157, loss 0.047201, acc 0.984375
2020-02-08T02:32:05.441425: step 2158, loss 0.112603, acc 0.96875
2020-02-08T02:32:05.561062: step 2159, loss 0.0330058, acc 1
2020-02-08T02:32:05.679207: step 2160, loss 0.0549315, acc 0.96875
2020-02-08T02:32:05.800117: step 2161, loss 0.0357628, acc 0.984375
2020-02-08T02:32:05.920924: step 2162, loss 0.054126, acc 0.96875
2020-02-08T02:32:06.041295: step 2163, loss 0.122198, acc 0.9375
2020-02-08T02:32:06.160420: step 2164, loss 0.0450446, acc 0.96875
2020-02-08T02:32:06.278335: step 2165, loss 0.0845113, acc 0.96875
2020-02-08T02:32:06.398463: step 2166, loss 0.0549949, acc 0.984375
2020-02-08T02:32:06.514333: step 2167, loss 0.0846287, acc 0.953125
2020-02-08T02:32:06.631672: step 2168, loss 0.0565273, acc 0.96875
2020-02-08T02:32:06.753524: step 2169, loss 0.0224986, acc 1
2020-02-08T02:32:06.874240: step 2170, loss 0.0290342, acc 1
2020-02-08T02:32:06.995598: step 2171, loss 0.0295159, acc 1
2020-02-08T02:32:07.114629: step 2172, loss 0.054723, acc 0.96875
2020-02-08T02:32:07.233345: step 2173, loss 0.0699205, acc 0.984375
2020-02-08T02:32:07.351917: step 2174, loss 0.0406009, acc 0.984375
2020-02-08T02:32:07.471577: step 2175, loss 0.0375485, acc 0.984375
2020-02-08T02:32:07.588365: step 2176, loss 0.120958, acc 0.9375
2020-02-08T02:32:07.709154: step 2177, loss 0.0196102, acc 1
2020-02-08T02:32:07.828182: step 2178, loss 0.0968044, acc 0.953125
2020-02-08T02:32:07.946385: step 2179, loss 0.0128195, acc 1
2020-02-08T02:32:08.063451: step 2180, loss 0.048258, acc 0.984375
2020-02-08T02:32:08.181230: step 2181, loss 0.0748877, acc 0.96875
2020-02-08T02:32:08.300192: step 2182, loss 0.0159939, acc 1
2020-02-08T02:32:08.418519: step 2183, loss 0.0485277, acc 0.96875
2020-02-08T02:32:08.536705: step 2184, loss 0.0390547, acc 0.984375
2020-02-08T02:32:08.655096: step 2185, loss 0.0585452, acc 0.96875
2020-02-08T02:32:08.774883: step 2186, loss 0.0470782, acc 0.984375
2020-02-08T02:32:08.891124: step 2187, loss 0.0303983, acc 0.984375
2020-02-08T02:32:09.008167: step 2188, loss 0.0725943, acc 0.96875
2020-02-08T02:32:09.125838: step 2189, loss 0.0226027, acc 1
2020-02-08T02:32:09.244820: step 2190, loss 0.0256393, acc 1
2020-02-08T02:32:09.362701: step 2191, loss 0.038417, acc 1
2020-02-08T02:32:09.482718: step 2192, loss 0.069251, acc 0.984375
2020-02-08T02:32:09.600766: step 2193, loss 0.0676885, acc 0.96875
2020-02-08T02:32:09.719588: step 2194, loss 0.0249781, acc 1
2020-02-08T02:32:09.839839: step 2195, loss 0.0278963, acc 1
2020-02-08T02:32:09.959423: step 2196, loss 0.0604261, acc 0.984375
2020-02-08T02:32:10.077721: step 2197, loss 0.0451243, acc 0.96875
2020-02-08T02:32:10.194081: step 2198, loss 0.0360235, acc 1
2020-02-08T02:32:10.313968: step 2199, loss 0.0239016, acc 1
2020-02-08T02:32:10.433126: step 2200, loss 0.0337452, acc 0.984375

Evaluation:
2020-02-08T02:32:10.624452: step 2200, loss 0.809206, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2200

2020-02-08T02:32:12.153613: step 2201, loss 0.0116154, acc 1
2020-02-08T02:32:12.273508: step 2202, loss 0.0779485, acc 0.96875
2020-02-08T02:32:12.391329: step 2203, loss 0.0307419, acc 1
2020-02-08T02:32:12.510252: step 2204, loss 0.0193121, acc 1
2020-02-08T02:32:12.626677: step 2205, loss 0.0377837, acc 0.984375
2020-02-08T02:32:12.747396: step 2206, loss 0.0468115, acc 0.984375
2020-02-08T02:32:12.864855: step 2207, loss 0.0444086, acc 0.984375
2020-02-08T02:32:12.981464: step 2208, loss 0.0773273, acc 0.984375
2020-02-08T02:32:13.099026: step 2209, loss 0.0402227, acc 0.984375
2020-02-08T02:32:13.217022: step 2210, loss 0.0482055, acc 0.984375
2020-02-08T02:32:13.332801: step 2211, loss 0.0608958, acc 0.96875
2020-02-08T02:32:13.452117: step 2212, loss 0.0305243, acc 1
2020-02-08T02:32:13.568645: step 2213, loss 0.0338678, acc 1
2020-02-08T02:32:13.688407: step 2214, loss 0.0633106, acc 0.96875
2020-02-08T02:32:13.809277: step 2215, loss 0.0193043, acc 1
2020-02-08T02:32:13.924485: step 2216, loss 0.01198, acc 1
2020-02-08T02:32:14.043024: step 2217, loss 0.0625732, acc 0.96875
2020-02-08T02:32:14.160388: step 2218, loss 0.057596, acc 0.984375
2020-02-08T02:32:14.278301: step 2219, loss 0.0420509, acc 0.96875
2020-02-08T02:32:14.398419: step 2220, loss 0.0682308, acc 0.96875
2020-02-08T02:32:14.515633: step 2221, loss 0.0510431, acc 0.984375
2020-02-08T02:32:14.635139: step 2222, loss 0.108438, acc 0.953125
2020-02-08T02:32:14.759190: step 2223, loss 0.0162464, acc 1
2020-02-08T02:32:14.877005: step 2224, loss 0.123046, acc 0.9375
2020-02-08T02:32:14.994732: step 2225, loss 0.0543892, acc 0.984375
2020-02-08T02:32:15.112528: step 2226, loss 0.0312453, acc 0.984375
2020-02-08T02:32:15.228425: step 2227, loss 0.0754956, acc 0.96875
2020-02-08T02:32:15.346642: step 2228, loss 0.0174111, acc 1
2020-02-08T02:32:15.465101: step 2229, loss 0.0167871, acc 1
2020-02-08T02:32:15.582206: step 2230, loss 0.0420328, acc 0.984375
2020-02-08T02:32:15.702148: step 2231, loss 0.0393712, acc 0.984375
2020-02-08T02:32:15.818438: step 2232, loss 0.0457808, acc 1
2020-02-08T02:32:15.935910: step 2233, loss 0.0400741, acc 1
2020-02-08T02:32:16.053086: step 2234, loss 0.0510603, acc 0.984375
2020-02-08T02:32:16.169937: step 2235, loss 0.0532203, acc 0.96875
2020-02-08T02:32:16.284726: step 2236, loss 0.0156067, acc 1
2020-02-08T02:32:16.401103: step 2237, loss 0.0347789, acc 1
2020-02-08T02:32:16.517619: step 2238, loss 0.0530293, acc 0.984375
2020-02-08T02:32:16.639819: step 2239, loss 0.0478824, acc 0.984375
2020-02-08T02:32:16.794767: step 2240, loss 0.0415433, acc 0.984375
2020-02-08T02:32:16.975133: step 2241, loss 0.040287, acc 0.984375
2020-02-08T02:32:17.113878: step 2242, loss 0.0183112, acc 1
2020-02-08T02:32:17.248569: step 2243, loss 0.0960945, acc 0.953125
2020-02-08T02:32:17.393211: step 2244, loss 0.112203, acc 0.96875
2020-02-08T02:32:17.527105: step 2245, loss 0.0753766, acc 0.96875
2020-02-08T02:32:17.661898: step 2246, loss 0.0312137, acc 0.984375
2020-02-08T02:32:17.801951: step 2247, loss 0.0411401, acc 1
2020-02-08T02:32:17.937955: step 2248, loss 0.0333235, acc 1
2020-02-08T02:32:18.070014: step 2249, loss 0.101415, acc 0.96875
2020-02-08T02:32:18.203537: step 2250, loss 0.0843006, acc 0.966667
2020-02-08T02:32:18.343632: step 2251, loss 0.0171198, acc 1
2020-02-08T02:32:18.472393: step 2252, loss 0.0622388, acc 0.96875
2020-02-08T02:32:18.604979: step 2253, loss 0.0183939, acc 1
2020-02-08T02:32:18.746192: step 2254, loss 0.0350499, acc 1
2020-02-08T02:32:18.880345: step 2255, loss 0.0254903, acc 0.984375
2020-02-08T02:32:19.012662: step 2256, loss 0.0727308, acc 0.96875
2020-02-08T02:32:19.146142: step 2257, loss 0.0606974, acc 0.984375
2020-02-08T02:32:19.277102: step 2258, loss 0.0484161, acc 0.96875
2020-02-08T02:32:19.407512: step 2259, loss 0.0149258, acc 1
2020-02-08T02:32:19.540988: step 2260, loss 0.0145598, acc 1
2020-02-08T02:32:19.675604: step 2261, loss 0.0981946, acc 0.953125
2020-02-08T02:32:19.816543: step 2262, loss 0.0183103, acc 1
2020-02-08T02:32:19.958338: step 2263, loss 0.0366518, acc 0.984375
2020-02-08T02:32:20.100896: step 2264, loss 0.0182683, acc 1
2020-02-08T02:32:20.241105: step 2265, loss 0.0122377, acc 1
2020-02-08T02:32:20.394389: step 2266, loss 0.0187806, acc 1
2020-02-08T02:32:20.540954: step 2267, loss 0.0391081, acc 0.984375
2020-02-08T02:32:20.664874: step 2268, loss 0.0232716, acc 1
2020-02-08T02:32:20.810982: step 2269, loss 0.126933, acc 0.953125
2020-02-08T02:32:20.951310: step 2270, loss 0.0260154, acc 1
2020-02-08T02:32:21.089923: step 2271, loss 0.0468899, acc 0.984375
2020-02-08T02:32:21.231361: step 2272, loss 0.0910081, acc 0.96875
2020-02-08T02:32:21.367756: step 2273, loss 0.0370005, acc 1
2020-02-08T02:32:21.485051: step 2274, loss 0.0179802, acc 1
2020-02-08T02:32:21.770316: step 2275, loss 0.0310096, acc 0.984375
2020-02-08T02:32:21.918243: step 2276, loss 0.0395191, acc 1
2020-02-08T02:32:22.055401: step 2277, loss 0.045051, acc 1
2020-02-08T02:32:22.196325: step 2278, loss 0.0656583, acc 0.96875
2020-02-08T02:32:22.335590: step 2279, loss 0.0154198, acc 1
2020-02-08T02:32:22.473395: step 2280, loss 0.0256882, acc 1
2020-02-08T02:32:22.612406: step 2281, loss 0.0102903, acc 1
2020-02-08T02:32:22.755731: step 2282, loss 0.0244843, acc 0.984375
2020-02-08T02:32:22.897441: step 2283, loss 0.0447782, acc 0.984375
2020-02-08T02:32:23.036398: step 2284, loss 0.026567, acc 1
2020-02-08T02:32:23.183662: step 2285, loss 0.0194455, acc 1
2020-02-08T02:32:23.324139: step 2286, loss 0.0751522, acc 0.96875
2020-02-08T02:32:23.462048: step 2287, loss 0.0211857, acc 1
2020-02-08T02:32:23.594877: step 2288, loss 0.0203201, acc 1
2020-02-08T02:32:23.736486: step 2289, loss 0.0390204, acc 0.984375
2020-02-08T02:32:23.877997: step 2290, loss 0.0141458, acc 1
2020-02-08T02:32:24.019436: step 2291, loss 0.0243297, acc 1
2020-02-08T02:32:24.159881: step 2292, loss 0.0525509, acc 0.984375
2020-02-08T02:32:24.301604: step 2293, loss 0.0373142, acc 1
2020-02-08T02:32:24.443697: step 2294, loss 0.0375399, acc 1
2020-02-08T02:32:24.574530: step 2295, loss 0.0323377, acc 1
2020-02-08T02:32:24.692093: step 2296, loss 0.0325103, acc 1
2020-02-08T02:32:24.821177: step 2297, loss 0.0366989, acc 0.984375
2020-02-08T02:32:24.947694: step 2298, loss 0.0598524, acc 0.96875
2020-02-08T02:32:25.073747: step 2299, loss 0.0147126, acc 1
2020-02-08T02:32:25.199835: step 2300, loss 0.021303, acc 1

Evaluation:
2020-02-08T02:32:25.404324: step 2300, loss 0.856185, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2300

2020-02-08T02:32:26.961271: step 2301, loss 0.0721256, acc 0.96875
2020-02-08T02:32:27.095322: step 2302, loss 0.0196844, acc 1
2020-02-08T02:32:27.228575: step 2303, loss 0.0460798, acc 0.984375
2020-02-08T02:32:27.349281: step 2304, loss 0.0240387, acc 1
2020-02-08T02:32:27.468700: step 2305, loss 0.0820281, acc 0.953125
2020-02-08T02:32:27.587634: step 2306, loss 0.0365481, acc 0.96875
2020-02-08T02:32:27.714680: step 2307, loss 0.0188311, acc 1
2020-02-08T02:32:27.834376: step 2308, loss 0.0203208, acc 1
2020-02-08T02:32:27.950597: step 2309, loss 0.0327831, acc 1
2020-02-08T02:32:28.067662: step 2310, loss 0.0728768, acc 0.96875
2020-02-08T02:32:28.184182: step 2311, loss 0.0351154, acc 0.984375
2020-02-08T02:32:28.302449: step 2312, loss 0.0307005, acc 1
2020-02-08T02:32:28.419873: step 2313, loss 0.0508928, acc 0.984375
2020-02-08T02:32:28.541682: step 2314, loss 0.0591666, acc 0.953125
2020-02-08T02:32:28.658351: step 2315, loss 0.0443286, acc 0.96875
2020-02-08T02:32:28.778680: step 2316, loss 0.0277019, acc 0.984375
2020-02-08T02:32:28.896229: step 2317, loss 0.0167818, acc 0.984375
2020-02-08T02:32:29.013480: step 2318, loss 0.0140444, acc 1
2020-02-08T02:32:29.131432: step 2319, loss 0.0102921, acc 1
2020-02-08T02:32:29.249881: step 2320, loss 0.0101133, acc 1
2020-02-08T02:32:29.368254: step 2321, loss 0.146434, acc 0.96875
2020-02-08T02:32:29.485219: step 2322, loss 0.0117106, acc 1
2020-02-08T02:32:29.604787: step 2323, loss 0.0426101, acc 0.984375
2020-02-08T02:32:29.722285: step 2324, loss 0.00946032, acc 1
2020-02-08T02:32:29.846228: step 2325, loss 0.00719093, acc 1
2020-02-08T02:32:29.962401: step 2326, loss 0.055667, acc 0.984375
2020-02-08T02:32:30.079437: step 2327, loss 0.0291103, acc 1
2020-02-08T02:32:30.197014: step 2328, loss 0.0243014, acc 1
2020-02-08T02:32:30.315459: step 2329, loss 0.0178301, acc 1
2020-02-08T02:32:30.432265: step 2330, loss 0.0504613, acc 0.984375
2020-02-08T02:32:30.553820: step 2331, loss 0.0329713, acc 1
2020-02-08T02:32:30.669930: step 2332, loss 0.0126604, acc 1
2020-02-08T02:32:30.793760: step 2333, loss 0.0136016, acc 1
2020-02-08T02:32:30.913332: step 2334, loss 0.0490336, acc 0.984375
2020-02-08T02:32:31.032324: step 2335, loss 0.0815238, acc 0.984375
2020-02-08T02:32:31.147371: step 2336, loss 0.0244152, acc 1
2020-02-08T02:32:31.264447: step 2337, loss 0.0227058, acc 1
2020-02-08T02:32:31.380471: step 2338, loss 0.0343714, acc 0.984375
2020-02-08T02:32:31.499600: step 2339, loss 0.158452, acc 0.96875
2020-02-08T02:32:31.616340: step 2340, loss 0.0101388, acc 1
2020-02-08T02:32:31.737868: step 2341, loss 0.0461349, acc 1
2020-02-08T02:32:31.855386: step 2342, loss 0.0290134, acc 0.984375
2020-02-08T02:32:31.971138: step 2343, loss 0.0070965, acc 1
2020-02-08T02:32:32.087931: step 2344, loss 0.0444766, acc 0.984375
2020-02-08T02:32:32.207507: step 2345, loss 0.0132229, acc 1
2020-02-08T02:32:32.324311: step 2346, loss 0.059614, acc 0.96875
2020-02-08T02:32:32.440056: step 2347, loss 0.0274255, acc 1
2020-02-08T02:32:32.557534: step 2348, loss 0.0130246, acc 1
2020-02-08T02:32:32.673241: step 2349, loss 0.0143296, acc 1
2020-02-08T02:32:32.806057: step 2350, loss 0.0199023, acc 1
2020-02-08T02:32:32.919607: step 2351, loss 0.150859, acc 0.9375
2020-02-08T02:32:33.038386: step 2352, loss 0.0282377, acc 0.984375
2020-02-08T02:32:33.156767: step 2353, loss 0.0271236, acc 0.984375
2020-02-08T02:32:33.274869: step 2354, loss 0.0288239, acc 1
2020-02-08T02:32:33.394666: step 2355, loss 0.0401493, acc 0.984375
2020-02-08T02:32:33.514677: step 2356, loss 0.0728245, acc 0.96875
2020-02-08T02:32:33.630294: step 2357, loss 0.0699298, acc 0.96875
2020-02-08T02:32:33.754158: step 2358, loss 0.0300559, acc 0.984375
2020-02-08T02:32:33.871363: step 2359, loss 0.0862595, acc 0.984375
2020-02-08T02:32:33.987359: step 2360, loss 0.0158196, acc 1
2020-02-08T02:32:34.104581: step 2361, loss 0.0501097, acc 0.96875
2020-02-08T02:32:34.219564: step 2362, loss 0.0223417, acc 0.984375
2020-02-08T02:32:34.338141: step 2363, loss 0.0328283, acc 0.96875
2020-02-08T02:32:34.455850: step 2364, loss 0.0218826, acc 1
2020-02-08T02:32:34.571679: step 2365, loss 0.020872, acc 1
2020-02-08T02:32:34.688874: step 2366, loss 0.0203217, acc 1
2020-02-08T02:32:34.807578: step 2367, loss 0.049451, acc 0.984375
2020-02-08T02:32:34.923683: step 2368, loss 0.0202084, acc 1
2020-02-08T02:32:35.043184: step 2369, loss 0.0557773, acc 0.984375
2020-02-08T02:32:35.161010: step 2370, loss 0.0432247, acc 1
2020-02-08T02:32:35.277001: step 2371, loss 0.0292541, acc 1
2020-02-08T02:32:35.397700: step 2372, loss 0.0261128, acc 0.984375
2020-02-08T02:32:35.515210: step 2373, loss 0.0185385, acc 1
2020-02-08T02:32:35.629277: step 2374, loss 0.0102273, acc 1
2020-02-08T02:32:35.752865: step 2375, loss 0.0242345, acc 1
2020-02-08T02:32:35.870474: step 2376, loss 0.0382538, acc 0.984375
2020-02-08T02:32:35.988395: step 2377, loss 0.0237254, acc 1
2020-02-08T02:32:36.107009: step 2378, loss 0.0274368, acc 1
2020-02-08T02:32:36.225476: step 2379, loss 0.0110798, acc 1
2020-02-08T02:32:36.345694: step 2380, loss 0.0199425, acc 1
2020-02-08T02:32:36.462877: step 2381, loss 0.0122317, acc 1
2020-02-08T02:32:36.582634: step 2382, loss 0.11081, acc 0.96875
2020-02-08T02:32:36.701461: step 2383, loss 0.0443619, acc 0.984375
2020-02-08T02:32:36.818391: step 2384, loss 0.0212873, acc 1
2020-02-08T02:32:36.936031: step 2385, loss 0.0320651, acc 0.984375
2020-02-08T02:32:37.054971: step 2386, loss 0.0327917, acc 1
2020-02-08T02:32:37.170061: step 2387, loss 0.0217227, acc 1
2020-02-08T02:32:37.286938: step 2388, loss 0.0335244, acc 0.984375
2020-02-08T02:32:37.403731: step 2389, loss 0.0315386, acc 0.984375
2020-02-08T02:32:37.517958: step 2390, loss 0.0649278, acc 0.96875
2020-02-08T02:32:37.637330: step 2391, loss 0.0238986, acc 1
2020-02-08T02:32:37.759957: step 2392, loss 0.144311, acc 0.9375
2020-02-08T02:32:37.877098: step 2393, loss 0.0700478, acc 0.96875
2020-02-08T02:32:37.995704: step 2394, loss 0.033663, acc 1
2020-02-08T02:32:38.114943: step 2395, loss 0.0600195, acc 0.984375
2020-02-08T02:32:38.232824: step 2396, loss 0.0367102, acc 0.984375
2020-02-08T02:32:38.348528: step 2397, loss 0.0360976, acc 0.984375
2020-02-08T02:32:38.468554: step 2398, loss 0.054542, acc 0.984375
2020-02-08T02:32:38.584582: step 2399, loss 0.0423619, acc 1
2020-02-08T02:32:38.700654: step 2400, loss 0.0395913, acc 0.983333

Evaluation:
2020-02-08T02:32:38.895861: step 2400, loss 0.882896, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2400

2020-02-08T02:32:42.105096: step 2401, loss 0.0142059, acc 1
2020-02-08T02:32:42.221504: step 2402, loss 0.00551191, acc 1
2020-02-08T02:32:42.340427: step 2403, loss 0.0127264, acc 1
2020-02-08T02:32:42.455069: step 2404, loss 0.081938, acc 0.96875
2020-02-08T02:32:42.570774: step 2405, loss 0.016547, acc 1
2020-02-08T02:32:42.689192: step 2406, loss 0.0176763, acc 1
2020-02-08T02:32:42.813143: step 2407, loss 0.0496287, acc 0.984375
2020-02-08T02:32:42.930624: step 2408, loss 0.0556779, acc 0.984375
2020-02-08T02:32:43.049670: step 2409, loss 0.0174946, acc 1
2020-02-08T02:32:43.165721: step 2410, loss 0.0476799, acc 0.984375
2020-02-08T02:32:43.280131: step 2411, loss 0.0333947, acc 0.984375
2020-02-08T02:32:43.398792: step 2412, loss 0.107466, acc 0.984375
2020-02-08T02:32:43.516089: step 2413, loss 0.010298, acc 1
2020-02-08T02:32:43.630320: step 2414, loss 0.00577266, acc 1
2020-02-08T02:32:43.755256: step 2415, loss 0.10081, acc 0.9375
2020-02-08T02:32:43.871379: step 2416, loss 0.0261337, acc 1
2020-02-08T02:32:43.988642: step 2417, loss 0.00937458, acc 1
2020-02-08T02:32:44.106634: step 2418, loss 0.0449425, acc 0.984375
2020-02-08T02:32:44.223013: step 2419, loss 0.0469105, acc 0.984375
2020-02-08T02:32:44.343578: step 2420, loss 0.0452986, acc 0.984375
2020-02-08T02:32:44.463745: step 2421, loss 0.0128617, acc 1
2020-02-08T02:32:44.581318: step 2422, loss 0.01351, acc 1
2020-02-08T02:32:44.701409: step 2423, loss 0.0113444, acc 1
2020-02-08T02:32:44.817489: step 2424, loss 0.0132302, acc 1
2020-02-08T02:32:44.933177: step 2425, loss 0.0558764, acc 0.96875
2020-02-08T02:32:45.051478: step 2426, loss 0.0105612, acc 1
2020-02-08T02:32:45.169456: step 2427, loss 0.0281603, acc 1
2020-02-08T02:32:45.287964: step 2428, loss 0.00508464, acc 1
2020-02-08T02:32:45.407501: step 2429, loss 0.0371856, acc 0.984375
2020-02-08T02:32:45.523173: step 2430, loss 0.00876538, acc 1
2020-02-08T02:32:45.642787: step 2431, loss 0.0122282, acc 1
2020-02-08T02:32:45.761723: step 2432, loss 0.0410954, acc 1
2020-02-08T02:32:45.877180: step 2433, loss 0.0143375, acc 1
2020-02-08T02:32:46.000871: step 2434, loss 0.0601782, acc 0.984375
2020-02-08T02:32:46.116489: step 2435, loss 0.0292529, acc 1
2020-02-08T02:32:46.232819: step 2436, loss 0.0345132, acc 0.984375
2020-02-08T02:32:46.351815: step 2437, loss 0.00824191, acc 1
2020-02-08T02:32:46.471874: step 2438, loss 0.00801372, acc 1
2020-02-08T02:32:46.592760: step 2439, loss 0.0143439, acc 1
2020-02-08T02:32:46.710529: step 2440, loss 0.0235309, acc 1
2020-02-08T02:32:46.824366: step 2441, loss 0.0118016, acc 1
2020-02-08T02:32:46.941069: step 2442, loss 0.04337, acc 0.96875
2020-02-08T02:32:47.056353: step 2443, loss 0.0103729, acc 1
2020-02-08T02:32:47.171594: step 2444, loss 0.0185493, acc 0.984375
2020-02-08T02:32:47.290543: step 2445, loss 0.025784, acc 1
2020-02-08T02:32:47.414277: step 2446, loss 0.00754092, acc 1
2020-02-08T02:32:47.531136: step 2447, loss 0.039246, acc 0.984375
2020-02-08T02:32:47.649277: step 2448, loss 0.0186837, acc 1
2020-02-08T02:32:47.770860: step 2449, loss 0.0351577, acc 0.984375
2020-02-08T02:32:47.886369: step 2450, loss 0.0536784, acc 0.984375
2020-02-08T02:32:48.006064: step 2451, loss 0.0516534, acc 0.984375
2020-02-08T02:32:48.123375: step 2452, loss 0.0237082, acc 1
2020-02-08T02:32:48.244540: step 2453, loss 0.0356114, acc 0.984375
2020-02-08T02:32:48.363132: step 2454, loss 0.012336, acc 1
2020-02-08T02:32:48.480827: step 2455, loss 0.0187861, acc 1
2020-02-08T02:32:48.599238: step 2456, loss 0.039763, acc 1
2020-02-08T02:32:48.718990: step 2457, loss 0.0213446, acc 0.984375
2020-02-08T02:32:48.838488: step 2458, loss 0.0310573, acc 1
2020-02-08T02:32:48.957981: step 2459, loss 0.0607649, acc 0.984375
2020-02-08T02:32:49.073046: step 2460, loss 0.0498199, acc 0.984375
2020-02-08T02:32:49.190962: step 2461, loss 0.0393346, acc 0.984375
2020-02-08T02:32:49.309456: step 2462, loss 0.0176908, acc 1
2020-02-08T02:32:49.425953: step 2463, loss 0.0370886, acc 0.984375
2020-02-08T02:32:49.544980: step 2464, loss 0.0435824, acc 0.984375
2020-02-08T02:32:49.661315: step 2465, loss 0.0493937, acc 0.96875
2020-02-08T02:32:49.782861: step 2466, loss 0.0157987, acc 1
2020-02-08T02:32:49.901477: step 2467, loss 0.0298478, acc 1
2020-02-08T02:32:50.017048: step 2468, loss 0.041261, acc 0.984375
2020-02-08T02:32:50.134136: step 2469, loss 0.00716997, acc 1
2020-02-08T02:32:50.251228: step 2470, loss 0.0721214, acc 0.96875
2020-02-08T02:32:50.367868: step 2471, loss 0.0323793, acc 0.984375
2020-02-08T02:32:50.484211: step 2472, loss 0.0131479, acc 1
2020-02-08T02:32:50.599244: step 2473, loss 0.0307449, acc 0.984375
2020-02-08T02:32:50.719948: step 2474, loss 0.00914757, acc 1
2020-02-08T02:32:50.838948: step 2475, loss 0.0311471, acc 0.984375
2020-02-08T02:32:50.959404: step 2476, loss 0.028847, acc 0.984375
2020-02-08T02:32:51.073409: step 2477, loss 0.0217527, acc 1
2020-02-08T02:32:51.190137: step 2478, loss 0.0455446, acc 0.984375
2020-02-08T02:32:51.636992: step 2479, loss 0.0500359, acc 0.984375
2020-02-08T02:32:51.760928: step 2480, loss 0.0658857, acc 0.96875
2020-02-08T02:32:51.874958: step 2481, loss 0.0429825, acc 0.984375
2020-02-08T02:32:51.994894: step 2482, loss 0.0141113, acc 1
2020-02-08T02:32:52.113996: step 2483, loss 0.0319, acc 0.984375
2020-02-08T02:32:52.231986: step 2484, loss 0.0262219, acc 1
2020-02-08T02:32:52.349683: step 2485, loss 0.0515416, acc 0.984375
2020-02-08T02:32:52.467285: step 2486, loss 0.0421785, acc 0.984375
2020-02-08T02:32:52.586340: step 2487, loss 0.0849401, acc 0.96875
2020-02-08T02:32:52.705068: step 2488, loss 0.014023, acc 1
2020-02-08T02:32:52.820787: step 2489, loss 0.0220238, acc 1
2020-02-08T02:32:52.935782: step 2490, loss 0.0374884, acc 0.984375
2020-02-08T02:32:53.053808: step 2491, loss 0.0522471, acc 0.96875
2020-02-08T02:32:53.171183: step 2492, loss 0.0272534, acc 0.984375
2020-02-08T02:32:53.289743: step 2493, loss 0.0178156, acc 1
2020-02-08T02:32:53.408486: step 2494, loss 0.0227496, acc 0.984375
2020-02-08T02:32:53.522272: step 2495, loss 0.0650074, acc 0.96875
2020-02-08T02:32:53.637402: step 2496, loss 0.00737837, acc 1
2020-02-08T02:32:53.758883: step 2497, loss 0.00740199, acc 1
2020-02-08T02:32:53.871900: step 2498, loss 0.0481869, acc 0.984375
2020-02-08T02:32:53.987069: step 2499, loss 0.0323243, acc 0.984375
2020-02-08T02:32:54.106109: step 2500, loss 0.0315555, acc 0.984375

Evaluation:
2020-02-08T02:32:54.297649: step 2500, loss 0.914186, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2500

2020-02-08T02:32:55.886377: step 2501, loss 0.00944102, acc 1
2020-02-08T02:32:56.008133: step 2502, loss 0.0100839, acc 1
2020-02-08T02:32:56.124201: step 2503, loss 0.0985398, acc 0.984375
2020-02-08T02:32:56.244633: step 2504, loss 0.0614666, acc 0.96875
2020-02-08T02:32:56.362630: step 2505, loss 0.00871849, acc 1
2020-02-08T02:32:56.480168: step 2506, loss 0.0509312, acc 0.96875
2020-02-08T02:32:56.595629: step 2507, loss 0.0391011, acc 0.984375
2020-02-08T02:32:56.715455: step 2508, loss 0.0472933, acc 0.984375
2020-02-08T02:32:56.836193: step 2509, loss 0.023089, acc 0.984375
2020-02-08T02:32:56.953910: step 2510, loss 0.0688495, acc 0.9375
2020-02-08T02:32:57.074234: step 2511, loss 0.0573736, acc 0.96875
2020-02-08T02:32:57.190190: step 2512, loss 0.00850547, acc 1
2020-02-08T02:32:57.309450: step 2513, loss 0.0692253, acc 0.984375
2020-02-08T02:32:57.424131: step 2514, loss 0.0677502, acc 0.984375
2020-02-08T02:32:57.541419: step 2515, loss 0.026206, acc 1
2020-02-08T02:32:57.658373: step 2516, loss 0.0499406, acc 0.984375
2020-02-08T02:32:57.779369: step 2517, loss 0.0235502, acc 0.984375
2020-02-08T02:32:57.898840: step 2518, loss 0.052157, acc 0.953125
2020-02-08T02:32:58.018763: step 2519, loss 0.0218923, acc 0.984375
2020-02-08T02:32:58.135586: step 2520, loss 0.0430219, acc 0.96875
2020-02-08T02:32:58.256023: step 2521, loss 0.0948014, acc 0.984375
2020-02-08T02:32:58.370270: step 2522, loss 0.00954455, acc 1
2020-02-08T02:32:58.486016: step 2523, loss 0.0265223, acc 1
2020-02-08T02:32:58.604073: step 2524, loss 0.0913203, acc 0.96875
2020-02-08T02:32:58.724245: step 2525, loss 0.0183347, acc 1
2020-02-08T02:32:58.844477: step 2526, loss 0.0189378, acc 1
2020-02-08T02:32:58.958963: step 2527, loss 0.0444478, acc 0.96875
2020-02-08T02:32:59.077009: step 2528, loss 0.0122826, acc 1
2020-02-08T02:32:59.193867: step 2529, loss 0.0142754, acc 1
2020-02-08T02:32:59.311877: step 2530, loss 0.0705655, acc 0.953125
2020-02-08T02:32:59.430002: step 2531, loss 0.0382753, acc 0.984375
2020-02-08T02:32:59.546667: step 2532, loss 0.0130552, acc 1
2020-02-08T02:32:59.663594: step 2533, loss 0.0166214, acc 1
2020-02-08T02:32:59.785709: step 2534, loss 0.0290889, acc 1
2020-02-08T02:32:59.903740: step 2535, loss 0.0377615, acc 0.984375
2020-02-08T02:33:00.020629: step 2536, loss 0.0158533, acc 1
2020-02-08T02:33:00.137781: step 2537, loss 0.00893182, acc 1
2020-02-08T02:33:00.253978: step 2538, loss 0.0295924, acc 0.984375
2020-02-08T02:33:00.371628: step 2539, loss 0.021769, acc 1
2020-02-08T02:33:00.488521: step 2540, loss 0.0195245, acc 1
2020-02-08T02:33:00.607513: step 2541, loss 0.0188494, acc 1
2020-02-08T02:33:00.727819: step 2542, loss 0.0301384, acc 0.984375
2020-02-08T02:33:00.845648: step 2543, loss 0.0147589, acc 1
2020-02-08T02:33:00.963715: step 2544, loss 0.0115861, acc 1
2020-02-08T02:33:01.080489: step 2545, loss 0.0362734, acc 0.984375
2020-02-08T02:33:01.198583: step 2546, loss 0.0599054, acc 0.984375
2020-02-08T02:33:01.317972: step 2547, loss 0.0160682, acc 1
2020-02-08T02:33:01.433874: step 2548, loss 0.0181198, acc 1
2020-02-08T02:33:01.552534: step 2549, loss 0.0577955, acc 0.984375
2020-02-08T02:33:01.665009: step 2550, loss 0.0636082, acc 0.966667
2020-02-08T02:33:01.789559: step 2551, loss 0.022613, acc 0.984375
2020-02-08T02:33:01.911611: step 2552, loss 0.0368317, acc 0.96875
2020-02-08T02:33:02.029771: step 2553, loss 0.0242059, acc 1
2020-02-08T02:33:02.144354: step 2554, loss 0.00725025, acc 1
2020-02-08T02:33:02.261570: step 2555, loss 0.0284466, acc 0.984375
2020-02-08T02:33:02.379618: step 2556, loss 0.0199446, acc 0.984375
2020-02-08T02:33:02.496152: step 2557, loss 0.0386347, acc 0.984375
2020-02-08T02:33:02.613554: step 2558, loss 0.0134539, acc 1
2020-02-08T02:33:02.737049: step 2559, loss 0.0326721, acc 0.984375
2020-02-08T02:33:02.856364: step 2560, loss 0.0111527, acc 1
2020-02-08T02:33:02.978797: step 2561, loss 0.0667944, acc 0.96875
2020-02-08T02:33:03.099363: step 2562, loss 0.0526648, acc 0.96875
2020-02-08T02:33:03.217783: step 2563, loss 0.0246775, acc 0.984375
2020-02-08T02:33:03.337384: step 2564, loss 0.0462103, acc 0.984375
2020-02-08T02:33:03.458554: step 2565, loss 0.037291, acc 0.96875
2020-02-08T02:33:03.577493: step 2566, loss 0.0900662, acc 0.96875
2020-02-08T02:33:03.697766: step 2567, loss 0.0099108, acc 1
2020-02-08T02:33:03.818254: step 2568, loss 0.0487853, acc 0.984375
2020-02-08T02:33:03.936042: step 2569, loss 0.0197813, acc 1
2020-02-08T02:33:04.052582: step 2570, loss 0.0147261, acc 1
2020-02-08T02:33:04.170632: step 2571, loss 0.0155547, acc 1
2020-02-08T02:33:04.288427: step 2572, loss 0.0394329, acc 0.984375
2020-02-08T02:33:04.408722: step 2573, loss 0.0183325, acc 1
2020-02-08T02:33:04.523110: step 2574, loss 0.033034, acc 0.984375
2020-02-08T02:33:04.637234: step 2575, loss 0.0319231, acc 1
2020-02-08T02:33:04.759818: step 2576, loss 0.0168572, acc 1
2020-02-08T02:33:04.875194: step 2577, loss 0.0397453, acc 0.984375
2020-02-08T02:33:04.994704: step 2578, loss 0.0168891, acc 1
2020-02-08T02:33:05.114167: step 2579, loss 0.0261522, acc 1
2020-02-08T02:33:05.230508: step 2580, loss 0.0303851, acc 1
2020-02-08T02:33:05.347978: step 2581, loss 0.0795028, acc 0.984375
2020-02-08T02:33:05.465557: step 2582, loss 0.0237395, acc 1
2020-02-08T02:33:05.581397: step 2583, loss 0.0566964, acc 0.984375
2020-02-08T02:33:05.705021: step 2584, loss 0.00562931, acc 1
2020-02-08T02:33:05.819694: step 2585, loss 0.011931, acc 1
2020-02-08T02:33:05.938890: step 2586, loss 0.0314865, acc 0.984375
2020-02-08T02:33:06.055184: step 2587, loss 0.013238, acc 1
2020-02-08T02:33:06.168537: step 2588, loss 0.0250969, acc 0.984375
2020-02-08T02:33:06.286525: step 2589, loss 0.00915662, acc 1
2020-02-08T02:33:06.405132: step 2590, loss 0.0485372, acc 0.984375
2020-02-08T02:33:06.523404: step 2591, loss 0.0557994, acc 0.984375
2020-02-08T02:33:06.641718: step 2592, loss 0.0424617, acc 0.96875
2020-02-08T02:33:06.765914: step 2593, loss 0.0102329, acc 1
2020-02-08T02:33:06.884494: step 2594, loss 0.022326, acc 1
2020-02-08T02:33:07.006400: step 2595, loss 0.0465136, acc 0.984375
2020-02-08T02:33:07.125020: step 2596, loss 0.011058, acc 1
2020-02-08T02:33:07.244224: step 2597, loss 0.0197402, acc 1
2020-02-08T02:33:07.363770: step 2598, loss 0.00875258, acc 1
2020-02-08T02:33:07.482980: step 2599, loss 0.0626666, acc 0.96875
2020-02-08T02:33:07.600971: step 2600, loss 0.0196762, acc 1

Evaluation:
2020-02-08T02:33:07.798999: step 2600, loss 0.939588, acc 0.732645

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2600

2020-02-08T02:33:09.312117: step 2601, loss 0.00499006, acc 1
2020-02-08T02:33:09.428393: step 2602, loss 0.0162329, acc 1
2020-02-08T02:33:09.545930: step 2603, loss 0.0205856, acc 1
2020-02-08T02:33:09.662520: step 2604, loss 0.0166841, acc 1
2020-02-08T02:33:09.781977: step 2605, loss 0.0101345, acc 1
2020-02-08T02:33:09.901546: step 2606, loss 0.0245577, acc 1
2020-02-08T02:33:10.019504: step 2607, loss 0.047402, acc 0.96875
2020-02-08T02:33:10.136157: step 2608, loss 0.017448, acc 1
2020-02-08T02:33:10.254231: step 2609, loss 0.0705706, acc 0.96875
2020-02-08T02:33:10.369210: step 2610, loss 0.0149462, acc 1
2020-02-08T02:33:10.485014: step 2611, loss 0.0195546, acc 1
2020-02-08T02:33:10.602252: step 2612, loss 0.0244412, acc 0.984375
2020-02-08T02:33:10.723724: step 2613, loss 0.00634969, acc 1
2020-02-08T02:33:10.841701: step 2614, loss 0.0160151, acc 1
2020-02-08T02:33:10.959759: step 2615, loss 0.0279465, acc 1
2020-02-08T02:33:11.075335: step 2616, loss 0.023531, acc 1
2020-02-08T02:33:11.194503: step 2617, loss 0.0256822, acc 1
2020-02-08T02:33:11.313404: step 2618, loss 0.0225402, acc 0.984375
2020-02-08T02:33:11.431649: step 2619, loss 0.0141596, acc 1
2020-02-08T02:33:11.551754: step 2620, loss 0.0345533, acc 0.984375
2020-02-08T02:33:11.669767: step 2621, loss 0.039658, acc 0.96875
2020-02-08T02:33:11.793676: step 2622, loss 0.0539214, acc 0.984375
2020-02-08T02:33:11.911315: step 2623, loss 0.0073883, acc 1
2020-02-08T02:33:12.026294: step 2624, loss 0.0284948, acc 1
2020-02-08T02:33:12.145582: step 2625, loss 0.044619, acc 0.984375
2020-02-08T02:33:12.263134: step 2626, loss 0.0683346, acc 0.984375
2020-02-08T02:33:12.377639: step 2627, loss 0.010125, acc 1
2020-02-08T02:33:12.495494: step 2628, loss 0.0102946, acc 1
2020-02-08T02:33:12.613706: step 2629, loss 0.0131717, acc 1
2020-02-08T02:33:12.738877: step 2630, loss 0.01281, acc 1
2020-02-08T02:33:12.858091: step 2631, loss 0.0210783, acc 1
2020-02-08T02:33:12.979053: step 2632, loss 0.0744191, acc 0.96875
2020-02-08T02:33:13.097628: step 2633, loss 0.0263596, acc 1
2020-02-08T02:33:13.216740: step 2634, loss 0.0468082, acc 0.984375
2020-02-08T02:33:13.337482: step 2635, loss 0.022323, acc 0.984375
2020-02-08T02:33:13.457299: step 2636, loss 0.055953, acc 0.96875
2020-02-08T02:33:13.574486: step 2637, loss 0.04372, acc 0.984375
2020-02-08T02:33:13.703205: step 2638, loss 0.05648, acc 0.96875
2020-02-08T02:33:13.818822: step 2639, loss 0.0191561, acc 1
2020-02-08T02:33:13.935937: step 2640, loss 0.0738892, acc 0.984375
2020-02-08T02:33:14.053863: step 2641, loss 0.0147068, acc 1
2020-02-08T02:33:14.170126: step 2642, loss 0.019678, acc 1
2020-02-08T02:33:14.287694: step 2643, loss 0.00981507, acc 1
2020-02-08T02:33:14.406241: step 2644, loss 0.0165329, acc 0.984375
2020-02-08T02:33:14.522145: step 2645, loss 0.0259817, acc 0.984375
2020-02-08T02:33:14.640262: step 2646, loss 0.0512349, acc 0.984375
2020-02-08T02:33:14.760175: step 2647, loss 0.0139383, acc 1
2020-02-08T02:33:14.876720: step 2648, loss 0.00970135, acc 1
2020-02-08T02:33:15.000085: step 2649, loss 0.0345385, acc 0.984375
2020-02-08T02:33:15.117269: step 2650, loss 0.0101957, acc 1
2020-02-08T02:33:15.239436: step 2651, loss 0.0395247, acc 1
2020-02-08T02:33:15.357746: step 2652, loss 0.0284399, acc 0.984375
2020-02-08T02:33:15.473862: step 2653, loss 0.0143131, acc 1
2020-02-08T02:33:15.593034: step 2654, loss 0.0106852, acc 1
2020-02-08T02:33:15.715127: step 2655, loss 0.0235908, acc 0.984375
2020-02-08T02:33:15.831414: step 2656, loss 0.0141103, acc 1
2020-02-08T02:33:15.949710: step 2657, loss 0.00394299, acc 1
2020-02-08T02:33:16.066943: step 2658, loss 0.00850615, acc 1
2020-02-08T02:33:16.186081: step 2659, loss 0.0234983, acc 0.984375
2020-02-08T02:33:16.306616: step 2660, loss 0.0618002, acc 0.96875
2020-02-08T02:33:16.423391: step 2661, loss 0.00969861, acc 1
2020-02-08T02:33:16.542464: step 2662, loss 0.0514215, acc 0.984375
2020-02-08T02:33:16.657835: step 2663, loss 0.0156994, acc 1
2020-02-08T02:33:16.778440: step 2664, loss 0.0250548, acc 0.984375
2020-02-08T02:33:16.898873: step 2665, loss 0.0249963, acc 0.984375
2020-02-08T02:33:17.015797: step 2666, loss 0.0119457, acc 1
2020-02-08T02:33:17.134835: step 2667, loss 0.0194795, acc 0.984375
2020-02-08T02:33:17.250925: step 2668, loss 0.0157498, acc 1
2020-02-08T02:33:17.366570: step 2669, loss 0.0203528, acc 1
2020-02-08T02:33:17.483241: step 2670, loss 0.0397794, acc 0.984375
2020-02-08T02:33:17.601543: step 2671, loss 0.0444452, acc 0.984375
2020-02-08T02:33:17.721343: step 2672, loss 0.00720786, acc 1
2020-02-08T02:33:17.838354: step 2673, loss 0.0295589, acc 0.984375
2020-02-08T02:33:17.956592: step 2674, loss 0.0202967, acc 1
2020-02-08T02:33:18.073213: step 2675, loss 0.019206, acc 1
2020-02-08T02:33:18.191173: step 2676, loss 0.00752622, acc 1
2020-02-08T02:33:18.311209: step 2677, loss 0.00691874, acc 1
2020-02-08T02:33:18.427699: step 2678, loss 0.0158353, acc 1
2020-02-08T02:33:18.544160: step 2679, loss 0.0365506, acc 1
2020-02-08T02:33:18.664645: step 2680, loss 0.0254205, acc 0.984375
2020-02-08T02:33:18.783981: step 2681, loss 0.037163, acc 0.984375
2020-02-08T02:33:18.902146: step 2682, loss 0.00616835, acc 1
2020-02-08T02:33:19.020366: step 2683, loss 0.111173, acc 0.953125
2020-02-08T02:33:19.141863: step 2684, loss 0.021056, acc 1
2020-02-08T02:33:19.260400: step 2685, loss 0.00919661, acc 1
2020-02-08T02:33:19.375104: step 2686, loss 0.027987, acc 0.984375
2020-02-08T02:33:19.493811: step 2687, loss 0.0430342, acc 0.984375
2020-02-08T02:33:19.615951: step 2688, loss 0.0277903, acc 1
2020-02-08T02:33:19.738081: step 2689, loss 0.0175886, acc 1
2020-02-08T02:33:19.857583: step 2690, loss 0.0524121, acc 0.984375
2020-02-08T02:33:19.977283: step 2691, loss 0.0547926, acc 0.96875
2020-02-08T02:33:20.094992: step 2692, loss 0.050907, acc 0.984375
2020-02-08T02:33:20.212718: step 2693, loss 0.0650248, acc 0.953125
2020-02-08T02:33:20.328033: step 2694, loss 0.00923795, acc 1
2020-02-08T02:33:20.448751: step 2695, loss 0.0339457, acc 0.984375
2020-02-08T02:33:20.568026: step 2696, loss 0.0334375, acc 1
2020-02-08T02:33:20.689763: step 2697, loss 0.0696722, acc 0.984375
2020-02-08T02:33:20.809810: step 2698, loss 0.0248994, acc 1
2020-02-08T02:33:20.930637: step 2699, loss 0.022315, acc 0.984375
2020-02-08T02:33:21.045464: step 2700, loss 0.0117426, acc 1

Evaluation:
2020-02-08T02:33:21.235899: step 2700, loss 0.951712, acc 0.731707

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2700

2020-02-08T02:33:23.872985: step 2701, loss 0.0275717, acc 1
2020-02-08T02:33:23.990430: step 2702, loss 0.0702375, acc 0.96875
2020-02-08T02:33:24.108044: step 2703, loss 0.0316818, acc 0.984375
2020-02-08T02:33:24.225492: step 2704, loss 0.0203561, acc 0.984375
2020-02-08T02:33:24.339818: step 2705, loss 0.0208118, acc 1
2020-02-08T02:33:24.456514: step 2706, loss 0.138082, acc 0.953125
2020-02-08T02:33:24.573207: step 2707, loss 0.00824737, acc 1
2020-02-08T02:33:24.691727: step 2708, loss 0.0220143, acc 0.984375
2020-02-08T02:33:24.809446: step 2709, loss 0.00898119, acc 1
2020-02-08T02:33:24.927531: step 2710, loss 0.0256376, acc 0.984375
2020-02-08T02:33:25.044797: step 2711, loss 0.0535089, acc 0.984375
2020-02-08T02:33:25.161555: step 2712, loss 0.0567598, acc 0.984375
2020-02-08T02:33:25.280185: step 2713, loss 0.0384604, acc 0.984375
2020-02-08T02:33:25.397383: step 2714, loss 0.0215544, acc 1
2020-02-08T02:33:25.513387: step 2715, loss 0.00413047, acc 1
2020-02-08T02:33:25.632140: step 2716, loss 0.0298823, acc 0.984375
2020-02-08T02:33:25.754503: step 2717, loss 0.00476768, acc 1
2020-02-08T02:33:25.871115: step 2718, loss 0.00998839, acc 1
2020-02-08T02:33:25.989835: step 2719, loss 0.0228628, acc 0.984375
2020-02-08T02:33:26.108458: step 2720, loss 0.027912, acc 1
2020-02-08T02:33:26.223317: step 2721, loss 0.020062, acc 0.984375
2020-02-08T02:33:26.340644: step 2722, loss 0.0389542, acc 0.984375
2020-02-08T02:33:26.459055: step 2723, loss 0.00483985, acc 1
2020-02-08T02:33:26.574542: step 2724, loss 0.0351738, acc 0.984375
2020-02-08T02:33:26.694010: step 2725, loss 0.0346593, acc 0.984375
2020-02-08T02:33:26.810153: step 2726, loss 0.0193419, acc 1
2020-02-08T02:33:26.928058: step 2727, loss 0.006889, acc 1
2020-02-08T02:33:27.047499: step 2728, loss 0.018814, acc 1
2020-02-08T02:33:27.165497: step 2729, loss 0.0179826, acc 0.984375
2020-02-08T02:33:27.281456: step 2730, loss 0.0326275, acc 0.984375
2020-02-08T02:33:27.400203: step 2731, loss 0.00734681, acc 1
2020-02-08T02:33:27.516558: step 2732, loss 0.00840274, acc 1
2020-02-08T02:33:27.629429: step 2733, loss 0.00901338, acc 1
2020-02-08T02:33:27.751417: step 2734, loss 0.00927938, acc 1
2020-02-08T02:33:27.867239: step 2735, loss 0.0247711, acc 0.984375
2020-02-08T02:33:27.982100: step 2736, loss 0.0238535, acc 0.984375
2020-02-08T02:33:28.101248: step 2737, loss 0.0316183, acc 0.984375
2020-02-08T02:33:28.216288: step 2738, loss 0.0102033, acc 1
2020-02-08T02:33:28.334355: step 2739, loss 0.00683645, acc 1
2020-02-08T02:33:28.454991: step 2740, loss 0.0139332, acc 1
2020-02-08T02:33:28.572898: step 2741, loss 0.0511199, acc 0.984375
2020-02-08T02:33:28.693821: step 2742, loss 0.00889124, acc 1
2020-02-08T02:33:28.816985: step 2743, loss 0.0225338, acc 0.984375
2020-02-08T02:33:28.933950: step 2744, loss 0.00799521, acc 1
2020-02-08T02:33:29.052368: step 2745, loss 0.0348354, acc 0.984375
2020-02-08T02:33:29.169149: step 2746, loss 0.0166998, acc 1
2020-02-08T02:33:29.283530: step 2747, loss 0.00747466, acc 1
2020-02-08T02:33:29.402397: step 2748, loss 0.0384008, acc 0.96875
2020-02-08T02:33:29.520114: step 2749, loss 0.0350911, acc 0.984375
2020-02-08T02:33:29.637690: step 2750, loss 0.0144741, acc 1
2020-02-08T02:33:29.760638: step 2751, loss 0.015146, acc 1
2020-02-08T02:33:29.877661: step 2752, loss 0.0246327, acc 0.984375
2020-02-08T02:33:29.997012: step 2753, loss 0.0112079, acc 1
2020-02-08T02:33:30.112178: step 2754, loss 0.0245476, acc 0.984375
2020-02-08T02:33:30.227126: step 2755, loss 0.0154779, acc 1
2020-02-08T02:33:30.342624: step 2756, loss 0.0221171, acc 0.984375
2020-02-08T02:33:30.462619: step 2757, loss 0.0199531, acc 0.984375
2020-02-08T02:33:30.579694: step 2758, loss 0.00983934, acc 1
2020-02-08T02:33:30.698124: step 2759, loss 0.0280587, acc 1
2020-02-08T02:33:30.817440: step 2760, loss 0.00504512, acc 1
2020-02-08T02:33:30.934379: step 2761, loss 0.0133462, acc 1
2020-02-08T02:33:31.052970: step 2762, loss 0.00394701, acc 1
2020-02-08T02:33:31.170247: step 2763, loss 0.0219157, acc 1
2020-02-08T02:33:31.289335: step 2764, loss 0.00934838, acc 1
2020-02-08T02:33:31.408256: step 2765, loss 0.0926591, acc 0.984375
2020-02-08T02:33:31.523567: step 2766, loss 0.0287755, acc 0.96875
2020-02-08T02:33:31.644478: step 2767, loss 0.0457032, acc 0.96875
2020-02-08T02:33:31.766605: step 2768, loss 0.0197883, acc 1
2020-02-08T02:33:31.883342: step 2769, loss 0.00635193, acc 1
2020-02-08T02:33:32.005741: step 2770, loss 0.00646492, acc 1
2020-02-08T02:33:32.121246: step 2771, loss 0.0204918, acc 1
2020-02-08T02:33:32.240488: step 2772, loss 0.0159329, acc 1
2020-02-08T02:33:32.358854: step 2773, loss 0.00593174, acc 1
2020-02-08T02:33:32.476684: step 2774, loss 0.0217592, acc 1
2020-02-08T02:33:32.594314: step 2775, loss 0.0241949, acc 1
2020-02-08T02:33:32.713304: step 2776, loss 0.00992625, acc 1
2020-02-08T02:33:32.830017: step 2777, loss 0.0121929, acc 1
2020-02-08T02:33:32.948572: step 2778, loss 0.0560331, acc 0.984375
2020-02-08T02:33:33.065498: step 2779, loss 0.0549756, acc 0.984375
2020-02-08T02:33:33.184221: step 2780, loss 0.00906161, acc 1
2020-02-08T02:33:33.302500: step 2781, loss 0.0172684, acc 1
2020-02-08T02:33:33.420743: step 2782, loss 0.0376599, acc 0.984375
2020-02-08T02:33:33.536554: step 2783, loss 0.0291416, acc 0.984375
2020-02-08T02:33:33.655079: step 2784, loss 0.0175142, acc 1
2020-02-08T02:33:33.774769: step 2785, loss 0.0515776, acc 0.984375
2020-02-08T02:33:33.891995: step 2786, loss 0.0108919, acc 1
2020-02-08T02:33:34.012469: step 2787, loss 0.00381856, acc 1
2020-02-08T02:33:34.126945: step 2788, loss 0.00690472, acc 1
2020-02-08T02:33:34.244557: step 2789, loss 0.0271112, acc 0.984375
2020-02-08T02:33:34.361674: step 2790, loss 0.0210442, acc 1
2020-02-08T02:33:34.477240: step 2791, loss 0.021834, acc 0.984375
2020-02-08T02:33:34.593913: step 2792, loss 0.0275427, acc 1
2020-02-08T02:33:34.713026: step 2793, loss 0.020463, acc 1
2020-02-08T02:33:34.831678: step 2794, loss 0.013059, acc 1
2020-02-08T02:33:34.949080: step 2795, loss 0.00573065, acc 1
2020-02-08T02:33:35.064539: step 2796, loss 0.0145931, acc 1
2020-02-08T02:33:35.181752: step 2797, loss 0.0307512, acc 0.984375
2020-02-08T02:33:35.300685: step 2798, loss 0.0128572, acc 1
2020-02-08T02:33:35.418639: step 2799, loss 0.0223583, acc 1
2020-02-08T02:33:35.537718: step 2800, loss 0.0422328, acc 0.984375

Evaluation:
2020-02-08T02:33:35.730366: step 2800, loss 1.01844, acc 0.728893

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2800

2020-02-08T02:33:37.305120: step 2801, loss 0.022903, acc 0.984375
2020-02-08T02:33:37.422869: step 2802, loss 0.0368959, acc 0.984375
2020-02-08T02:33:37.539096: step 2803, loss 0.00424998, acc 1
2020-02-08T02:33:37.657058: step 2804, loss 0.0999014, acc 0.96875
2020-02-08T02:33:37.777095: step 2805, loss 0.0285937, acc 1
2020-02-08T02:33:37.892864: step 2806, loss 0.0125658, acc 1
2020-02-08T02:33:38.011803: step 2807, loss 0.0363585, acc 1
2020-02-08T02:33:38.129358: step 2808, loss 0.0238539, acc 0.984375
2020-02-08T02:33:38.249266: step 2809, loss 0.0105151, acc 1
2020-02-08T02:33:38.366833: step 2810, loss 0.0443167, acc 0.984375
2020-02-08T02:33:38.483500: step 2811, loss 0.092239, acc 0.96875
2020-02-08T02:33:38.599879: step 2812, loss 0.019968, acc 1
2020-02-08T02:33:38.717076: step 2813, loss 0.0438823, acc 0.984375
2020-02-08T02:33:38.836418: step 2814, loss 0.0347775, acc 1
2020-02-08T02:33:38.956845: step 2815, loss 0.00841445, acc 1
2020-02-08T02:33:39.076588: step 2816, loss 0.0421767, acc 0.984375
2020-02-08T02:33:39.194684: step 2817, loss 0.00674623, acc 1
2020-02-08T02:33:39.310422: step 2818, loss 0.0198208, acc 1
2020-02-08T02:33:39.423843: step 2819, loss 0.0069272, acc 1
2020-02-08T02:33:39.543552: step 2820, loss 0.00258052, acc 1
2020-02-08T02:33:39.659488: step 2821, loss 0.0598273, acc 0.984375
2020-02-08T02:33:39.779171: step 2822, loss 0.00720527, acc 1
2020-02-08T02:33:39.898082: step 2823, loss 0.0148636, acc 1
2020-02-08T02:33:40.017048: step 2824, loss 0.00636861, acc 1
2020-02-08T02:33:40.134071: step 2825, loss 0.0141347, acc 1
2020-02-08T02:33:40.250609: step 2826, loss 0.0357271, acc 0.984375
2020-02-08T02:33:40.369428: step 2827, loss 0.0205732, acc 1
2020-02-08T02:33:40.488196: step 2828, loss 0.0029778, acc 1
2020-02-08T02:33:40.605178: step 2829, loss 0.00988388, acc 1
2020-02-08T02:33:40.723300: step 2830, loss 0.00770857, acc 1
2020-02-08T02:33:40.841172: step 2831, loss 0.0120895, acc 1
2020-02-08T02:33:40.958738: step 2832, loss 0.0148951, acc 1
2020-02-08T02:33:41.073612: step 2833, loss 0.0620415, acc 0.96875
2020-02-08T02:33:41.192736: step 2834, loss 0.038845, acc 0.984375
2020-02-08T02:33:41.311267: step 2835, loss 0.0216741, acc 0.984375
2020-02-08T02:33:41.425276: step 2836, loss 0.0134613, acc 1
2020-02-08T02:33:41.544464: step 2837, loss 0.13407, acc 0.953125
2020-02-08T02:33:41.663464: step 2838, loss 0.0220293, acc 1
2020-02-08T02:33:41.781832: step 2839, loss 0.0335207, acc 0.96875
2020-02-08T02:33:41.900770: step 2840, loss 0.0134187, acc 1
2020-02-08T02:33:42.018370: step 2841, loss 0.0120662, acc 1
2020-02-08T02:33:42.137898: step 2842, loss 0.0592331, acc 0.96875
2020-02-08T02:33:42.256208: step 2843, loss 0.0113299, acc 1
2020-02-08T02:33:42.373201: step 2844, loss 0.0244044, acc 0.984375
2020-02-08T02:33:42.488743: step 2845, loss 0.0308409, acc 0.984375
2020-02-08T02:33:42.607508: step 2846, loss 0.0289202, acc 0.984375
2020-02-08T02:33:42.728238: step 2847, loss 0.00619956, acc 1
2020-02-08T02:33:42.848094: step 2848, loss 0.0139505, acc 1
2020-02-08T02:33:42.964705: step 2849, loss 0.0206142, acc 1
2020-02-08T02:33:43.077631: step 2850, loss 0.0144974, acc 1
2020-02-08T02:33:43.198078: step 2851, loss 0.00718025, acc 1
2020-02-08T02:33:43.313851: step 2852, loss 0.00375392, acc 1
2020-02-08T02:33:43.430688: step 2853, loss 0.0262654, acc 0.984375
2020-02-08T02:33:43.549655: step 2854, loss 0.00725467, acc 1
2020-02-08T02:33:43.667598: step 2855, loss 0.111854, acc 0.953125
2020-02-08T02:33:43.791265: step 2856, loss 0.00882302, acc 1
2020-02-08T02:33:43.914750: step 2857, loss 0.0183437, acc 1
2020-02-08T02:33:44.032956: step 2858, loss 0.0041396, acc 1
2020-02-08T02:33:44.149721: step 2859, loss 0.0276114, acc 0.984375
2020-02-08T02:33:44.266557: step 2860, loss 0.0139132, acc 1
2020-02-08T02:33:44.383979: step 2861, loss 0.0490652, acc 0.984375
2020-02-08T02:33:44.504020: step 2862, loss 0.0619662, acc 0.984375
2020-02-08T02:33:44.620726: step 2863, loss 0.00175408, acc 1
2020-02-08T02:33:44.744944: step 2864, loss 0.00431481, acc 1
2020-02-08T02:33:44.861913: step 2865, loss 0.00369285, acc 1
2020-02-08T02:33:44.979871: step 2866, loss 0.010932, acc 1
2020-02-08T02:33:45.098443: step 2867, loss 0.00760343, acc 1
2020-02-08T02:33:45.217162: step 2868, loss 0.00902273, acc 1
2020-02-08T02:33:45.335930: step 2869, loss 0.013248, acc 1
2020-02-08T02:33:45.453453: step 2870, loss 0.0404913, acc 0.984375
2020-02-08T02:33:45.572118: step 2871, loss 0.0157768, acc 1
2020-02-08T02:33:45.689853: step 2872, loss 0.0147208, acc 1
2020-02-08T02:33:45.807879: step 2873, loss 0.0296792, acc 0.984375
2020-02-08T02:33:45.925416: step 2874, loss 0.0238581, acc 1
2020-02-08T02:33:46.042042: step 2875, loss 0.00789975, acc 1
2020-02-08T02:33:46.158881: step 2876, loss 0.00724035, acc 1
2020-02-08T02:33:46.275154: step 2877, loss 0.00560227, acc 1
2020-02-08T02:33:46.390785: step 2878, loss 0.00391305, acc 1
2020-02-08T02:33:46.514562: step 2879, loss 0.0307554, acc 1
2020-02-08T02:33:46.631992: step 2880, loss 0.0218865, acc 1
2020-02-08T02:33:46.754406: step 2881, loss 0.0192118, acc 1
2020-02-08T02:33:46.872235: step 2882, loss 0.00552688, acc 1
2020-02-08T02:33:46.989249: step 2883, loss 0.0248751, acc 0.984375
2020-02-08T02:33:47.105481: step 2884, loss 0.086089, acc 0.984375
2020-02-08T02:33:47.219650: step 2885, loss 0.0108556, acc 1
2020-02-08T02:33:47.338467: step 2886, loss 0.0446842, acc 0.984375
2020-02-08T02:33:47.454966: step 2887, loss 0.0156567, acc 1
2020-02-08T02:33:47.573118: step 2888, loss 0.00290627, acc 1
2020-02-08T02:33:47.690917: step 2889, loss 0.00741696, acc 1
2020-02-08T02:33:47.813555: step 2890, loss 0.0019641, acc 1
2020-02-08T02:33:47.929488: step 2891, loss 0.0541228, acc 0.984375
2020-02-08T02:33:48.047891: step 2892, loss 0.0525313, acc 0.984375
2020-02-08T02:33:48.163776: step 2893, loss 0.0223029, acc 1
2020-02-08T02:33:48.284647: step 2894, loss 0.0186368, acc 1
2020-02-08T02:33:48.403034: step 2895, loss 0.00474285, acc 1
2020-02-08T02:33:48.519927: step 2896, loss 0.0075586, acc 1
2020-02-08T02:33:48.636083: step 2897, loss 0.0107727, acc 1
2020-02-08T02:33:48.762662: step 2898, loss 0.0216091, acc 1
2020-02-08T02:33:48.879490: step 2899, loss 0.0124131, acc 1
2020-02-08T02:33:48.999940: step 2900, loss 0.0152964, acc 1

Evaluation:
2020-02-08T02:33:49.192558: step 2900, loss 1.02428, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-2900

2020-02-08T02:33:51.270741: step 2901, loss 0.0037369, acc 1
2020-02-08T02:33:51.388535: step 2902, loss 0.00304222, acc 1
2020-02-08T02:33:51.772079: step 2903, loss 0.0223803, acc 0.984375
2020-02-08T02:33:51.893837: step 2904, loss 0.00670965, acc 1
2020-02-08T02:33:52.013652: step 2905, loss 0.00881165, acc 1
2020-02-08T02:33:52.131062: step 2906, loss 0.0231727, acc 0.984375
2020-02-08T02:33:52.250048: step 2907, loss 0.0207755, acc 1
2020-02-08T02:33:52.367562: step 2908, loss 0.0371469, acc 0.984375
2020-02-08T02:33:52.487796: step 2909, loss 0.00335715, acc 1
2020-02-08T02:33:52.605828: step 2910, loss 0.00503712, acc 1
2020-02-08T02:33:52.724179: step 2911, loss 0.0154353, acc 1
2020-02-08T02:33:52.844053: step 2912, loss 0.00711525, acc 1
2020-02-08T02:33:52.963712: step 2913, loss 0.0264331, acc 0.984375
2020-02-08T02:33:53.080528: step 2914, loss 0.0464188, acc 0.984375
2020-02-08T02:33:53.197660: step 2915, loss 0.00994286, acc 1
2020-02-08T02:33:53.315628: step 2916, loss 0.00598355, acc 1
2020-02-08T02:33:53.431237: step 2917, loss 0.0059338, acc 1
2020-02-08T02:33:53.549583: step 2918, loss 0.00601562, acc 1
2020-02-08T02:33:53.665316: step 2919, loss 0.036522, acc 0.984375
2020-02-08T02:33:53.783731: step 2920, loss 0.00909195, acc 1
2020-02-08T02:33:53.902666: step 2921, loss 0.00868613, acc 1
2020-02-08T02:33:54.020333: step 2922, loss 0.0203657, acc 1
2020-02-08T02:33:54.135945: step 2923, loss 0.0292154, acc 0.984375
2020-02-08T02:33:54.253275: step 2924, loss 0.00252952, acc 1
2020-02-08T02:33:54.369843: step 2925, loss 0.0196143, acc 0.984375
2020-02-08T02:33:54.486480: step 2926, loss 0.013463, acc 1
2020-02-08T02:33:54.601980: step 2927, loss 0.0130666, acc 1
2020-02-08T02:33:54.721826: step 2928, loss 0.0191127, acc 1
2020-02-08T02:33:54.843061: step 2929, loss 0.00618488, acc 1
2020-02-08T02:33:54.958556: step 2930, loss 0.0358008, acc 0.984375
2020-02-08T02:33:55.074316: step 2931, loss 0.023171, acc 1
2020-02-08T02:33:55.187344: step 2932, loss 0.00509467, acc 1
2020-02-08T02:33:55.304114: step 2933, loss 0.00444815, acc 1
2020-02-08T02:33:55.421223: step 2934, loss 0.0202542, acc 1
2020-02-08T02:33:55.537388: step 2935, loss 0.0150758, acc 1
2020-02-08T02:33:55.652813: step 2936, loss 0.019155, acc 1
2020-02-08T02:33:55.773602: step 2937, loss 0.0301585, acc 0.984375
2020-02-08T02:33:55.890298: step 2938, loss 0.00953766, acc 1
2020-02-08T02:33:56.008811: step 2939, loss 0.0117441, acc 1
2020-02-08T02:33:56.126067: step 2940, loss 0.00720478, acc 1
2020-02-08T02:33:56.243928: step 2941, loss 0.00700388, acc 1
2020-02-08T02:33:56.360838: step 2942, loss 0.00561302, acc 1
2020-02-08T02:33:56.475596: step 2943, loss 0.0351455, acc 0.984375
2020-02-08T02:33:56.593338: step 2944, loss 0.00593698, acc 1
2020-02-08T02:33:56.712094: step 2945, loss 0.00585398, acc 1
2020-02-08T02:33:56.825504: step 2946, loss 0.00875298, acc 1
2020-02-08T02:33:56.943663: step 2947, loss 0.0083825, acc 1
2020-02-08T02:33:57.061224: step 2948, loss 0.0477094, acc 0.984375
2020-02-08T02:33:57.176523: step 2949, loss 0.0175058, acc 1
2020-02-08T02:33:57.295988: step 2950, loss 0.0123589, acc 1
2020-02-08T02:33:57.414354: step 2951, loss 0.0130068, acc 1
2020-02-08T02:33:57.527293: step 2952, loss 0.0322437, acc 1
2020-02-08T02:33:57.644583: step 2953, loss 0.0143065, acc 1
2020-02-08T02:33:57.766234: step 2954, loss 0.0509527, acc 0.984375
2020-02-08T02:33:57.882946: step 2955, loss 0.0365243, acc 0.984375
2020-02-08T02:33:58.000834: step 2956, loss 0.0132587, acc 1
2020-02-08T02:33:58.120078: step 2957, loss 0.00484398, acc 1
2020-02-08T02:33:58.238108: step 2958, loss 0.023723, acc 0.984375
2020-02-08T02:33:58.355658: step 2959, loss 0.0203604, acc 0.984375
2020-02-08T02:33:58.471064: step 2960, loss 0.00779635, acc 1
2020-02-08T02:33:58.588123: step 2961, loss 0.00884548, acc 1
2020-02-08T02:33:58.710082: step 2962, loss 0.029054, acc 0.984375
2020-02-08T02:33:58.826402: step 2963, loss 0.0210136, acc 0.984375
2020-02-08T02:33:58.941167: step 2964, loss 0.00674828, acc 1
2020-02-08T02:33:59.060253: step 2965, loss 0.00626594, acc 1
2020-02-08T02:33:59.177278: step 2966, loss 0.107946, acc 0.96875
2020-02-08T02:33:59.297290: step 2967, loss 0.00499064, acc 1
2020-02-08T02:33:59.416588: step 2968, loss 0.0635203, acc 0.96875
2020-02-08T02:33:59.534670: step 2969, loss 0.0133486, acc 0.984375
2020-02-08T02:33:59.653184: step 2970, loss 0.0143538, acc 1
2020-02-08T02:33:59.773207: step 2971, loss 0.0067279, acc 1
2020-02-08T02:33:59.891799: step 2972, loss 0.00738756, acc 1
2020-02-08T02:34:00.011178: step 2973, loss 0.0457626, acc 0.96875
2020-02-08T02:34:00.130078: step 2974, loss 0.0371408, acc 0.984375
2020-02-08T02:34:00.248347: step 2975, loss 0.00529015, acc 1
2020-02-08T02:34:00.366205: step 2976, loss 0.00605226, acc 1
2020-02-08T02:34:00.480135: step 2977, loss 0.00889638, acc 1
2020-02-08T02:34:00.597943: step 2978, loss 0.0184521, acc 1
2020-02-08T02:34:00.716488: step 2979, loss 0.0249568, acc 1
2020-02-08T02:34:00.833991: step 2980, loss 0.0142852, acc 1
2020-02-08T02:34:00.951643: step 2981, loss 0.0107926, acc 1
2020-02-08T02:34:01.066731: step 2982, loss 0.0316639, acc 0.984375
2020-02-08T02:34:01.184429: step 2983, loss 0.037235, acc 0.96875
2020-02-08T02:34:01.300057: step 2984, loss 0.00321262, acc 1
2020-02-08T02:34:01.419107: step 2985, loss 0.00371086, acc 1
2020-02-08T02:34:01.533974: step 2986, loss 0.0104688, acc 1
2020-02-08T02:34:01.651390: step 2987, loss 0.0467953, acc 0.984375
2020-02-08T02:34:01.772131: step 2988, loss 0.00649249, acc 1
2020-02-08T02:34:01.888307: step 2989, loss 0.00347333, acc 1
2020-02-08T02:34:02.008152: step 2990, loss 0.00385581, acc 1
2020-02-08T02:34:02.122647: step 2991, loss 0.00834712, acc 1
2020-02-08T02:34:02.240869: step 2992, loss 0.0192677, acc 1
2020-02-08T02:34:02.357403: step 2993, loss 0.0141129, acc 1
2020-02-08T02:34:02.475721: step 2994, loss 0.0168851, acc 0.984375
2020-02-08T02:34:02.594875: step 2995, loss 0.00625798, acc 1
2020-02-08T02:34:02.714375: step 2996, loss 0.0938551, acc 0.953125
2020-02-08T02:34:02.831920: step 2997, loss 0.0050357, acc 1
2020-02-08T02:34:02.950182: step 2998, loss 0.00421124, acc 1
2020-02-08T02:34:03.065901: step 2999, loss 0.0255206, acc 1
2020-02-08T02:34:03.179931: step 3000, loss 0.0238303, acc 1

Evaluation:
2020-02-08T02:34:03.368085: step 3000, loss 1.06946, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100025/checkpoints/model-3000

