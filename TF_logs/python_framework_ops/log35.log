WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 13:27:05.237725 4694511040 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 13:27:05.238020 4694511040 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0216 13:27:05.238147 4694511040 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0216 13:27:05.875663 4694511040 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0216 13:27:05.875974 4694511040 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-16 13:27:05.882374: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-16 13:27:05.926185: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8461216a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-16 13:27:05.926211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0216 13:27:05.939069 4694511040 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0216 13:27:05.965939 4694511040 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0216 13:27:05.995822 4694511040 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0216 13:27:06.007765 4694511040 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0216 13:27:06.035205 4694511040 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0216 13:27:06.049144 4694511040 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0216 13:27:06.049432 4694511040 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0216 13:27:06.064811 4694511040 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0216 13:27:06.067503 4694511040 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0216 13:27:06.157771 4694511040 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0216 13:27:06.474085 4694511040 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0216 13:27:06.474323 4694511040 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0216 13:27:06.489637 4694511040 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0216 13:27:06.518908 4694511040 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0216 13:27:06.520795 4694511040 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0216 13:27:06.542627 4694511040 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0216 13:27:06.544367 4694511040 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0216 13:27:06.566051 4694511040 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0216 13:27:06.567106 4694511040 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0216 13:27:06.581285 4694511040 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0216 13:27:06.582321 4694511040 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0216 13:27:06.604964 4694511040 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0216 13:27:06.607139 4694511040 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0216 13:27:06.626556 4694511040 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0216 13:27:06.627604 4694511040 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0216 13:27:06.649253 4694511040 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0216 13:27:06.651034 4694511040 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0216 13:27:06.669475 4694511040 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0216 13:27:06.670658 4694511040 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0216 13:27:06.686115 4694511040 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0216 13:27:06.688066 4694511040 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0216 13:27:06.694601 4694511040 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0216 13:27:07.081086 4694511040 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0216 13:27:07.081274 4694511040 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0216 13:27:07.731098 4694511040 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0216 13:27:08.817054 4694511040 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0216 13:28:47.123559 4694511040 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
2020-02-16 13:31:12.186179: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at save_restore_v2_ops.cc:109 : Not found: /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints; No such file or directory
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826

2020-02-16T13:27:08.815721: step 1, loss 4.1912, acc 0.453125
2020-02-16T13:27:08.966512: step 2, loss 2.65319, acc 0.546875
2020-02-16T13:27:09.103654: step 3, loss 2.41995, acc 0.515625
2020-02-16T13:27:09.277684: step 4, loss 2.32008, acc 0.46875
2020-02-16T13:27:09.450554: step 5, loss 2.20398, acc 0.546875
2020-02-16T13:27:09.580725: step 6, loss 2.07374, acc 0.578125
2020-02-16T13:27:09.729482: step 7, loss 2.14934, acc 0.59375
2020-02-16T13:27:09.859691: step 8, loss 1.99019, acc 0.484375
2020-02-16T13:27:09.984404: step 9, loss 2.45739, acc 0.453125
2020-02-16T13:27:10.127568: step 10, loss 1.9411, acc 0.453125
2020-02-16T13:27:10.277995: step 11, loss 2.22252, acc 0.46875
2020-02-16T13:27:10.437270: step 12, loss 1.70663, acc 0.5625
2020-02-16T13:27:10.591083: step 13, loss 2.06213, acc 0.53125
2020-02-16T13:27:10.737375: step 14, loss 2.51942, acc 0.4375
2020-02-16T13:27:10.876473: step 15, loss 1.87845, acc 0.546875
2020-02-16T13:27:11.014068: step 16, loss 1.90504, acc 0.5625
2020-02-16T13:27:11.158916: step 17, loss 1.86036, acc 0.46875
2020-02-16T13:27:11.288322: step 18, loss 1.71837, acc 0.53125
2020-02-16T13:27:11.429394: step 19, loss 1.52189, acc 0.5625
2020-02-16T13:27:11.565058: step 20, loss 1.96793, acc 0.59375
2020-02-16T13:27:11.697637: step 21, loss 2.71197, acc 0.46875
2020-02-16T13:27:11.831928: step 22, loss 2.07777, acc 0.546875
2020-02-16T13:27:11.966454: step 23, loss 2.04788, acc 0.5
2020-02-16T13:27:12.096800: step 24, loss 1.58418, acc 0.515625
2020-02-16T13:27:12.264793: step 25, loss 1.68038, acc 0.5625
2020-02-16T13:27:12.416026: step 26, loss 1.73994, acc 0.46875
2020-02-16T13:27:12.542972: step 27, loss 1.57788, acc 0.515625
2020-02-16T13:27:12.666106: step 28, loss 1.94672, acc 0.578125
2020-02-16T13:27:12.786323: step 29, loss 2.49766, acc 0.4375
2020-02-16T13:27:12.914922: step 30, loss 1.95048, acc 0.578125
2020-02-16T13:27:13.048881: step 31, loss 1.67295, acc 0.46875
2020-02-16T13:27:13.173107: step 32, loss 1.90598, acc 0.546875
2020-02-16T13:27:13.296592: step 33, loss 1.81461, acc 0.59375
2020-02-16T13:27:13.428270: step 34, loss 1.76016, acc 0.59375
2020-02-16T13:27:13.554349: step 35, loss 1.78257, acc 0.546875
2020-02-16T13:27:13.678201: step 36, loss 1.80857, acc 0.40625
2020-02-16T13:27:13.799866: step 37, loss 1.55007, acc 0.53125
2020-02-16T13:27:13.933334: step 38, loss 1.65949, acc 0.53125
2020-02-16T13:27:14.061855: step 39, loss 1.7267, acc 0.515625
2020-02-16T13:27:14.188486: step 40, loss 1.23194, acc 0.5625
2020-02-16T13:27:14.320808: step 41, loss 1.87815, acc 0.546875
2020-02-16T13:27:14.459278: step 42, loss 1.83963, acc 0.5625
2020-02-16T13:27:14.582301: step 43, loss 2.0079, acc 0.421875
2020-02-16T13:27:14.712526: step 44, loss 1.82565, acc 0.484375
2020-02-16T13:27:14.840137: step 45, loss 2.49516, acc 0.40625
2020-02-16T13:27:14.970038: step 46, loss 1.75996, acc 0.46875
2020-02-16T13:27:15.097762: step 47, loss 2.22527, acc 0.5
2020-02-16T13:27:15.223774: step 48, loss 1.40383, acc 0.515625
2020-02-16T13:27:15.353554: step 49, loss 1.85195, acc 0.515625
2020-02-16T13:27:15.488839: step 50, loss 1.80463, acc 0.5
2020-02-16T13:27:15.617152: step 51, loss 1.30834, acc 0.53125
2020-02-16T13:27:15.744401: step 52, loss 2.02679, acc 0.46875
2020-02-16T13:27:15.873046: step 53, loss 1.60239, acc 0.46875
2020-02-16T13:27:16.002020: step 54, loss 1.68456, acc 0.59375
2020-02-16T13:27:16.124885: step 55, loss 2.62128, acc 0.359375
2020-02-16T13:27:16.252013: step 56, loss 1.84663, acc 0.515625
2020-02-16T13:27:16.380345: step 57, loss 1.33538, acc 0.625
2020-02-16T13:27:16.514156: step 58, loss 1.5908, acc 0.5
2020-02-16T13:27:16.639607: step 59, loss 1.38603, acc 0.59375
2020-02-16T13:27:16.771692: step 60, loss 2.30009, acc 0.40625
2020-02-16T13:27:16.903649: step 61, loss 1.61384, acc 0.515625
2020-02-16T13:27:17.030208: step 62, loss 1.42295, acc 0.59375
2020-02-16T13:27:17.150727: step 63, loss 1.98086, acc 0.453125
2020-02-16T13:27:17.286559: step 64, loss 1.587, acc 0.546875
2020-02-16T13:27:17.424811: step 65, loss 1.80462, acc 0.484375
2020-02-16T13:27:17.563894: step 66, loss 1.54273, acc 0.546875
2020-02-16T13:27:17.696744: step 67, loss 1.71066, acc 0.546875
2020-02-16T13:27:17.828431: step 68, loss 1.32236, acc 0.59375
2020-02-16T13:27:17.959638: step 69, loss 1.66329, acc 0.59375
2020-02-16T13:27:18.084979: step 70, loss 1.57944, acc 0.515625
2020-02-16T13:27:18.219604: step 71, loss 1.58847, acc 0.53125
2020-02-16T13:27:18.364037: step 72, loss 2.2585, acc 0.453125
2020-02-16T13:27:18.664196: step 73, loss 2.19022, acc 0.421875
2020-02-16T13:27:18.874365: step 74, loss 1.87595, acc 0.484375
2020-02-16T13:27:19.065760: step 75, loss 1.35208, acc 0.59375
2020-02-16T13:27:19.320348: step 76, loss 1.35842, acc 0.59375
2020-02-16T13:27:19.487860: step 77, loss 1.6993, acc 0.484375
2020-02-16T13:27:19.634376: step 78, loss 1.37807, acc 0.578125
2020-02-16T13:27:19.761233: step 79, loss 1.54607, acc 0.53125
2020-02-16T13:27:19.897320: step 80, loss 1.60125, acc 0.546875
2020-02-16T13:27:20.033838: step 81, loss 1.45572, acc 0.609375
2020-02-16T13:27:20.161062: step 82, loss 1.47146, acc 0.515625
2020-02-16T13:27:20.292881: step 83, loss 1.41835, acc 0.609375
2020-02-16T13:27:20.435686: step 84, loss 1.45611, acc 0.515625
2020-02-16T13:27:20.576094: step 85, loss 1.1771, acc 0.515625
2020-02-16T13:27:20.704808: step 86, loss 1.43371, acc 0.515625
2020-02-16T13:27:20.838053: step 87, loss 1.83071, acc 0.5
2020-02-16T13:27:20.969527: step 88, loss 1.3748, acc 0.515625
2020-02-16T13:27:21.100827: step 89, loss 1.94956, acc 0.53125
2020-02-16T13:27:21.236030: step 90, loss 1.89936, acc 0.5625
2020-02-16T13:27:21.363834: step 91, loss 1.51664, acc 0.546875
2020-02-16T13:27:21.501618: step 92, loss 1.3264, acc 0.5
2020-02-16T13:27:21.635485: step 93, loss 1.30999, acc 0.5625
2020-02-16T13:27:21.762071: step 94, loss 1.56017, acc 0.5
2020-02-16T13:27:21.906357: step 95, loss 1.98252, acc 0.4375
2020-02-16T13:27:22.043750: step 96, loss 1.46564, acc 0.609375
2020-02-16T13:27:22.179251: step 97, loss 1.44872, acc 0.4375
2020-02-16T13:27:22.314001: step 98, loss 1.86422, acc 0.46875
2020-02-16T13:27:22.466903: step 99, loss 1.62861, acc 0.484375
2020-02-16T13:27:22.611030: step 100, loss 1.43363, acc 0.515625

Evaluation:
2020-02-16T13:27:22.896648: step 100, loss 0.935832, acc 0.546904

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-100

2020-02-16T13:27:25.918085: step 101, loss 1.04469, acc 0.65625
2020-02-16T13:27:26.150839: step 102, loss 1.5301, acc 0.53125
2020-02-16T13:27:26.376462: step 103, loss 1.49833, acc 0.53125
2020-02-16T13:27:26.539996: step 104, loss 1.46221, acc 0.546875
2020-02-16T13:27:26.664303: step 105, loss 1.41292, acc 0.5625
2020-02-16T13:27:26.798533: step 106, loss 1.10368, acc 0.546875
2020-02-16T13:27:26.931939: step 107, loss 1.22595, acc 0.625
2020-02-16T13:27:27.058340: step 108, loss 1.52523, acc 0.484375
2020-02-16T13:27:27.191568: step 109, loss 1.38231, acc 0.59375
2020-02-16T13:27:27.339933: step 110, loss 1.00411, acc 0.59375
2020-02-16T13:27:27.484526: step 111, loss 1.48389, acc 0.546875
2020-02-16T13:27:27.620346: step 112, loss 1.48904, acc 0.484375
2020-02-16T13:27:27.758205: step 113, loss 1.32384, acc 0.59375
2020-02-16T13:27:27.891241: step 114, loss 0.817783, acc 0.734375
2020-02-16T13:27:28.022998: step 115, loss 1.54019, acc 0.59375
2020-02-16T13:27:28.159895: step 116, loss 1.43728, acc 0.578125
2020-02-16T13:27:28.291569: step 117, loss 1.6551, acc 0.5
2020-02-16T13:27:28.435676: step 118, loss 1.29644, acc 0.609375
2020-02-16T13:27:28.579791: step 119, loss 1.00214, acc 0.625
2020-02-16T13:27:28.713213: step 120, loss 0.963071, acc 0.578125
2020-02-16T13:27:28.851787: step 121, loss 1.38143, acc 0.53125
2020-02-16T13:27:28.978475: step 122, loss 1.50838, acc 0.5625
2020-02-16T13:27:29.108077: step 123, loss 1.56585, acc 0.46875
2020-02-16T13:27:29.249129: step 124, loss 1.54326, acc 0.546875
2020-02-16T13:27:29.380429: step 125, loss 0.948499, acc 0.59375
2020-02-16T13:27:29.515639: step 126, loss 0.879507, acc 0.625
2020-02-16T13:27:29.649352: step 127, loss 1.22886, acc 0.53125
2020-02-16T13:27:29.778921: step 128, loss 1.32847, acc 0.53125
2020-02-16T13:27:29.908697: step 129, loss 1.20084, acc 0.578125
2020-02-16T13:27:30.034950: step 130, loss 1.24691, acc 0.625
2020-02-16T13:27:30.201793: step 131, loss 1.57928, acc 0.515625
2020-02-16T13:27:30.422602: step 132, loss 1.34421, acc 0.59375
2020-02-16T13:27:30.768709: step 133, loss 1.15804, acc 0.640625
2020-02-16T13:27:30.976360: step 134, loss 1.36828, acc 0.546875
2020-02-16T13:27:31.131898: step 135, loss 0.891894, acc 0.625
2020-02-16T13:27:31.326549: step 136, loss 1.26599, acc 0.5625
2020-02-16T13:27:31.490698: step 137, loss 1.12569, acc 0.609375
2020-02-16T13:27:31.624978: step 138, loss 1.51262, acc 0.484375
2020-02-16T13:27:31.757458: step 139, loss 1.44026, acc 0.484375
2020-02-16T13:27:31.892750: step 140, loss 0.961261, acc 0.59375
2020-02-16T13:27:32.030669: step 141, loss 1.33426, acc 0.4375
2020-02-16T13:27:32.189289: step 142, loss 1.34623, acc 0.640625
2020-02-16T13:27:32.355943: step 143, loss 1.45766, acc 0.484375
2020-02-16T13:27:32.496739: step 144, loss 1.42859, acc 0.4375
2020-02-16T13:27:32.631780: step 145, loss 1.27467, acc 0.609375
2020-02-16T13:27:32.773175: step 146, loss 1.40564, acc 0.4375
2020-02-16T13:27:32.928898: step 147, loss 1.46589, acc 0.4375
2020-02-16T13:27:33.072177: step 148, loss 1.54021, acc 0.453125
2020-02-16T13:27:33.203826: step 149, loss 1.66807, acc 0.453125
2020-02-16T13:27:33.330967: step 150, loss 1.03203, acc 0.633333
2020-02-16T13:27:33.463699: step 151, loss 1.20309, acc 0.578125
2020-02-16T13:27:33.592543: step 152, loss 1.35455, acc 0.515625
2020-02-16T13:27:33.727117: step 153, loss 1.30821, acc 0.53125
2020-02-16T13:27:33.865740: step 154, loss 1.37437, acc 0.484375
2020-02-16T13:27:33.999428: step 155, loss 0.98397, acc 0.640625
2020-02-16T13:27:34.142377: step 156, loss 0.776485, acc 0.671875
2020-02-16T13:27:34.275732: step 157, loss 0.955074, acc 0.578125
2020-02-16T13:27:34.409464: step 158, loss 1.09355, acc 0.53125
2020-02-16T13:27:34.534532: step 159, loss 0.909145, acc 0.625
2020-02-16T13:27:34.666874: step 160, loss 1.01305, acc 0.65625
2020-02-16T13:27:34.793191: step 161, loss 0.741062, acc 0.6875
2020-02-16T13:27:34.924720: step 162, loss 1.19173, acc 0.578125
2020-02-16T13:27:35.064653: step 163, loss 1.24568, acc 0.578125
2020-02-16T13:27:35.194258: step 164, loss 1.05141, acc 0.625
2020-02-16T13:27:35.327761: step 165, loss 1.40365, acc 0.515625
2020-02-16T13:27:35.463498: step 166, loss 0.912929, acc 0.625
2020-02-16T13:27:35.631403: step 167, loss 1.14742, acc 0.53125
2020-02-16T13:27:35.789822: step 168, loss 1.14756, acc 0.546875
2020-02-16T13:27:36.061801: step 169, loss 1.06211, acc 0.671875
2020-02-16T13:27:36.270821: step 170, loss 0.706245, acc 0.640625
2020-02-16T13:27:36.454961: step 171, loss 0.855857, acc 0.671875
2020-02-16T13:27:36.615735: step 172, loss 1.26347, acc 0.546875
2020-02-16T13:27:36.841162: step 173, loss 1.20965, acc 0.453125
2020-02-16T13:27:36.995601: step 174, loss 0.949726, acc 0.609375
2020-02-16T13:27:37.136869: step 175, loss 1.01476, acc 0.640625
2020-02-16T13:27:37.268736: step 176, loss 0.853883, acc 0.671875
2020-02-16T13:27:37.417486: step 177, loss 1.11626, acc 0.59375
2020-02-16T13:27:37.563901: step 178, loss 0.742433, acc 0.65625
2020-02-16T13:27:37.698957: step 179, loss 0.760866, acc 0.625
2020-02-16T13:27:37.832086: step 180, loss 1.37576, acc 0.53125
2020-02-16T13:27:37.966708: step 181, loss 1.34015, acc 0.578125
2020-02-16T13:27:38.098025: step 182, loss 0.79514, acc 0.65625
2020-02-16T13:27:38.240922: step 183, loss 0.916421, acc 0.578125
2020-02-16T13:27:38.366847: step 184, loss 1.24849, acc 0.515625
2020-02-16T13:27:38.503497: step 185, loss 1.33526, acc 0.5625
2020-02-16T13:27:38.637616: step 186, loss 0.899089, acc 0.59375
2020-02-16T13:27:38.770845: step 187, loss 1.10187, acc 0.59375
2020-02-16T13:27:38.904788: step 188, loss 0.949265, acc 0.578125
2020-02-16T13:27:39.033439: step 189, loss 0.952793, acc 0.625
2020-02-16T13:27:39.157774: step 190, loss 0.97492, acc 0.625
2020-02-16T13:27:39.353538: step 191, loss 0.744436, acc 0.703125
2020-02-16T13:27:39.595314: step 192, loss 0.981999, acc 0.640625
2020-02-16T13:27:39.814485: step 193, loss 0.886474, acc 0.640625
2020-02-16T13:27:39.993576: step 194, loss 0.98767, acc 0.625
2020-02-16T13:27:40.222280: step 195, loss 1.14216, acc 0.5625
2020-02-16T13:27:40.402763: step 196, loss 0.682827, acc 0.671875
2020-02-16T13:27:40.575317: step 197, loss 1.08963, acc 0.546875
2020-02-16T13:27:40.718094: step 198, loss 1.07932, acc 0.578125
2020-02-16T13:27:40.851109: step 199, loss 1.05821, acc 0.640625
2020-02-16T13:27:40.979652: step 200, loss 0.741058, acc 0.640625

Evaluation:
2020-02-16T13:27:41.198720: step 200, loss 0.709237, acc 0.590994

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-200

2020-02-16T13:27:43.741207: step 201, loss 0.93394, acc 0.609375
2020-02-16T13:27:43.879863: step 202, loss 0.883426, acc 0.625
2020-02-16T13:27:44.015682: step 203, loss 1.11672, acc 0.5
2020-02-16T13:27:44.151702: step 204, loss 1.21454, acc 0.5625
2020-02-16T13:27:44.282981: step 205, loss 0.735555, acc 0.671875
2020-02-16T13:27:44.471109: step 206, loss 0.764512, acc 0.640625
2020-02-16T13:27:44.610397: step 207, loss 0.976324, acc 0.59375
2020-02-16T13:27:44.751873: step 208, loss 0.624142, acc 0.671875
2020-02-16T13:27:44.914947: step 209, loss 0.867309, acc 0.6875
2020-02-16T13:27:45.081665: step 210, loss 0.929558, acc 0.53125
2020-02-16T13:27:45.215899: step 211, loss 0.847712, acc 0.65625
2020-02-16T13:27:45.347273: step 212, loss 0.857961, acc 0.703125
2020-02-16T13:27:45.484248: step 213, loss 0.728334, acc 0.640625
2020-02-16T13:27:45.687582: step 214, loss 0.696819, acc 0.71875
2020-02-16T13:27:45.821396: step 215, loss 0.953427, acc 0.609375
2020-02-16T13:27:45.984068: step 216, loss 0.711779, acc 0.625
2020-02-16T13:27:46.159847: step 217, loss 0.781288, acc 0.640625
2020-02-16T13:27:46.281510: step 218, loss 0.901306, acc 0.640625
2020-02-16T13:27:46.410176: step 219, loss 0.873721, acc 0.671875
2020-02-16T13:27:46.539572: step 220, loss 0.879299, acc 0.609375
2020-02-16T13:27:46.671619: step 221, loss 0.833087, acc 0.671875
2020-02-16T13:27:46.840871: step 222, loss 1.36988, acc 0.484375
2020-02-16T13:27:46.978296: step 223, loss 1.20432, acc 0.546875
2020-02-16T13:27:47.119161: step 224, loss 0.873418, acc 0.546875
2020-02-16T13:27:47.316138: step 225, loss 0.952751, acc 0.625
2020-02-16T13:27:47.462775: step 226, loss 1.03347, acc 0.546875
2020-02-16T13:27:47.637035: step 227, loss 0.938124, acc 0.65625
2020-02-16T13:27:47.782934: step 228, loss 0.998631, acc 0.5625
2020-02-16T13:27:47.919139: step 229, loss 0.897953, acc 0.65625
2020-02-16T13:27:48.055669: step 230, loss 0.72008, acc 0.609375
2020-02-16T13:27:48.187998: step 231, loss 0.794705, acc 0.65625
2020-02-16T13:27:48.353048: step 232, loss 0.826759, acc 0.671875
2020-02-16T13:27:48.547663: step 233, loss 1.25533, acc 0.5625
2020-02-16T13:27:48.715229: step 234, loss 0.876215, acc 0.6875
2020-02-16T13:27:48.857060: step 235, loss 0.793889, acc 0.671875
2020-02-16T13:27:49.077837: step 236, loss 0.870915, acc 0.65625
2020-02-16T13:27:49.226403: step 237, loss 0.938066, acc 0.671875
2020-02-16T13:27:49.368824: step 238, loss 1.01784, acc 0.53125
2020-02-16T13:27:49.536345: step 239, loss 1.20982, acc 0.53125
2020-02-16T13:27:49.663857: step 240, loss 0.944567, acc 0.5625
2020-02-16T13:27:49.813653: step 241, loss 0.872489, acc 0.640625
2020-02-16T13:27:49.938659: step 242, loss 0.871659, acc 0.65625
2020-02-16T13:27:50.075663: step 243, loss 0.886965, acc 0.703125
2020-02-16T13:27:50.218850: step 244, loss 0.891031, acc 0.5625
2020-02-16T13:27:50.346354: step 245, loss 0.994949, acc 0.578125
2020-02-16T13:27:50.534594: step 246, loss 0.867333, acc 0.609375
2020-02-16T13:27:50.662501: step 247, loss 0.905625, acc 0.5625
2020-02-16T13:27:50.782278: step 248, loss 0.832324, acc 0.59375
2020-02-16T13:27:50.898799: step 249, loss 0.798911, acc 0.65625
2020-02-16T13:27:51.018641: step 250, loss 0.963515, acc 0.578125
2020-02-16T13:27:51.152139: step 251, loss 0.913633, acc 0.625
2020-02-16T13:27:51.285686: step 252, loss 1.04016, acc 0.640625
2020-02-16T13:27:51.419363: step 253, loss 0.835446, acc 0.703125
2020-02-16T13:27:51.554921: step 254, loss 0.969986, acc 0.546875
2020-02-16T13:27:51.679183: step 255, loss 0.924427, acc 0.578125
2020-02-16T13:27:51.798763: step 256, loss 0.962255, acc 0.578125
2020-02-16T13:27:51.919040: step 257, loss 1.00062, acc 0.59375
2020-02-16T13:27:52.040427: step 258, loss 0.901845, acc 0.671875
2020-02-16T13:27:52.161862: step 259, loss 0.873331, acc 0.609375
2020-02-16T13:27:52.281650: step 260, loss 0.85912, acc 0.59375
2020-02-16T13:27:52.406708: step 261, loss 0.940409, acc 0.640625
2020-02-16T13:27:52.529494: step 262, loss 0.976688, acc 0.609375
2020-02-16T13:27:52.659359: step 263, loss 0.828732, acc 0.640625
2020-02-16T13:27:52.780770: step 264, loss 0.802901, acc 0.65625
2020-02-16T13:27:52.906459: step 265, loss 0.688513, acc 0.609375
2020-02-16T13:27:53.026168: step 266, loss 0.676756, acc 0.65625
2020-02-16T13:27:53.147409: step 267, loss 0.813282, acc 0.53125
2020-02-16T13:27:53.266742: step 268, loss 0.717623, acc 0.625
2020-02-16T13:27:53.392405: step 269, loss 1.00244, acc 0.609375
2020-02-16T13:27:53.531539: step 270, loss 0.850801, acc 0.5625
2020-02-16T13:27:53.660278: step 271, loss 0.828796, acc 0.546875
2020-02-16T13:27:53.780301: step 272, loss 0.797462, acc 0.671875
2020-02-16T13:27:53.909853: step 273, loss 0.731185, acc 0.65625
2020-02-16T13:27:54.041647: step 274, loss 0.798509, acc 0.640625
2020-02-16T13:27:54.165351: step 275, loss 0.852903, acc 0.5
2020-02-16T13:27:54.285479: step 276, loss 0.940605, acc 0.5625
2020-02-16T13:27:54.404198: step 277, loss 0.657485, acc 0.671875
2020-02-16T13:27:54.530464: step 278, loss 0.713264, acc 0.71875
2020-02-16T13:27:54.662890: step 279, loss 0.623585, acc 0.6875
2020-02-16T13:27:54.793363: step 280, loss 0.878736, acc 0.59375
2020-02-16T13:27:54.925239: step 281, loss 0.818143, acc 0.65625
2020-02-16T13:27:55.052815: step 282, loss 0.713037, acc 0.59375
2020-02-16T13:27:55.198016: step 283, loss 0.720297, acc 0.625
2020-02-16T13:27:55.331155: step 284, loss 0.854767, acc 0.609375
2020-02-16T13:27:55.470213: step 285, loss 0.895542, acc 0.609375
2020-02-16T13:27:55.634863: step 286, loss 0.791229, acc 0.65625
2020-02-16T13:27:55.761147: step 287, loss 0.753529, acc 0.578125
2020-02-16T13:27:55.906145: step 288, loss 0.867445, acc 0.609375
2020-02-16T13:27:56.039048: step 289, loss 0.784401, acc 0.609375
2020-02-16T13:27:56.166663: step 290, loss 0.759578, acc 0.640625
2020-02-16T13:27:56.286787: step 291, loss 0.715684, acc 0.609375
2020-02-16T13:27:56.410270: step 292, loss 0.887255, acc 0.640625
2020-02-16T13:27:56.532786: step 293, loss 0.865632, acc 0.578125
2020-02-16T13:27:56.657262: step 294, loss 0.640152, acc 0.6875
2020-02-16T13:27:56.785955: step 295, loss 0.787929, acc 0.609375
2020-02-16T13:27:56.904130: step 296, loss 0.848744, acc 0.5625
2020-02-16T13:27:57.024391: step 297, loss 0.803369, acc 0.734375
2020-02-16T13:27:57.144248: step 298, loss 0.899173, acc 0.5625
2020-02-16T13:27:57.265145: step 299, loss 0.868574, acc 0.609375
2020-02-16T13:27:57.382528: step 300, loss 0.856846, acc 0.616667

Evaluation:
2020-02-16T13:27:57.586355: step 300, loss 0.647321, acc 0.62758

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-300

2020-02-16T13:28:00.988616: step 301, loss 0.769719, acc 0.671875
2020-02-16T13:28:01.109054: step 302, loss 0.623043, acc 0.734375
2020-02-16T13:28:01.339479: step 303, loss 0.667854, acc 0.65625
2020-02-16T13:28:01.469486: step 304, loss 0.640927, acc 0.6875
2020-02-16T13:28:01.589487: step 305, loss 0.825938, acc 0.578125
2020-02-16T13:28:01.710399: step 306, loss 0.737408, acc 0.65625
2020-02-16T13:28:01.829031: step 307, loss 0.824425, acc 0.625
2020-02-16T13:28:01.948305: step 308, loss 0.705603, acc 0.625
2020-02-16T13:28:02.069794: step 309, loss 0.801864, acc 0.71875
2020-02-16T13:28:02.188586: step 310, loss 0.891222, acc 0.640625
2020-02-16T13:28:02.307780: step 311, loss 0.795629, acc 0.546875
2020-02-16T13:28:02.431687: step 312, loss 0.652721, acc 0.6875
2020-02-16T13:28:02.556515: step 313, loss 0.836953, acc 0.5625
2020-02-16T13:28:02.678515: step 314, loss 0.680717, acc 0.671875
2020-02-16T13:28:02.804432: step 315, loss 0.742107, acc 0.640625
2020-02-16T13:28:02.922192: step 316, loss 0.698853, acc 0.671875
2020-02-16T13:28:03.041868: step 317, loss 0.695472, acc 0.65625
2020-02-16T13:28:03.169240: step 318, loss 0.574433, acc 0.703125
2020-02-16T13:28:03.289884: step 319, loss 0.796713, acc 0.59375
2020-02-16T13:28:03.439881: step 320, loss 0.806002, acc 0.609375
2020-02-16T13:28:03.672096: step 321, loss 0.632475, acc 0.640625
2020-02-16T13:28:03.869214: step 322, loss 0.749362, acc 0.65625
2020-02-16T13:28:04.037978: step 323, loss 0.5767, acc 0.71875
2020-02-16T13:28:04.228157: step 324, loss 0.811135, acc 0.578125
2020-02-16T13:28:04.517589: step 325, loss 0.630231, acc 0.65625
2020-02-16T13:28:04.721437: step 326, loss 0.669166, acc 0.6875
2020-02-16T13:28:04.897706: step 327, loss 0.779649, acc 0.625
2020-02-16T13:28:05.086921: step 328, loss 0.616934, acc 0.6875
2020-02-16T13:28:05.245924: step 329, loss 0.770548, acc 0.625
2020-02-16T13:28:05.365993: step 330, loss 0.729395, acc 0.6875
2020-02-16T13:28:05.493281: step 331, loss 0.804199, acc 0.578125
2020-02-16T13:28:05.756945: step 332, loss 0.863804, acc 0.59375
2020-02-16T13:28:05.975989: step 333, loss 0.670934, acc 0.71875
2020-02-16T13:28:06.203896: step 334, loss 0.770557, acc 0.609375
2020-02-16T13:28:06.410658: step 335, loss 0.639735, acc 0.609375
2020-02-16T13:28:06.565139: step 336, loss 0.690427, acc 0.609375
2020-02-16T13:28:06.720612: step 337, loss 0.671494, acc 0.6875
2020-02-16T13:28:06.855199: step 338, loss 0.568565, acc 0.71875
2020-02-16T13:28:06.973635: step 339, loss 0.603187, acc 0.71875
2020-02-16T13:28:07.127082: step 340, loss 0.64117, acc 0.6875
2020-02-16T13:28:07.308182: step 341, loss 0.646783, acc 0.75
2020-02-16T13:28:07.432582: step 342, loss 0.607085, acc 0.6875
2020-02-16T13:28:07.552414: step 343, loss 0.703094, acc 0.65625
2020-02-16T13:28:07.672515: step 344, loss 0.839476, acc 0.625
2020-02-16T13:28:07.794264: step 345, loss 0.678728, acc 0.65625
2020-02-16T13:28:07.919077: step 346, loss 0.734266, acc 0.578125
2020-02-16T13:28:08.042792: step 347, loss 0.679497, acc 0.6875
2020-02-16T13:28:08.161916: step 348, loss 0.696819, acc 0.703125
2020-02-16T13:28:08.279042: step 349, loss 0.542041, acc 0.703125
2020-02-16T13:28:08.401486: step 350, loss 0.689552, acc 0.671875
2020-02-16T13:28:08.519233: step 351, loss 0.662493, acc 0.640625
2020-02-16T13:28:08.637052: step 352, loss 0.549791, acc 0.75
2020-02-16T13:28:08.756964: step 353, loss 0.5507, acc 0.703125
2020-02-16T13:28:08.876001: step 354, loss 0.674201, acc 0.59375
2020-02-16T13:28:08.994523: step 355, loss 0.518522, acc 0.78125
2020-02-16T13:28:09.113016: step 356, loss 0.53904, acc 0.71875
2020-02-16T13:28:09.229950: step 357, loss 0.639273, acc 0.609375
2020-02-16T13:28:09.350685: step 358, loss 0.680018, acc 0.625
2020-02-16T13:28:09.480181: step 359, loss 0.506293, acc 0.796875
2020-02-16T13:28:09.598938: step 360, loss 0.592703, acc 0.65625
2020-02-16T13:28:09.714517: step 361, loss 0.80789, acc 0.515625
2020-02-16T13:28:09.832834: step 362, loss 0.719279, acc 0.625
2020-02-16T13:28:09.953405: step 363, loss 0.578176, acc 0.75
2020-02-16T13:28:10.070919: step 364, loss 0.746541, acc 0.59375
2020-02-16T13:28:10.188419: step 365, loss 0.500527, acc 0.734375
2020-02-16T13:28:10.310317: step 366, loss 0.706029, acc 0.65625
2020-02-16T13:28:10.434563: step 367, loss 0.69148, acc 0.703125
2020-02-16T13:28:10.559270: step 368, loss 0.645568, acc 0.640625
2020-02-16T13:28:10.677628: step 369, loss 0.511478, acc 0.75
2020-02-16T13:28:10.800549: step 370, loss 0.487851, acc 0.796875
2020-02-16T13:28:10.916603: step 371, loss 0.719027, acc 0.671875
2020-02-16T13:28:11.033432: step 372, loss 0.812329, acc 0.59375
2020-02-16T13:28:11.151157: step 373, loss 0.65753, acc 0.640625
2020-02-16T13:28:11.271094: step 374, loss 0.720297, acc 0.625
2020-02-16T13:28:11.393348: step 375, loss 0.644523, acc 0.640625
2020-02-16T13:28:11.512438: step 376, loss 0.552234, acc 0.734375
2020-02-16T13:28:11.632815: step 377, loss 0.503024, acc 0.75
2020-02-16T13:28:11.751643: step 378, loss 0.649713, acc 0.6875
2020-02-16T13:28:11.870030: step 379, loss 0.581314, acc 0.71875
2020-02-16T13:28:11.986076: step 380, loss 0.605928, acc 0.75
2020-02-16T13:28:12.105859: step 381, loss 0.710269, acc 0.640625
2020-02-16T13:28:12.224500: step 382, loss 0.60637, acc 0.6875
2020-02-16T13:28:12.342257: step 383, loss 0.591595, acc 0.71875
2020-02-16T13:28:12.470205: step 384, loss 0.731827, acc 0.5625
2020-02-16T13:28:12.592557: step 385, loss 0.692831, acc 0.71875
2020-02-16T13:28:12.708152: step 386, loss 0.672413, acc 0.609375
2020-02-16T13:28:12.825299: step 387, loss 0.581118, acc 0.71875
2020-02-16T13:28:12.944857: step 388, loss 0.65159, acc 0.671875
2020-02-16T13:28:13.063690: step 389, loss 0.645627, acc 0.671875
2020-02-16T13:28:13.182600: step 390, loss 0.64974, acc 0.734375
2020-02-16T13:28:13.306126: step 391, loss 0.537137, acc 0.671875
2020-02-16T13:28:13.426610: step 392, loss 0.748568, acc 0.59375
2020-02-16T13:28:13.545567: step 393, loss 0.710284, acc 0.625
2020-02-16T13:28:13.664214: step 394, loss 0.801157, acc 0.6875
2020-02-16T13:28:13.784167: step 395, loss 0.696276, acc 0.640625
2020-02-16T13:28:13.901167: step 396, loss 0.556784, acc 0.703125
2020-02-16T13:28:14.020529: step 397, loss 0.836404, acc 0.546875
2020-02-16T13:28:14.138906: step 398, loss 0.659394, acc 0.671875
2020-02-16T13:28:14.257779: step 399, loss 0.463248, acc 0.71875
2020-02-16T13:28:14.377875: step 400, loss 0.85436, acc 0.546875

Evaluation:
2020-02-16T13:28:14.588233: step 400, loss 0.657383, acc 0.606942

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-400

2020-02-16T13:28:17.069550: step 401, loss 0.630704, acc 0.671875
2020-02-16T13:28:17.201811: step 402, loss 0.681248, acc 0.59375
2020-02-16T13:28:17.327313: step 403, loss 0.635413, acc 0.65625
2020-02-16T13:28:17.450683: step 404, loss 0.588956, acc 0.71875
2020-02-16T13:28:17.571969: step 405, loss 0.730484, acc 0.5625
2020-02-16T13:28:17.688967: step 406, loss 0.545226, acc 0.71875
2020-02-16T13:28:17.805386: step 407, loss 0.740519, acc 0.609375
2020-02-16T13:28:17.921494: step 408, loss 0.507816, acc 0.734375
2020-02-16T13:28:18.040012: step 409, loss 0.804263, acc 0.59375
2020-02-16T13:28:18.154117: step 410, loss 0.687134, acc 0.65625
2020-02-16T13:28:18.270092: step 411, loss 0.503765, acc 0.78125
2020-02-16T13:28:18.391317: step 412, loss 0.590081, acc 0.640625
2020-02-16T13:28:18.513252: step 413, loss 0.688246, acc 0.609375
2020-02-16T13:28:18.631821: step 414, loss 0.640759, acc 0.609375
2020-02-16T13:28:18.749968: step 415, loss 0.576123, acc 0.734375
2020-02-16T13:28:18.871040: step 416, loss 0.580742, acc 0.75
2020-02-16T13:28:18.987450: step 417, loss 0.699572, acc 0.6875
2020-02-16T13:28:19.106429: step 418, loss 0.591872, acc 0.65625
2020-02-16T13:28:19.226345: step 419, loss 0.818131, acc 0.5625
2020-02-16T13:28:19.345410: step 420, loss 0.659129, acc 0.734375
2020-02-16T13:28:19.473581: step 421, loss 0.630654, acc 0.703125
2020-02-16T13:28:19.590739: step 422, loss 0.680966, acc 0.640625
2020-02-16T13:28:19.704829: step 423, loss 0.708632, acc 0.640625
2020-02-16T13:28:19.823178: step 424, loss 0.583061, acc 0.671875
2020-02-16T13:28:19.944686: step 425, loss 0.638872, acc 0.640625
2020-02-16T13:28:20.074161: step 426, loss 0.761772, acc 0.59375
2020-02-16T13:28:20.193462: step 427, loss 0.614693, acc 0.671875
2020-02-16T13:28:20.313127: step 428, loss 0.524366, acc 0.765625
2020-02-16T13:28:20.433995: step 429, loss 0.628314, acc 0.6875
2020-02-16T13:28:20.555372: step 430, loss 0.657128, acc 0.671875
2020-02-16T13:28:20.675653: step 431, loss 0.67277, acc 0.625
2020-02-16T13:28:20.791993: step 432, loss 0.670462, acc 0.671875
2020-02-16T13:28:20.913720: step 433, loss 0.630782, acc 0.75
2020-02-16T13:28:21.033400: step 434, loss 0.620499, acc 0.65625
2020-02-16T13:28:21.152217: step 435, loss 0.626784, acc 0.78125
2020-02-16T13:28:21.272357: step 436, loss 0.797259, acc 0.640625
2020-02-16T13:28:21.388822: step 437, loss 0.643043, acc 0.671875
2020-02-16T13:28:21.520262: step 438, loss 0.707755, acc 0.65625
2020-02-16T13:28:21.640175: step 439, loss 0.650389, acc 0.671875
2020-02-16T13:28:21.763529: step 440, loss 0.720329, acc 0.609375
2020-02-16T13:28:21.883491: step 441, loss 0.647096, acc 0.625
2020-02-16T13:28:22.005853: step 442, loss 0.611501, acc 0.6875
2020-02-16T13:28:22.127374: step 443, loss 0.703848, acc 0.625
2020-02-16T13:28:22.241833: step 444, loss 0.520589, acc 0.71875
2020-02-16T13:28:22.360511: step 445, loss 0.570757, acc 0.6875
2020-02-16T13:28:22.485387: step 446, loss 0.666751, acc 0.609375
2020-02-16T13:28:22.606774: step 447, loss 0.652848, acc 0.625
2020-02-16T13:28:22.727382: step 448, loss 0.759997, acc 0.609375
2020-02-16T13:28:22.842241: step 449, loss 0.541378, acc 0.71875
2020-02-16T13:28:22.961132: step 450, loss 0.731685, acc 0.65
2020-02-16T13:28:23.082610: step 451, loss 0.714088, acc 0.6875
2020-02-16T13:28:23.199681: step 452, loss 0.571381, acc 0.6875
2020-02-16T13:28:23.321287: step 453, loss 0.608329, acc 0.671875
2020-02-16T13:28:23.444775: step 454, loss 0.656273, acc 0.6875
2020-02-16T13:28:23.564739: step 455, loss 0.64303, acc 0.6875
2020-02-16T13:28:23.682120: step 456, loss 0.508668, acc 0.71875
2020-02-16T13:28:23.801881: step 457, loss 0.612653, acc 0.6875
2020-02-16T13:28:23.923903: step 458, loss 0.679635, acc 0.640625
2020-02-16T13:28:24.040656: step 459, loss 0.566855, acc 0.703125
2020-02-16T13:28:24.160781: step 460, loss 0.491565, acc 0.703125
2020-02-16T13:28:24.278955: step 461, loss 0.573387, acc 0.703125
2020-02-16T13:28:24.399287: step 462, loss 0.514877, acc 0.71875
2020-02-16T13:28:24.524855: step 463, loss 0.517435, acc 0.796875
2020-02-16T13:28:24.645380: step 464, loss 0.661079, acc 0.65625
2020-02-16T13:28:24.762370: step 465, loss 0.478908, acc 0.796875
2020-02-16T13:28:24.882235: step 466, loss 0.572354, acc 0.6875
2020-02-16T13:28:25.003009: step 467, loss 0.531211, acc 0.75
2020-02-16T13:28:25.120776: step 468, loss 0.576236, acc 0.671875
2020-02-16T13:28:25.239720: step 469, loss 0.688222, acc 0.609375
2020-02-16T13:28:25.359115: step 470, loss 0.554334, acc 0.703125
2020-02-16T13:28:25.486107: step 471, loss 0.728628, acc 0.59375
2020-02-16T13:28:25.604131: step 472, loss 0.688641, acc 0.625
2020-02-16T13:28:25.723348: step 473, loss 0.565486, acc 0.765625
2020-02-16T13:28:25.840347: step 474, loss 0.668165, acc 0.671875
2020-02-16T13:28:25.960824: step 475, loss 0.482276, acc 0.75
2020-02-16T13:28:26.079151: step 476, loss 0.443565, acc 0.765625
2020-02-16T13:28:26.199449: step 477, loss 0.550828, acc 0.671875
2020-02-16T13:28:26.316608: step 478, loss 0.494203, acc 0.796875
2020-02-16T13:28:26.442591: step 479, loss 0.559389, acc 0.671875
2020-02-16T13:28:26.565271: step 480, loss 0.604665, acc 0.671875
2020-02-16T13:28:26.685282: step 481, loss 0.570548, acc 0.71875
2020-02-16T13:28:26.803297: step 482, loss 0.654106, acc 0.625
2020-02-16T13:28:26.920838: step 483, loss 0.499934, acc 0.765625
2020-02-16T13:28:27.041446: step 484, loss 0.586845, acc 0.703125
2020-02-16T13:28:27.160252: step 485, loss 0.647926, acc 0.6875
2020-02-16T13:28:27.279527: step 486, loss 0.552082, acc 0.765625
2020-02-16T13:28:27.403841: step 487, loss 0.451651, acc 0.796875
2020-02-16T13:28:27.526289: step 488, loss 0.562293, acc 0.671875
2020-02-16T13:28:27.643903: step 489, loss 0.507171, acc 0.75
2020-02-16T13:28:27.765150: step 490, loss 0.513384, acc 0.71875
2020-02-16T13:28:27.882518: step 491, loss 0.567884, acc 0.703125
2020-02-16T13:28:28.002603: step 492, loss 0.547933, acc 0.765625
2020-02-16T13:28:28.122449: step 493, loss 0.406639, acc 0.828125
2020-02-16T13:28:28.241574: step 494, loss 0.447692, acc 0.796875
2020-02-16T13:28:28.360086: step 495, loss 0.530232, acc 0.71875
2020-02-16T13:28:28.484892: step 496, loss 0.539037, acc 0.78125
2020-02-16T13:28:28.606000: step 497, loss 0.625505, acc 0.671875
2020-02-16T13:28:28.724371: step 498, loss 0.628832, acc 0.6875
2020-02-16T13:28:28.842119: step 499, loss 0.601122, acc 0.71875
2020-02-16T13:28:28.961045: step 500, loss 0.501648, acc 0.78125

Evaluation:
2020-02-16T13:28:29.159511: step 500, loss 0.620888, acc 0.655722

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-500

2020-02-16T13:28:31.612252: step 501, loss 0.629268, acc 0.734375
2020-02-16T13:28:31.732359: step 502, loss 0.746016, acc 0.59375
2020-02-16T13:28:32.254285: step 503, loss 0.598873, acc 0.71875
2020-02-16T13:28:32.387951: step 504, loss 0.499179, acc 0.71875
2020-02-16T13:28:32.512633: step 505, loss 0.500756, acc 0.75
2020-02-16T13:28:32.633464: step 506, loss 0.593431, acc 0.6875
2020-02-16T13:28:32.754785: step 507, loss 0.553464, acc 0.734375
2020-02-16T13:28:32.870690: step 508, loss 0.563983, acc 0.640625
2020-02-16T13:28:32.989200: step 509, loss 0.594435, acc 0.71875
2020-02-16T13:28:33.110425: step 510, loss 0.464481, acc 0.828125
2020-02-16T13:28:33.229686: step 511, loss 0.475194, acc 0.78125
2020-02-16T13:28:33.347612: step 512, loss 0.613668, acc 0.671875
2020-02-16T13:28:33.479222: step 513, loss 0.663807, acc 0.71875
2020-02-16T13:28:33.600782: step 514, loss 0.594786, acc 0.671875
2020-02-16T13:28:33.723047: step 515, loss 0.592469, acc 0.71875
2020-02-16T13:28:33.841722: step 516, loss 0.604721, acc 0.6875
2020-02-16T13:28:33.962230: step 517, loss 0.493824, acc 0.765625
2020-02-16T13:28:34.082923: step 518, loss 0.600354, acc 0.65625
2020-02-16T13:28:34.200882: step 519, loss 0.654277, acc 0.640625
2020-02-16T13:28:34.317386: step 520, loss 0.691247, acc 0.65625
2020-02-16T13:28:34.440406: step 521, loss 0.507516, acc 0.765625
2020-02-16T13:28:34.571855: step 522, loss 0.512598, acc 0.75
2020-02-16T13:28:34.691020: step 523, loss 0.52777, acc 0.734375
2020-02-16T13:28:34.809798: step 524, loss 0.565423, acc 0.71875
2020-02-16T13:28:34.926119: step 525, loss 0.613648, acc 0.703125
2020-02-16T13:28:35.045721: step 526, loss 0.604691, acc 0.734375
2020-02-16T13:28:35.164735: step 527, loss 0.55329, acc 0.734375
2020-02-16T13:28:35.285573: step 528, loss 0.660506, acc 0.6875
2020-02-16T13:28:35.406525: step 529, loss 0.585375, acc 0.71875
2020-02-16T13:28:35.531559: step 530, loss 0.528056, acc 0.71875
2020-02-16T13:28:35.650591: step 531, loss 0.610412, acc 0.65625
2020-02-16T13:28:35.779549: step 532, loss 0.582729, acc 0.6875
2020-02-16T13:28:35.898229: step 533, loss 0.611232, acc 0.6875
2020-02-16T13:28:36.018507: step 534, loss 0.545573, acc 0.75
2020-02-16T13:28:36.140299: step 535, loss 0.564729, acc 0.703125
2020-02-16T13:28:36.263688: step 536, loss 0.572237, acc 0.75
2020-02-16T13:28:36.383552: step 537, loss 0.546447, acc 0.71875
2020-02-16T13:28:36.513574: step 538, loss 0.533507, acc 0.6875
2020-02-16T13:28:36.632034: step 539, loss 0.673592, acc 0.703125
2020-02-16T13:28:36.749228: step 540, loss 0.572959, acc 0.734375
2020-02-16T13:28:36.866150: step 541, loss 0.64283, acc 0.703125
2020-02-16T13:28:36.983455: step 542, loss 0.520322, acc 0.75
2020-02-16T13:28:37.099345: step 543, loss 0.566992, acc 0.734375
2020-02-16T13:28:37.220247: step 544, loss 0.522742, acc 0.703125
2020-02-16T13:28:37.342024: step 545, loss 0.484813, acc 0.828125
2020-02-16T13:28:37.469079: step 546, loss 0.54841, acc 0.6875
2020-02-16T13:28:37.594144: step 547, loss 0.478391, acc 0.75
2020-02-16T13:28:37.715315: step 548, loss 0.595153, acc 0.703125
2020-02-16T13:28:37.838648: step 549, loss 0.638264, acc 0.71875
2020-02-16T13:28:37.959255: step 550, loss 0.532624, acc 0.71875
2020-02-16T13:28:38.080237: step 551, loss 0.457218, acc 0.8125
2020-02-16T13:28:38.198767: step 552, loss 0.650901, acc 0.671875
2020-02-16T13:28:38.318113: step 553, loss 0.623374, acc 0.765625
2020-02-16T13:28:38.441140: step 554, loss 0.558042, acc 0.703125
2020-02-16T13:28:38.563084: step 555, loss 0.503044, acc 0.75
2020-02-16T13:28:38.686204: step 556, loss 0.513924, acc 0.796875
2020-02-16T13:28:38.805311: step 557, loss 0.453132, acc 0.78125
2020-02-16T13:28:38.923141: step 558, loss 0.460069, acc 0.78125
2020-02-16T13:28:39.046695: step 559, loss 0.531414, acc 0.6875
2020-02-16T13:28:39.167106: step 560, loss 0.694757, acc 0.578125
2020-02-16T13:28:39.286814: step 561, loss 0.487658, acc 0.75
2020-02-16T13:28:39.408381: step 562, loss 0.545243, acc 0.671875
2020-02-16T13:28:39.531058: step 563, loss 0.548749, acc 0.6875
2020-02-16T13:28:39.650017: step 564, loss 0.633094, acc 0.703125
2020-02-16T13:28:39.768464: step 565, loss 0.494694, acc 0.75
2020-02-16T13:28:39.887169: step 566, loss 0.414075, acc 0.875
2020-02-16T13:28:40.005634: step 567, loss 0.562059, acc 0.71875
2020-02-16T13:28:40.126467: step 568, loss 0.546542, acc 0.734375
2020-02-16T13:28:40.244061: step 569, loss 0.556155, acc 0.71875
2020-02-16T13:28:40.361778: step 570, loss 0.594973, acc 0.6875
2020-02-16T13:28:40.488465: step 571, loss 0.611871, acc 0.6875
2020-02-16T13:28:40.609153: step 572, loss 0.427249, acc 0.828125
2020-02-16T13:28:40.727641: step 573, loss 0.622561, acc 0.71875
2020-02-16T13:28:40.846508: step 574, loss 0.534265, acc 0.75
2020-02-16T13:28:40.969987: step 575, loss 0.58756, acc 0.6875
2020-02-16T13:28:41.090543: step 576, loss 0.523393, acc 0.75
2020-02-16T13:28:41.210767: step 577, loss 0.571848, acc 0.65625
2020-02-16T13:28:41.330063: step 578, loss 0.542506, acc 0.71875
2020-02-16T13:28:41.456496: step 579, loss 0.52839, acc 0.671875
2020-02-16T13:28:41.577620: step 580, loss 0.677468, acc 0.65625
2020-02-16T13:28:41.694232: step 581, loss 0.654147, acc 0.59375
2020-02-16T13:28:41.812317: step 582, loss 0.655446, acc 0.671875
2020-02-16T13:28:41.933140: step 583, loss 0.516666, acc 0.71875
2020-02-16T13:28:42.057703: step 584, loss 0.492519, acc 0.78125
2020-02-16T13:28:42.177808: step 585, loss 0.563168, acc 0.734375
2020-02-16T13:28:42.294059: step 586, loss 0.531228, acc 0.75
2020-02-16T13:28:42.416930: step 587, loss 0.573192, acc 0.71875
2020-02-16T13:28:42.541846: step 588, loss 0.576021, acc 0.703125
2020-02-16T13:28:42.662770: step 589, loss 0.509181, acc 0.765625
2020-02-16T13:28:42.781802: step 590, loss 0.454851, acc 0.828125
2020-02-16T13:28:42.903796: step 591, loss 0.51981, acc 0.703125
2020-02-16T13:28:43.024052: step 592, loss 0.397167, acc 0.796875
2020-02-16T13:28:43.142063: step 593, loss 0.458773, acc 0.84375
2020-02-16T13:28:43.264849: step 594, loss 0.601437, acc 0.703125
2020-02-16T13:28:43.383057: step 595, loss 0.49106, acc 0.75
2020-02-16T13:28:43.507787: step 596, loss 0.531948, acc 0.671875
2020-02-16T13:28:43.633060: step 597, loss 0.51859, acc 0.75
2020-02-16T13:28:43.761365: step 598, loss 0.59035, acc 0.71875
2020-02-16T13:28:43.880650: step 599, loss 0.686364, acc 0.71875
2020-02-16T13:28:43.996586: step 600, loss 0.627544, acc 0.683333

Evaluation:
2020-02-16T13:28:44.200693: step 600, loss 0.6331, acc 0.638837

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-600

2020-02-16T13:28:47.396464: step 601, loss 0.463012, acc 0.78125
2020-02-16T13:28:47.523464: step 602, loss 0.579813, acc 0.703125
2020-02-16T13:28:47.642621: step 603, loss 0.626012, acc 0.71875
2020-02-16T13:28:47.762939: step 604, loss 0.511679, acc 0.75
2020-02-16T13:28:47.887707: step 605, loss 0.545668, acc 0.734375
2020-02-16T13:28:48.033106: step 606, loss 0.557439, acc 0.71875
2020-02-16T13:28:48.169982: step 607, loss 0.48814, acc 0.796875
2020-02-16T13:28:48.307911: step 608, loss 0.486598, acc 0.734375
2020-02-16T13:28:48.450107: step 609, loss 0.662985, acc 0.609375
2020-02-16T13:28:48.600387: step 610, loss 0.437524, acc 0.8125
2020-02-16T13:28:48.738917: step 611, loss 0.431867, acc 0.828125
2020-02-16T13:28:48.876314: step 612, loss 0.468817, acc 0.75
2020-02-16T13:28:49.007552: step 613, loss 0.499696, acc 0.796875
2020-02-16T13:28:49.135860: step 614, loss 0.51261, acc 0.6875
2020-02-16T13:28:49.260817: step 615, loss 0.60817, acc 0.703125
2020-02-16T13:28:49.390399: step 616, loss 0.499629, acc 0.78125
2020-02-16T13:28:49.518688: step 617, loss 0.528987, acc 0.765625
2020-02-16T13:28:49.641176: step 618, loss 0.585401, acc 0.703125
2020-02-16T13:28:49.760012: step 619, loss 0.518807, acc 0.734375
2020-02-16T13:28:49.878573: step 620, loss 0.52766, acc 0.71875
2020-02-16T13:28:49.998492: step 621, loss 0.44868, acc 0.796875
2020-02-16T13:28:50.121350: step 622, loss 0.417287, acc 0.78125
2020-02-16T13:28:50.241576: step 623, loss 0.488253, acc 0.78125
2020-02-16T13:28:50.361141: step 624, loss 0.44236, acc 0.796875
2020-02-16T13:28:50.490903: step 625, loss 0.44401, acc 0.765625
2020-02-16T13:28:50.613023: step 626, loss 0.64537, acc 0.671875
2020-02-16T13:28:50.733014: step 627, loss 0.541726, acc 0.734375
2020-02-16T13:28:50.852864: step 628, loss 0.441582, acc 0.765625
2020-02-16T13:28:50.975170: step 629, loss 0.484217, acc 0.734375
2020-02-16T13:28:51.097505: step 630, loss 0.593199, acc 0.671875
2020-02-16T13:28:51.225744: step 631, loss 0.638546, acc 0.71875
2020-02-16T13:28:51.355556: step 632, loss 0.613979, acc 0.71875
2020-02-16T13:28:51.489856: step 633, loss 0.402038, acc 0.796875
2020-02-16T13:28:51.609862: step 634, loss 0.49865, acc 0.765625
2020-02-16T13:28:51.733686: step 635, loss 0.562191, acc 0.71875
2020-02-16T13:28:51.856710: step 636, loss 0.632353, acc 0.71875
2020-02-16T13:28:51.981970: step 637, loss 0.544818, acc 0.703125
2020-02-16T13:28:52.109547: step 638, loss 0.505542, acc 0.75
2020-02-16T13:28:52.234224: step 639, loss 0.540226, acc 0.734375
2020-02-16T13:28:52.359851: step 640, loss 0.514612, acc 0.78125
2020-02-16T13:28:52.494644: step 641, loss 0.538248, acc 0.765625
2020-02-16T13:28:52.616909: step 642, loss 0.414023, acc 0.8125
2020-02-16T13:28:52.744258: step 643, loss 0.595286, acc 0.71875
2020-02-16T13:28:52.869251: step 644, loss 0.513704, acc 0.734375
2020-02-16T13:28:52.992131: step 645, loss 0.613864, acc 0.703125
2020-02-16T13:28:53.119470: step 646, loss 0.512658, acc 0.734375
2020-02-16T13:28:53.246271: step 647, loss 0.595121, acc 0.6875
2020-02-16T13:28:53.378262: step 648, loss 0.6121, acc 0.671875
2020-02-16T13:28:53.514603: step 649, loss 0.564393, acc 0.703125
2020-02-16T13:28:53.646484: step 650, loss 0.510562, acc 0.71875
2020-02-16T13:28:53.771161: step 651, loss 0.521537, acc 0.75
2020-02-16T13:28:53.891651: step 652, loss 0.572113, acc 0.703125
2020-02-16T13:28:54.016112: step 653, loss 0.549091, acc 0.6875
2020-02-16T13:28:54.134807: step 654, loss 0.382596, acc 0.828125
2020-02-16T13:28:54.255424: step 655, loss 0.409028, acc 0.859375
2020-02-16T13:28:54.378647: step 656, loss 0.763383, acc 0.59375
2020-02-16T13:28:54.509156: step 657, loss 0.574419, acc 0.71875
2020-02-16T13:28:54.630790: step 658, loss 0.486993, acc 0.75
2020-02-16T13:28:54.749955: step 659, loss 0.40191, acc 0.75
2020-02-16T13:28:54.873672: step 660, loss 0.414153, acc 0.828125
2020-02-16T13:28:54.994189: step 661, loss 0.560328, acc 0.71875
2020-02-16T13:28:55.114894: step 662, loss 0.52741, acc 0.703125
2020-02-16T13:28:55.234508: step 663, loss 0.531078, acc 0.71875
2020-02-16T13:28:55.352334: step 664, loss 0.550469, acc 0.75
2020-02-16T13:28:55.478391: step 665, loss 0.566145, acc 0.71875
2020-02-16T13:28:55.595912: step 666, loss 0.435582, acc 0.796875
2020-02-16T13:28:55.716537: step 667, loss 0.618016, acc 0.6875
2020-02-16T13:28:55.842457: step 668, loss 0.408206, acc 0.859375
2020-02-16T13:28:55.963486: step 669, loss 0.593272, acc 0.703125
2020-02-16T13:28:56.099075: step 670, loss 0.446286, acc 0.71875
2020-02-16T13:28:56.237377: step 671, loss 0.482467, acc 0.765625
2020-02-16T13:28:56.369326: step 672, loss 0.504891, acc 0.75
2020-02-16T13:28:56.497992: step 673, loss 0.492794, acc 0.734375
2020-02-16T13:28:56.647770: step 674, loss 0.465162, acc 0.796875
2020-02-16T13:28:56.795872: step 675, loss 0.601718, acc 0.65625
2020-02-16T13:28:56.993234: step 676, loss 0.628653, acc 0.765625
2020-02-16T13:28:57.135859: step 677, loss 0.532837, acc 0.75
2020-02-16T13:28:57.288607: step 678, loss 0.500804, acc 0.734375
2020-02-16T13:28:57.420531: step 679, loss 0.513348, acc 0.765625
2020-02-16T13:28:57.541223: step 680, loss 0.530624, acc 0.75
2020-02-16T13:28:57.661620: step 681, loss 0.45024, acc 0.8125
2020-02-16T13:28:57.784768: step 682, loss 0.539753, acc 0.75
2020-02-16T13:28:57.919713: step 683, loss 0.527186, acc 0.75
2020-02-16T13:28:58.052743: step 684, loss 0.523053, acc 0.765625
2020-02-16T13:28:58.177997: step 685, loss 0.54755, acc 0.734375
2020-02-16T13:28:58.296725: step 686, loss 0.47971, acc 0.75
2020-02-16T13:28:58.422570: step 687, loss 0.558757, acc 0.765625
2020-02-16T13:28:58.546842: step 688, loss 0.567628, acc 0.734375
2020-02-16T13:28:58.669284: step 689, loss 0.473875, acc 0.796875
2020-02-16T13:28:58.797613: step 690, loss 0.520573, acc 0.75
2020-02-16T13:28:58.930254: step 691, loss 0.46056, acc 0.734375
2020-02-16T13:28:59.082261: step 692, loss 0.466185, acc 0.796875
2020-02-16T13:28:59.204719: step 693, loss 0.464863, acc 0.765625
2020-02-16T13:28:59.334644: step 694, loss 0.445761, acc 0.796875
2020-02-16T13:28:59.480399: step 695, loss 0.573917, acc 0.703125
2020-02-16T13:28:59.619612: step 696, loss 0.474827, acc 0.78125
2020-02-16T13:28:59.745846: step 697, loss 0.544633, acc 0.71875
2020-02-16T13:28:59.888206: step 698, loss 0.45372, acc 0.78125
2020-02-16T13:29:00.009997: step 699, loss 0.574142, acc 0.65625
2020-02-16T13:29:00.129942: step 700, loss 0.466614, acc 0.765625

Evaluation:
2020-02-16T13:29:00.759263: step 700, loss 0.601, acc 0.673546

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-700

2020-02-16T13:29:03.272402: step 701, loss 0.48472, acc 0.75
2020-02-16T13:29:03.397266: step 702, loss 0.659224, acc 0.640625
2020-02-16T13:29:03.541134: step 703, loss 0.474707, acc 0.78125
2020-02-16T13:29:03.686474: step 704, loss 0.510913, acc 0.71875
2020-02-16T13:29:03.835437: step 705, loss 0.491803, acc 0.734375
2020-02-16T13:29:03.980526: step 706, loss 0.550276, acc 0.71875
2020-02-16T13:29:04.118840: step 707, loss 0.594807, acc 0.71875
2020-02-16T13:29:04.241254: step 708, loss 0.52946, acc 0.71875
2020-02-16T13:29:04.363253: step 709, loss 0.553207, acc 0.671875
2020-02-16T13:29:04.493911: step 710, loss 0.511506, acc 0.71875
2020-02-16T13:29:04.612515: step 711, loss 0.658691, acc 0.625
2020-02-16T13:29:04.736254: step 712, loss 0.553971, acc 0.71875
2020-02-16T13:29:04.851610: step 713, loss 0.432771, acc 0.78125
2020-02-16T13:29:04.972076: step 714, loss 0.442604, acc 0.859375
2020-02-16T13:29:05.092501: step 715, loss 0.429605, acc 0.84375
2020-02-16T13:29:05.212860: step 716, loss 0.445422, acc 0.78125
2020-02-16T13:29:05.335167: step 717, loss 0.472689, acc 0.78125
2020-02-16T13:29:05.462917: step 718, loss 0.39819, acc 0.828125
2020-02-16T13:29:05.584166: step 719, loss 0.4391, acc 0.8125
2020-02-16T13:29:05.704751: step 720, loss 0.46471, acc 0.796875
2020-02-16T13:29:05.824254: step 721, loss 0.43073, acc 0.84375
2020-02-16T13:29:05.944041: step 722, loss 0.455456, acc 0.796875
2020-02-16T13:29:06.065009: step 723, loss 0.43803, acc 0.8125
2020-02-16T13:29:06.183035: step 724, loss 0.573005, acc 0.703125
2020-02-16T13:29:06.302663: step 725, loss 0.612717, acc 0.65625
2020-02-16T13:29:06.426702: step 726, loss 0.56458, acc 0.703125
2020-02-16T13:29:06.554073: step 727, loss 0.596518, acc 0.703125
2020-02-16T13:29:06.679656: step 728, loss 0.488956, acc 0.6875
2020-02-16T13:29:06.800727: step 729, loss 0.602274, acc 0.625
2020-02-16T13:29:06.920132: step 730, loss 0.530193, acc 0.765625
2020-02-16T13:29:07.039211: step 731, loss 0.528725, acc 0.734375
2020-02-16T13:29:07.160205: step 732, loss 0.567856, acc 0.765625
2020-02-16T13:29:07.280865: step 733, loss 0.497544, acc 0.71875
2020-02-16T13:29:07.400522: step 734, loss 0.624568, acc 0.71875
2020-02-16T13:29:07.524303: step 735, loss 0.479433, acc 0.8125
2020-02-16T13:29:07.645620: step 736, loss 0.507201, acc 0.8125
2020-02-16T13:29:07.766557: step 737, loss 0.624361, acc 0.6875
2020-02-16T13:29:07.884699: step 738, loss 0.552, acc 0.71875
2020-02-16T13:29:08.000708: step 739, loss 0.591785, acc 0.734375
2020-02-16T13:29:08.117460: step 740, loss 0.397891, acc 0.84375
2020-02-16T13:29:08.238192: step 741, loss 0.564466, acc 0.6875
2020-02-16T13:29:08.354973: step 742, loss 0.549991, acc 0.796875
2020-02-16T13:29:08.481808: step 743, loss 0.47792, acc 0.75
2020-02-16T13:29:08.600038: step 744, loss 0.523069, acc 0.796875
2020-02-16T13:29:08.718207: step 745, loss 0.483065, acc 0.75
2020-02-16T13:29:08.837152: step 746, loss 0.576868, acc 0.6875
2020-02-16T13:29:08.956582: step 747, loss 0.433992, acc 0.78125
2020-02-16T13:29:09.074253: step 748, loss 0.480387, acc 0.78125
2020-02-16T13:29:09.192627: step 749, loss 0.469608, acc 0.75
2020-02-16T13:29:09.307885: step 750, loss 0.452175, acc 0.783333
2020-02-16T13:29:09.433895: step 751, loss 0.390189, acc 0.84375
2020-02-16T13:29:09.555067: step 752, loss 0.428557, acc 0.765625
2020-02-16T13:29:09.676266: step 753, loss 0.514655, acc 0.734375
2020-02-16T13:29:09.823206: step 754, loss 0.403489, acc 0.84375
2020-02-16T13:29:09.967442: step 755, loss 0.43405, acc 0.796875
2020-02-16T13:29:10.091041: step 756, loss 0.34751, acc 0.859375
2020-02-16T13:29:10.222437: step 757, loss 0.334105, acc 0.90625
2020-02-16T13:29:10.346953: step 758, loss 0.318129, acc 0.921875
2020-02-16T13:29:10.492193: step 759, loss 0.454163, acc 0.796875
2020-02-16T13:29:10.618503: step 760, loss 0.37507, acc 0.828125
2020-02-16T13:29:10.745851: step 761, loss 0.380608, acc 0.890625
2020-02-16T13:29:10.889411: step 762, loss 0.410796, acc 0.84375
2020-02-16T13:29:11.036519: step 763, loss 0.34636, acc 0.828125
2020-02-16T13:29:11.163347: step 764, loss 0.513102, acc 0.75
2020-02-16T13:29:11.289496: step 765, loss 0.373245, acc 0.859375
2020-02-16T13:29:11.429351: step 766, loss 0.346295, acc 0.859375
2020-02-16T13:29:11.553845: step 767, loss 0.492325, acc 0.734375
2020-02-16T13:29:11.679214: step 768, loss 0.365261, acc 0.84375
2020-02-16T13:29:11.804599: step 769, loss 0.377616, acc 0.859375
2020-02-16T13:29:11.926931: step 770, loss 0.519462, acc 0.78125
2020-02-16T13:29:12.049965: step 771, loss 0.442411, acc 0.828125
2020-02-16T13:29:12.172870: step 772, loss 0.419407, acc 0.828125
2020-02-16T13:29:12.300020: step 773, loss 0.502377, acc 0.78125
2020-02-16T13:29:12.430430: step 774, loss 0.349067, acc 0.875
2020-02-16T13:29:12.560668: step 775, loss 0.403071, acc 0.8125
2020-02-16T13:29:12.699135: step 776, loss 0.460372, acc 0.8125
2020-02-16T13:29:12.823779: step 777, loss 0.428228, acc 0.8125
2020-02-16T13:29:12.953263: step 778, loss 0.374515, acc 0.84375
2020-02-16T13:29:13.084105: step 779, loss 0.497853, acc 0.703125
2020-02-16T13:29:13.215694: step 780, loss 0.41255, acc 0.765625
2020-02-16T13:29:13.361320: step 781, loss 0.406844, acc 0.8125
2020-02-16T13:29:13.553568: step 782, loss 0.636582, acc 0.671875
2020-02-16T13:29:13.709455: step 783, loss 0.343185, acc 0.828125
2020-02-16T13:29:13.836971: step 784, loss 0.308427, acc 0.890625
2020-02-16T13:29:13.969298: step 785, loss 0.452338, acc 0.796875
2020-02-16T13:29:14.092624: step 786, loss 0.405788, acc 0.796875
2020-02-16T13:29:14.218896: step 787, loss 0.302762, acc 0.890625
2020-02-16T13:29:14.341853: step 788, loss 0.479754, acc 0.8125
2020-02-16T13:29:14.475931: step 789, loss 0.43265, acc 0.796875
2020-02-16T13:29:14.594474: step 790, loss 0.505945, acc 0.734375
2020-02-16T13:29:14.722162: step 791, loss 0.405842, acc 0.828125
2020-02-16T13:29:14.847381: step 792, loss 0.375822, acc 0.84375
2020-02-16T13:29:14.975572: step 793, loss 0.349995, acc 0.859375
2020-02-16T13:29:15.105651: step 794, loss 0.355838, acc 0.78125
2020-02-16T13:29:15.237547: step 795, loss 0.396258, acc 0.828125
2020-02-16T13:29:15.365935: step 796, loss 0.513452, acc 0.765625
2020-02-16T13:29:15.503462: step 797, loss 0.451447, acc 0.8125
2020-02-16T13:29:15.627170: step 798, loss 0.403294, acc 0.828125
2020-02-16T13:29:15.747029: step 799, loss 0.425742, acc 0.8125
2020-02-16T13:29:15.868388: step 800, loss 0.358994, acc 0.8125

Evaluation:
2020-02-16T13:29:16.065394: step 800, loss 0.593106, acc 0.678236

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-800

2020-02-16T13:29:18.867664: step 801, loss 0.397252, acc 0.828125
2020-02-16T13:29:18.987844: step 802, loss 0.571414, acc 0.71875
2020-02-16T13:29:19.115960: step 803, loss 0.410987, acc 0.8125
2020-02-16T13:29:19.238787: step 804, loss 0.435697, acc 0.828125
2020-02-16T13:29:19.362575: step 805, loss 0.365476, acc 0.828125
2020-02-16T13:29:19.492500: step 806, loss 0.537785, acc 0.734375
2020-02-16T13:29:19.615159: step 807, loss 0.419205, acc 0.765625
2020-02-16T13:29:19.737112: step 808, loss 0.390159, acc 0.828125
2020-02-16T13:29:19.858073: step 809, loss 0.492708, acc 0.734375
2020-02-16T13:29:19.979084: step 810, loss 0.3411, acc 0.90625
2020-02-16T13:29:20.098627: step 811, loss 0.530827, acc 0.75
2020-02-16T13:29:20.220070: step 812, loss 0.478944, acc 0.75
2020-02-16T13:29:20.339589: step 813, loss 0.366257, acc 0.78125
2020-02-16T13:29:20.472726: step 814, loss 0.453039, acc 0.765625
2020-02-16T13:29:20.592921: step 815, loss 0.430151, acc 0.828125
2020-02-16T13:29:20.717127: step 816, loss 0.494343, acc 0.75
2020-02-16T13:29:20.837266: step 817, loss 0.481965, acc 0.78125
2020-02-16T13:29:20.959165: step 818, loss 0.562755, acc 0.671875
2020-02-16T13:29:21.077720: step 819, loss 0.395626, acc 0.78125
2020-02-16T13:29:21.206379: step 820, loss 0.42512, acc 0.75
2020-02-16T13:29:21.335788: step 821, loss 0.428394, acc 0.859375
2020-02-16T13:29:21.475220: step 822, loss 0.339573, acc 0.84375
2020-02-16T13:29:21.605806: step 823, loss 0.307101, acc 0.875
2020-02-16T13:29:21.738453: step 824, loss 0.281346, acc 0.875
2020-02-16T13:29:21.869336: step 825, loss 0.521008, acc 0.78125
2020-02-16T13:29:21.997503: step 826, loss 0.263163, acc 0.921875
2020-02-16T13:29:22.122810: step 827, loss 0.43689, acc 0.796875
2020-02-16T13:29:22.249186: step 828, loss 0.510549, acc 0.71875
2020-02-16T13:29:22.419113: step 829, loss 0.37189, acc 0.828125
2020-02-16T13:29:22.538897: step 830, loss 0.346456, acc 0.859375
2020-02-16T13:29:22.660349: step 831, loss 0.413512, acc 0.78125
2020-02-16T13:29:22.780242: step 832, loss 0.369039, acc 0.84375
2020-02-16T13:29:22.898654: step 833, loss 0.396049, acc 0.8125
2020-02-16T13:29:23.021506: step 834, loss 0.381817, acc 0.84375
2020-02-16T13:29:23.137550: step 835, loss 0.425493, acc 0.828125
2020-02-16T13:29:23.259934: step 836, loss 0.488943, acc 0.734375
2020-02-16T13:29:23.380393: step 837, loss 0.358751, acc 0.8125
2020-02-16T13:29:23.510864: step 838, loss 0.29758, acc 0.875
2020-02-16T13:29:23.631539: step 839, loss 0.464887, acc 0.78125
2020-02-16T13:29:23.769754: step 840, loss 0.410682, acc 0.78125
2020-02-16T13:29:23.914973: step 841, loss 0.449907, acc 0.765625
2020-02-16T13:29:24.046013: step 842, loss 0.550417, acc 0.78125
2020-02-16T13:29:24.168594: step 843, loss 0.483555, acc 0.828125
2020-02-16T13:29:24.294567: step 844, loss 0.387872, acc 0.84375
2020-02-16T13:29:24.425777: step 845, loss 0.443392, acc 0.78125
2020-02-16T13:29:24.547262: step 846, loss 0.398267, acc 0.796875
2020-02-16T13:29:24.669704: step 847, loss 0.387875, acc 0.84375
2020-02-16T13:29:24.797614: step 848, loss 0.391917, acc 0.8125
2020-02-16T13:29:24.926123: step 849, loss 0.449442, acc 0.8125
2020-02-16T13:29:25.089343: step 850, loss 0.36516, acc 0.890625
2020-02-16T13:29:25.207875: step 851, loss 0.490669, acc 0.796875
2020-02-16T13:29:25.332842: step 852, loss 0.370553, acc 0.8125
2020-02-16T13:29:25.566713: step 853, loss 0.539637, acc 0.71875
2020-02-16T13:29:25.689652: step 854, loss 0.436874, acc 0.84375
2020-02-16T13:29:25.817890: step 855, loss 0.334683, acc 0.84375
2020-02-16T13:29:25.945507: step 856, loss 0.57253, acc 0.671875
2020-02-16T13:29:26.074217: step 857, loss 0.290454, acc 0.890625
2020-02-16T13:29:26.198333: step 858, loss 0.649021, acc 0.6875
2020-02-16T13:29:26.329317: step 859, loss 0.517078, acc 0.78125
2020-02-16T13:29:26.462000: step 860, loss 0.318684, acc 0.84375
2020-02-16T13:29:26.618105: step 861, loss 0.485083, acc 0.71875
2020-02-16T13:29:26.751091: step 862, loss 0.410462, acc 0.765625
2020-02-16T13:29:26.891822: step 863, loss 0.5242, acc 0.765625
2020-02-16T13:29:27.041143: step 864, loss 0.596493, acc 0.6875
2020-02-16T13:29:27.175289: step 865, loss 0.411756, acc 0.796875
2020-02-16T13:29:27.298776: step 866, loss 0.642986, acc 0.703125
2020-02-16T13:29:27.432470: step 867, loss 0.615037, acc 0.71875
2020-02-16T13:29:27.558213: step 868, loss 0.502205, acc 0.765625
2020-02-16T13:29:27.682076: step 869, loss 0.331648, acc 0.875
2020-02-16T13:29:27.820207: step 870, loss 0.432405, acc 0.765625
2020-02-16T13:29:27.947789: step 871, loss 0.378876, acc 0.796875
2020-02-16T13:29:28.070707: step 872, loss 0.423144, acc 0.796875
2020-02-16T13:29:28.195962: step 873, loss 0.572759, acc 0.78125
2020-02-16T13:29:28.330287: step 874, loss 0.565227, acc 0.71875
2020-02-16T13:29:28.465429: step 875, loss 0.487665, acc 0.71875
2020-02-16T13:29:28.589610: step 876, loss 0.323037, acc 0.875
2020-02-16T13:29:28.708682: step 877, loss 0.366558, acc 0.8125
2020-02-16T13:29:28.841242: step 878, loss 0.468519, acc 0.828125
2020-02-16T13:29:28.969636: step 879, loss 0.593577, acc 0.703125
2020-02-16T13:29:29.094702: step 880, loss 0.464519, acc 0.765625
2020-02-16T13:29:29.223753: step 881, loss 0.425087, acc 0.796875
2020-02-16T13:29:29.347654: step 882, loss 0.503732, acc 0.8125
2020-02-16T13:29:29.477665: step 883, loss 0.542095, acc 0.671875
2020-02-16T13:29:29.600192: step 884, loss 0.432044, acc 0.78125
2020-02-16T13:29:29.723990: step 885, loss 0.396771, acc 0.859375
2020-02-16T13:29:29.844909: step 886, loss 0.576226, acc 0.734375
2020-02-16T13:29:29.966716: step 887, loss 0.367935, acc 0.859375
2020-02-16T13:29:30.084188: step 888, loss 0.408081, acc 0.859375
2020-02-16T13:29:30.202093: step 889, loss 0.345986, acc 0.859375
2020-02-16T13:29:30.608077: step 890, loss 0.494001, acc 0.71875
2020-02-16T13:29:30.751351: step 891, loss 0.49614, acc 0.75
2020-02-16T13:29:30.886129: step 892, loss 0.394972, acc 0.8125
2020-02-16T13:29:31.012440: step 893, loss 0.531334, acc 0.78125
2020-02-16T13:29:31.136909: step 894, loss 0.611323, acc 0.703125
2020-02-16T13:29:31.263121: step 895, loss 0.316572, acc 0.890625
2020-02-16T13:29:31.389497: step 896, loss 0.386721, acc 0.859375
2020-02-16T13:29:31.517565: step 897, loss 0.499936, acc 0.8125
2020-02-16T13:29:31.638827: step 898, loss 0.374986, acc 0.84375
2020-02-16T13:29:31.761515: step 899, loss 0.480928, acc 0.71875
2020-02-16T13:29:31.893073: step 900, loss 0.454015, acc 0.75

Evaluation:
2020-02-16T13:29:32.108000: step 900, loss 0.584289, acc 0.686679

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-900

2020-02-16T13:29:34.814262: step 901, loss 0.357408, acc 0.859375
2020-02-16T13:29:34.938540: step 902, loss 0.301328, acc 0.875
2020-02-16T13:29:35.061332: step 903, loss 0.254894, acc 0.921875
2020-02-16T13:29:35.188758: step 904, loss 0.342276, acc 0.828125
2020-02-16T13:29:35.351189: step 905, loss 0.411472, acc 0.796875
2020-02-16T13:29:35.498615: step 906, loss 0.36738, acc 0.828125
2020-02-16T13:29:35.624274: step 907, loss 0.406468, acc 0.796875
2020-02-16T13:29:35.749322: step 908, loss 0.399851, acc 0.78125
2020-02-16T13:29:35.869815: step 909, loss 0.440209, acc 0.75
2020-02-16T13:29:35.988017: step 910, loss 0.461747, acc 0.78125
2020-02-16T13:29:36.111119: step 911, loss 0.354065, acc 0.875
2020-02-16T13:29:36.234795: step 912, loss 0.384053, acc 0.8125
2020-02-16T13:29:36.361514: step 913, loss 0.302473, acc 0.859375
2020-02-16T13:29:36.490659: step 914, loss 0.320955, acc 0.859375
2020-02-16T13:29:36.618559: step 915, loss 0.388318, acc 0.8125
2020-02-16T13:29:36.751923: step 916, loss 0.32442, acc 0.859375
2020-02-16T13:29:36.879239: step 917, loss 0.437649, acc 0.8125
2020-02-16T13:29:37.012445: step 918, loss 0.405515, acc 0.8125
2020-02-16T13:29:37.142515: step 919, loss 0.264011, acc 0.875
2020-02-16T13:29:37.269421: step 920, loss 0.336693, acc 0.859375
2020-02-16T13:29:37.389110: step 921, loss 0.440375, acc 0.84375
2020-02-16T13:29:37.513741: step 922, loss 0.287522, acc 0.890625
2020-02-16T13:29:37.632730: step 923, loss 0.329577, acc 0.875
2020-02-16T13:29:37.750700: step 924, loss 0.347911, acc 0.84375
2020-02-16T13:29:37.869795: step 925, loss 0.317636, acc 0.90625
2020-02-16T13:29:37.988713: step 926, loss 0.378915, acc 0.828125
2020-02-16T13:29:38.105295: step 927, loss 0.382924, acc 0.859375
2020-02-16T13:29:38.221775: step 928, loss 0.38331, acc 0.859375
2020-02-16T13:29:38.339624: step 929, loss 0.266744, acc 0.875
2020-02-16T13:29:38.468521: step 930, loss 0.363671, acc 0.8125
2020-02-16T13:29:38.589663: step 931, loss 0.533042, acc 0.75
2020-02-16T13:29:38.710752: step 932, loss 0.327708, acc 0.890625
2020-02-16T13:29:38.831211: step 933, loss 0.352877, acc 0.890625
2020-02-16T13:29:38.951063: step 934, loss 0.455219, acc 0.828125
2020-02-16T13:29:39.069206: step 935, loss 0.42892, acc 0.796875
2020-02-16T13:29:39.185696: step 936, loss 0.368087, acc 0.875
2020-02-16T13:29:39.307949: step 937, loss 0.383767, acc 0.828125
2020-02-16T13:29:39.501426: step 938, loss 0.357286, acc 0.859375
2020-02-16T13:29:39.629297: step 939, loss 0.256451, acc 0.890625
2020-02-16T13:29:39.784663: step 940, loss 0.435531, acc 0.78125
2020-02-16T13:29:39.915663: step 941, loss 0.492098, acc 0.828125
2020-02-16T13:29:40.035329: step 942, loss 0.332221, acc 0.921875
2020-02-16T13:29:40.151832: step 943, loss 0.300854, acc 0.828125
2020-02-16T13:29:40.268055: step 944, loss 0.379063, acc 0.78125
2020-02-16T13:29:40.387083: step 945, loss 0.354816, acc 0.859375
2020-02-16T13:29:40.529360: step 946, loss 0.446904, acc 0.828125
2020-02-16T13:29:40.662641: step 947, loss 0.288166, acc 0.875
2020-02-16T13:29:40.787503: step 948, loss 0.3127, acc 0.859375
2020-02-16T13:29:40.935950: step 949, loss 0.384931, acc 0.828125
2020-02-16T13:29:41.060412: step 950, loss 0.303448, acc 0.875
2020-02-16T13:29:41.182599: step 951, loss 0.362375, acc 0.859375
2020-02-16T13:29:41.311259: step 952, loss 0.339021, acc 0.828125
2020-02-16T13:29:41.439784: step 953, loss 0.312243, acc 0.859375
2020-02-16T13:29:41.585619: step 954, loss 0.344146, acc 0.859375
2020-02-16T13:29:41.720254: step 955, loss 0.257764, acc 0.921875
2020-02-16T13:29:41.848386: step 956, loss 0.489368, acc 0.75
2020-02-16T13:29:41.983197: step 957, loss 0.423661, acc 0.78125
2020-02-16T13:29:42.109933: step 958, loss 0.348838, acc 0.890625
2020-02-16T13:29:42.233177: step 959, loss 0.506731, acc 0.75
2020-02-16T13:29:42.355626: step 960, loss 0.484431, acc 0.796875
2020-02-16T13:29:42.483255: step 961, loss 0.412773, acc 0.828125
2020-02-16T13:29:42.602003: step 962, loss 0.350689, acc 0.8125
2020-02-16T13:29:42.724222: step 963, loss 0.344315, acc 0.84375
2020-02-16T13:29:42.841495: step 964, loss 0.399148, acc 0.828125
2020-02-16T13:29:42.962468: step 965, loss 0.439706, acc 0.828125
2020-02-16T13:29:43.081419: step 966, loss 0.345617, acc 0.875
2020-02-16T13:29:43.198178: step 967, loss 0.416117, acc 0.78125
2020-02-16T13:29:43.315685: step 968, loss 0.401738, acc 0.796875
2020-02-16T13:29:43.438527: step 969, loss 0.341338, acc 0.90625
2020-02-16T13:29:43.559961: step 970, loss 0.375824, acc 0.828125
2020-02-16T13:29:43.686900: step 971, loss 0.36119, acc 0.828125
2020-02-16T13:29:43.820160: step 972, loss 0.358466, acc 0.8125
2020-02-16T13:29:43.950272: step 973, loss 0.297415, acc 0.859375
2020-02-16T13:29:44.075588: step 974, loss 0.377476, acc 0.84375
2020-02-16T13:29:44.195777: step 975, loss 0.364099, acc 0.796875
2020-02-16T13:29:44.318035: step 976, loss 0.290762, acc 0.875
2020-02-16T13:29:44.447080: step 977, loss 0.33266, acc 0.890625
2020-02-16T13:29:44.571970: step 978, loss 0.462999, acc 0.75
2020-02-16T13:29:44.712346: step 979, loss 0.290413, acc 0.875
2020-02-16T13:29:44.949570: step 980, loss 0.321404, acc 0.875
2020-02-16T13:29:45.127771: step 981, loss 0.414137, acc 0.796875
2020-02-16T13:29:45.316565: step 982, loss 0.360432, acc 0.875
2020-02-16T13:29:45.484344: step 983, loss 0.429862, acc 0.796875
2020-02-16T13:29:45.752890: step 984, loss 0.34, acc 0.859375
2020-02-16T13:29:45.892164: step 985, loss 0.379471, acc 0.796875
2020-02-16T13:29:46.045292: step 986, loss 0.439771, acc 0.8125
2020-02-16T13:29:46.208663: step 987, loss 0.358479, acc 0.84375
2020-02-16T13:29:46.410512: step 988, loss 0.38156, acc 0.859375
2020-02-16T13:29:46.556944: step 989, loss 0.289581, acc 0.890625
2020-02-16T13:29:46.720358: step 990, loss 0.345721, acc 0.875
2020-02-16T13:29:46.881447: step 991, loss 0.339063, acc 0.84375
2020-02-16T13:29:47.028502: step 992, loss 0.475899, acc 0.765625
2020-02-16T13:29:47.169426: step 993, loss 0.347152, acc 0.875
2020-02-16T13:29:47.325341: step 994, loss 0.468712, acc 0.796875
2020-02-16T13:29:47.487520: step 995, loss 0.400233, acc 0.796875
2020-02-16T13:29:47.629061: step 996, loss 0.362153, acc 0.859375
2020-02-16T13:29:47.770373: step 997, loss 0.285695, acc 0.890625
2020-02-16T13:29:47.905185: step 998, loss 0.421359, acc 0.78125
2020-02-16T13:29:48.051182: step 999, loss 0.432127, acc 0.8125
2020-02-16T13:29:48.213386: step 1000, loss 0.537955, acc 0.734375

Evaluation:
2020-02-16T13:29:48.487848: step 1000, loss 0.586794, acc 0.699812

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-1000

2020-02-16T13:29:51.020539: step 1001, loss 0.503318, acc 0.796875
2020-02-16T13:29:51.154318: step 1002, loss 0.368077, acc 0.78125
2020-02-16T13:29:51.285464: step 1003, loss 0.300988, acc 0.890625
2020-02-16T13:29:51.423227: step 1004, loss 0.317671, acc 0.90625
2020-02-16T13:29:51.554754: step 1005, loss 0.382207, acc 0.8125
2020-02-16T13:29:51.685727: step 1006, loss 0.288976, acc 0.890625
2020-02-16T13:29:51.828033: step 1007, loss 0.374631, acc 0.84375
2020-02-16T13:29:51.979954: step 1008, loss 0.463235, acc 0.765625
2020-02-16T13:29:52.119672: step 1009, loss 0.45711, acc 0.796875
2020-02-16T13:29:52.247516: step 1010, loss 0.35639, acc 0.875
2020-02-16T13:29:52.385607: step 1011, loss 0.463006, acc 0.875
2020-02-16T13:29:52.532653: step 1012, loss 0.410797, acc 0.828125
2020-02-16T13:29:52.674182: step 1013, loss 0.365189, acc 0.828125
2020-02-16T13:29:52.803452: step 1014, loss 0.414855, acc 0.8125
2020-02-16T13:29:52.936670: step 1015, loss 0.385045, acc 0.796875
2020-02-16T13:29:53.082169: step 1016, loss 0.3152, acc 0.859375
2020-02-16T13:29:53.220123: step 1017, loss 0.353771, acc 0.84375
2020-02-16T13:29:53.363637: step 1018, loss 0.346482, acc 0.859375
2020-02-16T13:29:53.515357: step 1019, loss 0.459866, acc 0.78125
2020-02-16T13:29:53.658002: step 1020, loss 0.343404, acc 0.84375
2020-02-16T13:29:53.783013: step 1021, loss 0.422023, acc 0.828125
2020-02-16T13:29:53.916018: step 1022, loss 0.341717, acc 0.828125
2020-02-16T13:29:54.045321: step 1023, loss 0.388153, acc 0.78125
2020-02-16T13:29:54.174482: step 1024, loss 0.42546, acc 0.75
2020-02-16T13:29:54.307680: step 1025, loss 0.40072, acc 0.8125
2020-02-16T13:29:54.452349: step 1026, loss 0.357922, acc 0.8125
2020-02-16T13:29:54.604929: step 1027, loss 0.362374, acc 0.796875
2020-02-16T13:29:54.743402: step 1028, loss 0.520002, acc 0.734375
2020-02-16T13:29:54.889769: step 1029, loss 0.380392, acc 0.796875
2020-02-16T13:29:55.023088: step 1030, loss 0.392508, acc 0.796875
2020-02-16T13:29:55.162734: step 1031, loss 0.350894, acc 0.84375
2020-02-16T13:29:55.299788: step 1032, loss 0.366176, acc 0.859375
2020-02-16T13:29:55.475230: step 1033, loss 0.28276, acc 0.890625
2020-02-16T13:29:55.643926: step 1034, loss 0.443995, acc 0.78125
2020-02-16T13:29:55.848310: step 1035, loss 0.386285, acc 0.796875
2020-02-16T13:29:56.028376: step 1036, loss 0.411385, acc 0.84375
2020-02-16T13:29:56.168534: step 1037, loss 0.422826, acc 0.78125
2020-02-16T13:29:56.294344: step 1038, loss 0.469752, acc 0.78125
2020-02-16T13:29:56.422780: step 1039, loss 0.362475, acc 0.828125
2020-02-16T13:29:56.545057: step 1040, loss 0.336505, acc 0.8125
2020-02-16T13:29:56.672551: step 1041, loss 0.32792, acc 0.8125
2020-02-16T13:29:56.831583: step 1042, loss 0.367491, acc 0.796875
2020-02-16T13:29:57.054669: step 1043, loss 0.233933, acc 0.90625
2020-02-16T13:29:57.181878: step 1044, loss 0.454425, acc 0.828125
2020-02-16T13:29:57.306049: step 1045, loss 0.271168, acc 0.921875
2020-02-16T13:29:57.436683: step 1046, loss 0.22597, acc 0.9375
2020-02-16T13:29:57.626456: step 1047, loss 0.504255, acc 0.78125
2020-02-16T13:29:57.754035: step 1048, loss 0.422343, acc 0.734375
2020-02-16T13:29:57.901151: step 1049, loss 0.320236, acc 0.828125
2020-02-16T13:29:58.024013: step 1050, loss 0.3611, acc 0.833333
2020-02-16T13:29:58.154929: step 1051, loss 0.249213, acc 0.921875
2020-02-16T13:29:58.285696: step 1052, loss 0.25033, acc 0.921875
2020-02-16T13:29:58.426487: step 1053, loss 0.289627, acc 0.84375
2020-02-16T13:29:58.649451: step 1054, loss 0.312156, acc 0.859375
2020-02-16T13:29:58.869299: step 1055, loss 0.242516, acc 0.921875
2020-02-16T13:29:59.010038: step 1056, loss 0.300024, acc 0.859375
2020-02-16T13:29:59.148103: step 1057, loss 0.171347, acc 0.953125
2020-02-16T13:29:59.306813: step 1058, loss 0.318754, acc 0.890625
2020-02-16T13:29:59.512550: step 1059, loss 0.379158, acc 0.828125
2020-02-16T13:29:59.743574: step 1060, loss 0.383197, acc 0.875
2020-02-16T13:29:59.907535: step 1061, loss 0.252243, acc 0.9375
2020-02-16T13:30:00.047206: step 1062, loss 0.276956, acc 0.859375
2020-02-16T13:30:00.296687: step 1063, loss 0.392635, acc 0.84375
2020-02-16T13:30:00.643192: step 1064, loss 0.352639, acc 0.859375
2020-02-16T13:30:00.796240: step 1065, loss 0.266479, acc 0.890625
2020-02-16T13:30:01.003959: step 1066, loss 0.290272, acc 0.828125
2020-02-16T13:30:01.139254: step 1067, loss 0.35713, acc 0.828125
2020-02-16T13:30:01.272227: step 1068, loss 0.27761, acc 0.90625
2020-02-16T13:30:01.412142: step 1069, loss 0.381601, acc 0.796875
2020-02-16T13:30:01.550478: step 1070, loss 0.310415, acc 0.84375
2020-02-16T13:30:01.686155: step 1071, loss 0.332943, acc 0.828125
2020-02-16T13:30:01.817822: step 1072, loss 0.308582, acc 0.875
2020-02-16T13:30:01.937924: step 1073, loss 0.338182, acc 0.84375
2020-02-16T13:30:02.080287: step 1074, loss 0.420795, acc 0.8125
2020-02-16T13:30:02.214346: step 1075, loss 0.260798, acc 0.890625
2020-02-16T13:30:02.355034: step 1076, loss 0.375409, acc 0.84375
2020-02-16T13:30:02.494123: step 1077, loss 0.20513, acc 0.921875
2020-02-16T13:30:02.634409: step 1078, loss 0.325096, acc 0.828125
2020-02-16T13:30:02.793368: step 1079, loss 0.311968, acc 0.828125
2020-02-16T13:30:02.939640: step 1080, loss 0.390383, acc 0.8125
2020-02-16T13:30:03.095540: step 1081, loss 0.378625, acc 0.84375
2020-02-16T13:30:03.335771: step 1082, loss 0.337719, acc 0.859375
2020-02-16T13:30:03.526537: step 1083, loss 0.306542, acc 0.90625
2020-02-16T13:30:03.671101: step 1084, loss 0.219424, acc 0.9375
2020-02-16T13:30:03.807716: step 1085, loss 0.268808, acc 0.84375
2020-02-16T13:30:04.016756: step 1086, loss 0.35911, acc 0.84375
2020-02-16T13:30:04.156557: step 1087, loss 0.393292, acc 0.796875
2020-02-16T13:30:04.297691: step 1088, loss 0.216062, acc 0.9375
2020-02-16T13:30:04.439207: step 1089, loss 0.175579, acc 0.953125
2020-02-16T13:30:04.583807: step 1090, loss 0.389705, acc 0.828125
2020-02-16T13:30:04.721340: step 1091, loss 0.277375, acc 0.890625
2020-02-16T13:30:05.001632: step 1092, loss 0.343535, acc 0.8125
2020-02-16T13:30:05.222020: step 1093, loss 0.186889, acc 0.953125
2020-02-16T13:30:05.365839: step 1094, loss 0.347085, acc 0.890625
2020-02-16T13:30:05.520151: step 1095, loss 0.306585, acc 0.890625
2020-02-16T13:30:05.698308: step 1096, loss 0.375425, acc 0.8125
2020-02-16T13:30:05.849241: step 1097, loss 0.296639, acc 0.890625
2020-02-16T13:30:05.990144: step 1098, loss 0.310745, acc 0.875
2020-02-16T13:30:06.134734: step 1099, loss 0.240155, acc 0.90625
2020-02-16T13:30:06.284224: step 1100, loss 0.306264, acc 0.875

Evaluation:
2020-02-16T13:30:06.531836: step 1100, loss 0.604485, acc 0.689493

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-1100

2020-02-16T13:30:09.686025: step 1101, loss 0.362552, acc 0.84375
2020-02-16T13:30:09.832806: step 1102, loss 0.360042, acc 0.8125
2020-02-16T13:30:10.008280: step 1103, loss 0.238503, acc 0.890625
2020-02-16T13:30:10.173436: step 1104, loss 0.396117, acc 0.84375
2020-02-16T13:30:10.321989: step 1105, loss 0.295141, acc 0.828125
2020-02-16T13:30:10.498230: step 1106, loss 0.265287, acc 0.828125
2020-02-16T13:30:10.636959: step 1107, loss 0.433448, acc 0.78125
2020-02-16T13:30:10.791319: step 1108, loss 0.341882, acc 0.828125
2020-02-16T13:30:10.948879: step 1109, loss 0.316214, acc 0.90625
2020-02-16T13:30:11.113935: step 1110, loss 0.347413, acc 0.8125
2020-02-16T13:30:11.280008: step 1111, loss 0.241656, acc 0.9375
2020-02-16T13:30:11.443284: step 1112, loss 0.212399, acc 0.9375
2020-02-16T13:30:11.584082: step 1113, loss 0.338948, acc 0.84375
2020-02-16T13:30:11.727043: step 1114, loss 0.400255, acc 0.828125
2020-02-16T13:30:11.883880: step 1115, loss 0.316566, acc 0.859375
2020-02-16T13:30:12.047025: step 1116, loss 0.237609, acc 0.921875
2020-02-16T13:30:12.205152: step 1117, loss 0.361683, acc 0.828125
2020-02-16T13:30:12.385492: step 1118, loss 0.349026, acc 0.828125
2020-02-16T13:30:12.550449: step 1119, loss 0.295922, acc 0.859375
2020-02-16T13:30:12.682949: step 1120, loss 0.2899, acc 0.859375
2020-02-16T13:30:12.811198: step 1121, loss 0.295646, acc 0.828125
2020-02-16T13:30:12.971157: step 1122, loss 0.152029, acc 0.953125
2020-02-16T13:30:13.127574: step 1123, loss 0.434066, acc 0.828125
2020-02-16T13:30:13.287272: step 1124, loss 0.340202, acc 0.859375
2020-02-16T13:30:13.563337: step 1125, loss 0.337064, acc 0.84375
2020-02-16T13:30:13.694251: step 1126, loss 0.143291, acc 0.96875
2020-02-16T13:30:13.824171: step 1127, loss 0.325105, acc 0.828125
2020-02-16T13:30:13.997053: step 1128, loss 0.30055, acc 0.859375
2020-02-16T13:30:14.195385: step 1129, loss 0.379966, acc 0.890625
2020-02-16T13:30:14.362161: step 1130, loss 0.42785, acc 0.78125
2020-02-16T13:30:14.529238: step 1131, loss 0.332695, acc 0.859375
2020-02-16T13:30:14.658516: step 1132, loss 0.30985, acc 0.859375
2020-02-16T13:30:14.801531: step 1133, loss 0.268905, acc 0.84375
2020-02-16T13:30:14.958162: step 1134, loss 0.25642, acc 0.921875
2020-02-16T13:30:15.149385: step 1135, loss 0.328622, acc 0.828125
2020-02-16T13:30:15.351132: step 1136, loss 0.276886, acc 0.90625
2020-02-16T13:30:15.509442: step 1137, loss 0.300181, acc 0.859375
2020-02-16T13:30:15.651198: step 1138, loss 0.293841, acc 0.890625
2020-02-16T13:30:15.819966: step 1139, loss 0.300311, acc 0.890625
2020-02-16T13:30:15.984765: step 1140, loss 0.31133, acc 0.875
2020-02-16T13:30:16.168476: step 1141, loss 0.233517, acc 0.90625
2020-02-16T13:30:16.316867: step 1142, loss 0.374734, acc 0.8125
2020-02-16T13:30:16.490608: step 1143, loss 0.173062, acc 0.9375
2020-02-16T13:30:16.633504: step 1144, loss 0.25444, acc 0.890625
2020-02-16T13:30:16.779370: step 1145, loss 0.159259, acc 0.96875
2020-02-16T13:30:16.937460: step 1146, loss 0.224601, acc 0.921875
2020-02-16T13:30:17.079109: step 1147, loss 0.396217, acc 0.828125
2020-02-16T13:30:17.240783: step 1148, loss 0.284348, acc 0.890625
2020-02-16T13:30:17.435014: step 1149, loss 0.250393, acc 0.875
2020-02-16T13:30:17.567419: step 1150, loss 0.295928, acc 0.890625
2020-02-16T13:30:17.689322: step 1151, loss 0.22439, acc 0.90625
2020-02-16T13:30:17.830681: step 1152, loss 0.283437, acc 0.90625
2020-02-16T13:30:17.994378: step 1153, loss 0.353721, acc 0.78125
2020-02-16T13:30:18.149414: step 1154, loss 0.244431, acc 0.921875
2020-02-16T13:30:18.348675: step 1155, loss 0.323731, acc 0.859375
2020-02-16T13:30:18.516806: step 1156, loss 0.284467, acc 0.90625
2020-02-16T13:30:18.668270: step 1157, loss 0.330508, acc 0.875
2020-02-16T13:30:18.804790: step 1158, loss 0.207601, acc 0.890625
2020-02-16T13:30:18.953817: step 1159, loss 0.249432, acc 0.921875
2020-02-16T13:30:19.121665: step 1160, loss 0.324651, acc 0.875
2020-02-16T13:30:19.283264: step 1161, loss 0.322039, acc 0.84375
2020-02-16T13:30:19.489019: step 1162, loss 0.184148, acc 0.921875
2020-02-16T13:30:19.626444: step 1163, loss 0.24611, acc 0.890625
2020-02-16T13:30:19.761250: step 1164, loss 0.443815, acc 0.828125
2020-02-16T13:30:19.975949: step 1165, loss 0.26499, acc 0.921875
2020-02-16T13:30:20.130651: step 1166, loss 0.325408, acc 0.796875
2020-02-16T13:30:20.278099: step 1167, loss 0.428437, acc 0.859375
2020-02-16T13:30:20.406619: step 1168, loss 0.306634, acc 0.828125
2020-02-16T13:30:20.542826: step 1169, loss 0.383693, acc 0.84375
2020-02-16T13:30:20.685618: step 1170, loss 0.285621, acc 0.90625
2020-02-16T13:30:20.804153: step 1171, loss 0.407634, acc 0.828125
2020-02-16T13:30:20.925051: step 1172, loss 0.339123, acc 0.859375
2020-02-16T13:30:21.056956: step 1173, loss 0.239971, acc 0.90625
2020-02-16T13:30:21.191442: step 1174, loss 0.243897, acc 0.90625
2020-02-16T13:30:21.314581: step 1175, loss 0.272864, acc 0.859375
2020-02-16T13:30:21.437184: step 1176, loss 0.358757, acc 0.828125
2020-02-16T13:30:21.567282: step 1177, loss 0.407006, acc 0.796875
2020-02-16T13:30:21.710254: step 1178, loss 0.301394, acc 0.875
2020-02-16T13:30:21.843788: step 1179, loss 0.192328, acc 0.921875
2020-02-16T13:30:21.981438: step 1180, loss 0.326731, acc 0.859375
2020-02-16T13:30:22.123849: step 1181, loss 0.384351, acc 0.828125
2020-02-16T13:30:22.264701: step 1182, loss 0.464353, acc 0.765625
2020-02-16T13:30:22.389232: step 1183, loss 0.350801, acc 0.84375
2020-02-16T13:30:22.530380: step 1184, loss 0.205581, acc 0.90625
2020-02-16T13:30:22.650277: step 1185, loss 0.357485, acc 0.859375
2020-02-16T13:30:22.773990: step 1186, loss 0.166202, acc 0.9375
2020-02-16T13:30:22.903038: step 1187, loss 0.455415, acc 0.78125
2020-02-16T13:30:23.052123: step 1188, loss 0.238181, acc 0.953125
2020-02-16T13:30:23.177300: step 1189, loss 0.356057, acc 0.828125
2020-02-16T13:30:23.295769: step 1190, loss 0.309819, acc 0.859375
2020-02-16T13:30:23.420505: step 1191, loss 0.260634, acc 0.890625
2020-02-16T13:30:23.562814: step 1192, loss 0.280161, acc 0.875
2020-02-16T13:30:23.694100: step 1193, loss 0.213323, acc 0.921875
2020-02-16T13:30:23.827099: step 1194, loss 0.327302, acc 0.84375
2020-02-16T13:30:23.973973: step 1195, loss 0.300559, acc 0.859375
2020-02-16T13:30:24.113802: step 1196, loss 0.314926, acc 0.859375
2020-02-16T13:30:24.234874: step 1197, loss 0.327871, acc 0.828125
2020-02-16T13:30:24.358315: step 1198, loss 0.390325, acc 0.8125
2020-02-16T13:30:24.497814: step 1199, loss 0.318423, acc 0.875
2020-02-16T13:30:24.635845: step 1200, loss 0.334953, acc 0.85

Evaluation:
2020-02-16T13:30:24.878000: step 1200, loss 0.59104, acc 0.712946

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-1200

2020-02-16T13:30:27.383203: step 1201, loss 0.209834, acc 0.953125
2020-02-16T13:30:27.513448: step 1202, loss 0.268664, acc 0.90625
2020-02-16T13:30:27.632920: step 1203, loss 0.315181, acc 0.890625
2020-02-16T13:30:27.763418: step 1204, loss 0.226484, acc 0.921875
2020-02-16T13:30:27.904659: step 1205, loss 0.232135, acc 0.890625
2020-02-16T13:30:28.051537: step 1206, loss 0.165717, acc 0.921875
2020-02-16T13:30:28.192095: step 1207, loss 0.212734, acc 0.921875
2020-02-16T13:30:28.321241: step 1208, loss 0.241957, acc 0.890625
2020-02-16T13:30:28.456647: step 1209, loss 0.231841, acc 0.921875
2020-02-16T13:30:28.586752: step 1210, loss 0.307283, acc 0.890625
2020-02-16T13:30:28.723651: step 1211, loss 0.221607, acc 0.9375
2020-02-16T13:30:28.856255: step 1212, loss 0.276152, acc 0.875
2020-02-16T13:30:28.982040: step 1213, loss 0.282552, acc 0.859375
2020-02-16T13:30:29.101995: step 1214, loss 0.0849891, acc 0.984375
2020-02-16T13:30:29.240730: step 1215, loss 0.200296, acc 0.921875
2020-02-16T13:30:29.364677: step 1216, loss 0.373262, acc 0.8125
2020-02-16T13:30:29.503089: step 1217, loss 0.241236, acc 0.90625
2020-02-16T13:30:29.627672: step 1218, loss 0.170738, acc 0.96875
2020-02-16T13:30:29.766652: step 1219, loss 0.251167, acc 0.90625
2020-02-16T13:30:29.906834: step 1220, loss 0.211067, acc 0.9375
2020-02-16T13:30:30.033920: step 1221, loss 0.212278, acc 0.921875
2020-02-16T13:30:30.165869: step 1222, loss 0.264814, acc 0.859375
2020-02-16T13:30:30.309166: step 1223, loss 0.167708, acc 0.953125
2020-02-16T13:30:30.436234: step 1224, loss 0.371247, acc 0.765625
2020-02-16T13:30:30.670287: step 1225, loss 0.154785, acc 0.96875
2020-02-16T13:30:30.800671: step 1226, loss 0.171654, acc 0.953125
2020-02-16T13:30:30.922031: step 1227, loss 0.242949, acc 0.875
2020-02-16T13:30:31.041469: step 1228, loss 0.260212, acc 0.875
2020-02-16T13:30:31.164688: step 1229, loss 0.12871, acc 0.96875
2020-02-16T13:30:31.285078: step 1230, loss 0.260506, acc 0.875
2020-02-16T13:30:31.407930: step 1231, loss 0.18201, acc 0.9375
2020-02-16T13:30:31.529440: step 1232, loss 0.279402, acc 0.875
2020-02-16T13:30:31.667274: step 1233, loss 0.239045, acc 0.890625
2020-02-16T13:30:31.811773: step 1234, loss 0.233336, acc 0.90625
2020-02-16T13:30:31.945864: step 1235, loss 0.251168, acc 0.921875
2020-02-16T13:30:32.083048: step 1236, loss 0.178196, acc 0.921875
2020-02-16T13:30:32.230058: step 1237, loss 0.293123, acc 0.859375
2020-02-16T13:30:32.388525: step 1238, loss 0.319189, acc 0.890625
2020-02-16T13:30:32.537611: step 1239, loss 0.252173, acc 0.9375
2020-02-16T13:30:32.657748: step 1240, loss 0.178573, acc 0.90625
2020-02-16T13:30:32.802154: step 1241, loss 0.259555, acc 0.9375
2020-02-16T13:30:32.934484: step 1242, loss 0.127789, acc 0.984375
2020-02-16T13:30:33.064152: step 1243, loss 0.352764, acc 0.796875
2020-02-16T13:30:33.190615: step 1244, loss 0.186277, acc 0.921875
2020-02-16T13:30:33.319118: step 1245, loss 0.133177, acc 0.96875
2020-02-16T13:30:33.460133: step 1246, loss 0.348488, acc 0.890625
2020-02-16T13:30:33.587343: step 1247, loss 0.301578, acc 0.890625
2020-02-16T13:30:33.722945: step 1248, loss 0.480812, acc 0.828125
2020-02-16T13:30:33.848838: step 1249, loss 0.269847, acc 0.859375
2020-02-16T13:30:33.994961: step 1250, loss 0.0964913, acc 0.984375
2020-02-16T13:30:34.117225: step 1251, loss 0.128526, acc 0.984375
2020-02-16T13:30:34.255324: step 1252, loss 0.190482, acc 0.953125
2020-02-16T13:30:34.396339: step 1253, loss 0.16495, acc 0.9375
2020-02-16T13:30:34.542611: step 1254, loss 0.197334, acc 0.921875
2020-02-16T13:30:34.672131: step 1255, loss 0.29755, acc 0.875
2020-02-16T13:30:34.816620: step 1256, loss 0.145205, acc 0.953125
2020-02-16T13:30:34.954608: step 1257, loss 0.233761, acc 0.875
2020-02-16T13:30:35.087157: step 1258, loss 0.249849, acc 0.9375
2020-02-16T13:30:35.210495: step 1259, loss 0.235297, acc 0.890625
2020-02-16T13:30:35.340102: step 1260, loss 0.122585, acc 0.96875
2020-02-16T13:30:35.481986: step 1261, loss 0.146884, acc 0.9375
2020-02-16T13:30:35.602951: step 1262, loss 0.141712, acc 0.984375
2020-02-16T13:30:35.727647: step 1263, loss 0.344396, acc 0.890625
2020-02-16T13:30:35.847884: step 1264, loss 0.315128, acc 0.875
2020-02-16T13:30:35.969068: step 1265, loss 0.270332, acc 0.859375
2020-02-16T13:30:36.090564: step 1266, loss 0.309951, acc 0.84375
2020-02-16T13:30:36.212819: step 1267, loss 0.412094, acc 0.78125
2020-02-16T13:30:36.335204: step 1268, loss 0.312123, acc 0.8125
2020-02-16T13:30:36.462927: step 1269, loss 0.267635, acc 0.890625
2020-02-16T13:30:36.583823: step 1270, loss 0.224664, acc 0.890625
2020-02-16T13:30:36.702539: step 1271, loss 0.241786, acc 0.9375
2020-02-16T13:30:36.837156: step 1272, loss 0.209181, acc 0.890625
2020-02-16T13:30:36.969788: step 1273, loss 0.316448, acc 0.859375
2020-02-16T13:30:37.096615: step 1274, loss 0.286574, acc 0.828125
2020-02-16T13:30:37.220250: step 1275, loss 0.169996, acc 0.9375
2020-02-16T13:30:37.344573: step 1276, loss 0.408819, acc 0.84375
2020-02-16T13:30:37.477378: step 1277, loss 0.309011, acc 0.875
2020-02-16T13:30:37.600080: step 1278, loss 0.237091, acc 0.9375
2020-02-16T13:30:37.718405: step 1279, loss 0.381597, acc 0.828125
2020-02-16T13:30:37.840877: step 1280, loss 0.191109, acc 0.921875
2020-02-16T13:30:37.962737: step 1281, loss 0.271514, acc 0.859375
2020-02-16T13:30:38.082911: step 1282, loss 0.312359, acc 0.890625
2020-02-16T13:30:38.202753: step 1283, loss 0.257136, acc 0.921875
2020-02-16T13:30:38.326463: step 1284, loss 0.341673, acc 0.8125
2020-02-16T13:30:38.476705: step 1285, loss 0.23135, acc 0.859375
2020-02-16T13:30:38.599748: step 1286, loss 0.20502, acc 0.9375
2020-02-16T13:30:38.728089: step 1287, loss 0.323463, acc 0.859375
2020-02-16T13:30:38.852653: step 1288, loss 0.254283, acc 0.9375
2020-02-16T13:30:38.979253: step 1289, loss 0.269903, acc 0.859375
2020-02-16T13:30:39.100314: step 1290, loss 0.217391, acc 0.90625
2020-02-16T13:30:39.227211: step 1291, loss 0.466941, acc 0.859375
2020-02-16T13:30:39.347151: step 1292, loss 0.295017, acc 0.84375
2020-02-16T13:30:39.477168: step 1293, loss 0.215416, acc 0.9375
2020-02-16T13:30:39.602264: step 1294, loss 0.17759, acc 0.90625
2020-02-16T13:30:39.730498: step 1295, loss 0.231376, acc 0.921875
2020-02-16T13:30:39.856942: step 1296, loss 0.199241, acc 0.9375
2020-02-16T13:30:39.978505: step 1297, loss 0.26724, acc 0.921875
2020-02-16T13:30:40.100814: step 1298, loss 0.304188, acc 0.875
2020-02-16T13:30:40.222015: step 1299, loss 0.187239, acc 0.90625
2020-02-16T13:30:40.347194: step 1300, loss 0.389015, acc 0.84375

Evaluation:
2020-02-16T13:30:40.572291: step 1300, loss 0.605753, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-1300

2020-02-16T13:30:43.051316: step 1301, loss 0.254552, acc 0.859375
2020-02-16T13:30:43.177222: step 1302, loss 0.199557, acc 0.953125
2020-02-16T13:30:43.301524: step 1303, loss 0.215565, acc 0.875
2020-02-16T13:30:43.429748: step 1304, loss 0.2623, acc 0.890625
2020-02-16T13:30:43.552996: step 1305, loss 0.256442, acc 0.90625
2020-02-16T13:30:43.675024: step 1306, loss 0.196575, acc 0.9375
2020-02-16T13:30:43.795806: step 1307, loss 0.348964, acc 0.828125
2020-02-16T13:30:43.929900: step 1308, loss 0.201534, acc 0.921875
2020-02-16T13:30:44.060414: step 1309, loss 0.478429, acc 0.84375
2020-02-16T13:30:44.178048: step 1310, loss 0.230831, acc 0.9375
2020-02-16T13:30:44.300047: step 1311, loss 0.202313, acc 0.921875
2020-02-16T13:30:44.435254: step 1312, loss 0.150088, acc 0.96875
2020-02-16T13:30:44.558695: step 1313, loss 0.314704, acc 0.84375
2020-02-16T13:30:44.681762: step 1314, loss 0.290403, acc 0.90625
2020-02-16T13:30:44.804147: step 1315, loss 0.284379, acc 0.921875
2020-02-16T13:30:44.927340: step 1316, loss 0.276416, acc 0.859375
2020-02-16T13:30:45.063520: step 1317, loss 0.237966, acc 0.890625
2020-02-16T13:30:45.187665: step 1318, loss 0.229063, acc 0.921875
2020-02-16T13:30:45.310333: step 1319, loss 0.231109, acc 0.875
2020-02-16T13:30:45.459653: step 1320, loss 0.361023, acc 0.828125
2020-02-16T13:30:45.585414: step 1321, loss 0.406869, acc 0.765625
2020-02-16T13:30:45.709616: step 1322, loss 0.308891, acc 0.875
2020-02-16T13:30:45.832281: step 1323, loss 0.203146, acc 0.921875
2020-02-16T13:30:45.953306: step 1324, loss 0.333865, acc 0.828125
2020-02-16T13:30:46.075179: step 1325, loss 0.20616, acc 0.890625
2020-02-16T13:30:46.195154: step 1326, loss 0.253582, acc 0.875
2020-02-16T13:30:46.316938: step 1327, loss 0.29644, acc 0.875
2020-02-16T13:30:46.483374: step 1328, loss 0.18773, acc 0.90625
2020-02-16T13:30:46.605511: step 1329, loss 0.339385, acc 0.84375
2020-02-16T13:30:46.731971: step 1330, loss 0.214389, acc 0.921875
2020-02-16T13:30:46.851516: step 1331, loss 0.299994, acc 0.875
2020-02-16T13:30:46.975504: step 1332, loss 0.380699, acc 0.796875
2020-02-16T13:30:47.123589: step 1333, loss 0.181326, acc 0.921875
2020-02-16T13:30:47.241277: step 1334, loss 0.208157, acc 0.890625
2020-02-16T13:30:47.381830: step 1335, loss 0.290118, acc 0.890625
2020-02-16T13:30:47.517764: step 1336, loss 0.163496, acc 0.9375
2020-02-16T13:30:47.641798: step 1337, loss 0.206448, acc 0.9375
2020-02-16T13:30:47.771792: step 1338, loss 0.208969, acc 0.9375
2020-02-16T13:30:47.892869: step 1339, loss 0.282035, acc 0.859375
2020-02-16T13:30:48.015783: step 1340, loss 0.275884, acc 0.890625
2020-02-16T13:30:48.143173: step 1341, loss 0.161005, acc 0.953125
2020-02-16T13:30:48.266939: step 1342, loss 0.345376, acc 0.8125
2020-02-16T13:30:48.400259: step 1343, loss 0.270407, acc 0.90625
2020-02-16T13:30:48.532183: step 1344, loss 0.193709, acc 0.921875
2020-02-16T13:30:48.667647: step 1345, loss 0.30662, acc 0.890625
2020-02-16T13:30:48.793615: step 1346, loss 0.311317, acc 0.828125
2020-02-16T13:30:48.917484: step 1347, loss 0.364567, acc 0.84375
2020-02-16T13:30:49.056675: step 1348, loss 0.19892, acc 0.90625
2020-02-16T13:30:49.177530: step 1349, loss 0.113881, acc 0.96875
2020-02-16T13:30:49.301324: step 1350, loss 0.186447, acc 0.9
2020-02-16T13:30:49.431484: step 1351, loss 0.101206, acc 0.96875
2020-02-16T13:30:49.552092: step 1352, loss 0.146922, acc 0.953125
2020-02-16T13:30:49.670480: step 1353, loss 0.154261, acc 0.96875
2020-02-16T13:30:49.788522: step 1354, loss 0.252661, acc 0.84375
2020-02-16T13:30:49.912406: step 1355, loss 0.260729, acc 0.90625
2020-02-16T13:30:50.051196: step 1356, loss 0.123035, acc 0.96875
2020-02-16T13:30:50.173987: step 1357, loss 0.160894, acc 0.9375
2020-02-16T13:30:50.298100: step 1358, loss 0.370639, acc 0.828125
2020-02-16T13:30:50.420356: step 1359, loss 0.144542, acc 0.9375
2020-02-16T13:30:50.538798: step 1360, loss 0.266084, acc 0.890625
2020-02-16T13:30:50.657022: step 1361, loss 0.159234, acc 0.953125
2020-02-16T13:30:50.780769: step 1362, loss 0.163673, acc 0.9375
2020-02-16T13:30:50.922166: step 1363, loss 0.246237, acc 0.921875
2020-02-16T13:30:51.041577: step 1364, loss 0.295079, acc 0.90625
2020-02-16T13:30:51.166439: step 1365, loss 0.235549, acc 0.859375
2020-02-16T13:30:51.293807: step 1366, loss 0.187992, acc 0.921875
2020-02-16T13:30:51.425910: step 1367, loss 0.123902, acc 0.9375
2020-02-16T13:30:51.550838: step 1368, loss 0.167975, acc 0.9375
2020-02-16T13:30:51.685999: step 1369, loss 0.14748, acc 0.9375
2020-02-16T13:30:51.808613: step 1370, loss 0.269212, acc 0.90625
2020-02-16T13:30:51.950027: step 1371, loss 0.221327, acc 0.890625
2020-02-16T13:30:52.073923: step 1372, loss 0.158561, acc 0.953125
2020-02-16T13:30:52.198132: step 1373, loss 0.157624, acc 0.9375
2020-02-16T13:30:52.332968: step 1374, loss 0.177167, acc 0.90625
2020-02-16T13:30:52.466065: step 1375, loss 0.162811, acc 0.9375
2020-02-16T13:30:52.594883: step 1376, loss 0.222022, acc 0.921875
2020-02-16T13:30:52.718345: step 1377, loss 0.223619, acc 0.90625
2020-02-16T13:30:52.838259: step 1378, loss 0.17621, acc 0.921875
2020-02-16T13:30:52.980963: step 1379, loss 0.111651, acc 0.96875
2020-02-16T13:30:53.103289: step 1380, loss 0.200664, acc 0.921875
2020-02-16T13:30:53.225513: step 1381, loss 0.360998, acc 0.84375
2020-02-16T13:30:53.342553: step 1382, loss 0.204031, acc 0.921875
2020-02-16T13:30:53.469481: step 1383, loss 0.194501, acc 0.921875
2020-02-16T13:30:53.588549: step 1384, loss 0.110631, acc 0.984375
2020-02-16T13:30:53.709135: step 1385, loss 0.172646, acc 0.953125
2020-02-16T13:30:53.826559: step 1386, loss 0.118432, acc 0.984375
2020-02-16T13:30:53.949487: step 1387, loss 0.207528, acc 0.90625
2020-02-16T13:30:54.081454: step 1388, loss 0.243001, acc 0.921875
2020-02-16T13:30:54.208351: step 1389, loss 0.218805, acc 0.921875
2020-02-16T13:30:54.335498: step 1390, loss 0.320073, acc 0.859375
2020-02-16T13:30:54.476686: step 1391, loss 0.318473, acc 0.84375
2020-02-16T13:30:54.605333: step 1392, loss 0.242617, acc 0.921875
2020-02-16T13:30:54.729316: step 1393, loss 0.133387, acc 0.96875
2020-02-16T13:30:54.848782: step 1394, loss 0.236049, acc 0.875
2020-02-16T13:30:54.982045: step 1395, loss 0.216397, acc 0.921875
2020-02-16T13:30:55.110943: step 1396, loss 0.199919, acc 0.90625
2020-02-16T13:30:55.234991: step 1397, loss 0.186259, acc 0.9375
2020-02-16T13:30:55.370935: step 1398, loss 0.146181, acc 0.9375
2020-02-16T13:30:55.511722: step 1399, loss 0.150162, acc 0.9375
2020-02-16T13:30:55.703929: step 1400, loss 0.205274, acc 0.90625

Evaluation:
2020-02-16T13:30:55.929184: step 1400, loss 0.621573, acc 0.707317

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model-1400

2020-02-16T13:30:59.166799: step 1401, loss 0.164155, acc 0.96875
2020-02-16T13:30:59.294439: step 1402, loss 0.260421, acc 0.90625
2020-02-16T13:30:59.426520: step 1403, loss 0.200152, acc 0.921875
2020-02-16T13:30:59.557011: step 1404, loss 0.389037, acc 0.859375
2020-02-16T13:30:59.686704: step 1405, loss 0.0669995, acc 0.96875
2020-02-16T13:30:59.819633: step 1406, loss 0.158934, acc 0.953125
2020-02-16T13:30:59.956465: step 1407, loss 0.30161, acc 0.859375
2020-02-16T13:31:00.084000: step 1408, loss 0.187606, acc 0.9375
2020-02-16T13:31:00.209800: step 1409, loss 0.166914, acc 0.953125
2020-02-16T13:31:00.480646: step 1410, loss 0.140132, acc 0.9375
2020-02-16T13:31:00.604531: step 1411, loss 0.122923, acc 0.9375
2020-02-16T13:31:00.725263: step 1412, loss 0.121871, acc 0.9375
2020-02-16T13:31:00.847340: step 1413, loss 0.126642, acc 0.953125
2020-02-16T13:31:00.968079: step 1414, loss 0.106913, acc 0.96875
2020-02-16T13:31:01.089544: step 1415, loss 0.181401, acc 0.921875
2020-02-16T13:31:01.214276: step 1416, loss 0.171068, acc 0.90625
2020-02-16T13:31:01.337414: step 1417, loss 0.180787, acc 0.9375
2020-02-16T13:31:01.466245: step 1418, loss 0.209906, acc 0.921875
2020-02-16T13:31:01.588936: step 1419, loss 0.262182, acc 0.90625
2020-02-16T13:31:01.709740: step 1420, loss 0.178509, acc 0.90625
2020-02-16T13:31:01.828105: step 1421, loss 0.118812, acc 0.953125
2020-02-16T13:31:01.949504: step 1422, loss 0.164748, acc 0.9375
2020-02-16T13:31:02.070027: step 1423, loss 0.187885, acc 0.953125
2020-02-16T13:31:02.191865: step 1424, loss 0.188808, acc 0.921875
2020-02-16T13:31:02.311632: step 1425, loss 0.236026, acc 0.90625
2020-02-16T13:31:02.433439: step 1426, loss 0.280721, acc 0.921875
2020-02-16T13:31:02.566762: step 1427, loss 0.141218, acc 0.953125
2020-02-16T13:31:02.718553: step 1428, loss 0.18659, acc 0.921875
2020-02-16T13:31:02.860501: step 1429, loss 0.152662, acc 0.921875
2020-02-16T13:31:02.991397: step 1430, loss 0.172333, acc 0.9375
2020-02-16T13:31:03.129367: step 1431, loss 0.314859, acc 0.796875
2020-02-16T13:31:03.248866: step 1432, loss 0.228333, acc 0.921875
2020-02-16T13:31:03.366587: step 1433, loss 0.170682, acc 0.9375
2020-02-16T13:31:03.494045: step 1434, loss 0.139035, acc 0.9375
2020-02-16T13:31:03.621220: step 1435, loss 0.170041, acc 0.9375
2020-02-16T13:31:03.752964: step 1436, loss 0.220975, acc 0.921875
2020-02-16T13:31:03.901148: step 1437, loss 0.234244, acc 0.890625
2020-02-16T13:31:04.030181: step 1438, loss 0.232347, acc 0.890625
2020-02-16T13:31:04.159193: step 1439, loss 0.167839, acc 0.9375
2020-02-16T13:31:04.280574: step 1440, loss 0.256952, acc 0.921875
2020-02-16T13:31:04.402254: step 1441, loss 0.157573, acc 0.953125
2020-02-16T13:31:04.528699: step 1442, loss 0.232552, acc 0.890625
2020-02-16T13:31:04.656000: step 1443, loss 0.317335, acc 0.859375
2020-02-16T13:31:04.783652: step 1444, loss 0.270482, acc 0.859375
2020-02-16T13:31:04.913567: step 1445, loss 0.125063, acc 0.96875
2020-02-16T13:31:05.040670: step 1446, loss 0.0567101, acc 1
2020-02-16T13:31:05.160864: step 1447, loss 0.235026, acc 0.890625
2020-02-16T13:31:05.283821: step 1448, loss 0.172934, acc 0.921875
2020-02-16T13:31:05.413406: step 1449, loss 0.289232, acc 0.875
2020-02-16T13:31:05.535689: step 1450, loss 0.167406, acc 0.9375
2020-02-16T13:31:05.656860: step 1451, loss 0.247061, acc 0.90625
2020-02-16T13:31:05.782414: step 1452, loss 0.127014, acc 0.9375
2020-02-16T13:31:05.903244: step 1453, loss 0.217379, acc 0.921875
2020-02-16T13:31:06.026547: step 1454, loss 0.162121, acc 0.9375
2020-02-16T13:31:06.147486: step 1455, loss 0.248701, acc 0.921875
2020-02-16T13:31:06.265677: step 1456, loss 0.336771, acc 0.859375
2020-02-16T13:31:06.419568: step 1457, loss 0.222545, acc 0.921875
2020-02-16T13:31:06.576772: step 1458, loss 0.235063, acc 0.875
2020-02-16T13:31:06.695746: step 1459, loss 0.213931, acc 0.90625
2020-02-16T13:31:06.821105: step 1460, loss 0.235725, acc 0.90625
2020-02-16T13:31:06.945763: step 1461, loss 0.237845, acc 0.890625
2020-02-16T13:31:07.073074: step 1462, loss 0.204344, acc 0.90625
2020-02-16T13:31:07.195511: step 1463, loss 0.307711, acc 0.8125
2020-02-16T13:31:07.321160: step 1464, loss 0.204778, acc 0.890625
2020-02-16T13:31:07.448564: step 1465, loss 0.240533, acc 0.890625
2020-02-16T13:31:07.574936: step 1466, loss 0.213118, acc 0.9375
2020-02-16T13:31:07.696510: step 1467, loss 0.159388, acc 0.9375
2020-02-16T13:31:07.820295: step 1468, loss 0.256244, acc 0.890625
2020-02-16T13:31:07.945769: step 1469, loss 0.249177, acc 0.875
2020-02-16T13:31:08.077602: step 1470, loss 0.224544, acc 0.875
2020-02-16T13:31:08.195037: step 1471, loss 0.215906, acc 0.921875
2020-02-16T13:31:08.315387: step 1472, loss 0.352448, acc 0.859375
2020-02-16T13:31:08.439875: step 1473, loss 0.362694, acc 0.875
2020-02-16T13:31:08.559531: step 1474, loss 0.211677, acc 0.921875
2020-02-16T13:31:08.691611: step 1475, loss 0.195394, acc 0.90625
2020-02-16T13:31:08.849199: step 1476, loss 0.190901, acc 0.9375
2020-02-16T13:31:08.987422: step 1477, loss 0.169261, acc 0.953125
2020-02-16T13:31:09.113136: step 1478, loss 0.137239, acc 0.953125
2020-02-16T13:31:09.244233: step 1479, loss 0.140506, acc 0.984375
2020-02-16T13:31:09.367531: step 1480, loss 0.146043, acc 0.921875
2020-02-16T13:31:09.496572: step 1481, loss 0.105806, acc 0.96875
2020-02-16T13:31:09.621154: step 1482, loss 0.0670892, acc 1
2020-02-16T13:31:09.750112: step 1483, loss 0.171523, acc 0.9375
2020-02-16T13:31:09.883243: step 1484, loss 0.189767, acc 0.921875
2020-02-16T13:31:10.006344: step 1485, loss 0.134812, acc 0.96875
2020-02-16T13:31:10.178899: step 1486, loss 0.225307, acc 0.921875
2020-02-16T13:31:10.317827: step 1487, loss 0.260378, acc 0.859375
2020-02-16T13:31:10.462661: step 1488, loss 0.200797, acc 0.9375
2020-02-16T13:31:10.584490: step 1489, loss 0.155581, acc 0.9375
2020-02-16T13:31:10.702247: step 1490, loss 0.153221, acc 0.953125
2020-02-16T13:31:10.829009: step 1491, loss 0.061931, acc 1
2020-02-16T13:31:10.953372: step 1492, loss 0.229363, acc 0.875
2020-02-16T13:31:11.074313: step 1493, loss 0.222728, acc 0.890625
2020-02-16T13:31:11.196749: step 1494, loss 0.129462, acc 0.953125
2020-02-16T13:31:11.325521: step 1495, loss 0.220916, acc 0.9375
2020-02-16T13:31:11.458734: step 1496, loss 0.157803, acc 0.953125
2020-02-16T13:31:11.587780: step 1497, loss 0.334734, acc 0.859375
2020-02-16T13:31:11.719874: step 1498, loss 0.168486, acc 0.9375
2020-02-16T13:31:11.869686: step 1499, loss 0.229827, acc 0.875
2020-02-16T13:31:11.984376: step 1500, loss 0.141383, acc 0.95

Evaluation:
2020-02-16T13:31:12.185496: step 1500, loss 0.648762, acc 0.701689

Traceback (most recent call last):
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1365, in _do_call
    return fn(*args)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1350, in _run_fn
    target_list, run_metadata)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints; No such file or directory
	 [[{{node save/SaveV2}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 1176, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 956, in run
    run_metadata_ptr)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1359, in _do_run
    run_metadata)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints; No such file or directory
	 [[node save/SaveV2 (defined at /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]

Original stack trace for 'save/SaveV2':
  File "train.py", line 196, in <module>
    tf.app.run()
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "train.py", line 193, in main
    train(x_train, y_train, vocab_processor, x_dev, y_dev)
  File "train.py", line 134, in train
    saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 828, in __init__
    self.build()
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 840, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 878, in _build
    build_restore=build_restore)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 505, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 206, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 122, in save_op
    tensors)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_io_ops.py", line 1946, in save_v2
    name=name)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py", line 794, in _apply_op_helper
    op_def=op_def)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 3357, in create_op
    attrs, op_def, compute_device)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 3426, in _create_op_internal
    op_def=op_def)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 196, in <module>
    tf.app.run()
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "train.py", line 193, in main
    train(x_train, y_train, vocab_processor, x_dev, y_dev)
  File "train.py", line 188, in train
    path = saver.save(sess, checkpoint_prefix, global_step=current_step)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py", line 1193, in save
    raise exc
ValueError: Parent directory of /Volumes/Transcend/Mutation/CNN-TF/runs/1581830826/checkpoints/model doesn't exist, can't save.
