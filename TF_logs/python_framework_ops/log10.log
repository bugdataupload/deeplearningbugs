WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:34:09.812581 4626910656 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:34:09.812838 4626910656 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:34:09.812945 4626910656 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:34:10.327342 4626910656 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:34:10.327574 4626910656 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:34:10.327777: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:34:10.342707: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff05e863120 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:34:10.342729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:34:10.343206 4626910656 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:34:10.347924 4626910656 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:34:10.362160 4626910656 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:34:10.371322 4626910656 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:34:10.401250 4626910656 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:34:10.409394 4626910656 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:34:10.409610 4626910656 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:34:10.420456 4626910656 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:34:10.422862 4626910656 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:34:10.455430 4626910656 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:34:10.701000 4626910656 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:34:10.701232 4626910656 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:34:10.706312 4626910656 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:34:10.723839 4626910656 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:34:10.724927 4626910656 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:34:10.747492 4626910656 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:34:10.748645 4626910656 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:34:10.762873 4626910656 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:34:10.764101 4626910656 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:34:10.778659 4626910656 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:34:10.779906 4626910656 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:34:10.802307 4626910656 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:34:10.803407 4626910656 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:34:10.817620 4626910656 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:34:10.818669 4626910656 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:34:10.836616 4626910656 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:34:10.838543 4626910656 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:34:10.856965 4626910656 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:34:10.858036 4626910656 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:34:10.872581 4626910656 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:34:10.873661 4626910656 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:34:10.877129 4626910656 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:34:11.201090 4626910656 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:34:11.201277 4626910656 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:34:11.298027 4626910656 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:34:11.850920 4626910656 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:35:35.094064 4626910656 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450

2020-02-08T02:34:11.850501: step 1, loss 2.71369, acc 0.46875
2020-02-08T02:34:11.984029: step 2, loss 1.86044, acc 0.453125
2020-02-08T02:34:12.101751: step 3, loss 1.64253, acc 0.53125
2020-02-08T02:34:12.218960: step 4, loss 2.83968, acc 0.5
2020-02-08T02:34:12.335270: step 5, loss 2.14667, acc 0.453125
2020-02-08T02:34:12.454797: step 6, loss 1.85077, acc 0.5
2020-02-08T02:34:12.573651: step 7, loss 1.96204, acc 0.53125
2020-02-08T02:34:12.695430: step 8, loss 1.93522, acc 0.4375
2020-02-08T02:34:12.813519: step 9, loss 2.11011, acc 0.640625
2020-02-08T02:34:12.930253: step 10, loss 1.37014, acc 0.5625
2020-02-08T02:34:13.048424: step 11, loss 2.05531, acc 0.515625
2020-02-08T02:34:13.164754: step 12, loss 2.06746, acc 0.515625
2020-02-08T02:34:13.282805: step 13, loss 1.91622, acc 0.515625
2020-02-08T02:34:13.400946: step 14, loss 2.15329, acc 0.484375
2020-02-08T02:34:13.518338: step 15, loss 1.49287, acc 0.546875
2020-02-08T02:34:13.634761: step 16, loss 1.71736, acc 0.53125
2020-02-08T02:34:13.756673: step 17, loss 2.13938, acc 0.484375
2020-02-08T02:34:13.873218: step 18, loss 1.83013, acc 0.453125
2020-02-08T02:34:13.990674: step 19, loss 1.36336, acc 0.609375
2020-02-08T02:34:14.107919: step 20, loss 2.0774, acc 0.5625
2020-02-08T02:34:14.225425: step 21, loss 1.42657, acc 0.578125
2020-02-08T02:34:14.344560: step 22, loss 2.22778, acc 0.4375
2020-02-08T02:34:14.463625: step 23, loss 1.48779, acc 0.53125
2020-02-08T02:34:14.582888: step 24, loss 1.70264, acc 0.515625
2020-02-08T02:34:14.701066: step 25, loss 1.79549, acc 0.515625
2020-02-08T02:34:14.818546: step 26, loss 1.7991, acc 0.515625
2020-02-08T02:34:14.936381: step 27, loss 1.73621, acc 0.53125
2020-02-08T02:34:15.054348: step 28, loss 1.66372, acc 0.59375
2020-02-08T02:34:15.173008: step 29, loss 1.37042, acc 0.53125
2020-02-08T02:34:15.286161: step 30, loss 1.40903, acc 0.5
2020-02-08T02:34:15.406179: step 31, loss 1.75144, acc 0.53125
2020-02-08T02:34:15.526627: step 32, loss 1.38658, acc 0.578125
2020-02-08T02:34:15.643991: step 33, loss 1.63445, acc 0.5
2020-02-08T02:34:15.765974: step 34, loss 1.97128, acc 0.453125
2020-02-08T02:34:15.887674: step 35, loss 1.74674, acc 0.46875
2020-02-08T02:34:16.009463: step 36, loss 1.39192, acc 0.53125
2020-02-08T02:34:16.128763: step 37, loss 1.54599, acc 0.53125
2020-02-08T02:34:16.247586: step 38, loss 1.61301, acc 0.484375
2020-02-08T02:34:16.364941: step 39, loss 1.33417, acc 0.625
2020-02-08T02:34:16.482730: step 40, loss 1.70371, acc 0.546875
2020-02-08T02:34:16.597867: step 41, loss 1.21237, acc 0.625
2020-02-08T02:34:16.717170: step 42, loss 1.39466, acc 0.578125
2020-02-08T02:34:16.835848: step 43, loss 2.15695, acc 0.390625
2020-02-08T02:34:16.953700: step 44, loss 1.55746, acc 0.484375
2020-02-08T02:34:17.070769: step 45, loss 1.65695, acc 0.53125
2020-02-08T02:34:17.188215: step 46, loss 1.37436, acc 0.53125
2020-02-08T02:34:17.306589: step 47, loss 1.77471, acc 0.421875
2020-02-08T02:34:17.426148: step 48, loss 1.62892, acc 0.515625
2020-02-08T02:34:17.543938: step 49, loss 1.64748, acc 0.515625
2020-02-08T02:34:17.661747: step 50, loss 1.51097, acc 0.546875
2020-02-08T02:34:17.784225: step 51, loss 1.7599, acc 0.46875
2020-02-08T02:34:17.904820: step 52, loss 1.45867, acc 0.59375
2020-02-08T02:34:18.025960: step 53, loss 1.89041, acc 0.515625
2020-02-08T02:34:18.142500: step 54, loss 1.92239, acc 0.5
2020-02-08T02:34:18.262147: step 55, loss 1.39505, acc 0.546875
2020-02-08T02:34:18.381601: step 56, loss 1.60246, acc 0.515625
2020-02-08T02:34:18.500499: step 57, loss 1.83143, acc 0.5
2020-02-08T02:34:18.618940: step 58, loss 1.4248, acc 0.578125
2020-02-08T02:34:18.741639: step 59, loss 1.3428, acc 0.59375
2020-02-08T02:34:18.858678: step 60, loss 1.8782, acc 0.5
2020-02-08T02:34:18.976015: step 61, loss 1.51988, acc 0.515625
2020-02-08T02:34:19.096850: step 62, loss 1.29152, acc 0.5
2020-02-08T02:34:19.213736: step 63, loss 1.55112, acc 0.453125
2020-02-08T02:34:19.329471: step 64, loss 1.93349, acc 0.359375
2020-02-08T02:34:19.446464: step 65, loss 1.50477, acc 0.5
2020-02-08T02:34:19.565977: step 66, loss 1.38557, acc 0.515625
2020-02-08T02:34:19.686645: step 67, loss 1.39927, acc 0.484375
2020-02-08T02:34:19.804607: step 68, loss 1.27908, acc 0.5625
2020-02-08T02:34:19.927191: step 69, loss 1.42431, acc 0.546875
2020-02-08T02:34:20.045226: step 70, loss 1.417, acc 0.5
2020-02-08T02:34:20.162029: step 71, loss 1.14675, acc 0.671875
2020-02-08T02:34:20.283435: step 72, loss 1.33813, acc 0.5
2020-02-08T02:34:20.404632: step 73, loss 1.6643, acc 0.546875
2020-02-08T02:34:20.523097: step 74, loss 1.55355, acc 0.484375
2020-02-08T02:34:20.640867: step 75, loss 1.52831, acc 0.46875
2020-02-08T02:34:20.762841: step 76, loss 1.78172, acc 0.484375
2020-02-08T02:34:20.880093: step 77, loss 1.62354, acc 0.546875
2020-02-08T02:34:21.000201: step 78, loss 1.30111, acc 0.453125
2020-02-08T02:34:21.115730: step 79, loss 1.69058, acc 0.46875
2020-02-08T02:34:21.232184: step 80, loss 1.54316, acc 0.46875
2020-02-08T02:34:21.354419: step 81, loss 1.48481, acc 0.578125
2020-02-08T02:34:21.488627: step 82, loss 1.43398, acc 0.53125
2020-02-08T02:34:21.605113: step 83, loss 1.40832, acc 0.546875
2020-02-08T02:34:21.726440: step 84, loss 1.27574, acc 0.546875
2020-02-08T02:34:21.842831: step 85, loss 0.976942, acc 0.625
2020-02-08T02:34:21.961036: step 86, loss 1.21843, acc 0.484375
2020-02-08T02:34:22.079974: step 87, loss 1.50949, acc 0.484375
2020-02-08T02:34:22.197343: step 88, loss 1.29019, acc 0.484375
2020-02-08T02:34:22.317127: step 89, loss 1.17335, acc 0.59375
2020-02-08T02:34:22.435417: step 90, loss 1.38225, acc 0.546875
2020-02-08T02:34:22.554467: step 91, loss 1.11622, acc 0.546875
2020-02-08T02:34:22.673747: step 92, loss 1.77154, acc 0.515625
2020-02-08T02:34:22.795789: step 93, loss 1.39562, acc 0.515625
2020-02-08T02:34:22.914725: step 94, loss 1.57573, acc 0.484375
2020-02-08T02:34:23.030485: step 95, loss 1.39762, acc 0.53125
2020-02-08T02:34:23.150211: step 96, loss 1.4267, acc 0.5625
2020-02-08T02:34:23.268015: step 97, loss 1.03963, acc 0.6875
2020-02-08T02:34:23.387611: step 98, loss 1.42032, acc 0.53125
2020-02-08T02:34:23.510173: step 99, loss 1.47038, acc 0.515625
2020-02-08T02:34:23.629274: step 100, loss 1.44796, acc 0.546875

Evaluation:
2020-02-08T02:34:23.874255: step 100, loss 0.987442, acc 0.542214

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-100

2020-02-08T02:34:25.983418: step 101, loss 1.14842, acc 0.640625
2020-02-08T02:34:26.104067: step 102, loss 1.44022, acc 0.5
2020-02-08T02:34:26.222105: step 103, loss 1.06457, acc 0.65625
2020-02-08T02:34:26.339185: step 104, loss 1.5318, acc 0.5625
2020-02-08T02:34:26.458053: step 105, loss 1.50084, acc 0.40625
2020-02-08T02:34:26.573800: step 106, loss 1.46031, acc 0.515625
2020-02-08T02:34:26.691398: step 107, loss 1.33103, acc 0.5625
2020-02-08T02:34:26.810108: step 108, loss 1.15906, acc 0.625
2020-02-08T02:34:26.930827: step 109, loss 1.03045, acc 0.59375
2020-02-08T02:34:27.047361: step 110, loss 0.965396, acc 0.59375
2020-02-08T02:34:27.166025: step 111, loss 1.10532, acc 0.578125
2020-02-08T02:34:27.282454: step 112, loss 1.55073, acc 0.484375
2020-02-08T02:34:27.403950: step 113, loss 0.822657, acc 0.640625
2020-02-08T02:34:27.521828: step 114, loss 1.14959, acc 0.578125
2020-02-08T02:34:27.639187: step 115, loss 1.25467, acc 0.515625
2020-02-08T02:34:27.761707: step 116, loss 1.56167, acc 0.5625
2020-02-08T02:34:27.877493: step 117, loss 1.29299, acc 0.5625
2020-02-08T02:34:27.997987: step 118, loss 1.32414, acc 0.578125
2020-02-08T02:34:28.117077: step 119, loss 1.04594, acc 0.5625
2020-02-08T02:34:28.234193: step 120, loss 1.26584, acc 0.578125
2020-02-08T02:34:28.352033: step 121, loss 0.734586, acc 0.71875
2020-02-08T02:34:28.469418: step 122, loss 0.83115, acc 0.65625
2020-02-08T02:34:28.586227: step 123, loss 1.06218, acc 0.578125
2020-02-08T02:34:28.706283: step 124, loss 1.15548, acc 0.59375
2020-02-08T02:34:28.822283: step 125, loss 1.12621, acc 0.578125
2020-02-08T02:34:28.942320: step 126, loss 1.32366, acc 0.625
2020-02-08T02:34:29.088480: step 127, loss 1.24109, acc 0.546875
2020-02-08T02:34:29.207599: step 128, loss 1.14459, acc 0.640625
2020-02-08T02:34:29.326607: step 129, loss 1.37877, acc 0.484375
2020-02-08T02:34:29.444233: step 130, loss 1.12163, acc 0.546875
2020-02-08T02:34:29.563789: step 131, loss 1.42912, acc 0.59375
2020-02-08T02:34:29.679849: step 132, loss 0.834748, acc 0.640625
2020-02-08T02:34:29.801309: step 133, loss 1.02968, acc 0.640625
2020-02-08T02:34:29.919440: step 134, loss 1.05586, acc 0.578125
2020-02-08T02:34:30.037590: step 135, loss 0.974704, acc 0.59375
2020-02-08T02:34:30.155861: step 136, loss 1.27411, acc 0.46875
2020-02-08T02:34:30.272770: step 137, loss 1.22868, acc 0.546875
2020-02-08T02:34:30.391857: step 138, loss 1.63749, acc 0.453125
2020-02-08T02:34:30.510882: step 139, loss 1.44507, acc 0.59375
2020-02-08T02:34:30.626802: step 140, loss 1.50719, acc 0.53125
2020-02-08T02:34:30.753071: step 141, loss 1.16673, acc 0.5625
2020-02-08T02:34:30.870528: step 142, loss 1.08956, acc 0.578125
2020-02-08T02:34:30.987438: step 143, loss 0.781242, acc 0.671875
2020-02-08T02:34:31.104554: step 144, loss 1.15792, acc 0.5
2020-02-08T02:34:31.223061: step 145, loss 1.2879, acc 0.46875
2020-02-08T02:34:31.338120: step 146, loss 1.00222, acc 0.609375
2020-02-08T02:34:31.454920: step 147, loss 1.27787, acc 0.40625
2020-02-08T02:34:31.572962: step 148, loss 1.05683, acc 0.625
2020-02-08T02:34:31.691257: step 149, loss 0.840947, acc 0.65625
2020-02-08T02:34:31.806748: step 150, loss 1.16712, acc 0.566667
2020-02-08T02:34:31.925057: step 151, loss 0.882204, acc 0.59375
2020-02-08T02:34:32.043010: step 152, loss 0.936, acc 0.546875
2020-02-08T02:34:32.164452: step 153, loss 1.16469, acc 0.5
2020-02-08T02:34:32.282878: step 154, loss 0.975747, acc 0.515625
2020-02-08T02:34:32.401662: step 155, loss 0.936135, acc 0.65625
2020-02-08T02:34:32.520541: step 156, loss 0.659106, acc 0.640625
2020-02-08T02:34:32.636974: step 157, loss 1.11352, acc 0.5625
2020-02-08T02:34:32.760745: step 158, loss 1.01826, acc 0.59375
2020-02-08T02:34:32.880316: step 159, loss 0.949793, acc 0.703125
2020-02-08T02:34:33.001607: step 160, loss 1.2122, acc 0.4375
2020-02-08T02:34:33.122391: step 161, loss 0.909583, acc 0.609375
2020-02-08T02:34:33.241165: step 162, loss 1.16617, acc 0.53125
2020-02-08T02:34:33.355389: step 163, loss 0.915493, acc 0.59375
2020-02-08T02:34:33.472473: step 164, loss 0.91985, acc 0.578125
2020-02-08T02:34:33.587127: step 165, loss 0.970046, acc 0.609375
2020-02-08T02:34:33.707102: step 166, loss 0.997323, acc 0.546875
2020-02-08T02:34:33.826831: step 167, loss 0.870218, acc 0.578125
2020-02-08T02:34:33.945343: step 168, loss 0.871237, acc 0.640625
2020-02-08T02:34:34.065223: step 169, loss 1.01016, acc 0.625
2020-02-08T02:34:34.182773: step 170, loss 0.84074, acc 0.65625
2020-02-08T02:34:34.300946: step 171, loss 0.649372, acc 0.671875
2020-02-08T02:34:34.420444: step 172, loss 0.984619, acc 0.5625
2020-02-08T02:34:34.540692: step 173, loss 1.21009, acc 0.53125
2020-02-08T02:34:34.658393: step 174, loss 0.953611, acc 0.578125
2020-02-08T02:34:34.780603: step 175, loss 0.727523, acc 0.71875
2020-02-08T02:34:34.897170: step 176, loss 0.771862, acc 0.59375
2020-02-08T02:34:35.013615: step 177, loss 1.08921, acc 0.484375
2020-02-08T02:34:35.129788: step 178, loss 0.709936, acc 0.71875
2020-02-08T02:34:35.249084: step 179, loss 1.05125, acc 0.53125
2020-02-08T02:34:35.366477: step 180, loss 1.09009, acc 0.5625
2020-02-08T02:34:35.483108: step 181, loss 0.843208, acc 0.609375
2020-02-08T02:34:35.605019: step 182, loss 0.588212, acc 0.734375
2020-02-08T02:34:35.724525: step 183, loss 0.908168, acc 0.578125
2020-02-08T02:34:35.841221: step 184, loss 0.934778, acc 0.609375
2020-02-08T02:34:35.958103: step 185, loss 0.708197, acc 0.609375
2020-02-08T02:34:36.075174: step 186, loss 0.877968, acc 0.578125
2020-02-08T02:34:36.193041: step 187, loss 0.884198, acc 0.609375
2020-02-08T02:34:36.312254: step 188, loss 0.951327, acc 0.5
2020-02-08T02:34:36.429111: step 189, loss 0.846417, acc 0.640625
2020-02-08T02:34:36.545046: step 190, loss 0.637835, acc 0.703125
2020-02-08T02:34:36.660673: step 191, loss 0.764578, acc 0.640625
2020-02-08T02:34:36.784146: step 192, loss 0.888614, acc 0.59375
2020-02-08T02:34:36.901124: step 193, loss 0.947453, acc 0.640625
2020-02-08T02:34:37.019184: step 194, loss 0.811913, acc 0.671875
2020-02-08T02:34:37.136954: step 195, loss 0.908351, acc 0.609375
2020-02-08T02:34:37.254051: step 196, loss 0.920603, acc 0.578125
2020-02-08T02:34:37.374259: step 197, loss 1.08661, acc 0.5625
2020-02-08T02:34:37.493257: step 198, loss 0.853881, acc 0.5625
2020-02-08T02:34:37.610548: step 199, loss 0.76582, acc 0.65625
2020-02-08T02:34:37.729561: step 200, loss 1.2856, acc 0.4375

Evaluation:
2020-02-08T02:34:37.923222: step 200, loss 0.663939, acc 0.615385

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-200

2020-02-08T02:34:40.111962: step 201, loss 0.873194, acc 0.65625
2020-02-08T02:34:40.229276: step 202, loss 0.712994, acc 0.703125
2020-02-08T02:34:40.348223: step 203, loss 1.1194, acc 0.546875
2020-02-08T02:34:40.467919: step 204, loss 0.913872, acc 0.640625
2020-02-08T02:34:40.585641: step 205, loss 1.18226, acc 0.46875
2020-02-08T02:34:40.706542: step 206, loss 0.869333, acc 0.65625
2020-02-08T02:34:40.823402: step 207, loss 1.11309, acc 0.53125
2020-02-08T02:34:40.940769: step 208, loss 0.994411, acc 0.5625
2020-02-08T02:34:41.056550: step 209, loss 0.753874, acc 0.625
2020-02-08T02:34:41.174814: step 210, loss 0.787264, acc 0.59375
2020-02-08T02:34:41.294365: step 211, loss 1.0788, acc 0.5625
2020-02-08T02:34:41.411978: step 212, loss 0.954492, acc 0.625
2020-02-08T02:34:41.529491: step 213, loss 0.646983, acc 0.6875
2020-02-08T02:34:41.645620: step 214, loss 1.10486, acc 0.515625
2020-02-08T02:34:41.767050: step 215, loss 0.819711, acc 0.6875
2020-02-08T02:34:41.884279: step 216, loss 0.928142, acc 0.625
2020-02-08T02:34:42.003888: step 217, loss 0.91475, acc 0.515625
2020-02-08T02:34:42.121044: step 218, loss 0.898094, acc 0.625
2020-02-08T02:34:42.238540: step 219, loss 0.841764, acc 0.625
2020-02-08T02:34:42.354800: step 220, loss 0.722104, acc 0.609375
2020-02-08T02:34:42.472906: step 221, loss 0.670202, acc 0.671875
2020-02-08T02:34:42.590855: step 222, loss 0.624045, acc 0.75
2020-02-08T02:34:42.710136: step 223, loss 0.854498, acc 0.5625
2020-02-08T02:34:42.826575: step 224, loss 0.978941, acc 0.5
2020-02-08T02:34:42.943205: step 225, loss 0.863467, acc 0.65625
2020-02-08T02:34:43.059431: step 226, loss 0.886901, acc 0.5625
2020-02-08T02:34:43.175223: step 227, loss 0.841874, acc 0.640625
2020-02-08T02:34:43.295114: step 228, loss 0.836474, acc 0.609375
2020-02-08T02:34:43.414295: step 229, loss 0.732195, acc 0.59375
2020-02-08T02:34:43.530017: step 230, loss 0.681497, acc 0.703125
2020-02-08T02:34:43.650337: step 231, loss 0.786037, acc 0.515625
2020-02-08T02:34:43.774221: step 232, loss 0.778084, acc 0.59375
2020-02-08T02:34:43.892413: step 233, loss 0.777471, acc 0.578125
2020-02-08T02:34:44.013867: step 234, loss 0.876931, acc 0.515625
2020-02-08T02:34:44.132537: step 235, loss 0.643637, acc 0.6875
2020-02-08T02:34:44.251378: step 236, loss 0.894613, acc 0.5625
2020-02-08T02:34:44.371407: step 237, loss 0.920695, acc 0.53125
2020-02-08T02:34:44.490179: step 238, loss 0.868773, acc 0.59375
2020-02-08T02:34:44.609051: step 239, loss 0.694977, acc 0.640625
2020-02-08T02:34:44.726616: step 240, loss 0.895932, acc 0.609375
2020-02-08T02:34:44.845442: step 241, loss 0.762459, acc 0.609375
2020-02-08T02:34:44.967074: step 242, loss 0.868904, acc 0.609375
2020-02-08T02:34:45.085083: step 243, loss 0.877402, acc 0.546875
2020-02-08T02:34:45.203526: step 244, loss 1.03772, acc 0.515625
2020-02-08T02:34:45.321315: step 245, loss 0.97546, acc 0.5625
2020-02-08T02:34:45.440224: step 246, loss 1.02643, acc 0.515625
2020-02-08T02:34:45.560816: step 247, loss 0.691816, acc 0.703125
2020-02-08T02:34:45.677519: step 248, loss 1.04815, acc 0.578125
2020-02-08T02:34:45.799404: step 249, loss 0.887052, acc 0.515625
2020-02-08T02:34:45.920200: step 250, loss 0.86841, acc 0.625
2020-02-08T02:34:46.037601: step 251, loss 0.794341, acc 0.578125
2020-02-08T02:34:46.152356: step 252, loss 0.726158, acc 0.609375
2020-02-08T02:34:46.271934: step 253, loss 0.781444, acc 0.609375
2020-02-08T02:34:46.391007: step 254, loss 0.880133, acc 0.53125
2020-02-08T02:34:46.509464: step 255, loss 0.749708, acc 0.65625
2020-02-08T02:34:46.627542: step 256, loss 0.764474, acc 0.59375
2020-02-08T02:34:46.750973: step 257, loss 0.759949, acc 0.609375
2020-02-08T02:34:46.868820: step 258, loss 0.813406, acc 0.578125
2020-02-08T02:34:46.985655: step 259, loss 0.802917, acc 0.578125
2020-02-08T02:34:47.107981: step 260, loss 0.955054, acc 0.609375
2020-02-08T02:34:47.225808: step 261, loss 0.828227, acc 0.578125
2020-02-08T02:34:47.343860: step 262, loss 0.767572, acc 0.59375
2020-02-08T02:34:47.461255: step 263, loss 0.772579, acc 0.6875
2020-02-08T02:34:47.578845: step 264, loss 0.721005, acc 0.671875
2020-02-08T02:34:47.699874: step 265, loss 0.805819, acc 0.609375
2020-02-08T02:34:47.815545: step 266, loss 0.682146, acc 0.65625
2020-02-08T02:34:47.934631: step 267, loss 0.973188, acc 0.40625
2020-02-08T02:34:48.056423: step 268, loss 0.862633, acc 0.625
2020-02-08T02:34:48.174112: step 269, loss 0.630129, acc 0.6875
2020-02-08T02:34:48.291897: step 270, loss 0.611061, acc 0.703125
2020-02-08T02:34:48.410680: step 271, loss 0.7304, acc 0.625
2020-02-08T02:34:48.528633: step 272, loss 0.79718, acc 0.546875
2020-02-08T02:34:48.645987: step 273, loss 0.991429, acc 0.53125
2020-02-08T02:34:48.771079: step 274, loss 0.618518, acc 0.640625
2020-02-08T02:34:48.889161: step 275, loss 0.785526, acc 0.625
2020-02-08T02:34:49.006656: step 276, loss 0.634173, acc 0.671875
2020-02-08T02:34:49.123204: step 277, loss 0.703292, acc 0.671875
2020-02-08T02:34:49.241881: step 278, loss 0.750306, acc 0.59375
2020-02-08T02:34:49.367350: step 279, loss 0.934934, acc 0.5
2020-02-08T02:34:49.481911: step 280, loss 0.837793, acc 0.5
2020-02-08T02:34:49.600721: step 281, loss 0.704351, acc 0.625
2020-02-08T02:34:49.719782: step 282, loss 1.00539, acc 0.53125
2020-02-08T02:34:49.834677: step 283, loss 0.800785, acc 0.5625
2020-02-08T02:34:49.955038: step 284, loss 0.716613, acc 0.625
2020-02-08T02:34:50.073938: step 285, loss 0.553004, acc 0.765625
2020-02-08T02:34:50.191316: step 286, loss 0.697314, acc 0.6875
2020-02-08T02:34:50.310436: step 287, loss 0.530954, acc 0.703125
2020-02-08T02:34:50.427283: step 288, loss 0.908526, acc 0.609375
2020-02-08T02:34:50.547875: step 289, loss 0.819929, acc 0.671875
2020-02-08T02:34:50.667458: step 290, loss 0.792982, acc 0.578125
2020-02-08T02:34:50.790414: step 291, loss 0.692917, acc 0.609375
2020-02-08T02:34:50.914706: step 292, loss 0.831067, acc 0.625
2020-02-08T02:34:51.029022: step 293, loss 0.697873, acc 0.625
2020-02-08T02:34:51.152032: step 294, loss 0.651041, acc 0.6875
2020-02-08T02:34:51.265926: step 295, loss 0.746794, acc 0.625
2020-02-08T02:34:51.534623: step 296, loss 0.797336, acc 0.5625
2020-02-08T02:34:51.657112: step 297, loss 0.809702, acc 0.5625
2020-02-08T02:34:51.776783: step 298, loss 0.691109, acc 0.640625
2020-02-08T02:34:51.894154: step 299, loss 0.86672, acc 0.546875
2020-02-08T02:34:52.012580: step 300, loss 0.774293, acc 0.55

Evaluation:
2020-02-08T02:34:52.203664: step 300, loss 0.63772, acc 0.641651

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-300

2020-02-08T02:34:53.694366: step 301, loss 0.610376, acc 0.640625
2020-02-08T02:34:53.814161: step 302, loss 0.650341, acc 0.71875
2020-02-08T02:34:53.931322: step 303, loss 0.594979, acc 0.65625
2020-02-08T02:34:54.051467: step 304, loss 0.618781, acc 0.671875
2020-02-08T02:34:54.171412: step 305, loss 0.795739, acc 0.609375
2020-02-08T02:34:54.290372: step 306, loss 0.68746, acc 0.640625
2020-02-08T02:34:54.409615: step 307, loss 0.647176, acc 0.65625
2020-02-08T02:34:54.528295: step 308, loss 0.68173, acc 0.640625
2020-02-08T02:34:54.647633: step 309, loss 0.549545, acc 0.71875
2020-02-08T02:34:54.772275: step 310, loss 0.768484, acc 0.671875
2020-02-08T02:34:54.891023: step 311, loss 0.791322, acc 0.640625
2020-02-08T02:34:55.010550: step 312, loss 0.698869, acc 0.609375
2020-02-08T02:34:55.132403: step 313, loss 0.622976, acc 0.71875
2020-02-08T02:34:55.253409: step 314, loss 0.839924, acc 0.59375
2020-02-08T02:34:55.372183: step 315, loss 0.720273, acc 0.6875
2020-02-08T02:34:55.490781: step 316, loss 0.644244, acc 0.671875
2020-02-08T02:34:55.611656: step 317, loss 0.532491, acc 0.75
2020-02-08T02:34:55.730557: step 318, loss 0.616535, acc 0.609375
2020-02-08T02:34:55.847766: step 319, loss 0.63115, acc 0.65625
2020-02-08T02:34:55.965434: step 320, loss 0.643307, acc 0.609375
2020-02-08T02:34:56.081779: step 321, loss 0.603899, acc 0.703125
2020-02-08T02:34:56.200721: step 322, loss 0.743, acc 0.578125
2020-02-08T02:34:56.318814: step 323, loss 0.573928, acc 0.734375
2020-02-08T02:34:56.434274: step 324, loss 0.718091, acc 0.640625
2020-02-08T02:34:56.552327: step 325, loss 0.661428, acc 0.71875
2020-02-08T02:34:56.671128: step 326, loss 0.609889, acc 0.625
2020-02-08T02:34:56.796789: step 327, loss 0.479364, acc 0.75
2020-02-08T02:34:56.917338: step 328, loss 0.735043, acc 0.6875
2020-02-08T02:34:57.032523: step 329, loss 0.662231, acc 0.6875
2020-02-08T02:34:57.148878: step 330, loss 0.539309, acc 0.734375
2020-02-08T02:34:57.268825: step 331, loss 0.618992, acc 0.734375
2020-02-08T02:34:57.385642: step 332, loss 0.943972, acc 0.5
2020-02-08T02:34:57.501628: step 333, loss 0.624814, acc 0.71875
2020-02-08T02:34:57.622663: step 334, loss 0.502917, acc 0.71875
2020-02-08T02:34:57.747128: step 335, loss 0.683749, acc 0.625
2020-02-08T02:34:57.865786: step 336, loss 0.68418, acc 0.640625
2020-02-08T02:34:57.983803: step 337, loss 0.565016, acc 0.703125
2020-02-08T02:34:58.102266: step 338, loss 0.578795, acc 0.625
2020-02-08T02:34:58.219898: step 339, loss 0.719229, acc 0.640625
2020-02-08T02:34:58.335192: step 340, loss 0.700693, acc 0.6875
2020-02-08T02:34:58.453696: step 341, loss 0.468563, acc 0.765625
2020-02-08T02:34:58.574304: step 342, loss 0.608178, acc 0.671875
2020-02-08T02:34:58.696159: step 343, loss 0.659285, acc 0.609375
2020-02-08T02:34:58.815856: step 344, loss 0.58484, acc 0.734375
2020-02-08T02:34:58.932653: step 345, loss 0.61895, acc 0.625
2020-02-08T02:34:59.053672: step 346, loss 0.535504, acc 0.71875
2020-02-08T02:34:59.176769: step 347, loss 0.535291, acc 0.71875
2020-02-08T02:34:59.297905: step 348, loss 0.655864, acc 0.578125
2020-02-08T02:34:59.416033: step 349, loss 0.619976, acc 0.6875
2020-02-08T02:34:59.533507: step 350, loss 0.658374, acc 0.640625
2020-02-08T02:34:59.653065: step 351, loss 0.585237, acc 0.734375
2020-02-08T02:34:59.776370: step 352, loss 0.540118, acc 0.78125
2020-02-08T02:34:59.898116: step 353, loss 0.676307, acc 0.625
2020-02-08T02:35:00.018104: step 354, loss 0.643355, acc 0.703125
2020-02-08T02:35:00.133145: step 355, loss 0.644916, acc 0.734375
2020-02-08T02:35:00.250372: step 356, loss 0.639043, acc 0.640625
2020-02-08T02:35:00.366764: step 357, loss 0.562991, acc 0.765625
2020-02-08T02:35:00.485444: step 358, loss 0.789182, acc 0.609375
2020-02-08T02:35:00.605422: step 359, loss 0.701969, acc 0.59375
2020-02-08T02:35:00.723235: step 360, loss 0.538796, acc 0.71875
2020-02-08T02:35:00.839510: step 361, loss 0.749199, acc 0.578125
2020-02-08T02:35:00.957547: step 362, loss 0.631166, acc 0.65625
2020-02-08T02:35:01.080322: step 363, loss 0.63683, acc 0.625
2020-02-08T02:35:01.195075: step 364, loss 0.477346, acc 0.734375
2020-02-08T02:35:01.315688: step 365, loss 0.588261, acc 0.703125
2020-02-08T02:35:01.432988: step 366, loss 0.64048, acc 0.609375
2020-02-08T02:35:01.557009: step 367, loss 0.576179, acc 0.796875
2020-02-08T02:35:01.674067: step 368, loss 0.548535, acc 0.625
2020-02-08T02:35:01.802847: step 369, loss 0.694185, acc 0.625
2020-02-08T02:35:01.918869: step 370, loss 0.492306, acc 0.71875
2020-02-08T02:35:02.035632: step 371, loss 0.451555, acc 0.796875
2020-02-08T02:35:02.155530: step 372, loss 0.550912, acc 0.703125
2020-02-08T02:35:02.271505: step 373, loss 0.686407, acc 0.640625
2020-02-08T02:35:02.390996: step 374, loss 0.558083, acc 0.71875
2020-02-08T02:35:02.511553: step 375, loss 0.674294, acc 0.703125
2020-02-08T02:35:02.628364: step 376, loss 0.618189, acc 0.703125
2020-02-08T02:35:02.750666: step 377, loss 0.519373, acc 0.75
2020-02-08T02:35:02.870756: step 378, loss 0.668648, acc 0.640625
2020-02-08T02:35:02.989231: step 379, loss 0.715228, acc 0.671875
2020-02-08T02:35:03.109678: step 380, loss 0.57319, acc 0.734375
2020-02-08T02:35:03.225263: step 381, loss 0.804636, acc 0.578125
2020-02-08T02:35:03.344771: step 382, loss 0.747249, acc 0.640625
2020-02-08T02:35:03.465721: step 383, loss 0.574283, acc 0.703125
2020-02-08T02:35:03.583855: step 384, loss 0.662963, acc 0.59375
2020-02-08T02:35:03.709720: step 385, loss 0.741529, acc 0.59375
2020-02-08T02:35:03.825738: step 386, loss 0.563241, acc 0.71875
2020-02-08T02:35:03.944249: step 387, loss 0.616049, acc 0.625
2020-02-08T02:35:04.063444: step 388, loss 0.705698, acc 0.609375
2020-02-08T02:35:04.179689: step 389, loss 0.607449, acc 0.671875
2020-02-08T02:35:04.296918: step 390, loss 0.671551, acc 0.59375
2020-02-08T02:35:04.417523: step 391, loss 0.743261, acc 0.578125
2020-02-08T02:35:04.530617: step 392, loss 0.482702, acc 0.78125
2020-02-08T02:35:04.647456: step 393, loss 0.668947, acc 0.609375
2020-02-08T02:35:04.768833: step 394, loss 0.642066, acc 0.671875
2020-02-08T02:35:04.888134: step 395, loss 0.726929, acc 0.578125
2020-02-08T02:35:05.005562: step 396, loss 0.682616, acc 0.703125
2020-02-08T02:35:05.124419: step 397, loss 0.638526, acc 0.625
2020-02-08T02:35:05.246045: step 398, loss 0.687373, acc 0.5625
2020-02-08T02:35:05.366239: step 399, loss 0.415306, acc 0.828125
2020-02-08T02:35:05.482262: step 400, loss 0.756531, acc 0.625

Evaluation:
2020-02-08T02:35:05.676030: step 400, loss 0.668118, acc 0.598499

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-400

2020-02-08T02:35:07.183189: step 401, loss 0.669227, acc 0.65625
2020-02-08T02:35:07.299994: step 402, loss 0.639635, acc 0.6875
2020-02-08T02:35:07.419497: step 403, loss 0.710534, acc 0.625
2020-02-08T02:35:07.539205: step 404, loss 0.541642, acc 0.75
2020-02-08T02:35:07.659050: step 405, loss 0.653253, acc 0.609375
2020-02-08T02:35:07.778608: step 406, loss 0.625721, acc 0.671875
2020-02-08T02:35:07.896203: step 407, loss 0.774815, acc 0.625
2020-02-08T02:35:08.017176: step 408, loss 0.701075, acc 0.671875
2020-02-08T02:35:08.136762: step 409, loss 0.694669, acc 0.59375
2020-02-08T02:35:08.253997: step 410, loss 0.793918, acc 0.609375
2020-02-08T02:35:08.371684: step 411, loss 0.651561, acc 0.671875
2020-02-08T02:35:08.489491: step 412, loss 0.619731, acc 0.625
2020-02-08T02:35:08.605797: step 413, loss 0.736213, acc 0.65625
2020-02-08T02:35:08.723708: step 414, loss 0.577844, acc 0.75
2020-02-08T02:35:08.842630: step 415, loss 0.579185, acc 0.71875
2020-02-08T02:35:08.960738: step 416, loss 0.780031, acc 0.609375
2020-02-08T02:35:09.077046: step 417, loss 0.676083, acc 0.703125
2020-02-08T02:35:09.197073: step 418, loss 0.550498, acc 0.71875
2020-02-08T02:35:09.315981: step 419, loss 0.574317, acc 0.6875
2020-02-08T02:35:09.432987: step 420, loss 0.716482, acc 0.578125
2020-02-08T02:35:09.554431: step 421, loss 0.415106, acc 0.828125
2020-02-08T02:35:09.670003: step 422, loss 0.591364, acc 0.65625
2020-02-08T02:35:09.791178: step 423, loss 0.655221, acc 0.640625
2020-02-08T02:35:09.911295: step 424, loss 0.603119, acc 0.734375
2020-02-08T02:35:10.027399: step 425, loss 0.6853, acc 0.640625
2020-02-08T02:35:10.148817: step 426, loss 0.61458, acc 0.65625
2020-02-08T02:35:10.268932: step 427, loss 0.561906, acc 0.71875
2020-02-08T02:35:10.386431: step 428, loss 0.549418, acc 0.71875
2020-02-08T02:35:10.505039: step 429, loss 0.679917, acc 0.625
2020-02-08T02:35:10.622521: step 430, loss 0.634016, acc 0.671875
2020-02-08T02:35:10.746279: step 431, loss 0.629341, acc 0.609375
2020-02-08T02:35:10.865040: step 432, loss 0.598191, acc 0.65625
2020-02-08T02:35:10.981052: step 433, loss 0.600645, acc 0.703125
2020-02-08T02:35:11.100352: step 434, loss 0.665223, acc 0.71875
2020-02-08T02:35:11.218281: step 435, loss 0.461219, acc 0.765625
2020-02-08T02:35:11.335243: step 436, loss 0.485192, acc 0.765625
2020-02-08T02:35:11.452963: step 437, loss 0.57568, acc 0.75
2020-02-08T02:35:11.567966: step 438, loss 0.632931, acc 0.625
2020-02-08T02:35:11.683289: step 439, loss 0.617057, acc 0.640625
2020-02-08T02:35:11.807232: step 440, loss 0.638372, acc 0.640625
2020-02-08T02:35:11.922420: step 441, loss 0.695978, acc 0.59375
2020-02-08T02:35:12.042967: step 442, loss 0.648685, acc 0.703125
2020-02-08T02:35:12.160126: step 443, loss 0.681659, acc 0.6875
2020-02-08T02:35:12.275912: step 444, loss 0.608483, acc 0.796875
2020-02-08T02:35:12.394729: step 445, loss 0.519943, acc 0.71875
2020-02-08T02:35:12.513223: step 446, loss 0.5773, acc 0.6875
2020-02-08T02:35:12.630833: step 447, loss 0.732717, acc 0.5625
2020-02-08T02:35:12.754410: step 448, loss 0.589237, acc 0.71875
2020-02-08T02:35:12.870860: step 449, loss 0.665931, acc 0.671875
2020-02-08T02:35:12.984891: step 450, loss 0.645441, acc 0.633333
2020-02-08T02:35:13.105454: step 451, loss 0.707519, acc 0.625
2020-02-08T02:35:13.220040: step 452, loss 0.580904, acc 0.734375
2020-02-08T02:35:13.338745: step 453, loss 0.682846, acc 0.640625
2020-02-08T02:35:13.457309: step 454, loss 0.463487, acc 0.796875
2020-02-08T02:35:13.574601: step 455, loss 0.571763, acc 0.71875
2020-02-08T02:35:13.703242: step 456, loss 0.643374, acc 0.65625
2020-02-08T02:35:13.820699: step 457, loss 0.679259, acc 0.609375
2020-02-08T02:35:13.938735: step 458, loss 0.623915, acc 0.671875
2020-02-08T02:35:14.058035: step 459, loss 0.552911, acc 0.734375
2020-02-08T02:35:14.176125: step 460, loss 0.572751, acc 0.765625
2020-02-08T02:35:14.294768: step 461, loss 0.481807, acc 0.859375
2020-02-08T02:35:14.415818: step 462, loss 0.696615, acc 0.6875
2020-02-08T02:35:14.534253: step 463, loss 0.494495, acc 0.765625
2020-02-08T02:35:14.653519: step 464, loss 0.493733, acc 0.8125
2020-02-08T02:35:14.773551: step 465, loss 0.594135, acc 0.65625
2020-02-08T02:35:14.893955: step 466, loss 0.573753, acc 0.703125
2020-02-08T02:35:15.013403: step 467, loss 0.601491, acc 0.6875
2020-02-08T02:35:15.128778: step 468, loss 0.556984, acc 0.703125
2020-02-08T02:35:15.248270: step 469, loss 0.538145, acc 0.703125
2020-02-08T02:35:15.363656: step 470, loss 0.585019, acc 0.6875
2020-02-08T02:35:15.478381: step 471, loss 0.444142, acc 0.75
2020-02-08T02:35:15.595053: step 472, loss 0.56988, acc 0.6875
2020-02-08T02:35:15.716205: step 473, loss 0.547136, acc 0.71875
2020-02-08T02:35:15.831993: step 474, loss 0.586957, acc 0.671875
2020-02-08T02:35:15.952480: step 475, loss 0.523158, acc 0.765625
2020-02-08T02:35:16.070756: step 476, loss 0.674749, acc 0.5625
2020-02-08T02:35:16.189319: step 477, loss 0.52145, acc 0.75
2020-02-08T02:35:16.309571: step 478, loss 0.422131, acc 0.859375
2020-02-08T02:35:16.424859: step 479, loss 0.488358, acc 0.765625
2020-02-08T02:35:16.539975: step 480, loss 0.606629, acc 0.671875
2020-02-08T02:35:16.657777: step 481, loss 0.511311, acc 0.765625
2020-02-08T02:35:16.778583: step 482, loss 0.620944, acc 0.625
2020-02-08T02:35:16.896922: step 483, loss 0.55176, acc 0.75
2020-02-08T02:35:17.017554: step 484, loss 0.656211, acc 0.703125
2020-02-08T02:35:17.135600: step 485, loss 0.615889, acc 0.703125
2020-02-08T02:35:17.253333: step 486, loss 0.669036, acc 0.6875
2020-02-08T02:35:17.373925: step 487, loss 0.575213, acc 0.703125
2020-02-08T02:35:17.489402: step 488, loss 0.543598, acc 0.765625
2020-02-08T02:35:17.606903: step 489, loss 0.585009, acc 0.71875
2020-02-08T02:35:17.727075: step 490, loss 0.662741, acc 0.640625
2020-02-08T02:35:17.849599: step 491, loss 0.508181, acc 0.71875
2020-02-08T02:35:17.970040: step 492, loss 0.486785, acc 0.765625
2020-02-08T02:35:18.085316: step 493, loss 0.623493, acc 0.671875
2020-02-08T02:35:18.204040: step 494, loss 0.61321, acc 0.609375
2020-02-08T02:35:18.323266: step 495, loss 0.491579, acc 0.734375
2020-02-08T02:35:18.444327: step 496, loss 0.573138, acc 0.734375
2020-02-08T02:35:18.561281: step 497, loss 0.54035, acc 0.734375
2020-02-08T02:35:18.678909: step 498, loss 0.580895, acc 0.734375
2020-02-08T02:35:18.802911: step 499, loss 0.573865, acc 0.703125
2020-02-08T02:35:18.920070: step 500, loss 0.633043, acc 0.65625

Evaluation:
2020-02-08T02:35:19.109246: step 500, loss 0.622778, acc 0.667917

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-500

2020-02-08T02:35:21.828752: step 501, loss 0.502274, acc 0.75
2020-02-08T02:35:21.990918: step 502, loss 0.51794, acc 0.765625
2020-02-08T02:35:22.117323: step 503, loss 0.502265, acc 0.75
2020-02-08T02:35:22.231894: step 504, loss 0.528674, acc 0.734375
2020-02-08T02:35:22.349045: step 505, loss 0.509713, acc 0.734375
2020-02-08T02:35:22.464225: step 506, loss 0.687959, acc 0.609375
2020-02-08T02:35:22.582942: step 507, loss 0.710359, acc 0.625
2020-02-08T02:35:22.699527: step 508, loss 0.485242, acc 0.765625
2020-02-08T02:35:22.816704: step 509, loss 0.529529, acc 0.765625
2020-02-08T02:35:22.930850: step 510, loss 0.62383, acc 0.6875
2020-02-08T02:35:23.047642: step 511, loss 0.583431, acc 0.765625
2020-02-08T02:35:23.166051: step 512, loss 0.569174, acc 0.671875
2020-02-08T02:35:23.281992: step 513, loss 0.692385, acc 0.625
2020-02-08T02:35:23.400647: step 514, loss 0.673877, acc 0.578125
2020-02-08T02:35:23.518882: step 515, loss 0.553102, acc 0.65625
2020-02-08T02:35:23.636305: step 516, loss 0.602529, acc 0.671875
2020-02-08T02:35:23.758540: step 517, loss 0.511305, acc 0.75
2020-02-08T02:35:23.874822: step 518, loss 0.535154, acc 0.734375
2020-02-08T02:35:23.994193: step 519, loss 0.576316, acc 0.71875
2020-02-08T02:35:24.115456: step 520, loss 0.588729, acc 0.6875
2020-02-08T02:35:24.233448: step 521, loss 0.573632, acc 0.734375
2020-02-08T02:35:24.353141: step 522, loss 0.625117, acc 0.640625
2020-02-08T02:35:24.469215: step 523, loss 0.425862, acc 0.765625
2020-02-08T02:35:24.586350: step 524, loss 0.571943, acc 0.71875
2020-02-08T02:35:24.705747: step 525, loss 0.658064, acc 0.6875
2020-02-08T02:35:24.823435: step 526, loss 0.464405, acc 0.8125
2020-02-08T02:35:24.940904: step 527, loss 0.63479, acc 0.625
2020-02-08T02:35:25.058491: step 528, loss 0.675448, acc 0.59375
2020-02-08T02:35:25.175789: step 529, loss 0.714553, acc 0.59375
2020-02-08T02:35:25.295907: step 530, loss 0.476208, acc 0.75
2020-02-08T02:35:25.416209: step 531, loss 0.588901, acc 0.703125
2020-02-08T02:35:25.532331: step 532, loss 0.567138, acc 0.671875
2020-02-08T02:35:25.651769: step 533, loss 0.491149, acc 0.78125
2020-02-08T02:35:25.772395: step 534, loss 0.59699, acc 0.6875
2020-02-08T02:35:25.889697: step 535, loss 0.578103, acc 0.75
2020-02-08T02:35:26.010889: step 536, loss 0.639569, acc 0.65625
2020-02-08T02:35:26.126551: step 537, loss 0.530266, acc 0.734375
2020-02-08T02:35:26.244338: step 538, loss 0.503594, acc 0.796875
2020-02-08T02:35:26.362448: step 539, loss 0.504085, acc 0.75
2020-02-08T02:35:26.478100: step 540, loss 0.539782, acc 0.734375
2020-02-08T02:35:26.593928: step 541, loss 0.58817, acc 0.703125
2020-02-08T02:35:26.712435: step 542, loss 0.576984, acc 0.6875
2020-02-08T02:35:26.827752: step 543, loss 0.562838, acc 0.703125
2020-02-08T02:35:26.946792: step 544, loss 0.583372, acc 0.703125
2020-02-08T02:35:27.062372: step 545, loss 0.603777, acc 0.71875
2020-02-08T02:35:27.176850: step 546, loss 0.72855, acc 0.546875
2020-02-08T02:35:27.296676: step 547, loss 0.652508, acc 0.640625
2020-02-08T02:35:27.415362: step 548, loss 0.591777, acc 0.609375
2020-02-08T02:35:27.532720: step 549, loss 0.593448, acc 0.71875
2020-02-08T02:35:27.654272: step 550, loss 0.585335, acc 0.71875
2020-02-08T02:35:27.777619: step 551, loss 0.629454, acc 0.640625
2020-02-08T02:35:27.893726: step 552, loss 0.529914, acc 0.71875
2020-02-08T02:35:28.012502: step 553, loss 0.610094, acc 0.625
2020-02-08T02:35:28.129885: step 554, loss 0.52176, acc 0.765625
2020-02-08T02:35:28.250924: step 555, loss 0.632089, acc 0.65625
2020-02-08T02:35:28.370170: step 556, loss 0.64173, acc 0.734375
2020-02-08T02:35:28.487316: step 557, loss 0.569651, acc 0.703125
2020-02-08T02:35:28.606598: step 558, loss 0.535729, acc 0.765625
2020-02-08T02:35:28.726239: step 559, loss 0.63691, acc 0.640625
2020-02-08T02:35:28.843757: step 560, loss 0.582388, acc 0.6875
2020-02-08T02:35:28.961946: step 561, loss 0.653801, acc 0.671875
2020-02-08T02:35:29.078620: step 562, loss 0.467824, acc 0.765625
2020-02-08T02:35:29.197258: step 563, loss 0.530212, acc 0.71875
2020-02-08T02:35:29.313442: step 564, loss 0.685167, acc 0.65625
2020-02-08T02:35:29.430363: step 565, loss 0.538798, acc 0.734375
2020-02-08T02:35:29.547924: step 566, loss 0.56161, acc 0.734375
2020-02-08T02:35:29.663994: step 567, loss 0.592655, acc 0.671875
2020-02-08T02:35:29.784770: step 568, loss 0.549177, acc 0.765625
2020-02-08T02:35:29.900928: step 569, loss 0.556014, acc 0.734375
2020-02-08T02:35:30.017644: step 570, loss 0.601925, acc 0.625
2020-02-08T02:35:30.132562: step 571, loss 0.655332, acc 0.703125
2020-02-08T02:35:30.249273: step 572, loss 0.509608, acc 0.75
2020-02-08T02:35:30.368980: step 573, loss 0.505371, acc 0.796875
2020-02-08T02:35:30.486032: step 574, loss 0.625582, acc 0.671875
2020-02-08T02:35:30.601530: step 575, loss 0.521339, acc 0.75
2020-02-08T02:35:30.721357: step 576, loss 0.561531, acc 0.6875
2020-02-08T02:35:30.837419: step 577, loss 0.613542, acc 0.703125
2020-02-08T02:35:30.957862: step 578, loss 0.466247, acc 0.75
2020-02-08T02:35:31.075804: step 579, loss 0.407676, acc 0.8125
2020-02-08T02:35:31.195471: step 580, loss 0.556018, acc 0.765625
2020-02-08T02:35:31.314213: step 581, loss 0.682509, acc 0.625
2020-02-08T02:35:31.431867: step 582, loss 0.53419, acc 0.765625
2020-02-08T02:35:31.550403: step 583, loss 0.610586, acc 0.734375
2020-02-08T02:35:31.667021: step 584, loss 0.599913, acc 0.6875
2020-02-08T02:35:31.786932: step 585, loss 0.515837, acc 0.78125
2020-02-08T02:35:31.904702: step 586, loss 0.600677, acc 0.640625
2020-02-08T02:35:32.022343: step 587, loss 0.51899, acc 0.734375
2020-02-08T02:35:32.140264: step 588, loss 0.510723, acc 0.765625
2020-02-08T02:35:32.255956: step 589, loss 0.533986, acc 0.765625
2020-02-08T02:35:32.374365: step 590, loss 0.665097, acc 0.65625
2020-02-08T02:35:32.490638: step 591, loss 0.693045, acc 0.59375
2020-02-08T02:35:32.608165: step 592, loss 0.494324, acc 0.75
2020-02-08T02:35:32.725716: step 593, loss 0.580603, acc 0.703125
2020-02-08T02:35:32.838196: step 594, loss 0.63636, acc 0.65625
2020-02-08T02:35:32.958837: step 595, loss 0.549491, acc 0.734375
2020-02-08T02:35:33.077522: step 596, loss 0.652622, acc 0.671875
2020-02-08T02:35:33.196396: step 597, loss 0.636444, acc 0.71875
2020-02-08T02:35:33.311719: step 598, loss 0.582122, acc 0.703125
2020-02-08T02:35:33.427015: step 599, loss 0.560786, acc 0.71875
2020-02-08T02:35:33.540364: step 600, loss 0.552372, acc 0.683333

Evaluation:
2020-02-08T02:35:33.733499: step 600, loss 0.671017, acc 0.594747

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-600

2020-02-08T02:35:35.286807: step 601, loss 0.584244, acc 0.71875
2020-02-08T02:35:35.404984: step 602, loss 0.589216, acc 0.625
2020-02-08T02:35:35.523382: step 603, loss 0.582129, acc 0.703125
2020-02-08T02:35:35.642787: step 604, loss 0.502823, acc 0.71875
2020-02-08T02:35:35.764578: step 605, loss 0.59721, acc 0.65625
2020-02-08T02:35:35.884740: step 606, loss 0.531495, acc 0.75
2020-02-08T02:35:36.002305: step 607, loss 0.483808, acc 0.796875
2020-02-08T02:35:36.120161: step 608, loss 0.615283, acc 0.625
2020-02-08T02:35:36.239687: step 609, loss 0.521725, acc 0.78125
2020-02-08T02:35:36.359017: step 610, loss 0.394308, acc 0.875
2020-02-08T02:35:36.473291: step 611, loss 0.466818, acc 0.796875
2020-02-08T02:35:36.591955: step 612, loss 0.453379, acc 0.765625
2020-02-08T02:35:36.712041: step 613, loss 0.651141, acc 0.65625
2020-02-08T02:35:36.830987: step 614, loss 0.660058, acc 0.65625
2020-02-08T02:35:36.948294: step 615, loss 0.540265, acc 0.71875
2020-02-08T02:35:37.064271: step 616, loss 0.444751, acc 0.765625
2020-02-08T02:35:37.183507: step 617, loss 0.575239, acc 0.703125
2020-02-08T02:35:37.303414: step 618, loss 0.506453, acc 0.765625
2020-02-08T02:35:37.421415: step 619, loss 0.452912, acc 0.765625
2020-02-08T02:35:37.538661: step 620, loss 0.636328, acc 0.671875
2020-02-08T02:35:37.657258: step 621, loss 0.540942, acc 0.71875
2020-02-08T02:35:37.778206: step 622, loss 0.532142, acc 0.734375
2020-02-08T02:35:37.895793: step 623, loss 0.542786, acc 0.671875
2020-02-08T02:35:38.016051: step 624, loss 0.489786, acc 0.75
2020-02-08T02:35:38.131242: step 625, loss 0.335023, acc 0.875
2020-02-08T02:35:38.250542: step 626, loss 0.55635, acc 0.734375
2020-02-08T02:35:38.368792: step 627, loss 0.321276, acc 0.875
2020-02-08T02:35:38.484225: step 628, loss 0.476512, acc 0.78125
2020-02-08T02:35:38.602101: step 629, loss 0.541956, acc 0.75
2020-02-08T02:35:38.718330: step 630, loss 0.542064, acc 0.6875
2020-02-08T02:35:38.835415: step 631, loss 0.493042, acc 0.734375
2020-02-08T02:35:38.952828: step 632, loss 0.456568, acc 0.84375
2020-02-08T02:35:39.069769: step 633, loss 0.549615, acc 0.796875
2020-02-08T02:35:39.184238: step 634, loss 0.405386, acc 0.828125
2020-02-08T02:35:39.306127: step 635, loss 0.588865, acc 0.703125
2020-02-08T02:35:39.425649: step 636, loss 0.451892, acc 0.765625
2020-02-08T02:35:39.543247: step 637, loss 0.728772, acc 0.625
2020-02-08T02:35:39.660618: step 638, loss 0.395276, acc 0.828125
2020-02-08T02:35:39.783525: step 639, loss 0.522234, acc 0.796875
2020-02-08T02:35:39.901825: step 640, loss 0.542123, acc 0.71875
2020-02-08T02:35:40.020253: step 641, loss 0.439042, acc 0.796875
2020-02-08T02:35:40.137161: step 642, loss 0.551014, acc 0.671875
2020-02-08T02:35:40.255807: step 643, loss 0.480839, acc 0.796875
2020-02-08T02:35:40.372644: step 644, loss 0.500203, acc 0.796875
2020-02-08T02:35:40.486192: step 645, loss 0.509916, acc 0.6875
2020-02-08T02:35:40.603702: step 646, loss 0.429553, acc 0.828125
2020-02-08T02:35:40.720298: step 647, loss 0.554695, acc 0.703125
2020-02-08T02:35:40.838754: step 648, loss 0.419423, acc 0.828125
2020-02-08T02:35:40.956220: step 649, loss 0.481843, acc 0.734375
2020-02-08T02:35:41.074113: step 650, loss 0.506571, acc 0.6875
2020-02-08T02:35:41.187222: step 651, loss 0.455576, acc 0.84375
2020-02-08T02:35:41.309600: step 652, loss 0.447428, acc 0.8125
2020-02-08T02:35:41.430434: step 653, loss 0.493056, acc 0.71875
2020-02-08T02:35:41.552897: step 654, loss 0.411336, acc 0.84375
2020-02-08T02:35:41.718091: step 655, loss 0.510357, acc 0.6875
2020-02-08T02:35:41.880711: step 656, loss 0.516131, acc 0.734375
2020-02-08T02:35:42.017015: step 657, loss 0.456306, acc 0.796875
2020-02-08T02:35:42.144227: step 658, loss 0.547287, acc 0.71875
2020-02-08T02:35:42.290195: step 659, loss 0.43736, acc 0.828125
2020-02-08T02:35:42.425521: step 660, loss 0.497481, acc 0.71875
2020-02-08T02:35:42.557776: step 661, loss 0.605993, acc 0.59375
2020-02-08T02:35:42.695330: step 662, loss 0.456893, acc 0.78125
2020-02-08T02:35:42.828842: step 663, loss 0.539527, acc 0.78125
2020-02-08T02:35:42.964506: step 664, loss 0.578937, acc 0.671875
2020-02-08T02:35:43.097102: step 665, loss 0.549557, acc 0.71875
2020-02-08T02:35:43.236870: step 666, loss 0.500641, acc 0.828125
2020-02-08T02:35:43.366284: step 667, loss 0.522265, acc 0.765625
2020-02-08T02:35:43.498919: step 668, loss 0.494673, acc 0.765625
2020-02-08T02:35:43.634591: step 669, loss 0.458175, acc 0.734375
2020-02-08T02:35:43.772977: step 670, loss 0.563217, acc 0.765625
2020-02-08T02:35:43.909044: step 671, loss 0.448562, acc 0.796875
2020-02-08T02:35:44.041788: step 672, loss 0.632492, acc 0.6875
2020-02-08T02:35:44.173176: step 673, loss 0.401394, acc 0.875
2020-02-08T02:35:44.304329: step 674, loss 0.396741, acc 0.828125
2020-02-08T02:35:44.440106: step 675, loss 0.521612, acc 0.703125
2020-02-08T02:35:44.572156: step 676, loss 0.69097, acc 0.65625
2020-02-08T02:35:44.705975: step 677, loss 0.537841, acc 0.71875
2020-02-08T02:35:44.835674: step 678, loss 0.51259, acc 0.765625
2020-02-08T02:35:44.978026: step 679, loss 0.455871, acc 0.796875
2020-02-08T02:35:45.117615: step 680, loss 0.505734, acc 0.6875
2020-02-08T02:35:45.265047: step 681, loss 0.44916, acc 0.734375
2020-02-08T02:35:45.413524: step 682, loss 0.55814, acc 0.734375
2020-02-08T02:35:45.558194: step 683, loss 0.501579, acc 0.765625
2020-02-08T02:35:45.696237: step 684, loss 0.511271, acc 0.765625
2020-02-08T02:35:45.836804: step 685, loss 0.48928, acc 0.78125
2020-02-08T02:35:45.982539: step 686, loss 0.514685, acc 0.765625
2020-02-08T02:35:46.124558: step 687, loss 0.543171, acc 0.71875
2020-02-08T02:35:46.267300: step 688, loss 0.41767, acc 0.8125
2020-02-08T02:35:46.411682: step 689, loss 0.565066, acc 0.734375
2020-02-08T02:35:46.552126: step 690, loss 0.458065, acc 0.828125
2020-02-08T02:35:46.694411: step 691, loss 0.382245, acc 0.84375
2020-02-08T02:35:46.838943: step 692, loss 0.556723, acc 0.703125
2020-02-08T02:35:46.979809: step 693, loss 0.441492, acc 0.78125
2020-02-08T02:35:47.121025: step 694, loss 0.388933, acc 0.828125
2020-02-08T02:35:47.267299: step 695, loss 0.511291, acc 0.765625
2020-02-08T02:35:47.406670: step 696, loss 0.431286, acc 0.765625
2020-02-08T02:35:47.537800: step 697, loss 0.428409, acc 0.78125
2020-02-08T02:35:47.666419: step 698, loss 0.478586, acc 0.765625
2020-02-08T02:35:47.814078: step 699, loss 0.442937, acc 0.875
2020-02-08T02:35:47.938223: step 700, loss 0.519931, acc 0.75

Evaluation:
2020-02-08T02:35:48.169151: step 700, loss 0.610698, acc 0.669794

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-700

2020-02-08T02:35:50.326888: step 701, loss 0.522696, acc 0.75
2020-02-08T02:35:50.469106: step 702, loss 0.461539, acc 0.796875
2020-02-08T02:35:50.611364: step 703, loss 0.529799, acc 0.71875
2020-02-08T02:35:50.758886: step 704, loss 0.467397, acc 0.78125
2020-02-08T02:35:50.902979: step 705, loss 0.437894, acc 0.75
2020-02-08T02:35:51.047936: step 706, loss 0.503907, acc 0.796875
2020-02-08T02:35:51.191615: step 707, loss 0.547744, acc 0.734375
2020-02-08T02:35:51.329077: step 708, loss 0.532985, acc 0.75
2020-02-08T02:35:51.444719: step 709, loss 0.581495, acc 0.75
2020-02-08T02:35:51.826159: step 710, loss 0.479395, acc 0.78125
2020-02-08T02:35:51.974073: step 711, loss 0.400746, acc 0.8125
2020-02-08T02:35:52.116673: step 712, loss 0.433808, acc 0.796875
2020-02-08T02:35:52.255570: step 713, loss 0.479955, acc 0.765625
2020-02-08T02:35:52.397087: step 714, loss 0.477752, acc 0.828125
2020-02-08T02:35:52.533313: step 715, loss 0.500451, acc 0.71875
2020-02-08T02:35:52.670795: step 716, loss 0.512655, acc 0.796875
2020-02-08T02:35:52.795090: step 717, loss 0.563293, acc 0.703125
2020-02-08T02:35:52.916584: step 718, loss 0.50512, acc 0.703125
2020-02-08T02:35:53.041770: step 719, loss 0.389199, acc 0.84375
2020-02-08T02:35:53.159822: step 720, loss 0.514025, acc 0.78125
2020-02-08T02:35:53.278034: step 721, loss 0.507505, acc 0.765625
2020-02-08T02:35:53.399262: step 722, loss 0.459577, acc 0.8125
2020-02-08T02:35:53.516495: step 723, loss 0.496472, acc 0.78125
2020-02-08T02:35:53.631797: step 724, loss 0.494293, acc 0.75
2020-02-08T02:35:53.754927: step 725, loss 0.547013, acc 0.703125
2020-02-08T02:35:53.874308: step 726, loss 0.479621, acc 0.8125
2020-02-08T02:35:53.990357: step 727, loss 0.460756, acc 0.71875
2020-02-08T02:35:54.108193: step 728, loss 0.385852, acc 0.828125
2020-02-08T02:35:54.224103: step 729, loss 0.455892, acc 0.8125
2020-02-08T02:35:54.342718: step 730, loss 0.459001, acc 0.78125
2020-02-08T02:35:54.461923: step 731, loss 0.529886, acc 0.734375
2020-02-08T02:35:54.578015: step 732, loss 0.536485, acc 0.765625
2020-02-08T02:35:54.698226: step 733, loss 0.442034, acc 0.828125
2020-02-08T02:35:54.814185: step 734, loss 0.428277, acc 0.78125
2020-02-08T02:35:54.932403: step 735, loss 0.419577, acc 0.828125
2020-02-08T02:35:55.051459: step 736, loss 0.514446, acc 0.734375
2020-02-08T02:35:55.173057: step 737, loss 0.463602, acc 0.75
2020-02-08T02:35:55.295863: step 738, loss 0.422677, acc 0.796875
2020-02-08T02:35:55.415959: step 739, loss 0.570338, acc 0.71875
2020-02-08T02:35:55.530429: step 740, loss 0.482618, acc 0.765625
2020-02-08T02:35:55.648814: step 741, loss 0.636524, acc 0.671875
2020-02-08T02:35:55.771849: step 742, loss 0.537857, acc 0.828125
2020-02-08T02:35:55.888755: step 743, loss 0.480566, acc 0.78125
2020-02-08T02:35:56.005951: step 744, loss 0.594593, acc 0.65625
2020-02-08T02:35:56.124118: step 745, loss 0.519495, acc 0.734375
2020-02-08T02:35:56.244904: step 746, loss 0.482967, acc 0.765625
2020-02-08T02:35:56.363264: step 747, loss 0.495281, acc 0.75
2020-02-08T02:35:56.479827: step 748, loss 0.531847, acc 0.734375
2020-02-08T02:35:56.597549: step 749, loss 0.481277, acc 0.703125
2020-02-08T02:35:56.712080: step 750, loss 0.509388, acc 0.733333
2020-02-08T02:35:56.831935: step 751, loss 0.357777, acc 0.859375
2020-02-08T02:35:56.953173: step 752, loss 0.360677, acc 0.796875
2020-02-08T02:35:57.071633: step 753, loss 0.499303, acc 0.71875
2020-02-08T02:35:57.188520: step 754, loss 0.45526, acc 0.828125
2020-02-08T02:35:57.309249: step 755, loss 0.411315, acc 0.796875
2020-02-08T02:35:57.424750: step 756, loss 0.464759, acc 0.8125
2020-02-08T02:35:57.543561: step 757, loss 0.392539, acc 0.828125
2020-02-08T02:35:57.661995: step 758, loss 0.388543, acc 0.84375
2020-02-08T02:35:57.782839: step 759, loss 0.531634, acc 0.796875
2020-02-08T02:35:57.900059: step 760, loss 0.47734, acc 0.78125
2020-02-08T02:35:58.019379: step 761, loss 0.444302, acc 0.8125
2020-02-08T02:35:58.135353: step 762, loss 0.320886, acc 0.859375
2020-02-08T02:35:58.260162: step 763, loss 0.444019, acc 0.78125
2020-02-08T02:35:58.377444: step 764, loss 0.301011, acc 0.90625
2020-02-08T02:35:58.497093: step 765, loss 0.4123, acc 0.859375
2020-02-08T02:35:58.618226: step 766, loss 0.305458, acc 0.875
2020-02-08T02:35:58.741313: step 767, loss 0.582202, acc 0.75
2020-02-08T02:35:58.862315: step 768, loss 0.344091, acc 0.859375
2020-02-08T02:35:58.977100: step 769, loss 0.362402, acc 0.875
2020-02-08T02:35:59.097754: step 770, loss 0.584815, acc 0.71875
2020-02-08T02:35:59.216627: step 771, loss 0.343905, acc 0.859375
2020-02-08T02:35:59.333383: step 772, loss 0.390218, acc 0.875
2020-02-08T02:35:59.452719: step 773, loss 0.43605, acc 0.8125
2020-02-08T02:35:59.571595: step 774, loss 0.44434, acc 0.78125
2020-02-08T02:35:59.693722: step 775, loss 0.446925, acc 0.8125
2020-02-08T02:35:59.812963: step 776, loss 0.278853, acc 0.890625
2020-02-08T02:35:59.930398: step 777, loss 0.485167, acc 0.78125
2020-02-08T02:36:00.046818: step 778, loss 0.461955, acc 0.765625
2020-02-08T02:36:00.164179: step 779, loss 0.426607, acc 0.796875
2020-02-08T02:36:00.280985: step 780, loss 0.527471, acc 0.75
2020-02-08T02:36:00.397479: step 781, loss 0.362231, acc 0.875
2020-02-08T02:36:00.517176: step 782, loss 0.430401, acc 0.75
2020-02-08T02:36:00.632288: step 783, loss 0.473956, acc 0.796875
2020-02-08T02:36:00.756909: step 784, loss 0.416446, acc 0.796875
2020-02-08T02:36:00.873750: step 785, loss 0.432353, acc 0.828125
2020-02-08T02:36:00.992544: step 786, loss 0.45903, acc 0.765625
2020-02-08T02:36:01.111480: step 787, loss 0.458156, acc 0.859375
2020-02-08T02:36:01.229622: step 788, loss 0.483435, acc 0.75
2020-02-08T02:36:01.355286: step 789, loss 0.512748, acc 0.75
2020-02-08T02:36:01.473098: step 790, loss 0.399668, acc 0.796875
2020-02-08T02:36:01.588342: step 791, loss 0.495637, acc 0.796875
2020-02-08T02:36:01.707379: step 792, loss 0.504459, acc 0.75
2020-02-08T02:36:01.823145: step 793, loss 0.390533, acc 0.78125
2020-02-08T02:36:01.938161: step 794, loss 0.443006, acc 0.8125
2020-02-08T02:36:02.056375: step 795, loss 0.450191, acc 0.78125
2020-02-08T02:36:02.173541: step 796, loss 0.474502, acc 0.78125
2020-02-08T02:36:02.289383: step 797, loss 0.391302, acc 0.859375
2020-02-08T02:36:02.406989: step 798, loss 0.499869, acc 0.78125
2020-02-08T02:36:02.524755: step 799, loss 0.45109, acc 0.765625
2020-02-08T02:36:02.641378: step 800, loss 0.431575, acc 0.796875

Evaluation:
2020-02-08T02:36:02.836291: step 800, loss 0.606778, acc 0.684803

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-800

2020-02-08T02:36:04.637458: step 801, loss 0.373168, acc 0.78125
2020-02-08T02:36:04.759124: step 802, loss 0.564285, acc 0.703125
2020-02-08T02:36:04.875799: step 803, loss 0.51952, acc 0.734375
2020-02-08T02:36:04.991330: step 804, loss 0.357563, acc 0.875
2020-02-08T02:36:05.111056: step 805, loss 0.35291, acc 0.859375
2020-02-08T02:36:05.225757: step 806, loss 0.483239, acc 0.71875
2020-02-08T02:36:05.344751: step 807, loss 0.339139, acc 0.859375
2020-02-08T02:36:05.465254: step 808, loss 0.380522, acc 0.84375
2020-02-08T02:36:05.582340: step 809, loss 0.419964, acc 0.84375
2020-02-08T02:36:05.698952: step 810, loss 0.376006, acc 0.84375
2020-02-08T02:36:05.820102: step 811, loss 0.493706, acc 0.765625
2020-02-08T02:36:05.937375: step 812, loss 0.490736, acc 0.796875
2020-02-08T02:36:06.056676: step 813, loss 0.342623, acc 0.875
2020-02-08T02:36:06.174629: step 814, loss 0.382785, acc 0.796875
2020-02-08T02:36:06.291548: step 815, loss 0.57729, acc 0.6875
2020-02-08T02:36:06.408531: step 816, loss 0.498596, acc 0.8125
2020-02-08T02:36:06.526616: step 817, loss 0.35752, acc 0.828125
2020-02-08T02:36:06.646451: step 818, loss 0.314443, acc 0.828125
2020-02-08T02:36:06.771218: step 819, loss 0.420822, acc 0.78125
2020-02-08T02:36:06.888731: step 820, loss 0.499829, acc 0.71875
2020-02-08T02:36:07.006638: step 821, loss 0.449339, acc 0.78125
2020-02-08T02:36:07.122676: step 822, loss 0.446405, acc 0.765625
2020-02-08T02:36:07.242844: step 823, loss 0.421143, acc 0.84375
2020-02-08T02:36:07.361898: step 824, loss 0.375688, acc 0.84375
2020-02-08T02:36:07.479936: step 825, loss 0.441187, acc 0.828125
2020-02-08T02:36:07.596768: step 826, loss 0.380429, acc 0.828125
2020-02-08T02:36:07.716574: step 827, loss 0.506707, acc 0.75
2020-02-08T02:36:07.833309: step 828, loss 0.447678, acc 0.78125
2020-02-08T02:36:07.952988: step 829, loss 0.398616, acc 0.78125
2020-02-08T02:36:08.070569: step 830, loss 0.404518, acc 0.8125
2020-02-08T02:36:08.191433: step 831, loss 0.468488, acc 0.75
2020-02-08T02:36:08.313674: step 832, loss 0.468279, acc 0.734375
2020-02-08T02:36:08.430111: step 833, loss 0.502164, acc 0.703125
2020-02-08T02:36:08.547584: step 834, loss 0.569356, acc 0.765625
2020-02-08T02:36:08.668655: step 835, loss 0.514706, acc 0.71875
2020-02-08T02:36:08.790098: step 836, loss 0.309898, acc 0.859375
2020-02-08T02:36:08.912534: step 837, loss 0.369127, acc 0.875
2020-02-08T02:36:09.027015: step 838, loss 0.401603, acc 0.796875
2020-02-08T02:36:09.148097: step 839, loss 0.444858, acc 0.796875
2020-02-08T02:36:09.263177: step 840, loss 0.412241, acc 0.859375
2020-02-08T02:36:09.379484: step 841, loss 0.469741, acc 0.75
2020-02-08T02:36:09.496682: step 842, loss 0.493327, acc 0.765625
2020-02-08T02:36:09.616805: step 843, loss 0.465196, acc 0.75
2020-02-08T02:36:09.737154: step 844, loss 0.41821, acc 0.875
2020-02-08T02:36:09.858018: step 845, loss 0.437113, acc 0.796875
2020-02-08T02:36:09.975535: step 846, loss 0.399735, acc 0.8125
2020-02-08T02:36:10.091648: step 847, loss 0.354277, acc 0.890625
2020-02-08T02:36:10.208921: step 848, loss 0.374857, acc 0.859375
2020-02-08T02:36:10.325751: step 849, loss 0.540554, acc 0.75
2020-02-08T02:36:10.442969: step 850, loss 0.49648, acc 0.71875
2020-02-08T02:36:10.560162: step 851, loss 0.372262, acc 0.828125
2020-02-08T02:36:10.678246: step 852, loss 0.635432, acc 0.671875
2020-02-08T02:36:10.803055: step 853, loss 0.48383, acc 0.765625
2020-02-08T02:36:10.918640: step 854, loss 0.383751, acc 0.8125
2020-02-08T02:36:11.039269: step 855, loss 0.454041, acc 0.828125
2020-02-08T02:36:11.161457: step 856, loss 0.652802, acc 0.6875
2020-02-08T02:36:11.279239: step 857, loss 0.421728, acc 0.796875
2020-02-08T02:36:11.398907: step 858, loss 0.45633, acc 0.71875
2020-02-08T02:36:11.516787: step 859, loss 0.489452, acc 0.75
2020-02-08T02:36:11.633773: step 860, loss 0.406543, acc 0.8125
2020-02-08T02:36:11.754040: step 861, loss 0.489318, acc 0.71875
2020-02-08T02:36:11.870094: step 862, loss 0.393062, acc 0.828125
2020-02-08T02:36:11.986350: step 863, loss 0.481445, acc 0.796875
2020-02-08T02:36:12.104553: step 864, loss 0.522035, acc 0.71875
2020-02-08T02:36:12.223294: step 865, loss 0.427598, acc 0.78125
2020-02-08T02:36:12.340354: step 866, loss 0.648803, acc 0.765625
2020-02-08T02:36:12.458249: step 867, loss 0.46466, acc 0.765625
2020-02-08T02:36:12.576091: step 868, loss 0.47379, acc 0.734375
2020-02-08T02:36:12.695120: step 869, loss 0.426839, acc 0.796875
2020-02-08T02:36:12.812381: step 870, loss 0.476654, acc 0.765625
2020-02-08T02:36:12.926719: step 871, loss 0.395854, acc 0.84375
2020-02-08T02:36:13.042578: step 872, loss 0.326835, acc 0.90625
2020-02-08T02:36:13.163592: step 873, loss 0.372775, acc 0.859375
2020-02-08T02:36:13.281263: step 874, loss 0.455677, acc 0.75
2020-02-08T02:36:13.399258: step 875, loss 0.392491, acc 0.859375
2020-02-08T02:36:13.515023: step 876, loss 0.431132, acc 0.84375
2020-02-08T02:36:13.631950: step 877, loss 0.537891, acc 0.71875
2020-02-08T02:36:13.756305: step 878, loss 0.371606, acc 0.84375
2020-02-08T02:36:13.873062: step 879, loss 0.543761, acc 0.75
2020-02-08T02:36:13.991942: step 880, loss 0.384642, acc 0.8125
2020-02-08T02:36:14.110333: step 881, loss 0.434135, acc 0.8125
2020-02-08T02:36:14.227198: step 882, loss 0.455164, acc 0.8125
2020-02-08T02:36:14.344388: step 883, loss 0.54017, acc 0.6875
2020-02-08T02:36:14.465920: step 884, loss 0.362641, acc 0.875
2020-02-08T02:36:14.583233: step 885, loss 0.519397, acc 0.703125
2020-02-08T02:36:14.703698: step 886, loss 0.526365, acc 0.765625
2020-02-08T02:36:14.822895: step 887, loss 0.427333, acc 0.828125
2020-02-08T02:36:14.940921: step 888, loss 0.463522, acc 0.78125
2020-02-08T02:36:15.057815: step 889, loss 0.491386, acc 0.78125
2020-02-08T02:36:15.175996: step 890, loss 0.402618, acc 0.84375
2020-02-08T02:36:15.294891: step 891, loss 0.333657, acc 0.8125
2020-02-08T02:36:15.409827: step 892, loss 0.563472, acc 0.6875
2020-02-08T02:36:15.525480: step 893, loss 0.577381, acc 0.71875
2020-02-08T02:36:15.642683: step 894, loss 0.457063, acc 0.8125
2020-02-08T02:36:15.764766: step 895, loss 0.400388, acc 0.8125
2020-02-08T02:36:15.880593: step 896, loss 0.338493, acc 0.859375
2020-02-08T02:36:15.999937: step 897, loss 0.541228, acc 0.703125
2020-02-08T02:36:16.119058: step 898, loss 0.404258, acc 0.84375
2020-02-08T02:36:16.234829: step 899, loss 0.312355, acc 0.890625
2020-02-08T02:36:16.349376: step 900, loss 0.538457, acc 0.733333

Evaluation:
2020-02-08T02:36:16.539068: step 900, loss 0.587745, acc 0.695122

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-900

2020-02-08T02:36:19.576753: step 901, loss 0.29161, acc 0.890625
2020-02-08T02:36:19.700515: step 902, loss 0.289141, acc 0.90625
2020-02-08T02:36:19.821186: step 903, loss 0.162883, acc 0.984375
2020-02-08T02:36:19.941467: step 904, loss 0.402848, acc 0.84375
2020-02-08T02:36:20.059116: step 905, loss 0.359565, acc 0.84375
2020-02-08T02:36:20.175777: step 906, loss 0.308086, acc 0.921875
2020-02-08T02:36:20.290119: step 907, loss 0.421736, acc 0.75
2020-02-08T02:36:20.409056: step 908, loss 0.525986, acc 0.78125
2020-02-08T02:36:20.524479: step 909, loss 0.344662, acc 0.875
2020-02-08T02:36:20.643225: step 910, loss 0.391753, acc 0.84375
2020-02-08T02:36:20.765244: step 911, loss 0.406157, acc 0.78125
2020-02-08T02:36:20.879649: step 912, loss 0.434291, acc 0.765625
2020-02-08T02:36:20.999872: step 913, loss 0.365152, acc 0.84375
2020-02-08T02:36:21.121397: step 914, loss 0.457526, acc 0.796875
2020-02-08T02:36:21.577757: step 915, loss 0.37506, acc 0.734375
2020-02-08T02:36:21.708795: step 916, loss 0.385095, acc 0.75
2020-02-08T02:36:21.825975: step 917, loss 0.313598, acc 0.875
2020-02-08T02:36:21.942315: step 918, loss 0.313716, acc 0.859375
2020-02-08T02:36:22.060494: step 919, loss 0.301356, acc 0.875
2020-02-08T02:36:22.177874: step 920, loss 0.314852, acc 0.875
2020-02-08T02:36:22.294135: step 921, loss 0.364684, acc 0.859375
2020-02-08T02:36:22.413185: step 922, loss 0.38389, acc 0.8125
2020-02-08T02:36:22.527508: step 923, loss 0.29457, acc 0.890625
2020-02-08T02:36:22.644671: step 924, loss 0.218394, acc 0.9375
2020-02-08T02:36:22.768602: step 925, loss 0.355875, acc 0.859375
2020-02-08T02:36:22.886264: step 926, loss 0.340074, acc 0.84375
2020-02-08T02:36:23.001869: step 927, loss 0.380913, acc 0.828125
2020-02-08T02:36:23.119028: step 928, loss 0.265334, acc 0.859375
2020-02-08T02:36:23.236189: step 929, loss 0.274171, acc 0.9375
2020-02-08T02:36:23.353221: step 930, loss 0.317807, acc 0.859375
2020-02-08T02:36:23.473713: step 931, loss 0.421065, acc 0.78125
2020-02-08T02:36:23.592555: step 932, loss 0.429616, acc 0.78125
2020-02-08T02:36:23.714225: step 933, loss 0.362627, acc 0.828125
2020-02-08T02:36:23.829705: step 934, loss 0.376494, acc 0.796875
2020-02-08T02:36:23.945833: step 935, loss 0.307994, acc 0.875
2020-02-08T02:36:24.063331: step 936, loss 0.380738, acc 0.84375
2020-02-08T02:36:24.179303: step 937, loss 0.266198, acc 0.921875
2020-02-08T02:36:24.295156: step 938, loss 0.322977, acc 0.859375
2020-02-08T02:36:24.414688: step 939, loss 0.338643, acc 0.828125
2020-02-08T02:36:24.533478: step 940, loss 0.319407, acc 0.875
2020-02-08T02:36:24.652944: step 941, loss 0.282434, acc 0.84375
2020-02-08T02:36:24.777241: step 942, loss 0.28187, acc 0.875
2020-02-08T02:36:24.893425: step 943, loss 0.296754, acc 0.890625
2020-02-08T02:36:25.012590: step 944, loss 0.381831, acc 0.828125
2020-02-08T02:36:25.131647: step 945, loss 0.3393, acc 0.84375
2020-02-08T02:36:25.251707: step 946, loss 0.425423, acc 0.8125
2020-02-08T02:36:25.369811: step 947, loss 0.369062, acc 0.859375
2020-02-08T02:36:25.487435: step 948, loss 0.392438, acc 0.875
2020-02-08T02:36:25.607659: step 949, loss 0.299569, acc 0.921875
2020-02-08T02:36:25.724692: step 950, loss 0.376759, acc 0.8125
2020-02-08T02:36:25.842732: step 951, loss 0.341742, acc 0.859375
2020-02-08T02:36:25.959591: step 952, loss 0.344593, acc 0.859375
2020-02-08T02:36:26.076717: step 953, loss 0.493393, acc 0.765625
2020-02-08T02:36:26.196622: step 954, loss 0.33733, acc 0.859375
2020-02-08T02:36:26.313064: step 955, loss 0.335627, acc 0.859375
2020-02-08T02:36:26.429122: step 956, loss 0.38115, acc 0.828125
2020-02-08T02:36:26.544210: step 957, loss 0.3034, acc 0.859375
2020-02-08T02:36:26.666609: step 958, loss 0.287504, acc 0.875
2020-02-08T02:36:26.788371: step 959, loss 0.4777, acc 0.8125
2020-02-08T02:36:26.908689: step 960, loss 0.364648, acc 0.8125
2020-02-08T02:36:27.028064: step 961, loss 0.28725, acc 0.84375
2020-02-08T02:36:27.147012: step 962, loss 0.387031, acc 0.765625
2020-02-08T02:36:27.263569: step 963, loss 0.430627, acc 0.8125
2020-02-08T02:36:27.382333: step 964, loss 0.299798, acc 0.859375
2020-02-08T02:36:27.498312: step 965, loss 0.354482, acc 0.796875
2020-02-08T02:36:27.617921: step 966, loss 0.419636, acc 0.828125
2020-02-08T02:36:27.739218: step 967, loss 0.245005, acc 0.921875
2020-02-08T02:36:27.854857: step 968, loss 0.477019, acc 0.75
2020-02-08T02:36:27.970327: step 969, loss 0.353933, acc 0.84375
2020-02-08T02:36:28.087212: step 970, loss 0.368576, acc 0.828125
2020-02-08T02:36:28.203237: step 971, loss 0.287267, acc 0.859375
2020-02-08T02:36:28.320946: step 972, loss 0.358626, acc 0.859375
2020-02-08T02:36:28.438987: step 973, loss 0.3463, acc 0.796875
2020-02-08T02:36:28.557726: step 974, loss 0.411224, acc 0.796875
2020-02-08T02:36:28.677119: step 975, loss 0.304628, acc 0.859375
2020-02-08T02:36:28.799794: step 976, loss 0.412509, acc 0.828125
2020-02-08T02:36:28.918431: step 977, loss 0.389061, acc 0.828125
2020-02-08T02:36:29.037066: step 978, loss 0.421026, acc 0.859375
2020-02-08T02:36:29.155098: step 979, loss 0.372317, acc 0.8125
2020-02-08T02:36:29.273294: step 980, loss 0.310207, acc 0.84375
2020-02-08T02:36:29.388893: step 981, loss 0.299939, acc 0.859375
2020-02-08T02:36:29.508980: step 982, loss 0.253325, acc 0.90625
2020-02-08T02:36:29.625625: step 983, loss 0.437464, acc 0.8125
2020-02-08T02:36:29.745363: step 984, loss 0.215022, acc 0.9375
2020-02-08T02:36:29.863177: step 985, loss 0.361767, acc 0.859375
2020-02-08T02:36:29.980245: step 986, loss 0.376174, acc 0.8125
2020-02-08T02:36:30.096770: step 987, loss 0.342699, acc 0.859375
2020-02-08T02:36:30.210162: step 988, loss 0.434514, acc 0.796875
2020-02-08T02:36:30.329780: step 989, loss 0.388279, acc 0.796875
2020-02-08T02:36:30.446876: step 990, loss 0.307027, acc 0.875
2020-02-08T02:36:30.563038: step 991, loss 0.346395, acc 0.8125
2020-02-08T02:36:30.680819: step 992, loss 0.33746, acc 0.875
2020-02-08T02:36:30.802360: step 993, loss 0.283898, acc 0.921875
2020-02-08T02:36:30.920189: step 994, loss 0.392671, acc 0.8125
2020-02-08T02:36:31.041667: step 995, loss 0.303868, acc 0.8125
2020-02-08T02:36:31.163306: step 996, loss 0.394042, acc 0.828125
2020-02-08T02:36:31.279854: step 997, loss 0.328582, acc 0.90625
2020-02-08T02:36:31.398994: step 998, loss 0.520807, acc 0.734375
2020-02-08T02:36:31.515573: step 999, loss 0.425561, acc 0.828125
2020-02-08T02:36:31.630666: step 1000, loss 0.314507, acc 0.859375

Evaluation:
2020-02-08T02:36:31.824741: step 1000, loss 0.606343, acc 0.695122

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1000

2020-02-08T02:36:35.264904: step 1001, loss 0.354342, acc 0.875
2020-02-08T02:36:35.380731: step 1002, loss 0.399545, acc 0.84375
2020-02-08T02:36:35.498831: step 1003, loss 0.552806, acc 0.75
2020-02-08T02:36:35.614309: step 1004, loss 0.386142, acc 0.8125
2020-02-08T02:36:35.730234: step 1005, loss 0.380067, acc 0.859375
2020-02-08T02:36:35.849125: step 1006, loss 0.269449, acc 0.90625
2020-02-08T02:36:35.967522: step 1007, loss 0.300547, acc 0.84375
2020-02-08T02:36:36.088386: step 1008, loss 0.540844, acc 0.734375
2020-02-08T02:36:36.206585: step 1009, loss 0.48941, acc 0.78125
2020-02-08T02:36:36.325486: step 1010, loss 0.389534, acc 0.84375
2020-02-08T02:36:36.443364: step 1011, loss 0.357897, acc 0.84375
2020-02-08T02:36:36.560930: step 1012, loss 0.284568, acc 0.90625
2020-02-08T02:36:36.676153: step 1013, loss 0.282843, acc 0.890625
2020-02-08T02:36:36.801013: step 1014, loss 0.345021, acc 0.875
2020-02-08T02:36:36.919025: step 1015, loss 0.502475, acc 0.78125
2020-02-08T02:36:37.036742: step 1016, loss 0.471255, acc 0.734375
2020-02-08T02:36:37.155843: step 1017, loss 0.354935, acc 0.859375
2020-02-08T02:36:37.270295: step 1018, loss 0.341356, acc 0.828125
2020-02-08T02:36:37.388295: step 1019, loss 0.279706, acc 0.875
2020-02-08T02:36:37.506352: step 1020, loss 0.358622, acc 0.828125
2020-02-08T02:36:37.623138: step 1021, loss 0.342275, acc 0.875
2020-02-08T02:36:37.745417: step 1022, loss 0.381116, acc 0.828125
2020-02-08T02:36:37.862441: step 1023, loss 0.405253, acc 0.828125
2020-02-08T02:36:37.978980: step 1024, loss 0.428596, acc 0.828125
2020-02-08T02:36:38.096937: step 1025, loss 0.397442, acc 0.859375
2020-02-08T02:36:38.214326: step 1026, loss 0.433376, acc 0.765625
2020-02-08T02:36:38.330597: step 1027, loss 0.343663, acc 0.8125
2020-02-08T02:36:38.446743: step 1028, loss 0.473981, acc 0.765625
2020-02-08T02:36:38.565139: step 1029, loss 0.343198, acc 0.84375
2020-02-08T02:36:38.679054: step 1030, loss 0.266127, acc 0.90625
2020-02-08T02:36:38.799655: step 1031, loss 0.383554, acc 0.828125
2020-02-08T02:36:38.916414: step 1032, loss 0.400423, acc 0.8125
2020-02-08T02:36:39.035937: step 1033, loss 0.478438, acc 0.765625
2020-02-08T02:36:39.152724: step 1034, loss 0.43538, acc 0.765625
2020-02-08T02:36:39.267860: step 1035, loss 0.395383, acc 0.828125
2020-02-08T02:36:39.381569: step 1036, loss 0.294712, acc 0.828125
2020-02-08T02:36:39.501298: step 1037, loss 0.392571, acc 0.734375
2020-02-08T02:36:39.619930: step 1038, loss 0.373575, acc 0.84375
2020-02-08T02:36:39.740200: step 1039, loss 0.384704, acc 0.84375
2020-02-08T02:36:39.859715: step 1040, loss 0.389669, acc 0.796875
2020-02-08T02:36:39.975697: step 1041, loss 0.34618, acc 0.859375
2020-02-08T02:36:40.094858: step 1042, loss 0.339929, acc 0.84375
2020-02-08T02:36:40.213042: step 1043, loss 0.331276, acc 0.890625
2020-02-08T02:36:40.327834: step 1044, loss 0.395942, acc 0.84375
2020-02-08T02:36:40.446311: step 1045, loss 0.352028, acc 0.828125
2020-02-08T02:36:40.564622: step 1046, loss 0.368145, acc 0.875
2020-02-08T02:36:40.680994: step 1047, loss 0.416964, acc 0.828125
2020-02-08T02:36:40.801877: step 1048, loss 0.37504, acc 0.8125
2020-02-08T02:36:40.918384: step 1049, loss 0.4378, acc 0.828125
2020-02-08T02:36:41.031269: step 1050, loss 0.249598, acc 0.916667
2020-02-08T02:36:41.153198: step 1051, loss 0.19836, acc 0.921875
2020-02-08T02:36:41.270741: step 1052, loss 0.294741, acc 0.875
2020-02-08T02:36:41.390228: step 1053, loss 0.288841, acc 0.890625
2020-02-08T02:36:41.509458: step 1054, loss 0.313272, acc 0.859375
2020-02-08T02:36:41.625298: step 1055, loss 0.358092, acc 0.859375
2020-02-08T02:36:41.750439: step 1056, loss 0.349915, acc 0.84375
2020-02-08T02:36:41.868613: step 1057, loss 0.214915, acc 0.921875
2020-02-08T02:36:41.984465: step 1058, loss 0.454008, acc 0.796875
2020-02-08T02:36:42.102210: step 1059, loss 0.315362, acc 0.859375
2020-02-08T02:36:42.222800: step 1060, loss 0.35923, acc 0.90625
2020-02-08T02:36:42.341547: step 1061, loss 0.262366, acc 0.890625
2020-02-08T02:36:42.459424: step 1062, loss 0.351148, acc 0.828125
2020-02-08T02:36:42.578412: step 1063, loss 0.250473, acc 0.90625
2020-02-08T02:36:42.696953: step 1064, loss 0.313125, acc 0.890625
2020-02-08T02:36:42.814518: step 1065, loss 0.265559, acc 0.859375
2020-02-08T02:36:42.930005: step 1066, loss 0.205333, acc 0.9375
2020-02-08T02:36:43.047916: step 1067, loss 0.347265, acc 0.8125
2020-02-08T02:36:43.170156: step 1068, loss 0.274936, acc 0.875
2020-02-08T02:36:43.287822: step 1069, loss 0.241808, acc 0.90625
2020-02-08T02:36:43.410460: step 1070, loss 0.52804, acc 0.734375
2020-02-08T02:36:43.526191: step 1071, loss 0.308712, acc 0.875
2020-02-08T02:36:43.644149: step 1072, loss 0.206952, acc 0.921875
2020-02-08T02:36:43.766383: step 1073, loss 0.277579, acc 0.859375
2020-02-08T02:36:43.882470: step 1074, loss 0.395542, acc 0.8125
2020-02-08T02:36:43.999795: step 1075, loss 0.346999, acc 0.859375
2020-02-08T02:36:44.116923: step 1076, loss 0.419024, acc 0.859375
2020-02-08T02:36:44.234060: step 1077, loss 0.34268, acc 0.859375
2020-02-08T02:36:44.349676: step 1078, loss 0.328484, acc 0.890625
2020-02-08T02:36:44.469425: step 1079, loss 0.353797, acc 0.828125
2020-02-08T02:36:44.584239: step 1080, loss 0.24322, acc 0.9375
2020-02-08T02:36:44.701271: step 1081, loss 0.401501, acc 0.796875
2020-02-08T02:36:44.820930: step 1082, loss 0.188994, acc 0.953125
2020-02-08T02:36:44.939473: step 1083, loss 0.507004, acc 0.734375
2020-02-08T02:36:45.060670: step 1084, loss 0.298094, acc 0.84375
2020-02-08T02:36:45.177519: step 1085, loss 0.306578, acc 0.859375
2020-02-08T02:36:45.296710: step 1086, loss 0.350884, acc 0.828125
2020-02-08T02:36:45.417930: step 1087, loss 0.274081, acc 0.90625
2020-02-08T02:36:45.534989: step 1088, loss 0.307425, acc 0.828125
2020-02-08T02:36:45.652328: step 1089, loss 0.277171, acc 0.921875
2020-02-08T02:36:45.775201: step 1090, loss 0.406397, acc 0.828125
2020-02-08T02:36:45.893330: step 1091, loss 0.277871, acc 0.890625
2020-02-08T02:36:46.012194: step 1092, loss 0.241725, acc 0.921875
2020-02-08T02:36:46.130113: step 1093, loss 0.21633, acc 0.921875
2020-02-08T02:36:46.251662: step 1094, loss 0.367934, acc 0.828125
2020-02-08T02:36:46.371382: step 1095, loss 0.264382, acc 0.890625
2020-02-08T02:36:46.487492: step 1096, loss 0.222888, acc 0.875
2020-02-08T02:36:46.605348: step 1097, loss 0.213349, acc 0.921875
2020-02-08T02:36:46.724678: step 1098, loss 0.401947, acc 0.8125
2020-02-08T02:36:46.845985: step 1099, loss 0.251973, acc 0.921875
2020-02-08T02:36:46.966485: step 1100, loss 0.319296, acc 0.859375

Evaluation:
2020-02-08T02:36:47.155393: step 1100, loss 0.584542, acc 0.705441

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1100

2020-02-08T02:36:49.940369: step 1101, loss 0.297506, acc 0.9375
2020-02-08T02:36:50.056621: step 1102, loss 0.255991, acc 0.890625
2020-02-08T02:36:50.174364: step 1103, loss 0.260859, acc 0.875
2020-02-08T02:36:50.290267: step 1104, loss 0.261894, acc 0.890625
2020-02-08T02:36:50.414035: step 1105, loss 0.213342, acc 0.921875
2020-02-08T02:36:50.531458: step 1106, loss 0.36589, acc 0.828125
2020-02-08T02:36:50.650493: step 1107, loss 0.372154, acc 0.765625
2020-02-08T02:36:50.774498: step 1108, loss 0.46725, acc 0.78125
2020-02-08T02:36:50.892746: step 1109, loss 0.209599, acc 0.9375
2020-02-08T02:36:51.009113: step 1110, loss 0.208881, acc 0.9375
2020-02-08T02:36:51.127801: step 1111, loss 0.261316, acc 0.875
2020-02-08T02:36:51.591568: step 1112, loss 0.332523, acc 0.890625
2020-02-08T02:36:51.714692: step 1113, loss 0.334614, acc 0.828125
2020-02-08T02:36:51.832585: step 1114, loss 0.279628, acc 0.84375
2020-02-08T02:36:51.947854: step 1115, loss 0.29853, acc 0.90625
2020-02-08T02:36:52.064208: step 1116, loss 0.172937, acc 0.9375
2020-02-08T02:36:52.180797: step 1117, loss 0.30746, acc 0.828125
2020-02-08T02:36:52.304940: step 1118, loss 0.30504, acc 0.859375
2020-02-08T02:36:52.423109: step 1119, loss 0.305579, acc 0.890625
2020-02-08T02:36:52.539707: step 1120, loss 0.325177, acc 0.84375
2020-02-08T02:36:52.657013: step 1121, loss 0.302349, acc 0.84375
2020-02-08T02:36:52.777886: step 1122, loss 0.290145, acc 0.890625
2020-02-08T02:36:52.894943: step 1123, loss 0.347579, acc 0.8125
2020-02-08T02:36:53.008361: step 1124, loss 0.340989, acc 0.84375
2020-02-08T02:36:53.126130: step 1125, loss 0.267403, acc 0.890625
2020-02-08T02:36:53.242144: step 1126, loss 0.298648, acc 0.859375
2020-02-08T02:36:53.359960: step 1127, loss 0.342942, acc 0.875
2020-02-08T02:36:53.477490: step 1128, loss 0.315868, acc 0.84375
2020-02-08T02:36:53.593805: step 1129, loss 0.416396, acc 0.796875
2020-02-08T02:36:53.712959: step 1130, loss 0.267649, acc 0.890625
2020-02-08T02:36:53.829149: step 1131, loss 0.287726, acc 0.875
2020-02-08T02:36:53.946448: step 1132, loss 0.40067, acc 0.78125
2020-02-08T02:36:54.063192: step 1133, loss 0.205097, acc 0.90625
2020-02-08T02:36:54.178322: step 1134, loss 0.278021, acc 0.859375
2020-02-08T02:36:54.296252: step 1135, loss 0.338957, acc 0.84375
2020-02-08T02:36:54.416026: step 1136, loss 0.248796, acc 0.890625
2020-02-08T02:36:54.534326: step 1137, loss 0.336244, acc 0.890625
2020-02-08T02:36:54.650929: step 1138, loss 0.367394, acc 0.84375
2020-02-08T02:36:54.772222: step 1139, loss 0.200131, acc 0.90625
2020-02-08T02:36:54.889499: step 1140, loss 0.241618, acc 0.9375
2020-02-08T02:36:55.007393: step 1141, loss 0.308389, acc 0.84375
2020-02-08T02:36:55.125408: step 1142, loss 0.213179, acc 0.953125
2020-02-08T02:36:55.241928: step 1143, loss 0.30918, acc 0.828125
2020-02-08T02:36:55.358524: step 1144, loss 0.424588, acc 0.796875
2020-02-08T02:36:55.475055: step 1145, loss 0.272211, acc 0.90625
2020-02-08T02:36:55.593307: step 1146, loss 0.260343, acc 0.875
2020-02-08T02:36:55.715683: step 1147, loss 0.292354, acc 0.90625
2020-02-08T02:36:55.832486: step 1148, loss 0.349142, acc 0.859375
2020-02-08T02:36:55.952306: step 1149, loss 0.356448, acc 0.859375
2020-02-08T02:36:56.069162: step 1150, loss 0.346837, acc 0.84375
2020-02-08T02:36:56.185854: step 1151, loss 0.280168, acc 0.875
2020-02-08T02:36:56.302042: step 1152, loss 0.367692, acc 0.78125
2020-02-08T02:36:56.417470: step 1153, loss 0.268948, acc 0.890625
2020-02-08T02:36:56.532144: step 1154, loss 0.245945, acc 0.875
2020-02-08T02:36:56.649767: step 1155, loss 0.257483, acc 0.890625
2020-02-08T02:36:56.771380: step 1156, loss 0.27191, acc 0.890625
2020-02-08T02:36:56.888893: step 1157, loss 0.327426, acc 0.828125
2020-02-08T02:36:57.008910: step 1158, loss 0.26626, acc 0.890625
2020-02-08T02:36:57.129434: step 1159, loss 0.312482, acc 0.875
2020-02-08T02:36:57.247472: step 1160, loss 0.378102, acc 0.859375
2020-02-08T02:36:57.368623: step 1161, loss 0.250606, acc 0.859375
2020-02-08T02:36:57.482306: step 1162, loss 0.277408, acc 0.890625
2020-02-08T02:36:57.603442: step 1163, loss 0.391891, acc 0.8125
2020-02-08T02:36:57.722571: step 1164, loss 0.415965, acc 0.78125
2020-02-08T02:36:57.838367: step 1165, loss 0.160821, acc 0.96875
2020-02-08T02:36:57.956437: step 1166, loss 0.499259, acc 0.765625
2020-02-08T02:36:58.074384: step 1167, loss 0.25338, acc 0.859375
2020-02-08T02:36:58.192583: step 1168, loss 0.296231, acc 0.859375
2020-02-08T02:36:58.314089: step 1169, loss 0.337098, acc 0.859375
2020-02-08T02:36:58.432677: step 1170, loss 0.272102, acc 0.890625
2020-02-08T02:36:58.551165: step 1171, loss 0.247479, acc 0.90625
2020-02-08T02:36:58.668888: step 1172, loss 0.496651, acc 0.78125
2020-02-08T02:36:58.790148: step 1173, loss 0.292471, acc 0.859375
2020-02-08T02:36:58.908106: step 1174, loss 0.254218, acc 0.921875
2020-02-08T02:36:59.025089: step 1175, loss 0.298825, acc 0.890625
2020-02-08T02:36:59.145581: step 1176, loss 0.222304, acc 0.9375
2020-02-08T02:36:59.263294: step 1177, loss 0.330625, acc 0.796875
2020-02-08T02:36:59.380010: step 1178, loss 0.279835, acc 0.859375
2020-02-08T02:36:59.496959: step 1179, loss 0.282257, acc 0.890625
2020-02-08T02:36:59.616057: step 1180, loss 0.224132, acc 0.953125
2020-02-08T02:36:59.731920: step 1181, loss 0.366052, acc 0.859375
2020-02-08T02:36:59.854008: step 1182, loss 0.338429, acc 0.859375
2020-02-08T02:36:59.972815: step 1183, loss 0.291438, acc 0.875
2020-02-08T02:37:00.092692: step 1184, loss 0.334547, acc 0.875
2020-02-08T02:37:00.211166: step 1185, loss 0.311197, acc 0.859375
2020-02-08T02:37:00.326787: step 1186, loss 0.253883, acc 0.90625
2020-02-08T02:37:00.444264: step 1187, loss 0.466937, acc 0.8125
2020-02-08T02:37:00.562143: step 1188, loss 0.322944, acc 0.84375
2020-02-08T02:37:00.677650: step 1189, loss 0.397329, acc 0.828125
2020-02-08T02:37:00.798932: step 1190, loss 0.304688, acc 0.875
2020-02-08T02:37:00.916727: step 1191, loss 0.296981, acc 0.84375
2020-02-08T02:37:01.034354: step 1192, loss 0.310164, acc 0.859375
2020-02-08T02:37:01.152995: step 1193, loss 0.243336, acc 0.859375
2020-02-08T02:37:01.268880: step 1194, loss 0.311338, acc 0.859375
2020-02-08T02:37:01.384426: step 1195, loss 0.299134, acc 0.875
2020-02-08T02:37:01.504391: step 1196, loss 0.286075, acc 0.875
2020-02-08T02:37:01.622490: step 1197, loss 0.276803, acc 0.890625
2020-02-08T02:37:01.747199: step 1198, loss 0.333316, acc 0.828125
2020-02-08T02:37:01.863249: step 1199, loss 0.335195, acc 0.859375
2020-02-08T02:37:01.977396: step 1200, loss 0.252922, acc 0.916667

Evaluation:
2020-02-08T02:37:02.165760: step 1200, loss 0.595122, acc 0.712008

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1200

2020-02-08T02:37:03.921806: step 1201, loss 0.280852, acc 0.875
2020-02-08T02:37:04.042504: step 1202, loss 0.269905, acc 0.875
2020-02-08T02:37:04.164326: step 1203, loss 0.202802, acc 0.921875
2020-02-08T02:37:04.283759: step 1204, loss 0.207982, acc 0.921875
2020-02-08T02:37:04.404816: step 1205, loss 0.292904, acc 0.921875
2020-02-08T02:37:04.521488: step 1206, loss 0.330855, acc 0.859375
2020-02-08T02:37:04.636995: step 1207, loss 0.250004, acc 0.90625
2020-02-08T02:37:04.758045: step 1208, loss 0.316047, acc 0.84375
2020-02-08T02:37:04.873584: step 1209, loss 0.146408, acc 0.953125
2020-02-08T02:37:04.989150: step 1210, loss 0.27653, acc 0.859375
2020-02-08T02:37:05.106625: step 1211, loss 0.419468, acc 0.828125
2020-02-08T02:37:05.223490: step 1212, loss 0.348605, acc 0.828125
2020-02-08T02:37:05.340353: step 1213, loss 0.226228, acc 0.890625
2020-02-08T02:37:05.458744: step 1214, loss 0.181721, acc 0.90625
2020-02-08T02:37:05.576086: step 1215, loss 0.240569, acc 0.890625
2020-02-08T02:37:05.695582: step 1216, loss 0.290647, acc 0.921875
2020-02-08T02:37:05.813931: step 1217, loss 0.235777, acc 0.90625
2020-02-08T02:37:05.928426: step 1218, loss 0.252511, acc 0.890625
2020-02-08T02:37:06.044651: step 1219, loss 0.237375, acc 0.890625
2020-02-08T02:37:06.164206: step 1220, loss 0.235194, acc 0.953125
2020-02-08T02:37:06.279337: step 1221, loss 0.275022, acc 0.90625
2020-02-08T02:37:06.396834: step 1222, loss 0.25957, acc 0.90625
2020-02-08T02:37:06.515029: step 1223, loss 0.197568, acc 0.921875
2020-02-08T02:37:06.631937: step 1224, loss 0.417931, acc 0.78125
2020-02-08T02:37:06.755064: step 1225, loss 0.214381, acc 0.90625
2020-02-08T02:37:06.874421: step 1226, loss 0.214549, acc 0.9375
2020-02-08T02:37:06.990879: step 1227, loss 0.25099, acc 0.875
2020-02-08T02:37:07.108074: step 1228, loss 0.199473, acc 0.90625
2020-02-08T02:37:07.225886: step 1229, loss 0.226482, acc 0.921875
2020-02-08T02:37:07.344583: step 1230, loss 0.275371, acc 0.875
2020-02-08T02:37:07.465870: step 1231, loss 0.261942, acc 0.875
2020-02-08T02:37:07.581431: step 1232, loss 0.24507, acc 0.921875
2020-02-08T02:37:07.697868: step 1233, loss 0.256872, acc 0.90625
2020-02-08T02:37:07.815408: step 1234, loss 0.183742, acc 0.921875
2020-02-08T02:37:07.931239: step 1235, loss 0.198225, acc 0.9375
2020-02-08T02:37:08.050448: step 1236, loss 0.186052, acc 0.953125
2020-02-08T02:37:08.168999: step 1237, loss 0.25086, acc 0.890625
2020-02-08T02:37:08.287521: step 1238, loss 0.210777, acc 0.9375
2020-02-08T02:37:08.405530: step 1239, loss 0.266803, acc 0.859375
2020-02-08T02:37:08.522744: step 1240, loss 0.189674, acc 0.921875
2020-02-08T02:37:08.638004: step 1241, loss 0.197048, acc 0.921875
2020-02-08T02:37:08.761422: step 1242, loss 0.234323, acc 0.890625
2020-02-08T02:37:08.880875: step 1243, loss 0.207275, acc 0.9375
2020-02-08T02:37:09.001221: step 1244, loss 0.286716, acc 0.875
2020-02-08T02:37:09.120289: step 1245, loss 0.179759, acc 0.921875
2020-02-08T02:37:09.235782: step 1246, loss 0.268249, acc 0.90625
2020-02-08T02:37:09.352157: step 1247, loss 0.263525, acc 0.875
2020-02-08T02:37:09.469518: step 1248, loss 0.216811, acc 0.953125
2020-02-08T02:37:09.584974: step 1249, loss 0.267687, acc 0.875
2020-02-08T02:37:09.704889: step 1250, loss 0.119998, acc 0.953125
2020-02-08T02:37:09.822685: step 1251, loss 0.32022, acc 0.890625
2020-02-08T02:37:09.938520: step 1252, loss 0.249674, acc 0.859375
2020-02-08T02:37:10.055322: step 1253, loss 0.207887, acc 0.921875
2020-02-08T02:37:10.171198: step 1254, loss 0.274255, acc 0.890625
2020-02-08T02:37:10.288104: step 1255, loss 0.227473, acc 0.90625
2020-02-08T02:37:10.406141: step 1256, loss 0.27459, acc 0.859375
2020-02-08T02:37:10.523176: step 1257, loss 0.297435, acc 0.875
2020-02-08T02:37:10.640022: step 1258, loss 0.340805, acc 0.828125
2020-02-08T02:37:10.762947: step 1259, loss 0.200787, acc 0.921875
2020-02-08T02:37:10.881464: step 1260, loss 0.261618, acc 0.859375
2020-02-08T02:37:11.001290: step 1261, loss 0.276054, acc 0.890625
2020-02-08T02:37:11.117776: step 1262, loss 0.276034, acc 0.8125
2020-02-08T02:37:11.233523: step 1263, loss 0.293635, acc 0.875
2020-02-08T02:37:11.352257: step 1264, loss 0.404598, acc 0.859375
2020-02-08T02:37:11.470142: step 1265, loss 0.201784, acc 0.921875
2020-02-08T02:37:11.588255: step 1266, loss 0.160441, acc 0.921875
2020-02-08T02:37:11.708909: step 1267, loss 0.275897, acc 0.875
2020-02-08T02:37:11.827303: step 1268, loss 0.309488, acc 0.875
2020-02-08T02:37:11.944427: step 1269, loss 0.335556, acc 0.84375
2020-02-08T02:37:12.063457: step 1270, loss 0.236661, acc 0.921875
2020-02-08T02:37:12.180250: step 1271, loss 0.245513, acc 0.90625
2020-02-08T02:37:12.298830: step 1272, loss 0.235584, acc 0.921875
2020-02-08T02:37:12.415300: step 1273, loss 0.233315, acc 0.9375
2020-02-08T02:37:12.531445: step 1274, loss 0.294744, acc 0.890625
2020-02-08T02:37:12.649313: step 1275, loss 0.247419, acc 0.875
2020-02-08T02:37:12.770840: step 1276, loss 0.230004, acc 0.921875
2020-02-08T02:37:12.889415: step 1277, loss 0.225716, acc 0.890625
2020-02-08T02:37:13.009280: step 1278, loss 0.214638, acc 0.890625
2020-02-08T02:37:13.126136: step 1279, loss 0.372554, acc 0.796875
2020-02-08T02:37:13.243171: step 1280, loss 0.26059, acc 0.84375
2020-02-08T02:37:13.359726: step 1281, loss 0.249334, acc 0.921875
2020-02-08T02:37:13.476525: step 1282, loss 0.26977, acc 0.90625
2020-02-08T02:37:13.592924: step 1283, loss 0.271826, acc 0.84375
2020-02-08T02:37:13.712370: step 1284, loss 0.269357, acc 0.921875
2020-02-08T02:37:13.830621: step 1285, loss 0.237271, acc 0.921875
2020-02-08T02:37:13.951432: step 1286, loss 0.24105, acc 0.90625
2020-02-08T02:37:14.072920: step 1287, loss 0.262409, acc 0.875
2020-02-08T02:37:14.189814: step 1288, loss 0.241687, acc 0.859375
2020-02-08T02:37:14.311794: step 1289, loss 0.210916, acc 0.90625
2020-02-08T02:37:14.428552: step 1290, loss 0.239278, acc 0.890625
2020-02-08T02:37:14.547255: step 1291, loss 0.23381, acc 0.90625
2020-02-08T02:37:14.664384: step 1292, loss 0.137778, acc 0.96875
2020-02-08T02:37:14.783481: step 1293, loss 0.343293, acc 0.828125
2020-02-08T02:37:14.901191: step 1294, loss 0.208246, acc 0.890625
2020-02-08T02:37:15.022893: step 1295, loss 0.226824, acc 0.875
2020-02-08T02:37:15.138224: step 1296, loss 0.119786, acc 0.953125
2020-02-08T02:37:15.255893: step 1297, loss 0.297809, acc 0.90625
2020-02-08T02:37:15.374052: step 1298, loss 0.218837, acc 0.9375
2020-02-08T02:37:15.491140: step 1299, loss 0.300872, acc 0.875
2020-02-08T02:37:15.610700: step 1300, loss 0.232261, acc 0.921875

Evaluation:
2020-02-08T02:37:15.808684: step 1300, loss 0.609709, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1300

2020-02-08T02:37:18.455958: step 1301, loss 0.340733, acc 0.890625
2020-02-08T02:37:18.571937: step 1302, loss 0.227494, acc 0.921875
2020-02-08T02:37:18.688207: step 1303, loss 0.285548, acc 0.875
2020-02-08T02:37:18.808152: step 1304, loss 0.239493, acc 0.875
2020-02-08T02:37:18.925152: step 1305, loss 0.176899, acc 0.9375
2020-02-08T02:37:19.043047: step 1306, loss 0.240038, acc 0.90625
2020-02-08T02:37:19.160771: step 1307, loss 0.22283, acc 0.890625
2020-02-08T02:37:19.280225: step 1308, loss 0.197697, acc 0.96875
2020-02-08T02:37:19.402696: step 1309, loss 0.229912, acc 0.90625
2020-02-08T02:37:19.520362: step 1310, loss 0.110101, acc 0.96875
2020-02-08T02:37:19.639923: step 1311, loss 0.428489, acc 0.8125
2020-02-08T02:37:19.766535: step 1312, loss 0.391311, acc 0.84375
2020-02-08T02:37:19.882007: step 1313, loss 0.279428, acc 0.859375
2020-02-08T02:37:20.000434: step 1314, loss 0.25634, acc 0.90625
2020-02-08T02:37:20.121472: step 1315, loss 0.315453, acc 0.859375
2020-02-08T02:37:20.240175: step 1316, loss 0.302271, acc 0.859375
2020-02-08T02:37:20.358665: step 1317, loss 0.25519, acc 0.890625
2020-02-08T02:37:20.474976: step 1318, loss 0.280304, acc 0.875
2020-02-08T02:37:20.593060: step 1319, loss 0.225871, acc 0.921875
2020-02-08T02:37:20.714182: step 1320, loss 0.285797, acc 0.875
2020-02-08T02:37:20.828826: step 1321, loss 0.322296, acc 0.875
2020-02-08T02:37:20.950222: step 1322, loss 0.338783, acc 0.84375
2020-02-08T02:37:21.069135: step 1323, loss 0.177748, acc 0.953125
2020-02-08T02:37:21.188283: step 1324, loss 0.289744, acc 0.90625
2020-02-08T02:37:21.307797: step 1325, loss 0.245056, acc 0.890625
2020-02-08T02:37:21.423684: step 1326, loss 0.170189, acc 0.953125
2020-02-08T02:37:21.788920: step 1327, loss 0.236087, acc 0.90625
2020-02-08T02:37:21.922146: step 1328, loss 0.161755, acc 0.9375
2020-02-08T02:37:22.039560: step 1329, loss 0.333254, acc 0.828125
2020-02-08T02:37:22.159488: step 1330, loss 0.379893, acc 0.84375
2020-02-08T02:37:22.278612: step 1331, loss 0.36585, acc 0.859375
2020-02-08T02:37:22.396360: step 1332, loss 0.305959, acc 0.890625
2020-02-08T02:37:22.515466: step 1333, loss 0.206562, acc 0.921875
2020-02-08T02:37:22.630993: step 1334, loss 0.250448, acc 0.90625
2020-02-08T02:37:22.752315: step 1335, loss 0.261102, acc 0.859375
2020-02-08T02:37:22.867740: step 1336, loss 0.279188, acc 0.875
2020-02-08T02:37:22.983713: step 1337, loss 0.177199, acc 0.9375
2020-02-08T02:37:23.100906: step 1338, loss 0.279839, acc 0.875
2020-02-08T02:37:23.218682: step 1339, loss 0.280516, acc 0.875
2020-02-08T02:37:23.334854: step 1340, loss 0.187893, acc 0.9375
2020-02-08T02:37:23.455967: step 1341, loss 0.292305, acc 0.859375
2020-02-08T02:37:23.571942: step 1342, loss 0.303769, acc 0.84375
2020-02-08T02:37:23.690641: step 1343, loss 0.264739, acc 0.859375
2020-02-08T02:37:23.812569: step 1344, loss 0.179225, acc 0.921875
2020-02-08T02:37:23.930871: step 1345, loss 0.157504, acc 0.953125
2020-02-08T02:37:24.049791: step 1346, loss 0.317691, acc 0.875
2020-02-08T02:37:24.168140: step 1347, loss 0.237555, acc 0.9375
2020-02-08T02:37:24.283359: step 1348, loss 0.319238, acc 0.859375
2020-02-08T02:37:24.400052: step 1349, loss 0.270659, acc 0.890625
2020-02-08T02:37:24.511637: step 1350, loss 0.200327, acc 0.933333
2020-02-08T02:37:24.627950: step 1351, loss 0.151785, acc 0.96875
2020-02-08T02:37:24.750242: step 1352, loss 0.221316, acc 0.890625
2020-02-08T02:37:24.869721: step 1353, loss 0.188589, acc 0.9375
2020-02-08T02:37:24.985713: step 1354, loss 0.160504, acc 0.953125
2020-02-08T02:37:25.105404: step 1355, loss 0.147605, acc 0.96875
2020-02-08T02:37:25.224910: step 1356, loss 0.169879, acc 0.921875
2020-02-08T02:37:25.340778: step 1357, loss 0.198355, acc 0.90625
2020-02-08T02:37:25.459432: step 1358, loss 0.158325, acc 0.953125
2020-02-08T02:37:25.574647: step 1359, loss 0.156819, acc 0.953125
2020-02-08T02:37:25.692543: step 1360, loss 0.187296, acc 0.921875
2020-02-08T02:37:25.813670: step 1361, loss 0.213196, acc 0.921875
2020-02-08T02:37:25.928955: step 1362, loss 0.206538, acc 0.921875
2020-02-08T02:37:26.050591: step 1363, loss 0.130057, acc 0.9375
2020-02-08T02:37:26.168263: step 1364, loss 0.208687, acc 0.9375
2020-02-08T02:37:26.287400: step 1365, loss 0.170764, acc 0.9375
2020-02-08T02:37:26.404389: step 1366, loss 0.183196, acc 0.9375
2020-02-08T02:37:26.523894: step 1367, loss 0.110462, acc 0.953125
2020-02-08T02:37:26.640828: step 1368, loss 0.192386, acc 0.921875
2020-02-08T02:37:26.763189: step 1369, loss 0.184142, acc 0.9375
2020-02-08T02:37:26.881660: step 1370, loss 0.235698, acc 0.890625
2020-02-08T02:37:26.996728: step 1371, loss 0.233461, acc 0.90625
2020-02-08T02:37:27.114259: step 1372, loss 0.279255, acc 0.859375
2020-02-08T02:37:27.230670: step 1373, loss 0.138366, acc 0.96875
2020-02-08T02:37:27.348614: step 1374, loss 0.162584, acc 0.953125
2020-02-08T02:37:27.468135: step 1375, loss 0.174972, acc 0.921875
2020-02-08T02:37:27.583733: step 1376, loss 0.204814, acc 0.859375
2020-02-08T02:37:27.703210: step 1377, loss 0.252148, acc 0.921875
2020-02-08T02:37:27.823056: step 1378, loss 0.264263, acc 0.890625
2020-02-08T02:37:27.941133: step 1379, loss 0.155411, acc 0.96875
2020-02-08T02:37:28.062215: step 1380, loss 0.176207, acc 0.953125
2020-02-08T02:37:28.180006: step 1381, loss 0.162399, acc 0.90625
2020-02-08T02:37:28.298276: step 1382, loss 0.249566, acc 0.90625
2020-02-08T02:37:28.416463: step 1383, loss 0.177919, acc 0.921875
2020-02-08T02:37:28.534967: step 1384, loss 0.202842, acc 0.890625
2020-02-08T02:37:28.653844: step 1385, loss 0.220725, acc 0.9375
2020-02-08T02:37:28.777259: step 1386, loss 0.183758, acc 0.9375
2020-02-08T02:37:28.892206: step 1387, loss 0.262368, acc 0.875
2020-02-08T02:37:29.009892: step 1388, loss 0.118866, acc 0.9375
2020-02-08T02:37:29.127306: step 1389, loss 0.117002, acc 0.953125
2020-02-08T02:37:29.243961: step 1390, loss 0.219255, acc 0.953125
2020-02-08T02:37:29.361656: step 1391, loss 0.160307, acc 0.953125
2020-02-08T02:37:29.478128: step 1392, loss 0.170946, acc 0.921875
2020-02-08T02:37:29.597613: step 1393, loss 0.109495, acc 0.96875
2020-02-08T02:37:29.718170: step 1394, loss 0.189269, acc 0.9375
2020-02-08T02:37:29.833579: step 1395, loss 0.257788, acc 0.875
2020-02-08T02:37:29.949623: step 1396, loss 0.13288, acc 0.953125
2020-02-08T02:37:30.065901: step 1397, loss 0.125156, acc 0.96875
2020-02-08T02:37:30.182127: step 1398, loss 0.173115, acc 0.9375
2020-02-08T02:37:30.299862: step 1399, loss 0.193337, acc 0.921875
2020-02-08T02:37:30.420465: step 1400, loss 0.184123, acc 0.890625

Evaluation:
2020-02-08T02:37:30.605873: step 1400, loss 0.624422, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1400

2020-02-08T02:37:32.597536: step 1401, loss 0.189721, acc 0.953125
2020-02-08T02:37:32.717382: step 1402, loss 0.276245, acc 0.90625
2020-02-08T02:37:32.835301: step 1403, loss 0.233956, acc 0.90625
2020-02-08T02:37:32.957889: step 1404, loss 0.123563, acc 0.9375
2020-02-08T02:37:33.076769: step 1405, loss 0.108517, acc 0.984375
2020-02-08T02:37:33.197855: step 1406, loss 0.299733, acc 0.859375
2020-02-08T02:37:33.316338: step 1407, loss 0.167857, acc 0.921875
2020-02-08T02:37:33.432587: step 1408, loss 0.153071, acc 0.96875
2020-02-08T02:37:33.548451: step 1409, loss 0.262713, acc 0.859375
2020-02-08T02:37:33.667141: step 1410, loss 0.170205, acc 0.96875
2020-02-08T02:37:33.788301: step 1411, loss 0.095326, acc 0.953125
2020-02-08T02:37:33.907446: step 1412, loss 0.18607, acc 0.9375
2020-02-08T02:37:34.025076: step 1413, loss 0.116701, acc 0.953125
2020-02-08T02:37:34.142080: step 1414, loss 0.126715, acc 0.96875
2020-02-08T02:37:34.262374: step 1415, loss 0.155253, acc 0.921875
2020-02-08T02:37:34.382277: step 1416, loss 0.216776, acc 0.921875
2020-02-08T02:37:34.499708: step 1417, loss 0.145375, acc 0.953125
2020-02-08T02:37:34.619443: step 1418, loss 0.14319, acc 0.96875
2020-02-08T02:37:34.740105: step 1419, loss 0.115623, acc 0.96875
2020-02-08T02:37:34.859918: step 1420, loss 0.139329, acc 0.9375
2020-02-08T02:37:34.976101: step 1421, loss 0.162734, acc 0.953125
2020-02-08T02:37:35.092352: step 1422, loss 0.139911, acc 0.9375
2020-02-08T02:37:35.209947: step 1423, loss 0.183174, acc 0.9375
2020-02-08T02:37:35.328023: step 1424, loss 0.0912477, acc 0.984375
2020-02-08T02:37:35.446250: step 1425, loss 0.207561, acc 0.953125
2020-02-08T02:37:35.567509: step 1426, loss 0.0827439, acc 0.96875
2020-02-08T02:37:35.683447: step 1427, loss 0.298322, acc 0.859375
2020-02-08T02:37:35.804392: step 1428, loss 0.192173, acc 0.953125
2020-02-08T02:37:35.923263: step 1429, loss 0.181332, acc 0.921875
2020-02-08T02:37:36.042570: step 1430, loss 0.185648, acc 0.953125
2020-02-08T02:37:36.163143: step 1431, loss 0.260686, acc 0.921875
2020-02-08T02:37:36.281280: step 1432, loss 0.150611, acc 0.96875
2020-02-08T02:37:36.398381: step 1433, loss 0.133842, acc 0.953125
2020-02-08T02:37:36.517460: step 1434, loss 0.223666, acc 0.921875
2020-02-08T02:37:36.632302: step 1435, loss 0.135067, acc 0.9375
2020-02-08T02:37:36.758407: step 1436, loss 0.179643, acc 0.921875
2020-02-08T02:37:36.878141: step 1437, loss 0.1933, acc 0.890625
2020-02-08T02:37:36.998038: step 1438, loss 0.166441, acc 0.90625
2020-02-08T02:37:37.116972: step 1439, loss 0.245917, acc 0.9375
2020-02-08T02:37:37.237369: step 1440, loss 0.301766, acc 0.890625
2020-02-08T02:37:37.353965: step 1441, loss 0.146635, acc 0.953125
2020-02-08T02:37:37.469355: step 1442, loss 0.173957, acc 0.921875
2020-02-08T02:37:37.585872: step 1443, loss 0.218767, acc 0.921875
2020-02-08T02:37:37.705472: step 1444, loss 0.117287, acc 0.96875
2020-02-08T02:37:37.822765: step 1445, loss 0.122249, acc 0.96875
2020-02-08T02:37:37.937983: step 1446, loss 0.113355, acc 0.96875
2020-02-08T02:37:38.053351: step 1447, loss 0.156823, acc 0.96875
2020-02-08T02:37:38.168146: step 1448, loss 0.188449, acc 0.921875
2020-02-08T02:37:38.285899: step 1449, loss 0.124531, acc 0.953125
2020-02-08T02:37:38.404853: step 1450, loss 0.209387, acc 0.9375
2020-02-08T02:37:38.523298: step 1451, loss 0.225149, acc 0.90625
2020-02-08T02:37:38.639736: step 1452, loss 0.10271, acc 0.953125
2020-02-08T02:37:38.762131: step 1453, loss 0.212011, acc 0.9375
2020-02-08T02:37:38.879881: step 1454, loss 0.163071, acc 0.96875
2020-02-08T02:37:38.995931: step 1455, loss 0.197998, acc 0.9375
2020-02-08T02:37:39.114428: step 1456, loss 0.239108, acc 0.890625
2020-02-08T02:37:39.234517: step 1457, loss 0.116897, acc 0.984375
2020-02-08T02:37:39.355284: step 1458, loss 0.190779, acc 0.921875
2020-02-08T02:37:39.475221: step 1459, loss 0.183627, acc 0.9375
2020-02-08T02:37:39.594621: step 1460, loss 0.236939, acc 0.921875
2020-02-08T02:37:39.720755: step 1461, loss 0.134219, acc 0.9375
2020-02-08T02:37:39.840096: step 1462, loss 0.0837962, acc 0.96875
2020-02-08T02:37:39.957460: step 1463, loss 0.238512, acc 0.875
2020-02-08T02:37:40.074043: step 1464, loss 0.312294, acc 0.859375
2020-02-08T02:37:40.188319: step 1465, loss 0.274331, acc 0.90625
2020-02-08T02:37:40.307725: step 1466, loss 0.135182, acc 0.953125
2020-02-08T02:37:40.426572: step 1467, loss 0.129345, acc 0.96875
2020-02-08T02:37:40.547498: step 1468, loss 0.226763, acc 0.90625
2020-02-08T02:37:40.667411: step 1469, loss 0.262517, acc 0.875
2020-02-08T02:37:40.788207: step 1470, loss 0.192814, acc 0.9375
2020-02-08T02:37:40.909145: step 1471, loss 0.161552, acc 0.9375
2020-02-08T02:37:41.027684: step 1472, loss 0.255183, acc 0.890625
2020-02-08T02:37:41.148732: step 1473, loss 0.205171, acc 0.890625
2020-02-08T02:37:41.265278: step 1474, loss 0.167592, acc 0.9375
2020-02-08T02:37:41.382017: step 1475, loss 0.253207, acc 0.875
2020-02-08T02:37:41.500534: step 1476, loss 0.187057, acc 0.921875
2020-02-08T02:37:41.618933: step 1477, loss 0.177841, acc 0.953125
2020-02-08T02:37:41.740856: step 1478, loss 0.190709, acc 0.90625
2020-02-08T02:37:41.861211: step 1479, loss 0.292092, acc 0.90625
2020-02-08T02:37:41.980205: step 1480, loss 0.201309, acc 0.90625
2020-02-08T02:37:42.099803: step 1481, loss 0.181202, acc 0.921875
2020-02-08T02:37:42.221175: step 1482, loss 0.185342, acc 0.875
2020-02-08T02:37:42.336360: step 1483, loss 0.155161, acc 0.9375
2020-02-08T02:37:42.454242: step 1484, loss 0.149081, acc 0.96875
2020-02-08T02:37:42.573398: step 1485, loss 0.19959, acc 0.9375
2020-02-08T02:37:42.692717: step 1486, loss 0.216753, acc 0.90625
2020-02-08T02:37:42.811599: step 1487, loss 0.119963, acc 0.953125
2020-02-08T02:37:42.927037: step 1488, loss 0.132841, acc 0.9375
2020-02-08T02:37:43.044752: step 1489, loss 0.180041, acc 0.921875
2020-02-08T02:37:43.164786: step 1490, loss 0.255037, acc 0.875
2020-02-08T02:37:43.280054: step 1491, loss 0.120871, acc 0.953125
2020-02-08T02:37:43.397436: step 1492, loss 0.233416, acc 0.890625
2020-02-08T02:37:43.515349: step 1493, loss 0.282952, acc 0.890625
2020-02-08T02:37:43.633606: step 1494, loss 0.146921, acc 0.953125
2020-02-08T02:37:43.759434: step 1495, loss 0.233808, acc 0.875
2020-02-08T02:37:43.875365: step 1496, loss 0.121561, acc 0.953125
2020-02-08T02:37:43.991715: step 1497, loss 0.229484, acc 0.90625
2020-02-08T02:37:44.109980: step 1498, loss 0.19272, acc 0.90625
2020-02-08T02:37:44.228726: step 1499, loss 0.198276, acc 0.890625
2020-02-08T02:37:44.343047: step 1500, loss 0.237343, acc 0.9

Evaluation:
2020-02-08T02:37:44.536170: step 1500, loss 0.633878, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1500

2020-02-08T02:37:46.457420: step 1501, loss 0.149216, acc 0.9375
2020-02-08T02:37:46.574522: step 1502, loss 0.194414, acc 0.9375
2020-02-08T02:37:46.693552: step 1503, loss 0.0830191, acc 0.96875
2020-02-08T02:37:46.813716: step 1504, loss 0.245613, acc 0.921875
2020-02-08T02:37:46.932039: step 1505, loss 0.141746, acc 0.90625
2020-02-08T02:37:47.051851: step 1506, loss 0.125818, acc 0.953125
2020-02-08T02:37:47.173571: step 1507, loss 0.177503, acc 0.921875
2020-02-08T02:37:47.293779: step 1508, loss 0.176779, acc 0.9375
2020-02-08T02:37:47.412229: step 1509, loss 0.209948, acc 0.921875
2020-02-08T02:37:47.530933: step 1510, loss 0.12022, acc 0.96875
2020-02-08T02:37:47.647138: step 1511, loss 0.135906, acc 0.9375
2020-02-08T02:37:47.768473: step 1512, loss 0.218141, acc 0.90625
2020-02-08T02:37:47.887431: step 1513, loss 0.111604, acc 0.96875
2020-02-08T02:37:48.005339: step 1514, loss 0.138703, acc 0.921875
2020-02-08T02:37:48.121994: step 1515, loss 0.136652, acc 0.953125
2020-02-08T02:37:48.240578: step 1516, loss 0.192288, acc 0.921875
2020-02-08T02:37:48.359746: step 1517, loss 0.233443, acc 0.875
2020-02-08T02:37:48.482955: step 1518, loss 0.117664, acc 0.921875
2020-02-08T02:37:48.601120: step 1519, loss 0.15307, acc 0.90625
2020-02-08T02:37:48.723592: step 1520, loss 0.125698, acc 0.9375
2020-02-08T02:37:48.842728: step 1521, loss 0.149575, acc 0.96875
2020-02-08T02:37:48.960816: step 1522, loss 0.13196, acc 0.96875
2020-02-08T02:37:49.085018: step 1523, loss 0.152008, acc 0.90625
2020-02-08T02:37:49.206142: step 1524, loss 0.184455, acc 0.96875
2020-02-08T02:37:49.330855: step 1525, loss 0.16777, acc 0.953125
2020-02-08T02:37:49.449300: step 1526, loss 0.133412, acc 0.953125
2020-02-08T02:37:49.565020: step 1527, loss 0.0942016, acc 0.984375
2020-02-08T02:37:49.692364: step 1528, loss 0.209, acc 0.890625
2020-02-08T02:37:49.812491: step 1529, loss 0.0690721, acc 1
2020-02-08T02:37:49.930467: step 1530, loss 0.119025, acc 0.953125
2020-02-08T02:37:50.047560: step 1531, loss 0.0872514, acc 0.984375
2020-02-08T02:37:50.166353: step 1532, loss 0.122712, acc 0.9375
2020-02-08T02:37:50.283656: step 1533, loss 0.196382, acc 0.890625
2020-02-08T02:37:50.401931: step 1534, loss 0.114094, acc 0.953125
2020-02-08T02:37:50.520071: step 1535, loss 0.0596102, acc 1
2020-02-08T02:37:50.638423: step 1536, loss 0.206788, acc 0.9375
2020-02-08T02:37:50.760665: step 1537, loss 0.193908, acc 0.921875
2020-02-08T02:37:50.879169: step 1538, loss 0.120146, acc 0.953125
2020-02-08T02:37:51.000341: step 1539, loss 0.144023, acc 0.921875
2020-02-08T02:37:51.119199: step 1540, loss 0.181493, acc 0.921875
2020-02-08T02:37:51.236736: step 1541, loss 0.113471, acc 0.953125
2020-02-08T02:37:51.356500: step 1542, loss 0.116685, acc 0.9375
2020-02-08T02:37:51.489491: step 1543, loss 0.0964839, acc 0.953125
2020-02-08T02:37:51.609101: step 1544, loss 0.10742, acc 0.953125
2020-02-08T02:37:51.734776: step 1545, loss 0.148731, acc 0.9375
2020-02-08T02:37:51.853759: step 1546, loss 0.112822, acc 0.953125
2020-02-08T02:37:51.973523: step 1547, loss 0.158202, acc 0.9375
2020-02-08T02:37:52.092678: step 1548, loss 0.15352, acc 0.921875
2020-02-08T02:37:52.216482: step 1549, loss 0.149818, acc 0.9375
2020-02-08T02:37:52.335733: step 1550, loss 0.141719, acc 0.953125
2020-02-08T02:37:52.455933: step 1551, loss 0.173256, acc 0.921875
2020-02-08T02:37:52.575144: step 1552, loss 0.234104, acc 0.875
2020-02-08T02:37:52.697615: step 1553, loss 0.120877, acc 0.9375
2020-02-08T02:37:52.818523: step 1554, loss 0.141901, acc 0.9375
2020-02-08T02:37:52.940629: step 1555, loss 0.126557, acc 0.953125
2020-02-08T02:37:53.057296: step 1556, loss 0.100321, acc 0.953125
2020-02-08T02:37:53.174871: step 1557, loss 0.102036, acc 0.984375
2020-02-08T02:37:53.292893: step 1558, loss 0.198999, acc 0.890625
2020-02-08T02:37:53.411436: step 1559, loss 0.143533, acc 0.9375
2020-02-08T02:37:53.529972: step 1560, loss 0.16638, acc 0.953125
2020-02-08T02:37:53.648793: step 1561, loss 0.151462, acc 0.9375
2020-02-08T02:37:53.771470: step 1562, loss 0.201782, acc 0.90625
2020-02-08T02:37:53.890474: step 1563, loss 0.172079, acc 0.984375
2020-02-08T02:37:54.008642: step 1564, loss 0.136927, acc 0.921875
2020-02-08T02:37:54.126057: step 1565, loss 0.1294, acc 0.9375
2020-02-08T02:37:54.244690: step 1566, loss 0.0656021, acc 1
2020-02-08T02:37:54.362991: step 1567, loss 0.105671, acc 0.96875
2020-02-08T02:37:54.482723: step 1568, loss 0.0746065, acc 0.984375
2020-02-08T02:37:54.603098: step 1569, loss 0.157722, acc 0.890625
2020-02-08T02:37:54.726549: step 1570, loss 0.0958321, acc 1
2020-02-08T02:37:54.851913: step 1571, loss 0.0901811, acc 0.953125
2020-02-08T02:37:54.975687: step 1572, loss 0.141674, acc 0.953125
2020-02-08T02:37:55.102889: step 1573, loss 0.131429, acc 0.953125
2020-02-08T02:37:55.224892: step 1574, loss 0.117279, acc 0.953125
2020-02-08T02:37:55.342650: step 1575, loss 0.117234, acc 0.953125
2020-02-08T02:37:55.465596: step 1576, loss 0.110325, acc 0.96875
2020-02-08T02:37:55.581105: step 1577, loss 0.0740891, acc 1
2020-02-08T02:37:55.705627: step 1578, loss 0.205956, acc 0.875
2020-02-08T02:37:55.824609: step 1579, loss 0.135112, acc 0.953125
2020-02-08T02:37:55.943731: step 1580, loss 0.152241, acc 0.953125
2020-02-08T02:37:56.066148: step 1581, loss 0.110917, acc 0.953125
2020-02-08T02:37:56.182241: step 1582, loss 0.152897, acc 0.953125
2020-02-08T02:37:56.309228: step 1583, loss 0.130475, acc 0.953125
2020-02-08T02:37:56.429232: step 1584, loss 0.175759, acc 0.90625
2020-02-08T02:37:56.549040: step 1585, loss 0.224856, acc 0.921875
2020-02-08T02:37:56.668784: step 1586, loss 0.205848, acc 0.90625
2020-02-08T02:37:56.787913: step 1587, loss 0.0541957, acc 0.984375
2020-02-08T02:37:56.910519: step 1588, loss 0.197584, acc 0.9375
2020-02-08T02:37:57.033549: step 1589, loss 0.136532, acc 0.9375
2020-02-08T02:37:57.154751: step 1590, loss 0.0710455, acc 0.984375
2020-02-08T02:37:57.272462: step 1591, loss 0.166171, acc 0.921875
2020-02-08T02:37:57.391381: step 1592, loss 0.187703, acc 0.90625
2020-02-08T02:37:57.511133: step 1593, loss 0.341937, acc 0.859375
2020-02-08T02:37:57.629146: step 1594, loss 0.241453, acc 0.9375
2020-02-08T02:37:57.755118: step 1595, loss 0.190768, acc 0.90625
2020-02-08T02:37:57.878191: step 1596, loss 0.0831138, acc 0.96875
2020-02-08T02:37:57.995663: step 1597, loss 0.0426828, acc 1
2020-02-08T02:37:58.116640: step 1598, loss 0.162804, acc 0.9375
2020-02-08T02:37:58.235320: step 1599, loss 0.195596, acc 0.953125
2020-02-08T02:37:58.355774: step 1600, loss 0.117143, acc 0.953125

Evaluation:
2020-02-08T02:37:58.542883: step 1600, loss 0.677475, acc 0.717636

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1600

2020-02-08T02:38:01.345703: step 1601, loss 0.149519, acc 0.9375
2020-02-08T02:38:01.466093: step 1602, loss 0.0653783, acc 0.984375
2020-02-08T02:38:01.586833: step 1603, loss 0.0712419, acc 1
2020-02-08T02:38:01.708833: step 1604, loss 0.182866, acc 0.9375
2020-02-08T02:38:01.825488: step 1605, loss 0.0810805, acc 0.96875
2020-02-08T02:38:01.940636: step 1606, loss 0.133968, acc 0.9375
2020-02-08T02:38:02.060486: step 1607, loss 0.219001, acc 0.890625
2020-02-08T02:38:02.179576: step 1608, loss 0.115131, acc 0.9375
2020-02-08T02:38:02.301798: step 1609, loss 0.105289, acc 0.984375
2020-02-08T02:38:02.418826: step 1610, loss 0.146365, acc 0.953125
2020-02-08T02:38:02.538459: step 1611, loss 0.183878, acc 0.9375
2020-02-08T02:38:02.659178: step 1612, loss 0.21708, acc 0.890625
2020-02-08T02:38:02.781496: step 1613, loss 0.142335, acc 0.953125
2020-02-08T02:38:02.899472: step 1614, loss 0.195578, acc 0.9375
2020-02-08T02:38:03.019167: step 1615, loss 0.108551, acc 0.9375
2020-02-08T02:38:03.135456: step 1616, loss 0.111077, acc 0.96875
2020-02-08T02:38:03.254669: step 1617, loss 0.139346, acc 0.953125
2020-02-08T02:38:03.374208: step 1618, loss 0.127785, acc 0.9375
2020-02-08T02:38:03.494092: step 1619, loss 0.136761, acc 0.953125
2020-02-08T02:38:03.616868: step 1620, loss 0.129977, acc 0.9375
2020-02-08T02:38:03.735620: step 1621, loss 0.072541, acc 0.984375
2020-02-08T02:38:03.854347: step 1622, loss 0.23613, acc 0.90625
2020-02-08T02:38:03.973454: step 1623, loss 0.127651, acc 0.953125
2020-02-08T02:38:04.089498: step 1624, loss 0.146413, acc 0.9375
2020-02-08T02:38:04.206551: step 1625, loss 0.104288, acc 0.96875
2020-02-08T02:38:04.326088: step 1626, loss 0.0441718, acc 1
2020-02-08T02:38:04.444670: step 1627, loss 0.0966436, acc 0.96875
2020-02-08T02:38:04.565556: step 1628, loss 0.216755, acc 0.90625
2020-02-08T02:38:04.683588: step 1629, loss 0.128788, acc 0.953125
2020-02-08T02:38:04.810458: step 1630, loss 0.176471, acc 0.921875
2020-02-08T02:38:04.933169: step 1631, loss 0.186051, acc 0.921875
2020-02-08T02:38:05.052928: step 1632, loss 0.127902, acc 0.96875
2020-02-08T02:38:05.171357: step 1633, loss 0.156141, acc 0.921875
2020-02-08T02:38:05.291381: step 1634, loss 0.103251, acc 0.984375
2020-02-08T02:38:05.409975: step 1635, loss 0.104208, acc 0.96875
2020-02-08T02:38:05.526777: step 1636, loss 0.102705, acc 0.953125
2020-02-08T02:38:05.642772: step 1637, loss 0.206183, acc 0.921875
2020-02-08T02:38:05.763372: step 1638, loss 0.1347, acc 0.9375
2020-02-08T02:38:05.880285: step 1639, loss 0.0790662, acc 0.984375
2020-02-08T02:38:05.997260: step 1640, loss 0.143451, acc 0.953125
2020-02-08T02:38:06.113550: step 1641, loss 0.148204, acc 0.9375
2020-02-08T02:38:06.230458: step 1642, loss 0.238574, acc 0.921875
2020-02-08T02:38:06.349495: step 1643, loss 0.0935438, acc 0.984375
2020-02-08T02:38:06.467745: step 1644, loss 0.146367, acc 0.96875
2020-02-08T02:38:06.582681: step 1645, loss 0.136745, acc 0.921875
2020-02-08T02:38:06.701752: step 1646, loss 0.186727, acc 0.90625
2020-02-08T02:38:06.818706: step 1647, loss 0.0829837, acc 0.984375
2020-02-08T02:38:06.936125: step 1648, loss 0.209793, acc 0.890625
2020-02-08T02:38:07.051851: step 1649, loss 0.145968, acc 0.9375
2020-02-08T02:38:07.164522: step 1650, loss 0.151678, acc 0.933333
2020-02-08T02:38:07.284662: step 1651, loss 0.106091, acc 0.96875
2020-02-08T02:38:07.402113: step 1652, loss 0.166102, acc 0.953125
2020-02-08T02:38:07.519889: step 1653, loss 0.0625282, acc 0.984375
2020-02-08T02:38:07.638363: step 1654, loss 0.101845, acc 0.984375
2020-02-08T02:38:07.760276: step 1655, loss 0.122111, acc 0.953125
2020-02-08T02:38:07.882792: step 1656, loss 0.172043, acc 0.9375
2020-02-08T02:38:08.003766: step 1657, loss 0.0453541, acc 1
2020-02-08T02:38:08.123099: step 1658, loss 0.108857, acc 0.96875
2020-02-08T02:38:08.240406: step 1659, loss 0.052535, acc 0.984375
2020-02-08T02:38:08.358522: step 1660, loss 0.0809628, acc 0.96875
2020-02-08T02:38:08.478206: step 1661, loss 0.121778, acc 0.96875
2020-02-08T02:38:08.598587: step 1662, loss 0.0984939, acc 0.984375
2020-02-08T02:38:08.719974: step 1663, loss 0.0993966, acc 0.96875
2020-02-08T02:38:08.839013: step 1664, loss 0.172135, acc 0.9375
2020-02-08T02:38:08.956683: step 1665, loss 0.098803, acc 0.953125
2020-02-08T02:38:09.073741: step 1666, loss 0.101543, acc 0.96875
2020-02-08T02:38:09.193342: step 1667, loss 0.222498, acc 0.90625
2020-02-08T02:38:09.314753: step 1668, loss 0.103069, acc 0.984375
2020-02-08T02:38:09.432237: step 1669, loss 0.0987182, acc 0.953125
2020-02-08T02:38:09.552828: step 1670, loss 0.083677, acc 0.953125
2020-02-08T02:38:09.671431: step 1671, loss 0.0389074, acc 1
2020-02-08T02:38:09.795514: step 1672, loss 0.0679539, acc 0.984375
2020-02-08T02:38:09.917801: step 1673, loss 0.11219, acc 0.96875
2020-02-08T02:38:10.038620: step 1674, loss 0.139076, acc 0.953125
2020-02-08T02:38:10.158129: step 1675, loss 0.0896801, acc 0.953125
2020-02-08T02:38:10.273484: step 1676, loss 0.114804, acc 0.953125
2020-02-08T02:38:10.391851: step 1677, loss 0.093367, acc 0.984375
2020-02-08T02:38:10.506649: step 1678, loss 0.0988909, acc 0.953125
2020-02-08T02:38:10.624100: step 1679, loss 0.0743862, acc 0.984375
2020-02-08T02:38:10.744400: step 1680, loss 0.14714, acc 0.890625
2020-02-08T02:38:10.862314: step 1681, loss 0.0862531, acc 0.96875
2020-02-08T02:38:10.983362: step 1682, loss 0.139327, acc 0.953125
2020-02-08T02:38:11.100417: step 1683, loss 0.0840716, acc 0.96875
2020-02-08T02:38:11.218097: step 1684, loss 0.11115, acc 0.953125
2020-02-08T02:38:11.338017: step 1685, loss 0.113893, acc 0.96875
2020-02-08T02:38:11.455772: step 1686, loss 0.121089, acc 0.9375
2020-02-08T02:38:11.574292: step 1687, loss 0.0328322, acc 1
2020-02-08T02:38:11.689790: step 1688, loss 0.126081, acc 0.9375
2020-02-08T02:38:11.809666: step 1689, loss 0.152406, acc 0.953125
2020-02-08T02:38:11.929594: step 1690, loss 0.166847, acc 0.9375
2020-02-08T02:38:12.046143: step 1691, loss 0.0821288, acc 0.984375
2020-02-08T02:38:12.164197: step 1692, loss 0.0276821, acc 1
2020-02-08T02:38:12.283656: step 1693, loss 0.0934929, acc 0.96875
2020-02-08T02:38:12.402659: step 1694, loss 0.166499, acc 0.90625
2020-02-08T02:38:12.522332: step 1695, loss 0.0920882, acc 0.96875
2020-02-08T02:38:12.640977: step 1696, loss 0.0548631, acc 0.984375
2020-02-08T02:38:12.759982: step 1697, loss 0.105167, acc 0.96875
2020-02-08T02:38:12.879991: step 1698, loss 0.051225, acc 0.984375
2020-02-08T02:38:12.998553: step 1699, loss 0.0804816, acc 0.984375
2020-02-08T02:38:13.115877: step 1700, loss 0.165545, acc 0.9375

Evaluation:
2020-02-08T02:38:13.312739: step 1700, loss 0.693161, acc 0.72045

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1700

2020-02-08T02:38:15.119910: step 1701, loss 0.0815925, acc 0.96875
2020-02-08T02:38:15.237360: step 1702, loss 0.106727, acc 0.984375
2020-02-08T02:38:15.355790: step 1703, loss 0.123572, acc 0.953125
2020-02-08T02:38:15.473736: step 1704, loss 0.134036, acc 0.953125
2020-02-08T02:38:15.590752: step 1705, loss 0.0985868, acc 0.96875
2020-02-08T02:38:15.710521: step 1706, loss 0.184837, acc 0.9375
2020-02-08T02:38:15.828773: step 1707, loss 0.0615992, acc 0.984375
2020-02-08T02:38:15.946713: step 1708, loss 0.0948288, acc 0.953125
2020-02-08T02:38:16.063985: step 1709, loss 0.0441617, acc 1
2020-02-08T02:38:16.179558: step 1710, loss 0.0846673, acc 0.96875
2020-02-08T02:38:16.298022: step 1711, loss 0.100116, acc 0.96875
2020-02-08T02:38:16.415020: step 1712, loss 0.0698449, acc 0.984375
2020-02-08T02:38:16.531128: step 1713, loss 0.11835, acc 0.953125
2020-02-08T02:38:16.648595: step 1714, loss 0.206243, acc 0.921875
2020-02-08T02:38:16.769344: step 1715, loss 0.0496852, acc 1
2020-02-08T02:38:16.887434: step 1716, loss 0.115067, acc 0.96875
2020-02-08T02:38:17.008167: step 1717, loss 0.154923, acc 0.96875
2020-02-08T02:38:17.127591: step 1718, loss 0.0457893, acc 1
2020-02-08T02:38:17.243818: step 1719, loss 0.112547, acc 0.96875
2020-02-08T02:38:17.365531: step 1720, loss 0.171185, acc 0.921875
2020-02-08T02:38:17.486171: step 1721, loss 0.0671904, acc 1
2020-02-08T02:38:17.609925: step 1722, loss 0.138323, acc 0.953125
2020-02-08T02:38:17.729093: step 1723, loss 0.137832, acc 0.953125
2020-02-08T02:38:17.855436: step 1724, loss 0.0871526, acc 0.953125
2020-02-08T02:38:17.974343: step 1725, loss 0.0970812, acc 0.96875
2020-02-08T02:38:18.094721: step 1726, loss 0.105517, acc 0.953125
2020-02-08T02:38:18.210469: step 1727, loss 0.11303, acc 0.96875
2020-02-08T02:38:18.329034: step 1728, loss 0.0966653, acc 0.953125
2020-02-08T02:38:18.450309: step 1729, loss 0.12154, acc 0.96875
2020-02-08T02:38:18.570771: step 1730, loss 0.0729262, acc 0.96875
2020-02-08T02:38:18.693641: step 1731, loss 0.109186, acc 0.984375
2020-02-08T02:38:18.814705: step 1732, loss 0.152478, acc 0.96875
2020-02-08T02:38:18.932715: step 1733, loss 0.143923, acc 0.96875
2020-02-08T02:38:19.051419: step 1734, loss 0.0994713, acc 0.953125
2020-02-08T02:38:19.173735: step 1735, loss 0.089484, acc 0.953125
2020-02-08T02:38:19.289839: step 1736, loss 0.126195, acc 0.96875
2020-02-08T02:38:19.407907: step 1737, loss 0.0860524, acc 0.96875
2020-02-08T02:38:19.525816: step 1738, loss 0.103882, acc 0.96875
2020-02-08T02:38:19.642592: step 1739, loss 0.115757, acc 0.953125
2020-02-08T02:38:19.764613: step 1740, loss 0.174504, acc 0.9375
2020-02-08T02:38:19.885661: step 1741, loss 0.230863, acc 0.875
2020-02-08T02:38:20.003945: step 1742, loss 0.0862984, acc 0.96875
2020-02-08T02:38:20.121152: step 1743, loss 0.0828562, acc 0.96875
2020-02-08T02:38:20.239655: step 1744, loss 0.0718913, acc 1
2020-02-08T02:38:20.362997: step 1745, loss 0.0610696, acc 0.984375
2020-02-08T02:38:20.481777: step 1746, loss 0.142589, acc 0.921875
2020-02-08T02:38:20.602514: step 1747, loss 0.135482, acc 0.96875
2020-02-08T02:38:20.720124: step 1748, loss 0.139762, acc 0.921875
2020-02-08T02:38:20.840130: step 1749, loss 0.135362, acc 0.921875
2020-02-08T02:38:20.960585: step 1750, loss 0.0912647, acc 0.984375
2020-02-08T02:38:21.079433: step 1751, loss 0.118469, acc 0.9375
2020-02-08T02:38:21.198523: step 1752, loss 0.214357, acc 0.921875
2020-02-08T02:38:21.313524: step 1753, loss 0.133242, acc 0.953125
2020-02-08T02:38:21.526245: step 1754, loss 0.133852, acc 0.921875
2020-02-08T02:38:21.645919: step 1755, loss 0.170229, acc 0.9375
2020-02-08T02:38:21.768085: step 1756, loss 0.100063, acc 0.96875
2020-02-08T02:38:21.888311: step 1757, loss 0.117453, acc 0.96875
2020-02-08T02:38:22.005681: step 1758, loss 0.039382, acc 1
2020-02-08T02:38:22.123674: step 1759, loss 0.140062, acc 0.96875
2020-02-08T02:38:22.238824: step 1760, loss 0.0533294, acc 0.984375
2020-02-08T02:38:22.358154: step 1761, loss 0.0973533, acc 0.96875
2020-02-08T02:38:22.481521: step 1762, loss 0.148851, acc 0.921875
2020-02-08T02:38:22.596550: step 1763, loss 0.117063, acc 0.953125
2020-02-08T02:38:22.719814: step 1764, loss 0.21473, acc 0.921875
2020-02-08T02:38:22.836018: step 1765, loss 0.0601607, acc 0.984375
2020-02-08T02:38:22.955476: step 1766, loss 0.151, acc 0.953125
2020-02-08T02:38:23.076693: step 1767, loss 0.0716185, acc 0.96875
2020-02-08T02:38:23.200469: step 1768, loss 0.0677659, acc 0.984375
2020-02-08T02:38:23.319097: step 1769, loss 0.0838832, acc 0.96875
2020-02-08T02:38:23.434832: step 1770, loss 0.148391, acc 0.921875
2020-02-08T02:38:23.557123: step 1771, loss 0.106101, acc 0.953125
2020-02-08T02:38:23.678950: step 1772, loss 0.0875109, acc 0.96875
2020-02-08T02:38:23.809500: step 1773, loss 0.175971, acc 0.9375
2020-02-08T02:38:23.926985: step 1774, loss 0.215014, acc 0.90625
2020-02-08T02:38:24.045911: step 1775, loss 0.164742, acc 0.9375
2020-02-08T02:38:24.163772: step 1776, loss 0.101175, acc 0.984375
2020-02-08T02:38:24.280912: step 1777, loss 0.131109, acc 0.953125
2020-02-08T02:38:24.397015: step 1778, loss 0.101511, acc 0.96875
2020-02-08T02:38:24.523513: step 1779, loss 0.0710091, acc 0.984375
2020-02-08T02:38:24.639524: step 1780, loss 0.173243, acc 0.9375
2020-02-08T02:38:24.770148: step 1781, loss 0.0547288, acc 0.984375
2020-02-08T02:38:24.886347: step 1782, loss 0.0541373, acc 1
2020-02-08T02:38:25.009286: step 1783, loss 0.181373, acc 0.90625
2020-02-08T02:38:25.129059: step 1784, loss 0.0707853, acc 0.984375
2020-02-08T02:38:25.250009: step 1785, loss 0.185354, acc 0.9375
2020-02-08T02:38:25.369413: step 1786, loss 0.115887, acc 0.953125
2020-02-08T02:38:25.485259: step 1787, loss 0.149619, acc 0.9375
2020-02-08T02:38:25.603181: step 1788, loss 0.21655, acc 0.921875
2020-02-08T02:38:25.722666: step 1789, loss 0.0543129, acc 0.984375
2020-02-08T02:38:25.840548: step 1790, loss 0.0801665, acc 0.984375
2020-02-08T02:38:25.960381: step 1791, loss 0.0548198, acc 1
2020-02-08T02:38:26.077371: step 1792, loss 0.0730955, acc 0.96875
2020-02-08T02:38:26.196076: step 1793, loss 0.0614528, acc 0.984375
2020-02-08T02:38:26.315695: step 1794, loss 0.131536, acc 0.953125
2020-02-08T02:38:26.432158: step 1795, loss 0.131731, acc 0.9375
2020-02-08T02:38:26.553923: step 1796, loss 0.131666, acc 0.96875
2020-02-08T02:38:26.676716: step 1797, loss 0.0634859, acc 0.984375
2020-02-08T02:38:26.799787: step 1798, loss 0.139713, acc 0.921875
2020-02-08T02:38:26.920529: step 1799, loss 0.148195, acc 0.9375
2020-02-08T02:38:27.032433: step 1800, loss 0.15133, acc 0.933333

Evaluation:
2020-02-08T02:38:27.219409: step 1800, loss 0.716134, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1800

2020-02-08T02:38:29.143512: step 1801, loss 0.0809164, acc 0.953125
2020-02-08T02:38:29.265119: step 1802, loss 0.0748798, acc 0.96875
2020-02-08T02:38:29.380800: step 1803, loss 0.100663, acc 0.953125
2020-02-08T02:38:29.497350: step 1804, loss 0.0984101, acc 0.96875
2020-02-08T02:38:29.616403: step 1805, loss 0.0543881, acc 0.984375
2020-02-08T02:38:29.736270: step 1806, loss 0.0553863, acc 0.96875
2020-02-08T02:38:29.857549: step 1807, loss 0.0822143, acc 0.96875
2020-02-08T02:38:29.973837: step 1808, loss 0.0590001, acc 1
2020-02-08T02:38:30.095792: step 1809, loss 0.090247, acc 0.953125
2020-02-08T02:38:30.213121: step 1810, loss 0.0869052, acc 0.96875
2020-02-08T02:38:30.330963: step 1811, loss 0.0269343, acc 1
2020-02-08T02:38:30.449867: step 1812, loss 0.0442276, acc 0.984375
2020-02-08T02:38:30.569784: step 1813, loss 0.103539, acc 0.9375
2020-02-08T02:38:30.686480: step 1814, loss 0.126212, acc 0.953125
2020-02-08T02:38:30.809370: step 1815, loss 0.0408346, acc 1
2020-02-08T02:38:30.926569: step 1816, loss 0.027335, acc 1
2020-02-08T02:38:31.046500: step 1817, loss 0.0580424, acc 1
2020-02-08T02:38:31.164519: step 1818, loss 0.0903352, acc 0.96875
2020-02-08T02:38:31.284595: step 1819, loss 0.0511209, acc 1
2020-02-08T02:38:31.404997: step 1820, loss 0.083977, acc 0.96875
2020-02-08T02:38:31.522023: step 1821, loss 0.0519644, acc 1
2020-02-08T02:38:31.635701: step 1822, loss 0.0493349, acc 0.984375
2020-02-08T02:38:31.760876: step 1823, loss 0.142281, acc 0.9375
2020-02-08T02:38:31.878405: step 1824, loss 0.0723863, acc 0.96875
2020-02-08T02:38:31.995586: step 1825, loss 0.106131, acc 0.96875
2020-02-08T02:38:32.120725: step 1826, loss 0.0700718, acc 0.984375
2020-02-08T02:38:32.241050: step 1827, loss 0.0407189, acc 1
2020-02-08T02:38:32.361868: step 1828, loss 0.0976025, acc 0.96875
2020-02-08T02:38:32.478637: step 1829, loss 0.0841096, acc 0.96875
2020-02-08T02:38:32.598129: step 1830, loss 0.0569349, acc 0.96875
2020-02-08T02:38:32.718725: step 1831, loss 0.126856, acc 0.953125
2020-02-08T02:38:32.834097: step 1832, loss 0.0248775, acc 1
2020-02-08T02:38:32.954227: step 1833, loss 0.0587631, acc 0.984375
2020-02-08T02:38:33.072548: step 1834, loss 0.100664, acc 0.953125
2020-02-08T02:38:33.190180: step 1835, loss 0.112931, acc 0.96875
2020-02-08T02:38:33.308937: step 1836, loss 0.0780921, acc 0.9375
2020-02-08T02:38:33.426337: step 1837, loss 0.0771014, acc 0.96875
2020-02-08T02:38:33.544634: step 1838, loss 0.107571, acc 0.953125
2020-02-08T02:38:33.664444: step 1839, loss 0.0711395, acc 1
2020-02-08T02:38:33.784802: step 1840, loss 0.0982431, acc 0.953125
2020-02-08T02:38:33.903043: step 1841, loss 0.0726682, acc 1
2020-02-08T02:38:34.024041: step 1842, loss 0.13299, acc 0.953125
2020-02-08T02:38:34.139456: step 1843, loss 0.0463032, acc 0.984375
2020-02-08T02:38:34.258475: step 1844, loss 0.113117, acc 0.953125
2020-02-08T02:38:34.374687: step 1845, loss 0.0905674, acc 0.9375
2020-02-08T02:38:34.491163: step 1846, loss 0.0796833, acc 0.96875
2020-02-08T02:38:34.612000: step 1847, loss 0.0957901, acc 0.96875
2020-02-08T02:38:34.729804: step 1848, loss 0.0347699, acc 1
2020-02-08T02:38:34.850286: step 1849, loss 0.151258, acc 0.953125
2020-02-08T02:38:34.967786: step 1850, loss 0.0582501, acc 0.984375
2020-02-08T02:38:35.083868: step 1851, loss 0.0971756, acc 0.953125
2020-02-08T02:38:35.205669: step 1852, loss 0.059275, acc 0.984375
2020-02-08T02:38:35.325880: step 1853, loss 0.113556, acc 0.921875
2020-02-08T02:38:35.445744: step 1854, loss 0.0931712, acc 0.953125
2020-02-08T02:38:35.565929: step 1855, loss 0.110902, acc 0.953125
2020-02-08T02:38:35.683557: step 1856, loss 0.0788189, acc 0.96875
2020-02-08T02:38:35.808688: step 1857, loss 0.0973029, acc 0.953125
2020-02-08T02:38:35.927936: step 1858, loss 0.0726727, acc 0.96875
2020-02-08T02:38:36.044134: step 1859, loss 0.121765, acc 0.9375
2020-02-08T02:38:36.161921: step 1860, loss 0.0509791, acc 0.984375
2020-02-08T02:38:36.280714: step 1861, loss 0.101659, acc 0.96875
2020-02-08T02:38:36.397988: step 1862, loss 0.0444037, acc 1
2020-02-08T02:38:36.515138: step 1863, loss 0.0598481, acc 0.96875
2020-02-08T02:38:36.633709: step 1864, loss 0.0555614, acc 1
2020-02-08T02:38:36.759237: step 1865, loss 0.0600268, acc 0.984375
2020-02-08T02:38:36.877253: step 1866, loss 0.0399679, acc 0.984375
2020-02-08T02:38:36.998237: step 1867, loss 0.0667507, acc 0.984375
2020-02-08T02:38:37.123861: step 1868, loss 0.0622343, acc 0.984375
2020-02-08T02:38:37.239823: step 1869, loss 0.0832007, acc 0.984375
2020-02-08T02:38:37.359449: step 1870, loss 0.0678618, acc 0.984375
2020-02-08T02:38:37.478961: step 1871, loss 0.0949361, acc 0.984375
2020-02-08T02:38:37.595446: step 1872, loss 0.0849093, acc 0.96875
2020-02-08T02:38:37.720319: step 1873, loss 0.070527, acc 0.953125
2020-02-08T02:38:37.836698: step 1874, loss 0.078953, acc 0.984375
2020-02-08T02:38:37.954536: step 1875, loss 0.107324, acc 0.953125
2020-02-08T02:38:38.072618: step 1876, loss 0.075349, acc 0.96875
2020-02-08T02:38:38.188594: step 1877, loss 0.196478, acc 0.953125
2020-02-08T02:38:38.313424: step 1878, loss 0.0821859, acc 0.96875
2020-02-08T02:38:38.431348: step 1879, loss 0.0759067, acc 0.96875
2020-02-08T02:38:38.552501: step 1880, loss 0.161578, acc 0.96875
2020-02-08T02:38:38.670496: step 1881, loss 0.0544889, acc 0.984375
2020-02-08T02:38:38.789362: step 1882, loss 0.106946, acc 0.96875
2020-02-08T02:38:38.910442: step 1883, loss 0.0745034, acc 0.984375
2020-02-08T02:38:39.031367: step 1884, loss 0.0374827, acc 0.984375
2020-02-08T02:38:39.154448: step 1885, loss 0.198773, acc 0.9375
2020-02-08T02:38:39.272210: step 1886, loss 0.0947509, acc 0.96875
2020-02-08T02:38:39.390969: step 1887, loss 0.103167, acc 0.96875
2020-02-08T02:38:39.510744: step 1888, loss 0.0556767, acc 0.984375
2020-02-08T02:38:39.629804: step 1889, loss 0.094035, acc 0.96875
2020-02-08T02:38:39.755232: step 1890, loss 0.0579221, acc 0.984375
2020-02-08T02:38:39.871942: step 1891, loss 0.113759, acc 0.984375
2020-02-08T02:38:39.989065: step 1892, loss 0.0547034, acc 0.96875
2020-02-08T02:38:40.109010: step 1893, loss 0.144919, acc 0.953125
2020-02-08T02:38:40.228403: step 1894, loss 0.0576933, acc 0.984375
2020-02-08T02:38:40.346382: step 1895, loss 0.0798775, acc 0.984375
2020-02-08T02:38:40.468100: step 1896, loss 0.137447, acc 0.953125
2020-02-08T02:38:40.585995: step 1897, loss 0.0324383, acc 1
2020-02-08T02:38:40.704624: step 1898, loss 0.0903929, acc 0.953125
2020-02-08T02:38:40.823899: step 1899, loss 0.0829353, acc 0.984375
2020-02-08T02:38:40.941298: step 1900, loss 0.0850878, acc 0.953125

Evaluation:
2020-02-08T02:38:41.131573: step 1900, loss 0.741469, acc 0.729831

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-1900

2020-02-08T02:38:42.708944: step 1901, loss 0.0687956, acc 0.984375
2020-02-08T02:38:42.825875: step 1902, loss 0.0656955, acc 0.96875
2020-02-08T02:38:42.941370: step 1903, loss 0.0750238, acc 0.984375
2020-02-08T02:38:43.060603: step 1904, loss 0.0926724, acc 0.96875
2020-02-08T02:38:43.177510: step 1905, loss 0.0570443, acc 0.96875
2020-02-08T02:38:43.295244: step 1906, loss 0.0579056, acc 0.984375
2020-02-08T02:38:43.414242: step 1907, loss 0.0638567, acc 0.984375
2020-02-08T02:38:43.532397: step 1908, loss 0.0998984, acc 0.984375
2020-02-08T02:38:43.652202: step 1909, loss 0.0747051, acc 0.96875
2020-02-08T02:38:43.773583: step 1910, loss 0.0726895, acc 0.96875
2020-02-08T02:38:43.890368: step 1911, loss 0.0712607, acc 0.984375
2020-02-08T02:38:44.009842: step 1912, loss 0.0591905, acc 0.984375
2020-02-08T02:38:44.128296: step 1913, loss 0.0586463, acc 0.984375
2020-02-08T02:38:44.246063: step 1914, loss 0.0880921, acc 0.953125
2020-02-08T02:38:44.368832: step 1915, loss 0.0986704, acc 0.96875
2020-02-08T02:38:44.483277: step 1916, loss 0.0524451, acc 1
2020-02-08T02:38:44.600739: step 1917, loss 0.0730356, acc 0.96875
2020-02-08T02:38:44.721022: step 1918, loss 0.0684603, acc 0.96875
2020-02-08T02:38:44.840518: step 1919, loss 0.0790187, acc 0.96875
2020-02-08T02:38:44.959531: step 1920, loss 0.123969, acc 0.953125
2020-02-08T02:38:45.079734: step 1921, loss 0.0458902, acc 0.984375
2020-02-08T02:38:45.196146: step 1922, loss 0.0473317, acc 0.984375
2020-02-08T02:38:45.317537: step 1923, loss 0.0514742, acc 0.96875
2020-02-08T02:38:45.436381: step 1924, loss 0.0790149, acc 0.96875
2020-02-08T02:38:45.555988: step 1925, loss 0.043826, acc 1
2020-02-08T02:38:45.673699: step 1926, loss 0.0789646, acc 0.96875
2020-02-08T02:38:45.797729: step 1927, loss 0.117598, acc 0.96875
2020-02-08T02:38:45.916676: step 1928, loss 0.0916962, acc 0.9375
2020-02-08T02:38:46.031801: step 1929, loss 0.125353, acc 0.9375
2020-02-08T02:38:46.149717: step 1930, loss 0.0608569, acc 0.984375
2020-02-08T02:38:46.271400: step 1931, loss 0.115411, acc 0.9375
2020-02-08T02:38:46.387850: step 1932, loss 0.162802, acc 0.921875
2020-02-08T02:38:46.506039: step 1933, loss 0.105884, acc 0.96875
2020-02-08T02:38:46.625443: step 1934, loss 0.108819, acc 0.953125
2020-02-08T02:38:46.747670: step 1935, loss 0.133396, acc 0.9375
2020-02-08T02:38:46.867017: step 1936, loss 0.163402, acc 0.890625
2020-02-08T02:38:46.980684: step 1937, loss 0.183039, acc 0.90625
2020-02-08T02:38:47.102911: step 1938, loss 0.0511991, acc 1
2020-02-08T02:38:47.220881: step 1939, loss 0.121772, acc 0.96875
2020-02-08T02:38:47.338670: step 1940, loss 0.0337946, acc 1
2020-02-08T02:38:47.455704: step 1941, loss 0.0715467, acc 0.96875
2020-02-08T02:38:47.572998: step 1942, loss 0.0803682, acc 0.96875
2020-02-08T02:38:47.688784: step 1943, loss 0.0242071, acc 1
2020-02-08T02:38:47.810504: step 1944, loss 0.101511, acc 0.96875
2020-02-08T02:38:47.925142: step 1945, loss 0.0718104, acc 0.984375
2020-02-08T02:38:48.038569: step 1946, loss 0.114952, acc 0.96875
2020-02-08T02:38:48.158971: step 1947, loss 0.104532, acc 0.953125
2020-02-08T02:38:48.275492: step 1948, loss 0.106629, acc 0.953125
2020-02-08T02:38:48.393562: step 1949, loss 0.0280225, acc 1
2020-02-08T02:38:48.505501: step 1950, loss 0.0953447, acc 0.966667
2020-02-08T02:38:48.626070: step 1951, loss 0.143792, acc 0.953125
2020-02-08T02:38:48.752293: step 1952, loss 0.0599141, acc 0.984375
2020-02-08T02:38:48.870803: step 1953, loss 0.0678546, acc 0.96875
2020-02-08T02:38:48.988866: step 1954, loss 0.0698927, acc 0.984375
2020-02-08T02:38:49.108066: step 1955, loss 0.083874, acc 0.953125
2020-02-08T02:38:49.225582: step 1956, loss 0.0346247, acc 1
2020-02-08T02:38:49.344387: step 1957, loss 0.191221, acc 0.890625
2020-02-08T02:38:49.462749: step 1958, loss 0.117594, acc 0.953125
2020-02-08T02:38:49.579601: step 1959, loss 0.0563529, acc 0.984375
2020-02-08T02:38:49.699469: step 1960, loss 0.0310764, acc 0.984375
2020-02-08T02:38:49.821372: step 1961, loss 0.050042, acc 0.984375
2020-02-08T02:38:49.936035: step 1962, loss 0.0812971, acc 0.953125
2020-02-08T02:38:50.054746: step 1963, loss 0.0338486, acc 1
2020-02-08T02:38:50.174224: step 1964, loss 0.0634762, acc 0.984375
2020-02-08T02:38:50.291225: step 1965, loss 0.0419893, acc 1
2020-02-08T02:38:50.411091: step 1966, loss 0.140897, acc 0.96875
2020-02-08T02:38:50.532400: step 1967, loss 0.04672, acc 1
2020-02-08T02:38:50.650381: step 1968, loss 0.0183279, acc 1
2020-02-08T02:38:50.774272: step 1969, loss 0.0400412, acc 0.984375
2020-02-08T02:38:50.891777: step 1970, loss 0.0848301, acc 0.96875
2020-02-08T02:38:51.009717: step 1971, loss 0.0897789, acc 0.96875
2020-02-08T02:38:51.131735: step 1972, loss 0.0546255, acc 0.96875
2020-02-08T02:38:51.246205: step 1973, loss 0.0867222, acc 0.953125
2020-02-08T02:38:51.478037: step 1974, loss 0.0333812, acc 1
2020-02-08T02:38:51.610006: step 1975, loss 0.100473, acc 0.953125
2020-02-08T02:38:51.729973: step 1976, loss 0.101612, acc 0.984375
2020-02-08T02:38:51.847298: step 1977, loss 0.0428734, acc 0.984375
2020-02-08T02:38:51.967982: step 1978, loss 0.088591, acc 0.953125
2020-02-08T02:38:52.084134: step 1979, loss 0.0449898, acc 0.984375
2020-02-08T02:38:52.201267: step 1980, loss 0.0867001, acc 0.96875
2020-02-08T02:38:52.319625: step 1981, loss 0.0305637, acc 0.984375
2020-02-08T02:38:52.434431: step 1982, loss 0.126021, acc 0.953125
2020-02-08T02:38:52.551601: step 1983, loss 0.0661731, acc 0.96875
2020-02-08T02:38:52.671885: step 1984, loss 0.0508211, acc 0.984375
2020-02-08T02:38:52.792098: step 1985, loss 0.0601713, acc 0.984375
2020-02-08T02:38:52.910092: step 1986, loss 0.0892981, acc 0.96875
2020-02-08T02:38:53.025923: step 1987, loss 0.0688541, acc 0.96875
2020-02-08T02:38:53.142559: step 1988, loss 0.0368645, acc 1
2020-02-08T02:38:53.260979: step 1989, loss 0.0628815, acc 0.96875
2020-02-08T02:38:53.377386: step 1990, loss 0.0564794, acc 0.984375
2020-02-08T02:38:53.495770: step 1991, loss 0.0510164, acc 0.984375
2020-02-08T02:38:53.615820: step 1992, loss 0.0216505, acc 1
2020-02-08T02:38:53.735164: step 1993, loss 0.0742912, acc 0.96875
2020-02-08T02:38:53.855153: step 1994, loss 0.0805568, acc 0.984375
2020-02-08T02:38:53.972625: step 1995, loss 0.0379853, acc 0.984375
2020-02-08T02:38:54.089569: step 1996, loss 0.0255327, acc 1
2020-02-08T02:38:54.205915: step 1997, loss 0.0636655, acc 0.953125
2020-02-08T02:38:54.324851: step 1998, loss 0.0872512, acc 0.96875
2020-02-08T02:38:54.442530: step 1999, loss 0.10687, acc 0.984375
2020-02-08T02:38:54.560440: step 2000, loss 0.0708497, acc 0.953125

Evaluation:
2020-02-08T02:38:54.756455: step 2000, loss 0.780041, acc 0.726079

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2000

2020-02-08T02:38:57.037720: step 2001, loss 0.0509738, acc 0.984375
2020-02-08T02:38:57.157952: step 2002, loss 0.103303, acc 0.96875
2020-02-08T02:38:57.278116: step 2003, loss 0.063026, acc 0.984375
2020-02-08T02:38:57.397932: step 2004, loss 0.0793655, acc 0.96875
2020-02-08T02:38:57.516832: step 2005, loss 0.0979958, acc 0.953125
2020-02-08T02:38:57.635447: step 2006, loss 0.0277834, acc 1
2020-02-08T02:38:57.759729: step 2007, loss 0.0532547, acc 0.96875
2020-02-08T02:38:57.878500: step 2008, loss 0.0702123, acc 0.96875
2020-02-08T02:38:57.999027: step 2009, loss 0.102116, acc 0.953125
2020-02-08T02:38:58.115830: step 2010, loss 0.0237919, acc 1
2020-02-08T02:38:58.232986: step 2011, loss 0.0895412, acc 0.96875
2020-02-08T02:38:58.356610: step 2012, loss 0.0609734, acc 0.984375
2020-02-08T02:38:58.475408: step 2013, loss 0.0560185, acc 0.984375
2020-02-08T02:38:58.592869: step 2014, loss 0.0583253, acc 0.96875
2020-02-08T02:38:58.711359: step 2015, loss 0.0403254, acc 1
2020-02-08T02:38:58.828962: step 2016, loss 0.0322201, acc 1
2020-02-08T02:38:58.948447: step 2017, loss 0.0327915, acc 1
2020-02-08T02:38:59.071214: step 2018, loss 0.0680149, acc 0.984375
2020-02-08T02:38:59.190354: step 2019, loss 0.0542335, acc 0.96875
2020-02-08T02:38:59.310483: step 2020, loss 0.0691829, acc 0.953125
2020-02-08T02:38:59.430468: step 2021, loss 0.0676701, acc 0.984375
2020-02-08T02:38:59.547894: step 2022, loss 0.146801, acc 0.953125
2020-02-08T02:38:59.668118: step 2023, loss 0.134251, acc 0.96875
2020-02-08T02:38:59.796138: step 2024, loss 0.0348884, acc 0.984375
2020-02-08T02:38:59.915113: step 2025, loss 0.0742131, acc 0.953125
2020-02-08T02:39:00.032091: step 2026, loss 0.0314102, acc 1
2020-02-08T02:39:00.148583: step 2027, loss 0.110673, acc 0.9375
2020-02-08T02:39:00.273199: step 2028, loss 0.0563664, acc 0.984375
2020-02-08T02:39:00.392041: step 2029, loss 0.0333842, acc 1
2020-02-08T02:39:00.511021: step 2030, loss 0.0816657, acc 0.953125
2020-02-08T02:39:00.630232: step 2031, loss 0.0218067, acc 1
2020-02-08T02:39:00.755163: step 2032, loss 0.0800249, acc 0.953125
2020-02-08T02:39:00.874817: step 2033, loss 0.0818268, acc 0.984375
2020-02-08T02:39:00.992528: step 2034, loss 0.0265065, acc 1
2020-02-08T02:39:01.111567: step 2035, loss 0.0967074, acc 0.984375
2020-02-08T02:39:01.227480: step 2036, loss 0.0718484, acc 0.984375
2020-02-08T02:39:01.344187: step 2037, loss 0.135212, acc 0.953125
2020-02-08T02:39:01.462212: step 2038, loss 0.0314897, acc 1
2020-02-08T02:39:01.581507: step 2039, loss 0.0202133, acc 1
2020-02-08T02:39:01.704264: step 2040, loss 0.0517066, acc 0.984375
2020-02-08T02:39:01.819997: step 2041, loss 0.061471, acc 0.984375
2020-02-08T02:39:01.935117: step 2042, loss 0.105899, acc 0.953125
2020-02-08T02:39:02.053648: step 2043, loss 0.0965978, acc 0.953125
2020-02-08T02:39:02.169331: step 2044, loss 0.0928086, acc 0.9375
2020-02-08T02:39:02.287774: step 2045, loss 0.143993, acc 0.953125
2020-02-08T02:39:02.405269: step 2046, loss 0.0557511, acc 0.984375
2020-02-08T02:39:02.522880: step 2047, loss 0.0925626, acc 0.96875
2020-02-08T02:39:02.640394: step 2048, loss 0.0440714, acc 0.984375
2020-02-08T02:39:02.763408: step 2049, loss 0.0844666, acc 0.953125
2020-02-08T02:39:02.882141: step 2050, loss 0.0621639, acc 0.984375
2020-02-08T02:39:02.999146: step 2051, loss 0.0721333, acc 0.96875
2020-02-08T02:39:03.117888: step 2052, loss 0.0791336, acc 0.953125
2020-02-08T02:39:03.236344: step 2053, loss 0.14751, acc 0.953125
2020-02-08T02:39:03.353001: step 2054, loss 0.0217387, acc 1
2020-02-08T02:39:03.473090: step 2055, loss 0.072289, acc 0.984375
2020-02-08T02:39:03.591848: step 2056, loss 0.0317424, acc 1
2020-02-08T02:39:03.711991: step 2057, loss 0.0404317, acc 0.984375
2020-02-08T02:39:03.830481: step 2058, loss 0.0405366, acc 1
2020-02-08T02:39:03.951297: step 2059, loss 0.121657, acc 0.953125
2020-02-08T02:39:04.075631: step 2060, loss 0.040144, acc 0.984375
2020-02-08T02:39:04.194664: step 2061, loss 0.0823809, acc 0.953125
2020-02-08T02:39:04.315070: step 2062, loss 0.0321184, acc 1
2020-02-08T02:39:04.433819: step 2063, loss 0.0413826, acc 0.984375
2020-02-08T02:39:04.554521: step 2064, loss 0.0380516, acc 0.984375
2020-02-08T02:39:04.670358: step 2065, loss 0.0554762, acc 0.984375
2020-02-08T02:39:04.792521: step 2066, loss 0.0591938, acc 0.96875
2020-02-08T02:39:04.911224: step 2067, loss 0.0874801, acc 0.96875
2020-02-08T02:39:05.030030: step 2068, loss 0.0971697, acc 0.953125
2020-02-08T02:39:05.147723: step 2069, loss 0.0353225, acc 0.984375
2020-02-08T02:39:05.265617: step 2070, loss 0.108162, acc 0.953125
2020-02-08T02:39:05.383893: step 2071, loss 0.0937772, acc 0.96875
2020-02-08T02:39:05.502226: step 2072, loss 0.0206186, acc 1
2020-02-08T02:39:05.618476: step 2073, loss 0.242467, acc 0.890625
2020-02-08T02:39:05.739021: step 2074, loss 0.0315599, acc 1
2020-02-08T02:39:05.863329: step 2075, loss 0.0142154, acc 1
2020-02-08T02:39:05.981701: step 2076, loss 0.0812617, acc 0.96875
2020-02-08T02:39:06.103070: step 2077, loss 0.0755689, acc 0.96875
2020-02-08T02:39:06.219131: step 2078, loss 0.0695018, acc 0.984375
2020-02-08T02:39:06.334697: step 2079, loss 0.0997874, acc 0.953125
2020-02-08T02:39:06.454806: step 2080, loss 0.105979, acc 0.984375
2020-02-08T02:39:06.571469: step 2081, loss 0.120913, acc 0.96875
2020-02-08T02:39:06.693893: step 2082, loss 0.0884775, acc 0.953125
2020-02-08T02:39:06.812885: step 2083, loss 0.116793, acc 0.953125
2020-02-08T02:39:06.930297: step 2084, loss 0.0479448, acc 0.984375
2020-02-08T02:39:07.047951: step 2085, loss 0.0619992, acc 0.984375
2020-02-08T02:39:07.167354: step 2086, loss 0.162595, acc 0.921875
2020-02-08T02:39:07.287752: step 2087, loss 0.0808395, acc 0.953125
2020-02-08T02:39:07.407467: step 2088, loss 0.0480671, acc 1
2020-02-08T02:39:07.525586: step 2089, loss 0.155311, acc 0.90625
2020-02-08T02:39:07.643378: step 2090, loss 0.113321, acc 0.9375
2020-02-08T02:39:07.764969: step 2091, loss 0.0610951, acc 0.953125
2020-02-08T02:39:07.880631: step 2092, loss 0.107567, acc 0.984375
2020-02-08T02:39:07.996675: step 2093, loss 0.115554, acc 0.96875
2020-02-08T02:39:08.114138: step 2094, loss 0.0729466, acc 0.953125
2020-02-08T02:39:08.233133: step 2095, loss 0.198932, acc 0.921875
2020-02-08T02:39:08.352531: step 2096, loss 0.146741, acc 0.953125
2020-02-08T02:39:08.470365: step 2097, loss 0.0713049, acc 0.96875
2020-02-08T02:39:08.588168: step 2098, loss 0.0879383, acc 0.984375
2020-02-08T02:39:08.711675: step 2099, loss 0.139461, acc 0.984375
2020-02-08T02:39:08.827560: step 2100, loss 0.0701071, acc 0.966667

Evaluation:
2020-02-08T02:39:09.017654: step 2100, loss 0.81218, acc 0.726079

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2100

2020-02-08T02:39:11.651102: step 2101, loss 0.114263, acc 0.96875
2020-02-08T02:39:11.774327: step 2102, loss 0.0294503, acc 1
2020-02-08T02:39:11.889327: step 2103, loss 0.03122, acc 1
2020-02-08T02:39:12.011709: step 2104, loss 0.0460435, acc 1
2020-02-08T02:39:12.127946: step 2105, loss 0.105126, acc 0.953125
2020-02-08T02:39:12.246255: step 2106, loss 0.0704595, acc 0.96875
2020-02-08T02:39:12.365268: step 2107, loss 0.0254474, acc 0.984375
2020-02-08T02:39:12.480299: step 2108, loss 0.0449628, acc 1
2020-02-08T02:39:12.597186: step 2109, loss 0.041248, acc 0.984375
2020-02-08T02:39:12.715127: step 2110, loss 0.0942154, acc 0.984375
2020-02-08T02:39:12.832245: step 2111, loss 0.0870325, acc 0.96875
2020-02-08T02:39:12.952146: step 2112, loss 0.0188595, acc 1
2020-02-08T02:39:13.069870: step 2113, loss 0.0390058, acc 1
2020-02-08T02:39:13.187849: step 2114, loss 0.0407304, acc 0.96875
2020-02-08T02:39:13.307146: step 2115, loss 0.04392, acc 0.984375
2020-02-08T02:39:13.425154: step 2116, loss 0.0433006, acc 1
2020-02-08T02:39:13.543069: step 2117, loss 0.0498922, acc 0.984375
2020-02-08T02:39:13.663340: step 2118, loss 0.0940268, acc 0.953125
2020-02-08T02:39:13.783478: step 2119, loss 0.057915, acc 0.984375
2020-02-08T02:39:13.902056: step 2120, loss 0.0377828, acc 0.984375
2020-02-08T02:39:14.018412: step 2121, loss 0.0235019, acc 1
2020-02-08T02:39:14.132835: step 2122, loss 0.0424275, acc 1
2020-02-08T02:39:14.251049: step 2123, loss 0.03701, acc 0.984375
2020-02-08T02:39:14.371324: step 2124, loss 0.044508, acc 0.984375
2020-02-08T02:39:14.486645: step 2125, loss 0.0209222, acc 1
2020-02-08T02:39:14.605482: step 2126, loss 0.0462247, acc 0.96875
2020-02-08T02:39:14.722205: step 2127, loss 0.0574398, acc 0.984375
2020-02-08T02:39:14.844696: step 2128, loss 0.0478664, acc 0.984375
2020-02-08T02:39:14.964889: step 2129, loss 0.0339838, acc 1
2020-02-08T02:39:15.154466: step 2130, loss 0.074904, acc 0.96875
2020-02-08T02:39:15.304901: step 2131, loss 0.0630899, acc 0.953125
2020-02-08T02:39:15.430353: step 2132, loss 0.0255153, acc 1
2020-02-08T02:39:15.572351: step 2133, loss 0.0497035, acc 0.984375
2020-02-08T02:39:15.709886: step 2134, loss 0.0493899, acc 0.984375
2020-02-08T02:39:15.850211: step 2135, loss 0.0300958, acc 1
2020-02-08T02:39:15.982597: step 2136, loss 0.00892775, acc 1
2020-02-08T02:39:16.120260: step 2137, loss 0.0239743, acc 1
2020-02-08T02:39:16.253252: step 2138, loss 0.122957, acc 0.96875
2020-02-08T02:39:16.385927: step 2139, loss 0.0462594, acc 0.984375
2020-02-08T02:39:16.516623: step 2140, loss 0.0408455, acc 0.984375
2020-02-08T02:39:16.648046: step 2141, loss 0.00985577, acc 1
2020-02-08T02:39:16.784544: step 2142, loss 0.050059, acc 0.984375
2020-02-08T02:39:16.914137: step 2143, loss 0.0923174, acc 0.96875
2020-02-08T02:39:17.043298: step 2144, loss 0.037458, acc 0.984375
2020-02-08T02:39:17.174218: step 2145, loss 0.0206761, acc 1
2020-02-08T02:39:17.304506: step 2146, loss 0.0456039, acc 1
2020-02-08T02:39:17.438081: step 2147, loss 0.0392788, acc 1
2020-02-08T02:39:17.569240: step 2148, loss 0.021576, acc 1
2020-02-08T02:39:17.702193: step 2149, loss 0.0227056, acc 0.984375
2020-02-08T02:39:17.832257: step 2150, loss 0.0602716, acc 0.96875
2020-02-08T02:39:17.967550: step 2151, loss 0.118051, acc 0.96875
2020-02-08T02:39:18.102196: step 2152, loss 0.0640595, acc 0.96875
2020-02-08T02:39:18.236766: step 2153, loss 0.0861903, acc 0.96875
2020-02-08T02:39:18.380722: step 2154, loss 0.0830693, acc 0.953125
2020-02-08T02:39:18.529598: step 2155, loss 0.0254585, acc 1
2020-02-08T02:39:18.671799: step 2156, loss 0.0391955, acc 0.984375
2020-02-08T02:39:18.820215: step 2157, loss 0.11302, acc 0.953125
2020-02-08T02:39:18.956774: step 2158, loss 0.0708138, acc 0.984375
2020-02-08T02:39:19.114168: step 2159, loss 0.0293451, acc 1
2020-02-08T02:39:19.270888: step 2160, loss 0.0473856, acc 0.96875
2020-02-08T02:39:19.418158: step 2161, loss 0.0169438, acc 1
2020-02-08T02:39:19.558829: step 2162, loss 0.0445098, acc 0.96875
2020-02-08T02:39:19.702618: step 2163, loss 0.0358489, acc 1
2020-02-08T02:39:19.846508: step 2164, loss 0.0528208, acc 0.96875
2020-02-08T02:39:19.991186: step 2165, loss 0.0642461, acc 0.96875
2020-02-08T02:39:20.137301: step 2166, loss 0.0362968, acc 1
2020-02-08T02:39:20.284623: step 2167, loss 0.07266, acc 0.984375
2020-02-08T02:39:20.426239: step 2168, loss 0.0609527, acc 0.984375
2020-02-08T02:39:20.564964: step 2169, loss 0.0415719, acc 1
2020-02-08T02:39:20.705943: step 2170, loss 0.0457828, acc 0.984375
2020-02-08T02:39:20.849933: step 2171, loss 0.050283, acc 0.984375
2020-02-08T02:39:20.988601: step 2172, loss 0.0767764, acc 0.953125
2020-02-08T02:39:21.128012: step 2173, loss 0.0603409, acc 0.96875
2020-02-08T02:39:21.247792: step 2174, loss 0.0538092, acc 0.96875
2020-02-08T02:39:21.506058: step 2175, loss 0.0356681, acc 1
2020-02-08T02:39:21.645880: step 2176, loss 0.0212253, acc 1
2020-02-08T02:39:21.791602: step 2177, loss 0.092965, acc 0.96875
2020-02-08T02:39:21.929363: step 2178, loss 0.0944133, acc 0.953125
2020-02-08T02:39:22.059915: step 2179, loss 0.085189, acc 0.984375
2020-02-08T02:39:22.197782: step 2180, loss 0.0508443, acc 0.984375
2020-02-08T02:39:22.336312: step 2181, loss 0.0623197, acc 0.984375
2020-02-08T02:39:22.478247: step 2182, loss 0.0640413, acc 0.984375
2020-02-08T02:39:22.613192: step 2183, loss 0.0374315, acc 0.984375
2020-02-08T02:39:22.756969: step 2184, loss 0.0633387, acc 0.984375
2020-02-08T02:39:22.893191: step 2185, loss 0.0603015, acc 0.96875
2020-02-08T02:39:23.033629: step 2186, loss 0.070196, acc 0.96875
2020-02-08T02:39:23.159621: step 2187, loss 0.126829, acc 0.953125
2020-02-08T02:39:23.288936: step 2188, loss 0.0643286, acc 0.984375
2020-02-08T02:39:23.417886: step 2189, loss 0.0175964, acc 1
2020-02-08T02:39:23.541789: step 2190, loss 0.0458888, acc 0.96875
2020-02-08T02:39:23.663884: step 2191, loss 0.114117, acc 0.9375
2020-02-08T02:39:23.789138: step 2192, loss 0.0301874, acc 0.984375
2020-02-08T02:39:23.912615: step 2193, loss 0.0401228, acc 1
2020-02-08T02:39:24.046476: step 2194, loss 0.0329387, acc 0.984375
2020-02-08T02:39:24.161773: step 2195, loss 0.0506135, acc 0.984375
2020-02-08T02:39:24.280724: step 2196, loss 0.0797887, acc 0.984375
2020-02-08T02:39:24.401991: step 2197, loss 0.0466006, acc 0.984375
2020-02-08T02:39:24.529260: step 2198, loss 0.115849, acc 0.96875
2020-02-08T02:39:24.650601: step 2199, loss 0.0321195, acc 1
2020-02-08T02:39:24.774945: step 2200, loss 0.0528768, acc 0.984375

Evaluation:
2020-02-08T02:39:24.966101: step 2200, loss 0.850581, acc 0.725141

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2200

2020-02-08T02:39:26.603062: step 2201, loss 0.0416406, acc 0.984375
2020-02-08T02:39:26.720655: step 2202, loss 0.0864806, acc 0.96875
2020-02-08T02:39:26.835313: step 2203, loss 0.088608, acc 0.96875
2020-02-08T02:39:26.951031: step 2204, loss 0.0277351, acc 1
2020-02-08T02:39:27.069207: step 2205, loss 0.0782727, acc 0.984375
2020-02-08T02:39:27.186571: step 2206, loss 0.0631931, acc 0.96875
2020-02-08T02:39:27.305965: step 2207, loss 0.0672365, acc 0.96875
2020-02-08T02:39:27.422735: step 2208, loss 0.0356779, acc 0.984375
2020-02-08T02:39:27.538985: step 2209, loss 0.0351369, acc 0.96875
2020-02-08T02:39:27.656224: step 2210, loss 0.0817065, acc 0.96875
2020-02-08T02:39:27.778758: step 2211, loss 0.064819, acc 0.984375
2020-02-08T02:39:27.896320: step 2212, loss 0.0472781, acc 0.984375
2020-02-08T02:39:28.012628: step 2213, loss 0.0256672, acc 0.984375
2020-02-08T02:39:28.129448: step 2214, loss 0.0830336, acc 0.953125
2020-02-08T02:39:28.246576: step 2215, loss 0.0854701, acc 0.984375
2020-02-08T02:39:28.363979: step 2216, loss 0.0235452, acc 1
2020-02-08T02:39:28.481332: step 2217, loss 0.130613, acc 0.953125
2020-02-08T02:39:28.597593: step 2218, loss 0.0242322, acc 1
2020-02-08T02:39:28.717590: step 2219, loss 0.0401412, acc 0.984375
2020-02-08T02:39:28.832044: step 2220, loss 0.0440981, acc 0.96875
2020-02-08T02:39:28.948484: step 2221, loss 0.0777284, acc 0.984375
2020-02-08T02:39:29.089009: step 2222, loss 0.06426, acc 0.984375
2020-02-08T02:39:29.215126: step 2223, loss 0.0261616, acc 0.984375
2020-02-08T02:39:29.330521: step 2224, loss 0.159948, acc 0.953125
2020-02-08T02:39:29.447359: step 2225, loss 0.0290932, acc 1
2020-02-08T02:39:29.564465: step 2226, loss 0.0237869, acc 1
2020-02-08T02:39:29.680714: step 2227, loss 0.0873439, acc 0.96875
2020-02-08T02:39:29.802763: step 2228, loss 0.0521412, acc 0.984375
2020-02-08T02:39:29.919299: step 2229, loss 0.0717774, acc 0.96875
2020-02-08T02:39:30.035846: step 2230, loss 0.00690082, acc 1
2020-02-08T02:39:30.153278: step 2231, loss 0.0156573, acc 1
2020-02-08T02:39:30.272726: step 2232, loss 0.0911114, acc 0.953125
2020-02-08T02:39:30.388955: step 2233, loss 0.01287, acc 1
2020-02-08T02:39:30.505871: step 2234, loss 0.0223719, acc 1
2020-02-08T02:39:30.626287: step 2235, loss 0.0762979, acc 0.953125
2020-02-08T02:39:30.743730: step 2236, loss 0.01648, acc 1
2020-02-08T02:39:30.863033: step 2237, loss 0.0729097, acc 0.96875
2020-02-08T02:39:30.979362: step 2238, loss 0.0482685, acc 0.984375
2020-02-08T02:39:31.096978: step 2239, loss 0.024482, acc 1
2020-02-08T02:39:31.216508: step 2240, loss 0.0715291, acc 0.96875
2020-02-08T02:39:31.331098: step 2241, loss 0.106723, acc 0.96875
2020-02-08T02:39:31.450386: step 2242, loss 0.0292747, acc 1
2020-02-08T02:39:31.569010: step 2243, loss 0.0491679, acc 0.984375
2020-02-08T02:39:31.685847: step 2244, loss 0.0539368, acc 0.96875
2020-02-08T02:39:31.806747: step 2245, loss 0.0417839, acc 0.984375
2020-02-08T02:39:31.925989: step 2246, loss 0.0796632, acc 0.953125
2020-02-08T02:39:32.040632: step 2247, loss 0.0525342, acc 0.984375
2020-02-08T02:39:32.158607: step 2248, loss 0.0564414, acc 0.96875
2020-02-08T02:39:32.278021: step 2249, loss 0.0694505, acc 0.984375
2020-02-08T02:39:32.389329: step 2250, loss 0.154229, acc 0.933333
2020-02-08T02:39:32.511475: step 2251, loss 0.0181359, acc 1
2020-02-08T02:39:32.625360: step 2252, loss 0.0222442, acc 1
2020-02-08T02:39:32.746573: step 2253, loss 0.0351422, acc 0.984375
2020-02-08T02:39:32.864263: step 2254, loss 0.0450205, acc 0.984375
2020-02-08T02:39:32.981356: step 2255, loss 0.0620842, acc 0.984375
2020-02-08T02:39:33.104879: step 2256, loss 0.0532606, acc 0.984375
2020-02-08T02:39:33.220697: step 2257, loss 0.0592389, acc 0.953125
2020-02-08T02:39:33.338351: step 2258, loss 0.0553858, acc 0.984375
2020-02-08T02:39:33.454768: step 2259, loss 0.0346491, acc 1
2020-02-08T02:39:33.571470: step 2260, loss 0.0148989, acc 1
2020-02-08T02:39:33.688577: step 2261, loss 0.090801, acc 0.96875
2020-02-08T02:39:33.811953: step 2262, loss 0.0582237, acc 0.96875
2020-02-08T02:39:33.928054: step 2263, loss 0.0366783, acc 0.984375
2020-02-08T02:39:34.044076: step 2264, loss 0.0316188, acc 0.984375
2020-02-08T02:39:34.162330: step 2265, loss 0.0369262, acc 1
2020-02-08T02:39:34.277663: step 2266, loss 0.0357652, acc 1
2020-02-08T02:39:34.394682: step 2267, loss 0.110234, acc 0.9375
2020-02-08T02:39:34.515003: step 2268, loss 0.0311103, acc 1
2020-02-08T02:39:34.632874: step 2269, loss 0.0917641, acc 0.953125
2020-02-08T02:39:34.755130: step 2270, loss 0.067166, acc 0.984375
2020-02-08T02:39:34.875837: step 2271, loss 0.0237273, acc 1
2020-02-08T02:39:34.994454: step 2272, loss 0.00693611, acc 1
2020-02-08T02:39:35.113330: step 2273, loss 0.0737028, acc 0.984375
2020-02-08T02:39:35.230223: step 2274, loss 0.0824837, acc 0.96875
2020-02-08T02:39:35.345207: step 2275, loss 0.0261438, acc 1
2020-02-08T02:39:35.464860: step 2276, loss 0.0627844, acc 0.96875
2020-02-08T02:39:35.582974: step 2277, loss 0.118636, acc 0.953125
2020-02-08T02:39:35.703363: step 2278, loss 0.0822503, acc 0.96875
2020-02-08T02:39:35.822067: step 2279, loss 0.0361142, acc 0.984375
2020-02-08T02:39:35.938434: step 2280, loss 0.0894071, acc 0.953125
2020-02-08T02:39:36.056726: step 2281, loss 0.0354925, acc 1
2020-02-08T02:39:36.176013: step 2282, loss 0.0562098, acc 0.96875
2020-02-08T02:39:36.292802: step 2283, loss 0.0420695, acc 0.984375
2020-02-08T02:39:36.411015: step 2284, loss 0.0150551, acc 1
2020-02-08T02:39:36.529221: step 2285, loss 0.0426036, acc 0.96875
2020-02-08T02:39:36.644433: step 2286, loss 0.0496288, acc 0.984375
2020-02-08T02:39:36.766928: step 2287, loss 0.049536, acc 0.96875
2020-02-08T02:39:36.883661: step 2288, loss 0.0564809, acc 0.984375
2020-02-08T02:39:37.001783: step 2289, loss 0.02826, acc 1
2020-02-08T02:39:37.119871: step 2290, loss 0.0097495, acc 1
2020-02-08T02:39:37.235337: step 2291, loss 0.0118781, acc 1
2020-02-08T02:39:37.352573: step 2292, loss 0.0296385, acc 0.984375
2020-02-08T02:39:37.469299: step 2293, loss 0.0699534, acc 0.96875
2020-02-08T02:39:37.587221: step 2294, loss 0.0180733, acc 1
2020-02-08T02:39:37.705020: step 2295, loss 0.0434702, acc 1
2020-02-08T02:39:37.820520: step 2296, loss 0.0502994, acc 0.96875
2020-02-08T02:39:37.935462: step 2297, loss 0.0808157, acc 0.96875
2020-02-08T02:39:38.052057: step 2298, loss 0.048586, acc 0.984375
2020-02-08T02:39:38.170937: step 2299, loss 0.0730111, acc 0.984375
2020-02-08T02:39:38.289170: step 2300, loss 0.0265196, acc 1

Evaluation:
2020-02-08T02:39:38.476337: step 2300, loss 0.900305, acc 0.727955

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2300

2020-02-08T02:39:39.975639: step 2301, loss 0.0325218, acc 0.984375
2020-02-08T02:39:40.092666: step 2302, loss 0.0660863, acc 0.984375
2020-02-08T02:39:40.214617: step 2303, loss 0.0428723, acc 0.984375
2020-02-08T02:39:40.331169: step 2304, loss 0.0449352, acc 0.984375
2020-02-08T02:39:40.448871: step 2305, loss 0.0957742, acc 0.984375
2020-02-08T02:39:40.568032: step 2306, loss 0.023883, acc 1
2020-02-08T02:39:40.683489: step 2307, loss 0.0212138, acc 1
2020-02-08T02:39:40.803695: step 2308, loss 0.026734, acc 1
2020-02-08T02:39:40.919063: step 2309, loss 0.0284899, acc 1
2020-02-08T02:39:41.036366: step 2310, loss 0.0464547, acc 0.984375
2020-02-08T02:39:41.153322: step 2311, loss 0.0442482, acc 1
2020-02-08T02:39:41.271065: step 2312, loss 0.0337018, acc 1
2020-02-08T02:39:41.388476: step 2313, loss 0.0257915, acc 1
2020-02-08T02:39:41.506801: step 2314, loss 0.0248924, acc 0.984375
2020-02-08T02:39:41.624002: step 2315, loss 0.0245553, acc 1
2020-02-08T02:39:41.741085: step 2316, loss 0.0140677, acc 1
2020-02-08T02:39:41.859248: step 2317, loss 0.143594, acc 0.9375
2020-02-08T02:39:41.975385: step 2318, loss 0.095489, acc 0.96875
2020-02-08T02:39:42.092195: step 2319, loss 0.117867, acc 0.953125
2020-02-08T02:39:42.209712: step 2320, loss 0.0471652, acc 0.984375
2020-02-08T02:39:42.324820: step 2321, loss 0.0710904, acc 0.96875
2020-02-08T02:39:42.439997: step 2322, loss 0.0948502, acc 0.953125
2020-02-08T02:39:42.559422: step 2323, loss 0.0899572, acc 0.96875
2020-02-08T02:39:42.675319: step 2324, loss 0.0590462, acc 0.96875
2020-02-08T02:39:42.794737: step 2325, loss 0.0347103, acc 0.984375
2020-02-08T02:39:42.911063: step 2326, loss 0.115115, acc 0.96875
2020-02-08T02:39:43.029747: step 2327, loss 0.0789912, acc 0.96875
2020-02-08T02:39:43.149801: step 2328, loss 0.084133, acc 0.984375
2020-02-08T02:39:43.268283: step 2329, loss 0.0140187, acc 1
2020-02-08T02:39:43.385107: step 2330, loss 0.0134463, acc 1
2020-02-08T02:39:43.504802: step 2331, loss 0.0356628, acc 0.984375
2020-02-08T02:39:43.623059: step 2332, loss 0.0471029, acc 0.984375
2020-02-08T02:39:43.738416: step 2333, loss 0.061472, acc 0.984375
2020-02-08T02:39:43.863461: step 2334, loss 0.0858586, acc 0.96875
2020-02-08T02:39:43.979153: step 2335, loss 0.0345178, acc 0.984375
2020-02-08T02:39:44.095542: step 2336, loss 0.0706212, acc 0.96875
2020-02-08T02:39:44.215472: step 2337, loss 0.0206487, acc 1
2020-02-08T02:39:44.332274: step 2338, loss 0.0305105, acc 1
2020-02-08T02:39:44.450252: step 2339, loss 0.0486127, acc 1
2020-02-08T02:39:44.568182: step 2340, loss 0.068152, acc 0.984375
2020-02-08T02:39:44.683803: step 2341, loss 0.0273274, acc 1
2020-02-08T02:39:44.805028: step 2342, loss 0.0839035, acc 0.96875
2020-02-08T02:39:44.920358: step 2343, loss 0.0664282, acc 0.984375
2020-02-08T02:39:45.040409: step 2344, loss 0.0127473, acc 1
2020-02-08T02:39:45.157445: step 2345, loss 0.0222854, acc 1
2020-02-08T02:39:45.275508: step 2346, loss 0.0522133, acc 0.96875
2020-02-08T02:39:45.390625: step 2347, loss 0.011325, acc 1
2020-02-08T02:39:45.509939: step 2348, loss 0.0168501, acc 1
2020-02-08T02:39:45.627335: step 2349, loss 0.0169508, acc 1
2020-02-08T02:39:45.749507: step 2350, loss 0.110471, acc 0.96875
2020-02-08T02:39:45.867354: step 2351, loss 0.06602, acc 0.96875
2020-02-08T02:39:45.983526: step 2352, loss 0.0174525, acc 1
2020-02-08T02:39:46.099264: step 2353, loss 0.027811, acc 0.984375
2020-02-08T02:39:46.215788: step 2354, loss 0.0592534, acc 0.984375
2020-02-08T02:39:46.331653: step 2355, loss 0.0419297, acc 0.984375
2020-02-08T02:39:46.447357: step 2356, loss 0.0162078, acc 1
2020-02-08T02:39:46.563421: step 2357, loss 0.0277834, acc 0.984375
2020-02-08T02:39:46.680794: step 2358, loss 0.0707662, acc 0.984375
2020-02-08T02:39:46.799939: step 2359, loss 0.0206347, acc 1
2020-02-08T02:39:46.915780: step 2360, loss 0.0134851, acc 1
2020-02-08T02:39:47.030748: step 2361, loss 0.0136994, acc 1
2020-02-08T02:39:47.146992: step 2362, loss 0.0541312, acc 0.984375
2020-02-08T02:39:47.263266: step 2363, loss 0.0382037, acc 1
2020-02-08T02:39:47.380249: step 2364, loss 0.0175332, acc 1
2020-02-08T02:39:47.498062: step 2365, loss 0.0438736, acc 0.96875
2020-02-08T02:39:47.617396: step 2366, loss 0.122929, acc 0.96875
2020-02-08T02:39:47.734813: step 2367, loss 0.0635827, acc 0.96875
2020-02-08T02:39:47.854220: step 2368, loss 0.0703409, acc 0.96875
2020-02-08T02:39:47.972282: step 2369, loss 0.0348766, acc 1
2020-02-08T02:39:48.088618: step 2370, loss 0.040266, acc 0.984375
2020-02-08T02:39:48.210848: step 2371, loss 0.0217856, acc 1
2020-02-08T02:39:48.329378: step 2372, loss 0.0448868, acc 0.984375
2020-02-08T02:39:48.445987: step 2373, loss 0.0381929, acc 1
2020-02-08T02:39:48.563300: step 2374, loss 0.0344736, acc 0.984375
2020-02-08T02:39:48.677528: step 2375, loss 0.0367495, acc 0.984375
2020-02-08T02:39:48.799238: step 2376, loss 0.0281149, acc 0.984375
2020-02-08T02:39:48.917999: step 2377, loss 0.106131, acc 0.984375
2020-02-08T02:39:49.033267: step 2378, loss 0.0609593, acc 0.96875
2020-02-08T02:39:49.151449: step 2379, loss 0.0525969, acc 0.984375
2020-02-08T02:39:49.269243: step 2380, loss 0.0526715, acc 0.984375
2020-02-08T02:39:49.384963: step 2381, loss 0.0221192, acc 1
2020-02-08T02:39:49.504563: step 2382, loss 0.021551, acc 1
2020-02-08T02:39:49.621594: step 2383, loss 0.0497449, acc 0.984375
2020-02-08T02:39:49.741849: step 2384, loss 0.0328929, acc 1
2020-02-08T02:39:49.857762: step 2385, loss 0.0579256, acc 0.96875
2020-02-08T02:39:49.974433: step 2386, loss 0.0365276, acc 0.984375
2020-02-08T02:39:50.091762: step 2387, loss 0.0341951, acc 1
2020-02-08T02:39:50.209070: step 2388, loss 0.0464408, acc 0.984375
2020-02-08T02:39:50.326055: step 2389, loss 0.0209895, acc 1
2020-02-08T02:39:50.443797: step 2390, loss 0.020111, acc 1
2020-02-08T02:39:50.564603: step 2391, loss 0.0528987, acc 0.96875
2020-02-08T02:39:50.681839: step 2392, loss 0.104979, acc 0.96875
2020-02-08T02:39:50.801307: step 2393, loss 0.0213064, acc 1
2020-02-08T02:39:50.921469: step 2394, loss 0.168959, acc 0.953125
2020-02-08T02:39:51.038432: step 2395, loss 0.0175157, acc 1
2020-02-08T02:39:51.154372: step 2396, loss 0.0251635, acc 1
2020-02-08T02:39:51.272549: step 2397, loss 0.066788, acc 0.984375
2020-02-08T02:39:51.387687: step 2398, loss 0.0693582, acc 0.984375
2020-02-08T02:39:51.654624: step 2399, loss 0.0605171, acc 0.984375
2020-02-08T02:39:51.782567: step 2400, loss 0.0700149, acc 0.966667

Evaluation:
2020-02-08T02:39:51.971357: step 2400, loss 0.916556, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2400

2020-02-08T02:39:54.488931: step 2401, loss 0.0207442, acc 1
2020-02-08T02:39:54.616888: step 2402, loss 0.0157161, acc 1
2020-02-08T02:39:54.737844: step 2403, loss 0.03429, acc 0.984375
2020-02-08T02:39:54.856836: step 2404, loss 0.0508043, acc 0.96875
2020-02-08T02:39:54.975786: step 2405, loss 0.0349976, acc 0.984375
2020-02-08T02:39:55.092410: step 2406, loss 0.0881769, acc 0.984375
2020-02-08T02:39:55.209176: step 2407, loss 0.0284064, acc 0.984375
2020-02-08T02:39:55.327960: step 2408, loss 0.0455854, acc 0.984375
2020-02-08T02:39:55.445725: step 2409, loss 0.0438248, acc 0.96875
2020-02-08T02:39:55.563255: step 2410, loss 0.021092, acc 1
2020-02-08T02:39:55.679308: step 2411, loss 0.065213, acc 0.953125
2020-02-08T02:39:55.803399: step 2412, loss 0.041129, acc 0.984375
2020-02-08T02:39:55.922799: step 2413, loss 0.026624, acc 0.984375
2020-02-08T02:39:56.037937: step 2414, loss 0.0061968, acc 1
2020-02-08T02:39:56.157379: step 2415, loss 0.00674887, acc 1
2020-02-08T02:39:56.273221: step 2416, loss 0.0175998, acc 1
2020-02-08T02:39:56.391785: step 2417, loss 0.0232965, acc 1
2020-02-08T02:39:56.510713: step 2418, loss 0.0344334, acc 0.984375
2020-02-08T02:39:56.627295: step 2419, loss 0.00912582, acc 1
2020-02-08T02:39:56.746636: step 2420, loss 0.130721, acc 0.9375
2020-02-08T02:39:56.866130: step 2421, loss 0.108791, acc 0.96875
2020-02-08T02:39:56.984259: step 2422, loss 0.0511694, acc 0.984375
2020-02-08T02:39:57.100504: step 2423, loss 0.0573062, acc 0.984375
2020-02-08T02:39:57.217009: step 2424, loss 0.0301392, acc 1
2020-02-08T02:39:57.333408: step 2425, loss 0.0181574, acc 1
2020-02-08T02:39:57.452319: step 2426, loss 0.036716, acc 0.984375
2020-02-08T02:39:57.573587: step 2427, loss 0.048079, acc 0.984375
2020-02-08T02:39:57.699216: step 2428, loss 0.00764982, acc 1
2020-02-08T02:39:57.816923: step 2429, loss 0.0406936, acc 0.984375
2020-02-08T02:39:57.935320: step 2430, loss 0.0232373, acc 0.984375
2020-02-08T02:39:58.052996: step 2431, loss 0.0617006, acc 0.96875
2020-02-08T02:39:58.168703: step 2432, loss 0.0393191, acc 1
2020-02-08T02:39:58.284650: step 2433, loss 0.0377834, acc 0.984375
2020-02-08T02:39:58.403962: step 2434, loss 0.0332884, acc 0.984375
2020-02-08T02:39:58.519371: step 2435, loss 0.0148115, acc 1
2020-02-08T02:39:58.634331: step 2436, loss 0.0100599, acc 1
2020-02-08T02:39:58.755457: step 2437, loss 0.0368305, acc 0.984375
2020-02-08T02:39:58.873505: step 2438, loss 0.0233435, acc 0.984375
2020-02-08T02:39:58.989633: step 2439, loss 0.00491122, acc 1
2020-02-08T02:39:59.104394: step 2440, loss 0.0228108, acc 1
2020-02-08T02:39:59.223189: step 2441, loss 0.0492135, acc 0.96875
2020-02-08T02:39:59.339380: step 2442, loss 0.0173132, acc 1
2020-02-08T02:39:59.457448: step 2443, loss 0.0092404, acc 1
2020-02-08T02:39:59.578050: step 2444, loss 0.0454279, acc 0.984375
2020-02-08T02:39:59.696073: step 2445, loss 0.0560086, acc 0.984375
2020-02-08T02:39:59.815186: step 2446, loss 0.00866734, acc 1
2020-02-08T02:39:59.929493: step 2447, loss 0.010983, acc 1
2020-02-08T02:40:00.048058: step 2448, loss 0.030721, acc 0.984375
2020-02-08T02:40:00.165436: step 2449, loss 0.0184396, acc 1
2020-02-08T02:40:00.281814: step 2450, loss 0.032988, acc 0.984375
2020-02-08T02:40:00.398988: step 2451, loss 0.0299755, acc 1
2020-02-08T02:40:00.515279: step 2452, loss 0.0276704, acc 0.984375
2020-02-08T02:40:00.631225: step 2453, loss 0.0280815, acc 0.984375
2020-02-08T02:40:00.750770: step 2454, loss 0.00418251, acc 1
2020-02-08T02:40:00.869976: step 2455, loss 0.0976906, acc 0.984375
2020-02-08T02:40:00.989357: step 2456, loss 0.0248826, acc 1
2020-02-08T02:40:01.105721: step 2457, loss 0.00914106, acc 1
2020-02-08T02:40:01.224109: step 2458, loss 0.0198256, acc 0.984375
2020-02-08T02:40:01.342076: step 2459, loss 0.0752885, acc 0.96875
2020-02-08T02:40:01.459608: step 2460, loss 0.0244982, acc 1
2020-02-08T02:40:01.576915: step 2461, loss 0.0223129, acc 1
2020-02-08T02:40:01.696649: step 2462, loss 0.0439534, acc 0.984375
2020-02-08T02:40:01.816846: step 2463, loss 0.0367627, acc 0.984375
2020-02-08T02:40:01.934031: step 2464, loss 0.0186292, acc 1
2020-02-08T02:40:02.051278: step 2465, loss 0.0341398, acc 0.984375
2020-02-08T02:40:02.167559: step 2466, loss 0.0158229, acc 1
2020-02-08T02:40:02.283577: step 2467, loss 0.0426722, acc 0.984375
2020-02-08T02:40:02.403363: step 2468, loss 0.0309014, acc 0.984375
2020-02-08T02:40:02.519829: step 2469, loss 0.00864337, acc 1
2020-02-08T02:40:02.635323: step 2470, loss 0.0281469, acc 0.984375
2020-02-08T02:40:02.758761: step 2471, loss 0.0282414, acc 1
2020-02-08T02:40:02.874444: step 2472, loss 0.0372637, acc 1
2020-02-08T02:40:02.988806: step 2473, loss 0.0274936, acc 1
2020-02-08T02:40:03.107678: step 2474, loss 0.0293292, acc 0.984375
2020-02-08T02:40:03.227541: step 2475, loss 0.00627683, acc 1
2020-02-08T02:40:03.348581: step 2476, loss 0.00856629, acc 1
2020-02-08T02:40:03.467344: step 2477, loss 0.0199931, acc 1
2020-02-08T02:40:03.590673: step 2478, loss 0.00303431, acc 1
2020-02-08T02:40:03.709589: step 2479, loss 0.0311012, acc 1
2020-02-08T02:40:03.826762: step 2480, loss 0.0205525, acc 1
2020-02-08T02:40:03.939716: step 2481, loss 0.06851, acc 0.984375
2020-02-08T02:40:04.060467: step 2482, loss 0.0126543, acc 1
2020-02-08T02:40:04.175331: step 2483, loss 0.0245294, acc 0.984375
2020-02-08T02:40:04.297809: step 2484, loss 0.0688315, acc 0.984375
2020-02-08T02:40:04.416325: step 2485, loss 0.0125709, acc 1
2020-02-08T02:40:04.531972: step 2486, loss 0.0726038, acc 0.96875
2020-02-08T02:40:04.648923: step 2487, loss 0.0602529, acc 0.984375
2020-02-08T02:40:04.769105: step 2488, loss 0.0124442, acc 1
2020-02-08T02:40:04.884814: step 2489, loss 0.0210683, acc 1
2020-02-08T02:40:04.999339: step 2490, loss 0.0171339, acc 1
2020-02-08T02:40:05.119734: step 2491, loss 0.062484, acc 0.984375
2020-02-08T02:40:05.236396: step 2492, loss 0.0463842, acc 0.984375
2020-02-08T02:40:05.356864: step 2493, loss 0.0164045, acc 1
2020-02-08T02:40:05.476074: step 2494, loss 0.0255879, acc 1
2020-02-08T02:40:05.593171: step 2495, loss 0.0513294, acc 0.984375
2020-02-08T02:40:05.714969: step 2496, loss 0.0841897, acc 0.96875
2020-02-08T02:40:05.833250: step 2497, loss 0.0190084, acc 1
2020-02-08T02:40:05.950002: step 2498, loss 0.0223319, acc 1
2020-02-08T02:40:06.071688: step 2499, loss 0.0206201, acc 1
2020-02-08T02:40:06.190068: step 2500, loss 0.0241255, acc 1

Evaluation:
2020-02-08T02:40:06.379139: step 2500, loss 0.951852, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2500

2020-02-08T02:40:08.408802: step 2501, loss 0.0913288, acc 0.96875
2020-02-08T02:40:08.526809: step 2502, loss 0.0910324, acc 0.96875
2020-02-08T02:40:08.645203: step 2503, loss 0.0563887, acc 0.96875
2020-02-08T02:40:08.767028: step 2504, loss 0.0314298, acc 0.984375
2020-02-08T02:40:08.885244: step 2505, loss 0.0226076, acc 1
2020-02-08T02:40:09.001029: step 2506, loss 0.0473522, acc 0.984375
2020-02-08T02:40:09.122733: step 2507, loss 0.0206826, acc 0.984375
2020-02-08T02:40:09.239036: step 2508, loss 0.0169993, acc 1
2020-02-08T02:40:09.356438: step 2509, loss 0.00816312, acc 1
2020-02-08T02:40:09.471698: step 2510, loss 0.0251488, acc 1
2020-02-08T02:40:09.588189: step 2511, loss 0.0140612, acc 1
2020-02-08T02:40:09.707711: step 2512, loss 0.0306605, acc 0.984375
2020-02-08T02:40:09.824986: step 2513, loss 0.00613171, acc 1
2020-02-08T02:40:09.939598: step 2514, loss 0.0101545, acc 1
2020-02-08T02:40:10.056336: step 2515, loss 0.0249882, acc 1
2020-02-08T02:40:10.172831: step 2516, loss 0.00984688, acc 1
2020-02-08T02:40:10.287955: step 2517, loss 0.0413281, acc 0.984375
2020-02-08T02:40:10.407314: step 2518, loss 0.0315336, acc 0.984375
2020-02-08T02:40:10.524850: step 2519, loss 0.0919237, acc 0.96875
2020-02-08T02:40:10.641611: step 2520, loss 0.0132223, acc 1
2020-02-08T02:40:10.766887: step 2521, loss 0.0412403, acc 0.96875
2020-02-08T02:40:10.885323: step 2522, loss 0.026758, acc 0.984375
2020-02-08T02:40:11.003593: step 2523, loss 0.0056191, acc 1
2020-02-08T02:40:11.123079: step 2524, loss 0.0343914, acc 1
2020-02-08T02:40:11.237875: step 2525, loss 0.0217122, acc 0.984375
2020-02-08T02:40:11.360835: step 2526, loss 0.058064, acc 0.96875
2020-02-08T02:40:11.479093: step 2527, loss 0.0277175, acc 0.984375
2020-02-08T02:40:11.594559: step 2528, loss 0.00551746, acc 1
2020-02-08T02:40:11.713887: step 2529, loss 0.0192307, acc 1
2020-02-08T02:40:11.831388: step 2530, loss 0.0336522, acc 1
2020-02-08T02:40:11.946774: step 2531, loss 0.0318602, acc 1
2020-02-08T02:40:12.063390: step 2532, loss 0.0549611, acc 0.96875
2020-02-08T02:40:12.178995: step 2533, loss 0.00953796, acc 1
2020-02-08T02:40:12.297468: step 2534, loss 0.0353037, acc 0.984375
2020-02-08T02:40:12.417231: step 2535, loss 0.0499881, acc 0.96875
2020-02-08T02:40:12.533633: step 2536, loss 0.0840292, acc 0.984375
2020-02-08T02:40:12.651024: step 2537, loss 0.011071, acc 1
2020-02-08T02:40:12.774434: step 2538, loss 0.0422242, acc 0.96875
2020-02-08T02:40:12.891299: step 2539, loss 0.0218553, acc 1
2020-02-08T02:40:13.015495: step 2540, loss 0.043539, acc 0.984375
2020-02-08T02:40:13.135414: step 2541, loss 0.0506261, acc 0.984375
2020-02-08T02:40:13.252737: step 2542, loss 0.0574307, acc 0.96875
2020-02-08T02:40:13.371843: step 2543, loss 0.0539445, acc 0.96875
2020-02-08T02:40:13.486505: step 2544, loss 0.0160942, acc 1
2020-02-08T02:40:13.604263: step 2545, loss 0.0352656, acc 0.984375
2020-02-08T02:40:13.722786: step 2546, loss 0.056906, acc 0.984375
2020-02-08T02:40:13.838402: step 2547, loss 0.0375796, acc 0.984375
2020-02-08T02:40:13.957810: step 2548, loss 0.0738953, acc 0.96875
2020-02-08T02:40:14.073757: step 2549, loss 0.0505877, acc 0.984375
2020-02-08T02:40:14.187507: step 2550, loss 0.0192045, acc 1
2020-02-08T02:40:14.308542: step 2551, loss 0.0183634, acc 1
2020-02-08T02:40:14.429932: step 2552, loss 0.0569478, acc 0.96875
2020-02-08T02:40:14.546670: step 2553, loss 0.00630276, acc 1
2020-02-08T02:40:14.665830: step 2554, loss 0.0122012, acc 1
2020-02-08T02:40:14.785994: step 2555, loss 0.0241594, acc 0.984375
2020-02-08T02:40:14.907426: step 2556, loss 0.0057307, acc 1
2020-02-08T02:40:15.029746: step 2557, loss 0.0937237, acc 0.984375
2020-02-08T02:40:15.146485: step 2558, loss 0.00697036, acc 1
2020-02-08T02:40:15.265353: step 2559, loss 0.0199636, acc 1
2020-02-08T02:40:15.380984: step 2560, loss 0.0126516, acc 1
2020-02-08T02:40:15.497044: step 2561, loss 0.0504458, acc 0.96875
2020-02-08T02:40:15.617334: step 2562, loss 0.0322271, acc 0.984375
2020-02-08T02:40:15.736296: step 2563, loss 0.0435316, acc 0.984375
2020-02-08T02:40:15.855999: step 2564, loss 0.015768, acc 1
2020-02-08T02:40:15.973718: step 2565, loss 0.0042036, acc 1
2020-02-08T02:40:16.088358: step 2566, loss 0.0243114, acc 0.984375
2020-02-08T02:40:16.207107: step 2567, loss 0.010527, acc 1
2020-02-08T02:40:16.324591: step 2568, loss 0.0145879, acc 1
2020-02-08T02:40:16.444517: step 2569, loss 0.00688679, acc 1
2020-02-08T02:40:16.565236: step 2570, loss 0.0252416, acc 0.984375
2020-02-08T02:40:16.684051: step 2571, loss 0.0109385, acc 1
2020-02-08T02:40:16.812909: step 2572, loss 0.0264656, acc 1
2020-02-08T02:40:16.930618: step 2573, loss 0.0315052, acc 0.984375
2020-02-08T02:40:17.046387: step 2574, loss 0.0087905, acc 1
2020-02-08T02:40:17.167118: step 2575, loss 0.036948, acc 0.96875
2020-02-08T02:40:17.283615: step 2576, loss 0.0247755, acc 1
2020-02-08T02:40:17.399687: step 2577, loss 0.0222506, acc 0.984375
2020-02-08T02:40:17.518487: step 2578, loss 0.00912577, acc 1
2020-02-08T02:40:17.635332: step 2579, loss 0.00853114, acc 1
2020-02-08T02:40:17.754756: step 2580, loss 0.0349358, acc 1
2020-02-08T02:40:17.875100: step 2581, loss 0.0138164, acc 1
2020-02-08T02:40:17.989752: step 2582, loss 0.0817199, acc 0.984375
2020-02-08T02:40:18.109355: step 2583, loss 0.027574, acc 1
2020-02-08T02:40:18.225243: step 2584, loss 0.0208067, acc 1
2020-02-08T02:40:18.345639: step 2585, loss 0.0341694, acc 0.984375
2020-02-08T02:40:18.462834: step 2586, loss 0.045716, acc 0.984375
2020-02-08T02:40:18.581430: step 2587, loss 0.0285968, acc 1
2020-02-08T02:40:18.702342: step 2588, loss 0.136171, acc 0.953125
2020-02-08T02:40:18.822225: step 2589, loss 0.0396093, acc 0.984375
2020-02-08T02:40:18.937822: step 2590, loss 0.0318203, acc 0.984375
2020-02-08T02:40:19.053788: step 2591, loss 0.0474104, acc 0.984375
2020-02-08T02:40:19.172823: step 2592, loss 0.0189917, acc 1
2020-02-08T02:40:19.288468: step 2593, loss 0.0833274, acc 0.96875
2020-02-08T02:40:19.410160: step 2594, loss 0.0222367, acc 1
2020-02-08T02:40:19.525672: step 2595, loss 0.0532615, acc 0.984375
2020-02-08T02:40:19.642755: step 2596, loss 0.0353984, acc 0.984375
2020-02-08T02:40:19.765526: step 2597, loss 0.0487076, acc 0.96875
2020-02-08T02:40:19.880569: step 2598, loss 0.00951581, acc 1
2020-02-08T02:40:19.997007: step 2599, loss 0.0938277, acc 0.984375
2020-02-08T02:40:20.117059: step 2600, loss 0.0451867, acc 0.984375

Evaluation:
2020-02-08T02:40:20.307969: step 2600, loss 0.969201, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2600

2020-02-08T02:40:21.764874: step 2601, loss 0.0132347, acc 1
2020-02-08T02:40:21.882282: step 2602, loss 0.0275598, acc 0.984375
2020-02-08T02:40:22.020202: step 2603, loss 0.0169542, acc 1
2020-02-08T02:40:22.156503: step 2604, loss 0.0445357, acc 0.984375
2020-02-08T02:40:22.276364: step 2605, loss 0.0274096, acc 0.984375
2020-02-08T02:40:22.392629: step 2606, loss 0.0274977, acc 1
2020-02-08T02:40:22.513378: step 2607, loss 0.0391321, acc 0.984375
2020-02-08T02:40:22.631580: step 2608, loss 0.00400342, acc 1
2020-02-08T02:40:22.751383: step 2609, loss 0.0296019, acc 0.984375
2020-02-08T02:40:22.871839: step 2610, loss 0.0128814, acc 1
2020-02-08T02:40:22.986792: step 2611, loss 0.0106951, acc 1
2020-02-08T02:40:23.104687: step 2612, loss 0.00816017, acc 1
2020-02-08T02:40:23.223804: step 2613, loss 0.0305485, acc 0.984375
2020-02-08T02:40:23.339316: step 2614, loss 0.0215921, acc 1
2020-02-08T02:40:23.459877: step 2615, loss 0.0197098, acc 0.984375
2020-02-08T02:40:23.576388: step 2616, loss 0.0281395, acc 1
2020-02-08T02:40:23.692206: step 2617, loss 0.00952471, acc 1
2020-02-08T02:40:23.813846: step 2618, loss 0.0176224, acc 1
2020-02-08T02:40:23.931048: step 2619, loss 0.0508463, acc 0.984375
2020-02-08T02:40:24.047023: step 2620, loss 0.0409705, acc 0.984375
2020-02-08T02:40:24.165513: step 2621, loss 0.0385308, acc 0.984375
2020-02-08T02:40:24.281408: step 2622, loss 0.0120614, acc 1
2020-02-08T02:40:24.397848: step 2623, loss 0.0230679, acc 0.984375
2020-02-08T02:40:24.515635: step 2624, loss 0.0132593, acc 1
2020-02-08T02:40:24.633245: step 2625, loss 0.0169788, acc 1
2020-02-08T02:40:24.755266: step 2626, loss 0.0268384, acc 1
2020-02-08T02:40:24.872913: step 2627, loss 0.00621003, acc 1
2020-02-08T02:40:24.989470: step 2628, loss 0.0350795, acc 0.984375
2020-02-08T02:40:25.110434: step 2629, loss 0.035699, acc 0.984375
2020-02-08T02:40:25.228435: step 2630, loss 0.0320257, acc 0.984375
2020-02-08T02:40:25.346676: step 2631, loss 0.0154109, acc 1
2020-02-08T02:40:25.465272: step 2632, loss 0.0303518, acc 0.984375
2020-02-08T02:40:25.581641: step 2633, loss 0.0401016, acc 0.984375
2020-02-08T02:40:25.702704: step 2634, loss 0.0239034, acc 1
2020-02-08T02:40:25.820436: step 2635, loss 0.0433477, acc 0.96875
2020-02-08T02:40:25.938262: step 2636, loss 0.0389557, acc 0.984375
2020-02-08T02:40:26.051105: step 2637, loss 0.0545985, acc 0.984375
2020-02-08T02:40:26.170894: step 2638, loss 0.0168409, acc 1
2020-02-08T02:40:26.286644: step 2639, loss 0.0447447, acc 0.96875
2020-02-08T02:40:26.406011: step 2640, loss 0.0239464, acc 0.984375
2020-02-08T02:40:26.526290: step 2641, loss 0.0487405, acc 0.984375
2020-02-08T02:40:26.642415: step 2642, loss 0.00644324, acc 1
2020-02-08T02:40:26.765431: step 2643, loss 0.0076216, acc 1
2020-02-08T02:40:26.882470: step 2644, loss 0.0413208, acc 0.984375
2020-02-08T02:40:27.000654: step 2645, loss 0.0243558, acc 1
2020-02-08T02:40:27.117322: step 2646, loss 0.0193457, acc 1
2020-02-08T02:40:27.234214: step 2647, loss 0.0231627, acc 1
2020-02-08T02:40:27.352744: step 2648, loss 0.0135315, acc 1
2020-02-08T02:40:27.469736: step 2649, loss 0.00920671, acc 1
2020-02-08T02:40:27.586779: step 2650, loss 0.00699607, acc 1
2020-02-08T02:40:27.706605: step 2651, loss 0.0204717, acc 1
2020-02-08T02:40:27.825475: step 2652, loss 0.0838345, acc 0.96875
2020-02-08T02:40:27.943161: step 2653, loss 0.0171237, acc 1
2020-02-08T02:40:28.061000: step 2654, loss 0.00955265, acc 1
2020-02-08T02:40:28.178502: step 2655, loss 0.0324473, acc 0.984375
2020-02-08T02:40:28.294630: step 2656, loss 0.0183824, acc 1
2020-02-08T02:40:28.412340: step 2657, loss 0.0169839, acc 1
2020-02-08T02:40:28.529024: step 2658, loss 0.0190375, acc 1
2020-02-08T02:40:28.646604: step 2659, loss 0.0319287, acc 0.984375
2020-02-08T02:40:28.768562: step 2660, loss 0.0332037, acc 0.984375
2020-02-08T02:40:28.883525: step 2661, loss 0.0453935, acc 0.984375
2020-02-08T02:40:29.008446: step 2662, loss 0.023257, acc 1
2020-02-08T02:40:29.126960: step 2663, loss 0.0702396, acc 0.96875
2020-02-08T02:40:29.241151: step 2664, loss 0.022608, acc 1
2020-02-08T02:40:29.359149: step 2665, loss 0.0297364, acc 0.984375
2020-02-08T02:40:29.475984: step 2666, loss 0.0464534, acc 0.984375
2020-02-08T02:40:29.591060: step 2667, loss 0.0397591, acc 0.984375
2020-02-08T02:40:29.708653: step 2668, loss 0.0115066, acc 1
2020-02-08T02:40:29.826228: step 2669, loss 0.0368085, acc 0.984375
2020-02-08T02:40:29.940163: step 2670, loss 0.0518342, acc 0.96875
2020-02-08T02:40:30.058396: step 2671, loss 0.00638123, acc 1
2020-02-08T02:40:30.175829: step 2672, loss 0.0181426, acc 1
2020-02-08T02:40:30.294165: step 2673, loss 0.0313869, acc 0.984375
2020-02-08T02:40:30.411822: step 2674, loss 0.0369891, acc 0.984375
2020-02-08T02:40:30.530034: step 2675, loss 0.0259859, acc 0.984375
2020-02-08T02:40:30.646185: step 2676, loss 0.0177081, acc 0.984375
2020-02-08T02:40:30.766640: step 2677, loss 0.0218266, acc 1
2020-02-08T02:40:30.889729: step 2678, loss 0.0303402, acc 0.984375
2020-02-08T02:40:31.006132: step 2679, loss 0.0313164, acc 0.984375
2020-02-08T02:40:31.123702: step 2680, loss 0.0103426, acc 1
2020-02-08T02:40:31.239958: step 2681, loss 0.0579109, acc 0.984375
2020-02-08T02:40:31.356311: step 2682, loss 0.0120007, acc 1
2020-02-08T02:40:31.474292: step 2683, loss 0.00913712, acc 1
2020-02-08T02:40:31.588808: step 2684, loss 0.0267169, acc 1
2020-02-08T02:40:31.705794: step 2685, loss 0.0127134, acc 1
2020-02-08T02:40:31.825996: step 2686, loss 0.032725, acc 0.984375
2020-02-08T02:40:31.943066: step 2687, loss 0.0113581, acc 1
2020-02-08T02:40:32.065440: step 2688, loss 0.0759288, acc 0.984375
2020-02-08T02:40:32.182313: step 2689, loss 0.0174753, acc 1
2020-02-08T02:40:32.301047: step 2690, loss 0.013003, acc 1
2020-02-08T02:40:32.421374: step 2691, loss 0.0503467, acc 0.96875
2020-02-08T02:40:32.538841: step 2692, loss 0.0369193, acc 1
2020-02-08T02:40:32.658372: step 2693, loss 0.0116348, acc 1
2020-02-08T02:40:32.780070: step 2694, loss 0.0809866, acc 0.96875
2020-02-08T02:40:32.900951: step 2695, loss 0.0191759, acc 1
2020-02-08T02:40:33.017424: step 2696, loss 0.0888437, acc 0.96875
2020-02-08T02:40:33.131696: step 2697, loss 0.0692491, acc 0.96875
2020-02-08T02:40:33.251070: step 2698, loss 0.0370217, acc 1
2020-02-08T02:40:33.367399: step 2699, loss 0.0199203, acc 1
2020-02-08T02:40:33.482194: step 2700, loss 0.0439479, acc 0.966667

Evaluation:
2020-02-08T02:40:33.667211: step 2700, loss 1.00022, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2700

2020-02-08T02:40:35.226705: step 2701, loss 0.0134322, acc 1
2020-02-08T02:40:35.342901: step 2702, loss 0.0250119, acc 1
2020-02-08T02:40:35.460787: step 2703, loss 0.0475692, acc 0.984375
2020-02-08T02:40:35.578359: step 2704, loss 0.0513276, acc 0.984375
2020-02-08T02:40:35.695743: step 2705, loss 0.0198366, acc 1
2020-02-08T02:40:35.815541: step 2706, loss 0.0184461, acc 1
2020-02-08T02:40:35.934047: step 2707, loss 0.0211167, acc 0.984375
2020-02-08T02:40:36.051364: step 2708, loss 0.0169657, acc 1
2020-02-08T02:40:36.167463: step 2709, loss 0.0174699, acc 1
2020-02-08T02:40:36.283695: step 2710, loss 0.0138688, acc 1
2020-02-08T02:40:36.400123: step 2711, loss 0.0377446, acc 0.984375
2020-02-08T02:40:36.517890: step 2712, loss 0.0224259, acc 0.984375
2020-02-08T02:40:36.633641: step 2713, loss 0.00758458, acc 1
2020-02-08T02:40:36.752097: step 2714, loss 0.0122391, acc 1
2020-02-08T02:40:36.869100: step 2715, loss 0.0385324, acc 0.984375
2020-02-08T02:40:36.985722: step 2716, loss 0.0117763, acc 1
2020-02-08T02:40:37.103780: step 2717, loss 0.0113655, acc 1
2020-02-08T02:40:37.219841: step 2718, loss 0.0213083, acc 1
2020-02-08T02:40:37.338088: step 2719, loss 0.0237095, acc 1
2020-02-08T02:40:37.456897: step 2720, loss 0.0154492, acc 1
2020-02-08T02:40:37.574866: step 2721, loss 0.0106336, acc 1
2020-02-08T02:40:37.690709: step 2722, loss 0.0166035, acc 1
2020-02-08T02:40:37.812341: step 2723, loss 0.0072132, acc 1
2020-02-08T02:40:37.928347: step 2724, loss 0.0171422, acc 1
2020-02-08T02:40:38.042468: step 2725, loss 0.026483, acc 0.984375
2020-02-08T02:40:38.157496: step 2726, loss 0.0460181, acc 0.984375
2020-02-08T02:40:38.271864: step 2727, loss 0.0119213, acc 1
2020-02-08T02:40:38.388914: step 2728, loss 0.0132514, acc 1
2020-02-08T02:40:38.507244: step 2729, loss 0.131899, acc 0.953125
2020-02-08T02:40:38.623057: step 2730, loss 0.0334348, acc 0.984375
2020-02-08T02:40:38.741063: step 2731, loss 0.0246258, acc 0.984375
2020-02-08T02:40:38.855795: step 2732, loss 0.00699928, acc 1
2020-02-08T02:40:38.972236: step 2733, loss 0.0394379, acc 0.96875
2020-02-08T02:40:39.090845: step 2734, loss 0.0762082, acc 0.96875
2020-02-08T02:40:39.212770: step 2735, loss 0.00656915, acc 1
2020-02-08T02:40:39.327900: step 2736, loss 0.0107277, acc 1
2020-02-08T02:40:39.443757: step 2737, loss 0.0231083, acc 0.984375
2020-02-08T02:40:39.561112: step 2738, loss 0.00734219, acc 1
2020-02-08T02:40:39.677290: step 2739, loss 0.0169527, acc 1
2020-02-08T02:40:39.792743: step 2740, loss 0.00625649, acc 1
2020-02-08T02:40:39.910225: step 2741, loss 0.0563069, acc 0.984375
2020-02-08T02:40:40.026678: step 2742, loss 0.00734189, acc 1
2020-02-08T02:40:40.143849: step 2743, loss 0.0150913, acc 1
2020-02-08T02:40:40.261364: step 2744, loss 0.0603953, acc 0.984375
2020-02-08T02:40:40.380336: step 2745, loss 0.0280752, acc 0.984375
2020-02-08T02:40:40.495150: step 2746, loss 0.0254383, acc 1
2020-02-08T02:40:40.609400: step 2747, loss 0.0481608, acc 0.984375
2020-02-08T02:40:40.726939: step 2748, loss 0.0449834, acc 0.96875
2020-02-08T02:40:40.842106: step 2749, loss 0.00877615, acc 1
2020-02-08T02:40:40.958635: step 2750, loss 0.0486192, acc 0.984375
2020-02-08T02:40:41.074304: step 2751, loss 0.046072, acc 0.96875
2020-02-08T02:40:41.189741: step 2752, loss 0.00793024, acc 1
2020-02-08T02:40:41.306527: step 2753, loss 0.0190562, acc 1
2020-02-08T02:40:41.424267: step 2754, loss 0.0168253, acc 1
2020-02-08T02:40:41.539752: step 2755, loss 0.0431676, acc 0.984375
2020-02-08T02:40:41.656659: step 2756, loss 0.0228905, acc 1
2020-02-08T02:40:41.773855: step 2757, loss 0.011202, acc 1
2020-02-08T02:40:41.890511: step 2758, loss 0.00349759, acc 1
2020-02-08T02:40:42.011513: step 2759, loss 0.0152879, acc 1
2020-02-08T02:40:42.128809: step 2760, loss 0.0231045, acc 1
2020-02-08T02:40:42.246066: step 2761, loss 0.0111859, acc 1
2020-02-08T02:40:42.364811: step 2762, loss 0.0202308, acc 1
2020-02-08T02:40:42.482437: step 2763, loss 0.0615503, acc 0.984375
2020-02-08T02:40:42.600461: step 2764, loss 0.0101465, acc 1
2020-02-08T02:40:42.717191: step 2765, loss 0.0101164, acc 1
2020-02-08T02:40:42.834867: step 2766, loss 0.0322423, acc 0.984375
2020-02-08T02:40:42.952328: step 2767, loss 0.0220391, acc 0.984375
2020-02-08T02:40:43.069085: step 2768, loss 0.0132374, acc 1
2020-02-08T02:40:43.184891: step 2769, loss 0.00227694, acc 1
2020-02-08T02:40:43.304200: step 2770, loss 0.031046, acc 0.984375
2020-02-08T02:40:43.422202: step 2771, loss 0.0519806, acc 0.96875
2020-02-08T02:40:43.537037: step 2772, loss 0.136404, acc 0.953125
2020-02-08T02:40:43.654196: step 2773, loss 0.0300465, acc 0.984375
2020-02-08T02:40:43.775757: step 2774, loss 0.0221362, acc 1
2020-02-08T02:40:43.892507: step 2775, loss 0.0365099, acc 0.984375
2020-02-08T02:40:44.011693: step 2776, loss 0.0103914, acc 1
2020-02-08T02:40:44.130044: step 2777, loss 0.0063793, acc 1
2020-02-08T02:40:44.245184: step 2778, loss 0.0342989, acc 0.984375
2020-02-08T02:40:44.364385: step 2779, loss 0.055917, acc 0.984375
2020-02-08T02:40:44.482040: step 2780, loss 0.0185567, acc 1
2020-02-08T02:40:44.600999: step 2781, loss 0.0152836, acc 1
2020-02-08T02:40:44.719290: step 2782, loss 0.0389469, acc 0.96875
2020-02-08T02:40:44.835525: step 2783, loss 0.0238504, acc 0.984375
2020-02-08T02:40:44.952230: step 2784, loss 0.016062, acc 1
2020-02-08T02:40:45.072230: step 2785, loss 0.00930581, acc 1
2020-02-08T02:40:45.186314: step 2786, loss 0.0436951, acc 0.984375
2020-02-08T02:40:45.305885: step 2787, loss 0.0148128, acc 1
2020-02-08T02:40:45.423929: step 2788, loss 0.00664173, acc 1
2020-02-08T02:40:45.540653: step 2789, loss 0.00934522, acc 1
2020-02-08T02:40:45.656856: step 2790, loss 0.0682916, acc 0.984375
2020-02-08T02:40:45.775908: step 2791, loss 0.0552179, acc 0.984375
2020-02-08T02:40:45.890790: step 2792, loss 0.0196301, acc 1
2020-02-08T02:40:46.006460: step 2793, loss 0.0228598, acc 1
2020-02-08T02:40:46.120486: step 2794, loss 0.0118933, acc 1
2020-02-08T02:40:46.234425: step 2795, loss 0.0206778, acc 1
2020-02-08T02:40:46.353035: step 2796, loss 0.0113761, acc 1
2020-02-08T02:40:46.474506: step 2797, loss 0.0355757, acc 0.984375
2020-02-08T02:40:46.589863: step 2798, loss 0.0467961, acc 0.984375
2020-02-08T02:40:46.706444: step 2799, loss 0.0337966, acc 0.984375
2020-02-08T02:40:46.825483: step 2800, loss 0.015923, acc 1

Evaluation:
2020-02-08T02:40:47.013149: step 2800, loss 1.05552, acc 0.719512

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2800

2020-02-08T02:40:48.494029: step 2801, loss 0.0175661, acc 1
2020-02-08T02:40:48.610119: step 2802, loss 0.0136449, acc 1
2020-02-08T02:40:48.728468: step 2803, loss 0.0103032, acc 1
2020-02-08T02:40:48.845102: step 2804, loss 0.011485, acc 1
2020-02-08T02:40:48.962638: step 2805, loss 0.16579, acc 0.953125
2020-02-08T02:40:49.079398: step 2806, loss 0.0220109, acc 0.984375
2020-02-08T02:40:49.195490: step 2807, loss 0.019205, acc 1
2020-02-08T02:40:49.313529: step 2808, loss 0.00992941, acc 1
2020-02-08T02:40:49.431401: step 2809, loss 0.038008, acc 0.984375
2020-02-08T02:40:49.548500: step 2810, loss 0.0689214, acc 0.984375
2020-02-08T02:40:49.666453: step 2811, loss 0.023121, acc 1
2020-02-08T02:40:49.785422: step 2812, loss 0.0297506, acc 0.984375
2020-02-08T02:40:49.903610: step 2813, loss 0.0142307, acc 1
2020-02-08T02:40:50.021821: step 2814, loss 0.00688082, acc 1
2020-02-08T02:40:50.140362: step 2815, loss 0.0104559, acc 1
2020-02-08T02:40:50.258865: step 2816, loss 0.00900223, acc 1
2020-02-08T02:40:50.377465: step 2817, loss 0.00740275, acc 1
2020-02-08T02:40:50.494987: step 2818, loss 0.0260495, acc 0.984375
2020-02-08T02:40:50.612874: step 2819, loss 0.00637884, acc 1
2020-02-08T02:40:50.730933: step 2820, loss 0.0357381, acc 0.984375
2020-02-08T02:40:50.848336: step 2821, loss 0.037536, acc 0.984375
2020-02-08T02:40:50.967037: step 2822, loss 0.0171133, acc 1
2020-02-08T02:40:51.084380: step 2823, loss 0.0327424, acc 0.984375
2020-02-08T02:40:51.201992: step 2824, loss 0.0121393, acc 1
2020-02-08T02:40:51.317087: step 2825, loss 0.0202588, acc 0.984375
2020-02-08T02:40:51.526678: step 2826, loss 0.00614733, acc 1
2020-02-08T02:40:51.645526: step 2827, loss 0.0241568, acc 1
2020-02-08T02:40:51.768209: step 2828, loss 0.0520997, acc 0.984375
2020-02-08T02:40:51.884470: step 2829, loss 0.0288278, acc 0.984375
2020-02-08T02:40:51.998916: step 2830, loss 0.0149801, acc 1
2020-02-08T02:40:52.116720: step 2831, loss 0.0193198, acc 1
2020-02-08T02:40:52.233498: step 2832, loss 0.0488853, acc 0.96875
2020-02-08T02:40:52.351749: step 2833, loss 0.00456011, acc 1
2020-02-08T02:40:52.470725: step 2834, loss 0.0620784, acc 0.984375
2020-02-08T02:40:52.586468: step 2835, loss 0.00840989, acc 1
2020-02-08T02:40:52.706467: step 2836, loss 0.00671377, acc 1
2020-02-08T02:40:52.826842: step 2837, loss 0.0139277, acc 1
2020-02-08T02:40:52.939704: step 2838, loss 0.00463777, acc 1
2020-02-08T02:40:53.056939: step 2839, loss 0.024103, acc 1
2020-02-08T02:40:53.173581: step 2840, loss 0.0320906, acc 0.984375
2020-02-08T02:40:53.288844: step 2841, loss 0.0148113, acc 1
2020-02-08T02:40:53.405943: step 2842, loss 0.0125488, acc 1
2020-02-08T02:40:53.526747: step 2843, loss 0.00526773, acc 1
2020-02-08T02:40:53.642019: step 2844, loss 0.018195, acc 1
2020-02-08T02:40:53.766341: step 2845, loss 0.0155054, acc 1
2020-02-08T02:40:53.881757: step 2846, loss 0.00859177, acc 1
2020-02-08T02:40:53.997003: step 2847, loss 0.00773775, acc 1
2020-02-08T02:40:54.116370: step 2848, loss 0.0252986, acc 1
2020-02-08T02:40:54.232831: step 2849, loss 0.00197502, acc 1
2020-02-08T02:40:54.346367: step 2850, loss 0.00971096, acc 1
2020-02-08T02:40:54.467483: step 2851, loss 0.0430992, acc 0.984375
2020-02-08T02:40:54.583468: step 2852, loss 0.0107165, acc 1
2020-02-08T02:40:54.699278: step 2853, loss 0.00406372, acc 1
2020-02-08T02:40:54.815467: step 2854, loss 0.017891, acc 0.984375
2020-02-08T02:40:54.933024: step 2855, loss 0.0102502, acc 1
2020-02-08T02:40:55.048190: step 2856, loss 0.00933239, acc 1
2020-02-08T02:40:55.165430: step 2857, loss 0.0135959, acc 1
2020-02-08T02:40:55.284045: step 2858, loss 0.00708331, acc 1
2020-02-08T02:40:55.400989: step 2859, loss 0.0168311, acc 1
2020-02-08T02:40:55.522375: step 2860, loss 0.00614824, acc 1
2020-02-08T02:40:55.637804: step 2861, loss 0.0272804, acc 1
2020-02-08T02:40:55.757290: step 2862, loss 0.0234119, acc 1
2020-02-08T02:40:55.875600: step 2863, loss 0.026975, acc 0.984375
2020-02-08T02:40:55.992012: step 2864, loss 0.0320455, acc 0.984375
2020-02-08T02:40:56.111413: step 2865, loss 0.0329537, acc 0.984375
2020-02-08T02:40:56.228006: step 2866, loss 0.0211511, acc 0.984375
2020-02-08T02:40:56.343022: step 2867, loss 0.0134293, acc 1
2020-02-08T02:40:56.461409: step 2868, loss 0.0162146, acc 1
2020-02-08T02:40:56.583082: step 2869, loss 0.0367661, acc 0.984375
2020-02-08T02:40:56.700239: step 2870, loss 0.0265425, acc 1
2020-02-08T02:40:56.816739: step 2871, loss 0.0166103, acc 0.984375
2020-02-08T02:40:56.933685: step 2872, loss 0.00933585, acc 1
2020-02-08T02:40:57.051274: step 2873, loss 0.00367998, acc 1
2020-02-08T02:40:57.169675: step 2874, loss 0.00489108, acc 1
2020-02-08T02:40:57.285358: step 2875, loss 0.0251514, acc 0.984375
2020-02-08T02:40:57.404129: step 2876, loss 0.00693959, acc 1
2020-02-08T02:40:57.522548: step 2877, loss 0.0108246, acc 1
2020-02-08T02:40:57.637804: step 2878, loss 0.0394706, acc 0.984375
2020-02-08T02:40:57.757526: step 2879, loss 0.00833294, acc 1
2020-02-08T02:40:57.874799: step 2880, loss 0.0223418, acc 0.984375
2020-02-08T02:40:57.990431: step 2881, loss 0.0310252, acc 0.984375
2020-02-08T02:40:58.108100: step 2882, loss 0.015273, acc 1
2020-02-08T02:40:58.225547: step 2883, loss 0.0278177, acc 0.984375
2020-02-08T02:40:58.342117: step 2884, loss 0.00474368, acc 1
2020-02-08T02:40:58.461598: step 2885, loss 0.00965885, acc 1
2020-02-08T02:40:58.578461: step 2886, loss 0.00825109, acc 1
2020-02-08T02:40:58.693886: step 2887, loss 0.0183703, acc 1
2020-02-08T02:40:58.813524: step 2888, loss 0.0399532, acc 0.984375
2020-02-08T02:40:58.929173: step 2889, loss 0.0065969, acc 1
2020-02-08T02:40:59.047621: step 2890, loss 0.00205208, acc 1
2020-02-08T02:40:59.165599: step 2891, loss 0.0249013, acc 0.984375
2020-02-08T02:40:59.282988: step 2892, loss 0.0400569, acc 0.984375
2020-02-08T02:40:59.400835: step 2893, loss 0.00884669, acc 1
2020-02-08T02:40:59.521521: step 2894, loss 0.0140883, acc 1
2020-02-08T02:40:59.636048: step 2895, loss 0.00750203, acc 1
2020-02-08T02:40:59.753083: step 2896, loss 0.00956143, acc 1
2020-02-08T02:40:59.872001: step 2897, loss 0.00372446, acc 1
2020-02-08T02:40:59.988415: step 2898, loss 0.00984351, acc 1
2020-02-08T02:41:00.107498: step 2899, loss 0.0116415, acc 1
2020-02-08T02:41:00.226094: step 2900, loss 0.0122025, acc 1

Evaluation:
2020-02-08T02:41:00.414681: step 2900, loss 1.05542, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-2900

2020-02-08T02:41:01.941656: step 2901, loss 0.0123447, acc 1
2020-02-08T02:41:02.056236: step 2902, loss 0.0291346, acc 0.984375
2020-02-08T02:41:02.173120: step 2903, loss 0.00568513, acc 1
2020-02-08T02:41:02.288883: step 2904, loss 0.0128142, acc 1
2020-02-08T02:41:02.406793: step 2905, loss 0.0495204, acc 0.96875
2020-02-08T02:41:02.527662: step 2906, loss 0.0229703, acc 1
2020-02-08T02:41:02.644430: step 2907, loss 0.0198388, acc 1
2020-02-08T02:41:02.763403: step 2908, loss 0.00880632, acc 1
2020-02-08T02:41:02.880939: step 2909, loss 0.0454323, acc 0.984375
2020-02-08T02:41:02.997151: step 2910, loss 0.0134823, acc 1
2020-02-08T02:41:03.115399: step 2911, loss 0.0213227, acc 0.984375
2020-02-08T02:41:03.229683: step 2912, loss 0.0313017, acc 0.984375
2020-02-08T02:41:03.343835: step 2913, loss 0.00929804, acc 1
2020-02-08T02:41:03.466059: step 2914, loss 0.0166485, acc 1
2020-02-08T02:41:03.596918: step 2915, loss 0.00773553, acc 1
2020-02-08T02:41:03.732875: step 2916, loss 0.0132104, acc 1
2020-02-08T02:41:03.856071: step 2917, loss 0.0104611, acc 1
2020-02-08T02:41:03.978719: step 2918, loss 0.044619, acc 0.96875
2020-02-08T02:41:04.107405: step 2919, loss 0.0150764, acc 1
2020-02-08T02:41:04.225638: step 2920, loss 0.00573418, acc 1
2020-02-08T02:41:04.341471: step 2921, loss 0.0139369, acc 1
2020-02-08T02:41:04.457665: step 2922, loss 0.0313111, acc 0.984375
2020-02-08T02:41:04.573651: step 2923, loss 0.00826691, acc 1
2020-02-08T02:41:04.688872: step 2924, loss 0.0401467, acc 0.984375
2020-02-08T02:41:04.810044: step 2925, loss 0.00608197, acc 1
2020-02-08T02:41:04.927024: step 2926, loss 0.00364793, acc 1
2020-02-08T02:41:05.040760: step 2927, loss 0.0302003, acc 1
2020-02-08T02:41:05.161420: step 2928, loss 0.0426236, acc 0.984375
2020-02-08T02:41:05.278330: step 2929, loss 0.0179723, acc 1
2020-02-08T02:41:05.392360: step 2930, loss 0.0710468, acc 0.984375
2020-02-08T02:41:05.510271: step 2931, loss 0.017294, acc 1
2020-02-08T02:41:05.627800: step 2932, loss 0.01482, acc 1
2020-02-08T02:41:05.744469: step 2933, loss 0.0381727, acc 0.96875
2020-02-08T02:41:05.863643: step 2934, loss 0.00694351, acc 1
2020-02-08T02:41:05.979330: step 2935, loss 0.012682, acc 1
2020-02-08T02:41:06.095380: step 2936, loss 0.00922075, acc 1
2020-02-08T02:41:06.214132: step 2937, loss 0.0149403, acc 1
2020-02-08T02:41:06.331350: step 2938, loss 0.0195783, acc 1
2020-02-08T02:41:06.446800: step 2939, loss 0.00716643, acc 1
2020-02-08T02:41:06.565682: step 2940, loss 0.00562045, acc 1
2020-02-08T02:41:06.681655: step 2941, loss 0.00231636, acc 1
2020-02-08T02:41:06.802843: step 2942, loss 0.023917, acc 1
2020-02-08T02:41:06.921425: step 2943, loss 0.0737054, acc 0.96875
2020-02-08T02:41:07.037556: step 2944, loss 0.011233, acc 1
2020-02-08T02:41:07.154594: step 2945, loss 0.0343171, acc 0.984375
2020-02-08T02:41:07.271084: step 2946, loss 0.0225997, acc 0.984375
2020-02-08T02:41:07.390376: step 2947, loss 0.0358719, acc 0.984375
2020-02-08T02:41:07.506998: step 2948, loss 0.0293451, acc 0.984375
2020-02-08T02:41:07.626589: step 2949, loss 0.0121422, acc 1
2020-02-08T02:41:07.746671: step 2950, loss 0.0254027, acc 0.984375
2020-02-08T02:41:07.863902: step 2951, loss 0.0103986, acc 1
2020-02-08T02:41:07.979546: step 2952, loss 0.0300312, acc 0.984375
2020-02-08T02:41:08.098780: step 2953, loss 0.016935, acc 1
2020-02-08T02:41:08.216941: step 2954, loss 0.0105536, acc 1
2020-02-08T02:41:08.333302: step 2955, loss 0.0130548, acc 1
2020-02-08T02:41:08.452246: step 2956, loss 0.0077314, acc 1
2020-02-08T02:41:08.567268: step 2957, loss 0.0505449, acc 0.984375
2020-02-08T02:41:08.683626: step 2958, loss 0.00634222, acc 1
2020-02-08T02:41:08.801354: step 2959, loss 0.00893702, acc 1
2020-02-08T02:41:08.916718: step 2960, loss 0.0080348, acc 1
2020-02-08T02:41:09.032343: step 2961, loss 0.0074138, acc 1
2020-02-08T02:41:09.146614: step 2962, loss 0.044745, acc 0.96875
2020-02-08T02:41:09.263694: step 2963, loss 0.00635502, acc 1
2020-02-08T02:41:09.382328: step 2964, loss 0.00606289, acc 1
2020-02-08T02:41:09.498917: step 2965, loss 0.00527479, acc 1
2020-02-08T02:41:09.617214: step 2966, loss 0.0193152, acc 0.984375
2020-02-08T02:41:09.736906: step 2967, loss 0.0789957, acc 0.984375
2020-02-08T02:41:09.852632: step 2968, loss 0.00593651, acc 1
2020-02-08T02:41:09.969892: step 2969, loss 0.0107421, acc 1
2020-02-08T02:41:10.084455: step 2970, loss 0.0051955, acc 1
2020-02-08T02:41:10.202623: step 2971, loss 0.0370521, acc 0.984375
2020-02-08T02:41:10.321822: step 2972, loss 0.0204608, acc 1
2020-02-08T02:41:10.438294: step 2973, loss 0.0549584, acc 0.96875
2020-02-08T02:41:10.556641: step 2974, loss 0.00145548, acc 1
2020-02-08T02:41:10.673394: step 2975, loss 0.0368382, acc 0.984375
2020-02-08T02:41:10.792208: step 2976, loss 0.00775269, acc 1
2020-02-08T02:41:10.908307: step 2977, loss 0.00484873, acc 1
2020-02-08T02:41:11.025022: step 2978, loss 0.00898116, acc 1
2020-02-08T02:41:11.142333: step 2979, loss 0.00646143, acc 1
2020-02-08T02:41:11.257391: step 2980, loss 0.00306233, acc 1
2020-02-08T02:41:11.374484: step 2981, loss 0.0241486, acc 0.984375
2020-02-08T02:41:11.491391: step 2982, loss 0.00871725, acc 1
2020-02-08T02:41:11.609797: step 2983, loss 0.0135587, acc 1
2020-02-08T02:41:11.728868: step 2984, loss 0.0704526, acc 0.96875
2020-02-08T02:41:11.844734: step 2985, loss 0.0119165, acc 1
2020-02-08T02:41:11.961813: step 2986, loss 0.0146822, acc 1
2020-02-08T02:41:12.077635: step 2987, loss 0.0136209, acc 1
2020-02-08T02:41:12.195920: step 2988, loss 0.00790977, acc 1
2020-02-08T02:41:12.312803: step 2989, loss 0.017624, acc 1
2020-02-08T02:41:12.430592: step 2990, loss 0.0183866, acc 1
2020-02-08T02:41:12.548212: step 2991, loss 0.00717991, acc 1
2020-02-08T02:41:12.664807: step 2992, loss 0.0243768, acc 1
2020-02-08T02:41:12.784353: step 2993, loss 0.0253154, acc 0.984375
2020-02-08T02:41:12.900694: step 2994, loss 0.0122228, acc 1
2020-02-08T02:41:13.019414: step 2995, loss 0.0154183, acc 1
2020-02-08T02:41:13.137045: step 2996, loss 0.026424, acc 0.984375
2020-02-08T02:41:13.251725: step 2997, loss 0.0708064, acc 0.96875
2020-02-08T02:41:13.368522: step 2998, loss 0.0173929, acc 0.984375
2020-02-08T02:41:13.484810: step 2999, loss 0.017131, acc 0.984375
2020-02-08T02:41:13.598547: step 3000, loss 0.0107811, acc 1

Evaluation:
2020-02-08T02:41:13.791429: step 3000, loss 1.07802, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581100450/checkpoints/model-3000

