WARNING:tensorflow:From train.py:196: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:48:21.503237 4523789760 deprecation.py:323] From train.py:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:48:21.503458 4523789760 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
W0208 02:48:21.503561 4523789760 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0208 02:48:22.013808 4523789760 module_wrapper.py:139] From train.py:80: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0208 02:48:22.014187 4523789760 module_wrapper.py:139] From train.py:83: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-08 02:48:22.014418: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-08 02:48:22.028399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa60d98a320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-08 02:48:22.028421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0208 02:48:22.028780 4523789760 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0208 02:48:22.032404 4523789760 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:25: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

W0208 02:48:22.044619 4523789760 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:36: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W0208 02:48:22.055252 4523789760 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:47: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0208 02:48:22.082084 4523789760 deprecation.py:506] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0208 02:48:22.091722 4523789760 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:66: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0208 02:48:22.091948 4523789760 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

W0208 02:48:22.104336 4523789760 module_wrapper.py:139] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:73: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.

WARNING:tensorflow:From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0208 02:48:22.106989 4523789760 deprecation.py:323] From /Volumes/Transcend/Mutation/CNN-TF/text_cnn.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W0208 02:48:22.136199 4523789760 module_wrapper.py:139] From train.py:96: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0208 02:48:22.380101 4523789760 module_wrapper.py:139] From train.py:104: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
I0208 02:48:22.380338 4523789760 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.
WARNING:tensorflow:From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0208 02:48:22.386497 4523789760 module_wrapper.py:139] From train.py:105: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
I0208 02:48:22.407027 4523789760 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
I0208 02:48:22.408427 4523789760 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
I0208 02:48:22.426218 4523789760 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
I0208 02:48:22.427316 4523789760 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
I0208 02:48:22.444400 4523789760 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
I0208 02:48:22.445551 4523789760 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
I0208 02:48:22.462250 4523789760 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
I0208 02:48:22.463673 4523789760 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
I0208 02:48:22.480688 4523789760 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
I0208 02:48:22.481817 4523789760 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
I0208 02:48:22.498600 4523789760 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
I0208 02:48:22.499802 4523789760 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.
INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
I0208 02:48:22.516806 4523789760 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.
INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
I0208 02:48:22.518111 4523789760 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.
INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
I0208 02:48:22.534893 4523789760 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.
INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
I0208 02:48:22.536010 4523789760 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.
INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
I0208 02:48:22.552812 4523789760 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.
WARNING:tensorflow:From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0208 02:48:22.554146 4523789760 module_wrapper.py:139] From train.py:108: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

WARNING:tensorflow:From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W0208 02:48:22.558204 4523789760 module_wrapper.py:139] From train.py:122: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0208 02:48:22.899502 4523789760 module_wrapper.py:139] From train.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0208 02:48:22.899765 4523789760 module_wrapper.py:139] From train.py:134: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

W0208 02:48:23.147538 4523789760 module_wrapper.py:139] From train.py:140: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

W0208 02:48:23.668500 4523789760 module_wrapper.py:139] From train.py:182: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.

WARNING:tensorflow:From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0208 02:49:45.116543 4523789760 deprecation.py:323] From /Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Loading data...
Vocabulary Size: 18758
Train/Dev split: 9596/1066
Writing to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302

2020-02-08T02:48:23.667964: step 1, loss 3.15176, acc 0.484375
2020-02-08T02:48:23.801717: step 2, loss 2.34785, acc 0.578125
2020-02-08T02:48:23.923730: step 3, loss 1.89868, acc 0.484375
2020-02-08T02:48:24.040880: step 4, loss 2.58769, acc 0.484375
2020-02-08T02:48:24.156602: step 5, loss 1.97895, acc 0.578125
2020-02-08T02:48:24.273910: step 6, loss 2.62892, acc 0.421875
2020-02-08T02:48:24.392047: step 7, loss 1.99019, acc 0.640625
2020-02-08T02:48:24.511176: step 8, loss 2.03981, acc 0.515625
2020-02-08T02:48:24.631395: step 9, loss 1.94103, acc 0.59375
2020-02-08T02:48:24.748706: step 10, loss 2.27421, acc 0.5
2020-02-08T02:48:24.868959: step 11, loss 2.21014, acc 0.484375
2020-02-08T02:48:24.987186: step 12, loss 2.23435, acc 0.5
2020-02-08T02:48:25.102134: step 13, loss 2.43539, acc 0.53125
2020-02-08T02:48:25.221870: step 14, loss 2.70022, acc 0.40625
2020-02-08T02:48:25.341708: step 15, loss 1.86609, acc 0.421875
2020-02-08T02:48:25.456263: step 16, loss 2.05856, acc 0.46875
2020-02-08T02:48:25.574603: step 17, loss 1.64477, acc 0.5
2020-02-08T02:48:25.692061: step 18, loss 1.58752, acc 0.59375
2020-02-08T02:48:25.806570: step 19, loss 2.13669, acc 0.375
2020-02-08T02:48:25.922714: step 20, loss 1.82259, acc 0.46875
2020-02-08T02:48:26.041850: step 21, loss 1.79713, acc 0.453125
2020-02-08T02:48:26.158568: step 22, loss 2.16344, acc 0.515625
2020-02-08T02:48:26.273399: step 23, loss 2.24831, acc 0.515625
2020-02-08T02:48:26.392610: step 24, loss 1.5937, acc 0.640625
2020-02-08T02:48:26.507367: step 25, loss 1.44886, acc 0.59375
2020-02-08T02:48:26.627987: step 26, loss 1.59727, acc 0.59375
2020-02-08T02:48:26.744810: step 27, loss 1.25119, acc 0.5625
2020-02-08T02:48:26.861903: step 28, loss 1.6546, acc 0.546875
2020-02-08T02:48:26.978696: step 29, loss 2.00115, acc 0.4375
2020-02-08T02:48:27.096621: step 30, loss 1.67992, acc 0.546875
2020-02-08T02:48:27.210877: step 31, loss 2.03049, acc 0.484375
2020-02-08T02:48:27.328982: step 32, loss 2.30845, acc 0.375
2020-02-08T02:48:27.446168: step 33, loss 1.91948, acc 0.546875
2020-02-08T02:48:27.562312: step 34, loss 2.27067, acc 0.421875
2020-02-08T02:48:27.682756: step 35, loss 1.68632, acc 0.5625
2020-02-08T02:48:27.799672: step 36, loss 1.85502, acc 0.453125
2020-02-08T02:48:27.915106: step 37, loss 1.806, acc 0.515625
2020-02-08T02:48:28.034803: step 38, loss 1.87919, acc 0.515625
2020-02-08T02:48:28.150223: step 39, loss 1.82859, acc 0.578125
2020-02-08T02:48:28.269261: step 40, loss 2.01707, acc 0.484375
2020-02-08T02:48:28.388122: step 41, loss 2.1502, acc 0.4375
2020-02-08T02:48:28.508425: step 42, loss 1.70814, acc 0.578125
2020-02-08T02:48:28.628176: step 43, loss 1.61747, acc 0.453125
2020-02-08T02:48:28.746033: step 44, loss 1.65764, acc 0.53125
2020-02-08T02:48:28.858471: step 45, loss 1.80667, acc 0.53125
2020-02-08T02:48:28.974996: step 46, loss 1.93932, acc 0.421875
2020-02-08T02:48:29.091606: step 47, loss 1.63382, acc 0.46875
2020-02-08T02:48:29.206904: step 48, loss 1.86666, acc 0.453125
2020-02-08T02:48:29.325337: step 49, loss 1.65434, acc 0.453125
2020-02-08T02:48:29.441240: step 50, loss 1.62013, acc 0.46875
2020-02-08T02:48:29.556168: step 51, loss 2.12087, acc 0.515625
2020-02-08T02:48:29.674146: step 52, loss 1.8539, acc 0.390625
2020-02-08T02:48:29.791536: step 53, loss 1.29145, acc 0.546875
2020-02-08T02:48:29.906710: step 54, loss 1.50811, acc 0.546875
2020-02-08T02:48:30.023103: step 55, loss 1.85529, acc 0.484375
2020-02-08T02:48:30.140333: step 56, loss 2.0928, acc 0.515625
2020-02-08T02:48:30.255635: step 57, loss 1.5269, acc 0.515625
2020-02-08T02:48:30.373172: step 58, loss 1.98358, acc 0.53125
2020-02-08T02:48:30.490351: step 59, loss 1.34534, acc 0.59375
2020-02-08T02:48:30.607367: step 60, loss 1.47053, acc 0.5625
2020-02-08T02:48:30.723994: step 61, loss 1.63242, acc 0.46875
2020-02-08T02:48:30.843096: step 62, loss 1.71617, acc 0.59375
2020-02-08T02:48:30.958934: step 63, loss 1.86386, acc 0.421875
2020-02-08T02:48:31.074810: step 64, loss 1.69325, acc 0.546875
2020-02-08T02:48:31.193297: step 65, loss 1.84369, acc 0.515625
2020-02-08T02:48:31.308383: step 66, loss 0.918435, acc 0.609375
2020-02-08T02:48:31.430761: step 67, loss 1.35381, acc 0.53125
2020-02-08T02:48:31.547585: step 68, loss 1.91015, acc 0.484375
2020-02-08T02:48:31.665918: step 69, loss 1.45514, acc 0.515625
2020-02-08T02:48:31.783662: step 70, loss 1.58727, acc 0.5625
2020-02-08T02:48:31.898264: step 71, loss 1.5554, acc 0.515625
2020-02-08T02:48:32.015478: step 72, loss 1.93434, acc 0.46875
2020-02-08T02:48:32.133805: step 73, loss 1.48235, acc 0.5625
2020-02-08T02:48:32.250937: step 74, loss 2.02377, acc 0.46875
2020-02-08T02:48:32.367935: step 75, loss 0.936731, acc 0.640625
2020-02-08T02:48:32.487112: step 76, loss 1.52306, acc 0.484375
2020-02-08T02:48:32.603575: step 77, loss 1.53088, acc 0.5625
2020-02-08T02:48:32.721363: step 78, loss 1.33344, acc 0.640625
2020-02-08T02:48:32.840502: step 79, loss 1.69648, acc 0.453125
2020-02-08T02:48:32.956187: step 80, loss 1.64384, acc 0.5
2020-02-08T02:48:33.073855: step 81, loss 1.65409, acc 0.46875
2020-02-08T02:48:33.194510: step 82, loss 1.57719, acc 0.546875
2020-02-08T02:48:33.315231: step 83, loss 1.13164, acc 0.59375
2020-02-08T02:48:33.433743: step 84, loss 1.37801, acc 0.46875
2020-02-08T02:48:33.550847: step 85, loss 1.31114, acc 0.484375
2020-02-08T02:48:33.665213: step 86, loss 1.40009, acc 0.53125
2020-02-08T02:48:33.781836: step 87, loss 1.51653, acc 0.5
2020-02-08T02:48:33.897590: step 88, loss 1.24503, acc 0.5625
2020-02-08T02:48:34.013870: step 89, loss 1.68747, acc 0.546875
2020-02-08T02:48:34.133271: step 90, loss 1.4509, acc 0.5625
2020-02-08T02:48:34.249928: step 91, loss 0.903848, acc 0.609375
2020-02-08T02:48:34.366408: step 92, loss 1.49234, acc 0.546875
2020-02-08T02:48:34.486441: step 93, loss 1.20707, acc 0.515625
2020-02-08T02:48:34.600084: step 94, loss 1.68113, acc 0.40625
2020-02-08T02:48:34.717399: step 95, loss 1.41051, acc 0.546875
2020-02-08T02:48:34.836415: step 96, loss 1.43145, acc 0.5625
2020-02-08T02:48:34.951917: step 97, loss 1.4337, acc 0.484375
2020-02-08T02:48:35.069215: step 98, loss 1.41395, acc 0.484375
2020-02-08T02:48:35.187075: step 99, loss 1.03422, acc 0.65625
2020-02-08T02:48:35.302972: step 100, loss 1.39686, acc 0.53125

Evaluation:
2020-02-08T02:48:35.539023: step 100, loss 0.874232, acc 0.575985

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-100

2020-02-08T02:48:37.122199: step 101, loss 1.16504, acc 0.5625
2020-02-08T02:48:37.240576: step 102, loss 1.68083, acc 0.546875
2020-02-08T02:48:37.356327: step 103, loss 1.79094, acc 0.46875
2020-02-08T02:48:37.476630: step 104, loss 1.33194, acc 0.515625
2020-02-08T02:48:37.592234: step 105, loss 1.92178, acc 0.546875
2020-02-08T02:48:37.710168: step 106, loss 1.61647, acc 0.453125
2020-02-08T02:48:37.832241: step 107, loss 1.53516, acc 0.546875
2020-02-08T02:48:37.949677: step 108, loss 1.24075, acc 0.546875
2020-02-08T02:48:38.066355: step 109, loss 1.5545, acc 0.59375
2020-02-08T02:48:38.187243: step 110, loss 1.33854, acc 0.640625
2020-02-08T02:48:38.303356: step 111, loss 0.909722, acc 0.671875
2020-02-08T02:48:38.422096: step 112, loss 1.69608, acc 0.5
2020-02-08T02:48:38.541124: step 113, loss 1.23754, acc 0.578125
2020-02-08T02:48:38.656538: step 114, loss 1.57068, acc 0.5
2020-02-08T02:48:38.771636: step 115, loss 1.25631, acc 0.53125
2020-02-08T02:48:38.889968: step 116, loss 1.56161, acc 0.53125
2020-02-08T02:48:39.007791: step 117, loss 1.73142, acc 0.40625
2020-02-08T02:48:39.133328: step 118, loss 1.6083, acc 0.59375
2020-02-08T02:48:39.250109: step 119, loss 1.19179, acc 0.53125
2020-02-08T02:48:39.364301: step 120, loss 1.40748, acc 0.4375
2020-02-08T02:48:39.482884: step 121, loss 1.12433, acc 0.53125
2020-02-08T02:48:39.600901: step 122, loss 1.74971, acc 0.546875
2020-02-08T02:48:39.717489: step 123, loss 1.56711, acc 0.515625
2020-02-08T02:48:39.835289: step 124, loss 1.51922, acc 0.5
2020-02-08T02:48:39.952987: step 125, loss 1.17332, acc 0.546875
2020-02-08T02:48:40.070295: step 126, loss 1.5238, acc 0.484375
2020-02-08T02:48:40.187426: step 127, loss 1.33512, acc 0.484375
2020-02-08T02:48:40.303031: step 128, loss 1.48683, acc 0.46875
2020-02-08T02:48:40.422077: step 129, loss 1.45525, acc 0.625
2020-02-08T02:48:40.540216: step 130, loss 1.75961, acc 0.5
2020-02-08T02:48:40.656928: step 131, loss 1.49336, acc 0.546875
2020-02-08T02:48:40.776766: step 132, loss 1.5978, acc 0.5625
2020-02-08T02:48:40.893016: step 133, loss 1.43536, acc 0.5625
2020-02-08T02:48:41.007689: step 134, loss 1.62773, acc 0.40625
2020-02-08T02:48:41.125993: step 135, loss 1.44051, acc 0.5
2020-02-08T02:48:41.244170: step 136, loss 1.58235, acc 0.453125
2020-02-08T02:48:41.361715: step 137, loss 1.12136, acc 0.515625
2020-02-08T02:48:41.476566: step 138, loss 1.69055, acc 0.40625
2020-02-08T02:48:41.591740: step 139, loss 1.27188, acc 0.546875
2020-02-08T02:48:41.708287: step 140, loss 1.28475, acc 0.546875
2020-02-08T02:48:41.827116: step 141, loss 1.26691, acc 0.609375
2020-02-08T02:48:41.944106: step 142, loss 1.46774, acc 0.453125
2020-02-08T02:48:42.058798: step 143, loss 1.23975, acc 0.5625
2020-02-08T02:48:42.173098: step 144, loss 1.10562, acc 0.546875
2020-02-08T02:48:42.289566: step 145, loss 1.64744, acc 0.5
2020-02-08T02:48:42.404829: step 146, loss 1.04708, acc 0.59375
2020-02-08T02:48:42.518764: step 147, loss 1.31829, acc 0.609375
2020-02-08T02:48:42.638355: step 148, loss 1.06789, acc 0.546875
2020-02-08T02:48:42.754148: step 149, loss 1.29368, acc 0.5625
2020-02-08T02:48:42.866360: step 150, loss 1.21265, acc 0.533333
2020-02-08T02:48:42.986270: step 151, loss 0.931115, acc 0.609375
2020-02-08T02:48:43.102746: step 152, loss 0.882774, acc 0.53125
2020-02-08T02:48:43.219539: step 153, loss 1.12159, acc 0.625
2020-02-08T02:48:43.338551: step 154, loss 1.01839, acc 0.546875
2020-02-08T02:48:43.452402: step 155, loss 0.991049, acc 0.5625
2020-02-08T02:48:43.569886: step 156, loss 0.930427, acc 0.640625
2020-02-08T02:48:43.689489: step 157, loss 1.25151, acc 0.578125
2020-02-08T02:48:43.803819: step 158, loss 0.873129, acc 0.671875
2020-02-08T02:48:43.918245: step 159, loss 1.61079, acc 0.578125
2020-02-08T02:48:44.034069: step 160, loss 1.14304, acc 0.578125
2020-02-08T02:48:44.149165: step 161, loss 0.794988, acc 0.6875
2020-02-08T02:48:44.267246: step 162, loss 0.846665, acc 0.65625
2020-02-08T02:48:44.383403: step 163, loss 1.19676, acc 0.59375
2020-02-08T02:48:44.498409: step 164, loss 0.790225, acc 0.625
2020-02-08T02:48:44.612741: step 165, loss 0.910075, acc 0.609375
2020-02-08T02:48:44.730582: step 166, loss 1.0346, acc 0.5625
2020-02-08T02:48:44.846488: step 167, loss 0.772094, acc 0.65625
2020-02-08T02:48:44.966157: step 168, loss 1.04532, acc 0.609375
2020-02-08T02:48:45.087912: step 169, loss 0.683778, acc 0.703125
2020-02-08T02:48:45.209485: step 170, loss 1.03227, acc 0.5625
2020-02-08T02:48:45.330954: step 171, loss 0.829109, acc 0.65625
2020-02-08T02:48:45.449401: step 172, loss 1.03703, acc 0.640625
2020-02-08T02:48:45.565999: step 173, loss 1.18226, acc 0.5
2020-02-08T02:48:45.680648: step 174, loss 1.01904, acc 0.59375
2020-02-08T02:48:45.802147: step 175, loss 0.809054, acc 0.578125
2020-02-08T02:48:45.923881: step 176, loss 1.17436, acc 0.59375
2020-02-08T02:48:46.041913: step 177, loss 0.946682, acc 0.5625
2020-02-08T02:48:46.157817: step 178, loss 1.2183, acc 0.5625
2020-02-08T02:48:46.272412: step 179, loss 0.755838, acc 0.671875
2020-02-08T02:48:46.390429: step 180, loss 1.07038, acc 0.53125
2020-02-08T02:48:46.504361: step 181, loss 0.943595, acc 0.671875
2020-02-08T02:48:46.624145: step 182, loss 0.950729, acc 0.6875
2020-02-08T02:48:46.743872: step 183, loss 0.900718, acc 0.625
2020-02-08T02:48:46.859442: step 184, loss 1.0768, acc 0.578125
2020-02-08T02:48:46.977643: step 185, loss 1.24978, acc 0.5625
2020-02-08T02:48:47.094515: step 186, loss 1.07563, acc 0.59375
2020-02-08T02:48:47.208001: step 187, loss 0.930549, acc 0.671875
2020-02-08T02:48:47.326636: step 188, loss 0.80266, acc 0.609375
2020-02-08T02:48:47.443833: step 189, loss 1.11334, acc 0.5625
2020-02-08T02:48:47.560448: step 190, loss 0.894462, acc 0.609375
2020-02-08T02:48:47.678166: step 191, loss 0.779102, acc 0.71875
2020-02-08T02:48:47.796563: step 192, loss 0.800661, acc 0.734375
2020-02-08T02:48:47.913908: step 193, loss 1.11745, acc 0.59375
2020-02-08T02:48:48.032357: step 194, loss 0.90767, acc 0.640625
2020-02-08T02:48:48.149095: step 195, loss 0.741162, acc 0.6875
2020-02-08T02:48:48.264578: step 196, loss 0.982949, acc 0.59375
2020-02-08T02:48:48.382479: step 197, loss 0.830082, acc 0.640625
2020-02-08T02:48:48.501755: step 198, loss 1.09069, acc 0.515625
2020-02-08T02:48:48.619699: step 199, loss 1.082, acc 0.65625
2020-02-08T02:48:48.737708: step 200, loss 1.01808, acc 0.609375

Evaluation:
2020-02-08T02:48:48.927229: step 200, loss 0.673925, acc 0.606942

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-200

2020-02-08T02:48:50.545634: step 201, loss 1.06746, acc 0.515625
2020-02-08T02:48:50.662506: step 202, loss 0.959998, acc 0.59375
2020-02-08T02:48:50.779497: step 203, loss 1.0127, acc 0.59375
2020-02-08T02:48:50.898045: step 204, loss 1.11839, acc 0.546875
2020-02-08T02:48:51.013143: step 205, loss 0.969538, acc 0.59375
2020-02-08T02:48:51.134578: step 206, loss 1.08285, acc 0.578125
2020-02-08T02:48:51.248328: step 207, loss 1.0634, acc 0.515625
2020-02-08T02:48:51.363367: step 208, loss 0.77673, acc 0.59375
2020-02-08T02:48:51.480552: step 209, loss 0.863656, acc 0.640625
2020-02-08T02:48:51.609640: step 210, loss 1.07042, acc 0.5
2020-02-08T02:48:51.732571: step 211, loss 0.848764, acc 0.71875
2020-02-08T02:48:51.850040: step 212, loss 1.07145, acc 0.578125
2020-02-08T02:48:51.967057: step 213, loss 0.998133, acc 0.578125
2020-02-08T02:48:52.083847: step 214, loss 0.883185, acc 0.578125
2020-02-08T02:48:52.200006: step 215, loss 0.546685, acc 0.796875
2020-02-08T02:48:52.314640: step 216, loss 0.807493, acc 0.671875
2020-02-08T02:48:52.431865: step 217, loss 1.09157, acc 0.578125
2020-02-08T02:48:52.549210: step 218, loss 1.19584, acc 0.59375
2020-02-08T02:48:52.665951: step 219, loss 1.11831, acc 0.5625
2020-02-08T02:48:52.782906: step 220, loss 0.781741, acc 0.6875
2020-02-08T02:48:52.901091: step 221, loss 0.811952, acc 0.671875
2020-02-08T02:48:53.022706: step 222, loss 0.907766, acc 0.640625
2020-02-08T02:48:53.140867: step 223, loss 1.22885, acc 0.5
2020-02-08T02:48:53.258638: step 224, loss 0.911855, acc 0.640625
2020-02-08T02:48:53.375761: step 225, loss 1.57815, acc 0.390625
2020-02-08T02:48:53.495862: step 226, loss 0.918359, acc 0.578125
2020-02-08T02:48:53.612347: step 227, loss 1.00933, acc 0.515625
2020-02-08T02:48:53.731350: step 228, loss 0.789872, acc 0.609375
2020-02-08T02:48:53.849389: step 229, loss 0.877719, acc 0.640625
2020-02-08T02:48:53.964207: step 230, loss 0.882969, acc 0.65625
2020-02-08T02:48:54.083181: step 231, loss 0.939659, acc 0.5625
2020-02-08T02:48:54.199680: step 232, loss 1.18513, acc 0.515625
2020-02-08T02:48:54.315380: step 233, loss 0.888249, acc 0.625
2020-02-08T02:48:54.431936: step 234, loss 1.00815, acc 0.53125
2020-02-08T02:48:54.550884: step 235, loss 1.02198, acc 0.578125
2020-02-08T02:48:54.667571: step 236, loss 0.742089, acc 0.640625
2020-02-08T02:48:54.788755: step 237, loss 1.02913, acc 0.609375
2020-02-08T02:48:54.904897: step 238, loss 1.07043, acc 0.546875
2020-02-08T02:48:55.020472: step 239, loss 0.881248, acc 0.5625
2020-02-08T02:48:55.138154: step 240, loss 0.91652, acc 0.625
2020-02-08T02:48:55.252427: step 241, loss 0.941555, acc 0.640625
2020-02-08T02:48:55.367145: step 242, loss 1.04152, acc 0.5
2020-02-08T02:48:55.485534: step 243, loss 1.02734, acc 0.578125
2020-02-08T02:48:55.601277: step 244, loss 0.845948, acc 0.6875
2020-02-08T02:48:55.714629: step 245, loss 0.792337, acc 0.65625
2020-02-08T02:48:55.829662: step 246, loss 0.849407, acc 0.609375
2020-02-08T02:48:55.946823: step 247, loss 0.964014, acc 0.5625
2020-02-08T02:48:56.062332: step 248, loss 0.782874, acc 0.640625
2020-02-08T02:48:56.181587: step 249, loss 1.02446, acc 0.5625
2020-02-08T02:48:56.299079: step 250, loss 0.709053, acc 0.609375
2020-02-08T02:48:56.412729: step 251, loss 0.955848, acc 0.5625
2020-02-08T02:48:56.531387: step 252, loss 0.823417, acc 0.609375
2020-02-08T02:48:56.648322: step 253, loss 0.655977, acc 0.71875
2020-02-08T02:48:56.762342: step 254, loss 0.91886, acc 0.5625
2020-02-08T02:48:56.877702: step 255, loss 0.716884, acc 0.671875
2020-02-08T02:48:56.992928: step 256, loss 0.853488, acc 0.625
2020-02-08T02:48:57.108831: step 257, loss 0.753238, acc 0.640625
2020-02-08T02:48:57.226492: step 258, loss 0.727699, acc 0.609375
2020-02-08T02:48:57.343125: step 259, loss 0.739239, acc 0.671875
2020-02-08T02:48:57.457514: step 260, loss 0.887747, acc 0.625
2020-02-08T02:48:57.579284: step 261, loss 0.621015, acc 0.703125
2020-02-08T02:48:57.698881: step 262, loss 0.705151, acc 0.640625
2020-02-08T02:48:57.819840: step 263, loss 0.943473, acc 0.5625
2020-02-08T02:48:57.939578: step 264, loss 0.709883, acc 0.625
2020-02-08T02:48:58.056959: step 265, loss 0.701022, acc 0.734375
2020-02-08T02:48:58.175376: step 266, loss 0.860986, acc 0.578125
2020-02-08T02:48:58.290262: step 267, loss 0.714916, acc 0.625
2020-02-08T02:48:58.407714: step 268, loss 0.702024, acc 0.640625
2020-02-08T02:48:58.527434: step 269, loss 0.931826, acc 0.53125
2020-02-08T02:48:58.645486: step 270, loss 0.854336, acc 0.59375
2020-02-08T02:48:58.761598: step 271, loss 0.521457, acc 0.734375
2020-02-08T02:48:58.879014: step 272, loss 1.0272, acc 0.5625
2020-02-08T02:48:58.994867: step 273, loss 0.596771, acc 0.640625
2020-02-08T02:48:59.114228: step 274, loss 0.607516, acc 0.6875
2020-02-08T02:48:59.232452: step 275, loss 0.778286, acc 0.65625
2020-02-08T02:48:59.351657: step 276, loss 0.863878, acc 0.609375
2020-02-08T02:48:59.466072: step 277, loss 0.846, acc 0.671875
2020-02-08T02:48:59.582170: step 278, loss 0.658643, acc 0.703125
2020-02-08T02:48:59.697302: step 279, loss 1.05557, acc 0.53125
2020-02-08T02:48:59.812254: step 280, loss 0.695695, acc 0.671875
2020-02-08T02:48:59.927114: step 281, loss 0.889408, acc 0.65625
2020-02-08T02:49:00.044236: step 282, loss 0.931304, acc 0.609375
2020-02-08T02:49:00.159349: step 283, loss 0.646323, acc 0.6875
2020-02-08T02:49:00.276019: step 284, loss 0.885336, acc 0.578125
2020-02-08T02:49:00.394159: step 285, loss 0.725532, acc 0.59375
2020-02-08T02:49:00.513202: step 286, loss 0.791283, acc 0.609375
2020-02-08T02:49:00.629161: step 287, loss 0.827823, acc 0.640625
2020-02-08T02:49:00.747808: step 288, loss 0.630026, acc 0.703125
2020-02-08T02:49:00.865460: step 289, loss 0.849915, acc 0.671875
2020-02-08T02:49:00.982089: step 290, loss 0.879002, acc 0.625
2020-02-08T02:49:01.096129: step 291, loss 0.811505, acc 0.609375
2020-02-08T02:49:01.214196: step 292, loss 0.779889, acc 0.53125
2020-02-08T02:49:01.332369: step 293, loss 0.995145, acc 0.59375
2020-02-08T02:49:01.448628: step 294, loss 0.943256, acc 0.546875
2020-02-08T02:49:01.566239: step 295, loss 0.523778, acc 0.734375
2020-02-08T02:49:01.682600: step 296, loss 0.562251, acc 0.765625
2020-02-08T02:49:01.797811: step 297, loss 0.617599, acc 0.703125
2020-02-08T02:49:01.919249: step 298, loss 1.05632, acc 0.53125
2020-02-08T02:49:02.037701: step 299, loss 0.836673, acc 0.609375
2020-02-08T02:49:02.151630: step 300, loss 0.970128, acc 0.533333

Evaluation:
2020-02-08T02:49:02.341420: step 300, loss 0.637968, acc 0.636023

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-300

2020-02-08T02:49:04.085234: step 301, loss 0.775442, acc 0.640625
2020-02-08T02:49:04.200602: step 302, loss 0.64581, acc 0.65625
2020-02-08T02:49:04.318368: step 303, loss 0.802698, acc 0.59375
2020-02-08T02:49:04.434467: step 304, loss 0.711747, acc 0.671875
2020-02-08T02:49:04.549539: step 305, loss 0.978885, acc 0.5
2020-02-08T02:49:04.663540: step 306, loss 0.898887, acc 0.640625
2020-02-08T02:49:04.778170: step 307, loss 0.781117, acc 0.6875
2020-02-08T02:49:04.892744: step 308, loss 0.695209, acc 0.6875
2020-02-08T02:49:05.012937: step 309, loss 0.698973, acc 0.640625
2020-02-08T02:49:05.131198: step 310, loss 0.737291, acc 0.703125
2020-02-08T02:49:05.249012: step 311, loss 0.760931, acc 0.640625
2020-02-08T02:49:05.366448: step 312, loss 0.723613, acc 0.625
2020-02-08T02:49:05.483468: step 313, loss 0.691184, acc 0.640625
2020-02-08T02:49:05.597799: step 314, loss 0.73593, acc 0.609375
2020-02-08T02:49:05.713504: step 315, loss 0.624344, acc 0.6875
2020-02-08T02:49:05.831538: step 316, loss 0.739105, acc 0.71875
2020-02-08T02:49:05.949029: step 317, loss 0.688318, acc 0.671875
2020-02-08T02:49:06.063733: step 318, loss 0.934401, acc 0.578125
2020-02-08T02:49:06.181010: step 319, loss 0.595045, acc 0.703125
2020-02-08T02:49:06.299376: step 320, loss 0.618706, acc 0.71875
2020-02-08T02:49:06.416931: step 321, loss 0.780225, acc 0.609375
2020-02-08T02:49:06.536416: step 322, loss 0.657895, acc 0.6875
2020-02-08T02:49:06.652178: step 323, loss 0.745501, acc 0.703125
2020-02-08T02:49:06.766914: step 324, loss 0.758524, acc 0.671875
2020-02-08T02:49:06.884550: step 325, loss 0.917599, acc 0.5625
2020-02-08T02:49:06.998285: step 326, loss 0.611308, acc 0.6875
2020-02-08T02:49:07.115137: step 327, loss 0.680576, acc 0.65625
2020-02-08T02:49:07.232530: step 328, loss 0.633889, acc 0.625
2020-02-08T02:49:07.350161: step 329, loss 0.554436, acc 0.765625
2020-02-08T02:49:07.462932: step 330, loss 0.629126, acc 0.703125
2020-02-08T02:49:07.578448: step 331, loss 0.685289, acc 0.71875
2020-02-08T02:49:07.695339: step 332, loss 0.758675, acc 0.625
2020-02-08T02:49:07.816370: step 333, loss 0.638378, acc 0.703125
2020-02-08T02:49:07.933049: step 334, loss 0.652095, acc 0.625
2020-02-08T02:49:08.049208: step 335, loss 0.741447, acc 0.625
2020-02-08T02:49:08.164394: step 336, loss 0.608027, acc 0.703125
2020-02-08T02:49:08.284209: step 337, loss 0.565729, acc 0.625
2020-02-08T02:49:08.399405: step 338, loss 0.677651, acc 0.734375
2020-02-08T02:49:08.515957: step 339, loss 0.729727, acc 0.609375
2020-02-08T02:49:08.633610: step 340, loss 0.700133, acc 0.640625
2020-02-08T02:49:08.751615: step 341, loss 0.528066, acc 0.765625
2020-02-08T02:49:08.869056: step 342, loss 0.625534, acc 0.6875
2020-02-08T02:49:08.988999: step 343, loss 0.723343, acc 0.59375
2020-02-08T02:49:09.103898: step 344, loss 0.799037, acc 0.71875
2020-02-08T02:49:09.217849: step 345, loss 0.764565, acc 0.671875
2020-02-08T02:49:09.334185: step 346, loss 0.799134, acc 0.5625
2020-02-08T02:49:09.450050: step 347, loss 0.605697, acc 0.6875
2020-02-08T02:49:09.565967: step 348, loss 0.686153, acc 0.65625
2020-02-08T02:49:09.682773: step 349, loss 0.530863, acc 0.796875
2020-02-08T02:49:09.802940: step 350, loss 0.634971, acc 0.78125
2020-02-08T02:49:09.918403: step 351, loss 0.534787, acc 0.671875
2020-02-08T02:49:10.037175: step 352, loss 0.668237, acc 0.6875
2020-02-08T02:49:10.155163: step 353, loss 0.490639, acc 0.75
2020-02-08T02:49:10.273288: step 354, loss 0.804683, acc 0.609375
2020-02-08T02:49:10.388712: step 355, loss 0.452379, acc 0.796875
2020-02-08T02:49:10.504504: step 356, loss 0.688494, acc 0.609375
2020-02-08T02:49:10.620680: step 357, loss 0.543096, acc 0.71875
2020-02-08T02:49:10.742716: step 358, loss 0.526627, acc 0.78125
2020-02-08T02:49:10.857548: step 359, loss 0.567828, acc 0.71875
2020-02-08T02:49:10.976757: step 360, loss 0.678636, acc 0.65625
2020-02-08T02:49:11.198372: step 361, loss 0.746895, acc 0.578125
2020-02-08T02:49:11.339375: step 362, loss 0.744417, acc 0.640625
2020-02-08T02:49:11.467918: step 363, loss 0.760235, acc 0.65625
2020-02-08T02:49:11.604257: step 364, loss 0.76876, acc 0.6875
2020-02-08T02:49:11.738966: step 365, loss 0.83606, acc 0.625
2020-02-08T02:49:11.871688: step 366, loss 0.532287, acc 0.734375
2020-02-08T02:49:12.004261: step 367, loss 0.793591, acc 0.578125
2020-02-08T02:49:12.138983: step 368, loss 0.624942, acc 0.65625
2020-02-08T02:49:12.272376: step 369, loss 0.726056, acc 0.65625
2020-02-08T02:49:12.406814: step 370, loss 0.751584, acc 0.65625
2020-02-08T02:49:12.542844: step 371, loss 0.617107, acc 0.6875
2020-02-08T02:49:12.670622: step 372, loss 0.76054, acc 0.625
2020-02-08T02:49:12.800738: step 373, loss 0.631025, acc 0.65625
2020-02-08T02:49:12.928718: step 374, loss 0.72315, acc 0.671875
2020-02-08T02:49:13.059019: step 375, loss 0.811824, acc 0.609375
2020-02-08T02:49:13.179812: step 376, loss 0.676267, acc 0.625
2020-02-08T02:49:13.305089: step 377, loss 0.616793, acc 0.71875
2020-02-08T02:49:13.431205: step 378, loss 0.58536, acc 0.734375
2020-02-08T02:49:13.557872: step 379, loss 0.708479, acc 0.640625
2020-02-08T02:49:13.682950: step 380, loss 0.704588, acc 0.671875
2020-02-08T02:49:13.808246: step 381, loss 0.635599, acc 0.671875
2020-02-08T02:49:13.935582: step 382, loss 0.695771, acc 0.625
2020-02-08T02:49:14.062402: step 383, loss 0.632746, acc 0.71875
2020-02-08T02:49:14.195911: step 384, loss 0.634191, acc 0.6875
2020-02-08T02:49:14.332093: step 385, loss 0.688286, acc 0.640625
2020-02-08T02:49:14.465832: step 386, loss 0.733828, acc 0.640625
2020-02-08T02:49:14.605561: step 387, loss 0.607351, acc 0.703125
2020-02-08T02:49:14.753564: step 388, loss 0.65262, acc 0.734375
2020-02-08T02:49:14.898950: step 389, loss 0.693245, acc 0.578125
2020-02-08T02:49:15.044398: step 390, loss 0.623942, acc 0.671875
2020-02-08T02:49:15.181060: step 391, loss 0.767516, acc 0.65625
2020-02-08T02:49:15.308632: step 392, loss 0.828871, acc 0.625
2020-02-08T02:49:15.437194: step 393, loss 0.756176, acc 0.53125
2020-02-08T02:49:15.560930: step 394, loss 0.642435, acc 0.671875
2020-02-08T02:49:15.700050: step 395, loss 0.617682, acc 0.71875
2020-02-08T02:49:15.837449: step 396, loss 0.838737, acc 0.53125
2020-02-08T02:49:15.976032: step 397, loss 0.712958, acc 0.734375
2020-02-08T02:49:16.111911: step 398, loss 0.719954, acc 0.703125
2020-02-08T02:49:16.248532: step 399, loss 0.62257, acc 0.75
2020-02-08T02:49:16.380061: step 400, loss 0.679254, acc 0.625

Evaluation:
2020-02-08T02:49:16.604853: step 400, loss 0.700011, acc 0.579737

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-400

2020-02-08T02:49:18.187275: step 401, loss 0.790368, acc 0.703125
2020-02-08T02:49:18.322278: step 402, loss 0.650343, acc 0.6875
2020-02-08T02:49:18.458399: step 403, loss 0.702926, acc 0.703125
2020-02-08T02:49:18.593900: step 404, loss 0.589966, acc 0.578125
2020-02-08T02:49:18.735428: step 405, loss 0.592151, acc 0.671875
2020-02-08T02:49:18.874603: step 406, loss 0.652332, acc 0.625
2020-02-08T02:49:19.030012: step 407, loss 0.601346, acc 0.640625
2020-02-08T02:49:19.172457: step 408, loss 0.724491, acc 0.578125
2020-02-08T02:49:19.319081: step 409, loss 0.699257, acc 0.671875
2020-02-08T02:49:19.459026: step 410, loss 0.639511, acc 0.671875
2020-02-08T02:49:19.605258: step 411, loss 0.845737, acc 0.53125
2020-02-08T02:49:19.739076: step 412, loss 0.627069, acc 0.640625
2020-02-08T02:49:19.867971: step 413, loss 0.695648, acc 0.65625
2020-02-08T02:49:20.002643: step 414, loss 0.701894, acc 0.640625
2020-02-08T02:49:20.130245: step 415, loss 0.613782, acc 0.65625
2020-02-08T02:49:20.256327: step 416, loss 0.600138, acc 0.671875
2020-02-08T02:49:20.382827: step 417, loss 0.592878, acc 0.640625
2020-02-08T02:49:20.511043: step 418, loss 0.713514, acc 0.59375
2020-02-08T02:49:20.636161: step 419, loss 0.581959, acc 0.6875
2020-02-08T02:49:20.764196: step 420, loss 0.675071, acc 0.609375
2020-02-08T02:49:20.902802: step 421, loss 0.615138, acc 0.71875
2020-02-08T02:49:21.042839: step 422, loss 0.523595, acc 0.78125
2020-02-08T02:49:21.183865: step 423, loss 0.570596, acc 0.609375
2020-02-08T02:49:21.321168: step 424, loss 0.5537, acc 0.703125
2020-02-08T02:49:21.436149: step 425, loss 0.683984, acc 0.65625
2020-02-08T02:49:21.557650: step 426, loss 0.595954, acc 0.71875
2020-02-08T02:49:21.721701: step 427, loss 0.68845, acc 0.640625
2020-02-08T02:49:21.873303: step 428, loss 0.730882, acc 0.65625
2020-02-08T02:49:21.990201: step 429, loss 0.638866, acc 0.65625
2020-02-08T02:49:22.108358: step 430, loss 0.757923, acc 0.578125
2020-02-08T02:49:22.232607: step 431, loss 0.680885, acc 0.640625
2020-02-08T02:49:22.356651: step 432, loss 0.531517, acc 0.671875
2020-02-08T02:49:22.481604: step 433, loss 0.613955, acc 0.6875
2020-02-08T02:49:22.604911: step 434, loss 0.703531, acc 0.609375
2020-02-08T02:49:22.727957: step 435, loss 0.601992, acc 0.703125
2020-02-08T02:49:22.846110: step 436, loss 0.641124, acc 0.671875
2020-02-08T02:49:22.962446: step 437, loss 0.608163, acc 0.78125
2020-02-08T02:49:23.081912: step 438, loss 0.741774, acc 0.5625
2020-02-08T02:49:23.202991: step 439, loss 0.63964, acc 0.640625
2020-02-08T02:49:23.327675: step 440, loss 0.573227, acc 0.71875
2020-02-08T02:49:23.449401: step 441, loss 0.586132, acc 0.765625
2020-02-08T02:49:23.567530: step 442, loss 0.651143, acc 0.6875
2020-02-08T02:49:23.686599: step 443, loss 0.753692, acc 0.609375
2020-02-08T02:49:23.808946: step 444, loss 0.50257, acc 0.71875
2020-02-08T02:49:23.929831: step 445, loss 0.828171, acc 0.484375
2020-02-08T02:49:24.052222: step 446, loss 0.807323, acc 0.578125
2020-02-08T02:49:24.171202: step 447, loss 0.583337, acc 0.65625
2020-02-08T02:49:24.290346: step 448, loss 0.721443, acc 0.609375
2020-02-08T02:49:24.407058: step 449, loss 0.466681, acc 0.71875
2020-02-08T02:49:24.523614: step 450, loss 0.734119, acc 0.65
2020-02-08T02:49:24.645163: step 451, loss 0.636766, acc 0.6875
2020-02-08T02:49:24.761581: step 452, loss 0.519323, acc 0.734375
2020-02-08T02:49:24.882289: step 453, loss 0.519709, acc 0.71875
2020-02-08T02:49:24.999727: step 454, loss 0.519803, acc 0.71875
2020-02-08T02:49:25.117413: step 455, loss 0.521141, acc 0.65625
2020-02-08T02:49:25.238862: step 456, loss 0.530256, acc 0.6875
2020-02-08T02:49:25.361287: step 457, loss 0.54153, acc 0.6875
2020-02-08T02:49:25.479272: step 458, loss 0.516717, acc 0.75
2020-02-08T02:49:25.596881: step 459, loss 0.510774, acc 0.75
2020-02-08T02:49:25.713120: step 460, loss 0.618858, acc 0.703125
2020-02-08T02:49:25.828327: step 461, loss 0.631864, acc 0.734375
2020-02-08T02:49:25.941937: step 462, loss 0.539911, acc 0.6875
2020-02-08T02:49:26.057961: step 463, loss 0.373087, acc 0.8125
2020-02-08T02:49:26.177276: step 464, loss 0.561479, acc 0.703125
2020-02-08T02:49:26.294777: step 465, loss 0.584045, acc 0.734375
2020-02-08T02:49:26.411693: step 466, loss 0.635265, acc 0.703125
2020-02-08T02:49:26.528899: step 467, loss 0.585831, acc 0.671875
2020-02-08T02:49:26.645009: step 468, loss 0.502485, acc 0.734375
2020-02-08T02:49:26.765208: step 469, loss 0.574213, acc 0.671875
2020-02-08T02:49:26.882063: step 470, loss 0.447265, acc 0.78125
2020-02-08T02:49:26.998174: step 471, loss 0.591299, acc 0.640625
2020-02-08T02:49:27.114441: step 472, loss 0.612097, acc 0.71875
2020-02-08T02:49:27.232585: step 473, loss 0.671664, acc 0.609375
2020-02-08T02:49:27.347323: step 474, loss 0.515111, acc 0.8125
2020-02-08T02:49:27.463479: step 475, loss 0.542025, acc 0.734375
2020-02-08T02:49:27.579938: step 476, loss 0.677862, acc 0.625
2020-02-08T02:49:27.698127: step 477, loss 0.597131, acc 0.6875
2020-02-08T02:49:27.815564: step 478, loss 0.558673, acc 0.71875
2020-02-08T02:49:27.931821: step 479, loss 0.410435, acc 0.875
2020-02-08T02:49:28.050166: step 480, loss 0.567116, acc 0.71875
2020-02-08T02:49:28.166349: step 481, loss 0.710414, acc 0.609375
2020-02-08T02:49:28.281125: step 482, loss 0.554562, acc 0.6875
2020-02-08T02:49:28.397793: step 483, loss 0.496787, acc 0.765625
2020-02-08T02:49:28.515340: step 484, loss 0.593344, acc 0.734375
2020-02-08T02:49:28.632891: step 485, loss 0.578156, acc 0.703125
2020-02-08T02:49:28.751424: step 486, loss 0.69063, acc 0.640625
2020-02-08T02:49:28.868574: step 487, loss 0.554433, acc 0.671875
2020-02-08T02:49:28.989869: step 488, loss 0.580642, acc 0.6875
2020-02-08T02:49:29.138225: step 489, loss 0.610969, acc 0.75
2020-02-08T02:49:29.258068: step 490, loss 0.604526, acc 0.703125
2020-02-08T02:49:29.375921: step 491, loss 0.549121, acc 0.703125
2020-02-08T02:49:29.492245: step 492, loss 0.603215, acc 0.703125
2020-02-08T02:49:29.609117: step 493, loss 0.708591, acc 0.59375
2020-02-08T02:49:29.725200: step 494, loss 0.519619, acc 0.765625
2020-02-08T02:49:29.842610: step 495, loss 0.583959, acc 0.703125
2020-02-08T02:49:29.960141: step 496, loss 0.576323, acc 0.65625
2020-02-08T02:49:30.076454: step 497, loss 0.585041, acc 0.75
2020-02-08T02:49:30.193989: step 498, loss 0.501448, acc 0.765625
2020-02-08T02:49:30.309848: step 499, loss 0.55874, acc 0.75
2020-02-08T02:49:30.428733: step 500, loss 0.64933, acc 0.71875

Evaluation:
2020-02-08T02:49:30.617314: step 500, loss 0.610797, acc 0.660413

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-500

2020-02-08T02:49:32.101400: step 501, loss 0.589772, acc 0.765625
2020-02-08T02:49:32.218599: step 502, loss 0.657986, acc 0.625
2020-02-08T02:49:32.334411: step 503, loss 0.603459, acc 0.71875
2020-02-08T02:49:32.451109: step 504, loss 0.493807, acc 0.75
2020-02-08T02:49:32.565083: step 505, loss 0.560301, acc 0.640625
2020-02-08T02:49:32.682748: step 506, loss 0.607471, acc 0.734375
2020-02-08T02:49:32.799021: step 507, loss 0.600887, acc 0.703125
2020-02-08T02:49:32.916031: step 508, loss 0.62443, acc 0.609375
2020-02-08T02:49:33.034462: step 509, loss 0.493891, acc 0.8125
2020-02-08T02:49:33.148569: step 510, loss 0.568913, acc 0.71875
2020-02-08T02:49:33.264384: step 511, loss 0.512211, acc 0.71875
2020-02-08T02:49:33.380115: step 512, loss 0.488361, acc 0.78125
2020-02-08T02:49:33.494584: step 513, loss 0.60157, acc 0.671875
2020-02-08T02:49:33.609547: step 514, loss 0.655293, acc 0.65625
2020-02-08T02:49:33.727721: step 515, loss 0.605541, acc 0.65625
2020-02-08T02:49:33.845992: step 516, loss 0.623241, acc 0.703125
2020-02-08T02:49:33.962598: step 517, loss 0.631725, acc 0.671875
2020-02-08T02:49:34.078428: step 518, loss 0.486033, acc 0.75
2020-02-08T02:49:34.194417: step 519, loss 0.539925, acc 0.734375
2020-02-08T02:49:34.310154: step 520, loss 0.554407, acc 0.71875
2020-02-08T02:49:34.426427: step 521, loss 0.596125, acc 0.71875
2020-02-08T02:49:34.543318: step 522, loss 0.481241, acc 0.765625
2020-02-08T02:49:34.658157: step 523, loss 0.528919, acc 0.734375
2020-02-08T02:49:34.775004: step 524, loss 0.541217, acc 0.71875
2020-02-08T02:49:34.892901: step 525, loss 0.566039, acc 0.765625
2020-02-08T02:49:35.008374: step 526, loss 0.478841, acc 0.75
2020-02-08T02:49:35.124521: step 527, loss 0.592964, acc 0.671875
2020-02-08T02:49:35.241900: step 528, loss 0.526275, acc 0.703125
2020-02-08T02:49:35.357010: step 529, loss 0.521242, acc 0.75
2020-02-08T02:49:35.472730: step 530, loss 0.589928, acc 0.75
2020-02-08T02:49:35.590056: step 531, loss 0.678921, acc 0.6875
2020-02-08T02:49:35.706616: step 532, loss 0.574992, acc 0.734375
2020-02-08T02:49:35.824557: step 533, loss 0.558655, acc 0.796875
2020-02-08T02:49:35.941342: step 534, loss 0.481169, acc 0.796875
2020-02-08T02:49:36.056544: step 535, loss 0.44389, acc 0.84375
2020-02-08T02:49:36.174239: step 536, loss 0.73741, acc 0.625
2020-02-08T02:49:36.290340: step 537, loss 0.560766, acc 0.6875
2020-02-08T02:49:36.406093: step 538, loss 0.589636, acc 0.609375
2020-02-08T02:49:36.524731: step 539, loss 0.820222, acc 0.640625
2020-02-08T02:49:36.642255: step 540, loss 0.532057, acc 0.6875
2020-02-08T02:49:36.756493: step 541, loss 0.529413, acc 0.765625
2020-02-08T02:49:36.872478: step 542, loss 0.596448, acc 0.703125
2020-02-08T02:49:36.989054: step 543, loss 0.612861, acc 0.671875
2020-02-08T02:49:37.102975: step 544, loss 0.594177, acc 0.625
2020-02-08T02:49:37.216774: step 545, loss 0.473919, acc 0.78125
2020-02-08T02:49:37.332194: step 546, loss 0.616765, acc 0.6875
2020-02-08T02:49:37.447942: step 547, loss 0.513008, acc 0.75
2020-02-08T02:49:37.563354: step 548, loss 0.56116, acc 0.703125
2020-02-08T02:49:37.680393: step 549, loss 0.58669, acc 0.71875
2020-02-08T02:49:37.796771: step 550, loss 0.564599, acc 0.71875
2020-02-08T02:49:37.914344: step 551, loss 0.548234, acc 0.734375
2020-02-08T02:49:38.029897: step 552, loss 0.663707, acc 0.640625
2020-02-08T02:49:38.146658: step 553, loss 0.706732, acc 0.609375
2020-02-08T02:49:38.260943: step 554, loss 0.584556, acc 0.765625
2020-02-08T02:49:38.375950: step 555, loss 0.603085, acc 0.71875
2020-02-08T02:49:38.490175: step 556, loss 0.417053, acc 0.8125
2020-02-08T02:49:38.605527: step 557, loss 0.506764, acc 0.734375
2020-02-08T02:49:38.722044: step 558, loss 0.571135, acc 0.71875
2020-02-08T02:49:38.837933: step 559, loss 0.553512, acc 0.703125
2020-02-08T02:49:38.955606: step 560, loss 0.458106, acc 0.796875
2020-02-08T02:49:39.077267: step 561, loss 0.526125, acc 0.796875
2020-02-08T02:49:39.196615: step 562, loss 0.552174, acc 0.71875
2020-02-08T02:49:39.312660: step 563, loss 0.510644, acc 0.71875
2020-02-08T02:49:39.432037: step 564, loss 0.478971, acc 0.765625
2020-02-08T02:49:39.547114: step 565, loss 0.60217, acc 0.65625
2020-02-08T02:49:39.660310: step 566, loss 0.464528, acc 0.78125
2020-02-08T02:49:39.776045: step 567, loss 0.467033, acc 0.75
2020-02-08T02:49:39.895423: step 568, loss 0.652775, acc 0.671875
2020-02-08T02:49:40.010771: step 569, loss 0.536947, acc 0.75
2020-02-08T02:49:40.130405: step 570, loss 0.527887, acc 0.75
2020-02-08T02:49:40.248237: step 571, loss 0.518676, acc 0.734375
2020-02-08T02:49:40.364608: step 572, loss 0.598985, acc 0.6875
2020-02-08T02:49:40.482095: step 573, loss 0.593399, acc 0.703125
2020-02-08T02:49:40.598844: step 574, loss 0.646433, acc 0.6875
2020-02-08T02:49:40.713469: step 575, loss 0.533055, acc 0.71875
2020-02-08T02:49:40.833871: step 576, loss 0.547099, acc 0.765625
2020-02-08T02:49:40.949944: step 577, loss 0.681078, acc 0.59375
2020-02-08T02:49:41.064876: step 578, loss 0.508561, acc 0.765625
2020-02-08T02:49:41.183978: step 579, loss 0.522522, acc 0.734375
2020-02-08T02:49:41.299045: step 580, loss 0.568586, acc 0.75
2020-02-08T02:49:41.413041: step 581, loss 0.558171, acc 0.734375
2020-02-08T02:49:41.532511: step 582, loss 0.548244, acc 0.75
2020-02-08T02:49:41.650007: step 583, loss 0.627507, acc 0.6875
2020-02-08T02:49:41.765366: step 584, loss 0.470282, acc 0.765625
2020-02-08T02:49:41.882599: step 585, loss 0.47489, acc 0.734375
2020-02-08T02:49:41.999380: step 586, loss 0.588807, acc 0.6875
2020-02-08T02:49:42.119112: step 587, loss 0.564721, acc 0.671875
2020-02-08T02:49:42.235865: step 588, loss 0.528922, acc 0.734375
2020-02-08T02:49:42.351914: step 589, loss 0.727895, acc 0.59375
2020-02-08T02:49:42.469666: step 590, loss 0.631364, acc 0.65625
2020-02-08T02:49:42.589501: step 591, loss 0.525381, acc 0.75
2020-02-08T02:49:42.704418: step 592, loss 0.446263, acc 0.859375
2020-02-08T02:49:42.820306: step 593, loss 0.441464, acc 0.796875
2020-02-08T02:49:42.936282: step 594, loss 0.541412, acc 0.71875
2020-02-08T02:49:43.050328: step 595, loss 0.62522, acc 0.671875
2020-02-08T02:49:43.168365: step 596, loss 0.621045, acc 0.671875
2020-02-08T02:49:43.284190: step 597, loss 0.556791, acc 0.703125
2020-02-08T02:49:43.401603: step 598, loss 0.522424, acc 0.734375
2020-02-08T02:49:43.518503: step 599, loss 0.545624, acc 0.71875
2020-02-08T02:49:43.630459: step 600, loss 0.55695, acc 0.716667

Evaluation:
2020-02-08T02:49:43.829340: step 600, loss 0.649512, acc 0.618199

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-600

2020-02-08T02:49:45.297681: step 601, loss 0.349649, acc 0.890625
2020-02-08T02:49:45.414607: step 602, loss 0.528748, acc 0.71875
2020-02-08T02:49:45.528073: step 603, loss 0.510133, acc 0.71875
2020-02-08T02:49:45.642262: step 604, loss 0.46139, acc 0.8125
2020-02-08T02:49:45.756473: step 605, loss 0.413956, acc 0.828125
2020-02-08T02:49:45.872951: step 606, loss 0.508537, acc 0.75
2020-02-08T02:49:45.988651: step 607, loss 0.535615, acc 0.71875
2020-02-08T02:49:46.102190: step 608, loss 0.491286, acc 0.796875
2020-02-08T02:49:46.216716: step 609, loss 0.590096, acc 0.75
2020-02-08T02:49:46.333433: step 610, loss 0.541201, acc 0.734375
2020-02-08T02:49:46.449254: step 611, loss 0.518226, acc 0.703125
2020-02-08T02:49:46.564453: step 612, loss 0.467093, acc 0.78125
2020-02-08T02:49:46.680294: step 613, loss 0.427748, acc 0.796875
2020-02-08T02:49:46.797644: step 614, loss 0.507937, acc 0.734375
2020-02-08T02:49:46.910162: step 615, loss 0.461295, acc 0.78125
2020-02-08T02:49:47.026702: step 616, loss 0.435407, acc 0.765625
2020-02-08T02:49:47.143716: step 617, loss 0.451846, acc 0.796875
2020-02-08T02:49:47.259400: step 618, loss 0.484291, acc 0.78125
2020-02-08T02:49:47.377172: step 619, loss 0.572985, acc 0.71875
2020-02-08T02:49:47.495422: step 620, loss 0.505329, acc 0.703125
2020-02-08T02:49:47.612877: step 621, loss 0.520264, acc 0.734375
2020-02-08T02:49:47.729082: step 622, loss 0.51233, acc 0.765625
2020-02-08T02:49:47.845262: step 623, loss 0.429724, acc 0.796875
2020-02-08T02:49:47.962375: step 624, loss 0.51474, acc 0.734375
2020-02-08T02:49:48.076971: step 625, loss 0.410879, acc 0.8125
2020-02-08T02:49:48.193220: step 626, loss 0.513159, acc 0.78125
2020-02-08T02:49:48.307456: step 627, loss 0.441644, acc 0.796875
2020-02-08T02:49:48.422370: step 628, loss 0.49828, acc 0.703125
2020-02-08T02:49:48.537592: step 629, loss 0.479844, acc 0.734375
2020-02-08T02:49:48.653029: step 630, loss 0.543437, acc 0.75
2020-02-08T02:49:48.766186: step 631, loss 0.511083, acc 0.703125
2020-02-08T02:49:48.882489: step 632, loss 0.598498, acc 0.71875
2020-02-08T02:49:49.000494: step 633, loss 0.54851, acc 0.703125
2020-02-08T02:49:49.118486: step 634, loss 0.460755, acc 0.765625
2020-02-08T02:49:49.233814: step 635, loss 0.466417, acc 0.78125
2020-02-08T02:49:49.349131: step 636, loss 0.483718, acc 0.75
2020-02-08T02:49:49.460733: step 637, loss 0.508604, acc 0.734375
2020-02-08T02:49:49.575749: step 638, loss 0.482518, acc 0.796875
2020-02-08T02:49:49.691004: step 639, loss 0.577347, acc 0.65625
2020-02-08T02:49:49.807405: step 640, loss 0.569546, acc 0.765625
2020-02-08T02:49:49.922550: step 641, loss 0.523729, acc 0.703125
2020-02-08T02:49:50.040479: step 642, loss 0.661492, acc 0.671875
2020-02-08T02:49:50.156847: step 643, loss 0.552663, acc 0.734375
2020-02-08T02:49:50.274912: step 644, loss 0.571782, acc 0.8125
2020-02-08T02:49:50.391049: step 645, loss 0.470744, acc 0.75
2020-02-08T02:49:50.504930: step 646, loss 0.438702, acc 0.8125
2020-02-08T02:49:50.622922: step 647, loss 0.493117, acc 0.71875
2020-02-08T02:49:50.738773: step 648, loss 0.412317, acc 0.796875
2020-02-08T02:49:50.853274: step 649, loss 0.492786, acc 0.71875
2020-02-08T02:49:50.968603: step 650, loss 0.441182, acc 0.78125
2020-02-08T02:49:51.084361: step 651, loss 0.483873, acc 0.765625
2020-02-08T02:49:51.198403: step 652, loss 0.501496, acc 0.75
2020-02-08T02:49:51.314807: step 653, loss 0.504654, acc 0.796875
2020-02-08T02:49:51.428370: step 654, loss 0.482599, acc 0.78125
2020-02-08T02:49:51.542572: step 655, loss 0.459818, acc 0.796875
2020-02-08T02:49:51.688866: step 656, loss 0.492303, acc 0.71875
2020-02-08T02:49:51.815523: step 657, loss 0.530746, acc 0.75
2020-02-08T02:49:51.930139: step 658, loss 0.51592, acc 0.78125
2020-02-08T02:49:52.044755: step 659, loss 0.583958, acc 0.6875
2020-02-08T02:49:52.160058: step 660, loss 0.356155, acc 0.828125
2020-02-08T02:49:52.278014: step 661, loss 0.571962, acc 0.75
2020-02-08T02:49:52.395185: step 662, loss 0.544239, acc 0.71875
2020-02-08T02:49:52.509403: step 663, loss 0.550858, acc 0.78125
2020-02-08T02:49:52.625553: step 664, loss 0.566382, acc 0.6875
2020-02-08T02:49:52.741087: step 665, loss 0.594101, acc 0.671875
2020-02-08T02:49:52.855485: step 666, loss 0.630807, acc 0.671875
2020-02-08T02:49:52.971811: step 667, loss 0.646443, acc 0.59375
2020-02-08T02:49:53.086983: step 668, loss 0.382501, acc 0.875
2020-02-08T02:49:53.203565: step 669, loss 0.468556, acc 0.796875
2020-02-08T02:49:53.320508: step 670, loss 0.554343, acc 0.75
2020-02-08T02:49:53.436138: step 671, loss 0.454703, acc 0.796875
2020-02-08T02:49:53.551876: step 672, loss 0.519468, acc 0.78125
2020-02-08T02:49:53.665720: step 673, loss 0.701645, acc 0.5625
2020-02-08T02:49:53.782352: step 674, loss 0.477232, acc 0.765625
2020-02-08T02:49:53.898359: step 675, loss 0.573189, acc 0.703125
2020-02-08T02:49:54.014799: step 676, loss 0.546933, acc 0.71875
2020-02-08T02:49:54.130446: step 677, loss 0.567582, acc 0.71875
2020-02-08T02:49:54.247052: step 678, loss 0.441351, acc 0.78125
2020-02-08T02:49:54.362337: step 679, loss 0.562368, acc 0.71875
2020-02-08T02:49:54.478871: step 680, loss 0.592617, acc 0.671875
2020-02-08T02:49:54.593969: step 681, loss 0.395385, acc 0.796875
2020-02-08T02:49:54.707718: step 682, loss 0.431229, acc 0.796875
2020-02-08T02:49:54.823721: step 683, loss 0.580019, acc 0.703125
2020-02-08T02:49:54.939561: step 684, loss 0.49082, acc 0.8125
2020-02-08T02:49:55.055113: step 685, loss 0.477586, acc 0.734375
2020-02-08T02:49:55.173887: step 686, loss 0.572084, acc 0.671875
2020-02-08T02:49:55.290332: step 687, loss 0.629758, acc 0.703125
2020-02-08T02:49:55.405904: step 688, loss 0.570462, acc 0.71875
2020-02-08T02:49:55.522488: step 689, loss 0.512737, acc 0.78125
2020-02-08T02:49:55.639328: step 690, loss 0.545904, acc 0.71875
2020-02-08T02:49:55.757250: step 691, loss 0.405108, acc 0.859375
2020-02-08T02:49:55.873567: step 692, loss 0.501727, acc 0.796875
2020-02-08T02:49:55.990089: step 693, loss 0.533234, acc 0.78125
2020-02-08T02:49:56.106953: step 694, loss 0.580465, acc 0.703125
2020-02-08T02:49:56.225296: step 695, loss 0.435438, acc 0.796875
2020-02-08T02:49:56.339275: step 696, loss 0.48781, acc 0.78125
2020-02-08T02:49:56.456780: step 697, loss 0.531671, acc 0.75
2020-02-08T02:49:56.574346: step 698, loss 0.410763, acc 0.828125
2020-02-08T02:49:56.691368: step 699, loss 0.617983, acc 0.671875
2020-02-08T02:49:56.807273: step 700, loss 0.556245, acc 0.703125

Evaluation:
2020-02-08T02:49:56.994390: step 700, loss 0.608091, acc 0.670732

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-700

2020-02-08T02:49:58.557727: step 701, loss 0.483811, acc 0.734375
2020-02-08T02:49:58.671946: step 702, loss 0.479146, acc 0.796875
2020-02-08T02:49:58.790079: step 703, loss 0.595861, acc 0.71875
2020-02-08T02:49:58.908034: step 704, loss 0.474512, acc 0.765625
2020-02-08T02:49:59.026564: step 705, loss 0.440116, acc 0.8125
2020-02-08T02:49:59.144452: step 706, loss 0.622698, acc 0.65625
2020-02-08T02:49:59.257411: step 707, loss 0.462155, acc 0.71875
2020-02-08T02:49:59.373989: step 708, loss 0.531258, acc 0.75
2020-02-08T02:49:59.489064: step 709, loss 0.512384, acc 0.734375
2020-02-08T02:49:59.605800: step 710, loss 0.438594, acc 0.765625
2020-02-08T02:49:59.721962: step 711, loss 0.490433, acc 0.71875
2020-02-08T02:49:59.840424: step 712, loss 0.503035, acc 0.734375
2020-02-08T02:49:59.957351: step 713, loss 0.405894, acc 0.796875
2020-02-08T02:50:00.070630: step 714, loss 0.397089, acc 0.8125
2020-02-08T02:50:00.187097: step 715, loss 0.557994, acc 0.71875
2020-02-08T02:50:00.303106: step 716, loss 0.513116, acc 0.796875
2020-02-08T02:50:00.415568: step 717, loss 0.462839, acc 0.796875
2020-02-08T02:50:00.533022: step 718, loss 0.534163, acc 0.765625
2020-02-08T02:50:00.649467: step 719, loss 0.4576, acc 0.796875
2020-02-08T02:50:00.765221: step 720, loss 0.448008, acc 0.75
2020-02-08T02:50:00.883132: step 721, loss 0.527577, acc 0.75
2020-02-08T02:50:00.999607: step 722, loss 0.526274, acc 0.71875
2020-02-08T02:50:01.114763: step 723, loss 0.478625, acc 0.78125
2020-02-08T02:50:01.231577: step 724, loss 0.541421, acc 0.75
2020-02-08T02:50:01.348091: step 725, loss 0.797537, acc 0.640625
2020-02-08T02:50:01.460892: step 726, loss 0.578878, acc 0.703125
2020-02-08T02:50:01.577750: step 727, loss 0.519639, acc 0.71875
2020-02-08T02:50:01.696421: step 728, loss 0.472792, acc 0.765625
2020-02-08T02:50:01.811204: step 729, loss 0.494128, acc 0.78125
2020-02-08T02:50:01.928696: step 730, loss 0.513187, acc 0.734375
2020-02-08T02:50:02.048780: step 731, loss 0.630781, acc 0.640625
2020-02-08T02:50:02.164416: step 732, loss 0.641304, acc 0.6875
2020-02-08T02:50:02.282673: step 733, loss 0.540965, acc 0.6875
2020-02-08T02:50:02.399504: step 734, loss 0.626205, acc 0.703125
2020-02-08T02:50:02.520924: step 735, loss 0.531154, acc 0.71875
2020-02-08T02:50:02.637469: step 736, loss 0.501188, acc 0.75
2020-02-08T02:50:02.752359: step 737, loss 0.514423, acc 0.703125
2020-02-08T02:50:02.869903: step 738, loss 0.539503, acc 0.6875
2020-02-08T02:50:02.985491: step 739, loss 0.462996, acc 0.828125
2020-02-08T02:50:03.101200: step 740, loss 0.535845, acc 0.75
2020-02-08T02:50:03.218035: step 741, loss 0.646459, acc 0.703125
2020-02-08T02:50:03.337631: step 742, loss 0.752194, acc 0.59375
2020-02-08T02:50:03.452528: step 743, loss 0.468304, acc 0.796875
2020-02-08T02:50:03.572444: step 744, loss 0.827418, acc 0.515625
2020-02-08T02:50:03.689987: step 745, loss 0.529112, acc 0.765625
2020-02-08T02:50:03.805770: step 746, loss 0.582363, acc 0.671875
2020-02-08T02:50:03.921192: step 747, loss 0.410554, acc 0.78125
2020-02-08T02:50:04.036973: step 748, loss 0.486399, acc 0.671875
2020-02-08T02:50:04.160724: step 749, loss 0.650614, acc 0.6875
2020-02-08T02:50:04.271955: step 750, loss 0.432684, acc 0.833333
2020-02-08T02:50:04.392626: step 751, loss 0.48957, acc 0.75
2020-02-08T02:50:04.508497: step 752, loss 0.483002, acc 0.75
2020-02-08T02:50:04.622065: step 753, loss 0.479409, acc 0.765625
2020-02-08T02:50:04.740021: step 754, loss 0.527598, acc 0.75
2020-02-08T02:50:04.855915: step 755, loss 0.515294, acc 0.8125
2020-02-08T02:50:04.971901: step 756, loss 0.344091, acc 0.84375
2020-02-08T02:50:05.092937: step 757, loss 0.421678, acc 0.859375
2020-02-08T02:50:05.206848: step 758, loss 0.436506, acc 0.796875
2020-02-08T02:50:05.326275: step 759, loss 0.507745, acc 0.75
2020-02-08T02:50:05.442532: step 760, loss 0.365203, acc 0.859375
2020-02-08T02:50:05.558326: step 761, loss 0.45861, acc 0.84375
2020-02-08T02:50:05.674093: step 762, loss 0.449383, acc 0.8125
2020-02-08T02:50:05.790308: step 763, loss 0.40198, acc 0.828125
2020-02-08T02:50:05.908663: step 764, loss 0.452943, acc 0.8125
2020-02-08T02:50:06.025932: step 765, loss 0.436289, acc 0.8125
2020-02-08T02:50:06.144050: step 766, loss 0.434878, acc 0.8125
2020-02-08T02:50:06.259965: step 767, loss 0.414299, acc 0.8125
2020-02-08T02:50:06.373879: step 768, loss 0.497584, acc 0.765625
2020-02-08T02:50:06.489722: step 769, loss 0.338645, acc 0.890625
2020-02-08T02:50:06.605239: step 770, loss 0.406803, acc 0.84375
2020-02-08T02:50:06.722172: step 771, loss 0.450167, acc 0.796875
2020-02-08T02:50:06.839669: step 772, loss 0.488252, acc 0.8125
2020-02-08T02:50:06.953383: step 773, loss 0.425375, acc 0.828125
2020-02-08T02:50:07.069434: step 774, loss 0.368058, acc 0.8125
2020-02-08T02:50:07.185548: step 775, loss 0.429451, acc 0.828125
2020-02-08T02:50:07.301080: step 776, loss 0.3504, acc 0.8125
2020-02-08T02:50:07.419493: step 777, loss 0.338537, acc 0.8125
2020-02-08T02:50:07.537827: step 778, loss 0.458305, acc 0.734375
2020-02-08T02:50:07.656239: step 779, loss 0.395652, acc 0.859375
2020-02-08T02:50:07.773580: step 780, loss 0.446257, acc 0.796875
2020-02-08T02:50:07.893379: step 781, loss 0.48465, acc 0.78125
2020-02-08T02:50:08.009771: step 782, loss 0.496382, acc 0.8125
2020-02-08T02:50:08.123605: step 783, loss 0.445257, acc 0.796875
2020-02-08T02:50:08.239307: step 784, loss 0.396364, acc 0.828125
2020-02-08T02:50:08.353229: step 785, loss 0.456826, acc 0.796875
2020-02-08T02:50:08.467418: step 786, loss 0.391524, acc 0.859375
2020-02-08T02:50:08.584787: step 787, loss 0.5397, acc 0.765625
2020-02-08T02:50:08.701344: step 788, loss 0.507624, acc 0.734375
2020-02-08T02:50:08.820780: step 789, loss 0.371613, acc 0.796875
2020-02-08T02:50:08.938592: step 790, loss 0.464621, acc 0.78125
2020-02-08T02:50:09.054268: step 791, loss 0.517255, acc 0.75
2020-02-08T02:50:09.172988: step 792, loss 0.436547, acc 0.828125
2020-02-08T02:50:09.288893: step 793, loss 0.445146, acc 0.796875
2020-02-08T02:50:09.404943: step 794, loss 0.431048, acc 0.8125
2020-02-08T02:50:09.521927: step 795, loss 0.516266, acc 0.734375
2020-02-08T02:50:09.637650: step 796, loss 0.399359, acc 0.796875
2020-02-08T02:50:09.753262: step 797, loss 0.517694, acc 0.75
2020-02-08T02:50:09.870517: step 798, loss 0.446057, acc 0.765625
2020-02-08T02:50:09.988322: step 799, loss 0.420328, acc 0.8125
2020-02-08T02:50:10.102872: step 800, loss 0.465558, acc 0.828125

Evaluation:
2020-02-08T02:50:10.292296: step 800, loss 0.600726, acc 0.672608

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-800

2020-02-08T02:50:11.806781: step 801, loss 0.420825, acc 0.828125
2020-02-08T02:50:11.921664: step 802, loss 0.463818, acc 0.765625
2020-02-08T02:50:12.039277: step 803, loss 0.38585, acc 0.828125
2020-02-08T02:50:12.156820: step 804, loss 0.464586, acc 0.765625
2020-02-08T02:50:12.276195: step 805, loss 0.448004, acc 0.796875
2020-02-08T02:50:12.393093: step 806, loss 0.487647, acc 0.75
2020-02-08T02:50:12.509671: step 807, loss 0.426728, acc 0.8125
2020-02-08T02:50:12.628701: step 808, loss 0.558888, acc 0.6875
2020-02-08T02:50:12.750897: step 809, loss 0.529007, acc 0.703125
2020-02-08T02:50:12.864030: step 810, loss 0.434224, acc 0.8125
2020-02-08T02:50:12.982289: step 811, loss 0.413368, acc 0.828125
2020-02-08T02:50:13.100631: step 812, loss 0.378374, acc 0.890625
2020-02-08T02:50:13.214395: step 813, loss 0.332809, acc 0.875
2020-02-08T02:50:13.334381: step 814, loss 0.389461, acc 0.828125
2020-02-08T02:50:13.452142: step 815, loss 0.596757, acc 0.6875
2020-02-08T02:50:13.568156: step 816, loss 0.642343, acc 0.75
2020-02-08T02:50:13.694221: step 817, loss 0.477904, acc 0.78125
2020-02-08T02:50:13.809664: step 818, loss 0.470138, acc 0.703125
2020-02-08T02:50:13.927045: step 819, loss 0.41966, acc 0.828125
2020-02-08T02:50:14.042067: step 820, loss 0.320498, acc 0.84375
2020-02-08T02:50:14.156380: step 821, loss 0.384768, acc 0.84375
2020-02-08T02:50:14.271915: step 822, loss 0.400186, acc 0.796875
2020-02-08T02:50:14.390681: step 823, loss 0.440496, acc 0.828125
2020-02-08T02:50:14.506472: step 824, loss 0.506743, acc 0.765625
2020-02-08T02:50:14.621809: step 825, loss 0.378298, acc 0.8125
2020-02-08T02:50:14.739124: step 826, loss 0.415146, acc 0.78125
2020-02-08T02:50:14.853591: step 827, loss 0.464263, acc 0.828125
2020-02-08T02:50:14.969683: step 828, loss 0.55194, acc 0.765625
2020-02-08T02:50:15.088611: step 829, loss 0.327782, acc 0.84375
2020-02-08T02:50:15.202348: step 830, loss 0.35515, acc 0.84375
2020-02-08T02:50:15.316991: step 831, loss 0.394738, acc 0.796875
2020-02-08T02:50:15.432811: step 832, loss 0.323123, acc 0.875
2020-02-08T02:50:15.548435: step 833, loss 0.536467, acc 0.796875
2020-02-08T02:50:15.666761: step 834, loss 0.486132, acc 0.78125
2020-02-08T02:50:15.783921: step 835, loss 0.455717, acc 0.828125
2020-02-08T02:50:15.900159: step 836, loss 0.667438, acc 0.65625
2020-02-08T02:50:16.014466: step 837, loss 0.396884, acc 0.90625
2020-02-08T02:50:16.130546: step 838, loss 0.371909, acc 0.828125
2020-02-08T02:50:16.246738: step 839, loss 0.350051, acc 0.859375
2020-02-08T02:50:16.360199: step 840, loss 0.474715, acc 0.796875
2020-02-08T02:50:16.478641: step 841, loss 0.586844, acc 0.734375
2020-02-08T02:50:16.595269: step 842, loss 0.658718, acc 0.6875
2020-02-08T02:50:16.713238: step 843, loss 0.410481, acc 0.796875
2020-02-08T02:50:16.838061: step 844, loss 0.305135, acc 0.875
2020-02-08T02:50:16.952901: step 845, loss 0.457053, acc 0.796875
2020-02-08T02:50:17.065889: step 846, loss 0.388038, acc 0.859375
2020-02-08T02:50:17.183499: step 847, loss 0.450668, acc 0.703125
2020-02-08T02:50:17.299688: step 848, loss 0.469364, acc 0.796875
2020-02-08T02:50:17.414193: step 849, loss 0.497325, acc 0.78125
2020-02-08T02:50:17.531036: step 850, loss 0.47276, acc 0.734375
2020-02-08T02:50:17.648563: step 851, loss 0.476649, acc 0.796875
2020-02-08T02:50:17.767034: step 852, loss 0.42511, acc 0.765625
2020-02-08T02:50:17.885622: step 853, loss 0.53834, acc 0.75
2020-02-08T02:50:18.001834: step 854, loss 0.531282, acc 0.8125
2020-02-08T02:50:18.117263: step 855, loss 0.446295, acc 0.78125
2020-02-08T02:50:18.233670: step 856, loss 0.569656, acc 0.75
2020-02-08T02:50:18.349302: step 857, loss 0.326359, acc 0.90625
2020-02-08T02:50:18.463742: step 858, loss 0.499456, acc 0.8125
2020-02-08T02:50:18.582145: step 859, loss 0.412048, acc 0.796875
2020-02-08T02:50:18.698165: step 860, loss 0.458348, acc 0.765625
2020-02-08T02:50:18.813331: step 861, loss 0.536171, acc 0.734375
2020-02-08T02:50:18.929134: step 862, loss 0.525249, acc 0.71875
2020-02-08T02:50:19.045000: step 863, loss 0.451561, acc 0.8125
2020-02-08T02:50:19.159067: step 864, loss 0.550263, acc 0.6875
2020-02-08T02:50:19.274648: step 865, loss 0.374225, acc 0.8125
2020-02-08T02:50:19.394261: step 866, loss 0.466786, acc 0.796875
2020-02-08T02:50:19.509971: step 867, loss 0.517629, acc 0.75
2020-02-08T02:50:19.625604: step 868, loss 0.413798, acc 0.84375
2020-02-08T02:50:19.742671: step 869, loss 0.516887, acc 0.75
2020-02-08T02:50:19.859460: step 870, loss 0.311492, acc 0.890625
2020-02-08T02:50:19.975594: step 871, loss 0.383266, acc 0.828125
2020-02-08T02:50:20.093422: step 872, loss 0.380924, acc 0.859375
2020-02-08T02:50:20.208373: step 873, loss 0.440222, acc 0.8125
2020-02-08T02:50:20.327100: step 874, loss 0.559695, acc 0.734375
2020-02-08T02:50:20.446094: step 875, loss 0.39252, acc 0.8125
2020-02-08T02:50:20.562540: step 876, loss 0.472408, acc 0.734375
2020-02-08T02:50:20.678851: step 877, loss 0.470018, acc 0.734375
2020-02-08T02:50:20.795360: step 878, loss 0.493216, acc 0.765625
2020-02-08T02:50:20.910827: step 879, loss 0.724956, acc 0.609375
2020-02-08T02:50:21.027114: step 880, loss 0.595721, acc 0.71875
2020-02-08T02:50:21.147591: step 881, loss 0.510043, acc 0.734375
2020-02-08T02:50:21.260722: step 882, loss 0.519434, acc 0.703125
2020-02-08T02:50:21.376989: step 883, loss 0.358258, acc 0.859375
2020-02-08T02:50:21.506486: step 884, loss 0.53884, acc 0.765625
2020-02-08T02:50:21.624133: step 885, loss 0.521655, acc 0.75
2020-02-08T02:50:21.741261: step 886, loss 0.545202, acc 0.734375
2020-02-08T02:50:21.855766: step 887, loss 0.443464, acc 0.765625
2020-02-08T02:50:21.971590: step 888, loss 0.614366, acc 0.703125
2020-02-08T02:50:22.087088: step 889, loss 0.421378, acc 0.796875
2020-02-08T02:50:22.201427: step 890, loss 0.330592, acc 0.875
2020-02-08T02:50:22.315150: step 891, loss 0.481081, acc 0.796875
2020-02-08T02:50:22.430062: step 892, loss 0.544314, acc 0.703125
2020-02-08T02:50:22.548442: step 893, loss 0.499061, acc 0.75
2020-02-08T02:50:22.662831: step 894, loss 0.451041, acc 0.796875
2020-02-08T02:50:22.779399: step 895, loss 0.52654, acc 0.703125
2020-02-08T02:50:22.896445: step 896, loss 0.358657, acc 0.828125
2020-02-08T02:50:23.013824: step 897, loss 0.504757, acc 0.75
2020-02-08T02:50:23.130517: step 898, loss 0.297062, acc 0.90625
2020-02-08T02:50:23.247052: step 899, loss 0.401599, acc 0.78125
2020-02-08T02:50:23.357832: step 900, loss 0.385128, acc 0.816667

Evaluation:
2020-02-08T02:50:23.546094: step 900, loss 0.588385, acc 0.683865

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-900

2020-02-08T02:50:25.292812: step 901, loss 0.384832, acc 0.875
2020-02-08T02:50:25.408883: step 902, loss 0.438358, acc 0.765625
2020-02-08T02:50:25.523259: step 903, loss 0.335478, acc 0.890625
2020-02-08T02:50:25.638947: step 904, loss 0.375998, acc 0.84375
2020-02-08T02:50:25.757080: step 905, loss 0.45394, acc 0.8125
2020-02-08T02:50:25.872086: step 906, loss 0.485362, acc 0.78125
2020-02-08T02:50:25.988806: step 907, loss 0.431309, acc 0.8125
2020-02-08T02:50:26.106621: step 908, loss 0.459531, acc 0.765625
2020-02-08T02:50:26.223572: step 909, loss 0.422875, acc 0.84375
2020-02-08T02:50:26.344996: step 910, loss 0.434287, acc 0.796875
2020-02-08T02:50:26.459575: step 911, loss 0.461307, acc 0.828125
2020-02-08T02:50:26.576616: step 912, loss 0.288263, acc 0.90625
2020-02-08T02:50:26.693999: step 913, loss 0.386291, acc 0.8125
2020-02-08T02:50:26.810909: step 914, loss 0.369616, acc 0.828125
2020-02-08T02:50:26.928736: step 915, loss 0.444191, acc 0.765625
2020-02-08T02:50:27.045178: step 916, loss 0.340381, acc 0.828125
2020-02-08T02:50:27.160168: step 917, loss 0.401296, acc 0.765625
2020-02-08T02:50:27.277440: step 918, loss 0.420361, acc 0.765625
2020-02-08T02:50:27.392865: step 919, loss 0.225319, acc 0.9375
2020-02-08T02:50:27.505908: step 920, loss 0.421648, acc 0.8125
2020-02-08T02:50:27.622810: step 921, loss 0.445834, acc 0.8125
2020-02-08T02:50:27.741968: step 922, loss 0.316483, acc 0.859375
2020-02-08T02:50:27.857935: step 923, loss 0.35659, acc 0.84375
2020-02-08T02:50:27.973540: step 924, loss 0.302121, acc 0.859375
2020-02-08T02:50:28.092011: step 925, loss 0.388688, acc 0.8125
2020-02-08T02:50:28.205751: step 926, loss 0.43957, acc 0.78125
2020-02-08T02:50:28.320962: step 927, loss 0.371467, acc 0.8125
2020-02-08T02:50:28.436670: step 928, loss 0.308515, acc 0.859375
2020-02-08T02:50:28.553855: step 929, loss 0.371978, acc 0.8125
2020-02-08T02:50:28.669141: step 930, loss 0.495352, acc 0.78125
2020-02-08T02:50:28.786360: step 931, loss 0.416534, acc 0.8125
2020-02-08T02:50:28.900797: step 932, loss 0.389815, acc 0.78125
2020-02-08T02:50:29.016070: step 933, loss 0.291228, acc 0.875
2020-02-08T02:50:29.133854: step 934, loss 0.383943, acc 0.84375
2020-02-08T02:50:29.253552: step 935, loss 0.318681, acc 0.875
2020-02-08T02:50:29.367392: step 936, loss 0.472989, acc 0.734375
2020-02-08T02:50:29.489707: step 937, loss 0.341385, acc 0.859375
2020-02-08T02:50:29.605285: step 938, loss 0.328305, acc 0.90625
2020-02-08T02:50:29.723500: step 939, loss 0.392573, acc 0.796875
2020-02-08T02:50:29.844234: step 940, loss 0.385739, acc 0.796875
2020-02-08T02:50:29.958243: step 941, loss 0.336795, acc 0.859375
2020-02-08T02:50:30.074989: step 942, loss 0.316323, acc 0.796875
2020-02-08T02:50:30.191497: step 943, loss 0.346392, acc 0.90625
2020-02-08T02:50:30.308153: step 944, loss 0.316259, acc 0.890625
2020-02-08T02:50:30.421412: step 945, loss 0.297354, acc 0.875
2020-02-08T02:50:30.538908: step 946, loss 0.380826, acc 0.84375
2020-02-08T02:50:30.653797: step 947, loss 0.38406, acc 0.875
2020-02-08T02:50:30.766493: step 948, loss 0.415987, acc 0.796875
2020-02-08T02:50:30.882725: step 949, loss 0.412224, acc 0.796875
2020-02-08T02:50:30.997852: step 950, loss 0.498463, acc 0.75
2020-02-08T02:50:31.111405: step 951, loss 0.39917, acc 0.828125
2020-02-08T02:50:31.227956: step 952, loss 0.425109, acc 0.8125
2020-02-08T02:50:31.343418: step 953, loss 0.473424, acc 0.796875
2020-02-08T02:50:31.457978: step 954, loss 0.349611, acc 0.828125
2020-02-08T02:50:31.574446: step 955, loss 0.389564, acc 0.859375
2020-02-08T02:50:31.690458: step 956, loss 0.394173, acc 0.828125
2020-02-08T02:50:31.805083: step 957, loss 0.46181, acc 0.8125
2020-02-08T02:50:31.920977: step 958, loss 0.371451, acc 0.859375
2020-02-08T02:50:32.036275: step 959, loss 0.446154, acc 0.8125
2020-02-08T02:50:32.152737: step 960, loss 0.399993, acc 0.8125
2020-02-08T02:50:32.273030: step 961, loss 0.318172, acc 0.84375
2020-02-08T02:50:32.390098: step 962, loss 0.379794, acc 0.796875
2020-02-08T02:50:32.504760: step 963, loss 0.325364, acc 0.859375
2020-02-08T02:50:32.619482: step 964, loss 0.374355, acc 0.828125
2020-02-08T02:50:32.737851: step 965, loss 0.254032, acc 0.921875
2020-02-08T02:50:32.854894: step 966, loss 0.314349, acc 0.875
2020-02-08T02:50:32.975638: step 967, loss 0.33824, acc 0.90625
2020-02-08T02:50:33.091929: step 968, loss 0.428964, acc 0.796875
2020-02-08T02:50:33.207595: step 969, loss 0.546892, acc 0.71875
2020-02-08T02:50:33.325194: step 970, loss 0.487952, acc 0.765625
2020-02-08T02:50:33.442531: step 971, loss 0.427812, acc 0.75
2020-02-08T02:50:33.559756: step 972, loss 0.298755, acc 0.84375
2020-02-08T02:50:33.679634: step 973, loss 0.441525, acc 0.796875
2020-02-08T02:50:33.796842: step 974, loss 0.487419, acc 0.78125
2020-02-08T02:50:33.911942: step 975, loss 0.424364, acc 0.796875
2020-02-08T02:50:34.029637: step 976, loss 0.319597, acc 0.890625
2020-02-08T02:50:34.146740: step 977, loss 0.317136, acc 0.875
2020-02-08T02:50:34.261217: step 978, loss 0.372107, acc 0.84375
2020-02-08T02:50:34.376506: step 979, loss 0.389035, acc 0.828125
2020-02-08T02:50:34.491869: step 980, loss 0.33308, acc 0.875
2020-02-08T02:50:34.604475: step 981, loss 0.334121, acc 0.859375
2020-02-08T02:50:34.721220: step 982, loss 0.397805, acc 0.78125
2020-02-08T02:50:34.838600: step 983, loss 0.427219, acc 0.75
2020-02-08T02:50:34.954985: step 984, loss 0.38671, acc 0.796875
2020-02-08T02:50:35.072428: step 985, loss 0.314133, acc 0.84375
2020-02-08T02:50:35.186356: step 986, loss 0.32337, acc 0.828125
2020-02-08T02:50:35.302260: step 987, loss 0.325115, acc 0.828125
2020-02-08T02:50:35.417139: step 988, loss 0.325199, acc 0.796875
2020-02-08T02:50:35.536661: step 989, loss 0.645143, acc 0.734375
2020-02-08T02:50:35.651114: step 990, loss 0.485565, acc 0.75
2020-02-08T02:50:35.765511: step 991, loss 0.437848, acc 0.71875
2020-02-08T02:50:35.882725: step 992, loss 0.452621, acc 0.75
2020-02-08T02:50:35.999913: step 993, loss 0.322736, acc 0.859375
2020-02-08T02:50:36.116219: step 994, loss 0.444367, acc 0.796875
2020-02-08T02:50:36.234363: step 995, loss 0.529755, acc 0.71875
2020-02-08T02:50:36.351019: step 996, loss 0.474744, acc 0.796875
2020-02-08T02:50:36.469400: step 997, loss 0.322939, acc 0.828125
2020-02-08T02:50:36.586219: step 998, loss 0.288259, acc 0.875
2020-02-08T02:50:36.702509: step 999, loss 0.494904, acc 0.703125
2020-02-08T02:50:36.816721: step 1000, loss 0.489391, acc 0.8125

Evaluation:
2020-02-08T02:50:37.004492: step 1000, loss 0.642088, acc 0.686679

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1000

2020-02-08T02:50:38.709091: step 1001, loss 0.449537, acc 0.75
2020-02-08T02:50:38.825054: step 1002, loss 0.449706, acc 0.796875
2020-02-08T02:50:38.944497: step 1003, loss 0.389723, acc 0.875
2020-02-08T02:50:39.058621: step 1004, loss 0.329497, acc 0.890625
2020-02-08T02:50:39.173708: step 1005, loss 0.370936, acc 0.8125
2020-02-08T02:50:39.289511: step 1006, loss 0.313381, acc 0.84375
2020-02-08T02:50:39.404056: step 1007, loss 0.390313, acc 0.828125
2020-02-08T02:50:39.519886: step 1008, loss 0.439915, acc 0.765625
2020-02-08T02:50:39.637848: step 1009, loss 0.361858, acc 0.8125
2020-02-08T02:50:39.753904: step 1010, loss 0.406572, acc 0.8125
2020-02-08T02:50:39.873032: step 1011, loss 0.287681, acc 0.875
2020-02-08T02:50:39.987501: step 1012, loss 0.439009, acc 0.78125
2020-02-08T02:50:40.101228: step 1013, loss 0.430124, acc 0.8125
2020-02-08T02:50:40.217820: step 1014, loss 0.357472, acc 0.84375
2020-02-08T02:50:40.332743: step 1015, loss 0.478253, acc 0.765625
2020-02-08T02:50:40.446323: step 1016, loss 0.465045, acc 0.8125
2020-02-08T02:50:40.557221: step 1017, loss 0.364791, acc 0.84375
2020-02-08T02:50:40.673968: step 1018, loss 0.412696, acc 0.84375
2020-02-08T02:50:40.789921: step 1019, loss 0.320579, acc 0.875
2020-02-08T02:50:40.904384: step 1020, loss 0.278174, acc 0.875
2020-02-08T02:50:41.025683: step 1021, loss 0.426199, acc 0.8125
2020-02-08T02:50:41.142765: step 1022, loss 0.391645, acc 0.828125
2020-02-08T02:50:41.261250: step 1023, loss 0.331058, acc 0.859375
2020-02-08T02:50:41.377311: step 1024, loss 0.340761, acc 0.890625
2020-02-08T02:50:41.494119: step 1025, loss 0.496894, acc 0.734375
2020-02-08T02:50:41.607732: step 1026, loss 0.339142, acc 0.828125
2020-02-08T02:50:41.724981: step 1027, loss 0.3121, acc 0.90625
2020-02-08T02:50:41.840920: step 1028, loss 0.52352, acc 0.78125
2020-02-08T02:50:41.955994: step 1029, loss 0.380514, acc 0.765625
2020-02-08T02:50:42.072796: step 1030, loss 0.375523, acc 0.84375
2020-02-08T02:50:42.190676: step 1031, loss 0.343557, acc 0.875
2020-02-08T02:50:42.308784: step 1032, loss 0.407376, acc 0.78125
2020-02-08T02:50:42.424267: step 1033, loss 0.301588, acc 0.890625
2020-02-08T02:50:42.540059: step 1034, loss 0.41885, acc 0.8125
2020-02-08T02:50:42.654196: step 1035, loss 0.357702, acc 0.875
2020-02-08T02:50:42.770808: step 1036, loss 0.315686, acc 0.875
2020-02-08T02:50:42.886784: step 1037, loss 0.502049, acc 0.765625
2020-02-08T02:50:43.004386: step 1038, loss 0.458585, acc 0.75
2020-02-08T02:50:43.119908: step 1039, loss 0.49153, acc 0.765625
2020-02-08T02:50:43.236829: step 1040, loss 0.29017, acc 0.921875
2020-02-08T02:50:43.353235: step 1041, loss 0.354554, acc 0.859375
2020-02-08T02:50:43.471156: step 1042, loss 0.292828, acc 0.84375
2020-02-08T02:50:43.588098: step 1043, loss 0.263318, acc 0.890625
2020-02-08T02:50:43.706362: step 1044, loss 0.506093, acc 0.796875
2020-02-08T02:50:43.821951: step 1045, loss 0.420734, acc 0.796875
2020-02-08T02:50:43.937823: step 1046, loss 0.302537, acc 0.859375
2020-02-08T02:50:44.054281: step 1047, loss 0.480923, acc 0.765625
2020-02-08T02:50:44.167330: step 1048, loss 0.281461, acc 0.84375
2020-02-08T02:50:44.285337: step 1049, loss 0.34892, acc 0.84375
2020-02-08T02:50:44.396832: step 1050, loss 0.384892, acc 0.8
2020-02-08T02:50:44.513250: step 1051, loss 0.239498, acc 0.9375
2020-02-08T02:50:44.630191: step 1052, loss 0.321787, acc 0.890625
2020-02-08T02:50:44.745984: step 1053, loss 0.355544, acc 0.84375
2020-02-08T02:50:44.859970: step 1054, loss 0.416537, acc 0.78125
2020-02-08T02:50:44.975339: step 1055, loss 0.32447, acc 0.90625
2020-02-08T02:50:45.091394: step 1056, loss 0.393349, acc 0.8125
2020-02-08T02:50:45.206274: step 1057, loss 0.199316, acc 0.953125
2020-02-08T02:50:45.323772: step 1058, loss 0.471661, acc 0.8125
2020-02-08T02:50:45.442747: step 1059, loss 0.324729, acc 0.875
2020-02-08T02:50:45.557918: step 1060, loss 0.233999, acc 0.921875
2020-02-08T02:50:45.676308: step 1061, loss 0.307437, acc 0.90625
2020-02-08T02:50:45.793464: step 1062, loss 0.287908, acc 0.84375
2020-02-08T02:50:45.908904: step 1063, loss 0.407096, acc 0.84375
2020-02-08T02:50:46.022319: step 1064, loss 0.334335, acc 0.8125
2020-02-08T02:50:46.138732: step 1065, loss 0.235611, acc 0.921875
2020-02-08T02:50:46.255907: step 1066, loss 0.294461, acc 0.890625
2020-02-08T02:50:46.373113: step 1067, loss 0.370555, acc 0.828125
2020-02-08T02:50:46.491271: step 1068, loss 0.296311, acc 0.921875
2020-02-08T02:50:46.605169: step 1069, loss 0.298052, acc 0.890625
2020-02-08T02:50:46.716694: step 1070, loss 0.439104, acc 0.828125
2020-02-08T02:50:46.833670: step 1071, loss 0.296677, acc 0.859375
2020-02-08T02:50:46.948949: step 1072, loss 0.355294, acc 0.84375
2020-02-08T02:50:47.065629: step 1073, loss 0.381628, acc 0.859375
2020-02-08T02:50:47.182785: step 1074, loss 0.393749, acc 0.765625
2020-02-08T02:50:47.300714: step 1075, loss 0.285154, acc 0.859375
2020-02-08T02:50:47.416747: step 1076, loss 0.351695, acc 0.828125
2020-02-08T02:50:47.532028: step 1077, loss 0.30128, acc 0.875
2020-02-08T02:50:47.648875: step 1078, loss 0.31629, acc 0.84375
2020-02-08T02:50:47.764453: step 1079, loss 0.346352, acc 0.828125
2020-02-08T02:50:47.881511: step 1080, loss 0.340095, acc 0.84375
2020-02-08T02:50:47.997868: step 1081, loss 0.342602, acc 0.859375
2020-02-08T02:50:48.113384: step 1082, loss 0.232559, acc 0.875
2020-02-08T02:50:48.234036: step 1083, loss 0.325291, acc 0.84375
2020-02-08T02:50:48.350940: step 1084, loss 0.272943, acc 0.859375
2020-02-08T02:50:48.466692: step 1085, loss 0.411112, acc 0.796875
2020-02-08T02:50:48.581814: step 1086, loss 0.406054, acc 0.875
2020-02-08T02:50:48.699006: step 1087, loss 0.268554, acc 0.890625
2020-02-08T02:50:48.814566: step 1088, loss 0.333738, acc 0.859375
2020-02-08T02:50:48.934122: step 1089, loss 0.320105, acc 0.84375
2020-02-08T02:50:49.049015: step 1090, loss 0.430956, acc 0.84375
2020-02-08T02:50:49.163093: step 1091, loss 0.310506, acc 0.828125
2020-02-08T02:50:49.282313: step 1092, loss 0.222805, acc 0.9375
2020-02-08T02:50:49.399777: step 1093, loss 0.253352, acc 0.921875
2020-02-08T02:50:49.513001: step 1094, loss 0.306738, acc 0.875
2020-02-08T02:50:49.628032: step 1095, loss 0.26172, acc 0.890625
2020-02-08T02:50:49.743685: step 1096, loss 0.397671, acc 0.765625
2020-02-08T02:50:49.858047: step 1097, loss 0.305616, acc 0.859375
2020-02-08T02:50:49.975891: step 1098, loss 0.244062, acc 0.875
2020-02-08T02:50:50.096095: step 1099, loss 0.280691, acc 0.890625
2020-02-08T02:50:50.209428: step 1100, loss 0.338795, acc 0.84375

Evaluation:
2020-02-08T02:50:50.397137: step 1100, loss 0.578592, acc 0.705441

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1100

2020-02-08T02:50:53.172156: step 1101, loss 0.238644, acc 0.875
2020-02-08T02:50:53.452657: step 1102, loss 0.307697, acc 0.859375
2020-02-08T02:50:53.581458: step 1103, loss 0.363138, acc 0.859375
2020-02-08T02:50:53.694354: step 1104, loss 0.31865, acc 0.890625
2020-02-08T02:50:53.807002: step 1105, loss 0.323312, acc 0.890625
2020-02-08T02:50:53.922670: step 1106, loss 0.260665, acc 0.875
2020-02-08T02:50:54.039972: step 1107, loss 0.430075, acc 0.8125
2020-02-08T02:50:54.154480: step 1108, loss 0.267685, acc 0.921875
2020-02-08T02:50:54.268073: step 1109, loss 0.296284, acc 0.875
2020-02-08T02:50:54.384514: step 1110, loss 0.283923, acc 0.84375
2020-02-08T02:50:54.500237: step 1111, loss 0.238187, acc 0.890625
2020-02-08T02:50:54.617622: step 1112, loss 0.299005, acc 0.875
2020-02-08T02:50:54.735009: step 1113, loss 0.315765, acc 0.859375
2020-02-08T02:50:54.851195: step 1114, loss 0.277734, acc 0.921875
2020-02-08T02:50:54.967266: step 1115, loss 0.295393, acc 0.859375
2020-02-08T02:50:55.083067: step 1116, loss 0.376219, acc 0.828125
2020-02-08T02:50:55.197901: step 1117, loss 0.395997, acc 0.78125
2020-02-08T02:50:55.313595: step 1118, loss 0.221616, acc 0.90625
2020-02-08T02:50:55.428989: step 1119, loss 0.219137, acc 0.90625
2020-02-08T02:50:55.546790: step 1120, loss 0.473997, acc 0.75
2020-02-08T02:50:55.662052: step 1121, loss 0.284131, acc 0.828125
2020-02-08T02:50:55.780199: step 1122, loss 0.305596, acc 0.890625
2020-02-08T02:50:55.896532: step 1123, loss 0.328353, acc 0.8125
2020-02-08T02:50:56.012165: step 1124, loss 0.349543, acc 0.828125
2020-02-08T02:50:56.129556: step 1125, loss 0.277751, acc 0.90625
2020-02-08T02:50:56.246149: step 1126, loss 0.353516, acc 0.796875
2020-02-08T02:50:56.359974: step 1127, loss 0.302712, acc 0.890625
2020-02-08T02:50:56.475648: step 1128, loss 0.390149, acc 0.8125
2020-02-08T02:50:56.593681: step 1129, loss 0.287357, acc 0.890625
2020-02-08T02:50:56.707871: step 1130, loss 0.347973, acc 0.859375
2020-02-08T02:50:56.826849: step 1131, loss 0.352289, acc 0.859375
2020-02-08T02:50:56.942991: step 1132, loss 0.278966, acc 0.859375
2020-02-08T02:50:57.058013: step 1133, loss 0.24857, acc 0.875
2020-02-08T02:50:57.173582: step 1134, loss 0.230371, acc 0.921875
2020-02-08T02:50:57.291055: step 1135, loss 0.335757, acc 0.84375
2020-02-08T02:50:57.408309: step 1136, loss 0.325804, acc 0.84375
2020-02-08T02:50:57.521916: step 1137, loss 0.268262, acc 0.859375
2020-02-08T02:50:57.640709: step 1138, loss 0.332253, acc 0.84375
2020-02-08T02:50:57.753753: step 1139, loss 0.318268, acc 0.796875
2020-02-08T02:50:57.869574: step 1140, loss 0.225822, acc 0.90625
2020-02-08T02:50:57.985528: step 1141, loss 0.216221, acc 0.921875
2020-02-08T02:50:58.099333: step 1142, loss 0.287416, acc 0.890625
2020-02-08T02:50:58.213358: step 1143, loss 0.28037, acc 0.890625
2020-02-08T02:50:58.328978: step 1144, loss 0.305352, acc 0.890625
2020-02-08T02:50:58.445498: step 1145, loss 0.28931, acc 0.875
2020-02-08T02:50:58.561494: step 1146, loss 0.222784, acc 0.90625
2020-02-08T02:50:58.677603: step 1147, loss 0.337574, acc 0.84375
2020-02-08T02:50:58.800058: step 1148, loss 0.412489, acc 0.828125
2020-02-08T02:50:58.916329: step 1149, loss 0.312345, acc 0.875
2020-02-08T02:50:59.037273: step 1150, loss 0.312784, acc 0.8125
2020-02-08T02:50:59.152139: step 1151, loss 0.263751, acc 0.875
2020-02-08T02:50:59.267376: step 1152, loss 0.357813, acc 0.796875
2020-02-08T02:50:59.384177: step 1153, loss 0.333133, acc 0.859375
2020-02-08T02:50:59.498838: step 1154, loss 0.23578, acc 0.90625
2020-02-08T02:50:59.613189: step 1155, loss 0.369661, acc 0.859375
2020-02-08T02:50:59.728521: step 1156, loss 0.397519, acc 0.796875
2020-02-08T02:50:59.845764: step 1157, loss 0.345762, acc 0.84375
2020-02-08T02:50:59.960563: step 1158, loss 0.334384, acc 0.875
2020-02-08T02:51:00.076971: step 1159, loss 0.354753, acc 0.828125
2020-02-08T02:51:00.192512: step 1160, loss 0.380487, acc 0.8125
2020-02-08T02:51:00.307380: step 1161, loss 0.312571, acc 0.84375
2020-02-08T02:51:00.422406: step 1162, loss 0.404759, acc 0.828125
2020-02-08T02:51:00.539199: step 1163, loss 0.256907, acc 0.90625
2020-02-08T02:51:00.653633: step 1164, loss 0.403571, acc 0.875
2020-02-08T02:51:00.768419: step 1165, loss 0.28841, acc 0.890625
2020-02-08T02:51:00.884047: step 1166, loss 0.307275, acc 0.90625
2020-02-08T02:51:01.001046: step 1167, loss 0.270677, acc 0.890625
2020-02-08T02:51:01.114701: step 1168, loss 0.337766, acc 0.875
2020-02-08T02:51:01.231597: step 1169, loss 0.410097, acc 0.828125
2020-02-08T02:51:01.347295: step 1170, loss 0.229522, acc 0.953125
2020-02-08T02:51:01.462804: step 1171, loss 0.315117, acc 0.890625
2020-02-08T02:51:01.582098: step 1172, loss 0.296474, acc 0.890625
2020-02-08T02:51:01.698005: step 1173, loss 0.322104, acc 0.890625
2020-02-08T02:51:01.811380: step 1174, loss 0.258227, acc 0.90625
2020-02-08T02:51:01.926244: step 1175, loss 0.343207, acc 0.84375
2020-02-08T02:51:02.044620: step 1176, loss 0.178368, acc 0.953125
2020-02-08T02:51:02.158902: step 1177, loss 0.29561, acc 0.859375
2020-02-08T02:51:02.273085: step 1178, loss 0.455407, acc 0.78125
2020-02-08T02:51:02.388634: step 1179, loss 0.36502, acc 0.8125
2020-02-08T02:51:02.504513: step 1180, loss 0.263535, acc 0.90625
2020-02-08T02:51:02.618062: step 1181, loss 0.364048, acc 0.84375
2020-02-08T02:51:02.732410: step 1182, loss 0.577462, acc 0.703125
2020-02-08T02:51:02.850147: step 1183, loss 0.293752, acc 0.875
2020-02-08T02:51:02.965174: step 1184, loss 0.389391, acc 0.8125
2020-02-08T02:51:03.082400: step 1185, loss 0.232446, acc 0.890625
2020-02-08T02:51:03.198447: step 1186, loss 0.214038, acc 0.9375
2020-02-08T02:51:03.314682: step 1187, loss 0.303974, acc 0.859375
2020-02-08T02:51:03.428657: step 1188, loss 0.319138, acc 0.875
2020-02-08T02:51:03.544107: step 1189, loss 0.44874, acc 0.796875
2020-02-08T02:51:03.660125: step 1190, loss 0.302375, acc 0.90625
2020-02-08T02:51:03.779695: step 1191, loss 0.277778, acc 0.890625
2020-02-08T02:51:03.897011: step 1192, loss 0.465679, acc 0.828125
2020-02-08T02:51:04.014207: step 1193, loss 0.176859, acc 0.921875
2020-02-08T02:51:04.130727: step 1194, loss 0.373838, acc 0.859375
2020-02-08T02:51:04.245052: step 1195, loss 0.363289, acc 0.84375
2020-02-08T02:51:04.362402: step 1196, loss 0.462262, acc 0.75
2020-02-08T02:51:04.476179: step 1197, loss 0.298188, acc 0.90625
2020-02-08T02:51:04.590942: step 1198, loss 0.485577, acc 0.765625
2020-02-08T02:51:04.706294: step 1199, loss 0.323019, acc 0.84375
2020-02-08T02:51:04.816496: step 1200, loss 0.347071, acc 0.816667

Evaluation:
2020-02-08T02:51:05.005581: step 1200, loss 0.584381, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1200

2020-02-08T02:51:06.629556: step 1201, loss 0.312055, acc 0.875
2020-02-08T02:51:06.747572: step 1202, loss 0.28082, acc 0.875
2020-02-08T02:51:06.865248: step 1203, loss 0.248639, acc 0.9375
2020-02-08T02:51:06.980939: step 1204, loss 0.271441, acc 0.875
2020-02-08T02:51:07.095896: step 1205, loss 0.212912, acc 0.90625
2020-02-08T02:51:07.211852: step 1206, loss 0.297517, acc 0.875
2020-02-08T02:51:07.330156: step 1207, loss 0.25382, acc 0.90625
2020-02-08T02:51:07.446309: step 1208, loss 0.231881, acc 0.921875
2020-02-08T02:51:07.559286: step 1209, loss 0.164196, acc 0.9375
2020-02-08T02:51:07.675795: step 1210, loss 0.300978, acc 0.859375
2020-02-08T02:51:07.793646: step 1211, loss 0.304759, acc 0.84375
2020-02-08T02:51:07.912411: step 1212, loss 0.273321, acc 0.921875
2020-02-08T02:51:08.027012: step 1213, loss 0.339771, acc 0.84375
2020-02-08T02:51:08.141440: step 1214, loss 0.153109, acc 0.9375
2020-02-08T02:51:08.257241: step 1215, loss 0.288066, acc 0.875
2020-02-08T02:51:08.371492: step 1216, loss 0.354159, acc 0.84375
2020-02-08T02:51:08.488169: step 1217, loss 0.246428, acc 0.90625
2020-02-08T02:51:08.602569: step 1218, loss 0.145107, acc 0.953125
2020-02-08T02:51:08.717540: step 1219, loss 0.308507, acc 0.875
2020-02-08T02:51:08.834828: step 1220, loss 0.264573, acc 0.875
2020-02-08T02:51:08.951872: step 1221, loss 0.256111, acc 0.890625
2020-02-08T02:51:09.068458: step 1222, loss 0.270261, acc 0.921875
2020-02-08T02:51:09.186210: step 1223, loss 0.250189, acc 0.9375
2020-02-08T02:51:09.303609: step 1224, loss 0.3276, acc 0.890625
2020-02-08T02:51:09.418224: step 1225, loss 0.180979, acc 0.953125
2020-02-08T02:51:09.533555: step 1226, loss 0.324618, acc 0.875
2020-02-08T02:51:09.648097: step 1227, loss 0.232241, acc 0.9375
2020-02-08T02:51:09.764707: step 1228, loss 0.245022, acc 0.890625
2020-02-08T02:51:09.881314: step 1229, loss 0.168627, acc 0.90625
2020-02-08T02:51:09.998248: step 1230, loss 0.185559, acc 0.9375
2020-02-08T02:51:10.110824: step 1231, loss 0.207785, acc 0.9375
2020-02-08T02:51:10.226658: step 1232, loss 0.278362, acc 0.90625
2020-02-08T02:51:10.340706: step 1233, loss 0.260873, acc 0.90625
2020-02-08T02:51:10.454507: step 1234, loss 0.243672, acc 0.875
2020-02-08T02:51:10.572421: step 1235, loss 0.279602, acc 0.84375
2020-02-08T02:51:10.687130: step 1236, loss 0.271296, acc 0.875
2020-02-08T02:51:10.803803: step 1237, loss 0.23167, acc 0.875
2020-02-08T02:51:10.917802: step 1238, loss 0.282368, acc 0.890625
2020-02-08T02:51:11.030932: step 1239, loss 0.257138, acc 0.90625
2020-02-08T02:51:11.145126: step 1240, loss 0.271669, acc 0.890625
2020-02-08T02:51:11.259813: step 1241, loss 0.25941, acc 0.90625
2020-02-08T02:51:11.376475: step 1242, loss 0.231058, acc 0.90625
2020-02-08T02:51:11.491307: step 1243, loss 0.284608, acc 0.890625
2020-02-08T02:51:11.606920: step 1244, loss 0.272582, acc 0.859375
2020-02-08T02:51:11.723672: step 1245, loss 0.389634, acc 0.859375
2020-02-08T02:51:11.840471: step 1246, loss 0.283436, acc 0.890625
2020-02-08T02:51:11.956692: step 1247, loss 0.218144, acc 0.890625
2020-02-08T02:51:12.075305: step 1248, loss 0.451142, acc 0.796875
2020-02-08T02:51:12.189260: step 1249, loss 0.275729, acc 0.890625
2020-02-08T02:51:12.304677: step 1250, loss 0.280653, acc 0.859375
2020-02-08T02:51:12.420888: step 1251, loss 0.29495, acc 0.875
2020-02-08T02:51:12.534622: step 1252, loss 0.328501, acc 0.859375
2020-02-08T02:51:12.652842: step 1253, loss 0.339152, acc 0.8125
2020-02-08T02:51:12.769291: step 1254, loss 0.303692, acc 0.875
2020-02-08T02:51:12.887540: step 1255, loss 0.248936, acc 0.921875
2020-02-08T02:51:13.002665: step 1256, loss 0.25066, acc 0.859375
2020-02-08T02:51:13.120144: step 1257, loss 0.211002, acc 0.921875
2020-02-08T02:51:13.235721: step 1258, loss 0.328616, acc 0.890625
2020-02-08T02:51:13.351742: step 1259, loss 0.257653, acc 0.921875
2020-02-08T02:51:13.467643: step 1260, loss 0.214697, acc 0.90625
2020-02-08T02:51:13.580423: step 1261, loss 0.216917, acc 0.921875
2020-02-08T02:51:13.697236: step 1262, loss 0.310053, acc 0.875
2020-02-08T02:51:13.811628: step 1263, loss 0.227169, acc 0.953125
2020-02-08T02:51:13.927447: step 1264, loss 0.338234, acc 0.84375
2020-02-08T02:51:14.041346: step 1265, loss 0.22776, acc 0.921875
2020-02-08T02:51:14.155549: step 1266, loss 0.330651, acc 0.84375
2020-02-08T02:51:14.277887: step 1267, loss 0.222263, acc 0.9375
2020-02-08T02:51:14.394205: step 1268, loss 0.351938, acc 0.828125
2020-02-08T02:51:14.507756: step 1269, loss 0.202142, acc 0.90625
2020-02-08T02:51:14.625491: step 1270, loss 0.278054, acc 0.875
2020-02-08T02:51:14.742944: step 1271, loss 0.31849, acc 0.875
2020-02-08T02:51:14.857382: step 1272, loss 0.240521, acc 0.90625
2020-02-08T02:51:14.970276: step 1273, loss 0.308665, acc 0.875
2020-02-08T02:51:15.088935: step 1274, loss 0.215952, acc 0.90625
2020-02-08T02:51:15.203436: step 1275, loss 0.251708, acc 0.921875
2020-02-08T02:51:15.318011: step 1276, loss 0.327785, acc 0.859375
2020-02-08T02:51:15.434058: step 1277, loss 0.289829, acc 0.875
2020-02-08T02:51:15.551914: step 1278, loss 0.257356, acc 0.890625
2020-02-08T02:51:15.665048: step 1279, loss 0.327049, acc 0.828125
2020-02-08T02:51:15.780978: step 1280, loss 0.289925, acc 0.8125
2020-02-08T02:51:15.898600: step 1281, loss 0.377235, acc 0.84375
2020-02-08T02:51:16.012478: step 1282, loss 0.244442, acc 0.875
2020-02-08T02:51:16.129227: step 1283, loss 0.269985, acc 0.875
2020-02-08T02:51:16.246960: step 1284, loss 0.223728, acc 0.90625
2020-02-08T02:51:16.362874: step 1285, loss 0.305607, acc 0.8125
2020-02-08T02:51:16.480387: step 1286, loss 0.224788, acc 0.921875
2020-02-08T02:51:16.598845: step 1287, loss 0.270036, acc 0.890625
2020-02-08T02:51:16.715192: step 1288, loss 0.264586, acc 0.890625
2020-02-08T02:51:16.830571: step 1289, loss 0.241943, acc 0.859375
2020-02-08T02:51:16.945559: step 1290, loss 0.247371, acc 0.875
2020-02-08T02:51:17.060877: step 1291, loss 0.359049, acc 0.84375
2020-02-08T02:51:17.174258: step 1292, loss 0.246505, acc 0.90625
2020-02-08T02:51:17.294876: step 1293, loss 0.205332, acc 0.953125
2020-02-08T02:51:17.411956: step 1294, loss 0.234927, acc 0.890625
2020-02-08T02:51:17.529627: step 1295, loss 0.204978, acc 0.890625
2020-02-08T02:51:17.646701: step 1296, loss 0.139109, acc 0.953125
2020-02-08T02:51:17.759835: step 1297, loss 0.181892, acc 0.953125
2020-02-08T02:51:17.878490: step 1298, loss 0.276599, acc 0.90625
2020-02-08T02:51:17.992185: step 1299, loss 0.370988, acc 0.828125
2020-02-08T02:51:18.104629: step 1300, loss 0.296728, acc 0.875

Evaluation:
2020-02-08T02:51:18.291176: step 1300, loss 0.585056, acc 0.723265

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1300

2020-02-08T02:51:19.835050: step 1301, loss 0.233919, acc 0.890625
2020-02-08T02:51:19.951093: step 1302, loss 0.363226, acc 0.84375
2020-02-08T02:51:20.065487: step 1303, loss 0.174649, acc 0.96875
2020-02-08T02:51:20.180148: step 1304, loss 0.29016, acc 0.8125
2020-02-08T02:51:20.298429: step 1305, loss 0.271123, acc 0.890625
2020-02-08T02:51:20.411367: step 1306, loss 0.272145, acc 0.890625
2020-02-08T02:51:20.530119: step 1307, loss 0.28993, acc 0.859375
2020-02-08T02:51:20.647547: step 1308, loss 0.22201, acc 0.90625
2020-02-08T02:51:20.762935: step 1309, loss 0.472644, acc 0.78125
2020-02-08T02:51:20.879674: step 1310, loss 0.244287, acc 0.890625
2020-02-08T02:51:20.995076: step 1311, loss 0.298314, acc 0.828125
2020-02-08T02:51:21.108558: step 1312, loss 0.213849, acc 0.9375
2020-02-08T02:51:21.223513: step 1313, loss 0.323523, acc 0.796875
2020-02-08T02:51:21.342209: step 1314, loss 0.259236, acc 0.859375
2020-02-08T02:51:22.186020: step 1315, loss 0.260958, acc 0.90625
2020-02-08T02:51:22.308852: step 1316, loss 0.416038, acc 0.796875
2020-02-08T02:51:22.426602: step 1317, loss 0.231203, acc 0.890625
2020-02-08T02:51:22.545367: step 1318, loss 0.281545, acc 0.84375
2020-02-08T02:51:22.659658: step 1319, loss 0.291028, acc 0.875
2020-02-08T02:51:22.778368: step 1320, loss 0.287289, acc 0.890625
2020-02-08T02:51:22.893669: step 1321, loss 0.352113, acc 0.875
2020-02-08T02:51:23.008287: step 1322, loss 0.184092, acc 0.9375
2020-02-08T02:51:23.125725: step 1323, loss 0.204154, acc 0.921875
2020-02-08T02:51:23.241975: step 1324, loss 0.335134, acc 0.921875
2020-02-08T02:51:23.359371: step 1325, loss 0.279014, acc 0.890625
2020-02-08T02:51:23.475372: step 1326, loss 0.330788, acc 0.859375
2020-02-08T02:51:23.593521: step 1327, loss 0.398374, acc 0.84375
2020-02-08T02:51:23.710214: step 1328, loss 0.348464, acc 0.859375
2020-02-08T02:51:23.824926: step 1329, loss 0.318496, acc 0.890625
2020-02-08T02:51:23.941529: step 1330, loss 0.243214, acc 0.875
2020-02-08T02:51:24.058489: step 1331, loss 0.367815, acc 0.828125
2020-02-08T02:51:24.172806: step 1332, loss 0.238347, acc 0.90625
2020-02-08T02:51:24.288125: step 1333, loss 0.230868, acc 0.875
2020-02-08T02:51:24.403756: step 1334, loss 0.303321, acc 0.84375
2020-02-08T02:51:24.520339: step 1335, loss 0.315115, acc 0.875
2020-02-08T02:51:24.634294: step 1336, loss 0.198812, acc 0.921875
2020-02-08T02:51:24.746901: step 1337, loss 0.214322, acc 0.921875
2020-02-08T02:51:24.863166: step 1338, loss 0.315248, acc 0.859375
2020-02-08T02:51:24.974975: step 1339, loss 0.212555, acc 0.921875
2020-02-08T02:51:25.093430: step 1340, loss 0.209576, acc 0.890625
2020-02-08T02:51:25.208612: step 1341, loss 0.369663, acc 0.84375
2020-02-08T02:51:25.326336: step 1342, loss 0.237241, acc 0.921875
2020-02-08T02:51:25.442258: step 1343, loss 0.223043, acc 0.890625
2020-02-08T02:51:25.557039: step 1344, loss 0.270541, acc 0.9375
2020-02-08T02:51:25.673230: step 1345, loss 0.321024, acc 0.875
2020-02-08T02:51:25.792263: step 1346, loss 0.145295, acc 0.96875
2020-02-08T02:51:25.907465: step 1347, loss 0.304155, acc 0.875
2020-02-08T02:51:26.024234: step 1348, loss 0.221453, acc 0.890625
2020-02-08T02:51:26.141519: step 1349, loss 0.279069, acc 0.90625
2020-02-08T02:51:26.255618: step 1350, loss 0.21678, acc 0.916667
2020-02-08T02:51:26.375216: step 1351, loss 0.285341, acc 0.921875
2020-02-08T02:51:26.492836: step 1352, loss 0.1821, acc 0.9375
2020-02-08T02:51:26.608045: step 1353, loss 0.135256, acc 0.953125
2020-02-08T02:51:26.724019: step 1354, loss 0.322337, acc 0.828125
2020-02-08T02:51:26.839292: step 1355, loss 0.178072, acc 0.96875
2020-02-08T02:51:26.954742: step 1356, loss 0.207118, acc 0.921875
2020-02-08T02:51:27.069557: step 1357, loss 0.154989, acc 0.953125
2020-02-08T02:51:27.183818: step 1358, loss 0.2734, acc 0.84375
2020-02-08T02:51:27.301967: step 1359, loss 0.27403, acc 0.875
2020-02-08T02:51:27.415956: step 1360, loss 0.23939, acc 0.875
2020-02-08T02:51:27.532527: step 1361, loss 0.231108, acc 0.875
2020-02-08T02:51:27.649083: step 1362, loss 0.277441, acc 0.890625
2020-02-08T02:51:27.767259: step 1363, loss 0.197073, acc 0.953125
2020-02-08T02:51:27.882083: step 1364, loss 0.249648, acc 0.90625
2020-02-08T02:51:27.996550: step 1365, loss 0.127491, acc 0.96875
2020-02-08T02:51:28.111832: step 1366, loss 0.185114, acc 0.90625
2020-02-08T02:51:28.227027: step 1367, loss 0.146835, acc 0.96875
2020-02-08T02:51:28.345346: step 1368, loss 0.259239, acc 0.875
2020-02-08T02:51:28.460162: step 1369, loss 0.18914, acc 0.9375
2020-02-08T02:51:28.574289: step 1370, loss 0.148628, acc 0.96875
2020-02-08T02:51:28.688652: step 1371, loss 0.204932, acc 0.90625
2020-02-08T02:51:28.804042: step 1372, loss 0.154588, acc 0.953125
2020-02-08T02:51:28.920335: step 1373, loss 0.102109, acc 0.984375
2020-02-08T02:51:29.035875: step 1374, loss 0.237887, acc 0.890625
2020-02-08T02:51:29.151189: step 1375, loss 0.209082, acc 0.921875
2020-02-08T02:51:29.265687: step 1376, loss 0.214004, acc 0.875
2020-02-08T02:51:29.381631: step 1377, loss 0.215689, acc 0.921875
2020-02-08T02:51:29.498348: step 1378, loss 0.235577, acc 0.90625
2020-02-08T02:51:29.612332: step 1379, loss 0.169237, acc 0.9375
2020-02-08T02:51:29.727576: step 1380, loss 0.139725, acc 0.9375
2020-02-08T02:51:29.843693: step 1381, loss 0.236267, acc 0.875
2020-02-08T02:51:29.959450: step 1382, loss 0.169515, acc 0.9375
2020-02-08T02:51:30.075681: step 1383, loss 0.182645, acc 0.9375
2020-02-08T02:51:30.190651: step 1384, loss 0.233275, acc 0.921875
2020-02-08T02:51:30.308495: step 1385, loss 0.184143, acc 0.953125
2020-02-08T02:51:30.422071: step 1386, loss 0.138941, acc 0.96875
2020-02-08T02:51:30.538078: step 1387, loss 0.254891, acc 0.890625
2020-02-08T02:51:30.655734: step 1388, loss 0.233794, acc 0.875
2020-02-08T02:51:30.772037: step 1389, loss 0.17477, acc 0.953125
2020-02-08T02:51:30.888902: step 1390, loss 0.18709, acc 0.953125
2020-02-08T02:51:31.003742: step 1391, loss 0.247472, acc 0.921875
2020-02-08T02:51:31.120327: step 1392, loss 0.244399, acc 0.875
2020-02-08T02:51:31.235642: step 1393, loss 0.193734, acc 0.921875
2020-02-08T02:51:31.354899: step 1394, loss 0.209308, acc 0.9375
2020-02-08T02:51:31.469124: step 1395, loss 0.334599, acc 0.859375
2020-02-08T02:51:31.586764: step 1396, loss 0.215352, acc 0.90625
2020-02-08T02:51:31.703414: step 1397, loss 0.15893, acc 0.921875
2020-02-08T02:51:31.818975: step 1398, loss 0.175413, acc 0.921875
2020-02-08T02:51:31.936866: step 1399, loss 0.24607, acc 0.90625
2020-02-08T02:51:32.049817: step 1400, loss 0.234046, acc 0.875

Evaluation:
2020-02-08T02:51:32.236568: step 1400, loss 0.62453, acc 0.713884

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1400

2020-02-08T02:51:35.051007: step 1401, loss 0.306934, acc 0.859375
2020-02-08T02:51:35.163602: step 1402, loss 0.359613, acc 0.828125
2020-02-08T02:51:35.279829: step 1403, loss 0.23776, acc 0.859375
2020-02-08T02:51:35.397657: step 1404, loss 0.24624, acc 0.875
2020-02-08T02:51:35.512973: step 1405, loss 0.202659, acc 0.9375
2020-02-08T02:51:35.633699: step 1406, loss 0.170965, acc 0.90625
2020-02-08T02:51:35.754965: step 1407, loss 0.214269, acc 0.9375
2020-02-08T02:51:35.870798: step 1408, loss 0.164912, acc 0.953125
2020-02-08T02:51:35.987345: step 1409, loss 0.317795, acc 0.875
2020-02-08T02:51:36.106430: step 1410, loss 0.217669, acc 0.890625
2020-02-08T02:51:36.219299: step 1411, loss 0.104141, acc 0.96875
2020-02-08T02:51:36.337060: step 1412, loss 0.263782, acc 0.9375
2020-02-08T02:51:36.453299: step 1413, loss 0.268548, acc 0.953125
2020-02-08T02:51:36.569057: step 1414, loss 0.210401, acc 0.921875
2020-02-08T02:51:36.687186: step 1415, loss 0.207924, acc 0.90625
2020-02-08T02:51:36.806382: step 1416, loss 0.166509, acc 0.953125
2020-02-08T02:51:36.925552: step 1417, loss 0.248034, acc 0.921875
2020-02-08T02:51:37.041186: step 1418, loss 0.272083, acc 0.90625
2020-02-08T02:51:37.156253: step 1419, loss 0.186342, acc 0.90625
2020-02-08T02:51:37.273226: step 1420, loss 0.201564, acc 0.9375
2020-02-08T02:51:37.391675: step 1421, loss 0.196491, acc 0.90625
2020-02-08T02:51:37.505764: step 1422, loss 0.224637, acc 0.90625
2020-02-08T02:51:37.624898: step 1423, loss 0.202525, acc 0.921875
2020-02-08T02:51:37.740993: step 1424, loss 0.361028, acc 0.875
2020-02-08T02:51:37.856873: step 1425, loss 0.255648, acc 0.875
2020-02-08T02:51:37.974992: step 1426, loss 0.187461, acc 0.90625
2020-02-08T02:51:38.091779: step 1427, loss 0.1553, acc 0.921875
2020-02-08T02:51:38.206450: step 1428, loss 0.113887, acc 0.96875
2020-02-08T02:51:38.326053: step 1429, loss 0.178231, acc 0.953125
2020-02-08T02:51:38.443183: step 1430, loss 0.11012, acc 0.96875
2020-02-08T02:51:38.561429: step 1431, loss 0.242523, acc 0.890625
2020-02-08T02:51:38.676000: step 1432, loss 0.201479, acc 0.921875
2020-02-08T02:51:38.789237: step 1433, loss 0.150335, acc 0.96875
2020-02-08T02:51:38.906809: step 1434, loss 0.180685, acc 0.9375
2020-02-08T02:51:39.025377: step 1435, loss 0.127587, acc 0.9375
2020-02-08T02:51:39.140644: step 1436, loss 0.237794, acc 0.90625
2020-02-08T02:51:39.255016: step 1437, loss 0.246548, acc 0.921875
2020-02-08T02:51:39.371391: step 1438, loss 0.183846, acc 0.90625
2020-02-08T02:51:39.488267: step 1439, loss 0.238624, acc 0.875
2020-02-08T02:51:39.606108: step 1440, loss 0.513482, acc 0.796875
2020-02-08T02:51:39.721135: step 1441, loss 0.131441, acc 0.9375
2020-02-08T02:51:39.836885: step 1442, loss 0.229375, acc 0.875
2020-02-08T02:51:39.953563: step 1443, loss 0.332704, acc 0.90625
2020-02-08T02:51:40.068685: step 1444, loss 0.174642, acc 0.90625
2020-02-08T02:51:40.184821: step 1445, loss 0.227578, acc 0.921875
2020-02-08T02:51:40.300601: step 1446, loss 0.124936, acc 0.984375
2020-02-08T02:51:40.413312: step 1447, loss 0.154367, acc 0.9375
2020-02-08T02:51:40.532071: step 1448, loss 0.180455, acc 0.921875
2020-02-08T02:51:40.653072: step 1449, loss 0.187941, acc 0.9375
2020-02-08T02:51:40.768913: step 1450, loss 0.28111, acc 0.890625
2020-02-08T02:51:40.885736: step 1451, loss 0.259364, acc 0.90625
2020-02-08T02:51:41.001651: step 1452, loss 0.216852, acc 0.9375
2020-02-08T02:51:41.116906: step 1453, loss 0.146785, acc 0.953125
2020-02-08T02:51:41.232063: step 1454, loss 0.194978, acc 0.90625
2020-02-08T02:51:41.352810: step 1455, loss 0.183594, acc 0.9375
2020-02-08T02:51:41.468160: step 1456, loss 0.239953, acc 0.90625
2020-02-08T02:51:41.584691: step 1457, loss 0.146132, acc 0.96875
2020-02-08T02:51:41.701943: step 1458, loss 0.308099, acc 0.875
2020-02-08T02:51:41.818543: step 1459, loss 0.186642, acc 0.9375
2020-02-08T02:51:41.935739: step 1460, loss 0.26917, acc 0.90625
2020-02-08T02:51:42.052360: step 1461, loss 0.29171, acc 0.921875
2020-02-08T02:51:42.166691: step 1462, loss 0.198201, acc 0.9375
2020-02-08T02:51:42.283940: step 1463, loss 0.209761, acc 0.953125
2020-02-08T02:51:42.400302: step 1464, loss 0.183435, acc 0.90625
2020-02-08T02:51:42.516333: step 1465, loss 0.149875, acc 0.90625
2020-02-08T02:51:42.634216: step 1466, loss 0.0908746, acc 0.96875
2020-02-08T02:51:42.753412: step 1467, loss 0.18992, acc 0.90625
2020-02-08T02:51:42.868487: step 1468, loss 0.21437, acc 0.890625
2020-02-08T02:51:42.989239: step 1469, loss 0.139403, acc 0.96875
2020-02-08T02:51:43.104495: step 1470, loss 0.286774, acc 0.859375
2020-02-08T02:51:43.220400: step 1471, loss 0.281305, acc 0.84375
2020-02-08T02:51:43.337800: step 1472, loss 0.163386, acc 0.90625
2020-02-08T02:51:43.452705: step 1473, loss 0.148713, acc 0.9375
2020-02-08T02:51:43.566914: step 1474, loss 0.184259, acc 0.921875
2020-02-08T02:51:43.685757: step 1475, loss 0.134052, acc 0.953125
2020-02-08T02:51:43.800988: step 1476, loss 0.274092, acc 0.84375
2020-02-08T02:51:43.916169: step 1477, loss 0.109639, acc 0.96875
2020-02-08T02:51:44.032033: step 1478, loss 0.193472, acc 0.9375
2020-02-08T02:51:44.152258: step 1479, loss 0.307981, acc 0.90625
2020-02-08T02:51:44.268924: step 1480, loss 0.14668, acc 0.984375
2020-02-08T02:51:44.388538: step 1481, loss 0.236355, acc 0.859375
2020-02-08T02:51:44.503623: step 1482, loss 0.227085, acc 0.921875
2020-02-08T02:51:44.618313: step 1483, loss 0.132612, acc 0.953125
2020-02-08T02:51:44.734291: step 1484, loss 0.178623, acc 0.921875
2020-02-08T02:51:44.850750: step 1485, loss 0.181172, acc 0.921875
2020-02-08T02:51:44.967575: step 1486, loss 0.224153, acc 0.890625
2020-02-08T02:51:45.083752: step 1487, loss 0.229351, acc 0.90625
2020-02-08T02:51:45.200562: step 1488, loss 0.232633, acc 0.90625
2020-02-08T02:51:45.317112: step 1489, loss 0.265454, acc 0.890625
2020-02-08T02:51:45.434812: step 1490, loss 0.167706, acc 0.90625
2020-02-08T02:51:45.552078: step 1491, loss 0.215518, acc 0.921875
2020-02-08T02:51:45.666860: step 1492, loss 0.20264, acc 0.90625
2020-02-08T02:51:45.785377: step 1493, loss 0.288432, acc 0.859375
2020-02-08T02:51:45.902055: step 1494, loss 0.237299, acc 0.90625
2020-02-08T02:51:46.016324: step 1495, loss 0.250298, acc 0.921875
2020-02-08T02:51:46.132263: step 1496, loss 0.299582, acc 0.921875
2020-02-08T02:51:46.249109: step 1497, loss 0.202336, acc 0.921875
2020-02-08T02:51:46.363177: step 1498, loss 0.0833486, acc 1
2020-02-08T02:51:46.477658: step 1499, loss 0.234771, acc 0.875
2020-02-08T02:51:46.592603: step 1500, loss 0.169907, acc 0.95

Evaluation:
2020-02-08T02:51:46.780019: step 1500, loss 0.625838, acc 0.721388

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1500

2020-02-08T02:51:48.772067: step 1501, loss 0.113198, acc 0.96875
2020-02-08T02:51:48.890425: step 1502, loss 0.177444, acc 0.921875
2020-02-08T02:51:49.005981: step 1503, loss 0.122283, acc 0.9375
2020-02-08T02:51:49.119734: step 1504, loss 0.153216, acc 0.953125
2020-02-08T02:51:49.240893: step 1505, loss 0.104014, acc 0.984375
2020-02-08T02:51:49.356919: step 1506, loss 0.149539, acc 0.9375
2020-02-08T02:51:49.472144: step 1507, loss 0.150783, acc 0.953125
2020-02-08T02:51:49.588107: step 1508, loss 0.115655, acc 0.984375
2020-02-08T02:51:49.704314: step 1509, loss 0.157572, acc 0.921875
2020-02-08T02:51:49.821941: step 1510, loss 0.124835, acc 0.953125
2020-02-08T02:51:49.939830: step 1511, loss 0.122793, acc 0.953125
2020-02-08T02:51:50.056185: step 1512, loss 0.242633, acc 0.890625
2020-02-08T02:51:50.172608: step 1513, loss 0.241453, acc 0.875
2020-02-08T02:51:50.292107: step 1514, loss 0.143147, acc 0.921875
2020-02-08T02:51:50.408410: step 1515, loss 0.149362, acc 0.953125
2020-02-08T02:51:50.526430: step 1516, loss 0.130702, acc 0.9375
2020-02-08T02:51:50.644179: step 1517, loss 0.182511, acc 0.96875
2020-02-08T02:51:50.758663: step 1518, loss 0.194867, acc 0.921875
2020-02-08T02:51:50.872055: step 1519, loss 0.157276, acc 0.953125
2020-02-08T02:51:50.988378: step 1520, loss 0.145111, acc 0.9375
2020-02-08T02:51:51.105317: step 1521, loss 0.148685, acc 0.9375
2020-02-08T02:51:51.218174: step 1522, loss 0.253643, acc 0.90625
2020-02-08T02:51:51.335196: step 1523, loss 0.120185, acc 0.953125
2020-02-08T02:51:51.447779: step 1524, loss 0.24665, acc 0.90625
2020-02-08T02:51:51.561328: step 1525, loss 0.121796, acc 0.96875
2020-02-08T02:51:51.690849: step 1526, loss 0.104282, acc 0.984375
2020-02-08T02:51:51.807679: step 1527, loss 0.179964, acc 0.9375
2020-02-08T02:51:51.924105: step 1528, loss 0.232313, acc 0.90625
2020-02-08T02:51:52.042274: step 1529, loss 0.248848, acc 0.90625
2020-02-08T02:51:52.159757: step 1530, loss 0.154973, acc 0.921875
2020-02-08T02:51:52.278186: step 1531, loss 0.194437, acc 0.953125
2020-02-08T02:51:52.396018: step 1532, loss 0.120424, acc 0.984375
2020-02-08T02:51:52.511415: step 1533, loss 0.142097, acc 0.9375
2020-02-08T02:51:52.628882: step 1534, loss 0.211792, acc 0.90625
2020-02-08T02:51:52.747141: step 1535, loss 0.134732, acc 0.96875
2020-02-08T02:51:52.862686: step 1536, loss 0.131174, acc 0.96875
2020-02-08T02:51:52.977409: step 1537, loss 0.168845, acc 0.953125
2020-02-08T02:51:53.092170: step 1538, loss 0.134201, acc 0.984375
2020-02-08T02:51:53.208993: step 1539, loss 0.129732, acc 0.953125
2020-02-08T02:51:53.324840: step 1540, loss 0.182488, acc 0.90625
2020-02-08T02:51:53.440660: step 1541, loss 0.106611, acc 0.96875
2020-02-08T02:51:53.555914: step 1542, loss 0.229104, acc 0.890625
2020-02-08T02:51:53.671918: step 1543, loss 0.201463, acc 0.890625
2020-02-08T02:51:53.788176: step 1544, loss 0.171733, acc 0.9375
2020-02-08T02:51:53.901808: step 1545, loss 0.154206, acc 0.9375
2020-02-08T02:51:54.017973: step 1546, loss 0.0999066, acc 0.96875
2020-02-08T02:51:54.134608: step 1547, loss 0.192311, acc 0.9375
2020-02-08T02:51:54.251580: step 1548, loss 0.215691, acc 0.9375
2020-02-08T02:51:54.366168: step 1549, loss 0.184998, acc 0.953125
2020-02-08T02:51:54.483357: step 1550, loss 0.116834, acc 0.9375
2020-02-08T02:51:54.601110: step 1551, loss 0.101206, acc 0.984375
2020-02-08T02:51:54.717374: step 1552, loss 0.198334, acc 0.890625
2020-02-08T02:51:54.834353: step 1553, loss 0.220492, acc 0.921875
2020-02-08T02:51:54.951437: step 1554, loss 0.190752, acc 0.953125
2020-02-08T02:51:55.067117: step 1555, loss 0.213717, acc 0.921875
2020-02-08T02:51:55.184475: step 1556, loss 0.197352, acc 0.90625
2020-02-08T02:51:55.299970: step 1557, loss 0.137103, acc 0.921875
2020-02-08T02:51:55.414781: step 1558, loss 0.202457, acc 0.90625
2020-02-08T02:51:55.530315: step 1559, loss 0.118146, acc 0.96875
2020-02-08T02:51:55.647796: step 1560, loss 0.274908, acc 0.875
2020-02-08T02:51:55.764350: step 1561, loss 0.0587026, acc 1
2020-02-08T02:51:55.881896: step 1562, loss 0.133146, acc 0.96875
2020-02-08T02:51:56.003462: step 1563, loss 0.214673, acc 0.890625
2020-02-08T02:51:56.119175: step 1564, loss 0.195341, acc 0.921875
2020-02-08T02:51:56.236465: step 1565, loss 0.173545, acc 0.9375
2020-02-08T02:51:56.353600: step 1566, loss 0.142771, acc 0.953125
2020-02-08T02:51:56.469226: step 1567, loss 0.170176, acc 0.921875
2020-02-08T02:51:56.586091: step 1568, loss 0.126831, acc 0.96875
2020-02-08T02:51:56.703291: step 1569, loss 0.106414, acc 0.953125
2020-02-08T02:51:56.818631: step 1570, loss 0.114996, acc 0.953125
2020-02-08T02:51:56.933590: step 1571, loss 0.173992, acc 0.9375
2020-02-08T02:51:57.047759: step 1572, loss 0.15501, acc 0.9375
2020-02-08T02:51:57.162217: step 1573, loss 0.157994, acc 0.953125
2020-02-08T02:51:57.274731: step 1574, loss 0.159987, acc 0.96875
2020-02-08T02:51:57.392392: step 1575, loss 0.180519, acc 0.921875
2020-02-08T02:51:57.508326: step 1576, loss 0.202474, acc 0.921875
2020-02-08T02:51:57.624308: step 1577, loss 0.055938, acc 0.984375
2020-02-08T02:51:57.741002: step 1578, loss 0.126182, acc 0.96875
2020-02-08T02:51:57.856647: step 1579, loss 0.182098, acc 0.90625
2020-02-08T02:51:57.971107: step 1580, loss 0.131321, acc 0.921875
2020-02-08T02:51:58.086229: step 1581, loss 0.15622, acc 0.96875
2020-02-08T02:51:58.202171: step 1582, loss 0.168076, acc 0.9375
2020-02-08T02:51:58.318924: step 1583, loss 0.198837, acc 0.9375
2020-02-08T02:51:58.434718: step 1584, loss 0.135518, acc 0.953125
2020-02-08T02:51:58.551484: step 1585, loss 0.191097, acc 0.9375
2020-02-08T02:51:58.668790: step 1586, loss 0.140204, acc 0.953125
2020-02-08T02:51:58.786825: step 1587, loss 0.161069, acc 0.9375
2020-02-08T02:51:58.902237: step 1588, loss 0.221105, acc 0.90625
2020-02-08T02:51:59.018005: step 1589, loss 0.295741, acc 0.90625
2020-02-08T02:51:59.135078: step 1590, loss 0.154297, acc 0.921875
2020-02-08T02:51:59.248946: step 1591, loss 0.250932, acc 0.90625
2020-02-08T02:51:59.364358: step 1592, loss 0.200414, acc 0.921875
2020-02-08T02:51:59.480018: step 1593, loss 0.186625, acc 0.90625
2020-02-08T02:51:59.594857: step 1594, loss 0.173391, acc 0.921875
2020-02-08T02:51:59.709616: step 1595, loss 0.176161, acc 0.921875
2020-02-08T02:51:59.825707: step 1596, loss 0.127466, acc 0.984375
2020-02-08T02:51:59.942718: step 1597, loss 0.122108, acc 0.96875
2020-02-08T02:52:00.057616: step 1598, loss 0.102864, acc 0.96875
2020-02-08T02:52:00.175463: step 1599, loss 0.259976, acc 0.953125
2020-02-08T02:52:00.293883: step 1600, loss 0.283031, acc 0.84375

Evaluation:
2020-02-08T02:52:00.480264: step 1600, loss 0.635685, acc 0.722326

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1600

2020-02-08T02:52:01.999332: step 1601, loss 0.185881, acc 0.9375
2020-02-08T02:52:02.113470: step 1602, loss 0.141962, acc 0.9375
2020-02-08T02:52:02.229307: step 1603, loss 0.196159, acc 0.9375
2020-02-08T02:52:02.347843: step 1604, loss 0.183679, acc 0.9375
2020-02-08T02:52:02.463125: step 1605, loss 0.200582, acc 0.921875
2020-02-08T02:52:02.580333: step 1606, loss 0.14974, acc 0.921875
2020-02-08T02:52:02.698433: step 1607, loss 0.223474, acc 0.90625
2020-02-08T02:52:02.812104: step 1608, loss 0.228387, acc 0.875
2020-02-08T02:52:02.927784: step 1609, loss 0.201931, acc 0.9375
2020-02-08T02:52:03.044586: step 1610, loss 0.200807, acc 0.921875
2020-02-08T02:52:03.158348: step 1611, loss 0.175468, acc 0.921875
2020-02-08T02:52:03.273807: step 1612, loss 0.194603, acc 0.921875
2020-02-08T02:52:03.396956: step 1613, loss 0.23056, acc 0.890625
2020-02-08T02:52:03.511860: step 1614, loss 0.151982, acc 0.953125
2020-02-08T02:52:03.628235: step 1615, loss 0.178354, acc 0.9375
2020-02-08T02:52:03.744127: step 1616, loss 0.205275, acc 0.90625
2020-02-08T02:52:03.859725: step 1617, loss 0.193425, acc 0.90625
2020-02-08T02:52:03.973613: step 1618, loss 0.0825294, acc 0.96875
2020-02-08T02:52:04.091015: step 1619, loss 0.145293, acc 0.9375
2020-02-08T02:52:04.205730: step 1620, loss 0.108426, acc 0.953125
2020-02-08T02:52:04.320545: step 1621, loss 0.112914, acc 0.96875
2020-02-08T02:52:04.435260: step 1622, loss 0.209315, acc 0.921875
2020-02-08T02:52:04.550948: step 1623, loss 0.251496, acc 0.9375
2020-02-08T02:52:04.665094: step 1624, loss 0.125497, acc 0.953125
2020-02-08T02:52:04.782247: step 1625, loss 0.162328, acc 0.9375
2020-02-08T02:52:04.897378: step 1626, loss 0.0777848, acc 0.96875
2020-02-08T02:52:05.010562: step 1627, loss 0.224179, acc 0.90625
2020-02-08T02:52:05.128638: step 1628, loss 0.323871, acc 0.859375
2020-02-08T02:52:05.247635: step 1629, loss 0.209133, acc 0.890625
2020-02-08T02:52:05.363416: step 1630, loss 0.0961368, acc 0.9375
2020-02-08T02:52:05.482210: step 1631, loss 0.201891, acc 0.921875
2020-02-08T02:52:05.599085: step 1632, loss 0.160465, acc 0.9375
2020-02-08T02:52:05.713275: step 1633, loss 0.276666, acc 0.875
2020-02-08T02:52:05.830594: step 1634, loss 0.192235, acc 0.9375
2020-02-08T02:52:05.947691: step 1635, loss 0.128443, acc 0.984375
2020-02-08T02:52:06.063443: step 1636, loss 0.150039, acc 0.921875
2020-02-08T02:52:06.186430: step 1637, loss 0.333024, acc 0.859375
2020-02-08T02:52:06.304469: step 1638, loss 0.0999714, acc 0.96875
2020-02-08T02:52:06.418781: step 1639, loss 0.264007, acc 0.859375
2020-02-08T02:52:06.536301: step 1640, loss 0.134588, acc 0.96875
2020-02-08T02:52:06.654640: step 1641, loss 0.0968955, acc 0.953125
2020-02-08T02:52:06.767323: step 1642, loss 0.310759, acc 0.859375
2020-02-08T02:52:06.884819: step 1643, loss 0.152589, acc 0.9375
2020-02-08T02:52:07.003972: step 1644, loss 0.152065, acc 0.953125
2020-02-08T02:52:07.117175: step 1645, loss 0.158552, acc 0.953125
2020-02-08T02:52:07.232187: step 1646, loss 0.175251, acc 0.921875
2020-02-08T02:52:07.347981: step 1647, loss 0.101103, acc 0.953125
2020-02-08T02:52:07.464044: step 1648, loss 0.135492, acc 0.90625
2020-02-08T02:52:07.579731: step 1649, loss 0.145124, acc 0.9375
2020-02-08T02:52:07.691303: step 1650, loss 0.289398, acc 0.883333
2020-02-08T02:52:07.808629: step 1651, loss 0.134184, acc 0.90625
2020-02-08T02:52:07.925139: step 1652, loss 0.171481, acc 0.96875
2020-02-08T02:52:08.043286: step 1653, loss 0.203884, acc 0.90625
2020-02-08T02:52:08.158018: step 1654, loss 0.133998, acc 0.9375
2020-02-08T02:52:08.274035: step 1655, loss 0.171474, acc 0.953125
2020-02-08T02:52:08.394116: step 1656, loss 0.150577, acc 0.9375
2020-02-08T02:52:08.509852: step 1657, loss 0.232894, acc 0.921875
2020-02-08T02:52:08.622741: step 1658, loss 0.104954, acc 0.96875
2020-02-08T02:52:08.738460: step 1659, loss 0.0770276, acc 1
2020-02-08T02:52:08.854709: step 1660, loss 0.152691, acc 0.953125
2020-02-08T02:52:08.966633: step 1661, loss 0.14351, acc 0.921875
2020-02-08T02:52:09.084352: step 1662, loss 0.110304, acc 0.96875
2020-02-08T02:52:09.201378: step 1663, loss 0.0698907, acc 0.984375
2020-02-08T02:52:09.316122: step 1664, loss 0.133317, acc 0.9375
2020-02-08T02:52:09.433583: step 1665, loss 0.053226, acc 1
2020-02-08T02:52:09.550279: step 1666, loss 0.0933776, acc 0.984375
2020-02-08T02:52:09.666538: step 1667, loss 0.17941, acc 0.921875
2020-02-08T02:52:09.783932: step 1668, loss 0.0866197, acc 0.984375
2020-02-08T02:52:09.901999: step 1669, loss 0.0614272, acc 1
2020-02-08T02:52:10.017122: step 1670, loss 0.143587, acc 0.953125
2020-02-08T02:52:10.134745: step 1671, loss 0.0898164, acc 0.984375
2020-02-08T02:52:10.248404: step 1672, loss 0.128491, acc 0.921875
2020-02-08T02:52:10.363171: step 1673, loss 0.152876, acc 0.953125
2020-02-08T02:52:10.479756: step 1674, loss 0.0832462, acc 0.953125
2020-02-08T02:52:10.596755: step 1675, loss 0.123315, acc 0.96875
2020-02-08T02:52:10.712679: step 1676, loss 0.207651, acc 0.9375
2020-02-08T02:52:10.828409: step 1677, loss 0.197246, acc 0.90625
2020-02-08T02:52:10.944143: step 1678, loss 0.1963, acc 0.921875
2020-02-08T02:52:11.058424: step 1679, loss 0.168259, acc 0.9375
2020-02-08T02:52:11.175654: step 1680, loss 0.100454, acc 0.953125
2020-02-08T02:52:11.292693: step 1681, loss 0.037882, acc 1
2020-02-08T02:52:11.407731: step 1682, loss 0.257362, acc 0.90625
2020-02-08T02:52:11.526075: step 1683, loss 0.0818015, acc 0.984375
2020-02-08T02:52:11.642275: step 1684, loss 0.0641529, acc 0.984375
2020-02-08T02:52:11.758585: step 1685, loss 0.164599, acc 0.9375
2020-02-08T02:52:11.873596: step 1686, loss 0.178975, acc 0.90625
2020-02-08T02:52:11.992660: step 1687, loss 0.0530725, acc 0.984375
2020-02-08T02:52:12.109583: step 1688, loss 0.0606367, acc 1
2020-02-08T02:52:12.225260: step 1689, loss 0.11817, acc 0.96875
2020-02-08T02:52:12.344137: step 1690, loss 0.0873109, acc 0.953125
2020-02-08T02:52:12.459420: step 1691, loss 0.0766551, acc 0.96875
2020-02-08T02:52:12.579444: step 1692, loss 0.19088, acc 0.9375
2020-02-08T02:52:12.700730: step 1693, loss 0.122813, acc 0.96875
2020-02-08T02:52:12.816244: step 1694, loss 0.142082, acc 0.984375
2020-02-08T02:52:12.932336: step 1695, loss 0.21872, acc 0.90625
2020-02-08T02:52:13.052497: step 1696, loss 0.110375, acc 0.953125
2020-02-08T02:52:13.168645: step 1697, loss 0.107563, acc 0.953125
2020-02-08T02:52:13.285285: step 1698, loss 0.0778011, acc 0.984375
2020-02-08T02:52:13.401447: step 1699, loss 0.0780752, acc 0.96875
2020-02-08T02:52:13.515811: step 1700, loss 0.0827562, acc 0.96875

Evaluation:
2020-02-08T02:52:13.703942: step 1700, loss 0.715112, acc 0.714822

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1700

2020-02-08T02:52:15.256618: step 1701, loss 0.105873, acc 0.96875
2020-02-08T02:52:15.371562: step 1702, loss 0.148601, acc 0.921875
2020-02-08T02:52:15.487320: step 1703, loss 0.180612, acc 0.953125
2020-02-08T02:52:15.603067: step 1704, loss 0.264824, acc 0.921875
2020-02-08T02:52:15.720473: step 1705, loss 0.12981, acc 0.9375
2020-02-08T02:52:15.838739: step 1706, loss 0.154793, acc 0.921875
2020-02-08T02:52:15.956383: step 1707, loss 0.043393, acc 1
2020-02-08T02:52:16.072854: step 1708, loss 0.119056, acc 0.953125
2020-02-08T02:52:16.189999: step 1709, loss 0.122725, acc 0.953125
2020-02-08T02:52:16.307569: step 1710, loss 0.143127, acc 0.921875
2020-02-08T02:52:16.424788: step 1711, loss 0.172043, acc 0.921875
2020-02-08T02:52:16.541177: step 1712, loss 0.0760809, acc 0.96875
2020-02-08T02:52:16.654973: step 1713, loss 0.110617, acc 0.96875
2020-02-08T02:52:16.768313: step 1714, loss 0.182834, acc 0.9375
2020-02-08T02:52:16.884451: step 1715, loss 0.126814, acc 0.96875
2020-02-08T02:52:17.002255: step 1716, loss 0.123001, acc 0.96875
2020-02-08T02:52:17.117727: step 1717, loss 0.0957428, acc 0.984375
2020-02-08T02:52:17.234668: step 1718, loss 0.155409, acc 0.96875
2020-02-08T02:52:17.348886: step 1719, loss 0.0999191, acc 0.96875
2020-02-08T02:52:17.463096: step 1720, loss 0.166442, acc 0.921875
2020-02-08T02:52:17.577394: step 1721, loss 0.0788071, acc 0.96875
2020-02-08T02:52:17.691821: step 1722, loss 0.122538, acc 0.96875
2020-02-08T02:52:17.808057: step 1723, loss 0.0771599, acc 0.96875
2020-02-08T02:52:17.922618: step 1724, loss 0.157157, acc 0.953125
2020-02-08T02:52:18.039763: step 1725, loss 0.0601849, acc 1
2020-02-08T02:52:18.155338: step 1726, loss 0.0876304, acc 0.984375
2020-02-08T02:52:18.271015: step 1727, loss 0.15898, acc 0.9375
2020-02-08T02:52:18.386898: step 1728, loss 0.137686, acc 0.9375
2020-02-08T02:52:18.506020: step 1729, loss 0.257421, acc 0.875
2020-02-08T02:52:18.624677: step 1730, loss 0.144904, acc 0.921875
2020-02-08T02:52:18.740891: step 1731, loss 0.101004, acc 0.984375
2020-02-08T02:52:18.856367: step 1732, loss 0.127987, acc 0.953125
2020-02-08T02:52:18.972509: step 1733, loss 0.200981, acc 0.9375
2020-02-08T02:52:19.089363: step 1734, loss 0.107381, acc 0.984375
2020-02-08T02:52:19.207036: step 1735, loss 0.124013, acc 0.9375
2020-02-08T02:52:19.323489: step 1736, loss 0.18392, acc 0.953125
2020-02-08T02:52:19.436478: step 1737, loss 0.0930255, acc 0.984375
2020-02-08T02:52:19.552130: step 1738, loss 0.122643, acc 0.984375
2020-02-08T02:52:19.668460: step 1739, loss 0.088665, acc 0.953125
2020-02-08T02:52:19.786469: step 1740, loss 0.118452, acc 0.96875
2020-02-08T02:52:19.902565: step 1741, loss 0.285875, acc 0.921875
2020-02-08T02:52:20.016096: step 1742, loss 0.0895625, acc 0.96875
2020-02-08T02:52:20.132017: step 1743, loss 0.073127, acc 0.96875
2020-02-08T02:52:20.248255: step 1744, loss 0.136052, acc 0.953125
2020-02-08T02:52:20.363571: step 1745, loss 0.133612, acc 0.9375
2020-02-08T02:52:20.479387: step 1746, loss 0.199193, acc 0.90625
2020-02-08T02:52:20.599572: step 1747, loss 0.0807714, acc 0.96875
2020-02-08T02:52:20.713879: step 1748, loss 0.141456, acc 0.9375
2020-02-08T02:52:20.826504: step 1749, loss 0.140348, acc 0.953125
2020-02-08T02:52:20.940558: step 1750, loss 0.113847, acc 0.953125
2020-02-08T02:52:21.057633: step 1751, loss 0.109975, acc 0.953125
2020-02-08T02:52:21.172666: step 1752, loss 0.0930158, acc 0.96875
2020-02-08T02:52:21.560081: step 1753, loss 0.197371, acc 0.921875
2020-02-08T02:52:21.684279: step 1754, loss 0.147809, acc 0.9375
2020-02-08T02:52:21.800195: step 1755, loss 0.104756, acc 0.96875
2020-02-08T02:52:21.916918: step 1756, loss 0.0994833, acc 0.96875
2020-02-08T02:52:22.032428: step 1757, loss 0.0882666, acc 0.96875
2020-02-08T02:52:22.149201: step 1758, loss 0.104175, acc 0.953125
2020-02-08T02:52:22.262963: step 1759, loss 0.162258, acc 0.9375
2020-02-08T02:52:22.380843: step 1760, loss 0.115975, acc 0.9375
2020-02-08T02:52:22.496817: step 1761, loss 0.133107, acc 0.96875
2020-02-08T02:52:22.612891: step 1762, loss 0.193004, acc 0.921875
2020-02-08T02:52:22.728872: step 1763, loss 0.131698, acc 0.953125
2020-02-08T02:52:22.845624: step 1764, loss 0.133579, acc 0.96875
2020-02-08T02:52:22.963014: step 1765, loss 0.12, acc 0.9375
2020-02-08T02:52:23.078871: step 1766, loss 0.0959531, acc 0.96875
2020-02-08T02:52:23.196343: step 1767, loss 0.112852, acc 0.9375
2020-02-08T02:52:23.310989: step 1768, loss 0.11353, acc 0.953125
2020-02-08T02:52:23.424953: step 1769, loss 0.0813001, acc 0.953125
2020-02-08T02:52:23.541050: step 1770, loss 0.0513932, acc 1
2020-02-08T02:52:23.655075: step 1771, loss 0.222374, acc 0.9375
2020-02-08T02:52:23.770089: step 1772, loss 0.070532, acc 1
2020-02-08T02:52:23.885039: step 1773, loss 0.156704, acc 0.921875
2020-02-08T02:52:23.999441: step 1774, loss 0.110475, acc 0.953125
2020-02-08T02:52:24.114991: step 1775, loss 0.0818449, acc 0.96875
2020-02-08T02:52:24.231853: step 1776, loss 0.204838, acc 0.9375
2020-02-08T02:52:24.347437: step 1777, loss 0.166307, acc 0.890625
2020-02-08T02:52:24.464107: step 1778, loss 0.0515895, acc 0.984375
2020-02-08T02:52:24.581320: step 1779, loss 0.147091, acc 0.921875
2020-02-08T02:52:24.697515: step 1780, loss 0.170351, acc 0.921875
2020-02-08T02:52:24.813084: step 1781, loss 0.103429, acc 0.953125
2020-02-08T02:52:24.929749: step 1782, loss 0.139829, acc 0.921875
2020-02-08T02:52:25.046652: step 1783, loss 0.105198, acc 0.953125
2020-02-08T02:52:25.161885: step 1784, loss 0.186045, acc 0.9375
2020-02-08T02:52:25.278010: step 1785, loss 0.158863, acc 0.921875
2020-02-08T02:52:25.396565: step 1786, loss 0.137745, acc 0.9375
2020-02-08T02:52:25.509300: step 1787, loss 0.14614, acc 0.90625
2020-02-08T02:52:25.624318: step 1788, loss 0.169475, acc 0.9375
2020-02-08T02:52:25.743638: step 1789, loss 0.115408, acc 0.96875
2020-02-08T02:52:25.859224: step 1790, loss 0.166997, acc 0.9375
2020-02-08T02:52:25.977234: step 1791, loss 0.0918746, acc 0.96875
2020-02-08T02:52:26.094081: step 1792, loss 0.250147, acc 0.90625
2020-02-08T02:52:26.208880: step 1793, loss 0.150658, acc 0.9375
2020-02-08T02:52:26.323749: step 1794, loss 0.135789, acc 0.953125
2020-02-08T02:52:26.438279: step 1795, loss 0.231565, acc 0.875
2020-02-08T02:52:26.552553: step 1796, loss 0.0868887, acc 0.953125
2020-02-08T02:52:26.666056: step 1797, loss 0.127094, acc 0.96875
2020-02-08T02:52:26.781552: step 1798, loss 0.136431, acc 0.953125
2020-02-08T02:52:26.895557: step 1799, loss 0.0711428, acc 0.984375
2020-02-08T02:52:27.007579: step 1800, loss 0.201987, acc 0.933333

Evaluation:
2020-02-08T02:52:27.200871: step 1800, loss 0.68417, acc 0.730769

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1800

2020-02-08T02:52:28.692531: step 1801, loss 0.0887471, acc 0.96875
2020-02-08T02:52:28.810877: step 1802, loss 0.143663, acc 0.96875
2020-02-08T02:52:28.925456: step 1803, loss 0.0705087, acc 0.96875
2020-02-08T02:52:29.043873: step 1804, loss 0.0493672, acc 1
2020-02-08T02:52:29.159906: step 1805, loss 0.0682023, acc 1
2020-02-08T02:52:29.274803: step 1806, loss 0.0937444, acc 0.953125
2020-02-08T02:52:29.397597: step 1807, loss 0.098508, acc 0.96875
2020-02-08T02:52:29.511505: step 1808, loss 0.105276, acc 0.96875
2020-02-08T02:52:29.626055: step 1809, loss 0.149912, acc 0.953125
2020-02-08T02:52:29.838999: step 1810, loss 0.0848116, acc 0.984375
2020-02-08T02:52:29.982694: step 1811, loss 0.123536, acc 0.9375
2020-02-08T02:52:30.114278: step 1812, loss 0.0239376, acc 1
2020-02-08T02:52:30.246732: step 1813, loss 0.124534, acc 0.96875
2020-02-08T02:52:30.381948: step 1814, loss 0.123422, acc 0.9375
2020-02-08T02:52:30.513694: step 1815, loss 0.122134, acc 0.953125
2020-02-08T02:52:30.645586: step 1816, loss 0.13368, acc 0.953125
2020-02-08T02:52:30.776403: step 1817, loss 0.13706, acc 0.953125
2020-02-08T02:52:30.907908: step 1818, loss 0.0662467, acc 0.984375
2020-02-08T02:52:31.035472: step 1819, loss 0.115699, acc 0.953125
2020-02-08T02:52:31.165291: step 1820, loss 0.0785333, acc 0.96875
2020-02-08T02:52:31.304797: step 1821, loss 0.11186, acc 0.9375
2020-02-08T02:52:31.436727: step 1822, loss 0.0680137, acc 1
2020-02-08T02:52:31.564073: step 1823, loss 0.124879, acc 0.953125
2020-02-08T02:52:31.694824: step 1824, loss 0.188533, acc 0.890625
2020-02-08T02:52:31.824907: step 1825, loss 0.102111, acc 0.96875
2020-02-08T02:52:31.952368: step 1826, loss 0.1142, acc 0.9375
2020-02-08T02:52:32.082007: step 1827, loss 0.111753, acc 0.9375
2020-02-08T02:52:32.209143: step 1828, loss 0.0633404, acc 0.953125
2020-02-08T02:52:32.340726: step 1829, loss 0.158736, acc 0.953125
2020-02-08T02:52:32.471355: step 1830, loss 0.072444, acc 0.96875
2020-02-08T02:52:32.600512: step 1831, loss 0.104627, acc 0.921875
2020-02-08T02:52:32.736109: step 1832, loss 0.0880227, acc 0.96875
2020-02-08T02:52:32.869412: step 1833, loss 0.12075, acc 0.984375
2020-02-08T02:52:33.012548: step 1834, loss 0.118444, acc 0.953125
2020-02-08T02:52:33.150872: step 1835, loss 0.0846362, acc 0.984375
2020-02-08T02:52:33.308526: step 1836, loss 0.175754, acc 0.90625
2020-02-08T02:52:33.452398: step 1837, loss 0.0734919, acc 0.96875
2020-02-08T02:52:33.581716: step 1838, loss 0.131156, acc 0.9375
2020-02-08T02:52:33.711368: step 1839, loss 0.10875, acc 0.96875
2020-02-08T02:52:33.838018: step 1840, loss 0.038862, acc 1
2020-02-08T02:52:33.963175: step 1841, loss 0.10471, acc 0.921875
2020-02-08T02:52:34.086079: step 1842, loss 0.109115, acc 0.96875
2020-02-08T02:52:34.209831: step 1843, loss 0.0499339, acc 0.984375
2020-02-08T02:52:34.337121: step 1844, loss 0.0474387, acc 1
2020-02-08T02:52:34.464024: step 1845, loss 0.144396, acc 0.953125
2020-02-08T02:52:34.590048: step 1846, loss 0.032383, acc 0.984375
2020-02-08T02:52:34.722057: step 1847, loss 0.0758941, acc 0.96875
2020-02-08T02:52:34.859739: step 1848, loss 0.131861, acc 0.96875
2020-02-08T02:52:34.996402: step 1849, loss 0.100464, acc 0.984375
2020-02-08T02:52:35.131113: step 1850, loss 0.139056, acc 0.921875
2020-02-08T02:52:35.265367: step 1851, loss 0.127677, acc 0.9375
2020-02-08T02:52:35.406000: step 1852, loss 0.116575, acc 0.96875
2020-02-08T02:52:35.548692: step 1853, loss 0.123243, acc 0.921875
2020-02-08T02:52:35.687086: step 1854, loss 0.103797, acc 0.953125
2020-02-08T02:52:35.830242: step 1855, loss 0.161976, acc 0.96875
2020-02-08T02:52:35.966090: step 1856, loss 0.118201, acc 0.96875
2020-02-08T02:52:36.102061: step 1857, loss 0.0879495, acc 0.953125
2020-02-08T02:52:36.236803: step 1858, loss 0.0966896, acc 0.953125
2020-02-08T02:52:36.370443: step 1859, loss 0.127446, acc 0.9375
2020-02-08T02:52:36.510054: step 1860, loss 0.0935068, acc 0.96875
2020-02-08T02:52:36.644748: step 1861, loss 0.118197, acc 0.953125
2020-02-08T02:52:36.784270: step 1862, loss 0.0449585, acc 0.984375
2020-02-08T02:52:36.921506: step 1863, loss 0.096463, acc 0.984375
2020-02-08T02:52:37.059588: step 1864, loss 0.118103, acc 0.921875
2020-02-08T02:52:37.195347: step 1865, loss 0.111893, acc 0.96875
2020-02-08T02:52:37.332383: step 1866, loss 0.0751798, acc 0.984375
2020-02-08T02:52:37.475018: step 1867, loss 0.12148, acc 0.953125
2020-02-08T02:52:37.600104: step 1868, loss 0.12138, acc 0.9375
2020-02-08T02:52:37.735771: step 1869, loss 0.0676342, acc 1
2020-02-08T02:52:37.862691: step 1870, loss 0.0866711, acc 0.96875
2020-02-08T02:52:37.996238: step 1871, loss 0.157422, acc 0.9375
2020-02-08T02:52:38.136956: step 1872, loss 0.143318, acc 0.921875
2020-02-08T02:52:38.275112: step 1873, loss 0.207703, acc 0.921875
2020-02-08T02:52:38.411342: step 1874, loss 0.154144, acc 0.921875
2020-02-08T02:52:38.547863: step 1875, loss 0.113276, acc 0.9375
2020-02-08T02:52:38.688292: step 1876, loss 0.128771, acc 0.9375
2020-02-08T02:52:38.810379: step 1877, loss 0.135772, acc 0.953125
2020-02-08T02:52:38.930650: step 1878, loss 0.119319, acc 0.96875
2020-02-08T02:52:39.048960: step 1879, loss 0.0638129, acc 1
2020-02-08T02:52:39.172756: step 1880, loss 0.0507614, acc 1
2020-02-08T02:52:39.293606: step 1881, loss 0.0440723, acc 0.984375
2020-02-08T02:52:39.411336: step 1882, loss 0.130801, acc 0.953125
2020-02-08T02:52:39.529993: step 1883, loss 0.0945986, acc 0.96875
2020-02-08T02:52:39.653288: step 1884, loss 0.0847699, acc 0.953125
2020-02-08T02:52:39.778199: step 1885, loss 0.0618114, acc 0.984375
2020-02-08T02:52:39.908436: step 1886, loss 0.0553565, acc 1
2020-02-08T02:52:40.031678: step 1887, loss 0.0583286, acc 0.984375
2020-02-08T02:52:40.167815: step 1888, loss 0.0948556, acc 0.953125
2020-02-08T02:52:40.292080: step 1889, loss 0.119961, acc 0.9375
2020-02-08T02:52:40.418986: step 1890, loss 0.0960789, acc 0.984375
2020-02-08T02:52:40.542255: step 1891, loss 0.109204, acc 0.96875
2020-02-08T02:52:40.659620: step 1892, loss 0.0631557, acc 0.984375
2020-02-08T02:52:40.775291: step 1893, loss 0.0731267, acc 0.984375
2020-02-08T02:52:40.896931: step 1894, loss 0.123202, acc 0.96875
2020-02-08T02:52:41.012813: step 1895, loss 0.0693252, acc 0.96875
2020-02-08T02:52:41.132193: step 1896, loss 0.0680274, acc 0.984375
2020-02-08T02:52:41.251946: step 1897, loss 0.0888062, acc 0.953125
2020-02-08T02:52:41.366333: step 1898, loss 0.105899, acc 0.9375
2020-02-08T02:52:41.486154: step 1899, loss 0.122474, acc 0.9375
2020-02-08T02:52:41.604656: step 1900, loss 0.115115, acc 0.96875

Evaluation:
2020-02-08T02:52:41.795017: step 1900, loss 0.705841, acc 0.746717

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-1900

2020-02-08T02:52:43.541795: step 1901, loss 0.0712054, acc 0.984375
2020-02-08T02:52:43.659924: step 1902, loss 0.118764, acc 0.96875
2020-02-08T02:52:43.775538: step 1903, loss 0.0604619, acc 0.96875
2020-02-08T02:52:43.893320: step 1904, loss 0.0838956, acc 0.96875
2020-02-08T02:52:44.009667: step 1905, loss 0.0526563, acc 0.984375
2020-02-08T02:52:44.122220: step 1906, loss 0.103231, acc 0.984375
2020-02-08T02:52:44.239704: step 1907, loss 0.0482164, acc 0.984375
2020-02-08T02:52:44.356324: step 1908, loss 0.129007, acc 0.953125
2020-02-08T02:52:44.468837: step 1909, loss 0.0781386, acc 0.96875
2020-02-08T02:52:44.585642: step 1910, loss 0.063396, acc 0.984375
2020-02-08T02:52:44.702155: step 1911, loss 0.0214271, acc 1
2020-02-08T02:52:44.816981: step 1912, loss 0.158623, acc 0.953125
2020-02-08T02:52:44.935199: step 1913, loss 0.0447817, acc 1
2020-02-08T02:52:45.060315: step 1914, loss 0.120384, acc 0.953125
2020-02-08T02:52:45.176891: step 1915, loss 0.0898859, acc 0.96875
2020-02-08T02:52:45.293748: step 1916, loss 0.0514413, acc 0.984375
2020-02-08T02:52:45.410573: step 1917, loss 0.0828933, acc 0.96875
2020-02-08T02:52:45.526985: step 1918, loss 0.0793436, acc 0.96875
2020-02-08T02:52:45.642764: step 1919, loss 0.139611, acc 0.90625
2020-02-08T02:52:45.759576: step 1920, loss 0.0987028, acc 0.96875
2020-02-08T02:52:45.878663: step 1921, loss 0.138401, acc 0.921875
2020-02-08T02:52:45.997987: step 1922, loss 0.0323666, acc 1
2020-02-08T02:52:46.112185: step 1923, loss 0.0797425, acc 0.96875
2020-02-08T02:52:46.228819: step 1924, loss 0.0550702, acc 0.984375
2020-02-08T02:52:46.346000: step 1925, loss 0.11878, acc 0.921875
2020-02-08T02:52:46.460577: step 1926, loss 0.0617534, acc 0.96875
2020-02-08T02:52:46.581144: step 1927, loss 0.114891, acc 0.96875
2020-02-08T02:52:46.696184: step 1928, loss 0.0755889, acc 0.984375
2020-02-08T02:52:46.811776: step 1929, loss 0.103296, acc 0.953125
2020-02-08T02:52:46.929520: step 1930, loss 0.0526274, acc 0.984375
2020-02-08T02:52:47.044128: step 1931, loss 0.140324, acc 0.953125
2020-02-08T02:52:47.158495: step 1932, loss 0.113232, acc 0.96875
2020-02-08T02:52:47.274503: step 1933, loss 0.135486, acc 0.90625
2020-02-08T02:52:47.392233: step 1934, loss 0.18169, acc 0.953125
2020-02-08T02:52:47.508287: step 1935, loss 0.104333, acc 0.96875
2020-02-08T02:52:47.621156: step 1936, loss 0.234798, acc 0.921875
2020-02-08T02:52:47.738198: step 1937, loss 0.164736, acc 0.96875
2020-02-08T02:52:47.850469: step 1938, loss 0.102024, acc 0.953125
2020-02-08T02:52:47.963143: step 1939, loss 0.167147, acc 0.9375
2020-02-08T02:52:48.080123: step 1940, loss 0.0785099, acc 0.96875
2020-02-08T02:52:48.196694: step 1941, loss 0.102089, acc 0.953125
2020-02-08T02:52:48.312315: step 1942, loss 0.123256, acc 0.9375
2020-02-08T02:52:48.429313: step 1943, loss 0.0362118, acc 1
2020-02-08T02:52:48.547264: step 1944, loss 0.077463, acc 0.96875
2020-02-08T02:52:48.662627: step 1945, loss 0.0832311, acc 0.96875
2020-02-08T02:52:48.778432: step 1946, loss 0.0772127, acc 0.984375
2020-02-08T02:52:48.894385: step 1947, loss 0.0652113, acc 0.984375
2020-02-08T02:52:49.010007: step 1948, loss 0.0530629, acc 0.96875
2020-02-08T02:52:49.124933: step 1949, loss 0.048839, acc 1
2020-02-08T02:52:49.236885: step 1950, loss 0.103625, acc 0.966667
2020-02-08T02:52:49.357116: step 1951, loss 0.126028, acc 0.90625
2020-02-08T02:52:49.474122: step 1952, loss 0.0433469, acc 0.984375
2020-02-08T02:52:49.592690: step 1953, loss 0.0464465, acc 0.96875
2020-02-08T02:52:49.709697: step 1954, loss 0.063299, acc 0.984375
2020-02-08T02:52:49.827238: step 1955, loss 0.0462789, acc 1
2020-02-08T02:52:49.944161: step 1956, loss 0.058857, acc 0.984375
2020-02-08T02:52:50.061137: step 1957, loss 0.0566023, acc 1
2020-02-08T02:52:50.178314: step 1958, loss 0.048106, acc 0.984375
2020-02-08T02:52:50.293999: step 1959, loss 0.071314, acc 0.984375
2020-02-08T02:52:50.411263: step 1960, loss 0.0932781, acc 0.9375
2020-02-08T02:52:50.527492: step 1961, loss 0.0661765, acc 0.96875
2020-02-08T02:52:50.643528: step 1962, loss 0.054117, acc 0.984375
2020-02-08T02:52:50.758795: step 1963, loss 0.0905899, acc 0.953125
2020-02-08T02:52:50.871922: step 1964, loss 0.0847423, acc 0.96875
2020-02-08T02:52:50.990099: step 1965, loss 0.0879704, acc 0.953125
2020-02-08T02:52:51.104169: step 1966, loss 0.0370671, acc 1
2020-02-08T02:52:51.220298: step 1967, loss 0.0757743, acc 0.96875
2020-02-08T02:52:51.628715: step 1968, loss 0.0884497, acc 0.984375
2020-02-08T02:52:51.753240: step 1969, loss 0.0348963, acc 0.984375
2020-02-08T02:52:51.871252: step 1970, loss 0.146662, acc 0.9375
2020-02-08T02:52:51.989752: step 1971, loss 0.115236, acc 0.921875
2020-02-08T02:52:52.104005: step 1972, loss 0.0758478, acc 0.96875
2020-02-08T02:52:52.217839: step 1973, loss 0.0673677, acc 0.984375
2020-02-08T02:52:52.334145: step 1974, loss 0.0758186, acc 0.984375
2020-02-08T02:52:52.450238: step 1975, loss 0.128044, acc 0.921875
2020-02-08T02:52:52.563207: step 1976, loss 0.117885, acc 0.9375
2020-02-08T02:52:52.677239: step 1977, loss 0.050444, acc 0.984375
2020-02-08T02:52:52.792567: step 1978, loss 0.0296614, acc 1
2020-02-08T02:52:52.907692: step 1979, loss 0.109962, acc 0.9375
2020-02-08T02:52:53.023602: step 1980, loss 0.13875, acc 0.953125
2020-02-08T02:52:53.139122: step 1981, loss 0.0671251, acc 0.984375
2020-02-08T02:52:53.255645: step 1982, loss 0.113103, acc 0.953125
2020-02-08T02:52:53.367188: step 1983, loss 0.0367892, acc 1
2020-02-08T02:52:53.481510: step 1984, loss 0.0556549, acc 1
2020-02-08T02:52:53.598156: step 1985, loss 0.063801, acc 0.984375
2020-02-08T02:52:53.712686: step 1986, loss 0.0715009, acc 1
2020-02-08T02:52:53.828463: step 1987, loss 0.0257944, acc 1
2020-02-08T02:52:53.941730: step 1988, loss 0.047704, acc 0.984375
2020-02-08T02:52:54.057972: step 1989, loss 0.0651003, acc 0.984375
2020-02-08T02:52:54.174935: step 1990, loss 0.0433419, acc 0.984375
2020-02-08T02:52:54.291065: step 1991, loss 0.0743677, acc 0.984375
2020-02-08T02:52:54.407672: step 1992, loss 0.0667092, acc 0.984375
2020-02-08T02:52:54.521973: step 1993, loss 0.0950002, acc 0.96875
2020-02-08T02:52:54.637509: step 1994, loss 0.0787006, acc 0.984375
2020-02-08T02:52:54.753938: step 1995, loss 0.0590408, acc 0.984375
2020-02-08T02:52:54.867956: step 1996, loss 0.0720732, acc 0.96875
2020-02-08T02:52:54.984985: step 1997, loss 0.0523464, acc 0.96875
2020-02-08T02:52:55.101246: step 1998, loss 0.091272, acc 0.96875
2020-02-08T02:52:55.215669: step 1999, loss 0.0803531, acc 0.96875
2020-02-08T02:52:55.331474: step 2000, loss 0.127009, acc 0.953125

Evaluation:
2020-02-08T02:52:55.517133: step 2000, loss 0.748851, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2000

2020-02-08T02:52:57.325142: step 2001, loss 0.0842765, acc 0.984375
2020-02-08T02:52:57.441063: step 2002, loss 0.0766508, acc 0.96875
2020-02-08T02:52:57.557212: step 2003, loss 0.0630301, acc 0.984375
2020-02-08T02:52:57.672348: step 2004, loss 0.057766, acc 0.984375
2020-02-08T02:52:57.787957: step 2005, loss 0.0361917, acc 1
2020-02-08T02:52:57.904211: step 2006, loss 0.0275696, acc 1
2020-02-08T02:52:58.018409: step 2007, loss 0.031149, acc 0.984375
2020-02-08T02:52:58.134426: step 2008, loss 0.0486604, acc 0.984375
2020-02-08T02:52:58.251792: step 2009, loss 0.0501055, acc 0.984375
2020-02-08T02:52:58.365622: step 2010, loss 0.0555913, acc 0.984375
2020-02-08T02:52:58.479960: step 2011, loss 0.0682622, acc 0.96875
2020-02-08T02:52:58.598289: step 2012, loss 0.133038, acc 0.9375
2020-02-08T02:52:58.712184: step 2013, loss 0.0982934, acc 0.96875
2020-02-08T02:52:58.828003: step 2014, loss 0.0889011, acc 0.953125
2020-02-08T02:52:58.943677: step 2015, loss 0.0765743, acc 0.96875
2020-02-08T02:52:59.059032: step 2016, loss 0.0999874, acc 0.953125
2020-02-08T02:52:59.176329: step 2017, loss 0.0592759, acc 0.984375
2020-02-08T02:52:59.292046: step 2018, loss 0.0400697, acc 1
2020-02-08T02:52:59.407006: step 2019, loss 0.162181, acc 0.9375
2020-02-08T02:52:59.521698: step 2020, loss 0.0413387, acc 0.984375
2020-02-08T02:52:59.639229: step 2021, loss 0.05445, acc 1
2020-02-08T02:52:59.755634: step 2022, loss 0.0686434, acc 0.984375
2020-02-08T02:52:59.872948: step 2023, loss 0.0399562, acc 1
2020-02-08T02:52:59.989853: step 2024, loss 0.0733578, acc 0.984375
2020-02-08T02:53:00.107085: step 2025, loss 0.076315, acc 0.96875
2020-02-08T02:53:00.228088: step 2026, loss 0.0500444, acc 0.984375
2020-02-08T02:53:00.345016: step 2027, loss 0.0478023, acc 0.984375
2020-02-08T02:53:00.460679: step 2028, loss 0.0321105, acc 1
2020-02-08T02:53:00.576367: step 2029, loss 0.0724539, acc 0.96875
2020-02-08T02:53:00.691970: step 2030, loss 0.0811569, acc 0.984375
2020-02-08T02:53:00.807257: step 2031, loss 0.0612283, acc 0.984375
2020-02-08T02:53:00.924315: step 2032, loss 0.100911, acc 0.9375
2020-02-08T02:53:01.039877: step 2033, loss 0.153655, acc 0.953125
2020-02-08T02:53:01.154731: step 2034, loss 0.0788281, acc 0.96875
2020-02-08T02:53:01.271546: step 2035, loss 0.116583, acc 0.9375
2020-02-08T02:53:01.390248: step 2036, loss 0.0836697, acc 0.953125
2020-02-08T02:53:01.507805: step 2037, loss 0.043936, acc 0.984375
2020-02-08T02:53:01.620240: step 2038, loss 0.149168, acc 0.953125
2020-02-08T02:53:01.735577: step 2039, loss 0.0240142, acc 1
2020-02-08T02:53:01.851297: step 2040, loss 0.040619, acc 0.984375
2020-02-08T02:53:01.967686: step 2041, loss 0.0901741, acc 0.953125
2020-02-08T02:53:02.084471: step 2042, loss 0.17817, acc 0.90625
2020-02-08T02:53:02.200296: step 2043, loss 0.0764865, acc 0.953125
2020-02-08T02:53:02.314001: step 2044, loss 0.0552674, acc 0.984375
2020-02-08T02:53:02.431585: step 2045, loss 0.100371, acc 0.96875
2020-02-08T02:53:02.546563: step 2046, loss 0.116162, acc 0.953125
2020-02-08T02:53:02.662439: step 2047, loss 0.0916644, acc 0.984375
2020-02-08T02:53:02.779638: step 2048, loss 0.130585, acc 0.984375
2020-02-08T02:53:02.896604: step 2049, loss 0.0350584, acc 1
2020-02-08T02:53:03.012261: step 2050, loss 0.0996845, acc 0.96875
2020-02-08T02:53:03.129252: step 2051, loss 0.087447, acc 0.96875
2020-02-08T02:53:03.247286: step 2052, loss 0.0923672, acc 0.9375
2020-02-08T02:53:03.360716: step 2053, loss 0.0484873, acc 0.984375
2020-02-08T02:53:03.477444: step 2054, loss 0.0786294, acc 0.984375
2020-02-08T02:53:03.592976: step 2055, loss 0.0450049, acc 0.984375
2020-02-08T02:53:03.708504: step 2056, loss 0.165428, acc 0.921875
2020-02-08T02:53:03.824630: step 2057, loss 0.0583764, acc 1
2020-02-08T02:53:03.941237: step 2058, loss 0.0814248, acc 0.953125
2020-02-08T02:53:04.057230: step 2059, loss 0.0517873, acc 1
2020-02-08T02:53:04.173286: step 2060, loss 0.0383889, acc 0.984375
2020-02-08T02:53:04.288604: step 2061, loss 0.107903, acc 0.921875
2020-02-08T02:53:04.406957: step 2062, loss 0.0835986, acc 0.96875
2020-02-08T02:53:04.520968: step 2063, loss 0.0373411, acc 1
2020-02-08T02:53:04.640125: step 2064, loss 0.0537425, acc 0.96875
2020-02-08T02:53:04.756122: step 2065, loss 0.131205, acc 0.953125
2020-02-08T02:53:04.870688: step 2066, loss 0.0507909, acc 0.984375
2020-02-08T02:53:04.988581: step 2067, loss 0.0962101, acc 0.96875
2020-02-08T02:53:05.105315: step 2068, loss 0.0528964, acc 1
2020-02-08T02:53:05.220433: step 2069, loss 0.0646967, acc 0.984375
2020-02-08T02:53:05.337873: step 2070, loss 0.0986599, acc 0.953125
2020-02-08T02:53:05.455120: step 2071, loss 0.0494747, acc 0.984375
2020-02-08T02:53:05.570934: step 2072, loss 0.10712, acc 0.96875
2020-02-08T02:53:05.683819: step 2073, loss 0.223085, acc 0.859375
2020-02-08T02:53:05.799114: step 2074, loss 0.0354318, acc 1
2020-02-08T02:53:05.916120: step 2075, loss 0.0275707, acc 1
2020-02-08T02:53:06.031430: step 2076, loss 0.0449851, acc 0.984375
2020-02-08T02:53:06.147539: step 2077, loss 0.0481181, acc 0.984375
2020-02-08T02:53:06.261214: step 2078, loss 0.0746408, acc 0.96875
2020-02-08T02:53:06.378080: step 2079, loss 0.116196, acc 0.953125
2020-02-08T02:53:06.493476: step 2080, loss 0.180681, acc 0.90625
2020-02-08T02:53:06.605769: step 2081, loss 0.0388829, acc 1
2020-02-08T02:53:06.721012: step 2082, loss 0.137398, acc 0.921875
2020-02-08T02:53:06.837338: step 2083, loss 0.0432709, acc 0.984375
2020-02-08T02:53:06.951007: step 2084, loss 0.105926, acc 0.953125
2020-02-08T02:53:07.068410: step 2085, loss 0.0509429, acc 0.984375
2020-02-08T02:53:07.181471: step 2086, loss 0.0754644, acc 0.96875
2020-02-08T02:53:07.300333: step 2087, loss 0.0517231, acc 1
2020-02-08T02:53:07.417929: step 2088, loss 0.0297383, acc 1
2020-02-08T02:53:07.534321: step 2089, loss 0.067772, acc 0.984375
2020-02-08T02:53:07.650711: step 2090, loss 0.0495469, acc 0.984375
2020-02-08T02:53:07.768730: step 2091, loss 0.0679585, acc 0.96875
2020-02-08T02:53:07.885357: step 2092, loss 0.141957, acc 0.9375
2020-02-08T02:53:08.003057: step 2093, loss 0.0585573, acc 0.984375
2020-02-08T02:53:08.117924: step 2094, loss 0.12511, acc 0.96875
2020-02-08T02:53:08.235201: step 2095, loss 0.0861886, acc 0.96875
2020-02-08T02:53:08.350566: step 2096, loss 0.102471, acc 0.96875
2020-02-08T02:53:08.467220: step 2097, loss 0.0740286, acc 0.984375
2020-02-08T02:53:08.584811: step 2098, loss 0.0565334, acc 0.984375
2020-02-08T02:53:08.703306: step 2099, loss 0.0815119, acc 0.953125
2020-02-08T02:53:08.813581: step 2100, loss 0.0381175, acc 1

Evaluation:
2020-02-08T02:53:08.999771: step 2100, loss 0.774066, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2100

2020-02-08T02:53:10.544803: step 2101, loss 0.0620175, acc 0.984375
2020-02-08T02:53:10.663490: step 2102, loss 0.0337449, acc 1
2020-02-08T02:53:10.778470: step 2103, loss 0.0628012, acc 0.96875
2020-02-08T02:53:10.894084: step 2104, loss 0.0874638, acc 0.96875
2020-02-08T02:53:11.009479: step 2105, loss 0.0702787, acc 0.984375
2020-02-08T02:53:11.125317: step 2106, loss 0.0425131, acc 0.984375
2020-02-08T02:53:11.241474: step 2107, loss 0.0365784, acc 0.984375
2020-02-08T02:53:11.357649: step 2108, loss 0.0735158, acc 0.953125
2020-02-08T02:53:11.475652: step 2109, loss 0.0320413, acc 1
2020-02-08T02:53:11.591901: step 2110, loss 0.0407769, acc 0.984375
2020-02-08T02:53:11.707223: step 2111, loss 0.0681818, acc 0.96875
2020-02-08T02:53:11.823250: step 2112, loss 0.0899249, acc 0.953125
2020-02-08T02:53:11.941468: step 2113, loss 0.030634, acc 1
2020-02-08T02:53:12.056293: step 2114, loss 0.0415288, acc 0.984375
2020-02-08T02:53:12.171679: step 2115, loss 0.0285117, acc 1
2020-02-08T02:53:12.288737: step 2116, loss 0.163388, acc 0.9375
2020-02-08T02:53:12.402520: step 2117, loss 0.0520725, acc 0.984375
2020-02-08T02:53:12.517542: step 2118, loss 0.15158, acc 0.953125
2020-02-08T02:53:12.632785: step 2119, loss 0.0447959, acc 0.984375
2020-02-08T02:53:12.750103: step 2120, loss 0.0889533, acc 0.96875
2020-02-08T02:53:12.864609: step 2121, loss 0.0344551, acc 1
2020-02-08T02:53:12.981234: step 2122, loss 0.027587, acc 1
2020-02-08T02:53:13.098581: step 2123, loss 0.0514579, acc 0.984375
2020-02-08T02:53:13.214263: step 2124, loss 0.0804599, acc 0.953125
2020-02-08T02:53:13.334557: step 2125, loss 0.0464274, acc 0.984375
2020-02-08T02:53:13.451927: step 2126, loss 0.0574037, acc 0.984375
2020-02-08T02:53:13.570647: step 2127, loss 0.0173952, acc 1
2020-02-08T02:53:13.686422: step 2128, loss 0.0794203, acc 0.96875
2020-02-08T02:53:13.804832: step 2129, loss 0.108208, acc 0.953125
2020-02-08T02:53:13.922500: step 2130, loss 0.0696815, acc 0.984375
2020-02-08T02:53:14.038082: step 2131, loss 0.0719985, acc 0.96875
2020-02-08T02:53:14.151344: step 2132, loss 0.0579981, acc 0.984375
2020-02-08T02:53:14.267222: step 2133, loss 0.055458, acc 0.984375
2020-02-08T02:53:14.383099: step 2134, loss 0.0378496, acc 1
2020-02-08T02:53:14.501467: step 2135, loss 0.0851434, acc 0.96875
2020-02-08T02:53:14.614603: step 2136, loss 0.109444, acc 0.953125
2020-02-08T02:53:14.729075: step 2137, loss 0.102604, acc 0.953125
2020-02-08T02:53:14.847794: step 2138, loss 0.0590387, acc 0.96875
2020-02-08T02:53:14.962106: step 2139, loss 0.0730209, acc 0.984375
2020-02-08T02:53:15.078164: step 2140, loss 0.0546713, acc 0.984375
2020-02-08T02:53:15.195600: step 2141, loss 0.0513831, acc 0.984375
2020-02-08T02:53:15.311662: step 2142, loss 0.0500147, acc 0.96875
2020-02-08T02:53:15.429211: step 2143, loss 0.105531, acc 0.953125
2020-02-08T02:53:15.544581: step 2144, loss 0.0782779, acc 0.96875
2020-02-08T02:53:15.661034: step 2145, loss 0.0364297, acc 1
2020-02-08T02:53:15.776980: step 2146, loss 0.0514369, acc 1
2020-02-08T02:53:15.894054: step 2147, loss 0.0547449, acc 1
2020-02-08T02:53:16.010215: step 2148, loss 0.0385679, acc 1
2020-02-08T02:53:16.123771: step 2149, loss 0.0404251, acc 0.984375
2020-02-08T02:53:16.240612: step 2150, loss 0.0586836, acc 0.96875
2020-02-08T02:53:16.358525: step 2151, loss 0.0742013, acc 0.984375
2020-02-08T02:53:16.474106: step 2152, loss 0.0496837, acc 0.984375
2020-02-08T02:53:16.590417: step 2153, loss 0.0779728, acc 0.953125
2020-02-08T02:53:16.705438: step 2154, loss 0.0352161, acc 1
2020-02-08T02:53:16.818192: step 2155, loss 0.0480611, acc 0.96875
2020-02-08T02:53:16.934359: step 2156, loss 0.0306725, acc 0.984375
2020-02-08T02:53:17.050198: step 2157, loss 0.0478213, acc 0.984375
2020-02-08T02:53:17.163572: step 2158, loss 0.0452645, acc 0.984375
2020-02-08T02:53:17.282382: step 2159, loss 0.163936, acc 0.953125
2020-02-08T02:53:17.399791: step 2160, loss 0.0890868, acc 0.96875
2020-02-08T02:53:17.514832: step 2161, loss 0.0333228, acc 1
2020-02-08T02:53:17.633424: step 2162, loss 0.0344069, acc 0.984375
2020-02-08T02:53:17.753838: step 2163, loss 0.110047, acc 0.953125
2020-02-08T02:53:17.871060: step 2164, loss 0.0603999, acc 0.984375
2020-02-08T02:53:17.987214: step 2165, loss 0.0263469, acc 1
2020-02-08T02:53:18.102089: step 2166, loss 0.038164, acc 0.984375
2020-02-08T02:53:18.219015: step 2167, loss 0.0473109, acc 0.96875
2020-02-08T02:53:18.333022: step 2168, loss 0.0483966, acc 0.96875
2020-02-08T02:53:18.453669: step 2169, loss 0.0231451, acc 1
2020-02-08T02:53:18.568882: step 2170, loss 0.0441565, acc 0.984375
2020-02-08T02:53:18.687234: step 2171, loss 0.0172302, acc 1
2020-02-08T02:53:18.804143: step 2172, loss 0.0304161, acc 1
2020-02-08T02:53:18.920248: step 2173, loss 0.0393753, acc 0.984375
2020-02-08T02:53:19.038711: step 2174, loss 0.0292003, acc 1
2020-02-08T02:53:19.155240: step 2175, loss 0.0710212, acc 0.953125
2020-02-08T02:53:19.274336: step 2176, loss 0.057183, acc 0.96875
2020-02-08T02:53:19.392765: step 2177, loss 0.101019, acc 0.953125
2020-02-08T02:53:19.510343: step 2178, loss 0.0252284, acc 1
2020-02-08T02:53:19.627057: step 2179, loss 0.0470821, acc 0.984375
2020-02-08T02:53:19.743641: step 2180, loss 0.0763406, acc 0.96875
2020-02-08T02:53:19.861405: step 2181, loss 0.116261, acc 0.953125
2020-02-08T02:53:19.979415: step 2182, loss 0.139803, acc 0.9375
2020-02-08T02:53:20.096853: step 2183, loss 0.0778024, acc 0.953125
2020-02-08T02:53:20.209049: step 2184, loss 0.0625392, acc 0.96875
2020-02-08T02:53:20.322803: step 2185, loss 0.0681781, acc 0.984375
2020-02-08T02:53:20.440388: step 2186, loss 0.0225399, acc 1
2020-02-08T02:53:20.559210: step 2187, loss 0.032554, acc 0.984375
2020-02-08T02:53:20.673863: step 2188, loss 0.0453997, acc 1
2020-02-08T02:53:20.791754: step 2189, loss 0.0572152, acc 0.984375
2020-02-08T02:53:20.907758: step 2190, loss 0.0304678, acc 1
2020-02-08T02:53:21.022564: step 2191, loss 0.0350788, acc 1
2020-02-08T02:53:21.140064: step 2192, loss 0.0661982, acc 0.984375
2020-02-08T02:53:21.255984: step 2193, loss 0.0537345, acc 0.984375
2020-02-08T02:53:21.369914: step 2194, loss 0.0404356, acc 0.984375
2020-02-08T02:53:21.497902: step 2195, loss 0.0590393, acc 0.96875
2020-02-08T02:53:21.625705: step 2196, loss 0.0629544, acc 0.96875
2020-02-08T02:53:21.741949: step 2197, loss 0.0164929, acc 1
2020-02-08T02:53:21.860546: step 2198, loss 0.0437677, acc 0.984375
2020-02-08T02:53:21.979095: step 2199, loss 0.0562834, acc 0.96875
2020-02-08T02:53:22.094740: step 2200, loss 0.0475554, acc 0.984375

Evaluation:
2020-02-08T02:53:22.280639: step 2200, loss 0.80818, acc 0.731707

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2200

2020-02-08T02:53:24.435239: step 2201, loss 0.0151015, acc 1
2020-02-08T02:53:24.550712: step 2202, loss 0.1048, acc 0.953125
2020-02-08T02:53:24.668461: step 2203, loss 0.0311648, acc 1
2020-02-08T02:53:24.788380: step 2204, loss 0.0692666, acc 0.96875
2020-02-08T02:53:24.902358: step 2205, loss 0.0437446, acc 0.96875
2020-02-08T02:53:25.014736: step 2206, loss 0.0873365, acc 0.953125
2020-02-08T02:53:25.132093: step 2207, loss 0.0844142, acc 0.984375
2020-02-08T02:53:25.247382: step 2208, loss 0.0642649, acc 0.96875
2020-02-08T02:53:25.361152: step 2209, loss 0.0921975, acc 0.96875
2020-02-08T02:53:25.479123: step 2210, loss 0.136651, acc 0.953125
2020-02-08T02:53:25.594972: step 2211, loss 0.076725, acc 0.953125
2020-02-08T02:53:25.710920: step 2212, loss 0.0633179, acc 0.96875
2020-02-08T02:53:25.826481: step 2213, loss 0.0608189, acc 0.953125
2020-02-08T02:53:25.942049: step 2214, loss 0.0973065, acc 0.984375
2020-02-08T02:53:26.059295: step 2215, loss 0.0913292, acc 0.96875
2020-02-08T02:53:26.174366: step 2216, loss 0.0346463, acc 0.984375
2020-02-08T02:53:26.290814: step 2217, loss 0.0748241, acc 0.984375
2020-02-08T02:53:26.406822: step 2218, loss 0.096732, acc 0.96875
2020-02-08T02:53:26.523906: step 2219, loss 0.0466643, acc 0.96875
2020-02-08T02:53:26.641107: step 2220, loss 0.082822, acc 0.984375
2020-02-08T02:53:26.755687: step 2221, loss 0.0770319, acc 0.984375
2020-02-08T02:53:26.872645: step 2222, loss 0.0676485, acc 0.96875
2020-02-08T02:53:26.989371: step 2223, loss 0.0427158, acc 1
2020-02-08T02:53:27.108447: step 2224, loss 0.0689985, acc 0.96875
2020-02-08T02:53:27.221474: step 2225, loss 0.0753539, acc 0.953125
2020-02-08T02:53:27.343040: step 2226, loss 0.040075, acc 0.984375
2020-02-08T02:53:27.458932: step 2227, loss 0.0412419, acc 0.984375
2020-02-08T02:53:27.575373: step 2228, loss 0.094748, acc 0.984375
2020-02-08T02:53:27.691489: step 2229, loss 0.104084, acc 0.96875
2020-02-08T02:53:27.807581: step 2230, loss 0.0179462, acc 1
2020-02-08T02:53:27.924396: step 2231, loss 0.165926, acc 0.9375
2020-02-08T02:53:28.044278: step 2232, loss 0.0360177, acc 1
2020-02-08T02:53:28.161452: step 2233, loss 0.0301371, acc 1
2020-02-08T02:53:28.277515: step 2234, loss 0.139186, acc 0.953125
2020-02-08T02:53:28.393351: step 2235, loss 0.0224272, acc 1
2020-02-08T02:53:28.508776: step 2236, loss 0.0357388, acc 0.984375
2020-02-08T02:53:28.627934: step 2237, loss 0.0646756, acc 0.96875
2020-02-08T02:53:28.745752: step 2238, loss 0.0613181, acc 0.984375
2020-02-08T02:53:28.860224: step 2239, loss 0.0668933, acc 0.984375
2020-02-08T02:53:28.980379: step 2240, loss 0.0671291, acc 0.984375
2020-02-08T02:53:29.096677: step 2241, loss 0.0546509, acc 0.984375
2020-02-08T02:53:29.214976: step 2242, loss 0.0483995, acc 0.984375
2020-02-08T02:53:29.333916: step 2243, loss 0.0566654, acc 0.984375
2020-02-08T02:53:29.450339: step 2244, loss 0.0888086, acc 0.96875
2020-02-08T02:53:29.567094: step 2245, loss 0.0442755, acc 0.984375
2020-02-08T02:53:29.686114: step 2246, loss 0.0490314, acc 0.984375
2020-02-08T02:53:29.804877: step 2247, loss 0.0475848, acc 0.984375
2020-02-08T02:53:29.921590: step 2248, loss 0.0394047, acc 1
2020-02-08T02:53:30.043561: step 2249, loss 0.128767, acc 0.953125
2020-02-08T02:53:30.158740: step 2250, loss 0.085773, acc 0.983333
2020-02-08T02:53:30.277313: step 2251, loss 0.0287176, acc 1
2020-02-08T02:53:30.400322: step 2252, loss 0.0364054, acc 1
2020-02-08T02:53:30.518537: step 2253, loss 0.0164827, acc 1
2020-02-08T02:53:30.633839: step 2254, loss 0.0598935, acc 0.96875
2020-02-08T02:53:30.748877: step 2255, loss 0.022407, acc 0.984375
2020-02-08T02:53:30.864260: step 2256, loss 0.0321578, acc 0.984375
2020-02-08T02:53:30.979655: step 2257, loss 0.0286015, acc 1
2020-02-08T02:53:31.093686: step 2258, loss 0.0434478, acc 0.96875
2020-02-08T02:53:31.211974: step 2259, loss 0.02346, acc 1
2020-02-08T02:53:31.328127: step 2260, loss 0.0349315, acc 0.984375
2020-02-08T02:53:31.443237: step 2261, loss 0.0160884, acc 1
2020-02-08T02:53:31.561163: step 2262, loss 0.120647, acc 0.96875
2020-02-08T02:53:31.679622: step 2263, loss 0.024003, acc 1
2020-02-08T02:53:31.797036: step 2264, loss 0.0302535, acc 0.984375
2020-02-08T02:53:31.912164: step 2265, loss 0.0211873, acc 1
2020-02-08T02:53:32.027154: step 2266, loss 0.0442412, acc 0.984375
2020-02-08T02:53:32.141727: step 2267, loss 0.0347348, acc 0.984375
2020-02-08T02:53:32.256593: step 2268, loss 0.0479104, acc 0.984375
2020-02-08T02:53:32.374112: step 2269, loss 0.0394834, acc 1
2020-02-08T02:53:32.493487: step 2270, loss 0.117858, acc 0.9375
2020-02-08T02:53:32.610443: step 2271, loss 0.0395609, acc 0.984375
2020-02-08T02:53:32.724820: step 2272, loss 0.0206302, acc 1
2020-02-08T02:53:32.841789: step 2273, loss 0.0401428, acc 0.984375
2020-02-08T02:53:32.958450: step 2274, loss 0.0452771, acc 0.984375
2020-02-08T02:53:33.071937: step 2275, loss 0.0239698, acc 1
2020-02-08T02:53:33.187199: step 2276, loss 0.0240786, acc 1
2020-02-08T02:53:33.303956: step 2277, loss 0.0219706, acc 1
2020-02-08T02:53:33.417859: step 2278, loss 0.0151712, acc 1
2020-02-08T02:53:33.532955: step 2279, loss 0.0481341, acc 0.984375
2020-02-08T02:53:33.649454: step 2280, loss 0.0522324, acc 0.984375
2020-02-08T02:53:33.765372: step 2281, loss 0.022173, acc 1
2020-02-08T02:53:33.882941: step 2282, loss 0.0541974, acc 0.984375
2020-02-08T02:53:33.999899: step 2283, loss 0.0404309, acc 1
2020-02-08T02:53:34.117744: step 2284, loss 0.0535441, acc 0.96875
2020-02-08T02:53:34.233259: step 2285, loss 0.0210497, acc 1
2020-02-08T02:53:34.353178: step 2286, loss 0.0143998, acc 1
2020-02-08T02:53:34.468711: step 2287, loss 0.0125417, acc 1
2020-02-08T02:53:34.586160: step 2288, loss 0.0260948, acc 1
2020-02-08T02:53:34.699576: step 2289, loss 0.0468957, acc 0.984375
2020-02-08T02:53:34.815113: step 2290, loss 0.0301201, acc 0.984375
2020-02-08T02:53:34.931161: step 2291, loss 0.0569783, acc 0.96875
2020-02-08T02:53:35.048858: step 2292, loss 0.0562903, acc 0.96875
2020-02-08T02:53:35.164885: step 2293, loss 0.0206632, acc 1
2020-02-08T02:53:35.280339: step 2294, loss 0.0668386, acc 0.96875
2020-02-08T02:53:35.398062: step 2295, loss 0.0231209, acc 1
2020-02-08T02:53:35.513188: step 2296, loss 0.0228183, acc 1
2020-02-08T02:53:35.629070: step 2297, loss 0.0276867, acc 1
2020-02-08T02:53:35.748183: step 2298, loss 0.0457037, acc 0.984375
2020-02-08T02:53:35.862495: step 2299, loss 0.0848264, acc 0.96875
2020-02-08T02:53:35.978844: step 2300, loss 0.0650442, acc 0.96875

Evaluation:
2020-02-08T02:53:36.165627: step 2300, loss 0.837822, acc 0.732645

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2300

2020-02-08T02:53:37.933420: step 2301, loss 0.0390911, acc 0.984375
2020-02-08T02:53:38.051437: step 2302, loss 0.0470254, acc 0.96875
2020-02-08T02:53:38.166581: step 2303, loss 0.0822852, acc 0.953125
2020-02-08T02:53:38.280823: step 2304, loss 0.0556295, acc 0.96875
2020-02-08T02:53:38.398399: step 2305, loss 0.0320208, acc 0.984375
2020-02-08T02:53:38.514252: step 2306, loss 0.139615, acc 0.96875
2020-02-08T02:53:38.632968: step 2307, loss 0.0400766, acc 0.984375
2020-02-08T02:53:38.749777: step 2308, loss 0.108478, acc 0.953125
2020-02-08T02:53:38.863525: step 2309, loss 0.103295, acc 0.96875
2020-02-08T02:53:38.981630: step 2310, loss 0.109342, acc 0.96875
2020-02-08T02:53:39.101398: step 2311, loss 0.0227354, acc 1
2020-02-08T02:53:39.215151: step 2312, loss 0.0373563, acc 1
2020-02-08T02:53:39.329522: step 2313, loss 0.0489699, acc 0.984375
2020-02-08T02:53:39.446243: step 2314, loss 0.0631037, acc 0.96875
2020-02-08T02:53:39.561839: step 2315, loss 0.0794344, acc 0.96875
2020-02-08T02:53:39.677906: step 2316, loss 0.0215495, acc 1
2020-02-08T02:53:39.796529: step 2317, loss 0.0837728, acc 0.96875
2020-02-08T02:53:39.913484: step 2318, loss 0.060164, acc 0.984375
2020-02-08T02:53:40.028511: step 2319, loss 0.0354013, acc 0.984375
2020-02-08T02:53:40.146945: step 2320, loss 0.0143658, acc 1
2020-02-08T02:53:40.261654: step 2321, loss 0.0809247, acc 0.953125
2020-02-08T02:53:40.379677: step 2322, loss 0.00830178, acc 1
2020-02-08T02:53:40.496322: step 2323, loss 0.0456494, acc 0.984375
2020-02-08T02:53:40.610902: step 2324, loss 0.0301304, acc 0.984375
2020-02-08T02:53:40.725877: step 2325, loss 0.0524967, acc 0.984375
2020-02-08T02:53:40.843367: step 2326, loss 0.0465899, acc 0.984375
2020-02-08T02:53:40.958415: step 2327, loss 0.0710212, acc 0.96875
2020-02-08T02:53:41.072279: step 2328, loss 0.0134066, acc 1
2020-02-08T02:53:41.188811: step 2329, loss 0.0547544, acc 0.96875
2020-02-08T02:53:41.303462: step 2330, loss 0.0427734, acc 0.984375
2020-02-08T02:53:41.416584: step 2331, loss 0.063348, acc 0.984375
2020-02-08T02:53:41.532026: step 2332, loss 0.0832285, acc 0.953125
2020-02-08T02:53:41.647006: step 2333, loss 0.0717706, acc 0.984375
2020-02-08T02:53:41.762525: step 2334, loss 0.0889115, acc 0.953125
2020-02-08T02:53:41.879589: step 2335, loss 0.0534658, acc 0.984375
2020-02-08T02:53:41.995427: step 2336, loss 0.0791607, acc 0.96875
2020-02-08T02:53:42.110267: step 2337, loss 0.0890633, acc 0.953125
2020-02-08T02:53:42.227138: step 2338, loss 0.0210857, acc 1
2020-02-08T02:53:42.345323: step 2339, loss 0.0415329, acc 1
2020-02-08T02:53:42.461170: step 2340, loss 0.0427108, acc 0.984375
2020-02-08T02:53:42.578592: step 2341, loss 0.0935874, acc 0.984375
2020-02-08T02:53:42.695940: step 2342, loss 0.0312844, acc 1
2020-02-08T02:53:42.812327: step 2343, loss 0.0292376, acc 0.984375
2020-02-08T02:53:42.934118: step 2344, loss 0.0384382, acc 0.984375
2020-02-08T02:53:43.048739: step 2345, loss 0.0782894, acc 0.984375
2020-02-08T02:53:43.164151: step 2346, loss 0.0343533, acc 0.984375
2020-02-08T02:53:43.282134: step 2347, loss 0.033201, acc 0.984375
2020-02-08T02:53:43.400305: step 2348, loss 0.0142129, acc 1
2020-02-08T02:53:43.514758: step 2349, loss 0.0354276, acc 0.984375
2020-02-08T02:53:43.629276: step 2350, loss 0.0354456, acc 0.984375
2020-02-08T02:53:43.745761: step 2351, loss 0.0751321, acc 0.984375
2020-02-08T02:53:43.862389: step 2352, loss 0.0462584, acc 0.984375
2020-02-08T02:53:43.977158: step 2353, loss 0.0465388, acc 0.984375
2020-02-08T02:53:44.094739: step 2354, loss 0.140874, acc 0.9375
2020-02-08T02:53:44.209463: step 2355, loss 0.0777683, acc 0.96875
2020-02-08T02:53:44.325496: step 2356, loss 0.0512785, acc 0.984375
2020-02-08T02:53:44.442566: step 2357, loss 0.0964008, acc 0.953125
2020-02-08T02:53:44.558602: step 2358, loss 0.0398447, acc 0.96875
2020-02-08T02:53:44.678438: step 2359, loss 0.0238923, acc 1
2020-02-08T02:53:44.796794: step 2360, loss 0.0191403, acc 1
2020-02-08T02:53:44.911571: step 2361, loss 0.0728637, acc 0.96875
2020-02-08T02:53:45.027938: step 2362, loss 0.0417131, acc 0.984375
2020-02-08T02:53:45.145752: step 2363, loss 0.0469693, acc 0.96875
2020-02-08T02:53:45.262589: step 2364, loss 0.0245087, acc 1
2020-02-08T02:53:45.384474: step 2365, loss 0.0179309, acc 1
2020-02-08T02:53:45.500490: step 2366, loss 0.0518985, acc 0.96875
2020-02-08T02:53:45.614760: step 2367, loss 0.032509, acc 1
2020-02-08T02:53:45.730320: step 2368, loss 0.0792334, acc 0.96875
2020-02-08T02:53:45.855103: step 2369, loss 0.0473136, acc 1
2020-02-08T02:53:45.968784: step 2370, loss 0.086447, acc 0.953125
2020-02-08T02:53:46.082834: step 2371, loss 0.059863, acc 0.984375
2020-02-08T02:53:46.199799: step 2372, loss 0.0475412, acc 0.984375
2020-02-08T02:53:46.312698: step 2373, loss 0.0382808, acc 1
2020-02-08T02:53:46.427244: step 2374, loss 0.141665, acc 0.953125
2020-02-08T02:53:46.544283: step 2375, loss 0.0543725, acc 1
2020-02-08T02:53:46.661075: step 2376, loss 0.0167462, acc 1
2020-02-08T02:53:46.777255: step 2377, loss 0.0515848, acc 0.984375
2020-02-08T02:53:46.895265: step 2378, loss 0.03888, acc 0.96875
2020-02-08T02:53:47.011646: step 2379, loss 0.0175779, acc 1
2020-02-08T02:53:47.129514: step 2380, loss 0.0326755, acc 1
2020-02-08T02:53:47.247267: step 2381, loss 0.0124318, acc 1
2020-02-08T02:53:47.364041: step 2382, loss 0.0980566, acc 0.953125
2020-02-08T02:53:47.477352: step 2383, loss 0.0506343, acc 0.96875
2020-02-08T02:53:47.592647: step 2384, loss 0.0942371, acc 0.96875
2020-02-08T02:53:47.708802: step 2385, loss 0.0521449, acc 0.96875
2020-02-08T02:53:47.825444: step 2386, loss 0.0587139, acc 0.984375
2020-02-08T02:53:47.942765: step 2387, loss 0.0419863, acc 1
2020-02-08T02:53:48.057220: step 2388, loss 0.0296523, acc 0.984375
2020-02-08T02:53:48.171407: step 2389, loss 0.12985, acc 0.9375
2020-02-08T02:53:48.286509: step 2390, loss 0.0966276, acc 0.953125
2020-02-08T02:53:48.403374: step 2391, loss 0.0464687, acc 0.984375
2020-02-08T02:53:48.517189: step 2392, loss 0.0537353, acc 0.984375
2020-02-08T02:53:48.635503: step 2393, loss 0.0424563, acc 0.984375
2020-02-08T02:53:48.752003: step 2394, loss 0.0996876, acc 0.953125
2020-02-08T02:53:48.864156: step 2395, loss 0.107347, acc 0.921875
2020-02-08T02:53:48.980303: step 2396, loss 0.0355032, acc 0.984375
2020-02-08T02:53:49.096032: step 2397, loss 0.0558484, acc 0.984375
2020-02-08T02:53:49.210401: step 2398, loss 0.0467026, acc 0.984375
2020-02-08T02:53:49.327719: step 2399, loss 0.015682, acc 1
2020-02-08T02:53:49.443777: step 2400, loss 0.0725897, acc 0.983333

Evaluation:
2020-02-08T02:53:49.641634: step 2400, loss 0.860446, acc 0.727017

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2400

2020-02-08T02:53:51.144681: step 2401, loss 0.0162972, acc 1
2020-02-08T02:53:51.258096: step 2402, loss 0.0127461, acc 1
2020-02-08T02:53:51.375235: step 2403, loss 0.0112183, acc 1
2020-02-08T02:53:51.541898: step 2404, loss 0.0148286, acc 1
2020-02-08T02:53:51.672364: step 2405, loss 0.0190923, acc 1
2020-02-08T02:53:51.793317: step 2406, loss 0.0177884, acc 1
2020-02-08T02:53:51.908933: step 2407, loss 0.0767068, acc 0.96875
2020-02-08T02:53:52.023287: step 2408, loss 0.0204746, acc 1
2020-02-08T02:53:52.142481: step 2409, loss 0.0425363, acc 0.984375
2020-02-08T02:53:52.255911: step 2410, loss 0.0237856, acc 0.984375
2020-02-08T02:53:52.370615: step 2411, loss 0.0591651, acc 0.96875
2020-02-08T02:53:52.489043: step 2412, loss 0.0280437, acc 1
2020-02-08T02:53:52.603587: step 2413, loss 0.0168272, acc 1
2020-02-08T02:53:52.719067: step 2414, loss 0.0182091, acc 1
2020-02-08T02:53:52.836265: step 2415, loss 0.0121547, acc 1
2020-02-08T02:53:52.950949: step 2416, loss 0.0715907, acc 0.984375
2020-02-08T02:53:53.067054: step 2417, loss 0.0149809, acc 1
2020-02-08T02:53:53.183168: step 2418, loss 0.0530021, acc 0.984375
2020-02-08T02:53:53.299616: step 2419, loss 0.0286229, acc 0.984375
2020-02-08T02:53:53.412716: step 2420, loss 0.0719978, acc 0.984375
2020-02-08T02:53:53.530375: step 2421, loss 0.0417423, acc 0.96875
2020-02-08T02:53:53.647893: step 2422, loss 0.0175171, acc 0.984375
2020-02-08T02:53:53.762894: step 2423, loss 0.0108437, acc 1
2020-02-08T02:53:53.878320: step 2424, loss 0.0395931, acc 1
2020-02-08T02:53:53.996140: step 2425, loss 0.0586187, acc 0.984375
2020-02-08T02:53:54.113530: step 2426, loss 0.0241258, acc 1
2020-02-08T02:53:54.228840: step 2427, loss 0.0525078, acc 0.984375
2020-02-08T02:53:54.347071: step 2428, loss 0.0280005, acc 0.984375
2020-02-08T02:53:54.462148: step 2429, loss 0.0248117, acc 1
2020-02-08T02:53:54.576564: step 2430, loss 0.0103084, acc 1
2020-02-08T02:53:54.692506: step 2431, loss 0.0271762, acc 1
2020-02-08T02:53:54.808444: step 2432, loss 0.0158933, acc 1
2020-02-08T02:53:54.921969: step 2433, loss 0.0360252, acc 0.984375
2020-02-08T02:53:55.040816: step 2434, loss 0.0200165, acc 1
2020-02-08T02:53:55.158374: step 2435, loss 0.0592348, acc 0.96875
2020-02-08T02:53:55.274309: step 2436, loss 0.0312291, acc 0.984375
2020-02-08T02:53:55.391104: step 2437, loss 0.0315703, acc 1
2020-02-08T02:53:55.507456: step 2438, loss 0.0159192, acc 1
2020-02-08T02:53:55.622931: step 2439, loss 0.046004, acc 0.984375
2020-02-08T02:53:55.740648: step 2440, loss 0.0129126, acc 1
2020-02-08T02:53:55.860778: step 2441, loss 0.049264, acc 0.96875
2020-02-08T02:53:55.977529: step 2442, loss 0.0510322, acc 0.984375
2020-02-08T02:53:56.095801: step 2443, loss 0.0188388, acc 1
2020-02-08T02:53:56.212112: step 2444, loss 0.0395291, acc 1
2020-02-08T02:53:56.333258: step 2445, loss 0.0332327, acc 0.984375
2020-02-08T02:53:56.450076: step 2446, loss 0.0257455, acc 1
2020-02-08T02:53:56.565153: step 2447, loss 0.0270918, acc 0.984375
2020-02-08T02:53:56.683087: step 2448, loss 0.0299776, acc 0.984375
2020-02-08T02:53:56.801591: step 2449, loss 0.0546024, acc 0.984375
2020-02-08T02:53:56.915139: step 2450, loss 0.035262, acc 0.984375
2020-02-08T02:53:57.031037: step 2451, loss 0.0178697, acc 1
2020-02-08T02:53:57.147375: step 2452, loss 0.0382898, acc 0.984375
2020-02-08T02:53:57.261504: step 2453, loss 0.032761, acc 0.984375
2020-02-08T02:53:57.375959: step 2454, loss 0.0160883, acc 1
2020-02-08T02:53:57.493197: step 2455, loss 0.0652717, acc 0.96875
2020-02-08T02:53:57.609710: step 2456, loss 0.0202173, acc 1
2020-02-08T02:53:57.723021: step 2457, loss 0.00889417, acc 1
2020-02-08T02:53:57.843383: step 2458, loss 0.119595, acc 0.953125
2020-02-08T02:53:57.959993: step 2459, loss 0.0306145, acc 0.984375
2020-02-08T02:53:58.076609: step 2460, loss 0.0203583, acc 1
2020-02-08T02:53:58.196162: step 2461, loss 0.0121269, acc 1
2020-02-08T02:53:58.311448: step 2462, loss 0.0435086, acc 1
2020-02-08T02:53:58.427540: step 2463, loss 0.0309275, acc 0.984375
2020-02-08T02:53:58.546526: step 2464, loss 0.0508115, acc 0.984375
2020-02-08T02:53:58.659761: step 2465, loss 0.0259448, acc 1
2020-02-08T02:53:58.777457: step 2466, loss 0.0169583, acc 1
2020-02-08T02:53:58.893197: step 2467, loss 0.117719, acc 0.96875
2020-02-08T02:53:59.007797: step 2468, loss 0.0237684, acc 1
2020-02-08T02:53:59.120187: step 2469, loss 0.141437, acc 0.953125
2020-02-08T02:53:59.237017: step 2470, loss 0.0268883, acc 1
2020-02-08T02:53:59.352507: step 2471, loss 0.0331587, acc 1
2020-02-08T02:53:59.465625: step 2472, loss 0.0371104, acc 1
2020-02-08T02:53:59.582298: step 2473, loss 0.0305989, acc 1
2020-02-08T02:53:59.698573: step 2474, loss 0.00993595, acc 1
2020-02-08T02:53:59.814841: step 2475, loss 0.020763, acc 0.984375
2020-02-08T02:53:59.932646: step 2476, loss 0.0214029, acc 1
2020-02-08T02:54:00.048582: step 2477, loss 0.00988776, acc 1
2020-02-08T02:54:00.163296: step 2478, loss 0.0367732, acc 0.984375
2020-02-08T02:54:00.281521: step 2479, loss 0.0516126, acc 0.984375
2020-02-08T02:54:00.398998: step 2480, loss 0.0170785, acc 1
2020-02-08T02:54:00.514604: step 2481, loss 0.0296297, acc 1
2020-02-08T02:54:00.631434: step 2482, loss 0.0555675, acc 0.984375
2020-02-08T02:54:00.746781: step 2483, loss 0.0304022, acc 0.984375
2020-02-08T02:54:00.861300: step 2484, loss 0.0713629, acc 0.984375
2020-02-08T02:54:00.980733: step 2485, loss 0.0586115, acc 0.984375
2020-02-08T02:54:01.096791: step 2486, loss 0.0322933, acc 0.984375
2020-02-08T02:54:01.212529: step 2487, loss 0.0313322, acc 0.984375
2020-02-08T02:54:01.326270: step 2488, loss 0.0420216, acc 0.984375
2020-02-08T02:54:01.443021: step 2489, loss 0.00638881, acc 1
2020-02-08T02:54:01.558568: step 2490, loss 0.106281, acc 0.984375
2020-02-08T02:54:01.674780: step 2491, loss 0.0163204, acc 1
2020-02-08T02:54:01.790704: step 2492, loss 0.0148489, acc 1
2020-02-08T02:54:01.906601: step 2493, loss 0.0443132, acc 0.96875
2020-02-08T02:54:02.024591: step 2494, loss 0.021452, acc 1
2020-02-08T02:54:02.142262: step 2495, loss 0.0638443, acc 0.984375
2020-02-08T02:54:02.259666: step 2496, loss 0.0445931, acc 0.984375
2020-02-08T02:54:02.375231: step 2497, loss 0.0406432, acc 0.984375
2020-02-08T02:54:02.494382: step 2498, loss 0.130339, acc 0.953125
2020-02-08T02:54:02.610161: step 2499, loss 0.0292195, acc 0.984375
2020-02-08T02:54:02.724961: step 2500, loss 0.0416245, acc 0.984375

Evaluation:
2020-02-08T02:54:02.913251: step 2500, loss 0.890116, acc 0.733584

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2500

2020-02-08T02:54:04.734111: step 2501, loss 0.0201371, acc 1
2020-02-08T02:54:04.854666: step 2502, loss 0.0425615, acc 0.984375
2020-02-08T02:54:04.971548: step 2503, loss 0.0163127, acc 1
2020-02-08T02:54:05.087438: step 2504, loss 0.070188, acc 0.984375
2020-02-08T02:54:05.206798: step 2505, loss 0.0415428, acc 0.96875
2020-02-08T02:54:05.323829: step 2506, loss 0.0465458, acc 0.984375
2020-02-08T02:54:05.440188: step 2507, loss 0.0320423, acc 1
2020-02-08T02:54:05.557413: step 2508, loss 0.0254735, acc 1
2020-02-08T02:54:05.673110: step 2509, loss 0.057749, acc 0.984375
2020-02-08T02:54:05.792540: step 2510, loss 0.0338491, acc 0.984375
2020-02-08T02:54:05.908243: step 2511, loss 0.0145861, acc 1
2020-02-08T02:54:06.023506: step 2512, loss 0.0172211, acc 1
2020-02-08T02:54:06.142987: step 2513, loss 0.0344556, acc 1
2020-02-08T02:54:06.257863: step 2514, loss 0.0297896, acc 0.984375
2020-02-08T02:54:06.373750: step 2515, loss 0.0810627, acc 0.96875
2020-02-08T02:54:06.490057: step 2516, loss 0.0668637, acc 0.953125
2020-02-08T02:54:06.605089: step 2517, loss 0.0326033, acc 1
2020-02-08T02:54:06.721510: step 2518, loss 0.0502415, acc 0.96875
2020-02-08T02:54:06.839384: step 2519, loss 0.0649729, acc 0.953125
2020-02-08T02:54:06.955675: step 2520, loss 0.0393204, acc 0.984375
2020-02-08T02:54:07.076457: step 2521, loss 0.0567954, acc 0.984375
2020-02-08T02:54:07.191506: step 2522, loss 0.0233648, acc 1
2020-02-08T02:54:07.306009: step 2523, loss 0.0465782, acc 0.96875
2020-02-08T02:54:07.422097: step 2524, loss 0.0276214, acc 1
2020-02-08T02:54:07.539309: step 2525, loss 0.0296289, acc 1
2020-02-08T02:54:07.655694: step 2526, loss 0.0416879, acc 0.984375
2020-02-08T02:54:07.772453: step 2527, loss 0.0805299, acc 0.96875
2020-02-08T02:54:07.890012: step 2528, loss 0.0501187, acc 0.984375
2020-02-08T02:54:08.007023: step 2529, loss 0.0371737, acc 0.984375
2020-02-08T02:54:08.120670: step 2530, loss 0.0210713, acc 1
2020-02-08T02:54:08.238283: step 2531, loss 0.0124737, acc 1
2020-02-08T02:54:08.352253: step 2532, loss 0.0420634, acc 0.96875
2020-02-08T02:54:08.466994: step 2533, loss 0.0414171, acc 0.984375
2020-02-08T02:54:08.586236: step 2534, loss 0.017925, acc 1
2020-02-08T02:54:08.702751: step 2535, loss 0.0583171, acc 0.96875
2020-02-08T02:54:08.818247: step 2536, loss 0.0197032, acc 1
2020-02-08T02:54:08.934536: step 2537, loss 0.0230522, acc 1
2020-02-08T02:54:09.049363: step 2538, loss 0.0270508, acc 0.984375
2020-02-08T02:54:09.165070: step 2539, loss 0.0586253, acc 0.984375
2020-02-08T02:54:09.278739: step 2540, loss 0.0113661, acc 1
2020-02-08T02:54:09.397550: step 2541, loss 0.0318021, acc 0.984375
2020-02-08T02:54:09.511218: step 2542, loss 0.03652, acc 0.984375
2020-02-08T02:54:09.626276: step 2543, loss 0.0142078, acc 1
2020-02-08T02:54:09.744291: step 2544, loss 0.017167, acc 0.984375
2020-02-08T02:54:09.860240: step 2545, loss 0.0273732, acc 1
2020-02-08T02:54:09.976870: step 2546, loss 0.035238, acc 1
2020-02-08T02:54:10.094727: step 2547, loss 0.0433599, acc 0.984375
2020-02-08T02:54:10.210040: step 2548, loss 0.0180014, acc 1
2020-02-08T02:54:10.323932: step 2549, loss 0.0104426, acc 1
2020-02-08T02:54:10.435730: step 2550, loss 0.0206173, acc 1
2020-02-08T02:54:10.553786: step 2551, loss 0.0112875, acc 1
2020-02-08T02:54:10.668461: step 2552, loss 0.0402512, acc 0.984375
2020-02-08T02:54:10.784988: step 2553, loss 0.0124328, acc 1
2020-02-08T02:54:10.901045: step 2554, loss 0.0110875, acc 1
2020-02-08T02:54:11.014399: step 2555, loss 0.0365477, acc 0.984375
2020-02-08T02:54:11.127204: step 2556, loss 0.00548492, acc 1
2020-02-08T02:54:11.243256: step 2557, loss 0.0194187, acc 1
2020-02-08T02:54:11.359930: step 2558, loss 0.00540724, acc 1
2020-02-08T02:54:11.476042: step 2559, loss 0.0138294, acc 1
2020-02-08T02:54:11.594930: step 2560, loss 0.0439815, acc 0.96875
2020-02-08T02:54:11.712140: step 2561, loss 0.0182016, acc 1
2020-02-08T02:54:11.828481: step 2562, loss 0.0485258, acc 0.984375
2020-02-08T02:54:11.944318: step 2563, loss 0.00827232, acc 1
2020-02-08T02:54:12.060031: step 2564, loss 0.00534939, acc 1
2020-02-08T02:54:12.175435: step 2565, loss 0.00959405, acc 1
2020-02-08T02:54:12.293386: step 2566, loss 0.0375931, acc 0.984375
2020-02-08T02:54:12.411178: step 2567, loss 0.0113444, acc 1
2020-02-08T02:54:12.525245: step 2568, loss 0.0279221, acc 0.984375
2020-02-08T02:54:12.643058: step 2569, loss 0.00910252, acc 1
2020-02-08T02:54:12.760062: step 2570, loss 0.0159257, acc 1
2020-02-08T02:54:12.874993: step 2571, loss 0.0289903, acc 0.984375
2020-02-08T02:54:12.990647: step 2572, loss 0.0531014, acc 0.96875
2020-02-08T02:54:13.106841: step 2573, loss 0.0617933, acc 0.96875
2020-02-08T02:54:13.222029: step 2574, loss 0.0138878, acc 1
2020-02-08T02:54:13.338289: step 2575, loss 0.0280635, acc 0.984375
2020-02-08T02:54:13.452766: step 2576, loss 0.0282358, acc 0.984375
2020-02-08T02:54:13.566905: step 2577, loss 0.0180069, acc 1
2020-02-08T02:54:13.683193: step 2578, loss 0.043576, acc 0.984375
2020-02-08T02:54:13.800798: step 2579, loss 0.0359482, acc 1
2020-02-08T02:54:13.914678: step 2580, loss 0.0167496, acc 1
2020-02-08T02:54:14.031393: step 2581, loss 0.0141823, acc 1
2020-02-08T02:54:14.145680: step 2582, loss 0.0281291, acc 0.984375
2020-02-08T02:54:14.260926: step 2583, loss 0.0353417, acc 1
2020-02-08T02:54:14.377929: step 2584, loss 0.0146701, acc 1
2020-02-08T02:54:14.495661: step 2585, loss 0.011531, acc 1
2020-02-08T02:54:14.610260: step 2586, loss 0.0251996, acc 1
2020-02-08T02:54:14.727326: step 2587, loss 0.0281033, acc 0.984375
2020-02-08T02:54:14.843695: step 2588, loss 0.0246279, acc 0.984375
2020-02-08T02:54:14.959588: step 2589, loss 0.0179253, acc 1
2020-02-08T02:54:15.072785: step 2590, loss 0.125143, acc 0.96875
2020-02-08T02:54:15.190226: step 2591, loss 0.0205615, acc 1
2020-02-08T02:54:15.306639: step 2592, loss 0.0196601, acc 1
2020-02-08T02:54:15.425810: step 2593, loss 0.0571452, acc 0.984375
2020-02-08T02:54:15.543377: step 2594, loss 0.0239398, acc 1
2020-02-08T02:54:15.657934: step 2595, loss 0.0574967, acc 0.984375
2020-02-08T02:54:15.769906: step 2596, loss 0.0433129, acc 0.984375
2020-02-08T02:54:15.887822: step 2597, loss 0.0286466, acc 0.984375
2020-02-08T02:54:16.004489: step 2598, loss 0.0206225, acc 1
2020-02-08T02:54:16.118517: step 2599, loss 0.0114604, acc 1
2020-02-08T02:54:16.235935: step 2600, loss 0.0116325, acc 1

Evaluation:
2020-02-08T02:54:16.425911: step 2600, loss 0.92841, acc 0.736398

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2600

2020-02-08T02:54:18.281843: step 2601, loss 0.0277259, acc 1
2020-02-08T02:54:18.399558: step 2602, loss 0.0152533, acc 1
2020-02-08T02:54:18.516992: step 2603, loss 0.0165682, acc 1
2020-02-08T02:54:18.633279: step 2604, loss 0.0217355, acc 0.984375
2020-02-08T02:54:18.754889: step 2605, loss 0.0880337, acc 0.96875
2020-02-08T02:54:18.870379: step 2606, loss 0.0237536, acc 0.984375
2020-02-08T02:54:18.986553: step 2607, loss 0.0126944, acc 1
2020-02-08T02:54:19.100637: step 2608, loss 0.0658282, acc 0.96875
2020-02-08T02:54:19.215353: step 2609, loss 0.0291818, acc 0.984375
2020-02-08T02:54:19.331708: step 2610, loss 0.0104526, acc 1
2020-02-08T02:54:19.449649: step 2611, loss 0.018411, acc 1
2020-02-08T02:54:19.564371: step 2612, loss 0.0112063, acc 1
2020-02-08T02:54:19.685546: step 2613, loss 0.0216377, acc 0.984375
2020-02-08T02:54:19.801442: step 2614, loss 0.0329942, acc 1
2020-02-08T02:54:19.916834: step 2615, loss 0.0856856, acc 0.96875
2020-02-08T02:54:20.031737: step 2616, loss 0.0609294, acc 0.96875
2020-02-08T02:54:20.147734: step 2617, loss 0.0282582, acc 1
2020-02-08T02:54:20.262623: step 2618, loss 0.0877942, acc 0.953125
2020-02-08T02:54:20.377469: step 2619, loss 0.0137808, acc 1
2020-02-08T02:54:20.491768: step 2620, loss 0.0205037, acc 1
2020-02-08T02:54:20.606313: step 2621, loss 0.0138487, acc 1
2020-02-08T02:54:20.722164: step 2622, loss 0.0156314, acc 1
2020-02-08T02:54:20.838665: step 2623, loss 0.0137265, acc 1
2020-02-08T02:54:20.955798: step 2624, loss 0.0429912, acc 0.984375
2020-02-08T02:54:21.070344: step 2625, loss 0.0131625, acc 1
2020-02-08T02:54:21.185611: step 2626, loss 0.0255889, acc 0.984375
2020-02-08T02:54:21.304124: step 2627, loss 0.0105974, acc 1
2020-02-08T02:54:21.417864: step 2628, loss 0.0116815, acc 1
2020-02-08T02:54:21.565487: step 2629, loss 0.00532018, acc 1
2020-02-08T02:54:21.691047: step 2630, loss 0.0371196, acc 0.984375
2020-02-08T02:54:21.804009: step 2631, loss 0.0131449, acc 1
2020-02-08T02:54:21.917238: step 2632, loss 0.01562, acc 1
2020-02-08T02:54:22.029377: step 2633, loss 0.0342857, acc 0.984375
2020-02-08T02:54:22.146178: step 2634, loss 0.0188057, acc 1
2020-02-08T02:54:22.261176: step 2635, loss 0.0190623, acc 1
2020-02-08T02:54:22.377578: step 2636, loss 0.0182379, acc 0.984375
2020-02-08T02:54:22.494967: step 2637, loss 0.025349, acc 1
2020-02-08T02:54:22.612229: step 2638, loss 0.0490922, acc 0.96875
2020-02-08T02:54:22.729945: step 2639, loss 0.0167914, acc 1
2020-02-08T02:54:22.845606: step 2640, loss 0.0115989, acc 1
2020-02-08T02:54:22.960249: step 2641, loss 0.0304885, acc 0.984375
2020-02-08T02:54:23.074555: step 2642, loss 0.0081037, acc 1
2020-02-08T02:54:23.190134: step 2643, loss 0.0388718, acc 0.984375
2020-02-08T02:54:23.307651: step 2644, loss 0.0169853, acc 1
2020-02-08T02:54:23.424711: step 2645, loss 0.0434145, acc 0.984375
2020-02-08T02:54:23.541250: step 2646, loss 0.00526114, acc 1
2020-02-08T02:54:23.655216: step 2647, loss 0.0745321, acc 0.984375
2020-02-08T02:54:23.771081: step 2648, loss 0.0532114, acc 0.96875
2020-02-08T02:54:23.890758: step 2649, loss 0.027049, acc 0.984375
2020-02-08T02:54:24.007312: step 2650, loss 0.0342287, acc 0.984375
2020-02-08T02:54:24.124105: step 2651, loss 0.0216925, acc 1
2020-02-08T02:54:24.238971: step 2652, loss 0.0120058, acc 1
2020-02-08T02:54:24.355037: step 2653, loss 0.0106627, acc 1
2020-02-08T02:54:24.472692: step 2654, loss 0.0192726, acc 1
2020-02-08T02:54:24.588439: step 2655, loss 0.0204833, acc 1
2020-02-08T02:54:24.706659: step 2656, loss 0.043259, acc 0.984375
2020-02-08T02:54:24.820503: step 2657, loss 0.0197805, acc 1
2020-02-08T02:54:24.936625: step 2658, loss 0.00378484, acc 1
2020-02-08T02:54:25.050736: step 2659, loss 0.0796099, acc 0.984375
2020-02-08T02:54:25.163237: step 2660, loss 0.0486563, acc 0.96875
2020-02-08T02:54:25.279659: step 2661, loss 0.016176, acc 1
2020-02-08T02:54:25.398094: step 2662, loss 0.0337929, acc 0.984375
2020-02-08T02:54:25.513025: step 2663, loss 0.0239668, acc 1
2020-02-08T02:54:25.629857: step 2664, loss 0.147448, acc 0.953125
2020-02-08T02:54:25.745535: step 2665, loss 0.0725042, acc 0.953125
2020-02-08T02:54:25.857669: step 2666, loss 0.0354198, acc 0.984375
2020-02-08T02:54:25.974505: step 2667, loss 0.0053704, acc 1
2020-02-08T02:54:26.086206: step 2668, loss 0.0302376, acc 1
2020-02-08T02:54:26.202223: step 2669, loss 0.0343589, acc 0.984375
2020-02-08T02:54:26.316937: step 2670, loss 0.0626379, acc 0.96875
2020-02-08T02:54:26.434285: step 2671, loss 0.0513374, acc 0.96875
2020-02-08T02:54:26.550286: step 2672, loss 0.0107307, acc 1
2020-02-08T02:54:26.667636: step 2673, loss 0.00535834, acc 1
2020-02-08T02:54:26.784895: step 2674, loss 0.0120893, acc 1
2020-02-08T02:54:26.903358: step 2675, loss 0.0228294, acc 1
2020-02-08T02:54:27.021005: step 2676, loss 0.0348407, acc 0.984375
2020-02-08T02:54:27.136221: step 2677, loss 0.0299772, acc 0.984375
2020-02-08T02:54:27.252478: step 2678, loss 0.00708649, acc 1
2020-02-08T02:54:27.366867: step 2679, loss 0.0108975, acc 1
2020-02-08T02:54:27.482814: step 2680, loss 0.085777, acc 0.96875
2020-02-08T02:54:27.600982: step 2681, loss 0.0284791, acc 1
2020-02-08T02:54:27.716512: step 2682, loss 0.0100493, acc 1
2020-02-08T02:54:27.830969: step 2683, loss 0.0786897, acc 0.984375
2020-02-08T02:54:27.948653: step 2684, loss 0.0197019, acc 1
2020-02-08T02:54:28.064358: step 2685, loss 0.0216929, acc 1
2020-02-08T02:54:28.181739: step 2686, loss 0.0225395, acc 0.984375
2020-02-08T02:54:28.296305: step 2687, loss 0.0177993, acc 1
2020-02-08T02:54:28.413360: step 2688, loss 0.0568924, acc 0.96875
2020-02-08T02:54:28.528113: step 2689, loss 0.0930615, acc 0.96875
2020-02-08T02:54:28.644704: step 2690, loss 0.0081062, acc 1
2020-02-08T02:54:28.759258: step 2691, loss 0.0837723, acc 0.984375
2020-02-08T02:54:28.874823: step 2692, loss 0.0495993, acc 0.984375
2020-02-08T02:54:28.991894: step 2693, loss 0.0344935, acc 0.984375
2020-02-08T02:54:29.131952: step 2694, loss 0.0422325, acc 0.96875
2020-02-08T02:54:29.250470: step 2695, loss 0.0345298, acc 0.984375
2020-02-08T02:54:29.364451: step 2696, loss 0.0129317, acc 1
2020-02-08T02:54:29.484492: step 2697, loss 0.0136183, acc 1
2020-02-08T02:54:29.601825: step 2698, loss 0.0223805, acc 1
2020-02-08T02:54:29.716879: step 2699, loss 0.00838813, acc 1
2020-02-08T02:54:29.827874: step 2700, loss 0.03251, acc 0.983333

Evaluation:
2020-02-08T02:54:30.012933: step 2700, loss 0.957103, acc 0.742026

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2700

2020-02-08T02:54:31.576743: step 2701, loss 0.0179425, acc 1
2020-02-08T02:54:31.693852: step 2702, loss 0.00374625, acc 1
2020-02-08T02:54:31.811288: step 2703, loss 0.0059365, acc 1
2020-02-08T02:54:31.925124: step 2704, loss 0.00655844, acc 1
2020-02-08T02:54:32.043889: step 2705, loss 0.0265313, acc 1
2020-02-08T02:54:32.157685: step 2706, loss 0.0188416, acc 1
2020-02-08T02:54:32.272541: step 2707, loss 0.0115992, acc 1
2020-02-08T02:54:32.390208: step 2708, loss 0.00760971, acc 1
2020-02-08T02:54:32.506312: step 2709, loss 0.0171828, acc 0.984375
2020-02-08T02:54:32.621172: step 2710, loss 0.00969791, acc 1
2020-02-08T02:54:32.740157: step 2711, loss 0.0527378, acc 0.984375
2020-02-08T02:54:32.855829: step 2712, loss 0.0138833, acc 1
2020-02-08T02:54:32.974738: step 2713, loss 0.0144895, acc 1
2020-02-08T02:54:33.092195: step 2714, loss 0.00950337, acc 1
2020-02-08T02:54:33.208373: step 2715, loss 0.00925437, acc 1
2020-02-08T02:54:33.329022: step 2716, loss 0.0815646, acc 0.96875
2020-02-08T02:54:33.448296: step 2717, loss 0.00829546, acc 1
2020-02-08T02:54:33.563455: step 2718, loss 0.0331185, acc 0.984375
2020-02-08T02:54:33.680047: step 2719, loss 0.0185812, acc 1
2020-02-08T02:54:33.797281: step 2720, loss 0.0745615, acc 0.984375
2020-02-08T02:54:33.911378: step 2721, loss 0.0156414, acc 1
2020-02-08T02:54:34.028316: step 2722, loss 0.03548, acc 1
2020-02-08T02:54:34.145242: step 2723, loss 0.0135387, acc 1
2020-02-08T02:54:34.260704: step 2724, loss 0.019635, acc 1
2020-02-08T02:54:34.375722: step 2725, loss 0.0625691, acc 0.96875
2020-02-08T02:54:34.491840: step 2726, loss 0.0279641, acc 0.984375
2020-02-08T02:54:34.609048: step 2727, loss 0.0111022, acc 1
2020-02-08T02:54:34.727079: step 2728, loss 0.0619993, acc 0.984375
2020-02-08T02:54:34.845271: step 2729, loss 0.0717102, acc 0.96875
2020-02-08T02:54:34.962135: step 2730, loss 0.0395877, acc 0.984375
2020-02-08T02:54:35.076957: step 2731, loss 0.0168105, acc 1
2020-02-08T02:54:35.192382: step 2732, loss 0.0172156, acc 1
2020-02-08T02:54:35.309737: step 2733, loss 0.0277095, acc 0.984375
2020-02-08T02:54:35.423570: step 2734, loss 0.00812256, acc 1
2020-02-08T02:54:35.538117: step 2735, loss 0.0292232, acc 0.984375
2020-02-08T02:54:35.652235: step 2736, loss 0.0127142, acc 1
2020-02-08T02:54:35.766928: step 2737, loss 0.0227006, acc 1
2020-02-08T02:54:35.883873: step 2738, loss 0.0181268, acc 1
2020-02-08T02:54:36.000609: step 2739, loss 0.0378683, acc 0.984375
2020-02-08T02:54:36.115588: step 2740, loss 0.0115148, acc 1
2020-02-08T02:54:36.230234: step 2741, loss 0.00678051, acc 1
2020-02-08T02:54:36.348298: step 2742, loss 0.0563919, acc 0.984375
2020-02-08T02:54:36.464489: step 2743, loss 0.0797767, acc 0.96875
2020-02-08T02:54:36.581815: step 2744, loss 0.00745169, acc 1
2020-02-08T02:54:36.698509: step 2745, loss 0.086558, acc 0.984375
2020-02-08T02:54:36.813470: step 2746, loss 0.0313784, acc 0.984375
2020-02-08T02:54:36.927448: step 2747, loss 0.0117291, acc 1
2020-02-08T02:54:37.045739: step 2748, loss 0.00681686, acc 1
2020-02-08T02:54:37.162240: step 2749, loss 0.0172635, acc 0.984375
2020-02-08T02:54:37.276428: step 2750, loss 0.0191968, acc 1
2020-02-08T02:54:37.393465: step 2751, loss 0.00948337, acc 1
2020-02-08T02:54:37.508882: step 2752, loss 0.0389613, acc 1
2020-02-08T02:54:37.625740: step 2753, loss 0.00980594, acc 1
2020-02-08T02:54:37.747337: step 2754, loss 0.0269647, acc 0.984375
2020-02-08T02:54:37.862216: step 2755, loss 0.017902, acc 1
2020-02-08T02:54:37.978478: step 2756, loss 0.0156012, acc 1
2020-02-08T02:54:38.095502: step 2757, loss 0.0165248, acc 1
2020-02-08T02:54:38.212379: step 2758, loss 0.00655717, acc 1
2020-02-08T02:54:38.331440: step 2759, loss 0.012669, acc 1
2020-02-08T02:54:38.447813: step 2760, loss 0.0142614, acc 1
2020-02-08T02:54:38.566363: step 2761, loss 0.0206309, acc 1
2020-02-08T02:54:38.681608: step 2762, loss 0.0441321, acc 0.984375
2020-02-08T02:54:38.796694: step 2763, loss 0.00525903, acc 1
2020-02-08T02:54:38.913582: step 2764, loss 0.0121598, acc 1
2020-02-08T02:54:39.030778: step 2765, loss 0.00872729, acc 1
2020-02-08T02:54:39.146745: step 2766, loss 0.00291116, acc 1
2020-02-08T02:54:39.260936: step 2767, loss 0.0141721, acc 1
2020-02-08T02:54:39.375983: step 2768, loss 0.00893719, acc 1
2020-02-08T02:54:39.492364: step 2769, loss 0.0247311, acc 1
2020-02-08T02:54:39.610293: step 2770, loss 0.0122118, acc 1
2020-02-08T02:54:39.726329: step 2771, loss 0.00943831, acc 1
2020-02-08T02:54:39.843941: step 2772, loss 0.0266999, acc 0.984375
2020-02-08T02:54:39.963304: step 2773, loss 0.00970868, acc 1
2020-02-08T02:54:40.080306: step 2774, loss 0.0252525, acc 0.984375
2020-02-08T02:54:40.197206: step 2775, loss 0.0297843, acc 0.984375
2020-02-08T02:54:40.313768: step 2776, loss 0.0437328, acc 0.984375
2020-02-08T02:54:40.429053: step 2777, loss 0.0226272, acc 1
2020-02-08T02:54:40.545960: step 2778, loss 0.0139223, acc 1
2020-02-08T02:54:40.663236: step 2779, loss 0.047886, acc 0.984375
2020-02-08T02:54:40.780840: step 2780, loss 0.0599963, acc 0.984375
2020-02-08T02:54:40.897838: step 2781, loss 0.0589146, acc 0.96875
2020-02-08T02:54:41.014737: step 2782, loss 0.0180426, acc 1
2020-02-08T02:54:41.128188: step 2783, loss 0.0242776, acc 1
2020-02-08T02:54:41.242250: step 2784, loss 0.0177856, acc 1
2020-02-08T02:54:41.356528: step 2785, loss 0.00499019, acc 1
2020-02-08T02:54:41.473305: step 2786, loss 0.0327259, acc 0.984375
2020-02-08T02:54:41.589599: step 2787, loss 0.0058009, acc 1
2020-02-08T02:54:41.707327: step 2788, loss 0.0107715, acc 1
2020-02-08T02:54:41.824799: step 2789, loss 0.0950074, acc 0.9375
2020-02-08T02:54:41.940279: step 2790, loss 0.0296854, acc 0.984375
2020-02-08T02:54:42.055473: step 2791, loss 0.0527837, acc 0.984375
2020-02-08T02:54:42.173039: step 2792, loss 0.0307908, acc 1
2020-02-08T02:54:42.290182: step 2793, loss 0.0121547, acc 1
2020-02-08T02:54:42.407144: step 2794, loss 0.0475069, acc 0.984375
2020-02-08T02:54:42.524492: step 2795, loss 0.0166131, acc 1
2020-02-08T02:54:42.639049: step 2796, loss 0.00545592, acc 1
2020-02-08T02:54:42.757099: step 2797, loss 0.0182842, acc 1
2020-02-08T02:54:42.873974: step 2798, loss 0.0161147, acc 1
2020-02-08T02:54:42.990173: step 2799, loss 0.0233474, acc 1
2020-02-08T02:54:43.108208: step 2800, loss 0.0253898, acc 0.984375

Evaluation:
2020-02-08T02:54:43.295694: step 2800, loss 1.03906, acc 0.711069

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2800

2020-02-08T02:54:44.847065: step 2801, loss 0.021753, acc 0.984375
2020-02-08T02:54:44.962866: step 2802, loss 0.0143716, acc 1
2020-02-08T02:54:45.079896: step 2803, loss 0.0141654, acc 1
2020-02-08T02:54:45.195758: step 2804, loss 0.0576773, acc 0.984375
2020-02-08T02:54:45.313248: step 2805, loss 0.0188617, acc 1
2020-02-08T02:54:45.432356: step 2806, loss 0.0305297, acc 1
2020-02-08T02:54:45.550679: step 2807, loss 0.0222097, acc 1
2020-02-08T02:54:45.665775: step 2808, loss 0.0328436, acc 0.984375
2020-02-08T02:54:45.782847: step 2809, loss 0.0636861, acc 0.984375
2020-02-08T02:54:45.896493: step 2810, loss 0.00879423, acc 1
2020-02-08T02:54:46.011254: step 2811, loss 0.0715153, acc 0.984375
2020-02-08T02:54:46.124226: step 2812, loss 0.0233031, acc 1
2020-02-08T02:54:46.239534: step 2813, loss 0.0221754, acc 1
2020-02-08T02:54:46.355921: step 2814, loss 0.0581152, acc 0.984375
2020-02-08T02:54:46.470493: step 2815, loss 0.00473688, acc 1
2020-02-08T02:54:46.587986: step 2816, loss 0.0505631, acc 0.984375
2020-02-08T02:54:46.704845: step 2817, loss 0.0112101, acc 1
2020-02-08T02:54:46.823032: step 2818, loss 0.0203839, acc 1
2020-02-08T02:54:46.939886: step 2819, loss 0.0239315, acc 1
2020-02-08T02:54:47.054521: step 2820, loss 0.0203082, acc 0.984375
2020-02-08T02:54:47.169722: step 2821, loss 0.0104549, acc 1
2020-02-08T02:54:47.285833: step 2822, loss 0.0207253, acc 1
2020-02-08T02:54:47.401170: step 2823, loss 0.0260351, acc 1
2020-02-08T02:54:47.517227: step 2824, loss 0.0227552, acc 0.984375
2020-02-08T02:54:47.633861: step 2825, loss 0.0564138, acc 0.96875
2020-02-08T02:54:47.748368: step 2826, loss 0.0198072, acc 1
2020-02-08T02:54:47.865000: step 2827, loss 0.0176071, acc 1
2020-02-08T02:54:47.983706: step 2828, loss 0.0115251, acc 1
2020-02-08T02:54:48.101079: step 2829, loss 0.0418419, acc 0.984375
2020-02-08T02:54:48.217259: step 2830, loss 0.0796073, acc 0.96875
2020-02-08T02:54:48.338798: step 2831, loss 0.0760157, acc 0.96875
2020-02-08T02:54:48.455484: step 2832, loss 0.0767155, acc 0.96875
2020-02-08T02:54:48.576030: step 2833, loss 0.0155537, acc 1
2020-02-08T02:54:48.695021: step 2834, loss 0.0180782, acc 1
2020-02-08T02:54:48.812339: step 2835, loss 0.0147225, acc 1
2020-02-08T02:54:48.927250: step 2836, loss 0.0100272, acc 1
2020-02-08T02:54:49.044870: step 2837, loss 0.0208376, acc 1
2020-02-08T02:54:49.161531: step 2838, loss 0.0170526, acc 1
2020-02-08T02:54:49.277573: step 2839, loss 0.0170173, acc 1
2020-02-08T02:54:49.396479: step 2840, loss 0.103426, acc 0.96875
2020-02-08T02:54:49.513921: step 2841, loss 0.0858087, acc 0.984375
2020-02-08T02:54:49.631585: step 2842, loss 0.0475727, acc 0.984375
2020-02-08T02:54:49.751989: step 2843, loss 0.00501559, acc 1
2020-02-08T02:54:49.867110: step 2844, loss 0.0958083, acc 0.953125
2020-02-08T02:54:49.984599: step 2845, loss 0.0236055, acc 0.984375
2020-02-08T02:54:50.108457: step 2846, loss 0.0441363, acc 1
2020-02-08T02:54:50.225342: step 2847, loss 0.00867338, acc 1
2020-02-08T02:54:50.342436: step 2848, loss 0.0108303, acc 1
2020-02-08T02:54:50.460208: step 2849, loss 0.0114644, acc 1
2020-02-08T02:54:50.574027: step 2850, loss 0.0124865, acc 1
2020-02-08T02:54:50.693414: step 2851, loss 0.0230775, acc 0.984375
2020-02-08T02:54:50.810042: step 2852, loss 0.0220365, acc 1
2020-02-08T02:54:50.924469: step 2853, loss 0.0165167, acc 1
2020-02-08T02:54:51.041795: step 2854, loss 0.0134474, acc 1
2020-02-08T02:54:51.156664: step 2855, loss 0.0258608, acc 1
2020-02-08T02:54:51.277687: step 2856, loss 0.0105432, acc 1
2020-02-08T02:54:51.393072: step 2857, loss 0.0526365, acc 0.96875
2020-02-08T02:54:51.687302: step 2858, loss 0.00429044, acc 1
2020-02-08T02:54:51.815466: step 2859, loss 0.0184248, acc 1
2020-02-08T02:54:51.942705: step 2860, loss 0.0375892, acc 0.984375
2020-02-08T02:54:52.057203: step 2861, loss 0.0111494, acc 1
2020-02-08T02:54:52.172222: step 2862, loss 0.0200071, acc 1
2020-02-08T02:54:52.287957: step 2863, loss 0.0556637, acc 0.96875
2020-02-08T02:54:52.406079: step 2864, loss 0.00670561, acc 1
2020-02-08T02:54:52.522535: step 2865, loss 0.0324349, acc 0.984375
2020-02-08T02:54:52.638968: step 2866, loss 0.0124137, acc 1
2020-02-08T02:54:52.757299: step 2867, loss 0.00678595, acc 1
2020-02-08T02:54:52.874725: step 2868, loss 0.0419994, acc 0.984375
2020-02-08T02:54:52.993784: step 2869, loss 0.00845931, acc 1
2020-02-08T02:54:53.107781: step 2870, loss 0.00815705, acc 1
2020-02-08T02:54:53.223311: step 2871, loss 0.00803293, acc 1
2020-02-08T02:54:53.341677: step 2872, loss 0.0473991, acc 0.984375
2020-02-08T02:54:53.456586: step 2873, loss 0.00810632, acc 1
2020-02-08T02:54:53.574076: step 2874, loss 0.0306611, acc 0.984375
2020-02-08T02:54:53.690893: step 2875, loss 0.0623836, acc 0.96875
2020-02-08T02:54:53.807863: step 2876, loss 0.015507, acc 1
2020-02-08T02:54:53.923614: step 2877, loss 0.00679081, acc 1
2020-02-08T02:54:54.039370: step 2878, loss 0.00440895, acc 1
2020-02-08T02:54:54.156884: step 2879, loss 0.0499504, acc 0.96875
2020-02-08T02:54:54.274507: step 2880, loss 0.0264342, acc 0.984375
2020-02-08T02:54:54.395948: step 2881, loss 0.038058, acc 0.984375
2020-02-08T02:54:54.511216: step 2882, loss 0.0284384, acc 1
2020-02-08T02:54:54.627479: step 2883, loss 0.039066, acc 0.984375
2020-02-08T02:54:54.746524: step 2884, loss 0.0177655, acc 1
2020-02-08T02:54:54.862016: step 2885, loss 0.0188803, acc 1
2020-02-08T02:54:54.975858: step 2886, loss 0.0268324, acc 0.984375
2020-02-08T02:54:55.092707: step 2887, loss 0.00694987, acc 1
2020-02-08T02:54:55.210208: step 2888, loss 0.0123633, acc 1
2020-02-08T02:54:55.326519: step 2889, loss 0.0316944, acc 0.984375
2020-02-08T02:54:55.445410: step 2890, loss 0.0093252, acc 1
2020-02-08T02:54:55.561953: step 2891, loss 0.065112, acc 0.96875
2020-02-08T02:54:55.693125: step 2892, loss 0.0125895, acc 1
2020-02-08T02:54:55.810634: step 2893, loss 0.0227283, acc 0.984375
2020-02-08T02:54:55.927937: step 2894, loss 0.107417, acc 0.96875
2020-02-08T02:54:56.046750: step 2895, loss 0.0587476, acc 0.96875
2020-02-08T02:54:56.167514: step 2896, loss 0.00942309, acc 1
2020-02-08T02:54:56.286280: step 2897, loss 0.0351299, acc 0.984375
2020-02-08T02:54:56.401226: step 2898, loss 0.0246153, acc 1
2020-02-08T02:54:56.516592: step 2899, loss 0.00746936, acc 1
2020-02-08T02:54:56.634909: step 2900, loss 0.0448605, acc 0.984375

Evaluation:
2020-02-08T02:54:56.823131: step 2900, loss 1.00387, acc 0.732645

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-2900

2020-02-08T02:54:58.321686: step 2901, loss 0.0114639, acc 1
2020-02-08T02:54:58.442416: step 2902, loss 0.018129, acc 1
2020-02-08T02:54:58.558597: step 2903, loss 0.0126854, acc 1
2020-02-08T02:54:58.678608: step 2904, loss 0.0196737, acc 1
2020-02-08T02:54:58.793228: step 2905, loss 0.058814, acc 0.984375
2020-02-08T02:54:58.908381: step 2906, loss 0.00350262, acc 1
2020-02-08T02:54:59.025379: step 2907, loss 0.0153372, acc 1
2020-02-08T02:54:59.142604: step 2908, loss 0.0221527, acc 1
2020-02-08T02:54:59.258741: step 2909, loss 0.0119785, acc 1
2020-02-08T02:54:59.378772: step 2910, loss 0.0707605, acc 0.953125
2020-02-08T02:54:59.494486: step 2911, loss 0.0252339, acc 0.984375
2020-02-08T02:54:59.612193: step 2912, loss 0.0234577, acc 1
2020-02-08T02:54:59.728625: step 2913, loss 0.0139417, acc 1
2020-02-08T02:54:59.847291: step 2914, loss 0.0257459, acc 0.984375
2020-02-08T02:54:59.962197: step 2915, loss 0.0199765, acc 1
2020-02-08T02:55:00.079389: step 2916, loss 0.0190925, acc 1
2020-02-08T02:55:00.196866: step 2917, loss 0.0319268, acc 0.984375
2020-02-08T02:55:00.312337: step 2918, loss 0.0133605, acc 1
2020-02-08T02:55:00.425590: step 2919, loss 0.00886449, acc 1
2020-02-08T02:55:00.544741: step 2920, loss 0.0484517, acc 0.984375
2020-02-08T02:55:00.659658: step 2921, loss 0.0189271, acc 0.984375
2020-02-08T02:55:00.778075: step 2922, loss 0.00966118, acc 1
2020-02-08T02:55:00.895802: step 2923, loss 0.0326032, acc 0.984375
2020-02-08T02:55:01.011960: step 2924, loss 0.00971334, acc 1
2020-02-08T02:55:01.130078: step 2925, loss 0.107115, acc 0.96875
2020-02-08T02:55:01.249988: step 2926, loss 0.0786496, acc 0.96875
2020-02-08T02:55:01.364705: step 2927, loss 0.00460056, acc 1
2020-02-08T02:55:01.479466: step 2928, loss 0.0243576, acc 1
2020-02-08T02:55:01.599465: step 2929, loss 0.0114076, acc 1
2020-02-08T02:55:01.714278: step 2930, loss 0.017651, acc 1
2020-02-08T02:55:01.833041: step 2931, loss 0.0144715, acc 1
2020-02-08T02:55:01.948677: step 2932, loss 0.0191596, acc 0.984375
2020-02-08T02:55:02.064474: step 2933, loss 0.0219429, acc 0.984375
2020-02-08T02:55:02.180237: step 2934, loss 0.013411, acc 1
2020-02-08T02:55:02.297097: step 2935, loss 0.00686534, acc 1
2020-02-08T02:55:02.412707: step 2936, loss 0.0255242, acc 1
2020-02-08T02:55:02.529700: step 2937, loss 0.0270244, acc 0.984375
2020-02-08T02:55:02.655718: step 2938, loss 0.010734, acc 1
2020-02-08T02:55:02.773907: step 2939, loss 0.0126697, acc 1
2020-02-08T02:55:02.893966: step 2940, loss 0.0149654, acc 1
2020-02-08T02:55:03.009214: step 2941, loss 0.0241422, acc 1
2020-02-08T02:55:03.124946: step 2942, loss 0.019087, acc 0.984375
2020-02-08T02:55:03.244937: step 2943, loss 0.0310299, acc 0.984375
2020-02-08T02:55:03.359534: step 2944, loss 0.0227341, acc 0.984375
2020-02-08T02:55:03.476182: step 2945, loss 0.0143054, acc 1
2020-02-08T02:55:03.594947: step 2946, loss 0.0126703, acc 1
2020-02-08T02:55:03.713191: step 2947, loss 0.0598537, acc 0.984375
2020-02-08T02:55:03.828245: step 2948, loss 0.0331365, acc 0.984375
2020-02-08T02:55:03.944387: step 2949, loss 0.0142237, acc 1
2020-02-08T02:55:04.061276: step 2950, loss 0.017014, acc 1
2020-02-08T02:55:04.176491: step 2951, loss 0.00546785, acc 1
2020-02-08T02:55:04.292329: step 2952, loss 0.0258401, acc 0.984375
2020-02-08T02:55:04.410013: step 2953, loss 0.052452, acc 0.984375
2020-02-08T02:55:04.526805: step 2954, loss 0.0124047, acc 1
2020-02-08T02:55:04.644832: step 2955, loss 0.0308467, acc 0.984375
2020-02-08T02:55:04.760335: step 2956, loss 0.0154856, acc 0.984375
2020-02-08T02:55:04.875944: step 2957, loss 0.0138862, acc 1
2020-02-08T02:55:04.994061: step 2958, loss 0.0131369, acc 1
2020-02-08T02:55:05.108928: step 2959, loss 0.0557416, acc 0.96875
2020-02-08T02:55:05.225020: step 2960, loss 0.0214854, acc 0.984375
2020-02-08T02:55:05.339233: step 2961, loss 0.0120646, acc 1
2020-02-08T02:55:05.457999: step 2962, loss 0.0301181, acc 1
2020-02-08T02:55:05.578708: step 2963, loss 0.0139657, acc 1
2020-02-08T02:55:05.695840: step 2964, loss 0.0217221, acc 1
2020-02-08T02:55:05.810612: step 2965, loss 0.0210546, acc 1
2020-02-08T02:55:05.924748: step 2966, loss 0.00840945, acc 1
2020-02-08T02:55:06.042676: step 2967, loss 0.0217131, acc 1
2020-02-08T02:55:06.158588: step 2968, loss 0.0643792, acc 0.984375
2020-02-08T02:55:06.271793: step 2969, loss 0.0255617, acc 1
2020-02-08T02:55:06.390053: step 2970, loss 0.00270825, acc 1
2020-02-08T02:55:06.506026: step 2971, loss 0.0494721, acc 0.984375
2020-02-08T02:55:06.622155: step 2972, loss 0.0170852, acc 1
2020-02-08T02:55:06.737998: step 2973, loss 0.0215595, acc 1
2020-02-08T02:55:06.855648: step 2974, loss 0.0101001, acc 1
2020-02-08T02:55:06.971166: step 2975, loss 0.00392832, acc 1
2020-02-08T02:55:07.088773: step 2976, loss 0.0146392, acc 1
2020-02-08T02:55:07.204037: step 2977, loss 0.0092167, acc 1
2020-02-08T02:55:07.319945: step 2978, loss 0.00783746, acc 1
2020-02-08T02:55:07.436327: step 2979, loss 0.0157489, acc 1
2020-02-08T02:55:07.553450: step 2980, loss 0.0063015, acc 1
2020-02-08T02:55:07.671316: step 2981, loss 0.0108303, acc 1
2020-02-08T02:55:07.785436: step 2982, loss 0.0321861, acc 0.984375
2020-02-08T02:55:07.901356: step 2983, loss 0.0158162, acc 0.984375
2020-02-08T02:55:08.015594: step 2984, loss 0.0204906, acc 0.984375
2020-02-08T02:55:08.132098: step 2985, loss 0.00639301, acc 1
2020-02-08T02:55:08.247498: step 2986, loss 0.00634391, acc 1
2020-02-08T02:55:08.362858: step 2987, loss 0.0183554, acc 1
2020-02-08T02:55:08.478892: step 2988, loss 0.00850662, acc 1
2020-02-08T02:55:08.597376: step 2989, loss 0.0182154, acc 0.984375
2020-02-08T02:55:08.713617: step 2990, loss 0.00821327, acc 1
2020-02-08T02:55:08.830006: step 2991, loss 0.0191043, acc 0.984375
2020-02-08T02:55:08.948865: step 2992, loss 0.0187494, acc 1
2020-02-08T02:55:09.067236: step 2993, loss 0.00540241, acc 1
2020-02-08T02:55:09.184762: step 2994, loss 0.00597257, acc 1
2020-02-08T02:55:09.302471: step 2995, loss 0.0266064, acc 0.984375
2020-02-08T02:55:09.416620: step 2996, loss 0.0160968, acc 1
2020-02-08T02:55:09.534087: step 2997, loss 0.0372036, acc 0.984375
2020-02-08T02:55:09.650941: step 2998, loss 0.00941273, acc 1
2020-02-08T02:55:09.765196: step 2999, loss 0.00699222, acc 1
2020-02-08T02:55:09.879850: step 3000, loss 0.0979237, acc 0.983333

Evaluation:
2020-02-08T02:55:10.068456: step 3000, loss 1.03089, acc 0.726079

Saved model checkpoint to /Volumes/Transcend/Mutation/CNN-TF/runs/1581101302/checkpoints/model-3000

