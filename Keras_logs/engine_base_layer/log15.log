Using TensorFlow backend.
Load data...
Adjusting sequence length for actual size
x_train shape: (9595, 56)
x_test shape: (1067, 56)
Vocabulary Size: 18779
Model type is CNN-non-static
Load existing Word2Vec model '50features_1minwords_10context'
Traceback (most recent call last):
  File "sentiment_cnn.py", line 135, in <module>
    z = Embedding(len(vocabulary_inv), embedding_dim, input_length=sequence_length, name="embedding")(model_input)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/engine/base_layer.py", line 489, in __call__
    output = self.call(inputs, **kwargs)
  File "/Volumes/Transcend/opt/anaconda3/envs/keras/lib/python3.6/site-packages/keras/layers/embeddings.py", line 144, in call
    out = K.gather(self.embeddings, inputs)
AttributeError: 'Embedding' object has no attribute 'embeddings'
